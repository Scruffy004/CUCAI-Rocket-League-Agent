Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.52332
Policy Entropy: 2.32721
Value Function Loss: 0.01738

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.20353
Value Function Update Magnitude: 0.19808

Collected Steps per Second: 7,282.33451
Overall Steps per Second: 4,030.11543

Timestep Collection Time: 6.87005
Timestep Consumption Time: 5.54399
PPO Batch Consumption Time: 2.26332
Total Iteration Time: 12.41404

Cumulative Model Updates: 199,698
Cumulative Timesteps: 1,665,471,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.40250
Policy Entropy: 2.28925
Value Function Loss: 0.01769

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.43823
Value Function Update Magnitude: 0.39781

Collected Steps per Second: 22,379.90299
Overall Steps per Second: 11,947.44129

Timestep Collection Time: 2.23495
Timestep Consumption Time: 1.95155
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.18650

Cumulative Model Updates: 199,702
Cumulative Timesteps: 1,665,521,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1665521726...
Checkpoint 1665521726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.31939
Policy Entropy: 2.27002
Value Function Loss: 0.01648

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.43173
Value Function Update Magnitude: 0.41492

Collected Steps per Second: 20,539.59711
Overall Steps per Second: 11,473.85986

Timestep Collection Time: 2.43481
Timestep Consumption Time: 1.92379
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.35860

Cumulative Model Updates: 199,706
Cumulative Timesteps: 1,665,571,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.89113
Policy Entropy: 2.25576
Value Function Loss: 0.01655

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.59392
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 22,252.60241
Overall Steps per Second: 10,631.63152

Timestep Collection Time: 2.24774
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70464

Cumulative Model Updates: 199,712
Cumulative Timesteps: 1,665,621,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1665621754...
Checkpoint 1665621754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.38255
Policy Entropy: 2.23202
Value Function Loss: 0.01570

Mean KL Divergence: 0.02964
SB3 Clip Fraction: 0.19846
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.60334

Collected Steps per Second: 21,674.21457
Overall Steps per Second: 10,583.05633

Timestep Collection Time: 2.30790
Timestep Consumption Time: 2.41871
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.72661

Cumulative Model Updates: 199,718
Cumulative Timesteps: 1,665,671,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.18877
Policy Entropy: 2.25913
Value Function Loss: 0.01557

Mean KL Divergence: 0.02774
SB3 Clip Fraction: 0.18729
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.56782

Collected Steps per Second: 20,603.99221
Overall Steps per Second: 9,968.88629

Timestep Collection Time: 2.42788
Timestep Consumption Time: 2.59013
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 5.01801

Cumulative Model Updates: 199,724
Cumulative Timesteps: 1,665,721,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1665721800...
Checkpoint 1665721800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.48833
Policy Entropy: 2.26455
Value Function Loss: 0.01530

Mean KL Divergence: 0.02853
SB3 Clip Fraction: 0.18662
Policy Update Magnitude: 0.50254
Value Function Update Magnitude: 0.54709

Collected Steps per Second: 22,514.26387
Overall Steps per Second: 10,709.88942

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.66952

Cumulative Model Updates: 199,730
Cumulative Timesteps: 1,665,771,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.56967
Policy Entropy: 2.29381
Value Function Loss: 0.01594

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.50738
Value Function Update Magnitude: 0.52988

Collected Steps per Second: 22,589.86768
Overall Steps per Second: 10,348.97898

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.61916
PPO Batch Consumption Time: 0.30344
Total Iteration Time: 4.83352

Cumulative Model Updates: 199,736
Cumulative Timesteps: 1,665,821,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1665821832...
Checkpoint 1665821832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.48113
Policy Entropy: 2.29182
Value Function Loss: 0.01596

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.15882
Policy Update Magnitude: 0.51562
Value Function Update Magnitude: 0.54245

Collected Steps per Second: 21,851.63480
Overall Steps per Second: 10,434.48337

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.79238

Cumulative Model Updates: 199,742
Cumulative Timesteps: 1,665,871,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.40602
Policy Entropy: 2.27980
Value Function Loss: 0.01569

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 20,527.29347
Overall Steps per Second: 10,171.81145

Timestep Collection Time: 2.43666
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 4.91731

Cumulative Model Updates: 199,748
Cumulative Timesteps: 1,665,921,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1665921856...
Checkpoint 1665921856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.24154
Policy Entropy: 2.26835
Value Function Loss: 0.01581

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 21,436.05083
Overall Steps per Second: 10,265.49321

Timestep Collection Time: 2.33327
Timestep Consumption Time: 2.53898
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.87225

Cumulative Model Updates: 199,754
Cumulative Timesteps: 1,665,971,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.83584
Policy Entropy: 2.26491
Value Function Loss: 0.01647

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.54807

Collected Steps per Second: 20,432.55177
Overall Steps per Second: 10,217.21831

Timestep Collection Time: 2.44854
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.89664

Cumulative Model Updates: 199,760
Cumulative Timesteps: 1,666,021,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1666021902...
Checkpoint 1666021902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.55122
Policy Entropy: 2.28956
Value Function Loss: 0.01654

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.57877

Collected Steps per Second: 21,009.63608
Overall Steps per Second: 10,003.19414

Timestep Collection Time: 2.38081
Timestep Consumption Time: 2.61959
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 5.00040

Cumulative Model Updates: 199,766
Cumulative Timesteps: 1,666,071,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.80304
Policy Entropy: 2.29063
Value Function Loss: 0.01668

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 20,928.13094
Overall Steps per Second: 10,237.19169

Timestep Collection Time: 2.39018
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.88630

Cumulative Model Updates: 199,772
Cumulative Timesteps: 1,666,121,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1666121944...
Checkpoint 1666121944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.87413
Policy Entropy: 2.31232
Value Function Loss: 0.01618

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 21,528.71066
Overall Steps per Second: 10,272.59538

Timestep Collection Time: 2.32285
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.86810

Cumulative Model Updates: 199,778
Cumulative Timesteps: 1,666,171,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.18098
Policy Entropy: 2.30619
Value Function Loss: 0.01509

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.54260
Value Function Update Magnitude: 0.56836

Collected Steps per Second: 22,551.71684
Overall Steps per Second: 10,410.69678

Timestep Collection Time: 2.21713
Timestep Consumption Time: 2.58563
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.80275

Cumulative Model Updates: 199,784
Cumulative Timesteps: 1,666,221,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1666221952...
Checkpoint 1666221952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.39872
Policy Entropy: 2.32414
Value Function Loss: 0.01541

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.57173

Collected Steps per Second: 20,781.94597
Overall Steps per Second: 10,090.06414

Timestep Collection Time: 2.40603
Timestep Consumption Time: 2.54954
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.95557

Cumulative Model Updates: 199,790
Cumulative Timesteps: 1,666,271,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.29941
Policy Entropy: 2.31699
Value Function Loss: 0.01452

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.57022

Collected Steps per Second: 22,943.24931
Overall Steps per Second: 10,963.49434

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.56168

Cumulative Model Updates: 199,796
Cumulative Timesteps: 1,666,321,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1666321966...
Checkpoint 1666321966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.41673
Policy Entropy: 2.31315
Value Function Loss: 0.01592

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 21,276.51247
Overall Steps per Second: 10,246.54126

Timestep Collection Time: 2.35057
Timestep Consumption Time: 2.53029
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.88087

Cumulative Model Updates: 199,802
Cumulative Timesteps: 1,666,371,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.97562
Policy Entropy: 2.29224
Value Function Loss: 0.01674

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.59604

Collected Steps per Second: 22,757.68668
Overall Steps per Second: 10,614.04195

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.71357

Cumulative Model Updates: 199,808
Cumulative Timesteps: 1,666,422,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1666422008...
Checkpoint 1666422008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.74039
Policy Entropy: 2.28858
Value Function Loss: 0.01632

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 22,860.23230
Overall Steps per Second: 10,701.82482

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.67322

Cumulative Model Updates: 199,814
Cumulative Timesteps: 1,666,472,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.65734
Policy Entropy: 2.28145
Value Function Loss: 0.01668

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.59908

Collected Steps per Second: 23,207.14677
Overall Steps per Second: 10,761.08460

Timestep Collection Time: 2.15546
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.64842

Cumulative Model Updates: 199,820
Cumulative Timesteps: 1,666,522,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1666522042...
Checkpoint 1666522042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.38001
Policy Entropy: 2.32662
Value Function Loss: 0.01561

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.56828

Collected Steps per Second: 22,703.70180
Overall Steps per Second: 10,968.78201

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.35648
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.55912

Cumulative Model Updates: 199,826
Cumulative Timesteps: 1,666,572,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.92266
Policy Entropy: 2.32431
Value Function Loss: 0.01622

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.56630

Collected Steps per Second: 22,966.84111
Overall Steps per Second: 10,695.83049

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.49867
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.67659

Cumulative Model Updates: 199,832
Cumulative Timesteps: 1,666,622,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1666622070...
Checkpoint 1666622070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.52658
Policy Entropy: 2.31734
Value Function Loss: 0.01519

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.58798

Collected Steps per Second: 22,853.27340
Overall Steps per Second: 10,680.73362

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68282

Cumulative Model Updates: 199,838
Cumulative Timesteps: 1,666,672,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.86962
Policy Entropy: 2.27558
Value Function Loss: 0.01564

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 23,115.25706
Overall Steps per Second: 10,706.82910

Timestep Collection Time: 2.16307
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66992

Cumulative Model Updates: 199,844
Cumulative Timesteps: 1,666,722,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1666722086...
Checkpoint 1666722086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.65201
Policy Entropy: 2.26755
Value Function Loss: 0.01580

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.61033

Collected Steps per Second: 22,886.91491
Overall Steps per Second: 10,663.39386

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.68931

Cumulative Model Updates: 199,850
Cumulative Timesteps: 1,666,772,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.63281
Policy Entropy: 2.28394
Value Function Loss: 0.01611

Mean KL Divergence: 0.02642
SB3 Clip Fraction: 0.18399
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.60186

Collected Steps per Second: 22,805.16997
Overall Steps per Second: 10,912.10133

Timestep Collection Time: 2.19292
Timestep Consumption Time: 2.39006
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.58299

Cumulative Model Updates: 199,856
Cumulative Timesteps: 1,666,822,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1666822100...
Checkpoint 1666822100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.95926
Policy Entropy: 2.30021
Value Function Loss: 0.01551

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.16906
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.59572

Collected Steps per Second: 22,744.16445
Overall Steps per Second: 10,624.92225

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70648

Cumulative Model Updates: 199,862
Cumulative Timesteps: 1,666,872,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.10942
Policy Entropy: 2.32687
Value Function Loss: 0.01559

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.58463

Collected Steps per Second: 22,981.17819
Overall Steps per Second: 10,799.30167

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62993

Cumulative Model Updates: 199,868
Cumulative Timesteps: 1,666,922,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1666922106...
Checkpoint 1666922106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.02928
Policy Entropy: 2.32955
Value Function Loss: 0.01535

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.58926

Collected Steps per Second: 22,527.66531
Overall Steps per Second: 10,771.24413

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.64292

Cumulative Model Updates: 199,874
Cumulative Timesteps: 1,666,972,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.88569
Policy Entropy: 2.34768
Value Function Loss: 0.01564

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 23,300.68823
Overall Steps per Second: 10,904.22373

Timestep Collection Time: 2.14620
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.58611

Cumulative Model Updates: 199,880
Cumulative Timesteps: 1,667,022,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1667022124...
Checkpoint 1667022124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.59057
Policy Entropy: 2.34000
Value Function Loss: 0.01578

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.55205
Value Function Update Magnitude: 0.60952

Collected Steps per Second: 22,779.83066
Overall Steps per Second: 10,943.31675

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.37502
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.57083

Cumulative Model Updates: 199,886
Cumulative Timesteps: 1,667,072,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.42871
Policy Entropy: 2.34012
Value Function Loss: 0.01519

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.60247

Collected Steps per Second: 22,943.42193
Overall Steps per Second: 10,686.12659

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.68009

Cumulative Model Updates: 199,892
Cumulative Timesteps: 1,667,122,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1667122156...
Checkpoint 1667122156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.42731
Policy Entropy: 2.33074
Value Function Loss: 0.01518

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.60834

Collected Steps per Second: 22,839.93375
Overall Steps per Second: 10,649.63497

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.69669

Cumulative Model Updates: 199,898
Cumulative Timesteps: 1,667,172,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.91330
Policy Entropy: 2.33671
Value Function Loss: 0.01405

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 22,932.24629
Overall Steps per Second: 10,815.39876

Timestep Collection Time: 2.18095
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.62433

Cumulative Model Updates: 199,904
Cumulative Timesteps: 1,667,222,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1667222188...
Checkpoint 1667222188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.18266
Policy Entropy: 2.32841
Value Function Loss: 0.01507

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.58428

Collected Steps per Second: 22,681.59920
Overall Steps per Second: 10,825.88114

Timestep Collection Time: 2.20443
Timestep Consumption Time: 2.41413
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.61856

Cumulative Model Updates: 199,910
Cumulative Timesteps: 1,667,272,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.92899
Policy Entropy: 2.32848
Value Function Loss: 0.01594

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.57863

Collected Steps per Second: 22,813.86545
Overall Steps per Second: 10,706.41857

Timestep Collection Time: 2.19253
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.67196

Cumulative Model Updates: 199,916
Cumulative Timesteps: 1,667,322,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1667322208...
Checkpoint 1667322208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.40503
Policy Entropy: 2.32927
Value Function Loss: 0.01591

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.53720
Value Function Update Magnitude: 0.58991

Collected Steps per Second: 23,118.65520
Overall Steps per Second: 10,689.75684

Timestep Collection Time: 2.16397
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.67999

Cumulative Model Updates: 199,922
Cumulative Timesteps: 1,667,372,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.37651
Policy Entropy: 2.34984
Value Function Loss: 0.01575

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.57675

Collected Steps per Second: 23,287.91569
Overall Steps per Second: 10,748.39400

Timestep Collection Time: 2.14790
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.65372

Cumulative Model Updates: 199,928
Cumulative Timesteps: 1,667,422,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1667422256...
Checkpoint 1667422256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.41562
Policy Entropy: 2.34252
Value Function Loss: 0.01505

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 20,326.38808
Overall Steps per Second: 9,719.05588

Timestep Collection Time: 2.45996
Timestep Consumption Time: 2.68478
PPO Batch Consumption Time: 0.31160
Total Iteration Time: 5.14474

Cumulative Model Updates: 199,934
Cumulative Timesteps: 1,667,472,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.42216
Policy Entropy: 2.33788
Value Function Loss: 0.01497

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.57721

Collected Steps per Second: 18,891.21024
Overall Steps per Second: 9,582.13940

Timestep Collection Time: 2.64726
Timestep Consumption Time: 2.57182
PPO Batch Consumption Time: 0.30764
Total Iteration Time: 5.21909

Cumulative Model Updates: 199,940
Cumulative Timesteps: 1,667,522,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1667522268...
Checkpoint 1667522268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.35954
Policy Entropy: 2.33881
Value Function Loss: 0.01504

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.57890

Collected Steps per Second: 21,577.91061
Overall Steps per Second: 9,672.36339

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.85218
PPO Batch Consumption Time: 0.33700
Total Iteration Time: 5.16937

Cumulative Model Updates: 199,946
Cumulative Timesteps: 1,667,572,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.12312
Policy Entropy: 2.36028
Value Function Loss: 0.01424

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.53022
Value Function Update Magnitude: 0.58151

Collected Steps per Second: 20,830.86789
Overall Steps per Second: 9,743.68040

Timestep Collection Time: 2.40153
Timestep Consumption Time: 2.73267
PPO Batch Consumption Time: 0.32483
Total Iteration Time: 5.13420

Cumulative Model Updates: 199,952
Cumulative Timesteps: 1,667,622,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1667622294...
Checkpoint 1667622294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.59658
Policy Entropy: 2.37129
Value Function Loss: 0.01439

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.52268
Value Function Update Magnitude: 0.55402

Collected Steps per Second: 19,189.10233
Overall Steps per Second: 9,590.12403

Timestep Collection Time: 2.60606
Timestep Consumption Time: 2.60847
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 5.21453

Cumulative Model Updates: 199,958
Cumulative Timesteps: 1,667,672,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.71384
Policy Entropy: 2.37353
Value Function Loss: 0.01444

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.52997

Collected Steps per Second: 18,319.95538
Overall Steps per Second: 9,258.98154

Timestep Collection Time: 2.73145
Timestep Consumption Time: 2.67303
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 5.40448

Cumulative Model Updates: 199,964
Cumulative Timesteps: 1,667,722,342

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1667722342...
Checkpoint 1667722342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.44553
Policy Entropy: 2.35532
Value Function Loss: 0.01504

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.52744
Value Function Update Magnitude: 0.52719

Collected Steps per Second: 20,660.25172
Overall Steps per Second: 10,388.86648

Timestep Collection Time: 2.42146
Timestep Consumption Time: 2.39408
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.81554

Cumulative Model Updates: 199,970
Cumulative Timesteps: 1,667,772,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.81860
Policy Entropy: 2.36610
Value Function Loss: 0.01574

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.54196

Collected Steps per Second: 22,067.40846
Overall Steps per Second: 10,446.71069

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.52182
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.78888

Cumulative Model Updates: 199,976
Cumulative Timesteps: 1,667,822,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1667822398...
Checkpoint 1667822398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.00727
Policy Entropy: 2.34615
Value Function Loss: 0.01590

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.56162

Collected Steps per Second: 22,169.43616
Overall Steps per Second: 10,541.68512

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.74554

Cumulative Model Updates: 199,982
Cumulative Timesteps: 1,667,872,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.46533
Policy Entropy: 2.35616
Value Function Loss: 0.01662

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 22,249.08979
Overall Steps per Second: 10,531.62821

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.74855

Cumulative Model Updates: 199,988
Cumulative Timesteps: 1,667,922,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1667922434...
Checkpoint 1667922434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.05153
Policy Entropy: 2.33895
Value Function Loss: 0.01566

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.54463
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 21,897.73065
Overall Steps per Second: 10,404.46332

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.80717

Cumulative Model Updates: 199,994
Cumulative Timesteps: 1,667,972,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.41296
Policy Entropy: 2.36119
Value Function Loss: 0.01531

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.58407

Collected Steps per Second: 22,085.73788
Overall Steps per Second: 10,658.64684

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69290

Cumulative Model Updates: 200,000
Cumulative Timesteps: 1,668,022,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1668022470...
Checkpoint 1668022470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.50025
Policy Entropy: 2.35523
Value Function Loss: 0.01428

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.52493
Value Function Update Magnitude: 0.56001

Collected Steps per Second: 22,327.79795
Overall Steps per Second: 10,421.07712

Timestep Collection Time: 2.23972
Timestep Consumption Time: 2.55902
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.79874

Cumulative Model Updates: 200,006
Cumulative Timesteps: 1,668,072,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.29298
Policy Entropy: 2.32538
Value Function Loss: 0.01479

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 21,981.82101
Overall Steps per Second: 10,305.35707

Timestep Collection Time: 2.27588
Timestep Consumption Time: 2.57868
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.85456

Cumulative Model Updates: 200,012
Cumulative Timesteps: 1,668,122,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1668122506...
Checkpoint 1668122506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.26307
Policy Entropy: 2.31587
Value Function Loss: 0.01525

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.54521
Value Function Update Magnitude: 0.57158

Collected Steps per Second: 22,158.04033
Overall Steps per Second: 10,530.02376

Timestep Collection Time: 2.25661
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.74852

Cumulative Model Updates: 200,018
Cumulative Timesteps: 1,668,172,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.62159
Policy Entropy: 2.28734
Value Function Loss: 0.01567

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.58231

Collected Steps per Second: 21,958.77314
Overall Steps per Second: 10,518.27190

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.47733
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.75496

Cumulative Model Updates: 200,024
Cumulative Timesteps: 1,668,222,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1668222522...
Checkpoint 1668222522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.36817
Policy Entropy: 2.31736
Value Function Loss: 0.01614

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.58554

Collected Steps per Second: 21,967.59069
Overall Steps per Second: 10,650.65713

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.41963
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.69680

Cumulative Model Updates: 200,030
Cumulative Timesteps: 1,668,272,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.11522
Policy Entropy: 2.29239
Value Function Loss: 0.01623

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 21,562.99418
Overall Steps per Second: 10,498.56514

Timestep Collection Time: 2.31962
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.76427

Cumulative Model Updates: 200,036
Cumulative Timesteps: 1,668,322,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1668322564...
Checkpoint 1668322564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.64579
Policy Entropy: 2.29750
Value Function Loss: 0.01577

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 22,148.09110
Overall Steps per Second: 10,520.81573

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.75267

Cumulative Model Updates: 200,042
Cumulative Timesteps: 1,668,372,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.97243
Policy Entropy: 2.28715
Value Function Loss: 0.01586

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.56669

Collected Steps per Second: 22,386.81990
Overall Steps per Second: 10,535.28449

Timestep Collection Time: 2.23435
Timestep Consumption Time: 2.51350
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.74785

Cumulative Model Updates: 200,048
Cumulative Timesteps: 1,668,422,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1668422586...
Checkpoint 1668422586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.08983
Policy Entropy: 2.29277
Value Function Loss: 0.01582

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.54521
Value Function Update Magnitude: 0.60072

Collected Steps per Second: 21,905.87986
Overall Steps per Second: 10,420.29292

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.51705
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.80063

Cumulative Model Updates: 200,054
Cumulative Timesteps: 1,668,472,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.39663
Policy Entropy: 2.32084
Value Function Loss: 0.01540

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,374.73130
Overall Steps per Second: 10,778.10617

Timestep Collection Time: 2.23538
Timestep Consumption Time: 2.40514
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.64052

Cumulative Model Updates: 200,060
Cumulative Timesteps: 1,668,522,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1668522626...
Checkpoint 1668522626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.83560
Policy Entropy: 2.34001
Value Function Loss: 0.01521

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.61426

Collected Steps per Second: 22,239.71582
Overall Steps per Second: 10,545.35950

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.74294

Cumulative Model Updates: 200,066
Cumulative Timesteps: 1,668,572,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.99240
Policy Entropy: 2.33227
Value Function Loss: 0.01542

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 22,220.98886
Overall Steps per Second: 10,528.62206

Timestep Collection Time: 2.25039
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.74953

Cumulative Model Updates: 200,072
Cumulative Timesteps: 1,668,622,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1668622648...
Checkpoint 1668622648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.64498
Policy Entropy: 2.33233
Value Function Loss: 0.01501

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.52615
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 21,999.99965
Overall Steps per Second: 10,384.06186

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.54336
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.81700

Cumulative Model Updates: 200,078
Cumulative Timesteps: 1,668,672,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.50347
Policy Entropy: 2.31847
Value Function Loss: 0.01472

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.52149
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,012.88524
Overall Steps per Second: 10,445.39851

Timestep Collection Time: 2.27167
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.78737

Cumulative Model Updates: 200,084
Cumulative Timesteps: 1,668,722,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1668722674...
Checkpoint 1668722674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.65700
Policy Entropy: 2.32049
Value Function Loss: 0.01490

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.52789
Value Function Update Magnitude: 0.57916

Collected Steps per Second: 22,137.74241
Overall Steps per Second: 10,561.16430

Timestep Collection Time: 2.25958
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.73641

Cumulative Model Updates: 200,090
Cumulative Timesteps: 1,668,772,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.02787
Policy Entropy: 2.32503
Value Function Loss: 0.01406

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.52255
Value Function Update Magnitude: 0.56932

Collected Steps per Second: 22,318.52311
Overall Steps per Second: 10,393.42639

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.57126
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 4.81227

Cumulative Model Updates: 200,096
Cumulative Timesteps: 1,668,822,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1668822712...
Checkpoint 1668822712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.45032
Policy Entropy: 2.33464
Value Function Loss: 0.01470

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.52045
Value Function Update Magnitude: 0.57430

Collected Steps per Second: 22,306.67585
Overall Steps per Second: 10,539.47721

Timestep Collection Time: 2.24202
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.74521

Cumulative Model Updates: 200,102
Cumulative Timesteps: 1,668,872,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.38210
Policy Entropy: 2.31089
Value Function Loss: 0.01552

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.59092

Collected Steps per Second: 22,244.83583
Overall Steps per Second: 10,549.84260

Timestep Collection Time: 2.24771
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.73941

Cumulative Model Updates: 200,108
Cumulative Timesteps: 1,668,922,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1668922724...
Checkpoint 1668922724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.89954
Policy Entropy: 2.28919
Value Function Loss: 0.01658

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 22,226.18887
Overall Steps per Second: 10,584.76610

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.72434

Cumulative Model Updates: 200,114
Cumulative Timesteps: 1,668,972,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.25186
Policy Entropy: 2.27181
Value Function Loss: 0.01673

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.64312

Collected Steps per Second: 23,296.92572
Overall Steps per Second: 10,639.66826

Timestep Collection Time: 2.14741
Timestep Consumption Time: 2.55462
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.70203

Cumulative Model Updates: 200,120
Cumulative Timesteps: 1,669,022,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1669022758...
Checkpoint 1669022758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.83589
Policy Entropy: 2.29622
Value Function Loss: 0.01578

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.63210

Collected Steps per Second: 22,363.13644
Overall Steps per Second: 10,511.31312

Timestep Collection Time: 2.23681
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.75887

Cumulative Model Updates: 200,126
Cumulative Timesteps: 1,669,072,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.62198
Policy Entropy: 2.28865
Value Function Loss: 0.01616

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.60535

Collected Steps per Second: 22,306.90104
Overall Steps per Second: 10,458.55669

Timestep Collection Time: 2.24236
Timestep Consumption Time: 2.54033
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.78269

Cumulative Model Updates: 200,132
Cumulative Timesteps: 1,669,122,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1669122800...
Checkpoint 1669122800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.10270
Policy Entropy: 2.30063
Value Function Loss: 0.01718

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.61419

Collected Steps per Second: 22,081.46972
Overall Steps per Second: 10,564.03386

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.73399

Cumulative Model Updates: 200,138
Cumulative Timesteps: 1,669,172,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.65101
Policy Entropy: 2.29034
Value Function Loss: 0.01725

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.64762

Collected Steps per Second: 21,979.02549
Overall Steps per Second: 10,502.47168

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.76212

Cumulative Model Updates: 200,144
Cumulative Timesteps: 1,669,222,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1669222824...
Checkpoint 1669222824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.81639
Policy Entropy: 2.31469
Value Function Loss: 0.01653

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 22,221.84800
Overall Steps per Second: 10,656.69439

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.44243
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.69301

Cumulative Model Updates: 200,150
Cumulative Timesteps: 1,669,272,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.11638
Policy Entropy: 2.31156
Value Function Loss: 0.01610

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.64244

Collected Steps per Second: 22,548.28431
Overall Steps per Second: 10,467.87014

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.55998
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.77824

Cumulative Model Updates: 200,156
Cumulative Timesteps: 1,669,322,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1669322854...
Checkpoint 1669322854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.41265
Policy Entropy: 2.31336
Value Function Loss: 0.01532

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.62590

Collected Steps per Second: 21,931.75452
Overall Steps per Second: 10,336.42932

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.55828
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.83881

Cumulative Model Updates: 200,162
Cumulative Timesteps: 1,669,372,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.09031
Policy Entropy: 2.30304
Value Function Loss: 0.01619

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 22,182.32755
Overall Steps per Second: 10,691.91052

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.67643

Cumulative Model Updates: 200,168
Cumulative Timesteps: 1,669,422,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1669422870...
Checkpoint 1669422870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.52166
Policy Entropy: 2.28821
Value Function Loss: 0.01495

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 21,360.42062
Overall Steps per Second: 10,415.73439

Timestep Collection Time: 2.34115
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.80120

Cumulative Model Updates: 200,174
Cumulative Timesteps: 1,669,472,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.74566
Policy Entropy: 2.29737
Value Function Loss: 0.01532

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.54911
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 21,778.71907
Overall Steps per Second: 10,290.48129

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.56355
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.85983

Cumulative Model Updates: 200,180
Cumulative Timesteps: 1,669,522,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1669522888...
Checkpoint 1669522888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.90474
Policy Entropy: 2.29960
Value Function Loss: 0.01449

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.63100

Collected Steps per Second: 22,164.76655
Overall Steps per Second: 10,544.05312

Timestep Collection Time: 2.25673
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.74391

Cumulative Model Updates: 200,186
Cumulative Timesteps: 1,669,572,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.16650
Policy Entropy: 2.31371
Value Function Loss: 0.01417

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 22,473.41970
Overall Steps per Second: 10,576.79192

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.72866

Cumulative Model Updates: 200,192
Cumulative Timesteps: 1,669,622,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1669622922...
Checkpoint 1669622922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.03721
Policy Entropy: 2.32226
Value Function Loss: 0.01480

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.53094
Value Function Update Magnitude: 0.63621

Collected Steps per Second: 22,163.11428
Overall Steps per Second: 10,625.64227

Timestep Collection Time: 2.25636
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.70635

Cumulative Model Updates: 200,198
Cumulative Timesteps: 1,669,672,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.18539
Policy Entropy: 2.31687
Value Function Loss: 0.01409

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.52485
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 22,387.91473
Overall Steps per Second: 10,480.15662

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.53849
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.77264

Cumulative Model Updates: 200,204
Cumulative Timesteps: 1,669,722,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1669722948...
Checkpoint 1669722948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.89331
Policy Entropy: 2.28966
Value Function Loss: 0.01502

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.52336
Value Function Update Magnitude: 0.59868

Collected Steps per Second: 21,920.39821
Overall Steps per Second: 10,484.72136

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.76903

Cumulative Model Updates: 200,210
Cumulative Timesteps: 1,669,772,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.05093
Policy Entropy: 2.28358
Value Function Loss: 0.01471

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.53392
Value Function Update Magnitude: 0.59479

Collected Steps per Second: 22,041.79320
Overall Steps per Second: 10,498.47565

Timestep Collection Time: 2.26896
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.76374

Cumulative Model Updates: 200,216
Cumulative Timesteps: 1,669,822,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1669822962...
Checkpoint 1669822962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.18322
Policy Entropy: 2.29049
Value Function Loss: 0.01589

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 21,993.58893
Overall Steps per Second: 10,680.72580

Timestep Collection Time: 2.27475
Timestep Consumption Time: 2.40938
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68414

Cumulative Model Updates: 200,222
Cumulative Timesteps: 1,669,872,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.83457
Policy Entropy: 2.30125
Value Function Loss: 0.01625

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.61038

Collected Steps per Second: 22,555.41062
Overall Steps per Second: 10,502.90300

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.76325

Cumulative Model Updates: 200,228
Cumulative Timesteps: 1,669,923,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1669923020...
Checkpoint 1669923020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.96743
Policy Entropy: 2.30459
Value Function Loss: 0.01589

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 22,028.28961
Overall Steps per Second: 10,430.71869

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.52433
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.79468

Cumulative Model Updates: 200,234
Cumulative Timesteps: 1,669,973,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.05216
Policy Entropy: 2.31809
Value Function Loss: 0.01545

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.59145

Collected Steps per Second: 22,590.86691
Overall Steps per Second: 10,605.19704

Timestep Collection Time: 2.21523
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.71882

Cumulative Model Updates: 200,240
Cumulative Timesteps: 1,670,023,076

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1670023076...
Checkpoint 1670023076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.78418
Policy Entropy: 2.32310
Value Function Loss: 0.01530

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.58886

Collected Steps per Second: 21,957.95386
Overall Steps per Second: 10,461.67869

Timestep Collection Time: 2.27708
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.77935

Cumulative Model Updates: 200,246
Cumulative Timesteps: 1,670,073,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.41647
Policy Entropy: 2.32240
Value Function Loss: 0.01619

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 22,577.79013
Overall Steps per Second: 10,704.08666

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67130

Cumulative Model Updates: 200,252
Cumulative Timesteps: 1,670,123,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1670123078...
Checkpoint 1670123078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.23880
Policy Entropy: 2.32517
Value Function Loss: 0.01570

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.16038
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 22,079.15193
Overall Steps per Second: 10,397.27492

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.54458
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.80934

Cumulative Model Updates: 200,258
Cumulative Timesteps: 1,670,173,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.04478
Policy Entropy: 2.32199
Value Function Loss: 0.01650

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.17856
Policy Update Magnitude: 0.49478
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 22,682.54517
Overall Steps per Second: 10,622.40723

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.70891

Cumulative Model Updates: 200,264
Cumulative Timesteps: 1,670,223,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1670223102...
Checkpoint 1670223102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.44219
Policy Entropy: 2.30514
Value Function Loss: 0.01692

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.18180
Policy Update Magnitude: 0.51670
Value Function Update Magnitude: 0.62411

Collected Steps per Second: 22,178.34507
Overall Steps per Second: 10,522.34155

Timestep Collection Time: 2.25589
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.75484

Cumulative Model Updates: 200,270
Cumulative Timesteps: 1,670,273,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.81094
Policy Entropy: 2.27768
Value Function Loss: 0.01676

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.19758
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 22,645.96539
Overall Steps per Second: 10,693.05530

Timestep Collection Time: 2.20896
Timestep Consumption Time: 2.46922
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.67818

Cumulative Model Updates: 200,276
Cumulative Timesteps: 1,670,323,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1670323158...
Checkpoint 1670323158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.32687
Policy Entropy: 2.28914
Value Function Loss: 0.01555

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.18301
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.62389

Collected Steps per Second: 22,000.78891
Overall Steps per Second: 10,614.87662

Timestep Collection Time: 2.27301
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.71112

Cumulative Model Updates: 200,282
Cumulative Timesteps: 1,670,373,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.90359
Policy Entropy: 2.30025
Value Function Loss: 0.01487

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 22,486.41674
Overall Steps per Second: 10,464.80324

Timestep Collection Time: 2.22463
Timestep Consumption Time: 2.55558
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.78021

Cumulative Model Updates: 200,288
Cumulative Timesteps: 1,670,423,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1670423190...
Checkpoint 1670423190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.36369
Policy Entropy: 2.31964
Value Function Loss: 0.01531

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.63847

Collected Steps per Second: 22,187.06548
Overall Steps per Second: 10,551.93562

Timestep Collection Time: 2.25492
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.74131

Cumulative Model Updates: 200,294
Cumulative Timesteps: 1,670,473,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.77985
Policy Entropy: 2.31985
Value Function Loss: 0.01605

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.55401
Value Function Update Magnitude: 0.65682

Collected Steps per Second: 22,346.44061
Overall Steps per Second: 10,556.32794

Timestep Collection Time: 2.23776
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.73706

Cumulative Model Updates: 200,300
Cumulative Timesteps: 1,670,523,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1670523226...
Checkpoint 1670523226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.81327
Policy Entropy: 2.32422
Value Function Loss: 0.01598

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.66344

Collected Steps per Second: 22,037.84457
Overall Steps per Second: 10,529.68164

Timestep Collection Time: 2.26964
Timestep Consumption Time: 2.48055
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.75019

Cumulative Model Updates: 200,306
Cumulative Timesteps: 1,670,573,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.87149
Policy Entropy: 2.30562
Value Function Loss: 0.01551

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.64092

Collected Steps per Second: 22,157.82250
Overall Steps per Second: 10,596.88543

Timestep Collection Time: 2.25753
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72044

Cumulative Model Updates: 200,312
Cumulative Timesteps: 1,670,623,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1670623266...
Checkpoint 1670623266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.87715
Policy Entropy: 2.30414
Value Function Loss: 0.01437

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 22,050.26660
Overall Steps per Second: 10,497.86671

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.49642
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.76497

Cumulative Model Updates: 200,318
Cumulative Timesteps: 1,670,673,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.80115
Policy Entropy: 2.28806
Value Function Loss: 0.01483

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.56615

Collected Steps per Second: 22,392.82355
Overall Steps per Second: 10,586.19337

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.72559

Cumulative Model Updates: 200,324
Cumulative Timesteps: 1,670,723,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1670723314...
Checkpoint 1670723314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.04241
Policy Entropy: 2.29664
Value Function Loss: 0.01557

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.59328

Collected Steps per Second: 21,691.28802
Overall Steps per Second: 10,320.82501

Timestep Collection Time: 2.30535
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.84516

Cumulative Model Updates: 200,330
Cumulative Timesteps: 1,670,773,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.41510
Policy Entropy: 2.28768
Value Function Loss: 0.01546

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.64962

Collected Steps per Second: 22,478.99419
Overall Steps per Second: 10,809.86744

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.40216
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.62744

Cumulative Model Updates: 200,336
Cumulative Timesteps: 1,670,823,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1670823342...
Checkpoint 1670823342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.60771
Policy Entropy: 2.31235
Value Function Loss: 0.01494

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 22,258.64283
Overall Steps per Second: 10,561.55239

Timestep Collection Time: 2.24641
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.73434

Cumulative Model Updates: 200,342
Cumulative Timesteps: 1,670,873,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.25531
Policy Entropy: 2.29618
Value Function Loss: 0.01551

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.54855
Value Function Update Magnitude: 0.64131

Collected Steps per Second: 22,256.47162
Overall Steps per Second: 10,512.20299

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.75828

Cumulative Model Updates: 200,348
Cumulative Timesteps: 1,670,923,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1670923364...
Checkpoint 1670923364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.79019
Policy Entropy: 2.30372
Value Function Loss: 0.01562

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.63602

Collected Steps per Second: 21,706.39294
Overall Steps per Second: 10,349.56077

Timestep Collection Time: 2.30430
Timestep Consumption Time: 2.52856
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.83286

Cumulative Model Updates: 200,354
Cumulative Timesteps: 1,670,973,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.99923
Policy Entropy: 2.29352
Value Function Loss: 0.01652

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.63852

Collected Steps per Second: 22,239.46642
Overall Steps per Second: 10,702.10866

Timestep Collection Time: 2.24862
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.67272

Cumulative Model Updates: 200,360
Cumulative Timesteps: 1,671,023,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1671023390...
Checkpoint 1671023390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.14042
Policy Entropy: 2.28807
Value Function Loss: 0.01540

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 21,873.73287
Overall Steps per Second: 10,368.77047

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.53724
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.82391

Cumulative Model Updates: 200,366
Cumulative Timesteps: 1,671,073,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.65613
Policy Entropy: 2.26928
Value Function Loss: 0.01524

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.61549

Collected Steps per Second: 22,585.87544
Overall Steps per Second: 10,493.56651

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.55156
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.76578

Cumulative Model Updates: 200,372
Cumulative Timesteps: 1,671,123,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1671123418...
Checkpoint 1671123418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.99520
Policy Entropy: 2.25789
Value Function Loss: 0.01500

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.62105

Collected Steps per Second: 21,805.03408
Overall Steps per Second: 10,458.06019

Timestep Collection Time: 2.29360
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.78215

Cumulative Model Updates: 200,378
Cumulative Timesteps: 1,671,173,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.95529
Policy Entropy: 2.26779
Value Function Loss: 0.01614

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 22,211.20328
Overall Steps per Second: 10,594.48699

Timestep Collection Time: 2.25148
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.72019

Cumulative Model Updates: 200,384
Cumulative Timesteps: 1,671,223,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1671223438...
Checkpoint 1671223438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.66772
Policy Entropy: 2.26879
Value Function Loss: 0.01554

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.61962

Collected Steps per Second: 22,350.96367
Overall Steps per Second: 10,530.29994

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.74934

Cumulative Model Updates: 200,390
Cumulative Timesteps: 1,671,273,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.63226
Policy Entropy: 2.25097
Value Function Loss: 0.01576

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.62300

Collected Steps per Second: 22,388.12617
Overall Steps per Second: 10,420.04526

Timestep Collection Time: 2.23440
Timestep Consumption Time: 2.56635
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.80075

Cumulative Model Updates: 200,396
Cumulative Timesteps: 1,671,323,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1671323474...
Checkpoint 1671323474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.24982
Policy Entropy: 2.24598
Value Function Loss: 0.01604

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.62438

Collected Steps per Second: 22,030.43473
Overall Steps per Second: 10,391.93973

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.54204
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.81181

Cumulative Model Updates: 200,402
Cumulative Timesteps: 1,671,373,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.44349
Policy Entropy: 2.27152
Value Function Loss: 0.01594

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.55684
Value Function Update Magnitude: 0.62813

Collected Steps per Second: 22,527.05986
Overall Steps per Second: 10,656.84513

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.47256
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.69238

Cumulative Model Updates: 200,408
Cumulative Timesteps: 1,671,423,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1671423484...
Checkpoint 1671423484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.74259
Policy Entropy: 2.28614
Value Function Loss: 0.01606

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.63011

Collected Steps per Second: 23,021.12752
Overall Steps per Second: 10,725.89771

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.66199

Cumulative Model Updates: 200,414
Cumulative Timesteps: 1,671,473,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.25179
Policy Entropy: 2.29091
Value Function Loss: 0.01526

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 22,343.20187
Overall Steps per Second: 10,420.02711

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.56197
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.80095

Cumulative Model Updates: 200,420
Cumulative Timesteps: 1,671,523,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1671523514...
Checkpoint 1671523514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.00422
Policy Entropy: 2.26550
Value Function Loss: 0.01657

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.62236

Collected Steps per Second: 21,803.70536
Overall Steps per Second: 10,294.48306

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.56450
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.85833

Cumulative Model Updates: 200,426
Cumulative Timesteps: 1,671,573,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.31972
Policy Entropy: 2.26570
Value Function Loss: 0.01627

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.62636

Collected Steps per Second: 21,998.11249
Overall Steps per Second: 10,415.37063

Timestep Collection Time: 2.27410
Timestep Consumption Time: 2.52899
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.80309

Cumulative Model Updates: 200,432
Cumulative Timesteps: 1,671,623,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1671623554...
Checkpoint 1671623554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.49309
Policy Entropy: 2.26127
Value Function Loss: 0.01600

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.15474
Policy Update Magnitude: 0.55693
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 21,978.00073
Overall Steps per Second: 10,660.96808

Timestep Collection Time: 2.27564
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.69132

Cumulative Model Updates: 200,438
Cumulative Timesteps: 1,671,673,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.78362
Policy Entropy: 2.26061
Value Function Loss: 0.01656

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,458.01451
Overall Steps per Second: 10,428.99949

Timestep Collection Time: 2.22655
Timestep Consumption Time: 2.56815
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.79471

Cumulative Model Updates: 200,444
Cumulative Timesteps: 1,671,723,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1671723572...
Checkpoint 1671723572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.39362
Policy Entropy: 2.24671
Value Function Loss: 0.01649

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 22,274.29641
Overall Steps per Second: 10,522.43527

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.75384

Cumulative Model Updates: 200,450
Cumulative Timesteps: 1,671,773,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.38615
Policy Entropy: 2.22298
Value Function Loss: 0.01649

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.59292

Collected Steps per Second: 22,328.81694
Overall Steps per Second: 10,572.86610

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.49053
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.73041

Cumulative Model Updates: 200,456
Cumulative Timesteps: 1,671,823,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1671823608...
Checkpoint 1671823608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.96609
Policy Entropy: 2.20605
Value Function Loss: 0.01722

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.59163

Collected Steps per Second: 22,166.09805
Overall Steps per Second: 10,652.43445

Timestep Collection Time: 2.25615
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69470

Cumulative Model Updates: 200,462
Cumulative Timesteps: 1,671,873,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.06407
Policy Entropy: 2.24680
Value Function Loss: 0.01690

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 22,040.36791
Overall Steps per Second: 10,432.64234

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.79322

Cumulative Model Updates: 200,468
Cumulative Timesteps: 1,671,923,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1671923624...
Checkpoint 1671923624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.40839
Policy Entropy: 2.27510
Value Function Loss: 0.01710

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.61033

Collected Steps per Second: 22,060.11235
Overall Steps per Second: 10,413.07573

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.53654
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.80434

Cumulative Model Updates: 200,474
Cumulative Timesteps: 1,671,973,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.90569
Policy Entropy: 2.30543
Value Function Loss: 0.01662

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.54353
Value Function Update Magnitude: 0.61130

Collected Steps per Second: 22,547.02177
Overall Steps per Second: 10,655.67108

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.69328

Cumulative Model Updates: 200,480
Cumulative Timesteps: 1,672,023,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1672023662...
Checkpoint 1672023662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.65032
Policy Entropy: 2.31123
Value Function Loss: 0.01635

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.61643

Collected Steps per Second: 22,158.08317
Overall Steps per Second: 10,687.09376

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.67985

Cumulative Model Updates: 200,486
Cumulative Timesteps: 1,672,073,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.12999
Policy Entropy: 2.29791
Value Function Loss: 0.01678

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.61395

Collected Steps per Second: 22,205.44986
Overall Steps per Second: 10,466.92193

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.77925

Cumulative Model Updates: 200,492
Cumulative Timesteps: 1,672,123,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1672123700...
Checkpoint 1672123700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.42870
Policy Entropy: 2.28690
Value Function Loss: 0.01668

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.61317

Collected Steps per Second: 22,205.20633
Overall Steps per Second: 10,560.57107

Timestep Collection Time: 2.25253
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.73630

Cumulative Model Updates: 200,498
Cumulative Timesteps: 1,672,173,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.97862
Policy Entropy: 2.26144
Value Function Loss: 0.01609

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.61509

Collected Steps per Second: 22,149.89863
Overall Steps per Second: 10,524.56866

Timestep Collection Time: 2.25843
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.75307

Cumulative Model Updates: 200,504
Cumulative Timesteps: 1,672,223,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1672223742...
Checkpoint 1672223742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.36194
Policy Entropy: 2.26407
Value Function Loss: 0.01584

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.60534

Collected Steps per Second: 22,289.41939
Overall Steps per Second: 10,663.09610

Timestep Collection Time: 2.24447
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69170

Cumulative Model Updates: 200,510
Cumulative Timesteps: 1,672,273,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.62791
Policy Entropy: 2.27977
Value Function Loss: 0.01628

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.59323

Collected Steps per Second: 22,467.60497
Overall Steps per Second: 10,398.93369

Timestep Collection Time: 2.22676
Timestep Consumption Time: 2.58431
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.81107

Cumulative Model Updates: 200,516
Cumulative Timesteps: 1,672,323,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1672323800...
Checkpoint 1672323800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.98153
Policy Entropy: 2.27997
Value Function Loss: 0.01640

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.55389
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 22,136.31454
Overall Steps per Second: 10,436.52393

Timestep Collection Time: 2.25982
Timestep Consumption Time: 2.53335
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.79317

Cumulative Model Updates: 200,522
Cumulative Timesteps: 1,672,373,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.40114
Policy Entropy: 2.26404
Value Function Loss: 0.01711

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.61032

Collected Steps per Second: 22,472.21707
Overall Steps per Second: 10,623.27249

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.70778

Cumulative Model Updates: 200,528
Cumulative Timesteps: 1,672,423,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1672423836...
Checkpoint 1672423836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.12313
Policy Entropy: 2.25096
Value Function Loss: 0.01803

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.16221
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,536.80789
Overall Steps per Second: 10,747.63280

Timestep Collection Time: 2.21877
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.65256

Cumulative Model Updates: 200,534
Cumulative Timesteps: 1,672,473,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.60698
Policy Entropy: 2.25395
Value Function Loss: 0.01834

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.19130
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.64655

Collected Steps per Second: 22,438.58165
Overall Steps per Second: 10,410.00653

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.57497
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.80346

Cumulative Model Updates: 200,540
Cumulative Timesteps: 1,672,523,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1672523844...
Checkpoint 1672523844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.76609
Policy Entropy: 2.23590
Value Function Loss: 0.01784

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.17919
Policy Update Magnitude: 0.57271
Value Function Update Magnitude: 0.63618

Collected Steps per Second: 21,963.78005
Overall Steps per Second: 10,361.98772

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.55028
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.82803

Cumulative Model Updates: 200,546
Cumulative Timesteps: 1,672,573,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.24454
Policy Entropy: 2.22428
Value Function Loss: 0.01682

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.17333
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 22,667.46074
Overall Steps per Second: 10,435.16190

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.58672
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.79341

Cumulative Model Updates: 200,552
Cumulative Timesteps: 1,672,623,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1672623892...
Checkpoint 1672623892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.83877
Policy Entropy: 2.23850
Value Function Loss: 0.01555

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.16268
Policy Update Magnitude: 0.56672
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 22,337.45947
Overall Steps per Second: 10,528.29205

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.75006

Cumulative Model Updates: 200,558
Cumulative Timesteps: 1,672,673,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.94766
Policy Entropy: 2.26521
Value Function Loss: 0.01473

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.58678

Collected Steps per Second: 22,177.85666
Overall Steps per Second: 10,552.61460

Timestep Collection Time: 2.25540
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.74006

Cumulative Model Updates: 200,564
Cumulative Timesteps: 1,672,723,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1672723922...
Checkpoint 1672723922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.58745
Policy Entropy: 2.27730
Value Function Loss: 0.01538

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.56079

Collected Steps per Second: 22,414.48262
Overall Steps per Second: 10,511.65106

Timestep Collection Time: 2.23195
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.75929

Cumulative Model Updates: 200,570
Cumulative Timesteps: 1,672,773,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.38900
Policy Entropy: 2.25417
Value Function Loss: 0.01675

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.57002

Collected Steps per Second: 22,140.55522
Overall Steps per Second: 10,512.09556

Timestep Collection Time: 2.25947
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.75890

Cumulative Model Updates: 200,576
Cumulative Timesteps: 1,672,823,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1672823976...
Checkpoint 1672823976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.48670
Policy Entropy: 2.24371
Value Function Loss: 0.01669

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,200.72658
Overall Steps per Second: 10,620.63720

Timestep Collection Time: 2.25317
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.70989

Cumulative Model Updates: 200,582
Cumulative Timesteps: 1,672,873,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.80867
Policy Entropy: 2.23043
Value Function Loss: 0.01656

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.57532

Collected Steps per Second: 21,993.06706
Overall Steps per Second: 10,489.91731

Timestep Collection Time: 2.27390
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.76744

Cumulative Model Updates: 200,588
Cumulative Timesteps: 1,672,924,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1672924008...
Checkpoint 1672924008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.36597
Policy Entropy: 2.23979
Value Function Loss: 0.01600

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 22,349.81573
Overall Steps per Second: 10,571.95556

Timestep Collection Time: 2.23787
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.73101

Cumulative Model Updates: 200,594
Cumulative Timesteps: 1,672,974,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.95121
Policy Entropy: 2.25463
Value Function Loss: 0.01591

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.58185

Collected Steps per Second: 22,429.37136
Overall Steps per Second: 10,499.62136

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.53336
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.76303

Cumulative Model Updates: 200,600
Cumulative Timesteps: 1,673,024,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1673024034...
Checkpoint 1673024034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.95860
Policy Entropy: 2.28518
Value Function Loss: 0.01553

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 21,977.12100
Overall Steps per Second: 10,534.07606

Timestep Collection Time: 2.27591
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.74821

Cumulative Model Updates: 200,606
Cumulative Timesteps: 1,673,074,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.58267
Policy Entropy: 2.26750
Value Function Loss: 0.01513

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.56735

Collected Steps per Second: 22,222.97645
Overall Steps per Second: 10,575.63223

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.73012

Cumulative Model Updates: 200,612
Cumulative Timesteps: 1,673,124,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1673124076...
Checkpoint 1673124076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.70850
Policy Entropy: 2.23182
Value Function Loss: 0.01652

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 22,367.25611
Overall Steps per Second: 10,578.48399

Timestep Collection Time: 2.23684
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.72960

Cumulative Model Updates: 200,618
Cumulative Timesteps: 1,673,174,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.21703
Policy Entropy: 2.22898
Value Function Loss: 0.01670

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 22,439.55981
Overall Steps per Second: 10,510.49562

Timestep Collection Time: 2.22883
Timestep Consumption Time: 2.52965
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75848

Cumulative Model Updates: 200,624
Cumulative Timesteps: 1,673,224,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1673224122...
Checkpoint 1673224122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.94032
Policy Entropy: 2.22306
Value Function Loss: 0.01606

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.63694

Collected Steps per Second: 22,281.70506
Overall Steps per Second: 10,554.40427

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.73755

Cumulative Model Updates: 200,630
Cumulative Timesteps: 1,673,274,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.90291
Policy Entropy: 2.24214
Value Function Loss: 0.01570

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.60806

Collected Steps per Second: 22,234.17057
Overall Steps per Second: 10,528.09673

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.50161
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.75148

Cumulative Model Updates: 200,636
Cumulative Timesteps: 1,673,324,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1673324148...
Checkpoint 1673324148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.21642
Policy Entropy: 2.23205
Value Function Loss: 0.01528

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.57839

Collected Steps per Second: 22,256.63976
Overall Steps per Second: 10,642.71998

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.69955

Cumulative Model Updates: 200,642
Cumulative Timesteps: 1,673,374,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.25309
Policy Entropy: 2.24130
Value Function Loss: 0.01463

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.56594

Collected Steps per Second: 22,519.45018
Overall Steps per Second: 10,467.24778

Timestep Collection Time: 2.22048
Timestep Consumption Time: 2.55671
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.77719

Cumulative Model Updates: 200,648
Cumulative Timesteps: 1,673,424,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1673424168...
Checkpoint 1673424168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.92899
Policy Entropy: 2.23403
Value Function Loss: 0.01384

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.53242

Collected Steps per Second: 21,913.51890
Overall Steps per Second: 10,343.88067

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.55249
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.83455

Cumulative Model Updates: 200,654
Cumulative Timesteps: 1,673,474,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.54362
Policy Entropy: 2.22807
Value Function Loss: 0.01528

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.52576

Collected Steps per Second: 22,076.47203
Overall Steps per Second: 10,446.51848

Timestep Collection Time: 2.26540
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.78743

Cumulative Model Updates: 200,660
Cumulative Timesteps: 1,673,524,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1673524188...
Checkpoint 1673524188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.28928
Policy Entropy: 2.23633
Value Function Loss: 0.01607

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.52713
Value Function Update Magnitude: 0.54458

Collected Steps per Second: 22,440.89822
Overall Steps per Second: 10,673.53306

Timestep Collection Time: 2.22843
Timestep Consumption Time: 2.45680
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.68523

Cumulative Model Updates: 200,666
Cumulative Timesteps: 1,673,574,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.38393
Policy Entropy: 2.24467
Value Function Loss: 0.01682

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.53509
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,480.61016
Overall Steps per Second: 10,524.24190

Timestep Collection Time: 2.22574
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75436

Cumulative Model Updates: 200,672
Cumulative Timesteps: 1,673,624,232

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1673624232...
Checkpoint 1673624232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.86404
Policy Entropy: 2.24043
Value Function Loss: 0.01525

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.57295

Collected Steps per Second: 22,083.92926
Overall Steps per Second: 10,398.57539

Timestep Collection Time: 2.26445
Timestep Consumption Time: 2.54467
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.80912

Cumulative Model Updates: 200,678
Cumulative Timesteps: 1,673,674,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.77276
Policy Entropy: 2.25336
Value Function Loss: 0.01541

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.55422

Collected Steps per Second: 22,235.85456
Overall Steps per Second: 10,470.11700

Timestep Collection Time: 2.24988
Timestep Consumption Time: 2.52829
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.77817

Cumulative Model Updates: 200,684
Cumulative Timesteps: 1,673,724,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1673724268...
Checkpoint 1673724268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.76532
Policy Entropy: 2.26108
Value Function Loss: 0.01522

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.57126

Collected Steps per Second: 22,284.75962
Overall Steps per Second: 10,635.57210

Timestep Collection Time: 2.24396
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.70177

Cumulative Model Updates: 200,690
Cumulative Timesteps: 1,673,774,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.46125
Policy Entropy: 2.26763
Value Function Loss: 0.01599

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.57935

Collected Steps per Second: 22,197.37305
Overall Steps per Second: 10,458.61642

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.52894
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.78209

Cumulative Model Updates: 200,696
Cumulative Timesteps: 1,673,824,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1673824288...
Checkpoint 1673824288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.93566
Policy Entropy: 2.25394
Value Function Loss: 0.01481

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.53102
Value Function Update Magnitude: 0.54963

Collected Steps per Second: 22,477.76069
Overall Steps per Second: 10,631.14362

Timestep Collection Time: 2.22584
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.70617

Cumulative Model Updates: 200,702
Cumulative Timesteps: 1,673,874,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.67149
Policy Entropy: 2.23473
Value Function Loss: 0.01571

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.56450

Collected Steps per Second: 22,618.88526
Overall Steps per Second: 10,544.65060

Timestep Collection Time: 2.21143
Timestep Consumption Time: 2.53221
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.74364

Cumulative Model Updates: 200,708
Cumulative Timesteps: 1,673,924,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1673924340...
Checkpoint 1673924340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.38944
Policy Entropy: 2.24169
Value Function Loss: 0.01496

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.53301
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,580.77869
Overall Steps per Second: 10,713.43758

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.66909

Cumulative Model Updates: 200,714
Cumulative Timesteps: 1,673,974,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.36679
Policy Entropy: 2.22518
Value Function Loss: 0.01581

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.53343
Value Function Update Magnitude: 0.56925

Collected Steps per Second: 22,627.71563
Overall Steps per Second: 10,679.05215

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.47337
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.68394

Cumulative Model Updates: 200,720
Cumulative Timesteps: 1,674,024,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1674024382...
Checkpoint 1674024382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.74137
Policy Entropy: 2.20822
Value Function Loss: 0.01635

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.58670

Collected Steps per Second: 22,277.44187
Overall Steps per Second: 10,475.63743

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.77355

Cumulative Model Updates: 200,726
Cumulative Timesteps: 1,674,074,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.24465
Policy Entropy: 2.19378
Value Function Loss: 0.01727

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.59730

Collected Steps per Second: 22,739.21518
Overall Steps per Second: 10,674.04621

Timestep Collection Time: 2.19937
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.68538

Cumulative Model Updates: 200,732
Cumulative Timesteps: 1,674,124,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674124400...
Checkpoint 1674124400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.14970
Policy Entropy: 2.20267
Value Function Loss: 0.01748

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.55663
Value Function Update Magnitude: 0.57598

Collected Steps per Second: 22,297.11255
Overall Steps per Second: 10,607.48282

Timestep Collection Time: 2.24334
Timestep Consumption Time: 2.47220
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.71554

Cumulative Model Updates: 200,738
Cumulative Timesteps: 1,674,174,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.25292
Policy Entropy: 2.22656
Value Function Loss: 0.01693

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.57145

Collected Steps per Second: 22,616.71043
Overall Steps per Second: 10,783.20550

Timestep Collection Time: 2.21120
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.63777

Cumulative Model Updates: 200,744
Cumulative Timesteps: 1,674,224,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1674224430...
Checkpoint 1674224430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.22992
Policy Entropy: 2.22501
Value Function Loss: 0.01523

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.53743
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 21,656.07412
Overall Steps per Second: 10,484.01715

Timestep Collection Time: 2.31011
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.77183

Cumulative Model Updates: 200,750
Cumulative Timesteps: 1,674,274,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.58741
Policy Entropy: 2.23415
Value Function Loss: 0.01526

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.52260
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 22,593.71737
Overall Steps per Second: 10,551.97826

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.52605
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.73959

Cumulative Model Updates: 200,756
Cumulative Timesteps: 1,674,324,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674324470...
Checkpoint 1674324470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.34774
Policy Entropy: 2.23752
Value Function Loss: 0.01551

Mean KL Divergence: 0.03036
SB3 Clip Fraction: 0.19222
Policy Update Magnitude: 0.51695
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 22,365.66557
Overall Steps per Second: 10,438.80405

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.55466
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.79059

Cumulative Model Updates: 200,762
Cumulative Timesteps: 1,674,374,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.55724
Policy Entropy: 2.26147
Value Function Loss: 0.01594

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.49798
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 22,423.67987
Overall Steps per Second: 10,544.22659

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.74345

Cumulative Model Updates: 200,768
Cumulative Timesteps: 1,674,424,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1674424494...
Checkpoint 1674424494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.18224
Policy Entropy: 2.23398
Value Function Loss: 0.01622

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.52253
Value Function Update Magnitude: 0.56478

Collected Steps per Second: 21,907.98689
Overall Steps per Second: 10,653.83691

Timestep Collection Time: 2.28309
Timestep Consumption Time: 2.41174
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69483

Cumulative Model Updates: 200,774
Cumulative Timesteps: 1,674,474,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.88076
Policy Entropy: 2.21868
Value Function Loss: 0.01642

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.55668

Collected Steps per Second: 22,698.04658
Overall Steps per Second: 10,550.15504

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.53694
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.74021

Cumulative Model Updates: 200,780
Cumulative Timesteps: 1,674,524,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1674524522...
Checkpoint 1674524522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.67764
Policy Entropy: 2.20556
Value Function Loss: 0.01752

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.56861

Collected Steps per Second: 22,367.09478
Overall Steps per Second: 10,524.47382

Timestep Collection Time: 2.23668
Timestep Consumption Time: 2.51681
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.75349

Cumulative Model Updates: 200,786
Cumulative Timesteps: 1,674,574,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.70562
Policy Entropy: 2.21853
Value Function Loss: 0.01718

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.57867

Collected Steps per Second: 22,914.42453
Overall Steps per Second: 10,587.16092

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.72440

Cumulative Model Updates: 200,792
Cumulative Timesteps: 1,674,624,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1674624568...
Checkpoint 1674624568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.79668
Policy Entropy: 2.21642
Value Function Loss: 0.01600

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.57737

Collected Steps per Second: 22,021.07261
Overall Steps per Second: 10,549.57003

Timestep Collection Time: 2.27082
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.74010

Cumulative Model Updates: 200,798
Cumulative Timesteps: 1,674,674,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.62901
Policy Entropy: 2.23170
Value Function Loss: 0.01595

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.53612
Value Function Update Magnitude: 0.55050

Collected Steps per Second: 22,283.96813
Overall Steps per Second: 10,608.60625

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.46949
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71334

Cumulative Model Updates: 200,804
Cumulative Timesteps: 1,674,724,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1674724576...
Checkpoint 1674724576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.57167
Policy Entropy: 2.22953
Value Function Loss: 0.01612

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.54617

Collected Steps per Second: 22,223.01626
Overall Steps per Second: 10,410.46838

Timestep Collection Time: 2.25010
Timestep Consumption Time: 2.55314
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.80324

Cumulative Model Updates: 200,810
Cumulative Timesteps: 1,674,774,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.87981
Policy Entropy: 2.22408
Value Function Loss: 0.01656

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.53858
Value Function Update Magnitude: 0.55019

Collected Steps per Second: 22,654.49052
Overall Steps per Second: 10,478.55585

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.56489
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.77222

Cumulative Model Updates: 200,816
Cumulative Timesteps: 1,674,824,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1674824586...
Checkpoint 1674824586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.57936
Policy Entropy: 2.21454
Value Function Loss: 0.01662

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.53393
Value Function Update Magnitude: 0.55301

Collected Steps per Second: 22,106.95730
Overall Steps per Second: 10,557.00108

Timestep Collection Time: 2.26209
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.73695

Cumulative Model Updates: 200,822
Cumulative Timesteps: 1,674,874,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.76918
Policy Entropy: 2.21525
Value Function Loss: 0.01645

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.54697

Collected Steps per Second: 22,935.27067
Overall Steps per Second: 10,540.87510

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.56370
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.74401

Cumulative Model Updates: 200,828
Cumulative Timesteps: 1,674,924,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1674924600...
Checkpoint 1674924600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.34320
Policy Entropy: 2.24151
Value Function Loss: 0.01519

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.54050

Collected Steps per Second: 22,311.32342
Overall Steps per Second: 10,530.88275

Timestep Collection Time: 2.24227
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.75060

Cumulative Model Updates: 200,834
Cumulative Timesteps: 1,674,974,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.38037
Policy Entropy: 2.25717
Value Function Loss: 0.01529

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.54335

Collected Steps per Second: 22,714.77794
Overall Steps per Second: 10,574.98628

Timestep Collection Time: 2.20183
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.72946

Cumulative Model Updates: 200,840
Cumulative Timesteps: 1,675,024,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1675024642...
Checkpoint 1675024642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.65313
Policy Entropy: 2.23936
Value Function Loss: 0.01549

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.54093

Collected Steps per Second: 21,894.35224
Overall Steps per Second: 10,513.54074

Timestep Collection Time: 2.28415
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.75672

Cumulative Model Updates: 200,846
Cumulative Timesteps: 1,675,074,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.16417
Policy Entropy: 2.21049
Value Function Loss: 0.01752

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.55756

Collected Steps per Second: 22,229.18230
Overall Steps per Second: 10,558.18686

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.73642

Cumulative Model Updates: 200,852
Cumulative Timesteps: 1,675,124,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1675124660...
Checkpoint 1675124660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.22764
Policy Entropy: 2.20099
Value Function Loss: 0.01820

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.56963

Collected Steps per Second: 22,444.69173
Overall Steps per Second: 10,583.69194

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.72595

Cumulative Model Updates: 200,858
Cumulative Timesteps: 1,675,174,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.30240
Policy Entropy: 2.20957
Value Function Loss: 0.01794

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.15262
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 22,376.76953
Overall Steps per Second: 10,527.45332

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.75177

Cumulative Model Updates: 200,864
Cumulative Timesteps: 1,675,224,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1675224702...
Checkpoint 1675224702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.00095
Policy Entropy: 2.21459
Value Function Loss: 0.01792

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.57385

Collected Steps per Second: 21,998.80252
Overall Steps per Second: 10,522.65737

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.75184

Cumulative Model Updates: 200,870
Cumulative Timesteps: 1,675,274,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.42347
Policy Entropy: 2.23482
Value Function Loss: 0.01763

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.56142
Value Function Update Magnitude: 0.59537

Collected Steps per Second: 22,440.99672
Overall Steps per Second: 10,566.76888

Timestep Collection Time: 2.22913
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.73409

Cumulative Model Updates: 200,876
Cumulative Timesteps: 1,675,324,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1675324728...
Checkpoint 1675324728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.66001
Policy Entropy: 2.21349
Value Function Loss: 0.01723

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.60119

Collected Steps per Second: 22,221.09151
Overall Steps per Second: 10,634.01994

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70227

Cumulative Model Updates: 200,882
Cumulative Timesteps: 1,675,374,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.16753
Policy Entropy: 2.20238
Value Function Loss: 0.01766

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.56227
Value Function Update Magnitude: 0.59719

Collected Steps per Second: 22,346.22398
Overall Steps per Second: 10,472.98744

Timestep Collection Time: 2.23877
Timestep Consumption Time: 2.53809
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.77686

Cumulative Model Updates: 200,888
Cumulative Timesteps: 1,675,424,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1675424760...
Checkpoint 1675424760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.82085
Policy Entropy: 2.15858
Value Function Loss: 0.01662

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.55860
Value Function Update Magnitude: 0.59335

Collected Steps per Second: 21,861.26923
Overall Steps per Second: 10,363.38869

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.82622

Cumulative Model Updates: 200,894
Cumulative Timesteps: 1,675,474,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.60276
Policy Entropy: 2.16341
Value Function Loss: 0.01582

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.15308
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.59147

Collected Steps per Second: 22,540.90989
Overall Steps per Second: 10,634.37869

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.70192

Cumulative Model Updates: 200,900
Cumulative Timesteps: 1,675,524,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1675524778...
Checkpoint 1675524778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.42702
Policy Entropy: 2.14931
Value Function Loss: 0.01496

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.55504
Value Function Update Magnitude: 0.57465

Collected Steps per Second: 22,018.59905
Overall Steps per Second: 10,682.45012

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.41035
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.68170

Cumulative Model Updates: 200,906
Cumulative Timesteps: 1,675,574,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.11299
Policy Entropy: 2.18870
Value Function Loss: 0.01553

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.57638

Collected Steps per Second: 22,317.89343
Overall Steps per Second: 10,522.25783

Timestep Collection Time: 2.24089
Timestep Consumption Time: 2.51208
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.75297

Cumulative Model Updates: 200,912
Cumulative Timesteps: 1,675,624,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1675624802...
Checkpoint 1675624802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.48309
Policy Entropy: 2.17612
Value Function Loss: 0.01687

Mean KL Divergence: 0.03263
SB3 Clip Fraction: 0.20243
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.58680

Collected Steps per Second: 22,148.63841
Overall Steps per Second: 10,536.61968

Timestep Collection Time: 2.25865
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.74782

Cumulative Model Updates: 200,918
Cumulative Timesteps: 1,675,674,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.96433
Policy Entropy: 2.19706
Value Function Loss: 0.01696

Mean KL Divergence: 0.02853
SB3 Clip Fraction: 0.18392
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 22,328.08971
Overall Steps per Second: 10,506.03671

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.76088

Cumulative Model Updates: 200,924
Cumulative Timesteps: 1,675,724,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1675724846...
Checkpoint 1675724846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.39388
Policy Entropy: 2.19125
Value Function Loss: 0.01637

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 21,625.51593
Overall Steps per Second: 10,317.74104

Timestep Collection Time: 2.31301
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.84796

Cumulative Model Updates: 200,930
Cumulative Timesteps: 1,675,774,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.29064
Policy Entropy: 2.21829
Value Function Loss: 0.01492

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.57845

Collected Steps per Second: 22,581.75150
Overall Steps per Second: 10,753.07656

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.65113

Cumulative Model Updates: 200,936
Cumulative Timesteps: 1,675,824,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1675824880...
Checkpoint 1675824880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.96284
Policy Entropy: 2.23847
Value Function Loss: 0.01588

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.57422

Collected Steps per Second: 22,305.98250
Overall Steps per Second: 10,498.24082

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.76480

Cumulative Model Updates: 200,942
Cumulative Timesteps: 1,675,874,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.58696
Policy Entropy: 2.24935
Value Function Loss: 0.01635

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.58401

Collected Steps per Second: 22,579.16631
Overall Steps per Second: 10,616.02977

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.71268

Cumulative Model Updates: 200,948
Cumulative Timesteps: 1,675,924,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1675924932...
Checkpoint 1675924932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.50294
Policy Entropy: 2.23724
Value Function Loss: 0.01673

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.60872

Collected Steps per Second: 22,056.01858
Overall Steps per Second: 10,432.56962

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.79556

Cumulative Model Updates: 200,954
Cumulative Timesteps: 1,675,974,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.97835
Policy Entropy: 2.24153
Value Function Loss: 0.01628

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.60717

Collected Steps per Second: 22,469.98503
Overall Steps per Second: 10,768.54007

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.41893
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.64501

Cumulative Model Updates: 200,960
Cumulative Timesteps: 1,676,024,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1676024982...
Checkpoint 1676024982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.01154
Policy Entropy: 2.22573
Value Function Loss: 0.01736

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.55317
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 22,031.62399
Overall Steps per Second: 10,397.90916

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.53930
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.80885

Cumulative Model Updates: 200,966
Cumulative Timesteps: 1,676,074,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.02713
Policy Entropy: 2.22786
Value Function Loss: 0.01651

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 22,707.74699
Overall Steps per Second: 10,629.97079

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.70613

Cumulative Model Updates: 200,972
Cumulative Timesteps: 1,676,125,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1676125010...
Checkpoint 1676125010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.44713
Policy Entropy: 2.21432
Value Function Loss: 0.01629

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.60448

Collected Steps per Second: 22,400.39348
Overall Steps per Second: 10,651.47761

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.46238
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.69475

Cumulative Model Updates: 200,978
Cumulative Timesteps: 1,676,175,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.18862
Policy Entropy: 2.21107
Value Function Loss: 0.01633

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.59178

Collected Steps per Second: 23,021.17540
Overall Steps per Second: 10,547.71967

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.56989
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.74302

Cumulative Model Updates: 200,984
Cumulative Timesteps: 1,676,225,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1676225044...
Checkpoint 1676225044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.06008
Policy Entropy: 2.23490
Value Function Loss: 0.01619

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.59353

Collected Steps per Second: 22,209.79022
Overall Steps per Second: 10,548.74230

Timestep Collection Time: 2.25243
Timestep Consumption Time: 2.48994
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.74237

Cumulative Model Updates: 200,990
Cumulative Timesteps: 1,676,275,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.76022
Policy Entropy: 2.23648
Value Function Loss: 0.01665

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.59074

Collected Steps per Second: 22,369.48402
Overall Steps per Second: 10,583.06418

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.72453

Cumulative Model Updates: 200,996
Cumulative Timesteps: 1,676,325,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1676325070...
Checkpoint 1676325070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.87907
Policy Entropy: 2.19900
Value Function Loss: 0.01584

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.55665

Collected Steps per Second: 21,988.00808
Overall Steps per Second: 10,531.13756

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.74821

Cumulative Model Updates: 201,002
Cumulative Timesteps: 1,676,375,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.71039
Policy Entropy: 2.17087
Value Function Loss: 0.01674

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.55018
Value Function Update Magnitude: 0.56157

Collected Steps per Second: 22,239.86430
Overall Steps per Second: 10,565.40973

Timestep Collection Time: 2.24929
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.73470

Cumulative Model Updates: 201,008
Cumulative Timesteps: 1,676,425,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1676425098...
Checkpoint 1676425098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.63181
Policy Entropy: 2.15175
Value Function Loss: 0.01578

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.57040

Collected Steps per Second: 22,276.31289
Overall Steps per Second: 10,550.81714

Timestep Collection Time: 2.24463
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.73916

Cumulative Model Updates: 201,014
Cumulative Timesteps: 1,676,475,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.45884
Policy Entropy: 2.19484
Value Function Loss: 0.01629

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.57235

Collected Steps per Second: 22,362.12718
Overall Steps per Second: 10,525.93199

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.75302

Cumulative Model Updates: 201,020
Cumulative Timesteps: 1,676,525,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1676525130...
Checkpoint 1676525130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.27231
Policy Entropy: 2.15992
Value Function Loss: 0.01621

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 22,253.26078
Overall Steps per Second: 10,584.57617

Timestep Collection Time: 2.24767
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.72556

Cumulative Model Updates: 201,026
Cumulative Timesteps: 1,676,575,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.81420
Policy Entropy: 2.17105
Value Function Loss: 0.01612

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.58400

Collected Steps per Second: 22,426.26517
Overall Steps per Second: 10,634.49404

Timestep Collection Time: 2.22962
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.70187

Cumulative Model Updates: 201,032
Cumulative Timesteps: 1,676,625,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1676625150...
Checkpoint 1676625150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.15592
Policy Entropy: 2.13986
Value Function Loss: 0.01515

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 22,435.20860
Overall Steps per Second: 10,610.30867

Timestep Collection Time: 2.22971
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.71466

Cumulative Model Updates: 201,038
Cumulative Timesteps: 1,676,675,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.14943
Policy Entropy: 2.18962
Value Function Loss: 0.01590

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.54921
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 22,548.67591
Overall Steps per Second: 10,451.65086

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.56661
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.78412

Cumulative Model Updates: 201,044
Cumulative Timesteps: 1,676,725,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1676725176...
Checkpoint 1676725176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.18912
Policy Entropy: 2.20020
Value Function Loss: 0.01613

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.55068
Value Function Update Magnitude: 0.66243

Collected Steps per Second: 22,285.86614
Overall Steps per Second: 10,584.00982

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.72562

Cumulative Model Updates: 201,050
Cumulative Timesteps: 1,676,775,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.95600
Policy Entropy: 2.18973
Value Function Loss: 0.01708

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.64817

Collected Steps per Second: 22,137.79696
Overall Steps per Second: 10,552.41498

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.73844

Cumulative Model Updates: 201,056
Cumulative Timesteps: 1,676,825,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1676825194...
Checkpoint 1676825194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.60891
Policy Entropy: 2.17222
Value Function Loss: 0.01660

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.63133

Collected Steps per Second: 22,407.81059
Overall Steps per Second: 10,571.33056

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.73148

Cumulative Model Updates: 201,062
Cumulative Timesteps: 1,676,875,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.31819
Policy Entropy: 2.15205
Value Function Loss: 0.01646

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.61402

Collected Steps per Second: 22,396.24915
Overall Steps per Second: 10,440.04589

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.55837
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.79232

Cumulative Model Updates: 201,068
Cumulative Timesteps: 1,676,925,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1676925244...
Checkpoint 1676925244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.48901
Policy Entropy: 2.14901
Value Function Loss: 0.01638

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 22,303.60022
Overall Steps per Second: 10,558.19646

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.73793

Cumulative Model Updates: 201,074
Cumulative Timesteps: 1,676,975,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.28094
Policy Entropy: 2.15711
Value Function Loss: 0.01739

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.19052
Policy Update Magnitude: 0.53413
Value Function Update Magnitude: 0.68664

Collected Steps per Second: 22,028.99608
Overall Steps per Second: 10,553.75584

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.73860

Cumulative Model Updates: 201,080
Cumulative Timesteps: 1,677,025,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1677025278...
Checkpoint 1677025278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.43924
Policy Entropy: 2.15214
Value Function Loss: 0.01887

Mean KL Divergence: 0.02984
SB3 Clip Fraction: 0.19068
Policy Update Magnitude: 0.53357
Value Function Update Magnitude: 0.69943

Collected Steps per Second: 23,019.49209
Overall Steps per Second: 10,642.10253

Timestep Collection Time: 2.17233
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69888

Cumulative Model Updates: 201,086
Cumulative Timesteps: 1,677,075,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.73311
Policy Entropy: 2.19284
Value Function Loss: 0.01877

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.17795
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.69112

Collected Steps per Second: 20,816.75712
Overall Steps per Second: 10,033.12557

Timestep Collection Time: 2.40191
Timestep Consumption Time: 2.58158
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 4.98349

Cumulative Model Updates: 201,092
Cumulative Timesteps: 1,677,125,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1677125284...
Checkpoint 1677125284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.34967
Policy Entropy: 2.18787
Value Function Loss: 0.01824

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.18456
Policy Update Magnitude: 0.55763
Value Function Update Magnitude: 0.66393

Collected Steps per Second: 22,471.78695
Overall Steps per Second: 10,592.88630

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.72204

Cumulative Model Updates: 201,098
Cumulative Timesteps: 1,677,175,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.74198
Policy Entropy: 2.22603
Value Function Loss: 0.01746

Mean KL Divergence: 0.02532
SB3 Clip Fraction: 0.17644
Policy Update Magnitude: 0.56267
Value Function Update Magnitude: 0.62620

Collected Steps per Second: 22,399.18920
Overall Steps per Second: 10,521.55723

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.52043
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.75310

Cumulative Model Updates: 201,104
Cumulative Timesteps: 1,677,225,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1677225314...
Checkpoint 1677225314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.38436
Policy Entropy: 2.23971
Value Function Loss: 0.01652

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.60516

Collected Steps per Second: 22,273.78157
Overall Steps per Second: 10,644.61910

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.45359
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.69946

Cumulative Model Updates: 201,110
Cumulative Timesteps: 1,677,275,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.57427
Policy Entropy: 2.23165
Value Function Loss: 0.01614

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.61211

Collected Steps per Second: 22,128.41998
Overall Steps per Second: 10,444.86293

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.52771
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.78743

Cumulative Model Updates: 201,116
Cumulative Timesteps: 1,677,325,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1677325342...
Checkpoint 1677325342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.63648
Policy Entropy: 2.23284
Value Function Loss: 0.01518

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.62707

Collected Steps per Second: 22,523.06835
Overall Steps per Second: 10,648.06668

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.69569

Cumulative Model Updates: 201,122
Cumulative Timesteps: 1,677,375,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.93432
Policy Entropy: 2.22279
Value Function Loss: 0.01623

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.54091
Value Function Update Magnitude: 0.63779

Collected Steps per Second: 22,337.59775
Overall Steps per Second: 10,505.17558

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.75975

Cumulative Model Updates: 201,128
Cumulative Timesteps: 1,677,425,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1677425344...
Checkpoint 1677425344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.39622
Policy Entropy: 2.25209
Value Function Loss: 0.01680

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.65610

Collected Steps per Second: 22,539.68300
Overall Steps per Second: 10,716.54578

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.66848

Cumulative Model Updates: 201,134
Cumulative Timesteps: 1,677,475,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.60307
Policy Entropy: 2.23248
Value Function Loss: 0.01732

Mean KL Divergence: 0.02782
SB3 Clip Fraction: 0.17990
Policy Update Magnitude: 0.51622
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 22,604.15974
Overall Steps per Second: 10,672.02201

Timestep Collection Time: 2.21260
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.68646

Cumulative Model Updates: 201,140
Cumulative Timesteps: 1,677,525,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1677525388...
Checkpoint 1677525388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.66029
Policy Entropy: 2.23941
Value Function Loss: 0.01668

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.51372
Value Function Update Magnitude: 0.61874

Collected Steps per Second: 22,813.57238
Overall Steps per Second: 10,762.62274

Timestep Collection Time: 2.19273
Timestep Consumption Time: 2.45521
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.64794

Cumulative Model Updates: 201,146
Cumulative Timesteps: 1,677,575,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.80391
Policy Entropy: 2.22328
Value Function Loss: 0.01636

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.60851

Collected Steps per Second: 22,528.34313
Overall Steps per Second: 10,499.08689

Timestep Collection Time: 2.21952
Timestep Consumption Time: 2.54299
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.76251

Cumulative Model Updates: 201,152
Cumulative Timesteps: 1,677,625,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1677625414...
Checkpoint 1677625414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.99179
Policy Entropy: 2.22734
Value Function Loss: 0.01671

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.16576
Policy Update Magnitude: 0.51128
Value Function Update Magnitude: 0.61905

Collected Steps per Second: 22,349.49015
Overall Steps per Second: 10,601.20696

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.71644

Cumulative Model Updates: 201,158
Cumulative Timesteps: 1,677,675,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.19390
Policy Entropy: 2.21217
Value Function Loss: 0.01613

Mean KL Divergence: 0.02887
SB3 Clip Fraction: 0.19030
Policy Update Magnitude: 0.48399
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 22,295.15424
Overall Steps per Second: 10,591.07088

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.72134

Cumulative Model Updates: 201,164
Cumulative Timesteps: 1,677,725,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1677725418...
Checkpoint 1677725418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.40976
Policy Entropy: 2.20228
Value Function Loss: 0.01655

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.20194
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.64363

Collected Steps per Second: 22,401.47966
Overall Steps per Second: 10,439.50107

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.55761
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.78969

Cumulative Model Updates: 201,170
Cumulative Timesteps: 1,677,775,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.06751
Policy Entropy: 2.19662
Value Function Loss: 0.01643

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.18546
Policy Update Magnitude: 0.51501
Value Function Update Magnitude: 0.66099

Collected Steps per Second: 22,344.45157
Overall Steps per Second: 10,468.86098

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.53868
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.77664

Cumulative Model Updates: 201,176
Cumulative Timesteps: 1,677,825,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1677825426...
Checkpoint 1677825426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.86204
Policy Entropy: 2.20127
Value Function Loss: 0.01679

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.17972
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.63322

Collected Steps per Second: 21,956.87233
Overall Steps per Second: 10,403.26301

Timestep Collection Time: 2.27765
Timestep Consumption Time: 2.52950
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.80715

Cumulative Model Updates: 201,182
Cumulative Timesteps: 1,677,875,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.56521
Policy Entropy: 2.23166
Value Function Loss: 0.01633

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.17568
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.61557

Collected Steps per Second: 22,708.61972
Overall Steps per Second: 10,681.84716

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.68215

Cumulative Model Updates: 201,188
Cumulative Timesteps: 1,677,925,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1677925450...
Checkpoint 1677925450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.21297
Policy Entropy: 2.24155
Value Function Loss: 0.01567

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.61616

Collected Steps per Second: 22,513.23780
Overall Steps per Second: 10,602.09143

Timestep Collection Time: 2.22127
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.71681

Cumulative Model Updates: 201,194
Cumulative Timesteps: 1,677,975,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.28045
Policy Entropy: 2.25114
Value Function Loss: 0.01548

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 22,263.38972
Overall Steps per Second: 10,509.14178

Timestep Collection Time: 2.24638
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.75890

Cumulative Model Updates: 201,200
Cumulative Timesteps: 1,678,025,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1678025470...
Checkpoint 1678025470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.64130
Policy Entropy: 2.25232
Value Function Loss: 0.01557

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.54251
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,108.72359
Overall Steps per Second: 10,633.03927

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.70496

Cumulative Model Updates: 201,206
Cumulative Timesteps: 1,678,075,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.90824
Policy Entropy: 2.23886
Value Function Loss: 0.01560

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 22,157.02757
Overall Steps per Second: 10,440.50777

Timestep Collection Time: 2.25734
Timestep Consumption Time: 2.53323
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.79057

Cumulative Model Updates: 201,212
Cumulative Timesteps: 1,678,125,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1678125514...
Checkpoint 1678125514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.03506
Policy Entropy: 2.24015
Value Function Loss: 0.01555

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.57754

Collected Steps per Second: 21,753.47391
Overall Steps per Second: 10,582.66769

Timestep Collection Time: 2.29858
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.72490

Cumulative Model Updates: 201,218
Cumulative Timesteps: 1,678,175,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.39802
Policy Entropy: 2.22805
Value Function Loss: 0.01554

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.57896

Collected Steps per Second: 22,327.35980
Overall Steps per Second: 10,529.21630

Timestep Collection Time: 2.23958
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.74907

Cumulative Model Updates: 201,224
Cumulative Timesteps: 1,678,225,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1678225520...
Checkpoint 1678225520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.21630
Policy Entropy: 2.27001
Value Function Loss: 0.01503

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.53968
Value Function Update Magnitude: 0.58768

Collected Steps per Second: 22,000.52551
Overall Steps per Second: 10,512.34346

Timestep Collection Time: 2.27285
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.75669

Cumulative Model Updates: 201,230
Cumulative Timesteps: 1,678,275,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.35420
Policy Entropy: 2.25270
Value Function Loss: 0.01406

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.52983
Value Function Update Magnitude: 0.57542

Collected Steps per Second: 22,276.89359
Overall Steps per Second: 10,584.83230

Timestep Collection Time: 2.24538
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.72563

Cumulative Model Updates: 201,236
Cumulative Timesteps: 1,678,325,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1678325544...
Checkpoint 1678325544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.63190
Policy Entropy: 2.27225
Value Function Loss: 0.01386

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.51798
Value Function Update Magnitude: 0.54868

Collected Steps per Second: 22,215.40684
Overall Steps per Second: 10,634.02211

Timestep Collection Time: 2.25177
Timestep Consumption Time: 2.45238
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.70415

Cumulative Model Updates: 201,242
Cumulative Timesteps: 1,678,375,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.69890
Policy Entropy: 2.24125
Value Function Loss: 0.01429

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.51317
Value Function Update Magnitude: 0.53101

Collected Steps per Second: 22,455.00076
Overall Steps per Second: 10,449.11797

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.55903
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.78624

Cumulative Model Updates: 201,248
Cumulative Timesteps: 1,678,425,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1678425580...
Checkpoint 1678425580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.38015
Policy Entropy: 2.23743
Value Function Loss: 0.01534

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.55235

Collected Steps per Second: 22,033.08479
Overall Steps per Second: 10,379.38107

Timestep Collection Time: 2.26950
Timestep Consumption Time: 2.54813
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.81763

Cumulative Model Updates: 201,254
Cumulative Timesteps: 1,678,475,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.24950
Policy Entropy: 2.22932
Value Function Loss: 0.01540

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.58477

Collected Steps per Second: 22,553.69183
Overall Steps per Second: 10,647.59820

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.69796

Cumulative Model Updates: 201,260
Cumulative Timesteps: 1,678,525,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1678525606...
Checkpoint 1678525606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.97552
Policy Entropy: 2.26485
Value Function Loss: 0.01493

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.58014

Collected Steps per Second: 22,131.33186
Overall Steps per Second: 10,677.20543

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68437

Cumulative Model Updates: 201,266
Cumulative Timesteps: 1,678,575,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.34355
Policy Entropy: 2.28495
Value Function Loss: 0.01469

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 22,514.05238
Overall Steps per Second: 10,514.06949

Timestep Collection Time: 2.22217
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.75839

Cumulative Model Updates: 201,272
Cumulative Timesteps: 1,678,625,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1678625652...
Checkpoint 1678625652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.96660
Policy Entropy: 2.28560
Value Function Loss: 0.01483

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.54120

Collected Steps per Second: 22,147.02291
Overall Steps per Second: 10,525.87176

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.49286
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.75077

Cumulative Model Updates: 201,278
Cumulative Timesteps: 1,678,675,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.42442
Policy Entropy: 2.25047
Value Function Loss: 0.01586

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.57054

Collected Steps per Second: 22,254.10504
Overall Steps per Second: 10,512.57946

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.75811

Cumulative Model Updates: 201,284
Cumulative Timesteps: 1,678,725,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1678725678...
Checkpoint 1678725678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.61455
Policy Entropy: 2.24537
Value Function Loss: 0.01554

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.60731

Collected Steps per Second: 22,212.64665
Overall Steps per Second: 10,580.99945

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.72621

Cumulative Model Updates: 201,290
Cumulative Timesteps: 1,678,775,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.45936
Policy Entropy: 2.22390
Value Function Loss: 0.01590

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.62549

Collected Steps per Second: 22,258.15734
Overall Steps per Second: 10,581.62647

Timestep Collection Time: 2.24745
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.72744

Cumulative Model Updates: 201,296
Cumulative Timesteps: 1,678,825,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1678825710...
Checkpoint 1678825710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.64756
Policy Entropy: 2.25279
Value Function Loss: 0.01545

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.61062

Collected Steps per Second: 22,226.48984
Overall Steps per Second: 10,525.05636

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.75152

Cumulative Model Updates: 201,302
Cumulative Timesteps: 1,678,875,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.74572
Policy Entropy: 2.25005
Value Function Loss: 0.01536

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.58212

Collected Steps per Second: 22,655.02919
Overall Steps per Second: 10,548.00200

Timestep Collection Time: 2.20781
Timestep Consumption Time: 2.53413
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.74194

Cumulative Model Updates: 201,308
Cumulative Timesteps: 1,678,925,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1678925738...
Checkpoint 1678925738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.77247
Policy Entropy: 2.26078
Value Function Loss: 0.01578

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.54877

Collected Steps per Second: 21,791.58833
Overall Steps per Second: 10,410.99733

Timestep Collection Time: 2.29538
Timestep Consumption Time: 2.50915
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.80453

Cumulative Model Updates: 201,314
Cumulative Timesteps: 1,678,975,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.04334
Policy Entropy: 2.25569
Value Function Loss: 0.01609

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.55011

Collected Steps per Second: 22,669.91437
Overall Steps per Second: 10,678.14365

Timestep Collection Time: 2.20698
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.68546

Cumulative Model Updates: 201,320
Cumulative Timesteps: 1,679,025,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1679025790...
Checkpoint 1679025790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.47154
Policy Entropy: 2.24613
Value Function Loss: 0.01579

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.58221

Collected Steps per Second: 21,310.44040
Overall Steps per Second: 10,413.27780

Timestep Collection Time: 2.34702
Timestep Consumption Time: 2.45608
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.80310

Cumulative Model Updates: 201,326
Cumulative Timesteps: 1,679,075,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.10289
Policy Entropy: 2.26692
Value Function Loss: 0.01482

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.57790

Collected Steps per Second: 22,542.48988
Overall Steps per Second: 10,609.40860

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.71544

Cumulative Model Updates: 201,332
Cumulative Timesteps: 1,679,125,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1679125834...
Checkpoint 1679125834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.10001
Policy Entropy: 2.26914
Value Function Loss: 0.01416

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.52506
Value Function Update Magnitude: 0.56123

Collected Steps per Second: 22,159.25188
Overall Steps per Second: 10,403.48883

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.55030
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.80723

Cumulative Model Updates: 201,338
Cumulative Timesteps: 1,679,175,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.32110
Policy Entropy: 2.26970
Value Function Loss: 0.01441

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.52973
Value Function Update Magnitude: 0.55460

Collected Steps per Second: 22,167.64864
Overall Steps per Second: 10,370.20955

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.56607
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.82170

Cumulative Model Updates: 201,344
Cumulative Timesteps: 1,679,225,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1679225848...
Checkpoint 1679225848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.82455
Policy Entropy: 2.26331
Value Function Loss: 0.01504

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.55681

Collected Steps per Second: 22,082.27812
Overall Steps per Second: 10,565.53139

Timestep Collection Time: 2.26498
Timestep Consumption Time: 2.46890
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.73388

Cumulative Model Updates: 201,350
Cumulative Timesteps: 1,679,275,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.34397
Policy Entropy: 2.24210
Value Function Loss: 0.01660

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.58247

Collected Steps per Second: 22,419.06058
Overall Steps per Second: 10,635.33627

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.70131

Cumulative Model Updates: 201,356
Cumulative Timesteps: 1,679,325,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1679325864...
Checkpoint 1679325864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.68338
Policy Entropy: 2.25286
Value Function Loss: 0.01586

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.17654
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.59658

Collected Steps per Second: 22,393.74787
Overall Steps per Second: 10,529.68318

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.75114

Cumulative Model Updates: 201,362
Cumulative Timesteps: 1,679,375,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.63218
Policy Entropy: 2.25519
Value Function Loss: 0.01611

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.16903
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 22,172.68169
Overall Steps per Second: 10,469.41534

Timestep Collection Time: 2.25620
Timestep Consumption Time: 2.52210
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.77830

Cumulative Model Updates: 201,368
Cumulative Timesteps: 1,679,425,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1679425918...
Checkpoint 1679425918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.29802
Policy Entropy: 2.26728
Value Function Loss: 0.01615

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.17116
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 22,164.13524
Overall Steps per Second: 10,594.40771

Timestep Collection Time: 2.25635
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.72041

Cumulative Model Updates: 201,374
Cumulative Timesteps: 1,679,475,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.81525
Policy Entropy: 2.25962
Value Function Loss: 0.01595

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.17521
Policy Update Magnitude: 0.52567
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,482.35422
Overall Steps per Second: 10,478.91583

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.54772
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.77187

Cumulative Model Updates: 201,380
Cumulative Timesteps: 1,679,525,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1679525932...
Checkpoint 1679525932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.35383
Policy Entropy: 2.27736
Value Function Loss: 0.01488

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.16136
Policy Update Magnitude: 0.53642
Value Function Update Magnitude: 0.59029

Collected Steps per Second: 22,039.05099
Overall Steps per Second: 10,649.71160

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69759

Cumulative Model Updates: 201,386
Cumulative Timesteps: 1,679,575,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.04732
Policy Entropy: 2.25776
Value Function Loss: 0.01448

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 22,608.52219
Overall Steps per Second: 10,478.52233

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.56154
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.77434

Cumulative Model Updates: 201,392
Cumulative Timesteps: 1,679,625,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1679625988...
Checkpoint 1679625988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.04293
Policy Entropy: 2.29742
Value Function Loss: 0.01455

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,172.33973
Overall Steps per Second: 10,551.02956

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.74153

Cumulative Model Updates: 201,398
Cumulative Timesteps: 1,679,676,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.69034
Policy Entropy: 2.29825
Value Function Loss: 0.01483

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.57052

Collected Steps per Second: 21,767.96524
Overall Steps per Second: 10,405.12225

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.80725

Cumulative Model Updates: 201,404
Cumulative Timesteps: 1,679,726,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1679726036...
Checkpoint 1679726036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.81355
Policy Entropy: 2.30777
Value Function Loss: 0.01562

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.53832
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 22,126.65635
Overall Steps per Second: 10,458.63905

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.78303

Cumulative Model Updates: 201,410
Cumulative Timesteps: 1,679,776,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.13597
Policy Entropy: 2.28015
Value Function Loss: 0.01621

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.57348

Collected Steps per Second: 22,376.17097
Overall Steps per Second: 10,756.26609

Timestep Collection Time: 2.23559
Timestep Consumption Time: 2.41509
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.65068

Cumulative Model Updates: 201,416
Cumulative Timesteps: 1,679,826,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1679826084...
Checkpoint 1679826084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.69774
Policy Entropy: 2.28346
Value Function Loss: 0.01704

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.55400
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 22,054.00387
Overall Steps per Second: 10,438.38025

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.52376
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.79174

Cumulative Model Updates: 201,422
Cumulative Timesteps: 1,679,876,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.97086
Policy Entropy: 2.27174
Value Function Loss: 0.01607

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.63163

Collected Steps per Second: 22,740.59759
Overall Steps per Second: 10,633.88225

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.70308

Cumulative Model Updates: 201,428
Cumulative Timesteps: 1,679,926,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1679926114...
Checkpoint 1679926114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.04287
Policy Entropy: 2.28599
Value Function Loss: 0.01613

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.62922

Collected Steps per Second: 21,849.64789
Overall Steps per Second: 10,315.91037

Timestep Collection Time: 2.28864
Timestep Consumption Time: 2.55882
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.84746

Cumulative Model Updates: 201,434
Cumulative Timesteps: 1,679,976,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.44546
Policy Entropy: 2.26488
Value Function Loss: 0.01486

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.52813
Value Function Update Magnitude: 0.60650

Collected Steps per Second: 22,293.70388
Overall Steps per Second: 10,478.89528

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.52881
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.77169

Cumulative Model Updates: 201,440
Cumulative Timesteps: 1,680,026,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1680026122...
Checkpoint 1680026122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.46335
Policy Entropy: 2.28907
Value Function Loss: 0.01467

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,262.31172
Overall Steps per Second: 10,570.35597

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.73097

Cumulative Model Updates: 201,446
Cumulative Timesteps: 1,680,076,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.45378
Policy Entropy: 2.29542
Value Function Loss: 0.01445

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 22,536.67458
Overall Steps per Second: 10,798.24965

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.41322
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.63316

Cumulative Model Updates: 201,452
Cumulative Timesteps: 1,680,126,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1680126160...
Checkpoint 1680126160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.78481
Policy Entropy: 2.30377
Value Function Loss: 0.01440

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 22,145.84242
Overall Steps per Second: 10,406.71630

Timestep Collection Time: 2.25839
Timestep Consumption Time: 2.54754
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.80593

Cumulative Model Updates: 201,458
Cumulative Timesteps: 1,680,176,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.07620
Policy Entropy: 2.27542
Value Function Loss: 0.01406

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.53012
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 22,658.48637
Overall Steps per Second: 10,531.29634

Timestep Collection Time: 2.20677
Timestep Consumption Time: 2.54118
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.74794

Cumulative Model Updates: 201,464
Cumulative Timesteps: 1,680,226,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1680226176...
Checkpoint 1680226176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.92566
Policy Entropy: 2.25215
Value Function Loss: 0.01423

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.59118

Collected Steps per Second: 20,872.99207
Overall Steps per Second: 10,054.45351

Timestep Collection Time: 2.39601
Timestep Consumption Time: 2.57810
PPO Batch Consumption Time: 0.30959
Total Iteration Time: 4.97411

Cumulative Model Updates: 201,470
Cumulative Timesteps: 1,680,276,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.15363
Policy Entropy: 2.25764
Value Function Loss: 0.01424

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.58493

Collected Steps per Second: 20,361.29285
Overall Steps per Second: 9,962.04753

Timestep Collection Time: 2.45623
Timestep Consumption Time: 2.56402
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 5.02025

Cumulative Model Updates: 201,476
Cumulative Timesteps: 1,680,326,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1680326200...
Checkpoint 1680326200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.93258
Policy Entropy: 2.25959
Value Function Loss: 0.01531

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.60492

Collected Steps per Second: 21,796.00606
Overall Steps per Second: 10,624.76589

Timestep Collection Time: 2.29482
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.70768

Cumulative Model Updates: 201,482
Cumulative Timesteps: 1,680,376,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.27081
Policy Entropy: 2.27586
Value Function Loss: 0.01592

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.60874

Collected Steps per Second: 22,332.16849
Overall Steps per Second: 10,532.17925

Timestep Collection Time: 2.24027
Timestep Consumption Time: 2.50994
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.75020

Cumulative Model Updates: 201,488
Cumulative Timesteps: 1,680,426,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1680426248...
Checkpoint 1680426248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.39229
Policy Entropy: 2.26148
Value Function Loss: 0.01599

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 21,998.64021
Overall Steps per Second: 10,533.73841

Timestep Collection Time: 2.27314
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.74722

Cumulative Model Updates: 201,494
Cumulative Timesteps: 1,680,476,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.89295
Policy Entropy: 2.25837
Value Function Loss: 0.01479

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.52696
Value Function Update Magnitude: 0.59011

Collected Steps per Second: 22,417.25803
Overall Steps per Second: 10,559.20501

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.50518
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.73596

Cumulative Model Updates: 201,500
Cumulative Timesteps: 1,680,526,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1680526262...
Checkpoint 1680526262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.30124
Policy Entropy: 2.25659
Value Function Loss: 0.01374

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.52213
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 21,923.49888
Overall Steps per Second: 10,522.89397

Timestep Collection Time: 2.28184
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.75402

Cumulative Model Updates: 201,506
Cumulative Timesteps: 1,680,576,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.58407
Policy Entropy: 2.24439
Value Function Loss: 0.01465

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.55995

Collected Steps per Second: 22,319.11833
Overall Steps per Second: 10,576.14786

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.73046

Cumulative Model Updates: 201,512
Cumulative Timesteps: 1,680,626,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1680626318...
Checkpoint 1680626318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.79674
Policy Entropy: 2.24770
Value Function Loss: 0.01466

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.57383

Collected Steps per Second: 22,321.84011
Overall Steps per Second: 10,557.45637

Timestep Collection Time: 2.24005
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.73618

Cumulative Model Updates: 201,518
Cumulative Timesteps: 1,680,676,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.01111
Policy Entropy: 2.22719
Value Function Loss: 0.01597

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.58619

Collected Steps per Second: 22,251.10892
Overall Steps per Second: 10,550.30782

Timestep Collection Time: 2.24825
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.74166

Cumulative Model Updates: 201,524
Cumulative Timesteps: 1,680,726,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1680726346...
Checkpoint 1680726346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.74221
Policy Entropy: 2.25152
Value Function Loss: 0.01568

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.60006

Collected Steps per Second: 21,979.89593
Overall Steps per Second: 10,565.57339

Timestep Collection Time: 2.27526
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73330

Cumulative Model Updates: 201,530
Cumulative Timesteps: 1,680,776,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.00216
Policy Entropy: 2.26070
Value Function Loss: 0.01623

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.62164

Collected Steps per Second: 22,109.63244
Overall Steps per Second: 10,522.61574

Timestep Collection Time: 2.26182
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.75243

Cumulative Model Updates: 201,536
Cumulative Timesteps: 1,680,826,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1680826364...
Checkpoint 1680826364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.52563
Policy Entropy: 2.25736
Value Function Loss: 0.01529

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.54092
Value Function Update Magnitude: 0.61949

Collected Steps per Second: 22,207.82243
Overall Steps per Second: 10,633.24062

Timestep Collection Time: 2.25281
Timestep Consumption Time: 2.45225
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.70506

Cumulative Model Updates: 201,542
Cumulative Timesteps: 1,680,876,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.04532
Policy Entropy: 2.24151
Value Function Loss: 0.01504

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.53174
Value Function Update Magnitude: 0.60465

Collected Steps per Second: 22,481.59187
Overall Steps per Second: 10,421.68014

Timestep Collection Time: 2.22520
Timestep Consumption Time: 2.57499
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.80019

Cumulative Model Updates: 201,548
Cumulative Timesteps: 1,680,926,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1680926420...
Checkpoint 1680926420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.87178
Policy Entropy: 2.21874
Value Function Loss: 0.01471

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.52823
Value Function Update Magnitude: 0.57720

Collected Steps per Second: 22,186.67051
Overall Steps per Second: 10,447.22653

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.53286
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.78692

Cumulative Model Updates: 201,554
Cumulative Timesteps: 1,680,976,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.62205
Policy Entropy: 2.25767
Value Function Loss: 0.01480

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.56481

Collected Steps per Second: 22,549.64168
Overall Steps per Second: 10,615.64635

Timestep Collection Time: 2.21777
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.71097

Cumulative Model Updates: 201,560
Cumulative Timesteps: 1,681,026,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1681026440...
Checkpoint 1681026440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.12843
Policy Entropy: 2.23485
Value Function Loss: 0.01496

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.53447
Value Function Update Magnitude: 0.55564

Collected Steps per Second: 22,156.37424
Overall Steps per Second: 10,612.13135

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.71404

Cumulative Model Updates: 201,566
Cumulative Timesteps: 1,681,076,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.73126
Policy Entropy: 2.23034
Value Function Loss: 0.01507

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.55467

Collected Steps per Second: 22,070.73127
Overall Steps per Second: 10,554.47477

Timestep Collection Time: 2.26626
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.73903

Cumulative Model Updates: 201,572
Cumulative Timesteps: 1,681,126,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1681126484...
Checkpoint 1681126484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.76109
Policy Entropy: 2.21045
Value Function Loss: 0.01668

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.55543

Collected Steps per Second: 22,182.43239
Overall Steps per Second: 10,547.87143

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.74200

Cumulative Model Updates: 201,578
Cumulative Timesteps: 1,681,176,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.85668
Policy Entropy: 2.21355
Value Function Loss: 0.01640

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.54530

Collected Steps per Second: 22,453.77771
Overall Steps per Second: 10,544.94325

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.74218

Cumulative Model Updates: 201,584
Cumulative Timesteps: 1,681,226,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1681226508...
Checkpoint 1681226508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.33319
Policy Entropy: 2.21971
Value Function Loss: 0.01601

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.52675

Collected Steps per Second: 20,400.06028
Overall Steps per Second: 10,083.25387

Timestep Collection Time: 2.45186
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.96050

Cumulative Model Updates: 201,590
Cumulative Timesteps: 1,681,276,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.34997
Policy Entropy: 2.21449
Value Function Loss: 0.01590

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.52048

Collected Steps per Second: 22,108.11727
Overall Steps per Second: 10,582.80246

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.46402
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.72654

Cumulative Model Updates: 201,596
Cumulative Timesteps: 1,681,326,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1681326546...
Checkpoint 1681326546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.79802
Policy Entropy: 2.22462
Value Function Loss: 0.01514

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.54744

Collected Steps per Second: 22,129.56923
Overall Steps per Second: 10,638.68963

Timestep Collection Time: 2.25978
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.70058

Cumulative Model Updates: 201,602
Cumulative Timesteps: 1,681,376,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.76429
Policy Entropy: 2.22045
Value Function Loss: 0.01545

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.57335

Collected Steps per Second: 22,215.14794
Overall Steps per Second: 10,450.51512

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.53445
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.78579

Cumulative Model Updates: 201,608
Cumulative Timesteps: 1,681,426,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1681426568...
Checkpoint 1681426568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.90630
Policy Entropy: 2.23436
Value Function Loss: 0.01424

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 22,281.67924
Overall Steps per Second: 10,562.28519

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.49043
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.73496

Cumulative Model Updates: 201,614
Cumulative Timesteps: 1,681,476,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.26924
Policy Entropy: 2.22049
Value Function Loss: 0.01594

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.55796

Collected Steps per Second: 22,327.25754
Overall Steps per Second: 10,555.74212

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.49864
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.73922

Cumulative Model Updates: 201,620
Cumulative Timesteps: 1,681,526,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1681526606...
Checkpoint 1681526606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.06676
Policy Entropy: 2.23875
Value Function Loss: 0.01585

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.55611

Collected Steps per Second: 22,388.34535
Overall Steps per Second: 10,588.87506

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.72288

Cumulative Model Updates: 201,626
Cumulative Timesteps: 1,681,576,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.81186
Policy Entropy: 2.21750
Value Function Loss: 0.01531

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.52587
Value Function Update Magnitude: 0.56320

Collected Steps per Second: 22,159.88204
Overall Steps per Second: 10,572.35606

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.72931

Cumulative Model Updates: 201,632
Cumulative Timesteps: 1,681,626,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1681626616...
Checkpoint 1681626616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.04776
Policy Entropy: 2.22613
Value Function Loss: 0.01431

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.52153
Value Function Update Magnitude: 0.55474

Collected Steps per Second: 22,248.00188
Overall Steps per Second: 10,585.94237

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.72476

Cumulative Model Updates: 201,638
Cumulative Timesteps: 1,681,676,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.74547
Policy Entropy: 2.19131
Value Function Loss: 0.01511

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.53400
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 22,013.45794
Overall Steps per Second: 10,386.23411

Timestep Collection Time: 2.27161
Timestep Consumption Time: 2.54303
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.81464

Cumulative Model Updates: 201,644
Cumulative Timesteps: 1,681,726,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1681726638...
Checkpoint 1681726638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.23446
Policy Entropy: 2.22101
Value Function Loss: 0.01549

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.56734

Collected Steps per Second: 22,167.50439
Overall Steps per Second: 10,570.51235

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.73052

Cumulative Model Updates: 201,650
Cumulative Timesteps: 1,681,776,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.27332
Policy Entropy: 2.21204
Value Function Loss: 0.01571

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.56271

Collected Steps per Second: 22,378.54008
Overall Steps per Second: 10,613.56802

Timestep Collection Time: 2.23545
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.71340

Cumulative Model Updates: 201,656
Cumulative Timesteps: 1,681,826,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1681826668...
Checkpoint 1681826668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.24245
Policy Entropy: 2.25486
Value Function Loss: 0.01560

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.55645

Collected Steps per Second: 22,490.86309
Overall Steps per Second: 10,604.73250

Timestep Collection Time: 2.22348
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.71563

Cumulative Model Updates: 201,662
Cumulative Timesteps: 1,681,876,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.66975
Policy Entropy: 2.23876
Value Function Loss: 0.01570

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.55356

Collected Steps per Second: 22,229.35632
Overall Steps per Second: 10,416.37756

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.55228
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.80282

Cumulative Model Updates: 201,668
Cumulative Timesteps: 1,681,926,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1681926704...
Checkpoint 1681926704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.54942
Policy Entropy: 2.24667
Value Function Loss: 0.01552

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.52143
Value Function Update Magnitude: 0.53517

Collected Steps per Second: 22,348.64094
Overall Steps per Second: 10,620.41152

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.47183
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.71018

Cumulative Model Updates: 201,674
Cumulative Timesteps: 1,681,976,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.35341
Policy Entropy: 2.21594
Value Function Loss: 0.01590

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.53256

Collected Steps per Second: 22,526.41961
Overall Steps per Second: 10,729.59509

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.66169

Cumulative Model Updates: 201,680
Cumulative Timesteps: 1,682,026,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1682026746...
Checkpoint 1682026746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.55196
Policy Entropy: 2.23322
Value Function Loss: 0.01579

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.53150
Value Function Update Magnitude: 0.54602

Collected Steps per Second: 22,449.77312
Overall Steps per Second: 10,487.16686

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.54054
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.76773

Cumulative Model Updates: 201,686
Cumulative Timesteps: 1,682,076,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.64979
Policy Entropy: 2.21930
Value Function Loss: 0.01664

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.57382

Collected Steps per Second: 22,300.40522
Overall Steps per Second: 10,362.53864

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.58379
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.82662

Cumulative Model Updates: 201,692
Cumulative Timesteps: 1,682,126,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1682126762...
Checkpoint 1682126762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.67556
Policy Entropy: 2.25816
Value Function Loss: 0.01606

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.52381
Value Function Update Magnitude: 0.58050

Collected Steps per Second: 22,210.82257
Overall Steps per Second: 10,596.09138

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.71910

Cumulative Model Updates: 201,698
Cumulative Timesteps: 1,682,176,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.56270
Policy Entropy: 2.24611
Value Function Loss: 0.01665

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.58642

Collected Steps per Second: 22,228.25997
Overall Steps per Second: 10,520.07468

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.50443
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75472

Cumulative Model Updates: 201,704
Cumulative Timesteps: 1,682,226,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1682226786...
Checkpoint 1682226786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.26666
Policy Entropy: 2.24257
Value Function Loss: 0.01704

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.55318
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 22,441.35881
Overall Steps per Second: 10,633.43225

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.70234

Cumulative Model Updates: 201,710
Cumulative Timesteps: 1,682,276,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.91842
Policy Entropy: 2.22375
Value Function Loss: 0.01717

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.58450

Collected Steps per Second: 22,391.56331
Overall Steps per Second: 10,436.29654

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.55860
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.79212

Cumulative Model Updates: 201,716
Cumulative Timesteps: 1,682,326,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1682326800...
Checkpoint 1682326800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.40260
Policy Entropy: 2.21754
Value Function Loss: 0.01632

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.59228

Collected Steps per Second: 22,158.17251
Overall Steps per Second: 10,514.02933

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.49975
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.75688

Cumulative Model Updates: 201,722
Cumulative Timesteps: 1,682,376,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.46332
Policy Entropy: 2.24298
Value Function Loss: 0.01485

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.58311

Collected Steps per Second: 22,371.09052
Overall Steps per Second: 10,617.25357

Timestep Collection Time: 2.23601
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.71139

Cumulative Model Updates: 201,728
Cumulative Timesteps: 1,682,426,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1682426836...
Checkpoint 1682426836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.52166
Policy Entropy: 2.24768
Value Function Loss: 0.01554

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.57015

Collected Steps per Second: 22,408.92394
Overall Steps per Second: 10,625.14806

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.70826

Cumulative Model Updates: 201,734
Cumulative Timesteps: 1,682,476,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.47866
Policy Entropy: 2.25099
Value Function Loss: 0.01595

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.58005

Collected Steps per Second: 22,231.75086
Overall Steps per Second: 10,547.68477

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.74057

Cumulative Model Updates: 201,740
Cumulative Timesteps: 1,682,526,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1682526864...
Checkpoint 1682526864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.28727
Policy Entropy: 2.20310
Value Function Loss: 0.01558

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 22,266.35762
Overall Steps per Second: 10,556.78458

Timestep Collection Time: 2.24617
Timestep Consumption Time: 2.49145
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.73762

Cumulative Model Updates: 201,746
Cumulative Timesteps: 1,682,576,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.42302
Policy Entropy: 2.21287
Value Function Loss: 0.01509

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.60168

Collected Steps per Second: 22,572.28437
Overall Steps per Second: 10,441.84786

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.57363
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.78900

Cumulative Model Updates: 201,752
Cumulative Timesteps: 1,682,626,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1682626884...
Checkpoint 1682626884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.80163
Policy Entropy: 2.20291
Value Function Loss: 0.01574

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.60248

Collected Steps per Second: 22,300.48628
Overall Steps per Second: 10,648.24258

Timestep Collection Time: 2.24309
Timestep Consumption Time: 2.45459
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.69768

Cumulative Model Updates: 201,758
Cumulative Timesteps: 1,682,676,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.57308
Policy Entropy: 2.22823
Value Function Loss: 0.01701

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.62061

Collected Steps per Second: 22,175.41268
Overall Steps per Second: 10,564.20354

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.73429

Cumulative Model Updates: 201,764
Cumulative Timesteps: 1,682,726,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1682726920...
Checkpoint 1682726920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.10281
Policy Entropy: 2.20936
Value Function Loss: 0.01739

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.63040

Collected Steps per Second: 22,404.77032
Overall Steps per Second: 10,528.66611

Timestep Collection Time: 2.23220
Timestep Consumption Time: 2.51788
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.75008

Cumulative Model Updates: 201,770
Cumulative Timesteps: 1,682,776,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.42866
Policy Entropy: 2.21769
Value Function Loss: 0.01738

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.64495

Collected Steps per Second: 22,480.29973
Overall Steps per Second: 10,476.58709

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.54878
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77331

Cumulative Model Updates: 201,776
Cumulative Timesteps: 1,682,826,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1682826940...
Checkpoint 1682826940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.45029
Policy Entropy: 2.20388
Value Function Loss: 0.01719

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.64576

Collected Steps per Second: 21,970.18986
Overall Steps per Second: 10,540.57778

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.74585

Cumulative Model Updates: 201,782
Cumulative Timesteps: 1,682,876,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.48599
Policy Entropy: 2.19037
Value Function Loss: 0.01720

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.63825

Collected Steps per Second: 22,118.50891
Overall Steps per Second: 10,557.04365

Timestep Collection Time: 2.26091
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.73693

Cumulative Model Updates: 201,788
Cumulative Timesteps: 1,682,926,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1682926972...
Checkpoint 1682926972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.06733
Policy Entropy: 2.19872
Value Function Loss: 0.01659

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.62491

Collected Steps per Second: 22,735.70632
Overall Steps per Second: 10,602.34071

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.71669

Cumulative Model Updates: 201,794
Cumulative Timesteps: 1,682,976,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.14448
Policy Entropy: 2.22000
Value Function Loss: 0.01590

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.53026
Value Function Update Magnitude: 0.59149

Collected Steps per Second: 22,389.76631
Overall Steps per Second: 10,470.49700

Timestep Collection Time: 2.23450
Timestep Consumption Time: 2.54368
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.77819

Cumulative Model Updates: 201,800
Cumulative Timesteps: 1,683,027,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1683027010...
Checkpoint 1683027010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.17378
Policy Entropy: 2.21564
Value Function Loss: 0.01504

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.53938
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 22,190.70305
Overall Steps per Second: 10,535.08781

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.74775

Cumulative Model Updates: 201,806
Cumulative Timesteps: 1,683,077,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.88493
Policy Entropy: 2.23852
Value Function Loss: 0.01513

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.56088

Collected Steps per Second: 22,235.92076
Overall Steps per Second: 10,556.77321

Timestep Collection Time: 2.24906
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.73724

Cumulative Model Updates: 201,812
Cumulative Timesteps: 1,683,127,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1683127038...
Checkpoint 1683127038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.67193
Policy Entropy: 2.23675
Value Function Loss: 0.01564

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 21,876.62157
Overall Steps per Second: 10,633.53027

Timestep Collection Time: 2.28655
Timestep Consumption Time: 2.41763
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.70418

Cumulative Model Updates: 201,818
Cumulative Timesteps: 1,683,177,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.14357
Policy Entropy: 2.23204
Value Function Loss: 0.01579

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.58223

Collected Steps per Second: 22,560.13091
Overall Steps per Second: 10,472.24629

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.55843
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.77491

Cumulative Model Updates: 201,824
Cumulative Timesteps: 1,683,227,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1683227064...
Checkpoint 1683227064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.43641
Policy Entropy: 2.21646
Value Function Loss: 0.01664

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.60724

Collected Steps per Second: 22,232.76171
Overall Steps per Second: 10,575.80158

Timestep Collection Time: 2.25037
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.73080

Cumulative Model Updates: 201,830
Cumulative Timesteps: 1,683,277,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.08484
Policy Entropy: 2.21059
Value Function Loss: 0.01714

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.64715

Collected Steps per Second: 22,492.38845
Overall Steps per Second: 10,511.05344

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.53534
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.75956

Cumulative Model Updates: 201,836
Cumulative Timesteps: 1,683,327,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1683327124...
Checkpoint 1683327124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27361
Policy Entropy: 2.21965
Value Function Loss: 0.01678

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.56252
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 22,227.10825
Overall Steps per Second: 10,643.23467

Timestep Collection Time: 2.24996
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69876

Cumulative Model Updates: 201,842
Cumulative Timesteps: 1,683,377,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.94562
Policy Entropy: 2.20438
Value Function Loss: 0.01636

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.66738

Collected Steps per Second: 21,942.63682
Overall Steps per Second: 10,495.12067

Timestep Collection Time: 2.27903
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.76488

Cumulative Model Updates: 201,848
Cumulative Timesteps: 1,683,427,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1683427142...
Checkpoint 1683427142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.35840
Policy Entropy: 2.17250
Value Function Loss: 0.01634

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.65547

Collected Steps per Second: 22,111.31532
Overall Steps per Second: 10,517.88012

Timestep Collection Time: 2.26138
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.75400

Cumulative Model Updates: 201,854
Cumulative Timesteps: 1,683,477,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.12976
Policy Entropy: 2.18182
Value Function Loss: 0.01669

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 21,813.12994
Overall Steps per Second: 10,429.69697

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.79419

Cumulative Model Updates: 201,860
Cumulative Timesteps: 1,683,527,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1683527146...
Checkpoint 1683527146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.80741
Policy Entropy: 2.19422
Value Function Loss: 0.01577

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.55929
Value Function Update Magnitude: 0.64207

Collected Steps per Second: 22,244.92142
Overall Steps per Second: 10,514.17384

Timestep Collection Time: 2.24824
Timestep Consumption Time: 2.50838
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.75663

Cumulative Model Updates: 201,866
Cumulative Timesteps: 1,683,577,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.52777
Policy Entropy: 2.23170
Value Function Loss: 0.01557

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.60674

Collected Steps per Second: 22,477.63817
Overall Steps per Second: 10,722.58351

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66548

Cumulative Model Updates: 201,872
Cumulative Timesteps: 1,683,627,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1683627184...
Checkpoint 1683627184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.17045
Policy Entropy: 2.22913
Value Function Loss: 0.01543

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.59265

Collected Steps per Second: 22,155.82407
Overall Steps per Second: 10,516.12438

Timestep Collection Time: 2.25692
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.75498

Cumulative Model Updates: 201,878
Cumulative Timesteps: 1,683,677,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.37517
Policy Entropy: 2.19483
Value Function Loss: 0.01637

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.58391

Collected Steps per Second: 22,556.36589
Overall Steps per Second: 10,551.47475

Timestep Collection Time: 2.21782
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.74114

Cumulative Model Updates: 201,884
Cumulative Timesteps: 1,683,727,214

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1683727214...
Checkpoint 1683727214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.78891
Policy Entropy: 2.22295
Value Function Loss: 0.01596

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.58768

Collected Steps per Second: 22,268.28939
Overall Steps per Second: 10,564.82063

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.73477

Cumulative Model Updates: 201,890
Cumulative Timesteps: 1,683,777,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.85075
Policy Entropy: 2.20695
Value Function Loss: 0.01593

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.57694

Collected Steps per Second: 22,353.49286
Overall Steps per Second: 10,533.79602

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.74796

Cumulative Model Updates: 201,896
Cumulative Timesteps: 1,683,827,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1683827250...
Checkpoint 1683827250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.03390
Policy Entropy: 2.23303
Value Function Loss: 0.01534

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 22,273.62686
Overall Steps per Second: 10,650.63332

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.69681

Cumulative Model Updates: 201,902
Cumulative Timesteps: 1,683,877,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.40240
Policy Entropy: 2.20187
Value Function Loss: 0.01611

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.60142

Collected Steps per Second: 22,659.07825
Overall Steps per Second: 10,489.64575

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.56142
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.76927

Cumulative Model Updates: 201,908
Cumulative Timesteps: 1,683,927,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1683927302...
Checkpoint 1683927302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.82245
Policy Entropy: 2.19768
Value Function Loss: 0.01538

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 22,090.55866
Overall Steps per Second: 10,515.95295

Timestep Collection Time: 2.26368
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.75525

Cumulative Model Updates: 201,914
Cumulative Timesteps: 1,683,977,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.40533
Policy Entropy: 2.16599
Value Function Loss: 0.01590

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.62053

Collected Steps per Second: 22,751.25988
Overall Steps per Second: 10,579.71152

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.72886

Cumulative Model Updates: 201,920
Cumulative Timesteps: 1,684,027,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1684027338...
Checkpoint 1684027338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.44559
Policy Entropy: 2.16738
Value Function Loss: 0.01542

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.59513

Collected Steps per Second: 22,441.32067
Overall Steps per Second: 10,636.48820

Timestep Collection Time: 2.22901
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.70287

Cumulative Model Updates: 201,926
Cumulative Timesteps: 1,684,077,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.70229
Policy Entropy: 2.18307
Value Function Loss: 0.01522

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 22,744.24103
Overall Steps per Second: 10,528.93609

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.74996

Cumulative Model Updates: 201,932
Cumulative Timesteps: 1,684,127,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1684127372...
Checkpoint 1684127372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.97469
Policy Entropy: 2.18593
Value Function Loss: 0.01532

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 22,454.47953
Overall Steps per Second: 10,544.44900

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.74297

Cumulative Model Updates: 201,938
Cumulative Timesteps: 1,684,177,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.10302
Policy Entropy: 2.17522
Value Function Loss: 0.01440

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 22,435.71308
Overall Steps per Second: 10,450.89829

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.55794
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.78849

Cumulative Model Updates: 201,944
Cumulative Timesteps: 1,684,227,428

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1684227428...
Checkpoint 1684227428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.37316
Policy Entropy: 2.17272
Value Function Loss: 0.01464

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.57887

Collected Steps per Second: 22,058.19462
Overall Steps per Second: 10,559.91617

Timestep Collection Time: 2.26818
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.73792

Cumulative Model Updates: 201,950
Cumulative Timesteps: 1,684,277,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.89376
Policy Entropy: 2.18761
Value Function Loss: 0.01492

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.55428

Collected Steps per Second: 23,229.44765
Overall Steps per Second: 10,651.69210

Timestep Collection Time: 2.15356
Timestep Consumption Time: 2.54297
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.69653

Cumulative Model Updates: 201,956
Cumulative Timesteps: 1,684,327,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1684327486...
Checkpoint 1684327486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.11762
Policy Entropy: 2.18609
Value Function Loss: 0.01560

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.53892
Value Function Update Magnitude: 0.56411

Collected Steps per Second: 22,413.76614
Overall Steps per Second: 10,524.98575

Timestep Collection Time: 2.23131
Timestep Consumption Time: 2.52043
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.75174

Cumulative Model Updates: 201,962
Cumulative Timesteps: 1,684,377,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.73919
Policy Entropy: 2.21110
Value Function Loss: 0.01563

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.56012

Collected Steps per Second: 20,701.30235
Overall Steps per Second: 10,003.79852

Timestep Collection Time: 2.41627
Timestep Consumption Time: 2.58383
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 5.00010

Cumulative Model Updates: 201,968
Cumulative Timesteps: 1,684,427,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1684427518...
Checkpoint 1684427518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.41368
Policy Entropy: 2.20854
Value Function Loss: 0.01560

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.54301
Value Function Update Magnitude: 0.57136

Collected Steps per Second: 20,558.93669
Overall Steps per Second: 10,154.93536

Timestep Collection Time: 2.43252
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.92470

Cumulative Model Updates: 201,974
Cumulative Timesteps: 1,684,477,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.28375
Policy Entropy: 2.22387
Value Function Loss: 0.01582

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.59711

Collected Steps per Second: 22,130.54945
Overall Steps per Second: 10,600.57505

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.45819
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.71823

Cumulative Model Updates: 201,980
Cumulative Timesteps: 1,684,527,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1684527544...
Checkpoint 1684527544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.64897
Policy Entropy: 2.21878
Value Function Loss: 0.01520

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.54213
Value Function Update Magnitude: 0.59516

Collected Steps per Second: 22,075.85915
Overall Steps per Second: 10,525.63472

Timestep Collection Time: 2.26528
Timestep Consumption Time: 2.48579
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.75107

Cumulative Model Updates: 201,986
Cumulative Timesteps: 1,684,577,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.86954
Policy Entropy: 2.21631
Value Function Loss: 0.01526

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.52719
Value Function Update Magnitude: 0.58875

Collected Steps per Second: 22,238.30867
Overall Steps per Second: 10,505.56338

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.76033

Cumulative Model Updates: 201,992
Cumulative Timesteps: 1,684,627,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1684627562...
Checkpoint 1684627562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.11792
Policy Entropy: 2.23122
Value Function Loss: 0.01566

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.52011
Value Function Update Magnitude: 0.58651

Collected Steps per Second: 21,970.18898
Overall Steps per Second: 10,365.54583

Timestep Collection Time: 2.27608
Timestep Consumption Time: 2.54817
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.82425

Cumulative Model Updates: 201,998
Cumulative Timesteps: 1,684,677,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.54359
Policy Entropy: 2.22663
Value Function Loss: 0.01535

Mean KL Divergence: 0.03518
SB3 Clip Fraction: 0.20306
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.59464

Collected Steps per Second: 22,512.16006
Overall Steps per Second: 10,654.95592

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.69322

Cumulative Model Updates: 202,004
Cumulative Timesteps: 1,684,727,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1684727574...
Checkpoint 1684727574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.40321
Policy Entropy: 2.22432
Value Function Loss: 0.01519

Mean KL Divergence: 0.03390
SB3 Clip Fraction: 0.20623
Policy Update Magnitude: 0.51798
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 21,864.58721
Overall Steps per Second: 10,670.70423

Timestep Collection Time: 2.28790
Timestep Consumption Time: 2.40008
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.68798

Cumulative Model Updates: 202,010
Cumulative Timesteps: 1,684,777,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.92967
Policy Entropy: 2.21963
Value Function Loss: 0.01474

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.17908
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.57759

Collected Steps per Second: 22,706.94213
Overall Steps per Second: 10,564.12794

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.53133
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.73357

Cumulative Model Updates: 202,016
Cumulative Timesteps: 1,684,827,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1684827604...
Checkpoint 1684827604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.47706
Policy Entropy: 2.21833
Value Function Loss: 0.01482

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.17204
Policy Update Magnitude: 0.52023
Value Function Update Magnitude: 0.55112

Collected Steps per Second: 21,819.87568
Overall Steps per Second: 10,362.05017

Timestep Collection Time: 2.29277
Timestep Consumption Time: 2.53523
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.82800

Cumulative Model Updates: 202,022
Cumulative Timesteps: 1,684,877,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.41639
Policy Entropy: 2.23871
Value Function Loss: 0.01518

Mean KL Divergence: 0.02333
SB3 Clip Fraction: 0.16488
Policy Update Magnitude: 0.50477
Value Function Update Magnitude: 0.53792

Collected Steps per Second: 22,478.71601
Overall Steps per Second: 10,613.61959

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.71187

Cumulative Model Updates: 202,028
Cumulative Timesteps: 1,684,927,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1684927642...
Checkpoint 1684927642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.62626
Policy Entropy: 2.23972
Value Function Loss: 0.01565

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.17898
Policy Update Magnitude: 0.48955
Value Function Update Magnitude: 0.53831

Collected Steps per Second: 22,243.73167
Overall Steps per Second: 10,776.20368

Timestep Collection Time: 2.24800
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.64022

Cumulative Model Updates: 202,034
Cumulative Timesteps: 1,684,977,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.69851
Policy Entropy: 2.21521
Value Function Loss: 0.01554

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.55620

Collected Steps per Second: 22,479.62851
Overall Steps per Second: 10,433.94910

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.56864
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.79358

Cumulative Model Updates: 202,040
Cumulative Timesteps: 1,685,027,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1685027662...
Checkpoint 1685027662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.32421
Policy Entropy: 2.22650
Value Function Loss: 0.01600

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.57903

Collected Steps per Second: 22,349.83687
Overall Steps per Second: 10,608.49409

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.47744
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.71584

Cumulative Model Updates: 202,046
Cumulative Timesteps: 1,685,077,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.17754
Policy Entropy: 2.21943
Value Function Loss: 0.01525

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.54908
Value Function Update Magnitude: 0.59916

Collected Steps per Second: 21,952.68463
Overall Steps per Second: 10,432.43894

Timestep Collection Time: 2.27835
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.79428

Cumulative Model Updates: 202,052
Cumulative Timesteps: 1,685,127,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1685127706...
Checkpoint 1685127706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.54073
Policy Entropy: 2.23376
Value Function Loss: 0.01433

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.54139
Value Function Update Magnitude: 0.59904

Collected Steps per Second: 22,209.00075
Overall Steps per Second: 10,600.90533

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.71809

Cumulative Model Updates: 202,058
Cumulative Timesteps: 1,685,177,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.57190
Policy Entropy: 2.23966
Value Function Loss: 0.01369

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.52438
Value Function Update Magnitude: 0.56849

Collected Steps per Second: 22,424.83745
Overall Steps per Second: 10,603.96639

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.71616

Cumulative Model Updates: 202,064
Cumulative Timesteps: 1,685,227,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1685227732...
Checkpoint 1685227732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.82064
Policy Entropy: 2.24965
Value Function Loss: 0.01427

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.52155
Value Function Update Magnitude: 0.56822

Collected Steps per Second: 22,202.46006
Overall Steps per Second: 10,555.31468

Timestep Collection Time: 2.25200
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.73695

Cumulative Model Updates: 202,070
Cumulative Timesteps: 1,685,277,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.29749
Policy Entropy: 2.25713
Value Function Loss: 0.01457

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.52493
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 22,589.33899
Overall Steps per Second: 10,465.92487

Timestep Collection Time: 2.21458
Timestep Consumption Time: 2.56531
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.77989

Cumulative Model Updates: 202,076
Cumulative Timesteps: 1,685,327,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1685327758...
Checkpoint 1685327758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.33398
Policy Entropy: 2.24435
Value Function Loss: 0.01592

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 22,396.74754
Overall Steps per Second: 10,686.39250

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.68016

Cumulative Model Updates: 202,082
Cumulative Timesteps: 1,685,377,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.76505
Policy Entropy: 2.25334
Value Function Loss: 0.01631

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.54573
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 22,338.36085
Overall Steps per Second: 10,431.26326

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.55498
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.79328

Cumulative Model Updates: 202,088
Cumulative Timesteps: 1,685,427,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1685427772...
Checkpoint 1685427772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.85144
Policy Entropy: 2.25131
Value Function Loss: 0.01611

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.63122

Collected Steps per Second: 23,158.44624
Overall Steps per Second: 10,633.80836

Timestep Collection Time: 2.15947
Timestep Consumption Time: 2.54345
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.70292

Cumulative Model Updates: 202,094
Cumulative Timesteps: 1,685,477,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.61731
Policy Entropy: 2.27322
Value Function Loss: 0.01513

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 22,442.69046
Overall Steps per Second: 10,443.70660

Timestep Collection Time: 2.22914
Timestep Consumption Time: 2.56111
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.79025

Cumulative Model Updates: 202,100
Cumulative Timesteps: 1,685,527,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1685527810...
Checkpoint 1685527810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.08469
Policy Entropy: 2.27943
Value Function Loss: 0.01549

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.60339

Collected Steps per Second: 22,013.03411
Overall Steps per Second: 10,401.89119

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.53696
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.80970

Cumulative Model Updates: 202,106
Cumulative Timesteps: 1,685,577,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.91714
Policy Entropy: 2.29717
Value Function Loss: 0.01469

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.52174
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,436.32388
Overall Steps per Second: 10,661.62780

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.46197
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.69122

Cumulative Model Updates: 202,112
Cumulative Timesteps: 1,685,627,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1685627856...
Checkpoint 1685627856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.21698
Policy Entropy: 2.28132
Value Function Loss: 0.01518

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.51923
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 22,314.59853
Overall Steps per Second: 10,715.37779

Timestep Collection Time: 2.24095
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66675

Cumulative Model Updates: 202,118
Cumulative Timesteps: 1,685,677,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.56264
Policy Entropy: 2.25575
Value Function Loss: 0.01544

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.58268

Collected Steps per Second: 22,333.76251
Overall Steps per Second: 10,424.70923

Timestep Collection Time: 2.23903
Timestep Consumption Time: 2.55784
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.79687

Cumulative Model Updates: 202,124
Cumulative Timesteps: 1,685,727,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1685727868...
Checkpoint 1685727868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.66187
Policy Entropy: 2.25451
Value Function Loss: 0.01584

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.58630

Collected Steps per Second: 22,371.89002
Overall Steps per Second: 10,566.50173

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73326

Cumulative Model Updates: 202,130
Cumulative Timesteps: 1,685,777,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.57553
Policy Entropy: 2.23237
Value Function Loss: 0.01629

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 22,308.53609
Overall Steps per Second: 10,504.06204

Timestep Collection Time: 2.24210
Timestep Consumption Time: 2.51968
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.76178

Cumulative Model Updates: 202,136
Cumulative Timesteps: 1,685,827,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1685827900...
Checkpoint 1685827900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.64661
Policy Entropy: 2.24993
Value Function Loss: 0.01588

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.58497

Collected Steps per Second: 22,138.50071
Overall Steps per Second: 10,558.41297

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.73575

Cumulative Model Updates: 202,142
Cumulative Timesteps: 1,685,877,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.16847
Policy Entropy: 2.23540
Value Function Loss: 0.01635

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.57720

Collected Steps per Second: 22,502.63895
Overall Steps per Second: 10,603.76844

Timestep Collection Time: 2.22285
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.71719

Cumulative Model Updates: 202,148
Cumulative Timesteps: 1,685,927,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1685927922...
Checkpoint 1685927922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.10734
Policy Entropy: 2.27015
Value Function Loss: 0.01553

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.56557

Collected Steps per Second: 22,418.94008
Overall Steps per Second: 10,588.66989

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.72411

Cumulative Model Updates: 202,154
Cumulative Timesteps: 1,685,977,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.00303
Policy Entropy: 2.26087
Value Function Loss: 0.01594

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.54092
Value Function Update Magnitude: 0.56061

Collected Steps per Second: 22,484.95429
Overall Steps per Second: 10,469.71961

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.55278
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.77721

Cumulative Model Updates: 202,160
Cumulative Timesteps: 1,686,027,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1686027960...
Checkpoint 1686027960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.02507
Policy Entropy: 2.27949
Value Function Loss: 0.01476

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,352.38498
Overall Steps per Second: 10,655.72728

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.69438

Cumulative Model Updates: 202,166
Cumulative Timesteps: 1,686,077,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.12837
Policy Entropy: 2.25492
Value Function Loss: 0.01493

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.54258

Collected Steps per Second: 22,662.82535
Overall Steps per Second: 10,801.61542

Timestep Collection Time: 2.20740
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.63134

Cumulative Model Updates: 202,172
Cumulative Timesteps: 1,686,128,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1686128008...
Checkpoint 1686128008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.12872
Policy Entropy: 2.26502
Value Function Loss: 0.01513

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.52839
Value Function Update Magnitude: 0.53966

Collected Steps per Second: 22,404.10750
Overall Steps per Second: 10,508.83609

Timestep Collection Time: 2.23209
Timestep Consumption Time: 2.52657
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75866

Cumulative Model Updates: 202,178
Cumulative Timesteps: 1,686,178,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.83925
Policy Entropy: 2.25698
Value Function Loss: 0.01497

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.52013
Value Function Update Magnitude: 0.54439

Collected Steps per Second: 22,375.46066
Overall Steps per Second: 10,587.36525

Timestep Collection Time: 2.23495
Timestep Consumption Time: 2.48842
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.72337

Cumulative Model Updates: 202,184
Cumulative Timesteps: 1,686,228,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1686228024...
Checkpoint 1686228024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.38737
Policy Entropy: 2.24216
Value Function Loss: 0.01631

Mean KL Divergence: 0.02885
SB3 Clip Fraction: 0.18195
Policy Update Magnitude: 0.51758
Value Function Update Magnitude: 0.54359

Collected Steps per Second: 22,198.77829
Overall Steps per Second: 10,456.80459

Timestep Collection Time: 2.25247
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.78177

Cumulative Model Updates: 202,190
Cumulative Timesteps: 1,686,278,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.37379
Policy Entropy: 2.21447
Value Function Loss: 0.01657

Mean KL Divergence: 0.02624
SB3 Clip Fraction: 0.17359
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.57181

Collected Steps per Second: 22,641.56377
Overall Steps per Second: 10,686.15232

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.67933

Cumulative Model Updates: 202,196
Cumulative Timesteps: 1,686,328,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1686328030...
Checkpoint 1686328030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.81339
Policy Entropy: 2.20080
Value Function Loss: 0.01681

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.17408
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 22,392.50155
Overall Steps per Second: 10,688.84738

Timestep Collection Time: 2.23334
Timestep Consumption Time: 2.44537
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67871

Cumulative Model Updates: 202,202
Cumulative Timesteps: 1,686,378,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.01916
Policy Entropy: 2.20811
Value Function Loss: 0.01671

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.56423

Collected Steps per Second: 22,319.65581
Overall Steps per Second: 10,468.44272

Timestep Collection Time: 2.24125
Timestep Consumption Time: 2.53730
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.77855

Cumulative Model Updates: 202,208
Cumulative Timesteps: 1,686,428,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1686428064...
Checkpoint 1686428064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.90361
Policy Entropy: 2.20290
Value Function Loss: 0.01575

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.57548

Collected Steps per Second: 22,102.07146
Overall Steps per Second: 10,531.22246

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.48645
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.74950

Cumulative Model Updates: 202,214
Cumulative Timesteps: 1,686,478,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.29542
Policy Entropy: 2.22035
Value Function Loss: 0.01522

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 22,343.45342
Overall Steps per Second: 10,554.69758

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.73817

Cumulative Model Updates: 202,220
Cumulative Timesteps: 1,686,528,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1686528092...
Checkpoint 1686528092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.78283
Policy Entropy: 2.23115
Value Function Loss: 0.01606

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 22,264.71373
Overall Steps per Second: 10,635.21635

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.45654
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70305

Cumulative Model Updates: 202,226
Cumulative Timesteps: 1,686,578,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.38358
Policy Entropy: 2.22397
Value Function Loss: 0.01602

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.58259

Collected Steps per Second: 22,003.04355
Overall Steps per Second: 10,432.74962

Timestep Collection Time: 2.27241
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.79260

Cumulative Model Updates: 202,232
Cumulative Timesteps: 1,686,628,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1686628110...
Checkpoint 1686628110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.61105
Policy Entropy: 2.21238
Value Function Loss: 0.01695

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.58283

Collected Steps per Second: 22,167.18679
Overall Steps per Second: 10,447.47774

Timestep Collection Time: 2.25685
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.78852

Cumulative Model Updates: 202,238
Cumulative Timesteps: 1,686,678,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.11786
Policy Entropy: 2.21071
Value Function Loss: 0.01511

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.59145

Collected Steps per Second: 22,575.71338
Overall Steps per Second: 10,638.32593

Timestep Collection Time: 2.21512
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.70074

Cumulative Model Updates: 202,244
Cumulative Timesteps: 1,686,728,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1686728146...
Checkpoint 1686728146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.46886
Policy Entropy: 2.23583
Value Function Loss: 0.01493

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.58051

Collected Steps per Second: 22,269.16623
Overall Steps per Second: 10,606.27978

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.46952
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.71532

Cumulative Model Updates: 202,250
Cumulative Timesteps: 1,686,778,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.21385
Policy Entropy: 2.24280
Value Function Loss: 0.01514

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,089.77955
Overall Steps per Second: 10,535.49668

Timestep Collection Time: 2.26367
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.74624

Cumulative Model Updates: 202,256
Cumulative Timesteps: 1,686,828,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1686828162...
Checkpoint 1686828162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.49129
Policy Entropy: 2.25615
Value Function Loss: 0.01569

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.52500
Value Function Update Magnitude: 0.57333

Collected Steps per Second: 22,362.72792
Overall Steps per Second: 10,597.73873

Timestep Collection Time: 2.23720
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.72082

Cumulative Model Updates: 202,262
Cumulative Timesteps: 1,686,878,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.91775
Policy Entropy: 2.25762
Value Function Loss: 0.01610

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.17542
Policy Update Magnitude: 0.48698
Value Function Update Magnitude: 0.56953

Collected Steps per Second: 22,429.35326
Overall Steps per Second: 10,475.98379

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.54411
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.77378

Cumulative Model Updates: 202,268
Cumulative Timesteps: 1,686,928,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1686928202...
Checkpoint 1686928202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.96636
Policy Entropy: 2.26294
Value Function Loss: 0.01494

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.49882
Value Function Update Magnitude: 0.56817

Collected Steps per Second: 22,516.18224
Overall Steps per Second: 10,658.07030

Timestep Collection Time: 2.22089
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.69184

Cumulative Model Updates: 202,274
Cumulative Timesteps: 1,686,978,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.06115
Policy Entropy: 2.26517
Value Function Loss: 0.01548

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.57094

Collected Steps per Second: 22,111.46112
Overall Steps per Second: 10,597.42625

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.72096

Cumulative Model Updates: 202,280
Cumulative Timesteps: 1,687,028,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1687028238...
Checkpoint 1687028238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.38834
Policy Entropy: 2.27680
Value Function Loss: 0.01538

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.58461

Collected Steps per Second: 22,640.68336
Overall Steps per Second: 10,512.72133

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.54854
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.75766

Cumulative Model Updates: 202,286
Cumulative Timesteps: 1,687,078,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.31678
Policy Entropy: 2.29124
Value Function Loss: 0.01501

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 22,501.28437
Overall Steps per Second: 10,444.74785

Timestep Collection Time: 2.22307
Timestep Consumption Time: 2.56613
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.78920

Cumulative Model Updates: 202,292
Cumulative Timesteps: 1,687,128,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1687128276...
Checkpoint 1687128276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.03252
Policy Entropy: 2.29663
Value Function Loss: 0.01494

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.52545
Value Function Update Magnitude: 0.55330

Collected Steps per Second: 22,307.61732
Overall Steps per Second: 10,604.60270

Timestep Collection Time: 2.24228
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.71682

Cumulative Model Updates: 202,298
Cumulative Timesteps: 1,687,178,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.60612
Policy Entropy: 2.27311
Value Function Loss: 0.01608

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.55758

Collected Steps per Second: 21,780.09979
Overall Steps per Second: 10,516.25412

Timestep Collection Time: 2.29705
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.75740

Cumulative Model Updates: 202,304
Cumulative Timesteps: 1,687,228,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1687228326...
Checkpoint 1687228326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.48105
Policy Entropy: 2.26620
Value Function Loss: 0.01602

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.55307
Value Function Update Magnitude: 0.58490

Collected Steps per Second: 22,488.74989
Overall Steps per Second: 10,656.07728

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.69441

Cumulative Model Updates: 202,310
Cumulative Timesteps: 1,687,278,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.71806
Policy Entropy: 2.23551
Value Function Loss: 0.01563

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.57596

Collected Steps per Second: 22,551.50166
Overall Steps per Second: 10,442.93781

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.79003

Cumulative Model Updates: 202,316
Cumulative Timesteps: 1,687,328,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1687328372...
Checkpoint 1687328372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.75100
Policy Entropy: 2.22984
Value Function Loss: 0.01519

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.56479

Collected Steps per Second: 22,411.47548
Overall Steps per Second: 10,583.29746

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.72575

Cumulative Model Updates: 202,322
Cumulative Timesteps: 1,687,378,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.48370
Policy Entropy: 2.21322
Value Function Loss: 0.01585

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.58423

Collected Steps per Second: 22,299.22019
Overall Steps per Second: 10,514.08746

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.75686

Cumulative Model Updates: 202,328
Cumulative Timesteps: 1,687,428,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1687428400...
Checkpoint 1687428400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.89898
Policy Entropy: 2.23086
Value Function Loss: 0.01597

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.55492
Value Function Update Magnitude: 0.59367

Collected Steps per Second: 22,269.83940
Overall Steps per Second: 10,639.80486

Timestep Collection Time: 2.24555
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.70009

Cumulative Model Updates: 202,334
Cumulative Timesteps: 1,687,478,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.76453
Policy Entropy: 2.24099
Value Function Loss: 0.01549

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.54511
Value Function Update Magnitude: 0.58706

Collected Steps per Second: 21,756.46921
Overall Steps per Second: 10,447.69313

Timestep Collection Time: 2.29982
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.78919

Cumulative Model Updates: 202,340
Cumulative Timesteps: 1,687,528,444

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1687528444...
Checkpoint 1687528444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.12198
Policy Entropy: 2.24778
Value Function Loss: 0.01498

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.53519
Value Function Update Magnitude: 0.57198

Collected Steps per Second: 22,253.59477
Overall Steps per Second: 10,548.23507

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.74089

Cumulative Model Updates: 202,346
Cumulative Timesteps: 1,687,578,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.18449
Policy Entropy: 2.24642
Value Function Loss: 0.01416

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.52889
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 22,322.77112
Overall Steps per Second: 10,597.03815

Timestep Collection Time: 2.24121
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.72113

Cumulative Model Updates: 202,352
Cumulative Timesteps: 1,687,628,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1687628482...
Checkpoint 1687628482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.51033
Policy Entropy: 2.25275
Value Function Loss: 0.01409

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.55915

Collected Steps per Second: 21,940.82442
Overall Steps per Second: 10,553.09454

Timestep Collection Time: 2.28013
Timestep Consumption Time: 2.46047
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.74060

Cumulative Model Updates: 202,358
Cumulative Timesteps: 1,687,678,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 833.54912
Policy Entropy: 2.25636
Value Function Loss: 0.01426

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.57133

Collected Steps per Second: 22,686.12769
Overall Steps per Second: 10,746.61563

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.65430

Cumulative Model Updates: 202,364
Cumulative Timesteps: 1,687,728,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1687728528...
Checkpoint 1687728528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.03459
Policy Entropy: 2.26489
Value Function Loss: 0.01551

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.56118

Collected Steps per Second: 22,315.29132
Overall Steps per Second: 10,409.59254

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.56408
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.80595

Cumulative Model Updates: 202,370
Cumulative Timesteps: 1,687,778,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.93439
Policy Entropy: 2.26465
Value Function Loss: 0.01575

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.55057

Collected Steps per Second: 22,495.18402
Overall Steps per Second: 10,462.17318

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.55673
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.77970

Cumulative Model Updates: 202,376
Cumulative Timesteps: 1,687,828,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1687828562...
Checkpoint 1687828562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.19159
Policy Entropy: 2.25921
Value Function Loss: 0.01555

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.54114
Value Function Update Magnitude: 0.55043

Collected Steps per Second: 22,228.68082
Overall Steps per Second: 10,623.11769

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.70785

Cumulative Model Updates: 202,382
Cumulative Timesteps: 1,687,878,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.54068
Policy Entropy: 2.26623
Value Function Loss: 0.01487

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 22,485.48427
Overall Steps per Second: 10,695.77515

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.67474

Cumulative Model Updates: 202,388
Cumulative Timesteps: 1,687,928,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1687928574...
Checkpoint 1687928574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.30675
Policy Entropy: 2.24253
Value Function Loss: 0.01405

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.56405

Collected Steps per Second: 22,612.93980
Overall Steps per Second: 10,505.39622

Timestep Collection Time: 2.21174
Timestep Consumption Time: 2.54905
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.76079

Cumulative Model Updates: 202,394
Cumulative Timesteps: 1,687,978,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.99320
Policy Entropy: 2.25036
Value Function Loss: 0.01488

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.56155

Collected Steps per Second: 22,736.56111
Overall Steps per Second: 10,590.49338

Timestep Collection Time: 2.19972
Timestep Consumption Time: 2.52282
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.72254

Cumulative Model Updates: 202,400
Cumulative Timesteps: 1,688,028,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1688028602...
Checkpoint 1688028602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.57305
Policy Entropy: 2.22821
Value Function Loss: 0.01666

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.54670
Value Function Update Magnitude: 0.56412

Collected Steps per Second: 22,355.51998
Overall Steps per Second: 10,507.66476

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.76091

Cumulative Model Updates: 202,406
Cumulative Timesteps: 1,688,078,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.02824
Policy Entropy: 2.20628
Value Function Loss: 0.01702

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.57335

Collected Steps per Second: 22,661.42379
Overall Steps per Second: 10,862.01647

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.39767
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.60485

Cumulative Model Updates: 202,412
Cumulative Timesteps: 1,688,128,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1688128646...
Checkpoint 1688128646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.39883
Policy Entropy: 2.20015
Value Function Loss: 0.01742

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.59969

Collected Steps per Second: 22,467.07690
Overall Steps per Second: 10,613.69885

Timestep Collection Time: 2.22664
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.71334

Cumulative Model Updates: 202,418
Cumulative Timesteps: 1,688,178,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.33934
Policy Entropy: 2.19478
Value Function Loss: 0.01592

Mean KL Divergence: 0.03077
SB3 Clip Fraction: 0.19199
Policy Update Magnitude: 0.53931
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 22,828.73428
Overall Steps per Second: 10,517.10657

Timestep Collection Time: 2.19048
Timestep Consumption Time: 2.56424
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.75473

Cumulative Model Updates: 202,424
Cumulative Timesteps: 1,688,228,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1688228678...
Checkpoint 1688228678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.44616
Policy Entropy: 2.20959
Value Function Loss: 0.01581

Mean KL Divergence: 0.02819
SB3 Clip Fraction: 0.17917
Policy Update Magnitude: 0.54010
Value Function Update Magnitude: 0.61249

Collected Steps per Second: 22,028.57390
Overall Steps per Second: 10,547.79772

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.74146

Cumulative Model Updates: 202,430
Cumulative Timesteps: 1,688,278,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.02386
Policy Entropy: 2.21811
Value Function Loss: 0.01632

Mean KL Divergence: 0.02732
SB3 Clip Fraction: 0.18334
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.62319

Collected Steps per Second: 22,244.65950
Overall Steps per Second: 10,591.18272

Timestep Collection Time: 2.24854
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.72261

Cumulative Model Updates: 202,436
Cumulative Timesteps: 1,688,328,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1688328708...
Checkpoint 1688328708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.26372
Policy Entropy: 2.21172
Value Function Loss: 0.01627

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.19156
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.60807

Collected Steps per Second: 21,976.94693
Overall Steps per Second: 10,498.38151

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.76321

Cumulative Model Updates: 202,442
Cumulative Timesteps: 1,688,378,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.02878
Policy Entropy: 2.21347
Value Function Loss: 0.01595

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.17673
Policy Update Magnitude: 0.56337
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,374.86901
Overall Steps per Second: 10,509.88136

Timestep Collection Time: 2.23563
Timestep Consumption Time: 2.52389
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75952

Cumulative Model Updates: 202,448
Cumulative Timesteps: 1,688,428,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1688428736...
Checkpoint 1688428736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.09654
Policy Entropy: 2.18701
Value Function Loss: 0.01596

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.17357
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.58239

Collected Steps per Second: 22,175.30650
Overall Steps per Second: 10,533.42597

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.74812

Cumulative Model Updates: 202,454
Cumulative Timesteps: 1,688,478,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.80856
Policy Entropy: 2.19373
Value Function Loss: 0.01630

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.56722

Collected Steps per Second: 22,651.64039
Overall Steps per Second: 10,730.40280

Timestep Collection Time: 2.20814
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.66133

Cumulative Model Updates: 202,460
Cumulative Timesteps: 1,688,528,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1688528768...
Checkpoint 1688528768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.80971
Policy Entropy: 2.19181
Value Function Loss: 0.01663

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 0.56688

Collected Steps per Second: 22,574.38235
Overall Steps per Second: 10,483.62040

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.55506
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.77049

Cumulative Model Updates: 202,466
Cumulative Timesteps: 1,688,578,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.07814
Policy Entropy: 2.20381
Value Function Loss: 0.01676

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.57004

Collected Steps per Second: 22,768.90950
Overall Steps per Second: 10,548.04566

Timestep Collection Time: 2.19703
Timestep Consumption Time: 2.54546
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.74249

Cumulative Model Updates: 202,472
Cumulative Timesteps: 1,688,628,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1688628804...
Checkpoint 1688628804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.22212
Policy Entropy: 2.20961
Value Function Loss: 0.01698

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.59245

Collected Steps per Second: 22,416.22593
Overall Steps per Second: 10,541.64958

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.74556

Cumulative Model Updates: 202,478
Cumulative Timesteps: 1,688,678,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.82677
Policy Entropy: 2.21448
Value Function Loss: 0.01627

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.59191

Collected Steps per Second: 22,379.28080
Overall Steps per Second: 10,461.42402

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.54597
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.78080

Cumulative Model Updates: 202,484
Cumulative Timesteps: 1,688,728,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1688728844...
Checkpoint 1688728844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.62528
Policy Entropy: 2.20049
Value Function Loss: 0.01568

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 21,861.24670
Overall Steps per Second: 10,606.66384

Timestep Collection Time: 2.28761
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.71496

Cumulative Model Updates: 202,490
Cumulative Timesteps: 1,688,778,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.86117
Policy Entropy: 2.21030
Value Function Loss: 0.01487

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 22,621.15221
Overall Steps per Second: 10,468.77246

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.56774
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.77974

Cumulative Model Updates: 202,496
Cumulative Timesteps: 1,688,828,892

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1688828892...
Checkpoint 1688828892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.48250
Policy Entropy: 2.20747
Value Function Loss: 0.01583

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 22,012.61058
Overall Steps per Second: 10,367.73628

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.55235
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.82478

Cumulative Model Updates: 202,502
Cumulative Timesteps: 1,688,878,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.78653
Policy Entropy: 2.20283
Value Function Loss: 0.01577

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.55007

Collected Steps per Second: 22,761.37500
Overall Steps per Second: 10,700.94849

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.67510

Cumulative Model Updates: 202,508
Cumulative Timesteps: 1,688,928,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1688928942...
Checkpoint 1688928942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.28056
Policy Entropy: 2.19143
Value Function Loss: 0.01587

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 21,865.03054
Overall Steps per Second: 10,606.76988

Timestep Collection Time: 2.28758
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.71567

Cumulative Model Updates: 202,514
Cumulative Timesteps: 1,688,978,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.53147
Policy Entropy: 2.19572
Value Function Loss: 0.01492

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.56095

Collected Steps per Second: 22,353.83585
Overall Steps per Second: 10,534.28977

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.74754

Cumulative Model Updates: 202,520
Cumulative Timesteps: 1,689,028,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1689028972...
Checkpoint 1689028972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.69077
Policy Entropy: 2.19711
Value Function Loss: 0.01456

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.53062
Value Function Update Magnitude: 0.53694

Collected Steps per Second: 22,110.91841
Overall Steps per Second: 10,506.59297

Timestep Collection Time: 2.26160
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.75949

Cumulative Model Updates: 202,526
Cumulative Timesteps: 1,689,078,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.36144
Policy Entropy: 2.21275
Value Function Loss: 0.01575

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.53608

Collected Steps per Second: 22,496.51678
Overall Steps per Second: 10,592.60411

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.72046

Cumulative Model Updates: 202,532
Cumulative Timesteps: 1,689,128,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1689128980...
Checkpoint 1689128980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.67278
Policy Entropy: 2.19999
Value Function Loss: 0.01545

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.54884

Collected Steps per Second: 22,095.39400
Overall Steps per Second: 10,615.87277

Timestep Collection Time: 2.26418
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71257

Cumulative Model Updates: 202,538
Cumulative Timesteps: 1,689,179,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.66761
Policy Entropy: 2.18496
Value Function Loss: 0.01646

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.55269

Collected Steps per Second: 22,685.14676
Overall Steps per Second: 10,461.73939

Timestep Collection Time: 2.20497
Timestep Consumption Time: 2.57626
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.78123

Cumulative Model Updates: 202,544
Cumulative Timesteps: 1,689,229,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1689229028...
Checkpoint 1689229028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.52502
Policy Entropy: 2.18831
Value Function Loss: 0.01616

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.55905

Collected Steps per Second: 22,362.16649
Overall Steps per Second: 10,574.60447

Timestep Collection Time: 2.23637
Timestep Consumption Time: 2.49289
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.72925

Cumulative Model Updates: 202,550
Cumulative Timesteps: 1,689,279,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.18841
Policy Entropy: 2.18973
Value Function Loss: 0.01599

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.56988

Collected Steps per Second: 22,396.85382
Overall Steps per Second: 10,535.00925

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.51453
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.74779

Cumulative Model Updates: 202,556
Cumulative Timesteps: 1,689,329,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1689329056...
Checkpoint 1689329056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.89588
Policy Entropy: 2.20012
Value Function Loss: 0.01556

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.56031

Collected Steps per Second: 21,980.39675
Overall Steps per Second: 10,625.86678

Timestep Collection Time: 2.27576
Timestep Consumption Time: 2.43181
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.70757

Cumulative Model Updates: 202,562
Cumulative Timesteps: 1,689,379,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.45411
Policy Entropy: 2.18724
Value Function Loss: 0.01595

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.55034

Collected Steps per Second: 22,660.96461
Overall Steps per Second: 10,464.81926

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.57343
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.78154

Cumulative Model Updates: 202,568
Cumulative Timesteps: 1,689,429,116

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1689429116...
Checkpoint 1689429116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.00861
Policy Entropy: 2.20096
Value Function Loss: 0.01614

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.57368

Collected Steps per Second: 22,174.38457
Overall Steps per Second: 10,424.97188

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.54153
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.79656

Cumulative Model Updates: 202,574
Cumulative Timesteps: 1,689,479,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.12709
Policy Entropy: 2.20436
Value Function Loss: 0.01519

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,578.67362
Overall Steps per Second: 10,640.71144

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.69950

Cumulative Model Updates: 202,580
Cumulative Timesteps: 1,689,529,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1689529126...
Checkpoint 1689529126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.31386
Policy Entropy: 2.21749
Value Function Loss: 0.01516

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.58845

Collected Steps per Second: 22,683.15923
Overall Steps per Second: 10,636.23607

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70411

Cumulative Model Updates: 202,586
Cumulative Timesteps: 1,689,579,160

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.13199
Policy Entropy: 2.23225
Value Function Loss: 0.01497

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.57215

Collected Steps per Second: 22,547.72835
Overall Steps per Second: 10,528.10013

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.75185

Cumulative Model Updates: 202,592
Cumulative Timesteps: 1,689,629,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1689629188...
Checkpoint 1689629188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.39563
Policy Entropy: 2.22706
Value Function Loss: 0.01567

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.52360
Value Function Update Magnitude: 0.57002

Collected Steps per Second: 22,002.05212
Overall Steps per Second: 10,530.69657

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.74897

Cumulative Model Updates: 202,598
Cumulative Timesteps: 1,689,679,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.21638
Policy Entropy: 2.21705
Value Function Loss: 0.01582

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 22,535.30011
Overall Steps per Second: 10,558.33949

Timestep Collection Time: 2.21936
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.73692

Cumulative Model Updates: 202,604
Cumulative Timesteps: 1,689,729,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1689729212...
Checkpoint 1689729212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.36476
Policy Entropy: 2.19713
Value Function Loss: 0.01735

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 22,315.37601
Overall Steps per Second: 10,643.18157

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.69822

Cumulative Model Updates: 202,610
Cumulative Timesteps: 1,689,779,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.75625
Policy Entropy: 2.17684
Value Function Loss: 0.01660

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.55544
Value Function Update Magnitude: 0.60872

Collected Steps per Second: 22,572.37122
Overall Steps per Second: 10,445.27490

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.57268
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.78858

Cumulative Model Updates: 202,616
Cumulative Timesteps: 1,689,829,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1689829234...
Checkpoint 1689829234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.45491
Policy Entropy: 2.16440
Value Function Loss: 0.01662

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.62164

Collected Steps per Second: 21,818.13422
Overall Steps per Second: 10,346.86561

Timestep Collection Time: 2.29185
Timestep Consumption Time: 2.54091
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.83277

Cumulative Model Updates: 202,622
Cumulative Timesteps: 1,689,879,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.08787
Policy Entropy: 2.18745
Value Function Loss: 0.01672

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.62498

Collected Steps per Second: 22,501.62768
Overall Steps per Second: 10,660.87970

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.69192

Cumulative Model Updates: 202,628
Cumulative Timesteps: 1,689,929,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1689929258...
Checkpoint 1689929258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.34582
Policy Entropy: 2.20044
Value Function Loss: 0.01787

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.62945

Collected Steps per Second: 21,982.85473
Overall Steps per Second: 10,654.40944

Timestep Collection Time: 2.27523
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.69439

Cumulative Model Updates: 202,634
Cumulative Timesteps: 1,689,979,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.31675
Policy Entropy: 2.22845
Value Function Loss: 0.01709

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.56881
Value Function Update Magnitude: 0.63051

Collected Steps per Second: 22,578.88488
Overall Steps per Second: 10,569.18699

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.73111

Cumulative Model Updates: 202,640
Cumulative Timesteps: 1,690,029,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1690029278...
Checkpoint 1690029278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.97367
Policy Entropy: 2.22814
Value Function Loss: 0.01663

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 22,391.96339
Overall Steps per Second: 10,585.31341

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.72579

Cumulative Model Updates: 202,646
Cumulative Timesteps: 1,690,079,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.21793
Policy Entropy: 2.22759
Value Function Loss: 0.01480

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.54739
Value Function Update Magnitude: 0.59683

Collected Steps per Second: 22,524.11360
Overall Steps per Second: 10,469.48326

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.55727
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.77827

Cumulative Model Updates: 202,652
Cumulative Timesteps: 1,690,129,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1690129328...
Checkpoint 1690129328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.73412
Policy Entropy: 2.21449
Value Function Loss: 0.01530

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.59208

Collected Steps per Second: 21,862.14661
Overall Steps per Second: 10,543.54356

Timestep Collection Time: 2.28770
Timestep Consumption Time: 2.45587
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.74357

Cumulative Model Updates: 202,658
Cumulative Timesteps: 1,690,179,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.44400
Policy Entropy: 2.20645
Value Function Loss: 0.01581

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.58992

Collected Steps per Second: 22,473.31260
Overall Steps per Second: 10,651.22432

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.69580

Cumulative Model Updates: 202,664
Cumulative Timesteps: 1,690,229,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1690229358...
Checkpoint 1690229358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.70203
Policy Entropy: 2.19699
Value Function Loss: 0.01766

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,432.38402
Overall Steps per Second: 10,572.78811

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.72988

Cumulative Model Updates: 202,670
Cumulative Timesteps: 1,690,279,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.10577
Policy Entropy: 2.15828
Value Function Loss: 0.01745

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.62281

Collected Steps per Second: 22,101.80661
Overall Steps per Second: 10,446.19639

Timestep Collection Time: 2.26325
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.78854

Cumulative Model Updates: 202,676
Cumulative Timesteps: 1,690,329,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1690329388...
Checkpoint 1690329388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.42916
Policy Entropy: 2.16815
Value Function Loss: 0.01666

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.17860
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.62790

Collected Steps per Second: 21,982.17536
Overall Steps per Second: 10,420.79030

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.52444
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.79983

Cumulative Model Updates: 202,682
Cumulative Timesteps: 1,690,379,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.72024
Policy Entropy: 2.16795
Value Function Loss: 0.01575

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.19409
Policy Update Magnitude: 0.50646
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 22,513.85781
Overall Steps per Second: 10,691.20118

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67843

Cumulative Model Updates: 202,688
Cumulative Timesteps: 1,690,429,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1690429424...
Checkpoint 1690429424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.61244
Policy Entropy: 2.16691
Value Function Loss: 0.01606

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.18877
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.58687

Collected Steps per Second: 22,233.50460
Overall Steps per Second: 10,641.09469

Timestep Collection Time: 2.25012
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70140

Cumulative Model Updates: 202,694
Cumulative Timesteps: 1,690,479,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.07283
Policy Entropy: 2.18483
Value Function Loss: 0.01642

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.18149
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 22,560.25262
Overall Steps per Second: 10,442.68560

Timestep Collection Time: 2.21691
Timestep Consumption Time: 2.57247
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.78938

Cumulative Model Updates: 202,700
Cumulative Timesteps: 1,690,529,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1690529466...
Checkpoint 1690529466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.43751
Policy Entropy: 2.19776
Value Function Loss: 0.01631

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.15568
Policy Update Magnitude: 0.54365
Value Function Update Magnitude: 0.55013

Collected Steps per Second: 21,978.35312
Overall Steps per Second: 10,427.26421

Timestep Collection Time: 2.27651
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.79838

Cumulative Model Updates: 202,706
Cumulative Timesteps: 1,690,579,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.30698
Policy Entropy: 2.20435
Value Function Loss: 0.01564

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.53298

Collected Steps per Second: 22,263.06707
Overall Steps per Second: 10,586.05605

Timestep Collection Time: 2.24704
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.72565

Cumulative Model Updates: 202,712
Cumulative Timesteps: 1,690,629,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1690629526...
Checkpoint 1690629526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.69214
Policy Entropy: 2.19135
Value Function Loss: 0.01626

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.56308

Collected Steps per Second: 22,435.06534
Overall Steps per Second: 10,770.79210

Timestep Collection Time: 2.22946
Timestep Consumption Time: 2.41440
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.64386

Cumulative Model Updates: 202,718
Cumulative Timesteps: 1,690,679,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.78140
Policy Entropy: 2.19418
Value Function Loss: 0.01588

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.57477

Collected Steps per Second: 22,552.94097
Overall Steps per Second: 10,436.64732

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.57463
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.79234

Cumulative Model Updates: 202,724
Cumulative Timesteps: 1,690,729,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1690729560...
Checkpoint 1690729560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.20239
Policy Entropy: 2.18417
Value Function Loss: 0.01570

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.55708

Collected Steps per Second: 22,198.65775
Overall Steps per Second: 10,535.58547

Timestep Collection Time: 2.25311
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.74734

Cumulative Model Updates: 202,730
Cumulative Timesteps: 1,690,779,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.15829
Policy Entropy: 2.17291
Value Function Loss: 0.01605

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 22,441.95086
Overall Steps per Second: 10,566.18010

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.73208

Cumulative Model Updates: 202,736
Cumulative Timesteps: 1,690,829,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1690829576...
Checkpoint 1690829576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.71540
Policy Entropy: 2.15172
Value Function Loss: 0.01696

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.52892

Collected Steps per Second: 22,055.29554
Overall Steps per Second: 10,632.00315

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70523

Cumulative Model Updates: 202,742
Cumulative Timesteps: 1,690,879,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.15866
Policy Entropy: 2.17683
Value Function Loss: 0.01735

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.53332

Collected Steps per Second: 22,591.64406
Overall Steps per Second: 10,471.36247

Timestep Collection Time: 2.21392
Timestep Consumption Time: 2.56254
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.77646

Cumulative Model Updates: 202,748
Cumulative Timesteps: 1,690,929,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1690929618...
Checkpoint 1690929618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.02340
Policy Entropy: 2.17569
Value Function Loss: 0.01709

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.54917

Collected Steps per Second: 22,330.22473
Overall Steps per Second: 10,538.98869

Timestep Collection Time: 2.23921
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.74448

Cumulative Model Updates: 202,754
Cumulative Timesteps: 1,690,979,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.65519
Policy Entropy: 2.17010
Value Function Loss: 0.01649

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 22,045.49435
Overall Steps per Second: 10,555.72236

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73904

Cumulative Model Updates: 202,760
Cumulative Timesteps: 1,691,029,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1691029644...
Checkpoint 1691029644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.92740
Policy Entropy: 2.15672
Value Function Loss: 0.01688

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.18035
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.56412

Collected Steps per Second: 22,377.04757
Overall Steps per Second: 10,635.00658

Timestep Collection Time: 2.23559
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.70390

Cumulative Model Updates: 202,766
Cumulative Timesteps: 1,691,079,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.82869
Policy Entropy: 2.16062
Value Function Loss: 0.01711

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.58901

Collected Steps per Second: 22,178.96537
Overall Steps per Second: 10,603.17922

Timestep Collection Time: 2.25475
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.71632

Cumulative Model Updates: 202,772
Cumulative Timesteps: 1,691,129,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1691129678...
Checkpoint 1691129678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.16231
Policy Entropy: 2.15799
Value Function Loss: 0.01642

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 22,484.64901
Overall Steps per Second: 10,475.54799

Timestep Collection Time: 2.22463
Timestep Consumption Time: 2.55030
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.77493

Cumulative Model Updates: 202,778
Cumulative Timesteps: 1,691,179,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.94521
Policy Entropy: 2.19531
Value Function Loss: 0.01627

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.58732

Collected Steps per Second: 22,322.44451
Overall Steps per Second: 10,495.06646

Timestep Collection Time: 2.24106
Timestep Consumption Time: 2.52556
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.76662

Cumulative Model Updates: 202,784
Cumulative Timesteps: 1,691,229,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1691229724...
Checkpoint 1691229724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.45046
Policy Entropy: 2.19098
Value Function Loss: 0.01603

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.57517

Collected Steps per Second: 22,176.45481
Overall Steps per Second: 10,568.57050

Timestep Collection Time: 2.25600
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.73385

Cumulative Model Updates: 202,790
Cumulative Timesteps: 1,691,279,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.05098
Policy Entropy: 2.18201
Value Function Loss: 0.01699

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.57912

Collected Steps per Second: 23,139.55250
Overall Steps per Second: 10,628.38120

Timestep Collection Time: 2.16141
Timestep Consumption Time: 2.54430
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.70570

Cumulative Model Updates: 202,796
Cumulative Timesteps: 1,691,329,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1691329768...
Checkpoint 1691329768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.76499
Policy Entropy: 2.13602
Value Function Loss: 0.01783

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.58728

Collected Steps per Second: 22,102.90109
Overall Steps per Second: 10,421.16992

Timestep Collection Time: 2.26269
Timestep Consumption Time: 2.53639
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.79908

Cumulative Model Updates: 202,802
Cumulative Timesteps: 1,691,379,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.82157
Policy Entropy: 2.15441
Value Function Loss: 0.01727

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 22,649.00018
Overall Steps per Second: 10,550.48644

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.53233
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74063

Cumulative Model Updates: 202,808
Cumulative Timesteps: 1,691,429,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1691429796...
Checkpoint 1691429796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.87683
Policy Entropy: 2.18560
Value Function Loss: 0.01644

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 22,194.71955
Overall Steps per Second: 10,575.06286

Timestep Collection Time: 2.25360
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.72981

Cumulative Model Updates: 202,814
Cumulative Timesteps: 1,691,479,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.12535
Policy Entropy: 2.19952
Value Function Loss: 0.01579

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.58816

Collected Steps per Second: 23,215.05598
Overall Steps per Second: 10,636.28412

Timestep Collection Time: 2.15464
Timestep Consumption Time: 2.54813
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.70277

Cumulative Model Updates: 202,820
Cumulative Timesteps: 1,691,529,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1691529834...
Checkpoint 1691529834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.64948
Policy Entropy: 2.18692
Value Function Loss: 0.01487

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.52798
Value Function Update Magnitude: 0.55532

Collected Steps per Second: 22,206.20621
Overall Steps per Second: 10,506.35317

Timestep Collection Time: 2.25288
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.76169

Cumulative Model Updates: 202,826
Cumulative Timesteps: 1,691,579,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.32404
Policy Entropy: 2.16859
Value Function Loss: 0.01607

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.52997
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 22,229.23227
Overall Steps per Second: 10,480.11256

Timestep Collection Time: 2.24947
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.77132

Cumulative Model Updates: 202,832
Cumulative Timesteps: 1,691,629,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1691629866...
Checkpoint 1691629866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.34744
Policy Entropy: 2.17283
Value Function Loss: 0.01524

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 22,216.02544
Overall Steps per Second: 10,596.44307

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.72083

Cumulative Model Updates: 202,838
Cumulative Timesteps: 1,691,679,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.44820
Policy Entropy: 2.16126
Value Function Loss: 0.01605

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.54568
Value Function Update Magnitude: 0.58866

Collected Steps per Second: 22,283.96118
Overall Steps per Second: 10,615.91860

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.71010

Cumulative Model Updates: 202,844
Cumulative Timesteps: 1,691,729,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1691729892...
Checkpoint 1691729892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.67497
Policy Entropy: 2.16203
Value Function Loss: 0.01515

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,558.36014
Overall Steps per Second: 10,512.15404

Timestep Collection Time: 2.21727
Timestep Consumption Time: 2.54084
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.75811

Cumulative Model Updates: 202,850
Cumulative Timesteps: 1,691,779,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.62131
Policy Entropy: 2.14164
Value Function Loss: 0.01484

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.61167

Collected Steps per Second: 22,103.54680
Overall Steps per Second: 10,524.02299

Timestep Collection Time: 2.26262
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.75218

Cumulative Model Updates: 202,856
Cumulative Timesteps: 1,691,829,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1691829922...
Checkpoint 1691829922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.11012
Policy Entropy: 2.15456
Value Function Loss: 0.01422

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.51741
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 22,379.90663
Overall Steps per Second: 10,612.18650

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.71401

Cumulative Model Updates: 202,862
Cumulative Timesteps: 1,691,879,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.22100
Policy Entropy: 2.16952
Value Function Loss: 0.01488

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.51316
Value Function Update Magnitude: 0.55789

Collected Steps per Second: 22,297.71195
Overall Steps per Second: 10,436.90524

Timestep Collection Time: 2.24319
Timestep Consumption Time: 2.54923
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.79242

Cumulative Model Updates: 202,868
Cumulative Timesteps: 1,691,929,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1691929966...
Checkpoint 1691929966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.59429
Policy Entropy: 2.17436
Value Function Loss: 0.01515

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.52006
Value Function Update Magnitude: 0.54654

Collected Steps per Second: 22,293.70138
Overall Steps per Second: 10,687.97688

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68077

Cumulative Model Updates: 202,874
Cumulative Timesteps: 1,691,979,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.25782
Policy Entropy: 2.17824
Value Function Loss: 0.01441

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.52042
Value Function Update Magnitude: 0.54124

Collected Steps per Second: 22,535.23716
Overall Steps per Second: 10,457.75652

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.56332
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.78286

Cumulative Model Updates: 202,880
Cumulative Timesteps: 1,692,030,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1692030012...
Checkpoint 1692030012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.54773
Policy Entropy: 2.19634
Value Function Loss: 0.01486

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.51915
Value Function Update Magnitude: 0.55155

Collected Steps per Second: 22,318.25085
Overall Steps per Second: 10,586.10216

Timestep Collection Time: 2.24077
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.72412

Cumulative Model Updates: 202,886
Cumulative Timesteps: 1,692,080,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.53855
Policy Entropy: 2.19529
Value Function Loss: 0.01580

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.52429
Value Function Update Magnitude: 0.56535

Collected Steps per Second: 21,976.49311
Overall Steps per Second: 10,473.79349

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.49916
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77477

Cumulative Model Updates: 202,892
Cumulative Timesteps: 1,692,130,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1692130032...
Checkpoint 1692130032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.38544
Policy Entropy: 2.18289
Value Function Loss: 0.01755

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.57238

Collected Steps per Second: 22,353.24075
Overall Steps per Second: 10,674.68460

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68417

Cumulative Model Updates: 202,898
Cumulative Timesteps: 1,692,180,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.65767
Policy Entropy: 2.17338
Value Function Loss: 0.01737

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.56871

Collected Steps per Second: 21,925.06450
Overall Steps per Second: 10,505.12647

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.76148

Cumulative Model Updates: 202,904
Cumulative Timesteps: 1,692,230,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1692230054...
Checkpoint 1692230054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.87494
Policy Entropy: 2.16219
Value Function Loss: 0.01627

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.54946

Collected Steps per Second: 22,349.88905
Overall Steps per Second: 10,611.74132

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.71270

Cumulative Model Updates: 202,910
Cumulative Timesteps: 1,692,280,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.78643
Policy Entropy: 2.17050
Value Function Loss: 0.01702

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.51901

Collected Steps per Second: 22,352.72307
Overall Steps per Second: 10,428.74752

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.55891
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.79693

Cumulative Model Updates: 202,916
Cumulative Timesteps: 1,692,330,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1692330090...
Checkpoint 1692330090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.19638
Policy Entropy: 2.17772
Value Function Loss: 0.01789

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.52942

Collected Steps per Second: 22,080.03636
Overall Steps per Second: 10,545.48193

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.74345

Cumulative Model Updates: 202,922
Cumulative Timesteps: 1,692,380,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.84121
Policy Entropy: 2.20253
Value Function Loss: 0.01710

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.54255

Collected Steps per Second: 21,187.01681
Overall Steps per Second: 10,415.73722

Timestep Collection Time: 2.36088
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.80235

Cumulative Model Updates: 202,928
Cumulative Timesteps: 1,692,430,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1692430132...
Checkpoint 1692430132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.63428
Policy Entropy: 2.18973
Value Function Loss: 0.01645

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.54073

Collected Steps per Second: 21,169.53311
Overall Steps per Second: 10,350.92629

Timestep Collection Time: 2.36255
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.83184

Cumulative Model Updates: 202,934
Cumulative Timesteps: 1,692,480,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.92138
Policy Entropy: 2.17075
Value Function Loss: 0.01498

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.54140

Collected Steps per Second: 21,825.64814
Overall Steps per Second: 10,422.93613

Timestep Collection Time: 2.29189
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.79922

Cumulative Model Updates: 202,940
Cumulative Timesteps: 1,692,530,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1692530168...
Checkpoint 1692530168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.37900
Policy Entropy: 2.14911
Value Function Loss: 0.01556

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.55099

Collected Steps per Second: 22,359.30263
Overall Steps per Second: 10,555.69128

Timestep Collection Time: 2.23621
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.73678

Cumulative Model Updates: 202,946
Cumulative Timesteps: 1,692,580,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.14274
Policy Entropy: 2.18621
Value Function Loss: 0.01527

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 22,288.46811
Overall Steps per Second: 10,548.86805

Timestep Collection Time: 2.24403
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.74136

Cumulative Model Updates: 202,952
Cumulative Timesteps: 1,692,630,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1692630184...
Checkpoint 1692630184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.14530
Policy Entropy: 2.18793
Value Function Loss: 0.01691

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.57304

Collected Steps per Second: 22,275.60019
Overall Steps per Second: 10,573.99692

Timestep Collection Time: 2.24479
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.72896

Cumulative Model Updates: 202,958
Cumulative Timesteps: 1,692,680,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.49659
Policy Entropy: 2.22548
Value Function Loss: 0.01704

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.58222

Collected Steps per Second: 22,395.21758
Overall Steps per Second: 10,524.16890

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.51996
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.75401

Cumulative Model Updates: 202,964
Cumulative Timesteps: 1,692,730,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1692730220...
Checkpoint 1692730220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.17363
Policy Entropy: 2.18765
Value Function Loss: 0.01886

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.58020

Collected Steps per Second: 21,951.61419
Overall Steps per Second: 10,374.63604

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.54252
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.82099

Cumulative Model Updates: 202,970
Cumulative Timesteps: 1,692,780,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.09073
Policy Entropy: 2.22472
Value Function Loss: 0.01805

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.58882

Collected Steps per Second: 22,246.82530
Overall Steps per Second: 10,499.88966

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.51585
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.76462

Cumulative Model Updates: 202,976
Cumulative Timesteps: 1,692,830,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1692830264...
Checkpoint 1692830264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.51254
Policy Entropy: 2.22164
Value Function Loss: 0.01742

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.59611

Collected Steps per Second: 22,338.45982
Overall Steps per Second: 10,699.06085

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.67518

Cumulative Model Updates: 202,982
Cumulative Timesteps: 1,692,880,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.59658
Policy Entropy: 2.23435
Value Function Loss: 0.01640

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.54791
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 22,529.31188
Overall Steps per Second: 10,598.89070

Timestep Collection Time: 2.22128
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.72163

Cumulative Model Updates: 202,988
Cumulative Timesteps: 1,692,930,328

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1692930328...
Checkpoint 1692930328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.82022
Policy Entropy: 2.21063
Value Function Loss: 0.01675

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.55547

Collected Steps per Second: 22,245.44776
Overall Steps per Second: 10,437.13458

Timestep Collection Time: 2.24810
Timestep Consumption Time: 2.54344
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.79155

Cumulative Model Updates: 202,994
Cumulative Timesteps: 1,692,980,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.87776
Policy Entropy: 2.20108
Value Function Loss: 0.01632

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.53966

Collected Steps per Second: 22,697.84304
Overall Steps per Second: 10,700.90523

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.67400

Cumulative Model Updates: 203,000
Cumulative Timesteps: 1,693,030,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1693030354...
Checkpoint 1693030354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.49927
Policy Entropy: 2.18664
Value Function Loss: 0.01586

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.53450

Collected Steps per Second: 21,934.64114
Overall Steps per Second: 10,689.81906

Timestep Collection Time: 2.28014
Timestep Consumption Time: 2.39852
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.67866

Cumulative Model Updates: 203,006
Cumulative Timesteps: 1,693,080,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.05207
Policy Entropy: 2.16191
Value Function Loss: 0.01572

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.54475

Collected Steps per Second: 22,748.88552
Overall Steps per Second: 10,497.70665

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.56586
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.76447

Cumulative Model Updates: 203,012
Cumulative Timesteps: 1,693,130,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1693130384...
Checkpoint 1693130384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.09037
Policy Entropy: 2.15189
Value Function Loss: 0.01511

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.56221

Collected Steps per Second: 22,244.68441
Overall Steps per Second: 10,575.94010

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.72771

Cumulative Model Updates: 203,018
Cumulative Timesteps: 1,693,180,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.93720
Policy Entropy: 2.14628
Value Function Loss: 0.01533

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.52403
Value Function Update Magnitude: 0.55852

Collected Steps per Second: 22,533.45646
Overall Steps per Second: 10,545.28958

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.52273
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.74183

Cumulative Model Updates: 203,024
Cumulative Timesteps: 1,693,230,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1693230388...
Checkpoint 1693230388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.29557
Policy Entropy: 2.17154
Value Function Loss: 0.01497

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.52776
Value Function Update Magnitude: 0.55513

Collected Steps per Second: 22,165.33612
Overall Steps per Second: 10,559.79969

Timestep Collection Time: 2.25577
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.73494

Cumulative Model Updates: 203,030
Cumulative Timesteps: 1,693,280,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.85154
Policy Entropy: 2.13147
Value Function Loss: 0.01663

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.57582

Collected Steps per Second: 22,709.45510
Overall Steps per Second: 10,494.70089

Timestep Collection Time: 2.20173
Timestep Consumption Time: 2.56258
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.76431

Cumulative Model Updates: 203,036
Cumulative Timesteps: 1,693,330,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1693330388...
Checkpoint 1693330388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.81336
Policy Entropy: 2.12329
Value Function Loss: 0.01702

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,328.37195
Overall Steps per Second: 10,604.40104

Timestep Collection Time: 2.24038
Timestep Consumption Time: 2.47691
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.71729

Cumulative Model Updates: 203,042
Cumulative Timesteps: 1,693,380,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.73396
Policy Entropy: 2.10809
Value Function Loss: 0.01676

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 22,398.37704
Overall Steps per Second: 10,532.80150

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.75182

Cumulative Model Updates: 203,048
Cumulative Timesteps: 1,693,430,462

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1693430462...
Checkpoint 1693430462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.65472
Policy Entropy: 2.15713
Value Function Loss: 0.01526

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.56902

Collected Steps per Second: 21,895.60716
Overall Steps per Second: 10,525.15162

Timestep Collection Time: 2.28448
Timestep Consumption Time: 2.46795
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.75243

Cumulative Model Updates: 203,054
Cumulative Timesteps: 1,693,480,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.72268
Policy Entropy: 2.17077
Value Function Loss: 0.01564

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 22,655.75355
Overall Steps per Second: 10,478.70296

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.56607
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.77425

Cumulative Model Updates: 203,060
Cumulative Timesteps: 1,693,530,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1693530510...
Checkpoint 1693530510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.20816
Policy Entropy: 2.20721
Value Function Loss: 0.01545

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.52347
Value Function Update Magnitude: 0.53620

Collected Steps per Second: 22,075.11754
Overall Steps per Second: 10,534.07148

Timestep Collection Time: 2.26572
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.74802

Cumulative Model Updates: 203,066
Cumulative Timesteps: 1,693,580,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.59862
Policy Entropy: 2.19124
Value Function Loss: 0.01626

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 22,454.10776
Overall Steps per Second: 10,570.26522

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.73252

Cumulative Model Updates: 203,072
Cumulative Timesteps: 1,693,630,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1693630550...
Checkpoint 1693630550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.92092
Policy Entropy: 2.20377
Value Function Loss: 0.01512

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.54569

Collected Steps per Second: 22,118.99866
Overall Steps per Second: 10,579.17493

Timestep Collection Time: 2.26159
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.72854

Cumulative Model Updates: 203,078
Cumulative Timesteps: 1,693,680,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.63866
Policy Entropy: 2.18287
Value Function Loss: 0.01573

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.55188

Collected Steps per Second: 23,237.97439
Overall Steps per Second: 10,658.40835

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.53958
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.69132

Cumulative Model Updates: 203,084
Cumulative Timesteps: 1,693,730,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1693730576...
Checkpoint 1693730576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.44689
Policy Entropy: 2.18121
Value Function Loss: 0.01609

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.53582
Value Function Update Magnitude: 0.57058

Collected Steps per Second: 22,461.80342
Overall Steps per Second: 10,466.09069

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.55225
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.77905

Cumulative Model Updates: 203,090
Cumulative Timesteps: 1,693,780,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.15226
Policy Entropy: 2.16431
Value Function Loss: 0.01638

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.55664

Collected Steps per Second: 22,633.29092
Overall Steps per Second: 10,346.70907

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.62458
PPO Batch Consumption Time: 0.30720
Total Iteration Time: 4.83477

Cumulative Model Updates: 203,096
Cumulative Timesteps: 1,693,830,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1693830618...
Checkpoint 1693830618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.87267
Policy Entropy: 2.13862
Value Function Loss: 0.01784

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.53524
Value Function Update Magnitude: 0.56938

Collected Steps per Second: 21,532.93418
Overall Steps per Second: 10,341.23192

Timestep Collection Time: 2.32332
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.83772

Cumulative Model Updates: 203,102
Cumulative Timesteps: 1,693,880,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.99839
Policy Entropy: 2.14191
Value Function Loss: 0.01703

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.17943
Policy Update Magnitude: 0.53691
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 22,254.81433
Overall Steps per Second: 10,602.51015

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.71813

Cumulative Model Updates: 203,108
Cumulative Timesteps: 1,693,930,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1693930670...
Checkpoint 1693930670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.56359
Policy Entropy: 2.13347
Value Function Loss: 0.01712

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.18209
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.62797

Collected Steps per Second: 22,699.94286
Overall Steps per Second: 10,524.50371

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.54960
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.75348

Cumulative Model Updates: 203,114
Cumulative Timesteps: 1,693,980,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.68058
Policy Entropy: 2.13733
Value Function Loss: 0.01685

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.16537
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 22,707.37790
Overall Steps per Second: 10,561.57609

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.53313
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.73585

Cumulative Model Updates: 203,120
Cumulative Timesteps: 1,694,030,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1694030716...
Checkpoint 1694030716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.45025
Policy Entropy: 2.14618
Value Function Loss: 0.01643

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.58403

Collected Steps per Second: 22,299.74564
Overall Steps per Second: 10,486.63878

Timestep Collection Time: 2.24316
Timestep Consumption Time: 2.52691
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.77007

Cumulative Model Updates: 203,126
Cumulative Timesteps: 1,694,080,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.04418
Policy Entropy: 2.14078
Value Function Loss: 0.01663

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.57836

Collected Steps per Second: 22,712.11670
Overall Steps per Second: 10,529.53314

Timestep Collection Time: 2.20164
Timestep Consumption Time: 2.54728
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.74893

Cumulative Model Updates: 203,132
Cumulative Timesteps: 1,694,130,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1694130742...
Checkpoint 1694130742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.28679
Policy Entropy: 2.14921
Value Function Loss: 0.01637

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.60458

Collected Steps per Second: 22,480.30715
Overall Steps per Second: 10,527.85899

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.52635
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.75158

Cumulative Model Updates: 203,138
Cumulative Timesteps: 1,694,180,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.19652
Policy Entropy: 2.15042
Value Function Loss: 0.01586

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.61514

Collected Steps per Second: 22,475.42049
Overall Steps per Second: 10,500.25974

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.53774
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76293

Cumulative Model Updates: 203,144
Cumulative Timesteps: 1,694,230,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1694230778...
Checkpoint 1694230778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.84481
Policy Entropy: 2.15210
Value Function Loss: 0.01611

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.59698

Collected Steps per Second: 21,994.72763
Overall Steps per Second: 10,560.32245

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.73489

Cumulative Model Updates: 203,150
Cumulative Timesteps: 1,694,280,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.70306
Policy Entropy: 2.13783
Value Function Loss: 0.01583

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.57978

Collected Steps per Second: 22,287.55327
Overall Steps per Second: 10,614.57300

Timestep Collection Time: 2.24484
Timestep Consumption Time: 2.46868
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.71352

Cumulative Model Updates: 203,156
Cumulative Timesteps: 1,694,330,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1694330812...
Checkpoint 1694330812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.23463
Policy Entropy: 2.13585
Value Function Loss: 0.01595

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.58272

Collected Steps per Second: 22,476.37639
Overall Steps per Second: 10,572.69199

Timestep Collection Time: 2.22491
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.72992

Cumulative Model Updates: 203,162
Cumulative Timesteps: 1,694,380,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.16534
Policy Entropy: 2.14738
Value Function Loss: 0.01474

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53557
Value Function Update Magnitude: 0.57435

Collected Steps per Second: 22,469.59688
Overall Steps per Second: 10,474.18058

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.54994
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.77651

Cumulative Model Updates: 203,168
Cumulative Timesteps: 1,694,430,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1694430850...
Checkpoint 1694430850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.28682
Policy Entropy: 2.15802
Value Function Loss: 0.01520

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.55182

Collected Steps per Second: 22,155.15154
Overall Steps per Second: 10,562.17767

Timestep Collection Time: 2.25735
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.73501

Cumulative Model Updates: 203,174
Cumulative Timesteps: 1,694,480,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.74393
Policy Entropy: 2.14762
Value Function Loss: 0.01615

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.53263
Value Function Update Magnitude: 0.54804

Collected Steps per Second: 22,402.74376
Overall Steps per Second: 10,463.66249

Timestep Collection Time: 2.23285
Timestep Consumption Time: 2.54769
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.78054

Cumulative Model Updates: 203,180
Cumulative Timesteps: 1,694,530,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1694530884...
Checkpoint 1694530884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.61589
Policy Entropy: 2.12735
Value Function Loss: 0.01632

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.53182
Value Function Update Magnitude: 0.56117

Collected Steps per Second: 21,449.80834
Overall Steps per Second: 10,257.08141

Timestep Collection Time: 2.33112
Timestep Consumption Time: 2.54376
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.87488

Cumulative Model Updates: 203,186
Cumulative Timesteps: 1,694,580,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.78054
Policy Entropy: 2.09794
Value Function Loss: 0.01704

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.56856

Collected Steps per Second: 22,552.11508
Overall Steps per Second: 10,481.83967

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.55460
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.77302

Cumulative Model Updates: 203,192
Cumulative Timesteps: 1,694,630,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1694630916...
Checkpoint 1694630916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.56306
Policy Entropy: 2.10101
Value Function Loss: 0.01654

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 22,151.90953
Overall Steps per Second: 10,562.44112

Timestep Collection Time: 2.25750
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.73451

Cumulative Model Updates: 203,198
Cumulative Timesteps: 1,694,680,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.36054
Policy Entropy: 2.10101
Value Function Loss: 0.01652

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 22,237.28862
Overall Steps per Second: 10,521.85359

Timestep Collection Time: 2.24857
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75220

Cumulative Model Updates: 203,204
Cumulative Timesteps: 1,694,730,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1694730926...
Checkpoint 1694730926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.36174
Policy Entropy: 2.12848
Value Function Loss: 0.01657

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 22,236.46158
Overall Steps per Second: 10,629.84499

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.45567
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.70468

Cumulative Model Updates: 203,210
Cumulative Timesteps: 1,694,780,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.85040
Policy Entropy: 2.11627
Value Function Loss: 0.01645

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 22,514.43476
Overall Steps per Second: 10,470.55560

Timestep Collection Time: 2.22169
Timestep Consumption Time: 2.55552
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.77721

Cumulative Model Updates: 203,216
Cumulative Timesteps: 1,694,830,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1694830956...
Checkpoint 1694830956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.16021
Policy Entropy: 2.11780
Value Function Loss: 0.01618

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.59626

Collected Steps per Second: 22,247.09639
Overall Steps per Second: 10,583.38459

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.47799
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.72647

Cumulative Model Updates: 203,222
Cumulative Timesteps: 1,694,880,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.47414
Policy Entropy: 2.09371
Value Function Loss: 0.01630

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.60758

Collected Steps per Second: 22,507.64788
Overall Steps per Second: 10,502.63998

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.54178
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.76547

Cumulative Model Updates: 203,228
Cumulative Timesteps: 1,694,931,028

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1694931028...
Checkpoint 1694931028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.71882
Policy Entropy: 2.11464
Value Function Loss: 0.01599

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.16526
Policy Update Magnitude: 0.57458
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,097.85053
Overall Steps per Second: 10,582.21136

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.72756

Cumulative Model Updates: 203,234
Cumulative Timesteps: 1,694,981,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.56199
Policy Entropy: 2.13631
Value Function Loss: 0.01636

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.58437

Collected Steps per Second: 22,373.61922
Overall Steps per Second: 10,658.82210

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.45706
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.69264

Cumulative Model Updates: 203,240
Cumulative Timesteps: 1,695,031,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1695031074...
Checkpoint 1695031074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.36877
Policy Entropy: 2.12475
Value Function Loss: 0.01549

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.57303

Collected Steps per Second: 21,288.17907
Overall Steps per Second: 10,541.41519

Timestep Collection Time: 2.35022
Timestep Consumption Time: 2.39601
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.74623

Cumulative Model Updates: 203,246
Cumulative Timesteps: 1,695,081,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.58437
Policy Entropy: 2.11371
Value Function Loss: 0.01572

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.59066

Collected Steps per Second: 22,606.14650
Overall Steps per Second: 10,527.50283

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.53818
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.75041

Cumulative Model Updates: 203,252
Cumulative Timesteps: 1,695,131,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1695131116...
Checkpoint 1695131116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.29044
Policy Entropy: 2.12421
Value Function Loss: 0.01573

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.53863
Value Function Update Magnitude: 0.61681

Collected Steps per Second: 22,342.02153
Overall Steps per Second: 10,549.07074

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.74127

Cumulative Model Updates: 203,258
Cumulative Timesteps: 1,695,181,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.16626
Policy Entropy: 2.14623
Value Function Loss: 0.01579

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 22,203.55819
Overall Steps per Second: 10,438.27523

Timestep Collection Time: 2.25234
Timestep Consumption Time: 2.53868
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.79102

Cumulative Model Updates: 203,264
Cumulative Timesteps: 1,695,231,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1695231142...
Checkpoint 1695231142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.80459
Policy Entropy: 2.14740
Value Function Loss: 0.01595

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.53059
Value Function Update Magnitude: 0.56944

Collected Steps per Second: 22,943.88627
Overall Steps per Second: 10,671.48798

Timestep Collection Time: 2.18028
Timestep Consumption Time: 2.50736
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.68763

Cumulative Model Updates: 203,270
Cumulative Timesteps: 1,695,281,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.82328
Policy Entropy: 2.12461
Value Function Loss: 0.01670

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.54097
Value Function Update Magnitude: 0.57322

Collected Steps per Second: 22,273.03986
Overall Steps per Second: 10,449.52795

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.54105
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.78682

Cumulative Model Updates: 203,276
Cumulative Timesteps: 1,695,331,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1695331186...
Checkpoint 1695331186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.04207
Policy Entropy: 2.12123
Value Function Loss: 0.01758

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 21,769.02229
Overall Steps per Second: 10,310.25192

Timestep Collection Time: 2.29748
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.85090

Cumulative Model Updates: 203,282
Cumulative Timesteps: 1,695,381,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.84235
Policy Entropy: 2.13284
Value Function Loss: 0.01778

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.60298

Collected Steps per Second: 22,376.38877
Overall Steps per Second: 10,740.62167

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.65690

Cumulative Model Updates: 203,288
Cumulative Timesteps: 1,695,431,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1695431218...
Checkpoint 1695431218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.05331
Policy Entropy: 2.13665
Value Function Loss: 0.01681

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15029
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.58758

Collected Steps per Second: 22,494.73858
Overall Steps per Second: 10,652.49572

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.69392

Cumulative Model Updates: 203,294
Cumulative Timesteps: 1,695,481,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.43622
Policy Entropy: 2.14768
Value Function Loss: 0.01668

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 22,483.92888
Overall Steps per Second: 10,495.01259

Timestep Collection Time: 2.22461
Timestep Consumption Time: 2.54127
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.76588

Cumulative Model Updates: 203,300
Cumulative Timesteps: 1,695,531,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1695531238...
Checkpoint 1695531238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.95043
Policy Entropy: 2.11959
Value Function Loss: 0.01639

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 21,987.15341
Overall Steps per Second: 10,565.10553

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.73294

Cumulative Model Updates: 203,306
Cumulative Timesteps: 1,695,581,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.71342
Policy Entropy: 2.12469
Value Function Loss: 0.01669

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.59687

Collected Steps per Second: 22,115.54577
Overall Steps per Second: 10,573.41053

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.73111

Cumulative Model Updates: 203,312
Cumulative Timesteps: 1,695,631,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1695631266...
Checkpoint 1695631266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.51488
Policy Entropy: 2.10607
Value Function Loss: 0.01605

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 21,584.16181
Overall Steps per Second: 10,613.97573

Timestep Collection Time: 2.31698
Timestep Consumption Time: 2.39474
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.71171

Cumulative Model Updates: 203,318
Cumulative Timesteps: 1,695,681,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.82750
Policy Entropy: 2.10838
Value Function Loss: 0.01645

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 22,492.83352
Overall Steps per Second: 10,443.39572

Timestep Collection Time: 2.22320
Timestep Consumption Time: 2.56509
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.78829

Cumulative Model Updates: 203,324
Cumulative Timesteps: 1,695,731,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1695731282...
Checkpoint 1695731282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.38677
Policy Entropy: 2.11236
Value Function Loss: 0.01736

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.57420

Collected Steps per Second: 22,319.40569
Overall Steps per Second: 10,581.17562

Timestep Collection Time: 2.24110
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.72726

Cumulative Model Updates: 203,330
Cumulative Timesteps: 1,695,781,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.95433
Policy Entropy: 2.11602
Value Function Loss: 0.01708

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.58904

Collected Steps per Second: 22,324.42997
Overall Steps per Second: 10,547.31530

Timestep Collection Time: 2.24077
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.74282

Cumulative Model Updates: 203,336
Cumulative Timesteps: 1,695,831,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1695831326...
Checkpoint 1695831326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.12840
Policy Entropy: 2.11711
Value Function Loss: 0.01659

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.14998
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.58533

Collected Steps per Second: 22,136.63005
Overall Steps per Second: 10,627.06188

Timestep Collection Time: 2.25942
Timestep Consumption Time: 2.44705
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.70647

Cumulative Model Updates: 203,342
Cumulative Timesteps: 1,695,881,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.04868
Policy Entropy: 2.09943
Value Function Loss: 0.01531

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 22,462.46363
Overall Steps per Second: 10,433.06631

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.56785
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.79495

Cumulative Model Updates: 203,348
Cumulative Timesteps: 1,695,931,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1695931368...
Checkpoint 1695931368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.29368
Policy Entropy: 2.08942
Value Function Loss: 0.01543

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.55614

Collected Steps per Second: 22,234.75558
Overall Steps per Second: 10,530.70737

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.75144

Cumulative Model Updates: 203,354
Cumulative Timesteps: 1,695,981,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.58082
Policy Entropy: 2.11099
Value Function Loss: 0.01561

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.53535

Collected Steps per Second: 21,655.90648
Overall Steps per Second: 10,478.39916

Timestep Collection Time: 2.30930
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.77268

Cumulative Model Updates: 203,360
Cumulative Timesteps: 1,696,031,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1696031414...
Checkpoint 1696031414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.07894
Policy Entropy: 2.12630
Value Function Loss: 0.01537

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.52679
Value Function Update Magnitude: 0.52471

Collected Steps per Second: 22,229.26558
Overall Steps per Second: 10,796.30302

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.38221
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.63177

Cumulative Model Updates: 203,366
Cumulative Timesteps: 1,696,081,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.42735
Policy Entropy: 2.14303
Value Function Loss: 0.01482

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.51960
Value Function Update Magnitude: 0.51332

Collected Steps per Second: 22,455.22425
Overall Steps per Second: 10,433.83574

Timestep Collection Time: 2.22728
Timestep Consumption Time: 2.56617
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.79344

Cumulative Model Updates: 203,372
Cumulative Timesteps: 1,696,131,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1696131434...
Checkpoint 1696131434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.66388
Policy Entropy: 2.11921
Value Function Loss: 0.01522

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.50255

Collected Steps per Second: 22,387.49995
Overall Steps per Second: 10,603.34594

Timestep Collection Time: 2.23446
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.71776

Cumulative Model Updates: 203,378
Cumulative Timesteps: 1,696,181,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.03210
Policy Entropy: 2.11594
Value Function Loss: 0.01599

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.53691
Value Function Update Magnitude: 0.52820

Collected Steps per Second: 22,249.19769
Overall Steps per Second: 10,472.60186

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.52760
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.77532

Cumulative Model Updates: 203,384
Cumulative Timesteps: 1,696,231,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1696231468...
Checkpoint 1696231468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.21655
Policy Entropy: 2.10501
Value Function Loss: 0.01635

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.55094

Collected Steps per Second: 22,079.96405
Overall Steps per Second: 10,642.83022

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.69837

Cumulative Model Updates: 203,390
Cumulative Timesteps: 1,696,281,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.00209
Policy Entropy: 2.09476
Value Function Loss: 0.01648

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.54613

Collected Steps per Second: 22,692.59879
Overall Steps per Second: 10,486.77472

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.56465
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.76810

Cumulative Model Updates: 203,396
Cumulative Timesteps: 1,696,331,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1696331474...
Checkpoint 1696331474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.25584
Policy Entropy: 2.07725
Value Function Loss: 0.01592

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.53492

Collected Steps per Second: 21,760.56764
Overall Steps per Second: 10,472.48851

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.77690

Cumulative Model Updates: 203,402
Cumulative Timesteps: 1,696,381,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.20816
Policy Entropy: 2.06422
Value Function Loss: 0.01558

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.53440
Value Function Update Magnitude: 0.52773

Collected Steps per Second: 22,157.65198
Overall Steps per Second: 10,531.65172

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.74854

Cumulative Model Updates: 203,408
Cumulative Timesteps: 1,696,431,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1696431510...
Checkpoint 1696431510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.91321
Policy Entropy: 2.09318
Value Function Loss: 0.01556

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.53489
Value Function Update Magnitude: 0.51042

Collected Steps per Second: 22,077.02272
Overall Steps per Second: 10,602.33293

Timestep Collection Time: 2.26525
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.71689

Cumulative Model Updates: 203,414
Cumulative Timesteps: 1,696,481,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.20650
Policy Entropy: 2.11022
Value Function Loss: 0.01562

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.51149

Collected Steps per Second: 22,415.59917
Overall Steps per Second: 10,659.80634

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.69296

Cumulative Model Updates: 203,420
Cumulative Timesteps: 1,696,531,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1696531546...
Checkpoint 1696531546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.06130
Policy Entropy: 2.11539
Value Function Loss: 0.01556

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.52366
Value Function Update Magnitude: 0.51934

Collected Steps per Second: 22,349.14162
Overall Steps per Second: 10,531.61050

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74913

Cumulative Model Updates: 203,426
Cumulative Timesteps: 1,696,581,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.41777
Policy Entropy: 2.11950
Value Function Loss: 0.01548

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.52359
Value Function Update Magnitude: 0.51181

Collected Steps per Second: 22,199.76379
Overall Steps per Second: 10,461.68101

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.78183

Cumulative Model Updates: 203,432
Cumulative Timesteps: 1,696,631,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1696631588...
Checkpoint 1696631588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.79020
Policy Entropy: 2.10847
Value Function Loss: 0.01527

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.53033
Value Function Update Magnitude: 0.51846

Collected Steps per Second: 22,162.53277
Overall Steps per Second: 10,649.00017

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.69734

Cumulative Model Updates: 203,438
Cumulative Timesteps: 1,696,681,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.71073
Policy Entropy: 2.13958
Value Function Loss: 0.01522

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.53618

Collected Steps per Second: 22,282.76234
Overall Steps per Second: 10,649.36534

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.69624

Cumulative Model Updates: 203,444
Cumulative Timesteps: 1,696,731,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1696731622...
Checkpoint 1696731622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.62586
Policy Entropy: 2.13799
Value Function Loss: 0.01523

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.52515
Value Function Update Magnitude: 0.54427

Collected Steps per Second: 22,637.15632
Overall Steps per Second: 10,551.07298

Timestep Collection Time: 2.21017
Timestep Consumption Time: 2.53172
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.74189

Cumulative Model Updates: 203,450
Cumulative Timesteps: 1,696,781,654

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.59198
Policy Entropy: 2.13130
Value Function Loss: 0.01519

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.54289

Collected Steps per Second: 22,252.35841
Overall Steps per Second: 10,442.88099

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.54120
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.78833

Cumulative Model Updates: 203,456
Cumulative Timesteps: 1,696,831,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1696831658...
Checkpoint 1696831658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.81575
Policy Entropy: 2.12111
Value Function Loss: 0.01564

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.50908
Value Function Update Magnitude: 0.53293

Collected Steps per Second: 22,341.13133
Overall Steps per Second: 10,543.10592

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.74395

Cumulative Model Updates: 203,462
Cumulative Timesteps: 1,696,881,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.13998
Policy Entropy: 2.09361
Value Function Loss: 0.01657

Mean KL Divergence: 0.03059
SB3 Clip Fraction: 0.19974
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.52165

Collected Steps per Second: 22,374.24620
Overall Steps per Second: 10,777.18247

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.40520
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.64036

Cumulative Model Updates: 203,468
Cumulative Timesteps: 1,696,931,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1696931684...
Checkpoint 1696931684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.28249
Policy Entropy: 2.11327
Value Function Loss: 0.01677

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.18979
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.53396

Collected Steps per Second: 21,927.35640
Overall Steps per Second: 10,328.13364

Timestep Collection Time: 2.28080
Timestep Consumption Time: 2.56150
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.84231

Cumulative Model Updates: 203,474
Cumulative Timesteps: 1,696,981,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.64129
Policy Entropy: 2.11386
Value Function Loss: 0.01702

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.18556
Policy Update Magnitude: 0.51848
Value Function Update Magnitude: 0.55251

Collected Steps per Second: 22,322.06514
Overall Steps per Second: 10,461.88897

Timestep Collection Time: 2.24065
Timestep Consumption Time: 2.54013
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.78078

Cumulative Model Updates: 203,480
Cumulative Timesteps: 1,697,031,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1697031712...
Checkpoint 1697031712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.47062
Policy Entropy: 2.15099
Value Function Loss: 0.01618

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.18339
Policy Update Magnitude: 0.52793
Value Function Update Magnitude: 0.54936

Collected Steps per Second: 21,914.26634
Overall Steps per Second: 10,642.30501

Timestep Collection Time: 2.28189
Timestep Consumption Time: 2.41690
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69879

Cumulative Model Updates: 203,486
Cumulative Timesteps: 1,697,081,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.75019
Policy Entropy: 2.15806
Value Function Loss: 0.01808

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.17114
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.54043

Collected Steps per Second: 22,451.24828
Overall Steps per Second: 10,445.05983

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.56083
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.78868

Cumulative Model Updates: 203,492
Cumulative Timesteps: 1,697,131,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1697131736...
Checkpoint 1697131736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.00061
Policy Entropy: 2.13082
Value Function Loss: 0.01847

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.58299

Collected Steps per Second: 22,225.13868
Overall Steps per Second: 10,583.15517

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.72524

Cumulative Model Updates: 203,498
Cumulative Timesteps: 1,697,181,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.22178
Policy Entropy: 2.11389
Value Function Loss: 0.01949

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.61076

Collected Steps per Second: 22,063.21489
Overall Steps per Second: 10,535.57126

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.74848

Cumulative Model Updates: 203,504
Cumulative Timesteps: 1,697,231,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1697231772...
Checkpoint 1697231772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.32879
Policy Entropy: 2.11882
Value Function Loss: 0.01860

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 21,814.28220
Overall Steps per Second: 10,641.92448

Timestep Collection Time: 2.29281
Timestep Consumption Time: 2.40709
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.69990

Cumulative Model Updates: 203,510
Cumulative Timesteps: 1,697,281,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.41837
Policy Entropy: 2.14969
Value Function Loss: 0.01756

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 22,513.49047
Overall Steps per Second: 10,460.17315

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.55935
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 4.78042

Cumulative Model Updates: 203,516
Cumulative Timesteps: 1,697,331,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1697331792...
Checkpoint 1697331792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.78468
Policy Entropy: 2.14862
Value Function Loss: 0.01639

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.53696
Value Function Update Magnitude: 0.56401

Collected Steps per Second: 22,462.24275
Overall Steps per Second: 10,609.48868

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.71521

Cumulative Model Updates: 203,522
Cumulative Timesteps: 1,697,381,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.46595
Policy Entropy: 2.14938
Value Function Loss: 0.01524

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.56321

Collected Steps per Second: 22,119.35296
Overall Steps per Second: 10,471.53128

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.77638

Cumulative Model Updates: 203,528
Cumulative Timesteps: 1,697,431,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1697431834...
Checkpoint 1697431834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.59073
Policy Entropy: 2.13804
Value Function Loss: 0.01600

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 22,256.72337
Overall Steps per Second: 10,620.39461

Timestep Collection Time: 2.24759
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.71018

Cumulative Model Updates: 203,534
Cumulative Timesteps: 1,697,481,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.63082
Policy Entropy: 2.13283
Value Function Loss: 0.01568

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.58093

Collected Steps per Second: 22,475.85403
Overall Steps per Second: 10,445.36356

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.56333
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.78892

Cumulative Model Updates: 203,540
Cumulative Timesteps: 1,697,531,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1697531880...
Checkpoint 1697531880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.17764
Policy Entropy: 2.13192
Value Function Loss: 0.01557

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.53540
Value Function Update Magnitude: 0.59186

Collected Steps per Second: 22,394.15586
Overall Steps per Second: 10,576.77252

Timestep Collection Time: 2.23299
Timestep Consumption Time: 2.49491
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.72791

Cumulative Model Updates: 203,546
Cumulative Timesteps: 1,697,581,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.90276
Policy Entropy: 2.13631
Value Function Loss: 0.01499

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.58657

Collected Steps per Second: 21,861.47198
Overall Steps per Second: 10,511.56088

Timestep Collection Time: 2.28713
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.75667

Cumulative Model Updates: 203,552
Cumulative Timesteps: 1,697,631,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1697631886...
Checkpoint 1697631886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.44494
Policy Entropy: 2.13341
Value Function Loss: 0.01628

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.52964
Value Function Update Magnitude: 0.58587

Collected Steps per Second: 22,193.85395
Overall Steps per Second: 10,629.09060

Timestep Collection Time: 2.25432
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.70708

Cumulative Model Updates: 203,558
Cumulative Timesteps: 1,697,681,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.92074
Policy Entropy: 2.11704
Value Function Loss: 0.01768

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.60021

Collected Steps per Second: 22,387.25922
Overall Steps per Second: 10,677.64773

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.68530

Cumulative Model Updates: 203,564
Cumulative Timesteps: 1,697,731,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1697731946...
Checkpoint 1697731946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.88030
Policy Entropy: 2.12347
Value Function Loss: 0.01742

Mean KL Divergence: 0.02926
SB3 Clip Fraction: 0.19135
Policy Update Magnitude: 0.50847
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 22,202.97331
Overall Steps per Second: 10,465.64067

Timestep Collection Time: 2.25294
Timestep Consumption Time: 2.52670
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.77964

Cumulative Model Updates: 203,570
Cumulative Timesteps: 1,697,781,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.38544
Policy Entropy: 2.12602
Value Function Loss: 0.01742

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.18419
Policy Update Magnitude: 0.51336
Value Function Update Magnitude: 0.61285

Collected Steps per Second: 22,521.42128
Overall Steps per Second: 10,472.42547

Timestep Collection Time: 2.22109
Timestep Consumption Time: 2.55546
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.77654

Cumulative Model Updates: 203,576
Cumulative Timesteps: 1,697,831,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1697831990...
Checkpoint 1697831990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.42902
Policy Entropy: 2.13646
Value Function Loss: 0.01768

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.17940
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.61495

Collected Steps per Second: 22,125.31802
Overall Steps per Second: 10,585.29363

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.72429

Cumulative Model Updates: 203,582
Cumulative Timesteps: 1,697,881,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.67870
Policy Entropy: 2.14859
Value Function Loss: 0.01729

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.55739
Value Function Update Magnitude: 0.60720

Collected Steps per Second: 22,310.85278
Overall Steps per Second: 10,646.28015

Timestep Collection Time: 2.24232
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.69911

Cumulative Model Updates: 203,588
Cumulative Timesteps: 1,697,932,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1697932026...
Checkpoint 1697932026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.95201
Policy Entropy: 2.16497
Value Function Loss: 0.01726

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 22,287.10345
Overall Steps per Second: 10,498.01932

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.76280

Cumulative Model Updates: 203,594
Cumulative Timesteps: 1,697,982,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.95078
Policy Entropy: 2.16398
Value Function Loss: 0.01635

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,414.68603
Overall Steps per Second: 10,458.29871

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.55072
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.78185

Cumulative Model Updates: 203,600
Cumulative Timesteps: 1,698,032,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1698032036...
Checkpoint 1698032036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.88815
Policy Entropy: 2.14811
Value Function Loss: 0.01803

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.58395

Collected Steps per Second: 22,068.49482
Overall Steps per Second: 10,580.27684

Timestep Collection Time: 2.26694
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.72842

Cumulative Model Updates: 203,606
Cumulative Timesteps: 1,698,082,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.01491
Policy Entropy: 2.14445
Value Function Loss: 0.01719

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 23,154.76119
Overall Steps per Second: 10,645.18281

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.53758
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.69696

Cumulative Model Updates: 203,612
Cumulative Timesteps: 1,698,132,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1698132064...
Checkpoint 1698132064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.60710
Policy Entropy: 2.14286
Value Function Loss: 0.01804

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 22,044.18983
Overall Steps per Second: 10,521.77423

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.75376

Cumulative Model Updates: 203,618
Cumulative Timesteps: 1,698,182,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.45213
Policy Entropy: 2.14789
Value Function Loss: 0.01720

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.58757

Collected Steps per Second: 22,463.44065
Overall Steps per Second: 10,448.54886

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.56013
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.78650

Cumulative Model Updates: 203,624
Cumulative Timesteps: 1,698,232,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1698232094...
Checkpoint 1698232094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.36280
Policy Entropy: 2.10835
Value Function Loss: 0.01795

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.60733

Collected Steps per Second: 22,227.67179
Overall Steps per Second: 10,668.45443

Timestep Collection Time: 2.24972
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.68728

Cumulative Model Updates: 203,630
Cumulative Timesteps: 1,698,282,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.93256
Policy Entropy: 2.09472
Value Function Loss: 0.01791

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14548
Policy Update Magnitude: 0.56648
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 22,377.02781
Overall Steps per Second: 10,757.69534

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.41369
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.64839

Cumulative Model Updates: 203,636
Cumulative Timesteps: 1,698,332,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1698332106...
Checkpoint 1698332106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.01348
Policy Entropy: 2.09796
Value Function Loss: 0.01831

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 22,046.72992
Overall Steps per Second: 10,375.40423

Timestep Collection Time: 2.26827
Timestep Consumption Time: 2.55159
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.81986

Cumulative Model Updates: 203,642
Cumulative Timesteps: 1,698,382,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.77340
Policy Entropy: 2.09025
Value Function Loss: 0.01804

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.55129
Value Function Update Magnitude: 0.61673

Collected Steps per Second: 22,193.92454
Overall Steps per Second: 10,406.62859

Timestep Collection Time: 2.25413
Timestep Consumption Time: 2.55319
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.80732

Cumulative Model Updates: 203,648
Cumulative Timesteps: 1,698,432,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1698432142...
Checkpoint 1698432142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.72231
Policy Entropy: 2.09455
Value Function Loss: 0.01767

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.58430

Collected Steps per Second: 21,770.17518
Overall Steps per Second: 10,510.13735

Timestep Collection Time: 2.29746
Timestep Consumption Time: 2.46138
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.75883

Cumulative Model Updates: 203,654
Cumulative Timesteps: 1,698,482,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.90472
Policy Entropy: 2.12234
Value Function Loss: 0.01732

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.56815

Collected Steps per Second: 22,462.43690
Overall Steps per Second: 10,655.42495

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.69413

Cumulative Model Updates: 203,660
Cumulative Timesteps: 1,698,532,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1698532176...
Checkpoint 1698532176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.54062
Policy Entropy: 2.14742
Value Function Loss: 0.01743

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.56171

Collected Steps per Second: 22,150.50591
Overall Steps per Second: 10,589.04181

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.72375

Cumulative Model Updates: 203,666
Cumulative Timesteps: 1,698,582,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.55224
Policy Entropy: 2.15110
Value Function Loss: 0.01762

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.55404
Value Function Update Magnitude: 0.57149

Collected Steps per Second: 22,552.22169
Overall Steps per Second: 10,475.96291

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.55616
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.77359

Cumulative Model Updates: 203,672
Cumulative Timesteps: 1,698,632,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1698632204...
Checkpoint 1698632204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.88741
Policy Entropy: 2.10348
Value Function Loss: 0.01769

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.57414

Collected Steps per Second: 22,132.97289
Overall Steps per Second: 10,629.31391

Timestep Collection Time: 2.25989
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70567

Cumulative Model Updates: 203,678
Cumulative Timesteps: 1,698,682,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.92314
Policy Entropy: 2.12714
Value Function Loss: 0.01708

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.56585

Collected Steps per Second: 22,212.92513
Overall Steps per Second: 10,446.50909

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.53555
PPO Batch Consumption Time: 0.29920
Total Iteration Time: 4.78667

Cumulative Model Updates: 203,684
Cumulative Timesteps: 1,698,732,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1698732226...
Checkpoint 1698732226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.59016
Policy Entropy: 2.11407
Value Function Loss: 0.01614

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.56264

Collected Steps per Second: 22,908.59125
Overall Steps per Second: 10,640.47407

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.69979

Cumulative Model Updates: 203,690
Cumulative Timesteps: 1,698,782,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.68783
Policy Entropy: 2.12238
Value Function Loss: 0.01678

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,686.91683
Overall Steps per Second: 10,538.77551

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.54047
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.74438

Cumulative Model Updates: 203,696
Cumulative Timesteps: 1,698,832,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1698832234...
Checkpoint 1698832234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.20612
Policy Entropy: 2.10049
Value Function Loss: 0.01608

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.57781

Collected Steps per Second: 22,094.95600
Overall Steps per Second: 10,563.96731

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.47051
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.73383

Cumulative Model Updates: 203,702
Cumulative Timesteps: 1,698,882,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.23605
Policy Entropy: 2.11120
Value Function Loss: 0.01538

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.56974

Collected Steps per Second: 22,274.17611
Overall Steps per Second: 10,451.82958

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.54052
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.78653

Cumulative Model Updates: 203,708
Cumulative Timesteps: 1,698,932,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1698932270...
Checkpoint 1698932270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.04174
Policy Entropy: 2.10994
Value Function Loss: 0.01541

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.55120

Collected Steps per Second: 21,817.41216
Overall Steps per Second: 10,650.15611

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.40369
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.69608

Cumulative Model Updates: 203,714
Cumulative Timesteps: 1,698,982,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.93260
Policy Entropy: 2.09354
Value Function Loss: 0.01688

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 22,463.86865
Overall Steps per Second: 10,470.48958

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.55116
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.77838

Cumulative Model Updates: 203,720
Cumulative Timesteps: 1,699,032,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1699032316...
Checkpoint 1699032316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.02721
Policy Entropy: 2.09927
Value Function Loss: 0.01719

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 22,182.89770
Overall Steps per Second: 10,544.27740

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.74456

Cumulative Model Updates: 203,726
Cumulative Timesteps: 1,699,082,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.51462
Policy Entropy: 2.09050
Value Function Loss: 0.01667

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.57058

Collected Steps per Second: 22,048.68754
Overall Steps per Second: 10,481.08090

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.77107

Cumulative Model Updates: 203,732
Cumulative Timesteps: 1,699,132,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1699132350...
Checkpoint 1699132350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.32006
Policy Entropy: 2.09594
Value Function Loss: 0.01563

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.58051

Collected Steps per Second: 21,696.30593
Overall Steps per Second: 10,405.30677

Timestep Collection Time: 2.30592
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.80812

Cumulative Model Updates: 203,738
Cumulative Timesteps: 1,699,182,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.85332
Policy Entropy: 2.08625
Value Function Loss: 0.01509

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.59070

Collected Steps per Second: 22,445.51337
Overall Steps per Second: 10,778.24730

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.41174
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.63972

Cumulative Model Updates: 203,744
Cumulative Timesteps: 1,699,232,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1699232388...
Checkpoint 1699232388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.86772
Policy Entropy: 2.10085
Value Function Loss: 0.01562

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.56968

Collected Steps per Second: 22,382.31985
Overall Steps per Second: 10,578.59312

Timestep Collection Time: 2.23444
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.72766

Cumulative Model Updates: 203,750
Cumulative Timesteps: 1,699,282,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.29917
Policy Entropy: 2.11015
Value Function Loss: 0.01647

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.55374

Collected Steps per Second: 22,406.59336
Overall Steps per Second: 10,504.30932

Timestep Collection Time: 2.23265
Timestep Consumption Time: 2.52978
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76243

Cumulative Model Updates: 203,756
Cumulative Timesteps: 1,699,332,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1699332426...
Checkpoint 1699332426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.31599
Policy Entropy: 2.12816
Value Function Loss: 0.01571

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.53341
Value Function Update Magnitude: 0.57368

Collected Steps per Second: 22,075.66417
Overall Steps per Second: 10,576.04088

Timestep Collection Time: 2.26557
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.72899

Cumulative Model Updates: 203,762
Cumulative Timesteps: 1,699,382,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.50255
Policy Entropy: 2.13317
Value Function Loss: 0.01634

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.53717
Value Function Update Magnitude: 0.59452

Collected Steps per Second: 22,585.85654
Overall Steps per Second: 10,763.11923

Timestep Collection Time: 2.21395
Timestep Consumption Time: 2.43191
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.64587

Cumulative Model Updates: 203,768
Cumulative Timesteps: 1,699,432,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1699432444...
Checkpoint 1699432444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.78090
Policy Entropy: 2.13642
Value Function Loss: 0.01595

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.53809
Value Function Update Magnitude: 0.62289

Collected Steps per Second: 22,322.73248
Overall Steps per Second: 10,452.46716

Timestep Collection Time: 2.24085
Timestep Consumption Time: 2.54481
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.78566

Cumulative Model Updates: 203,774
Cumulative Timesteps: 1,699,482,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.70364
Policy Entropy: 2.14647
Value Function Loss: 0.01735

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 22,579.66742
Overall Steps per Second: 10,502.74920

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.54750
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.76294

Cumulative Model Updates: 203,780
Cumulative Timesteps: 1,699,532,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1699532490...
Checkpoint 1699532490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.79777
Policy Entropy: 2.13678
Value Function Loss: 0.01722

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 22,154.73740
Overall Steps per Second: 10,561.35779

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.73462

Cumulative Model Updates: 203,786
Cumulative Timesteps: 1,699,582,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.82723
Policy Entropy: 2.09924
Value Function Loss: 0.01736

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.55356
Value Function Update Magnitude: 0.61293

Collected Steps per Second: 22,461.59398
Overall Steps per Second: 10,814.14955

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.39803
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.62450

Cumulative Model Updates: 203,792
Cumulative Timesteps: 1,699,632,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1699632504...
Checkpoint 1699632504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.37256
Policy Entropy: 2.10145
Value Function Loss: 0.01680

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 22,142.71022
Overall Steps per Second: 10,483.97900

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.77166

Cumulative Model Updates: 203,798
Cumulative Timesteps: 1,699,682,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.41916
Policy Entropy: 2.11632
Value Function Loss: 0.01650

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.60548

Collected Steps per Second: 22,462.16623
Overall Steps per Second: 10,596.67395

Timestep Collection Time: 2.22623
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.71903

Cumulative Model Updates: 203,804
Cumulative Timesteps: 1,699,732,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1699732536...
Checkpoint 1699732536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.23595
Policy Entropy: 2.12412
Value Function Loss: 0.01643

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.59923

Collected Steps per Second: 22,140.28739
Overall Steps per Second: 10,630.04989

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.70534

Cumulative Model Updates: 203,810
Cumulative Timesteps: 1,699,782,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.84674
Policy Entropy: 2.10318
Value Function Loss: 0.01713

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,163.09758
Overall Steps per Second: 10,591.94749

Timestep Collection Time: 2.25636
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.72132

Cumulative Model Updates: 203,816
Cumulative Timesteps: 1,699,832,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1699832562...
Checkpoint 1699832562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.66353
Policy Entropy: 2.08196
Value Function Loss: 0.01723

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.60463

Collected Steps per Second: 22,119.52059
Overall Steps per Second: 10,625.78254

Timestep Collection Time: 2.26135
Timestep Consumption Time: 2.44607
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.70742

Cumulative Model Updates: 203,822
Cumulative Timesteps: 1,699,882,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.20677
Policy Entropy: 2.10095
Value Function Loss: 0.01793

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 22,221.25353
Overall Steps per Second: 10,433.93446

Timestep Collection Time: 2.25046
Timestep Consumption Time: 2.54236
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.79282

Cumulative Model Updates: 203,828
Cumulative Timesteps: 1,699,932,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1699932590...
Checkpoint 1699932590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.82634
Policy Entropy: 2.10828
Value Function Loss: 0.01647

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,225.73545
Overall Steps per Second: 10,557.00774

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.73808

Cumulative Model Updates: 203,834
Cumulative Timesteps: 1,699,982,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.02542
Policy Entropy: 2.07543
Value Function Loss: 0.01716

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.60122

Collected Steps per Second: 22,183.26224
Overall Steps per Second: 10,531.10565

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.74841

Cumulative Model Updates: 203,840
Cumulative Timesteps: 1,700,032,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1700032616...
Checkpoint 1700032616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.29851
Policy Entropy: 2.08156
Value Function Loss: 0.01660

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.56111
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 20,362.02043
Overall Steps per Second: 10,235.30223

Timestep Collection Time: 2.45555
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.88505

Cumulative Model Updates: 203,846
Cumulative Timesteps: 1,700,082,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.36487
Policy Entropy: 2.11244
Value Function Loss: 0.01660

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.55569
Value Function Update Magnitude: 0.60491

Collected Steps per Second: 22,072.25790
Overall Steps per Second: 10,460.20337

Timestep Collection Time: 2.26647
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.78251

Cumulative Model Updates: 203,852
Cumulative Timesteps: 1,700,132,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1700132642...
Checkpoint 1700132642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.83297
Policy Entropy: 2.14713
Value Function Loss: 0.01611

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 22,421.80099
Overall Steps per Second: 10,607.81585

Timestep Collection Time: 2.23140
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.71652

Cumulative Model Updates: 203,858
Cumulative Timesteps: 1,700,182,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.36465
Policy Entropy: 2.12015
Value Function Loss: 0.01622

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 22,280.42482
Overall Steps per Second: 10,505.14044

Timestep Collection Time: 2.24484
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.76110

Cumulative Model Updates: 203,864
Cumulative Timesteps: 1,700,232,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1700232690...
Checkpoint 1700232690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.85210
Policy Entropy: 2.11729
Value Function Loss: 0.01695

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 23,102.78582
Overall Steps per Second: 10,644.16845

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.53337
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.69778

Cumulative Model Updates: 203,870
Cumulative Timesteps: 1,700,282,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.19891
Policy Entropy: 2.11034
Value Function Loss: 0.01735

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 22,673.03287
Overall Steps per Second: 10,501.70772

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.55607
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.76151

Cumulative Model Updates: 203,876
Cumulative Timesteps: 1,700,332,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1700332698...
Checkpoint 1700332698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.09039
Policy Entropy: 2.13605
Value Function Loss: 0.01706

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.55104
Value Function Update Magnitude: 0.60782

Collected Steps per Second: 22,257.67748
Overall Steps per Second: 10,539.60821

Timestep Collection Time: 2.24678
Timestep Consumption Time: 2.49799
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.74477

Cumulative Model Updates: 203,882
Cumulative Timesteps: 1,700,382,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.12622
Policy Entropy: 2.12767
Value Function Loss: 0.01730

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.60573

Collected Steps per Second: 22,200.12943
Overall Steps per Second: 10,503.24742

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.76081

Cumulative Model Updates: 203,888
Cumulative Timesteps: 1,700,432,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1700432710...
Checkpoint 1700432710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.55979
Policy Entropy: 2.14966
Value Function Loss: 0.01620

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.60170

Collected Steps per Second: 22,278.46910
Overall Steps per Second: 10,642.56163

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.69868

Cumulative Model Updates: 203,894
Cumulative Timesteps: 1,700,482,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.25206
Policy Entropy: 2.13647
Value Function Loss: 0.01496

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.56764

Collected Steps per Second: 22,547.43046
Overall Steps per Second: 10,484.05041

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.55232
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.77048

Cumulative Model Updates: 203,900
Cumulative Timesteps: 1,700,532,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1700532730...
Checkpoint 1700532730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.79086
Policy Entropy: 2.15820
Value Function Loss: 0.01428

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.52355
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 22,488.69292
Overall Steps per Second: 10,621.15266

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.70853

Cumulative Model Updates: 203,906
Cumulative Timesteps: 1,700,582,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.60288
Policy Entropy: 2.16886
Value Function Loss: 0.01531

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.52267
Value Function Update Magnitude: 0.52275

Collected Steps per Second: 22,562.64471
Overall Steps per Second: 10,597.32277

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.72100

Cumulative Model Updates: 203,912
Cumulative Timesteps: 1,700,632,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1700632770...
Checkpoint 1700632770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.67561
Policy Entropy: 2.16379
Value Function Loss: 0.01578

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.54169

Collected Steps per Second: 22,090.73982
Overall Steps per Second: 10,613.39717

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.71404

Cumulative Model Updates: 203,918
Cumulative Timesteps: 1,700,682,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.63602
Policy Entropy: 2.15373
Value Function Loss: 0.01528

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 22,405.54730
Overall Steps per Second: 10,424.77021

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.56611
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.79895

Cumulative Model Updates: 203,924
Cumulative Timesteps: 1,700,732,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1700732830...
Checkpoint 1700732830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.94957
Policy Entropy: 2.13512
Value Function Loss: 0.01419

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.57144

Collected Steps per Second: 22,104.56307
Overall Steps per Second: 10,546.81992

Timestep Collection Time: 2.26198
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.74077

Cumulative Model Updates: 203,930
Cumulative Timesteps: 1,700,782,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.18221
Policy Entropy: 2.17881
Value Function Loss: 0.01481

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.57855

Collected Steps per Second: 22,431.19894
Overall Steps per Second: 10,535.97640

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.74678

Cumulative Model Updates: 203,936
Cumulative Timesteps: 1,700,832,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1700832842...
Checkpoint 1700832842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.44357
Policy Entropy: 2.17510
Value Function Loss: 0.01567

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.53101
Value Function Update Magnitude: 0.58485

Collected Steps per Second: 22,267.47901
Overall Steps per Second: 10,569.79469

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.73197

Cumulative Model Updates: 203,942
Cumulative Timesteps: 1,700,882,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.30061
Policy Entropy: 2.17483
Value Function Loss: 0.01600

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.51727
Value Function Update Magnitude: 0.59507

Collected Steps per Second: 22,156.71181
Overall Steps per Second: 10,663.06482

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69152

Cumulative Model Updates: 203,948
Cumulative Timesteps: 1,700,932,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1700932884...
Checkpoint 1700932884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.55126
Policy Entropy: 2.17147
Value Function Loss: 0.01599

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.50572
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 22,112.05105
Overall Steps per Second: 10,439.22891

Timestep Collection Time: 2.26175
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.79078

Cumulative Model Updates: 203,954
Cumulative Timesteps: 1,700,982,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.16119
Policy Entropy: 2.19135
Value Function Loss: 0.01635

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 22,289.16350
Overall Steps per Second: 10,465.14482

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.53503
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.77872

Cumulative Model Updates: 203,960
Cumulative Timesteps: 1,701,032,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1701032906...
Checkpoint 1701032906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.19522
Policy Entropy: 2.19531
Value Function Loss: 0.01651

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.52234
Value Function Update Magnitude: 0.60039

Collected Steps per Second: 22,036.76518
Overall Steps per Second: 10,529.17447

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.75118

Cumulative Model Updates: 203,966
Cumulative Timesteps: 1,701,082,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.09814
Policy Entropy: 2.16746
Value Function Loss: 0.01701

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.62049

Collected Steps per Second: 21,950.76456
Overall Steps per Second: 10,554.26392

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73761

Cumulative Model Updates: 203,972
Cumulative Timesteps: 1,701,132,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1701132934...
Checkpoint 1701132934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.86086
Policy Entropy: 2.15521
Value Function Loss: 0.01637

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.62019

Collected Steps per Second: 22,233.71762
Overall Steps per Second: 10,572.40199

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.72967

Cumulative Model Updates: 203,978
Cumulative Timesteps: 1,701,182,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.31783
Policy Entropy: 2.13558
Value Function Loss: 0.01597

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.54493
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,558.90245
Overall Steps per Second: 10,520.45913

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.75302

Cumulative Model Updates: 203,984
Cumulative Timesteps: 1,701,232,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1701232942...
Checkpoint 1701232942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.21164
Policy Entropy: 2.14583
Value Function Loss: 0.01654

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.58742

Collected Steps per Second: 22,348.16213
Overall Steps per Second: 10,587.52306

Timestep Collection Time: 2.23786
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.72367

Cumulative Model Updates: 203,990
Cumulative Timesteps: 1,701,282,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.30927
Policy Entropy: 2.15223
Value Function Loss: 0.01622

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 22,031.86785
Overall Steps per Second: 10,497.16604

Timestep Collection Time: 2.27026
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.76491

Cumulative Model Updates: 203,996
Cumulative Timesteps: 1,701,332,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1701332972...
Checkpoint 1701332972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.88673
Policy Entropy: 2.16151
Value Function Loss: 0.01646

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.59636

Collected Steps per Second: 22,129.62407
Overall Steps per Second: 10,659.58597

Timestep Collection Time: 2.25978
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.69136

Cumulative Model Updates: 204,002
Cumulative Timesteps: 1,701,382,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.89462
Policy Entropy: 2.16161
Value Function Loss: 0.01664

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 22,661.50410
Overall Steps per Second: 10,541.12558

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.53826
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.74579

Cumulative Model Updates: 204,008
Cumulative Timesteps: 1,701,433,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1701433006...
Checkpoint 1701433006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.70125
Policy Entropy: 2.15496
Value Function Loss: 0.01699

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.62091

Collected Steps per Second: 22,357.96485
Overall Steps per Second: 10,535.34709

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.74840

Cumulative Model Updates: 204,014
Cumulative Timesteps: 1,701,483,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.05622
Policy Entropy: 2.14885
Value Function Loss: 0.01683

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.60450

Collected Steps per Second: 22,024.23247
Overall Steps per Second: 10,477.40027

Timestep Collection Time: 2.27150
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.77485

Cumulative Model Updates: 204,020
Cumulative Timesteps: 1,701,533,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1701533060...
Checkpoint 1701533060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.71093
Policy Entropy: 2.12991
Value Function Loss: 0.01716

Mean KL Divergence: 0.02817
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.58706

Collected Steps per Second: 22,149.46109
Overall Steps per Second: 10,633.94803

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.44600
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.70474

Cumulative Model Updates: 204,026
Cumulative Timesteps: 1,701,583,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.36055
Policy Entropy: 2.13349
Value Function Loss: 0.01750

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.17220
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.57291

Collected Steps per Second: 22,478.71659
Overall Steps per Second: 10,455.88105

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.55910
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.78468

Cumulative Model Updates: 204,032
Cumulative Timesteps: 1,701,633,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1701633118...
Checkpoint 1701633118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.16663
Policy Entropy: 2.11936
Value Function Loss: 0.01659

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.56821

Collected Steps per Second: 22,056.31096
Overall Steps per Second: 10,524.23277

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.75322

Cumulative Model Updates: 204,038
Cumulative Timesteps: 1,701,683,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.96483
Policy Entropy: 2.11956
Value Function Loss: 0.01623

Mean KL Divergence: 0.02865
SB3 Clip Fraction: 0.18849
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.55685

Collected Steps per Second: 21,973.41839
Overall Steps per Second: 10,512.35974

Timestep Collection Time: 2.27630
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.75802

Cumulative Model Updates: 204,044
Cumulative Timesteps: 1,701,733,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1701733160...
Checkpoint 1701733160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.62932
Policy Entropy: 2.11984
Value Function Loss: 0.01548

Mean KL Divergence: 0.02750
SB3 Clip Fraction: 0.18134
Policy Update Magnitude: 0.55416
Value Function Update Magnitude: 0.55660

Collected Steps per Second: 22,032.39919
Overall Steps per Second: 10,598.28777

Timestep Collection Time: 2.27038
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.71982

Cumulative Model Updates: 204,050
Cumulative Timesteps: 1,701,783,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.43077
Policy Entropy: 2.12329
Value Function Loss: 0.01574

Mean KL Divergence: 0.02632
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 22,506.35769
Overall Steps per Second: 10,673.09009

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.68768

Cumulative Model Updates: 204,056
Cumulative Timesteps: 1,701,833,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1701833214...
Checkpoint 1701833214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.70784
Policy Entropy: 2.15832
Value Function Loss: 0.01545

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.18288
Policy Update Magnitude: 0.51611
Value Function Update Magnitude: 0.55698

Collected Steps per Second: 22,433.58319
Overall Steps per Second: 10,552.45060

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.74032

Cumulative Model Updates: 204,062
Cumulative Timesteps: 1,701,883,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.44277
Policy Entropy: 2.16804
Value Function Loss: 0.01566

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.15506
Policy Update Magnitude: 0.52415
Value Function Update Magnitude: 0.59551

Collected Steps per Second: 22,295.04826
Overall Steps per Second: 10,481.89074

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.53001
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.77490

Cumulative Model Updates: 204,068
Cumulative Timesteps: 1,701,933,286

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1701933286...
Checkpoint 1701933286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.77665
Policy Entropy: 2.15847
Value Function Loss: 0.01578

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.60124

Collected Steps per Second: 22,046.51072
Overall Steps per Second: 10,522.82058

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.75177

Cumulative Model Updates: 204,074
Cumulative Timesteps: 1,701,983,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.90813
Policy Entropy: 2.15041
Value Function Loss: 0.01521

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.59757

Collected Steps per Second: 22,227.58313
Overall Steps per Second: 10,574.02506

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.48020
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.73065

Cumulative Model Updates: 204,080
Cumulative Timesteps: 1,702,033,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1702033310...
Checkpoint 1702033310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.89943
Policy Entropy: 2.16363
Value Function Loss: 0.01543

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.59183

Collected Steps per Second: 22,195.75644
Overall Steps per Second: 10,547.20690

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.74173

Cumulative Model Updates: 204,086
Cumulative Timesteps: 1,702,083,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.04624
Policy Entropy: 2.14751
Value Function Loss: 0.01568

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.58022

Collected Steps per Second: 22,190.83524
Overall Steps per Second: 10,566.78998

Timestep Collection Time: 2.25408
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.73370

Cumulative Model Updates: 204,092
Cumulative Timesteps: 1,702,133,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1702133342...
Checkpoint 1702133342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.42243
Policy Entropy: 2.12870
Value Function Loss: 0.01768

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.59131

Collected Steps per Second: 22,145.30238
Overall Steps per Second: 10,560.70519

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.73775

Cumulative Model Updates: 204,098
Cumulative Timesteps: 1,702,183,376

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.92451
Policy Entropy: 2.14280
Value Function Loss: 0.01667

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 22,297.40463
Overall Steps per Second: 10,499.88877

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.52095
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.76462

Cumulative Model Updates: 204,104
Cumulative Timesteps: 1,702,233,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1702233404...
Checkpoint 1702233404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.89816
Policy Entropy: 2.14955
Value Function Loss: 0.01634

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.61206

Collected Steps per Second: 22,055.69484
Overall Steps per Second: 10,638.76543

Timestep Collection Time: 2.26744
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.70073

Cumulative Model Updates: 204,110
Cumulative Timesteps: 1,702,283,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.88518
Policy Entropy: 2.18957
Value Function Loss: 0.01579

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.59828

Collected Steps per Second: 22,512.94746
Overall Steps per Second: 10,471.58750

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.55552
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.77788

Cumulative Model Updates: 204,116
Cumulative Timesteps: 1,702,333,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1702333446...
Checkpoint 1702333446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.48545
Policy Entropy: 2.18546
Value Function Loss: 0.01507

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.56840

Collected Steps per Second: 22,051.82289
Overall Steps per Second: 10,532.79715

Timestep Collection Time: 2.26838
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.74917

Cumulative Model Updates: 204,122
Cumulative Timesteps: 1,702,383,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.52998
Policy Entropy: 2.17194
Value Function Loss: 0.01517

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 22,380.39350
Overall Steps per Second: 10,561.83026

Timestep Collection Time: 2.23544
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73687

Cumulative Model Updates: 204,128
Cumulative Timesteps: 1,702,433,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1702433498...
Checkpoint 1702433498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.21520
Policy Entropy: 2.16797
Value Function Loss: 0.01534

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.56815

Collected Steps per Second: 21,993.55157
Overall Steps per Second: 10,629.64151

Timestep Collection Time: 2.27358
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.70420

Cumulative Model Updates: 204,134
Cumulative Timesteps: 1,702,483,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.15758
Policy Entropy: 2.17047
Value Function Loss: 0.01632

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.16952
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.58535

Collected Steps per Second: 22,309.50143
Overall Steps per Second: 10,529.69935

Timestep Collection Time: 2.24129
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.74866

Cumulative Model Updates: 204,140
Cumulative Timesteps: 1,702,533,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1702533504...
Checkpoint 1702533504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.90367
Policy Entropy: 2.18069
Value Function Loss: 0.01649

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.17141
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.60333

Collected Steps per Second: 22,403.57726
Overall Steps per Second: 10,628.08429

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.70546

Cumulative Model Updates: 204,146
Cumulative Timesteps: 1,702,583,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.90170
Policy Entropy: 2.17595
Value Function Loss: 0.01596

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.60821

Collected Steps per Second: 22,484.02906
Overall Steps per Second: 10,454.86630

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.56020
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.78533

Cumulative Model Updates: 204,152
Cumulative Timesteps: 1,702,633,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1702633544...
Checkpoint 1702633544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.72196
Policy Entropy: 2.18063
Value Function Loss: 0.01559

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.57526

Collected Steps per Second: 21,679.41798
Overall Steps per Second: 10,640.57847

Timestep Collection Time: 2.30827
Timestep Consumption Time: 2.39467
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.70294

Cumulative Model Updates: 204,158
Cumulative Timesteps: 1,702,683,586

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.68933
Policy Entropy: 2.16262
Value Function Loss: 0.01551

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.53196
Value Function Update Magnitude: 0.55265

Collected Steps per Second: 22,575.16858
Overall Steps per Second: 10,472.03519

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.56103
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.77691

Cumulative Model Updates: 204,164
Cumulative Timesteps: 1,702,733,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1702733610...
Checkpoint 1702733610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.18166
Policy Entropy: 2.18168
Value Function Loss: 0.01511

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.52759
Value Function Update Magnitude: 0.54141

Collected Steps per Second: 22,340.12721
Overall Steps per Second: 10,623.12603

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.70728

Cumulative Model Updates: 204,170
Cumulative Timesteps: 1,702,783,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.38315
Policy Entropy: 2.16312
Value Function Loss: 0.01475

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.52400
Value Function Update Magnitude: 0.52098

Collected Steps per Second: 22,453.97461
Overall Steps per Second: 10,462.10125

Timestep Collection Time: 2.22696
Timestep Consumption Time: 2.55258
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.77954

Cumulative Model Updates: 204,176
Cumulative Timesteps: 1,702,833,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1702833620...
Checkpoint 1702833620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.54928
Policy Entropy: 2.18654
Value Function Loss: 0.01483

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.51724
Value Function Update Magnitude: 0.50506

Collected Steps per Second: 21,965.07225
Overall Steps per Second: 10,549.18161

Timestep Collection Time: 2.27762
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.74236

Cumulative Model Updates: 204,182
Cumulative Timesteps: 1,702,883,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.41575
Policy Entropy: 2.16026
Value Function Loss: 0.01540

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.51362

Collected Steps per Second: 22,368.10340
Overall Steps per Second: 10,687.72037

Timestep Collection Time: 2.23559
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.67883

Cumulative Model Updates: 204,188
Cumulative Timesteps: 1,702,933,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1702933654...
Checkpoint 1702933654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.11083
Policy Entropy: 2.16459
Value Function Loss: 0.01581

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.51762

Collected Steps per Second: 22,479.35085
Overall Steps per Second: 10,503.75645

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.53634
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.76096

Cumulative Model Updates: 204,194
Cumulative Timesteps: 1,702,983,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.43678
Policy Entropy: 2.13168
Value Function Loss: 0.01581

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.52721

Collected Steps per Second: 22,661.37303
Overall Steps per Second: 10,532.54502

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.54181
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.74909

Cumulative Model Updates: 204,200
Cumulative Timesteps: 1,703,033,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1703033682...
Checkpoint 1703033682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.48517
Policy Entropy: 2.14384
Value Function Loss: 0.01442

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.52429
Value Function Update Magnitude: 0.52770

Collected Steps per Second: 21,932.34911
Overall Steps per Second: 10,532.37171

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.75012

Cumulative Model Updates: 204,206
Cumulative Timesteps: 1,703,083,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.48623
Policy Entropy: 2.16474
Value Function Loss: 0.01447

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.52515
Value Function Update Magnitude: 0.50626

Collected Steps per Second: 22,288.43604
Overall Steps per Second: 10,473.15574

Timestep Collection Time: 2.24341
Timestep Consumption Time: 2.53090
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.77430

Cumulative Model Updates: 204,212
Cumulative Timesteps: 1,703,133,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1703133714...
Checkpoint 1703133714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.91441
Policy Entropy: 2.17006
Value Function Loss: 0.01507

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.53806
Value Function Update Magnitude: 0.51921

Collected Steps per Second: 21,686.99259
Overall Steps per Second: 10,646.63064

Timestep Collection Time: 2.30664
Timestep Consumption Time: 2.39194
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.69858

Cumulative Model Updates: 204,218
Cumulative Timesteps: 1,703,183,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.39038
Policy Entropy: 2.16423
Value Function Loss: 0.01528

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.54428

Collected Steps per Second: 22,486.70019
Overall Steps per Second: 10,441.47685

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.56639
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.79108

Cumulative Model Updates: 204,224
Cumulative Timesteps: 1,703,233,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1703233764...
Checkpoint 1703233764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.73828
Policy Entropy: 2.17982
Value Function Loss: 0.01558

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.54569

Collected Steps per Second: 21,982.92721
Overall Steps per Second: 10,431.82555

Timestep Collection Time: 2.27477
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.79360

Cumulative Model Updates: 204,230
Cumulative Timesteps: 1,703,283,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.26531
Policy Entropy: 2.17860
Value Function Loss: 0.01615

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.53892

Collected Steps per Second: 22,572.15701
Overall Steps per Second: 10,666.79522

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.68801

Cumulative Model Updates: 204,236
Cumulative Timesteps: 1,703,333,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1703333776...
Checkpoint 1703333776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.76918
Policy Entropy: 2.18081
Value Function Loss: 0.01662

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.54799

Collected Steps per Second: 22,323.90195
Overall Steps per Second: 10,650.53218

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.45603
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.69685

Cumulative Model Updates: 204,242
Cumulative Timesteps: 1,703,383,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.75146
Policy Entropy: 2.19488
Value Function Loss: 0.01723

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.57628

Collected Steps per Second: 22,524.87046
Overall Steps per Second: 10,453.42231

Timestep Collection Time: 2.22066
Timestep Consumption Time: 2.56438
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.78504

Cumulative Model Updates: 204,248
Cumulative Timesteps: 1,703,433,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1703433820...
Checkpoint 1703433820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.07365
Policy Entropy: 2.20313
Value Function Loss: 0.01700

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.59340

Collected Steps per Second: 21,848.46505
Overall Steps per Second: 10,388.80086

Timestep Collection Time: 2.28968
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.81538

Cumulative Model Updates: 204,254
Cumulative Timesteps: 1,703,483,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.71255
Policy Entropy: 2.19733
Value Function Loss: 0.01641

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.56624

Collected Steps per Second: 22,261.93806
Overall Steps per Second: 10,650.36787

Timestep Collection Time: 2.24679
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.69636

Cumulative Model Updates: 204,260
Cumulative Timesteps: 1,703,533,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1703533864...
Checkpoint 1703533864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.32249
Policy Entropy: 2.17664
Value Function Loss: 0.01604

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.52767
Value Function Update Magnitude: 0.53037

Collected Steps per Second: 21,979.93175
Overall Steps per Second: 10,671.71907

Timestep Collection Time: 2.27517
Timestep Consumption Time: 2.41086
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.68603

Cumulative Model Updates: 204,266
Cumulative Timesteps: 1,703,583,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.19799
Policy Entropy: 2.19298
Value Function Loss: 0.01493

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.52002
Value Function Update Magnitude: 0.53617

Collected Steps per Second: 22,569.73975
Overall Steps per Second: 10,490.42429

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.55141
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.76720

Cumulative Model Updates: 204,272
Cumulative Timesteps: 1,703,633,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1703633882...
Checkpoint 1703633882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.80348
Policy Entropy: 2.17619
Value Function Loss: 0.01478

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.55939

Collected Steps per Second: 22,147.62934
Overall Steps per Second: 10,530.56117

Timestep Collection Time: 2.25857
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.75017

Cumulative Model Updates: 204,278
Cumulative Timesteps: 1,703,683,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.85274
Policy Entropy: 2.15327
Value Function Loss: 0.01554

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 22,372.94221
Overall Steps per Second: 10,572.03300

Timestep Collection Time: 2.23493
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.72965

Cumulative Model Updates: 204,284
Cumulative Timesteps: 1,703,733,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1703733906...
Checkpoint 1703733906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.41092
Policy Entropy: 2.15425
Value Function Loss: 0.01629

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,159.35551
Overall Steps per Second: 10,622.91094

Timestep Collection Time: 2.25702
Timestep Consumption Time: 2.45111
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70813

Cumulative Model Updates: 204,290
Cumulative Timesteps: 1,703,783,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.23703
Policy Entropy: 2.13989
Value Function Loss: 0.01581

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.57485

Collected Steps per Second: 23,550.43148
Overall Steps per Second: 10,828.99387

Timestep Collection Time: 2.12327
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.61760

Cumulative Model Updates: 204,296
Cumulative Timesteps: 1,703,833,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1703833924...
Checkpoint 1703833924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.72837
Policy Entropy: 2.16598
Value Function Loss: 0.01569

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.53479

Collected Steps per Second: 21,775.72001
Overall Steps per Second: 10,294.36974

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.56150
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.85819

Cumulative Model Updates: 204,302
Cumulative Timesteps: 1,703,883,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.21468
Policy Entropy: 2.15669
Value Function Loss: 0.01504

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.53055
Value Function Update Magnitude: 0.53012

Collected Steps per Second: 22,407.41829
Overall Steps per Second: 10,463.77402

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.54739
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.77916

Cumulative Model Updates: 204,308
Cumulative Timesteps: 1,703,933,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1703933944...
Checkpoint 1703933944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.17806
Policy Entropy: 2.17432
Value Function Loss: 0.01583

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.53540
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 22,040.44716
Overall Steps per Second: 10,593.53318

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.45150
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.72024

Cumulative Model Updates: 204,314
Cumulative Timesteps: 1,703,983,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.13004
Policy Entropy: 2.17135
Value Function Loss: 0.01619

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.57582

Collected Steps per Second: 22,002.57772
Overall Steps per Second: 10,515.48411

Timestep Collection Time: 2.27310
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.75622

Cumulative Model Updates: 204,320
Cumulative Timesteps: 1,704,033,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1704033962...
Checkpoint 1704033962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.42775
Policy Entropy: 2.16461
Value Function Loss: 0.01644

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.58254

Collected Steps per Second: 22,524.88862
Overall Steps per Second: 10,606.83627

Timestep Collection Time: 2.22074
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.71602

Cumulative Model Updates: 204,326
Cumulative Timesteps: 1,704,083,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.52459
Policy Entropy: 2.14375
Value Function Loss: 0.01702

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.54920
Value Function Update Magnitude: 0.57822

Collected Steps per Second: 22,333.63892
Overall Steps per Second: 10,498.83529

Timestep Collection Time: 2.23994
Timestep Consumption Time: 2.52497
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.76491

Cumulative Model Updates: 204,332
Cumulative Timesteps: 1,704,134,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1704134010...
Checkpoint 1704134010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.15880
Policy Entropy: 2.14879
Value Function Loss: 0.01588

Mean KL Divergence: 0.02872
SB3 Clip Fraction: 0.18477
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.56805

Collected Steps per Second: 21,876.88432
Overall Steps per Second: 10,399.53285

Timestep Collection Time: 2.28680
Timestep Consumption Time: 2.52380
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.81060

Cumulative Model Updates: 204,338
Cumulative Timesteps: 1,704,184,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.59406
Policy Entropy: 2.15686
Value Function Loss: 0.01682

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.18146
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.57487

Collected Steps per Second: 22,368.84164
Overall Steps per Second: 10,632.78008

Timestep Collection Time: 2.23624
Timestep Consumption Time: 2.46827
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.70451

Cumulative Model Updates: 204,344
Cumulative Timesteps: 1,704,234,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1704234060...
Checkpoint 1704234060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.44472
Policy Entropy: 2.18523
Value Function Loss: 0.01623

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.58781

Collected Steps per Second: 22,059.62112
Overall Steps per Second: 10,722.99587

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.39763
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.66549

Cumulative Model Updates: 204,350
Cumulative Timesteps: 1,704,284,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.20971
Policy Entropy: 2.17243
Value Function Loss: 0.01740

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16036
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.59640

Collected Steps per Second: 22,400.06520
Overall Steps per Second: 10,492.24732

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.76752

Cumulative Model Updates: 204,356
Cumulative Timesteps: 1,704,334,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1704334110...
Checkpoint 1704334110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.62571
Policy Entropy: 2.15132
Value Function Loss: 0.01666

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15550
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.60677

Collected Steps per Second: 22,305.24999
Overall Steps per Second: 10,590.65373

Timestep Collection Time: 2.24324
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.72454

Cumulative Model Updates: 204,362
Cumulative Timesteps: 1,704,384,146

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.62390
Policy Entropy: 2.13884
Value Function Loss: 0.01685

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.54359
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 22,002.31637
Overall Steps per Second: 10,507.18225

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.76017

Cumulative Model Updates: 204,368
Cumulative Timesteps: 1,704,434,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1704434162...
Checkpoint 1704434162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.28844
Policy Entropy: 2.15745
Value Function Loss: 0.01698

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.53562
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,013.11731
Overall Steps per Second: 10,640.45224

Timestep Collection Time: 2.27255
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.70149

Cumulative Model Updates: 204,374
Cumulative Timesteps: 1,704,484,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.10307
Policy Entropy: 2.15420
Value Function Loss: 0.01672

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 22,405.98171
Overall Steps per Second: 10,476.23843

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.54207
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.77442

Cumulative Model Updates: 204,380
Cumulative Timesteps: 1,704,534,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1704534206...
Checkpoint 1704534206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.51943
Policy Entropy: 2.14479
Value Function Loss: 0.01705

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.53479

Collected Steps per Second: 22,104.07848
Overall Steps per Second: 10,556.47257

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.73833

Cumulative Model Updates: 204,386
Cumulative Timesteps: 1,704,584,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.88776
Policy Entropy: 2.11076
Value Function Loss: 0.01738

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.55938

Collected Steps per Second: 21,958.64222
Overall Steps per Second: 10,548.68629

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.46351
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.74106

Cumulative Model Updates: 204,392
Cumulative Timesteps: 1,704,634,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1704634238...
Checkpoint 1704634238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.09579
Policy Entropy: 2.10756
Value Function Loss: 0.01707

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.15839
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.59261

Collected Steps per Second: 22,148.01064
Overall Steps per Second: 10,604.46737

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.71499

Cumulative Model Updates: 204,398
Cumulative Timesteps: 1,704,684,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.61996
Policy Entropy: 2.09772
Value Function Loss: 0.01722

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 22,272.67668
Overall Steps per Second: 10,507.17524

Timestep Collection Time: 2.24625
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76151

Cumulative Model Updates: 204,404
Cumulative Timesteps: 1,704,734,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1704734268...
Checkpoint 1704734268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.14145
Policy Entropy: 2.12268
Value Function Loss: 0.01764

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.18870
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.57490

Collected Steps per Second: 22,260.90295
Overall Steps per Second: 10,580.05820

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.48028
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.72682

Cumulative Model Updates: 204,410
Cumulative Timesteps: 1,704,784,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.49054
Policy Entropy: 2.13677
Value Function Loss: 0.01769

Mean KL Divergence: 0.02690
SB3 Clip Fraction: 0.17734
Policy Update Magnitude: 0.55928
Value Function Update Magnitude: 0.59118

Collected Steps per Second: 22,055.11061
Overall Steps per Second: 10,499.66046

Timestep Collection Time: 2.26732
Timestep Consumption Time: 2.49531
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.76263

Cumulative Model Updates: 204,416
Cumulative Timesteps: 1,704,834,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1704834284...
Checkpoint 1704834284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.06691
Policy Entropy: 2.13673
Value Function Loss: 0.01631

Mean KL Divergence: 0.02815
SB3 Clip Fraction: 0.18513
Policy Update Magnitude: 0.52412
Value Function Update Magnitude: 0.59634

Collected Steps per Second: 22,377.80331
Overall Steps per Second: 10,617.19441

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.71179

Cumulative Model Updates: 204,422
Cumulative Timesteps: 1,704,884,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.02536
Policy Entropy: 2.12934
Value Function Loss: 0.01644

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16579
Policy Update Magnitude: 0.52826
Value Function Update Magnitude: 0.57369

Collected Steps per Second: 21,960.74243
Overall Steps per Second: 10,528.14156

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.74956

Cumulative Model Updates: 204,428
Cumulative Timesteps: 1,704,934,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1704934314...
Checkpoint 1704934314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.14078
Policy Entropy: 2.09914
Value Function Loss: 0.01572

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.56275

Collected Steps per Second: 22,314.85131
Overall Steps per Second: 10,610.32107

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.47272
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.71428

Cumulative Model Updates: 204,434
Cumulative Timesteps: 1,704,984,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.35499
Policy Entropy: 2.09905
Value Function Loss: 0.01506

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.56916

Collected Steps per Second: 22,139.33527
Overall Steps per Second: 10,434.93376

Timestep Collection Time: 2.26032
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.79562

Cumulative Model Updates: 204,440
Cumulative Timesteps: 1,705,034,376

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1705034376...
Checkpoint 1705034376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.71205
Policy Entropy: 2.11069
Value Function Loss: 0.01461

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.56263

Collected Steps per Second: 22,229.70114
Overall Steps per Second: 10,592.51233

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.47275
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.72353

Cumulative Model Updates: 204,446
Cumulative Timesteps: 1,705,084,410

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.05708
Policy Entropy: 2.13741
Value Function Loss: 0.01559

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.56633

Collected Steps per Second: 22,404.84089
Overall Steps per Second: 10,711.43310

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.67052

Cumulative Model Updates: 204,452
Cumulative Timesteps: 1,705,134,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1705134438...
Checkpoint 1705134438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.07254
Policy Entropy: 2.13014
Value Function Loss: 0.01740

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.58222

Collected Steps per Second: 22,313.62970
Overall Steps per Second: 10,459.95807

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.53966
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.78071

Cumulative Model Updates: 204,458
Cumulative Timesteps: 1,705,184,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.42275
Policy Entropy: 2.12722
Value Function Loss: 0.01680

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.59525

Collected Steps per Second: 22,090.57755
Overall Steps per Second: 10,461.11493

Timestep Collection Time: 2.26377
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.78037

Cumulative Model Updates: 204,464
Cumulative Timesteps: 1,705,234,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1705234452...
Checkpoint 1705234452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.13240
Policy Entropy: 2.13937
Value Function Loss: 0.01643

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.60567

Collected Steps per Second: 22,042.50112
Overall Steps per Second: 10,533.85381

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.74926

Cumulative Model Updates: 204,470
Cumulative Timesteps: 1,705,284,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.45290
Policy Entropy: 2.12518
Value Function Loss: 0.01510

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 22,455.77187
Overall Steps per Second: 10,558.86759

Timestep Collection Time: 2.22669
Timestep Consumption Time: 2.50886
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.73555

Cumulative Model Updates: 204,476
Cumulative Timesteps: 1,705,334,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1705334482...
Checkpoint 1705334482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.39049
Policy Entropy: 2.11725
Value Function Loss: 0.01633

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 22,112.73952
Overall Steps per Second: 10,600.05202

Timestep Collection Time: 2.26232
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71941

Cumulative Model Updates: 204,482
Cumulative Timesteps: 1,705,384,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.97056
Policy Entropy: 2.10241
Value Function Loss: 0.01677

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.57980

Collected Steps per Second: 22,195.07824
Overall Steps per Second: 10,504.79926

Timestep Collection Time: 2.25374
Timestep Consumption Time: 2.50808
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.76182

Cumulative Model Updates: 204,488
Cumulative Timesteps: 1,705,434,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1705434530...
Checkpoint 1705434530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.32229
Policy Entropy: 2.11662
Value Function Loss: 0.01681

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.16377
Policy Update Magnitude: 0.54411
Value Function Update Magnitude: 0.57074

Collected Steps per Second: 22,185.83796
Overall Steps per Second: 10,563.32922

Timestep Collection Time: 2.25549
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.73714

Cumulative Model Updates: 204,494
Cumulative Timesteps: 1,705,484,570

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.07126
Policy Entropy: 2.10587
Value Function Loss: 0.01647

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.54271
Value Function Update Magnitude: 0.57398

Collected Steps per Second: 22,027.11579
Overall Steps per Second: 10,504.14828

Timestep Collection Time: 2.27002
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.76021

Cumulative Model Updates: 204,500
Cumulative Timesteps: 1,705,534,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1705534572...
Checkpoint 1705534572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.04413
Policy Entropy: 2.13903
Value Function Loss: 0.01566

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.16438
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 22,413.29538
Overall Steps per Second: 10,654.94186

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.69341

Cumulative Model Updates: 204,506
Cumulative Timesteps: 1,705,584,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.99393
Policy Entropy: 2.12914
Value Function Loss: 0.01585

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.16213
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 22,289.24858
Overall Steps per Second: 10,476.48533

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.77527

Cumulative Model Updates: 204,512
Cumulative Timesteps: 1,705,634,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1705634608...
Checkpoint 1705634608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.79440
Policy Entropy: 2.14125
Value Function Loss: 0.01554

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.58177

Collected Steps per Second: 22,444.63976
Overall Steps per Second: 10,658.63563

Timestep Collection Time: 2.22895
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.69366

Cumulative Model Updates: 204,518
Cumulative Timesteps: 1,705,684,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.61403
Policy Entropy: 2.12221
Value Function Loss: 0.01521

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.57363

Collected Steps per Second: 22,565.54170
Overall Steps per Second: 10,601.75958

Timestep Collection Time: 2.21586
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.71639

Cumulative Model Updates: 204,524
Cumulative Timesteps: 1,705,734,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1705734638...
Checkpoint 1705734638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.61466
Policy Entropy: 2.11545
Value Function Loss: 0.01484

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.55443

Collected Steps per Second: 22,495.51905
Overall Steps per Second: 10,530.77791

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.74875

Cumulative Model Updates: 204,530
Cumulative Timesteps: 1,705,784,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.99656
Policy Entropy: 2.12553
Value Function Loss: 0.01413

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.54319
Value Function Update Magnitude: 0.54395

Collected Steps per Second: 22,216.67585
Overall Steps per Second: 10,731.05920

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.66012

Cumulative Model Updates: 204,536
Cumulative Timesteps: 1,705,834,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1705834654...
Checkpoint 1705834654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.75140
Policy Entropy: 2.11386
Value Function Loss: 0.01508

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.54505

Collected Steps per Second: 22,111.85940
Overall Steps per Second: 10,456.67664

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.78355

Cumulative Model Updates: 204,542
Cumulative Timesteps: 1,705,884,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.17974
Policy Entropy: 2.11906
Value Function Loss: 0.01525

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.53811

Collected Steps per Second: 22,644.96302
Overall Steps per Second: 10,661.78092

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.69021

Cumulative Model Updates: 204,548
Cumulative Timesteps: 1,705,934,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1705934680...
Checkpoint 1705934680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.16342
Policy Entropy: 2.12001
Value Function Loss: 0.01631

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.54305

Collected Steps per Second: 22,438.50805
Overall Steps per Second: 10,719.15438

Timestep Collection Time: 2.22956
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.66716

Cumulative Model Updates: 204,554
Cumulative Timesteps: 1,705,984,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.40402
Policy Entropy: 2.13260
Value Function Loss: 0.01550

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.55307

Collected Steps per Second: 22,268.11846
Overall Steps per Second: 10,478.62617

Timestep Collection Time: 2.24608
Timestep Consumption Time: 2.52706
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.77314

Cumulative Model Updates: 204,560
Cumulative Timesteps: 1,706,034,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1706034724...
Checkpoint 1706034724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.35153
Policy Entropy: 2.13553
Value Function Loss: 0.01633

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.54293
Value Function Update Magnitude: 0.55900

Collected Steps per Second: 22,322.29208
Overall Steps per Second: 10,609.60503

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.47418
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.71535

Cumulative Model Updates: 204,566
Cumulative Timesteps: 1,706,084,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.76305
Policy Entropy: 2.13696
Value Function Loss: 0.01525

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.56646

Collected Steps per Second: 22,289.32229
Overall Steps per Second: 10,504.35615

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.76012

Cumulative Model Updates: 204,572
Cumulative Timesteps: 1,706,134,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1706134754...
Checkpoint 1706134754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.19549
Policy Entropy: 2.13610
Value Function Loss: 0.01569

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.56560

Collected Steps per Second: 22,247.30725
Overall Steps per Second: 10,641.73927

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.69904

Cumulative Model Updates: 204,578
Cumulative Timesteps: 1,706,184,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.43698
Policy Entropy: 2.13368
Value Function Loss: 0.01567

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.54739
Value Function Update Magnitude: 0.56107

Collected Steps per Second: 22,251.36441
Overall Steps per Second: 10,651.18121

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.69450

Cumulative Model Updates: 204,584
Cumulative Timesteps: 1,706,234,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1706234762...
Checkpoint 1706234762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.33301
Policy Entropy: 2.15182
Value Function Loss: 0.01624

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.56134

Collected Steps per Second: 22,497.10991
Overall Steps per Second: 10,486.26114

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.54564
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.76814

Cumulative Model Updates: 204,590
Cumulative Timesteps: 1,706,284,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.98592
Policy Entropy: 2.14831
Value Function Loss: 0.01675

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.56175

Collected Steps per Second: 19,332.44974
Overall Steps per Second: 9,706.12494

Timestep Collection Time: 2.58633
Timestep Consumption Time: 2.56506
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 5.15139

Cumulative Model Updates: 204,596
Cumulative Timesteps: 1,706,334,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1706334762...
Checkpoint 1706334762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.06323
Policy Entropy: 2.15924
Value Function Loss: 0.01648

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.58545

Collected Steps per Second: 22,057.86026
Overall Steps per Second: 10,602.47397

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.71814

Cumulative Model Updates: 204,602
Cumulative Timesteps: 1,706,384,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.05691
Policy Entropy: 2.15274
Value Function Loss: 0.01674

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.54728
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 23,096.45131
Overall Steps per Second: 10,961.51273

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.39706
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.56233

Cumulative Model Updates: 204,608
Cumulative Timesteps: 1,706,434,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1706434796...
Checkpoint 1706434796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.80543
Policy Entropy: 2.15138
Value Function Loss: 0.01532

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 23,344.07518
Overall Steps per Second: 10,968.92059

Timestep Collection Time: 2.14221
Timestep Consumption Time: 2.41685
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.55906

Cumulative Model Updates: 204,614
Cumulative Timesteps: 1,706,484,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.54510
Policy Entropy: 2.12803
Value Function Loss: 0.01532

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 23,355.29925
Overall Steps per Second: 10,929.97037

Timestep Collection Time: 2.14196
Timestep Consumption Time: 2.43500
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.57696

Cumulative Model Updates: 204,620
Cumulative Timesteps: 1,706,534,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1706534830...
Checkpoint 1706534830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.46100
Policy Entropy: 2.11307
Value Function Loss: 0.01589

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,454.79509
Overall Steps per Second: 10,744.04279

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.65486

Cumulative Model Updates: 204,626
Cumulative Timesteps: 1,706,584,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.76669
Policy Entropy: 2.11417
Value Function Loss: 0.01712

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 22,935.43792
Overall Steps per Second: 10,929.98562

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.39473
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.57494

Cumulative Model Updates: 204,632
Cumulative Timesteps: 1,706,634,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1706634846...
Checkpoint 1706634846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.73180
Policy Entropy: 2.09900
Value Function Loss: 0.01716

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.61506

Collected Steps per Second: 22,985.64753
Overall Steps per Second: 11,033.82930

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.35662
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.53224

Cumulative Model Updates: 204,638
Cumulative Timesteps: 1,706,684,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.47233
Policy Entropy: 2.11404
Value Function Loss: 0.01680

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.55533
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 22,930.92781
Overall Steps per Second: 10,849.67414

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60972

Cumulative Model Updates: 204,644
Cumulative Timesteps: 1,706,734,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1706734868...
Checkpoint 1706734868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.79748
Policy Entropy: 2.10872
Value Function Loss: 0.01696

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 22,979.23989
Overall Steps per Second: 10,715.19882

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.66776

Cumulative Model Updates: 204,650
Cumulative Timesteps: 1,706,784,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.98466
Policy Entropy: 2.12667
Value Function Loss: 0.01698

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.58973

Collected Steps per Second: 23,158.79457
Overall Steps per Second: 10,982.96433

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.39426
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.55396

Cumulative Model Updates: 204,656
Cumulative Timesteps: 1,706,834,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1706834900...
Checkpoint 1706834900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.82643
Policy Entropy: 2.13708
Value Function Loss: 0.01651

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.58936

Collected Steps per Second: 23,527.54943
Overall Steps per Second: 11,107.58112

Timestep Collection Time: 2.12636
Timestep Consumption Time: 2.37759
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.50395

Cumulative Model Updates: 204,662
Cumulative Timesteps: 1,706,884,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.50216
Policy Entropy: 2.14704
Value Function Loss: 0.01732

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 23,342.97749
Overall Steps per Second: 10,850.26549

Timestep Collection Time: 2.14206
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.60837

Cumulative Model Updates: 204,668
Cumulative Timesteps: 1,706,934,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1706934930...
Checkpoint 1706934930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.72675
Policy Entropy: 2.16553
Value Function Loss: 0.01769

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.59558

Collected Steps per Second: 23,097.01685
Overall Steps per Second: 10,731.78516

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.65962

Cumulative Model Updates: 204,674
Cumulative Timesteps: 1,706,984,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.65547
Policy Entropy: 2.14993
Value Function Loss: 0.01873

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 22,582.95964
Overall Steps per Second: 10,798.29540

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.41727
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.63221

Cumulative Model Updates: 204,680
Cumulative Timesteps: 1,707,034,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1707034956...
Checkpoint 1707034956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.07955
Policy Entropy: 2.14455
Value Function Loss: 0.01738

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.59722

Collected Steps per Second: 23,130.83454
Overall Steps per Second: 11,102.00485

Timestep Collection Time: 2.16205
Timestep Consumption Time: 2.34254
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.50459

Cumulative Model Updates: 204,686
Cumulative Timesteps: 1,707,084,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.55405
Policy Entropy: 2.13270
Value Function Loss: 0.01743

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.52914
Value Function Update Magnitude: 0.61319

Collected Steps per Second: 23,199.88699
Overall Steps per Second: 10,897.91533

Timestep Collection Time: 2.15622
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59024

Cumulative Model Updates: 204,692
Cumulative Timesteps: 1,707,134,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1707134990...
Checkpoint 1707134990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.48010
Policy Entropy: 2.12163
Value Function Loss: 0.01727

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.17261
Policy Update Magnitude: 0.50625
Value Function Update Magnitude: 0.62390

Collected Steps per Second: 23,116.47556
Overall Steps per Second: 10,712.93326

Timestep Collection Time: 2.16305
Timestep Consumption Time: 2.50440
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.66744

Cumulative Model Updates: 204,698
Cumulative Timesteps: 1,707,184,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.85324
Policy Entropy: 2.11387
Value Function Loss: 0.01754

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.50205
Value Function Update Magnitude: 0.62467

Collected Steps per Second: 23,352.87813
Overall Steps per Second: 10,906.50687

Timestep Collection Time: 2.14124
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.58479

Cumulative Model Updates: 204,704
Cumulative Timesteps: 1,707,234,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1707234996...
Checkpoint 1707234996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.95712
Policy Entropy: 2.11256
Value Function Loss: 0.01722

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.17982
Policy Update Magnitude: 0.51490
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 23,258.19132
Overall Steps per Second: 11,149.47502

Timestep Collection Time: 2.15012
Timestep Consumption Time: 2.33511
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.48523

Cumulative Model Updates: 204,710
Cumulative Timesteps: 1,707,285,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.08800
Policy Entropy: 2.12927
Value Function Loss: 0.01688

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.18467
Policy Update Magnitude: 0.52589
Value Function Update Magnitude: 0.57944

Collected Steps per Second: 23,244.37381
Overall Steps per Second: 10,872.68019

Timestep Collection Time: 2.15175
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.60015

Cumulative Model Updates: 204,716
Cumulative Timesteps: 1,707,335,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1707335020...
Checkpoint 1707335020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.93973
Policy Entropy: 2.10594
Value Function Loss: 0.01722

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.18436
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.58853

Collected Steps per Second: 23,010.53768
Overall Steps per Second: 10,738.12407

Timestep Collection Time: 2.17344
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65742

Cumulative Model Updates: 204,722
Cumulative Timesteps: 1,707,385,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.78827
Policy Entropy: 2.11046
Value Function Loss: 0.01756

Mean KL Divergence: 0.02671
SB3 Clip Fraction: 0.18246
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 23,228.73359
Overall Steps per Second: 10,797.10338

Timestep Collection Time: 2.15311
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.63217

Cumulative Model Updates: 204,728
Cumulative Timesteps: 1,707,435,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1707435046...
Checkpoint 1707435046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.68614
Policy Entropy: 2.12440
Value Function Loss: 0.01752

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.16392
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.61986

Collected Steps per Second: 23,167.69676
Overall Steps per Second: 11,145.20019

Timestep Collection Time: 2.15844
Timestep Consumption Time: 2.32834
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.48677

Cumulative Model Updates: 204,734
Cumulative Timesteps: 1,707,485,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.35492
Policy Entropy: 2.15327
Value Function Loss: 0.01779

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.17609
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.61893

Collected Steps per Second: 23,562.61744
Overall Steps per Second: 10,867.43792

Timestep Collection Time: 2.12260
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.60219

Cumulative Model Updates: 204,740
Cumulative Timesteps: 1,707,535,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1707535066...
Checkpoint 1707535066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.63929
Policy Entropy: 2.16144
Value Function Loss: 0.01666

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 23,224.84761
Overall Steps per Second: 10,800.87893

Timestep Collection Time: 2.15313
Timestep Consumption Time: 2.47668
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.62981

Cumulative Model Updates: 204,746
Cumulative Timesteps: 1,707,585,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.94456
Policy Entropy: 2.12701
Value Function Loss: 0.01820

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.17349
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.65276

Collected Steps per Second: 23,131.30822
Overall Steps per Second: 10,754.79702

Timestep Collection Time: 2.16183
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.64965

Cumulative Model Updates: 204,752
Cumulative Timesteps: 1,707,635,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1707635078...
Checkpoint 1707635078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.36592
Policy Entropy: 2.10562
Value Function Loss: 0.01699

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16680
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 23,242.18060
Overall Steps per Second: 11,160.87214

Timestep Collection Time: 2.15255
Timestep Consumption Time: 2.33007
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.48262

Cumulative Model Updates: 204,758
Cumulative Timesteps: 1,707,685,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.09354
Policy Entropy: 2.09494
Value Function Loss: 0.01679

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 23,523.48835
Overall Steps per Second: 10,859.53962

Timestep Collection Time: 2.12596
Timestep Consumption Time: 2.47921
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.60517

Cumulative Model Updates: 204,764
Cumulative Timesteps: 1,707,735,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1707735118...
Checkpoint 1707735118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.85342
Policy Entropy: 2.08889
Value Function Loss: 0.01628

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.63035

Collected Steps per Second: 23,439.84424
Overall Steps per Second: 10,816.42772

Timestep Collection Time: 2.13389
Timestep Consumption Time: 2.49037
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.62426

Cumulative Model Updates: 204,770
Cumulative Timesteps: 1,707,785,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.45176
Policy Entropy: 2.09307
Value Function Loss: 0.01649

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.56822
Value Function Update Magnitude: 0.60841

Collected Steps per Second: 23,505.88272
Overall Steps per Second: 10,932.26910

Timestep Collection Time: 2.12823
Timestep Consumption Time: 2.44776
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.57599

Cumulative Model Updates: 204,776
Cumulative Timesteps: 1,707,835,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1707835162...
Checkpoint 1707835162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.27224
Policy Entropy: 2.08608
Value Function Loss: 0.01696

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.57130
Value Function Update Magnitude: 0.59895

Collected Steps per Second: 23,273.29339
Overall Steps per Second: 10,914.15840

Timestep Collection Time: 2.14950
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.58359

Cumulative Model Updates: 204,782
Cumulative Timesteps: 1,707,885,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.47177
Policy Entropy: 2.06759
Value Function Loss: 0.01654

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.56818
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 22,960.53327
Overall Steps per Second: 10,888.55651

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.59290

Cumulative Model Updates: 204,788
Cumulative Timesteps: 1,707,935,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1707935198...
Checkpoint 1707935198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.04166
Policy Entropy: 2.07834
Value Function Loss: 0.01733

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 23,235.03942
Overall Steps per Second: 10,816.65718

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.62269

Cumulative Model Updates: 204,794
Cumulative Timesteps: 1,707,985,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.53783
Policy Entropy: 2.09094
Value Function Loss: 0.01705

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.61437

Collected Steps per Second: 23,499.87853
Overall Steps per Second: 10,806.10010

Timestep Collection Time: 2.12801
Timestep Consumption Time: 2.49975
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.62776

Cumulative Model Updates: 204,800
Cumulative Timesteps: 1,708,035,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1708035208...
Checkpoint 1708035208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.59040
Policy Entropy: 2.12867
Value Function Loss: 0.01701

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 23,009.48310
Overall Steps per Second: 10,964.45474

Timestep Collection Time: 2.17432
Timestep Consumption Time: 2.38861
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.56293

Cumulative Model Updates: 204,806
Cumulative Timesteps: 1,708,085,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.61302
Policy Entropy: 2.11799
Value Function Loss: 0.01675

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,975.82825
Overall Steps per Second: 10,971.70806

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.38155
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.55827

Cumulative Model Updates: 204,812
Cumulative Timesteps: 1,708,135,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1708135250...
Checkpoint 1708135250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.00819
Policy Entropy: 2.12843
Value Function Loss: 0.01668

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.56764
Value Function Update Magnitude: 0.58707

Collected Steps per Second: 23,356.83978
Overall Steps per Second: 10,835.20377

Timestep Collection Time: 2.14113
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.61551

Cumulative Model Updates: 204,818
Cumulative Timesteps: 1,708,185,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.27194
Policy Entropy: 2.12172
Value Function Loss: 0.01687

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.56505
Value Function Update Magnitude: 0.57924

Collected Steps per Second: 23,527.96395
Overall Steps per Second: 10,839.11371

Timestep Collection Time: 2.12573
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.61421

Cumulative Model Updates: 204,824
Cumulative Timesteps: 1,708,235,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1708235274...
Checkpoint 1708235274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.91777
Policy Entropy: 2.12338
Value Function Loss: 0.01735

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 23,355.60610
Overall Steps per Second: 10,948.27248

Timestep Collection Time: 2.14098
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.56730

Cumulative Model Updates: 204,830
Cumulative Timesteps: 1,708,285,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.97043
Policy Entropy: 2.14925
Value Function Loss: 0.01723

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.58717

Collected Steps per Second: 22,991.70876
Overall Steps per Second: 10,910.57562

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.40878
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.58418

Cumulative Model Updates: 204,836
Cumulative Timesteps: 1,708,335,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1708335294...
Checkpoint 1708335294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.66937
Policy Entropy: 2.15397
Value Function Loss: 0.01696

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.55319
Value Function Update Magnitude: 0.58477

Collected Steps per Second: 23,295.03817
Overall Steps per Second: 11,153.64987

Timestep Collection Time: 2.14758
Timestep Consumption Time: 2.33777
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.48535

Cumulative Model Updates: 204,842
Cumulative Timesteps: 1,708,385,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.45686
Policy Entropy: 2.16807
Value Function Loss: 0.01662

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 22,754.65150
Overall Steps per Second: 10,807.24114

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62727

Cumulative Model Updates: 204,848
Cumulative Timesteps: 1,708,435,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1708435330...
Checkpoint 1708435330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.62152
Policy Entropy: 2.15387
Value Function Loss: 0.01747

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.58833

Collected Steps per Second: 22,876.31427
Overall Steps per Second: 10,766.78654

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.64410

Cumulative Model Updates: 204,854
Cumulative Timesteps: 1,708,485,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.01185
Policy Entropy: 2.13937
Value Function Loss: 0.01794

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.60682

Collected Steps per Second: 22,969.47445
Overall Steps per Second: 10,896.69535

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.59112

Cumulative Model Updates: 204,860
Cumulative Timesteps: 1,708,535,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1708535360...
Checkpoint 1708535360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.64137
Policy Entropy: 2.11540
Value Function Loss: 0.01767

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.57455
Value Function Update Magnitude: 0.62362

Collected Steps per Second: 23,204.84413
Overall Steps per Second: 10,877.32242

Timestep Collection Time: 2.15636
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.60021

Cumulative Model Updates: 204,866
Cumulative Timesteps: 1,708,585,398

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.84114
Policy Entropy: 2.12875
Value Function Loss: 0.01647

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 22,938.37029
Overall Steps per Second: 10,935.80897

Timestep Collection Time: 2.18071
Timestep Consumption Time: 2.39343
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.57415

Cumulative Model Updates: 204,872
Cumulative Timesteps: 1,708,635,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1708635420...
Checkpoint 1708635420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.98213
Policy Entropy: 2.10848
Value Function Loss: 0.01567

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.58373

Collected Steps per Second: 23,267.27061
Overall Steps per Second: 10,853.92940

Timestep Collection Time: 2.14946
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.60773

Cumulative Model Updates: 204,878
Cumulative Timesteps: 1,708,685,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.95921
Policy Entropy: 2.11402
Value Function Loss: 0.01580

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.56370

Collected Steps per Second: 23,375.28975
Overall Steps per Second: 10,892.38629

Timestep Collection Time: 2.13927
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.59091

Cumulative Model Updates: 204,884
Cumulative Timesteps: 1,708,735,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1708735438...
Checkpoint 1708735438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.18227
Policy Entropy: 2.10099
Value Function Loss: 0.01601

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.55820

Collected Steps per Second: 22,911.69521
Overall Steps per Second: 10,789.95109

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.63394

Cumulative Model Updates: 204,890
Cumulative Timesteps: 1,708,785,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.16829
Policy Entropy: 2.10564
Value Function Loss: 0.01600

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 23,154.27579
Overall Steps per Second: 10,994.57019

Timestep Collection Time: 2.15969
Timestep Consumption Time: 2.38856
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.54825

Cumulative Model Updates: 204,896
Cumulative Timesteps: 1,708,835,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1708835444...
Checkpoint 1708835444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.25426
Policy Entropy: 2.10147
Value Function Loss: 0.01578

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.56456

Collected Steps per Second: 23,053.22780
Overall Steps per Second: 10,876.94002

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.59762

Cumulative Model Updates: 204,902
Cumulative Timesteps: 1,708,885,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.11655
Policy Entropy: 2.11279
Value Function Loss: 0.01556

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.56195

Collected Steps per Second: 23,578.44634
Overall Steps per Second: 10,893.88380

Timestep Collection Time: 2.12177
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.59230

Cumulative Model Updates: 204,908
Cumulative Timesteps: 1,708,935,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1708935480...
Checkpoint 1708935480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.75182
Policy Entropy: 2.12565
Value Function Loss: 0.01566

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.58583

Collected Steps per Second: 23,189.47355
Overall Steps per Second: 11,008.62958

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.38612
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.54262

Cumulative Model Updates: 204,914
Cumulative Timesteps: 1,708,985,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.01054
Policy Entropy: 2.13234
Value Function Loss: 0.01677

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.54728
Value Function Update Magnitude: 0.58642

Collected Steps per Second: 23,273.51910
Overall Steps per Second: 11,029.71270

Timestep Collection Time: 2.15034
Timestep Consumption Time: 2.38704
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.53738

Cumulative Model Updates: 204,920
Cumulative Timesteps: 1,709,035,534

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1709035534...
Checkpoint 1709035534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.69309
Policy Entropy: 2.12871
Value Function Loss: 0.01773

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 23,297.39420
Overall Steps per Second: 11,114.77998

Timestep Collection Time: 2.14659
Timestep Consumption Time: 2.35282
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.49941

Cumulative Model Updates: 204,926
Cumulative Timesteps: 1,709,085,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.84006
Policy Entropy: 2.10112
Value Function Loss: 0.01739

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.59926

Collected Steps per Second: 23,396.13630
Overall Steps per Second: 10,906.16981

Timestep Collection Time: 2.13822
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.58694

Cumulative Model Updates: 204,932
Cumulative Timesteps: 1,709,135,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1709135570...
Checkpoint 1709135570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.40478
Policy Entropy: 2.07615
Value Function Loss: 0.01668

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.54554
Value Function Update Magnitude: 0.59966

Collected Steps per Second: 23,268.60077
Overall Steps per Second: 10,847.63455

Timestep Collection Time: 2.15011
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.61207

Cumulative Model Updates: 204,938
Cumulative Timesteps: 1,709,185,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.83942
Policy Entropy: 2.08599
Value Function Loss: 0.01539

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 23,094.64982
Overall Steps per Second: 10,809.59733

Timestep Collection Time: 2.16500
Timestep Consumption Time: 2.46052
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.62552

Cumulative Model Updates: 204,944
Cumulative Timesteps: 1,709,235,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1709235600...
Checkpoint 1709235600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.57384
Policy Entropy: 2.08978
Value Function Loss: 0.01676

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.57775

Collected Steps per Second: 23,148.88721
Overall Steps per Second: 10,974.24407

Timestep Collection Time: 2.16114
Timestep Consumption Time: 2.39753
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.55867

Cumulative Model Updates: 204,950
Cumulative Timesteps: 1,709,285,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.50097
Policy Entropy: 2.10543
Value Function Loss: 0.01709

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.59592

Collected Steps per Second: 22,779.31196
Overall Steps per Second: 10,908.26911

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.38966
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.58551

Cumulative Model Updates: 204,956
Cumulative Timesteps: 1,709,335,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1709335648...
Checkpoint 1709335648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.12595
Policy Entropy: 2.09802
Value Function Loss: 0.01762

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.60772

Collected Steps per Second: 23,389.42024
Overall Steps per Second: 10,872.44726

Timestep Collection Time: 2.13815
Timestep Consumption Time: 2.46155
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.59970

Cumulative Model Updates: 204,962
Cumulative Timesteps: 1,709,385,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.68932
Policy Entropy: 2.09132
Value Function Loss: 0.01700

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.59522

Collected Steps per Second: 22,372.35101
Overall Steps per Second: 10,685.57926

Timestep Collection Time: 2.23633
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.68220

Cumulative Model Updates: 204,968
Cumulative Timesteps: 1,709,435,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1709435690...
Checkpoint 1709435690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.69349
Policy Entropy: 2.09308
Value Function Loss: 0.01782

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.56569
Value Function Update Magnitude: 0.58304

Collected Steps per Second: 23,357.66369
Overall Steps per Second: 11,039.35038

Timestep Collection Time: 2.14182
Timestep Consumption Time: 2.38996
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.53179

Cumulative Model Updates: 204,974
Cumulative Timesteps: 1,709,485,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.02052
Policy Entropy: 2.08832
Value Function Loss: 0.01779

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.57063

Collected Steps per Second: 23,128.14656
Overall Steps per Second: 10,951.00943

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.40469
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.56725

Cumulative Model Updates: 204,980
Cumulative Timesteps: 1,709,535,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1709535734...
Checkpoint 1709535734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.05640
Policy Entropy: 2.09638
Value Function Loss: 0.01723

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.57260
Value Function Update Magnitude: 0.56667

Collected Steps per Second: 23,294.12697
Overall Steps per Second: 10,835.93272

Timestep Collection Time: 2.14810
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.61778

Cumulative Model Updates: 204,986
Cumulative Timesteps: 1,709,585,772

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.14353
Policy Entropy: 2.11248
Value Function Loss: 0.01635

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.55732
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 23,344.96722
Overall Steps per Second: 10,787.73577

Timestep Collection Time: 2.14196
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.63526

Cumulative Model Updates: 204,992
Cumulative Timesteps: 1,709,635,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1709635776...
Checkpoint 1709635776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.96981
Policy Entropy: 2.14996
Value Function Loss: 0.01556

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 23,153.97719
Overall Steps per Second: 10,983.73053

Timestep Collection Time: 2.16032
Timestep Consumption Time: 2.39369
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.55401

Cumulative Model Updates: 204,998
Cumulative Timesteps: 1,709,685,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.32852
Policy Entropy: 2.15781
Value Function Loss: 0.01482

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.53249
Value Function Update Magnitude: 0.52831

Collected Steps per Second: 23,069.85972
Overall Steps per Second: 10,983.22868

Timestep Collection Time: 2.16785
Timestep Consumption Time: 2.38564
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.55349

Cumulative Model Updates: 205,004
Cumulative Timesteps: 1,709,735,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1709735808...
Checkpoint 1709735808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.33442
Policy Entropy: 2.15587
Value Function Loss: 0.01467

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.53426

Collected Steps per Second: 23,258.82197
Overall Steps per Second: 10,824.67557

Timestep Collection Time: 2.15084
Timestep Consumption Time: 2.47064
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.62148

Cumulative Model Updates: 205,010
Cumulative Timesteps: 1,709,785,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.16141
Policy Entropy: 2.13393
Value Function Loss: 0.01623

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.54962

Collected Steps per Second: 23,578.50840
Overall Steps per Second: 10,883.35277

Timestep Collection Time: 2.12134
Timestep Consumption Time: 2.47449
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.59583

Cumulative Model Updates: 205,016
Cumulative Timesteps: 1,709,835,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1709835852...
Checkpoint 1709835852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.29003
Policy Entropy: 2.12326
Value Function Loss: 0.01682

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.57690

Collected Steps per Second: 23,187.27131
Overall Steps per Second: 11,000.24511

Timestep Collection Time: 2.15843
Timestep Consumption Time: 2.39129
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.54972

Cumulative Model Updates: 205,022
Cumulative Timesteps: 1,709,885,900

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.62805
Policy Entropy: 2.10812
Value Function Loss: 0.01647

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.58775

Collected Steps per Second: 23,041.87588
Overall Steps per Second: 10,857.99099

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.60656

Cumulative Model Updates: 205,028
Cumulative Timesteps: 1,709,935,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1709935918...
Checkpoint 1709935918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.85244
Policy Entropy: 2.11789
Value Function Loss: 0.01565

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.55295

Collected Steps per Second: 23,375.38460
Overall Steps per Second: 10,841.26194

Timestep Collection Time: 2.13994
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.61404

Cumulative Model Updates: 205,034
Cumulative Timesteps: 1,709,985,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.01388
Policy Entropy: 2.11205
Value Function Loss: 0.01666

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.56322

Collected Steps per Second: 23,349.21106
Overall Steps per Second: 10,766.12516

Timestep Collection Time: 2.14174
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.64494

Cumulative Model Updates: 205,040
Cumulative Timesteps: 1,710,035,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1710035948...
Checkpoint 1710035948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.01137
Policy Entropy: 2.11039
Value Function Loss: 0.01688

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.57264

Collected Steps per Second: 23,054.20739
Overall Steps per Second: 10,945.29405

Timestep Collection Time: 2.17010
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.57091

Cumulative Model Updates: 205,046
Cumulative Timesteps: 1,710,085,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.79254
Policy Entropy: 2.09491
Value Function Loss: 0.01773

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.56880

Collected Steps per Second: 23,392.42764
Overall Steps per Second: 11,019.53378

Timestep Collection Time: 2.13838
Timestep Consumption Time: 2.40101
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.53939

Cumulative Model Updates: 205,052
Cumulative Timesteps: 1,710,136,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1710136000...
Checkpoint 1710136000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.66157
Policy Entropy: 2.10963
Value Function Loss: 0.01706

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.55638
Value Function Update Magnitude: 0.57777

Collected Steps per Second: 23,484.80390
Overall Steps per Second: 11,002.63588

Timestep Collection Time: 2.12904
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.54437

Cumulative Model Updates: 205,058
Cumulative Timesteps: 1,710,186,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.66538
Policy Entropy: 2.10916
Value Function Loss: 0.01616

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.58619

Collected Steps per Second: 23,171.51452
Overall Steps per Second: 10,926.76776

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.57683

Cumulative Model Updates: 205,064
Cumulative Timesteps: 1,710,236,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1710236010...
Checkpoint 1710236010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.33375
Policy Entropy: 2.09608
Value Function Loss: 0.01578

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 23,232.14866
Overall Steps per Second: 10,740.97673

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.50518
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.65935

Cumulative Model Updates: 205,070
Cumulative Timesteps: 1,710,286,056

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.01673
Policy Entropy: 2.09116
Value Function Loss: 0.01614

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.55262

Collected Steps per Second: 23,029.46275
Overall Steps per Second: 10,937.49915

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.40126
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.57326

Cumulative Model Updates: 205,076
Cumulative Timesteps: 1,710,336,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1710336076...
Checkpoint 1710336076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.19693
Policy Entropy: 2.10407
Value Function Loss: 0.01628

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.54815

Collected Steps per Second: 24,013.08418
Overall Steps per Second: 11,127.40044

Timestep Collection Time: 2.08270
Timestep Consumption Time: 2.41179
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.49449

Cumulative Model Updates: 205,082
Cumulative Timesteps: 1,710,386,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.22630
Policy Entropy: 2.09564
Value Function Loss: 0.01666

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.54602

Collected Steps per Second: 23,483.22447
Overall Steps per Second: 10,903.75911

Timestep Collection Time: 2.13020
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.58778

Cumulative Model Updates: 205,088
Cumulative Timesteps: 1,710,436,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1710436112...
Checkpoint 1710436112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.98595
Policy Entropy: 2.10968
Value Function Loss: 0.01707

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.53635

Collected Steps per Second: 23,200.06825
Overall Steps per Second: 10,845.52477

Timestep Collection Time: 2.15551
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.61093

Cumulative Model Updates: 205,094
Cumulative Timesteps: 1,710,486,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.78640
Policy Entropy: 2.11657
Value Function Loss: 0.01636

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.55398

Collected Steps per Second: 23,243.48421
Overall Steps per Second: 10,860.06938

Timestep Collection Time: 2.15191
Timestep Consumption Time: 2.45376
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.60568

Cumulative Model Updates: 205,100
Cumulative Timesteps: 1,710,536,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1710536138...
Checkpoint 1710536138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.24525
Policy Entropy: 2.11886
Value Function Loss: 0.01624

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.57418

Collected Steps per Second: 23,316.40254
Overall Steps per Second: 10,956.13482

Timestep Collection Time: 2.14493
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.56475

Cumulative Model Updates: 205,106
Cumulative Timesteps: 1,710,586,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.58708
Policy Entropy: 2.13849
Value Function Loss: 0.01543

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.58280

Collected Steps per Second: 23,281.54671
Overall Steps per Second: 10,904.41444

Timestep Collection Time: 2.14874
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.58768

Cumulative Model Updates: 205,112
Cumulative Timesteps: 1,710,636,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1710636176...
Checkpoint 1710636176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.08654
Policy Entropy: 2.13530
Value Function Loss: 0.01592

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.58248

Collected Steps per Second: 23,358.87840
Overall Steps per Second: 10,990.30886

Timestep Collection Time: 2.14163
Timestep Consumption Time: 2.41020
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.55183

Cumulative Model Updates: 205,118
Cumulative Timesteps: 1,710,686,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.39574
Policy Entropy: 2.13725
Value Function Loss: 0.01610

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 23,233.44263
Overall Steps per Second: 10,920.61215

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.57978

Cumulative Model Updates: 205,124
Cumulative Timesteps: 1,710,736,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1710736216...
Checkpoint 1710736216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.58410
Policy Entropy: 2.13921
Value Function Loss: 0.01637

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.60663

Collected Steps per Second: 23,386.24743
Overall Steps per Second: 11,128.82948

Timestep Collection Time: 2.13809
Timestep Consumption Time: 2.35492
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.49302

Cumulative Model Updates: 205,130
Cumulative Timesteps: 1,710,786,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.44794
Policy Entropy: 2.11118
Value Function Loss: 0.01592

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.55196
Value Function Update Magnitude: 0.60217

Collected Steps per Second: 23,531.07668
Overall Steps per Second: 10,988.63894

Timestep Collection Time: 2.12553
Timestep Consumption Time: 2.42608
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.55161

Cumulative Model Updates: 205,136
Cumulative Timesteps: 1,710,836,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1710836234...
Checkpoint 1710836234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.66784
Policy Entropy: 2.12287
Value Function Loss: 0.01605

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 23,402.63276
Overall Steps per Second: 11,001.77256

Timestep Collection Time: 2.13728
Timestep Consumption Time: 2.40908
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.54636

Cumulative Model Updates: 205,142
Cumulative Timesteps: 1,710,886,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.70143
Policy Entropy: 2.12169
Value Function Loss: 0.01568

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.56289

Collected Steps per Second: 23,402.92429
Overall Steps per Second: 11,017.19888

Timestep Collection Time: 2.13657
Timestep Consumption Time: 2.40197
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.53854

Cumulative Model Updates: 205,148
Cumulative Timesteps: 1,710,936,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1710936254...
Checkpoint 1710936254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.58279
Policy Entropy: 2.14180
Value Function Loss: 0.01614

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.52338
Value Function Update Magnitude: 0.57059

Collected Steps per Second: 23,998.25244
Overall Steps per Second: 11,126.34212

Timestep Collection Time: 2.08382
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.49456

Cumulative Model Updates: 205,154
Cumulative Timesteps: 1,710,986,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.04384
Policy Entropy: 2.14157
Value Function Loss: 0.01608

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.56654

Collected Steps per Second: 23,515.25130
Overall Steps per Second: 10,885.35221

Timestep Collection Time: 2.12722
Timestep Consumption Time: 2.46813
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.59535

Cumulative Model Updates: 205,160
Cumulative Timesteps: 1,711,036,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1711036284...
Checkpoint 1711036284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.08755
Policy Entropy: 2.13593
Value Function Loss: 0.01657

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.54794

Collected Steps per Second: 23,007.92139
Overall Steps per Second: 10,850.44860

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.60958

Cumulative Model Updates: 205,166
Cumulative Timesteps: 1,711,086,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.88267
Policy Entropy: 2.11105
Value Function Loss: 0.01795

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.54342

Collected Steps per Second: 23,329.38774
Overall Steps per Second: 10,889.23712

Timestep Collection Time: 2.14425
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.59389

Cumulative Model Updates: 205,172
Cumulative Timesteps: 1,711,136,324

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1711136324...
Checkpoint 1711136324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.23268
Policy Entropy: 2.10988
Value Function Loss: 0.01716

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.55121
Value Function Update Magnitude: 0.56023

Collected Steps per Second: 23,409.93409
Overall Steps per Second: 11,027.64139

Timestep Collection Time: 2.13610
Timestep Consumption Time: 2.39850
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.53461

Cumulative Model Updates: 205,178
Cumulative Timesteps: 1,711,186,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.47487
Policy Entropy: 2.09337
Value Function Loss: 0.01755

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.57947

Collected Steps per Second: 23,318.89689
Overall Steps per Second: 10,796.08489

Timestep Collection Time: 2.14513
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.63335

Cumulative Model Updates: 205,184
Cumulative Timesteps: 1,711,236,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1711236352...
Checkpoint 1711236352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.79108
Policy Entropy: 2.09907
Value Function Loss: 0.01676

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.56776

Collected Steps per Second: 22,394.10819
Overall Steps per Second: 10,607.58385

Timestep Collection Time: 2.23344
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.71512

Cumulative Model Updates: 205,190
Cumulative Timesteps: 1,711,286,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.47025
Policy Entropy: 2.08590
Value Function Loss: 0.01647

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.57798

Collected Steps per Second: 23,169.96157
Overall Steps per Second: 10,968.56048

Timestep Collection Time: 2.15814
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.55885

Cumulative Model Updates: 205,196
Cumulative Timesteps: 1,711,336,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1711336372...
Checkpoint 1711336372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.27309
Policy Entropy: 2.10644
Value Function Loss: 0.01593

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.58878

Collected Steps per Second: 23,213.71955
Overall Steps per Second: 11,040.25526

Timestep Collection Time: 2.15485
Timestep Consumption Time: 2.37603
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.53087

Cumulative Model Updates: 205,202
Cumulative Timesteps: 1,711,386,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.12516
Policy Entropy: 2.11567
Value Function Loss: 0.01501

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.53447
Value Function Update Magnitude: 0.58717

Collected Steps per Second: 23,345.49001
Overall Steps per Second: 10,924.20938

Timestep Collection Time: 2.14286
Timestep Consumption Time: 2.43652
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.57937

Cumulative Model Updates: 205,208
Cumulative Timesteps: 1,711,436,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1711436420...
Checkpoint 1711436420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.07374
Policy Entropy: 2.13403
Value Function Loss: 0.01435

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.58066

Collected Steps per Second: 23,136.28234
Overall Steps per Second: 10,794.98571

Timestep Collection Time: 2.16171
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.63308

Cumulative Model Updates: 205,214
Cumulative Timesteps: 1,711,486,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.77451
Policy Entropy: 2.15168
Value Function Loss: 0.01462

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.51626
Value Function Update Magnitude: 0.55057

Collected Steps per Second: 23,407.00993
Overall Steps per Second: 10,821.24737

Timestep Collection Time: 2.13645
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.62128

Cumulative Model Updates: 205,220
Cumulative Timesteps: 1,711,536,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1711536442...
Checkpoint 1711536442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.14316
Policy Entropy: 2.14481
Value Function Loss: 0.01572

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.52489
Value Function Update Magnitude: 0.54241

Collected Steps per Second: 23,355.91389
Overall Steps per Second: 11,048.31098

Timestep Collection Time: 2.14181
Timestep Consumption Time: 2.38594
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.52775

Cumulative Model Updates: 205,226
Cumulative Timesteps: 1,711,586,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.95319
Policy Entropy: 2.14311
Value Function Loss: 0.01662

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.55228

Collected Steps per Second: 23,453.62478
Overall Steps per Second: 10,924.84516

Timestep Collection Time: 2.13298
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.57910

Cumulative Model Updates: 205,232
Cumulative Timesteps: 1,711,636,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1711636492...
Checkpoint 1711636492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.49488
Policy Entropy: 2.12107
Value Function Loss: 0.01737

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14990
Policy Update Magnitude: 0.53015
Value Function Update Magnitude: 0.54596

Collected Steps per Second: 23,530.98688
Overall Steps per Second: 10,874.40476

Timestep Collection Time: 2.12571
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.59979

Cumulative Model Updates: 205,238
Cumulative Timesteps: 1,711,686,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.94174
Policy Entropy: 2.14391
Value Function Loss: 0.01755

Mean KL Divergence: 0.02701
SB3 Clip Fraction: 0.17912
Policy Update Magnitude: 0.50747
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 23,020.96695
Overall Steps per Second: 11,066.07372

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.34760
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.52066

Cumulative Model Updates: 205,244
Cumulative Timesteps: 1,711,736,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1711736538...
Checkpoint 1711736538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.80915
Policy Entropy: 2.12739
Value Function Loss: 0.01689

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.17383
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.55673

Collected Steps per Second: 23,505.07215
Overall Steps per Second: 10,842.09057

Timestep Collection Time: 2.12754
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.61239

Cumulative Model Updates: 205,250
Cumulative Timesteps: 1,711,786,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.03507
Policy Entropy: 2.14366
Value Function Loss: 0.01484

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.57657

Collected Steps per Second: 23,293.88541
Overall Steps per Second: 10,784.11433

Timestep Collection Time: 2.14743
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.63849

Cumulative Model Updates: 205,256
Cumulative Timesteps: 1,711,836,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1711836568...
Checkpoint 1711836568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.58867
Policy Entropy: 2.14263
Value Function Loss: 0.01465

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.54606

Collected Steps per Second: 23,269.32316
Overall Steps per Second: 10,829.00563

Timestep Collection Time: 2.14961
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.61908

Cumulative Model Updates: 205,262
Cumulative Timesteps: 1,711,886,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.48347
Policy Entropy: 2.14600
Value Function Loss: 0.01531

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.54322

Collected Steps per Second: 23,353.36613
Overall Steps per Second: 10,881.71360

Timestep Collection Time: 2.14170
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.59633

Cumulative Model Updates: 205,268
Cumulative Timesteps: 1,711,936,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1711936604...
Checkpoint 1711936604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.01193
Policy Entropy: 2.14845
Value Function Loss: 0.01557

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.55884

Collected Steps per Second: 23,384.88579
Overall Steps per Second: 10,967.77612

Timestep Collection Time: 2.13925
Timestep Consumption Time: 2.42193
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.56118

Cumulative Model Updates: 205,274
Cumulative Timesteps: 1,711,986,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.01284
Policy Entropy: 2.16229
Value Function Loss: 0.01578

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.55785

Collected Steps per Second: 23,298.95459
Overall Steps per Second: 10,919.23222

Timestep Collection Time: 2.14679
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.58073

Cumulative Model Updates: 205,280
Cumulative Timesteps: 1,712,036,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1712036648...
Checkpoint 1712036648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.88772
Policy Entropy: 2.16627
Value Function Loss: 0.01565

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 23,354.01235
Overall Steps per Second: 10,882.17531

Timestep Collection Time: 2.14156
Timestep Consumption Time: 2.45440
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.59596

Cumulative Model Updates: 205,286
Cumulative Timesteps: 1,712,086,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.00408
Policy Entropy: 2.17925
Value Function Loss: 0.01622

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.55517

Collected Steps per Second: 23,105.47830
Overall Steps per Second: 10,873.03032

Timestep Collection Time: 2.16434
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.59927

Cumulative Model Updates: 205,292
Cumulative Timesteps: 1,712,136,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1712136670...
Checkpoint 1712136670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.31032
Policy Entropy: 2.17020
Value Function Loss: 0.01597

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.54588

Collected Steps per Second: 23,092.96521
Overall Steps per Second: 10,884.33598

Timestep Collection Time: 2.16603
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.59560

Cumulative Model Updates: 205,298
Cumulative Timesteps: 1,712,186,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.47030
Policy Entropy: 2.15630
Value Function Loss: 0.01614

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.54118
Value Function Update Magnitude: 0.53911

Collected Steps per Second: 23,829.35665
Overall Steps per Second: 10,929.61511

Timestep Collection Time: 2.09909
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.57656

Cumulative Model Updates: 205,304
Cumulative Timesteps: 1,712,236,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1712236710...
Checkpoint 1712236710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.16786
Policy Entropy: 2.16631
Value Function Loss: 0.01528

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.53977

Collected Steps per Second: 23,310.20251
Overall Steps per Second: 10,837.46928

Timestep Collection Time: 2.14627
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.61639

Cumulative Model Updates: 205,310
Cumulative Timesteps: 1,712,286,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.87483
Policy Entropy: 2.15691
Value Function Loss: 0.01487

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.53936

Collected Steps per Second: 23,459.50692
Overall Steps per Second: 10,904.03390

Timestep Collection Time: 2.13150
Timestep Consumption Time: 2.45432
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.58583

Cumulative Model Updates: 205,316
Cumulative Timesteps: 1,712,336,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1712336744...
Checkpoint 1712336744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.15038
Policy Entropy: 2.15807
Value Function Loss: 0.01486

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.51659
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 23,007.15533
Overall Steps per Second: 10,908.86784

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.58563

Cumulative Model Updates: 205,322
Cumulative Timesteps: 1,712,386,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.66778
Policy Entropy: 2.16372
Value Function Loss: 0.01492

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.51840

Collected Steps per Second: 23,212.70224
Overall Steps per Second: 10,892.26786

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.59078

Cumulative Model Updates: 205,328
Cumulative Timesteps: 1,712,436,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1712436772...
Checkpoint 1712436772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.63718
Policy Entropy: 2.17363
Value Function Loss: 0.01544

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.51362
Value Function Update Magnitude: 0.49435

Collected Steps per Second: 23,192.17136
Overall Steps per Second: 10,798.76632

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.63220

Cumulative Model Updates: 205,334
Cumulative Timesteps: 1,712,486,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.33964
Policy Entropy: 2.19736
Value Function Loss: 0.01512

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.50954
Value Function Update Magnitude: 0.52128

Collected Steps per Second: 23,701.06527
Overall Steps per Second: 10,902.79183

Timestep Collection Time: 2.11079
Timestep Consumption Time: 2.47776
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.58855

Cumulative Model Updates: 205,340
Cumulative Timesteps: 1,712,536,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1712536822...
Checkpoint 1712536822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.13329
Policy Entropy: 2.18626
Value Function Loss: 0.01578

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.51658
Value Function Update Magnitude: 0.53681

Collected Steps per Second: 23,263.77182
Overall Steps per Second: 10,965.04210

Timestep Collection Time: 2.14969
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.56086

Cumulative Model Updates: 205,346
Cumulative Timesteps: 1,712,586,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.54410
Policy Entropy: 2.17431
Value Function Loss: 0.01480

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.51689
Value Function Update Magnitude: 0.53992

Collected Steps per Second: 23,307.07276
Overall Steps per Second: 10,952.80297

Timestep Collection Time: 2.14570
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.56595

Cumulative Model Updates: 205,352
Cumulative Timesteps: 1,712,636,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1712636842...
Checkpoint 1712636842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.46107
Policy Entropy: 2.14942
Value Function Loss: 0.01528

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.52405
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 23,477.02617
Overall Steps per Second: 10,977.66241

Timestep Collection Time: 2.13000
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.55525

Cumulative Model Updates: 205,358
Cumulative Timesteps: 1,712,686,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.65536
Policy Entropy: 2.16549
Value Function Loss: 0.01506

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.53218
Value Function Update Magnitude: 0.56157

Collected Steps per Second: 23,277.07211
Overall Steps per Second: 10,918.95680

Timestep Collection Time: 2.14812
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.57938

Cumulative Model Updates: 205,364
Cumulative Timesteps: 1,712,736,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1712736850...
Checkpoint 1712736850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.97787
Policy Entropy: 2.16227
Value Function Loss: 0.01603

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.53052
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 22,986.28163
Overall Steps per Second: 10,784.53317

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.46165
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.63738

Cumulative Model Updates: 205,370
Cumulative Timesteps: 1,712,786,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.56148
Policy Entropy: 2.19138
Value Function Loss: 0.01580

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.52977
Value Function Update Magnitude: 0.53222

Collected Steps per Second: 22,997.65617
Overall Steps per Second: 10,864.28116

Timestep Collection Time: 2.17413
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.60224

Cumulative Model Updates: 205,376
Cumulative Timesteps: 1,712,836,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1712836862...
Checkpoint 1712836862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.08231
Policy Entropy: 2.17433
Value Function Loss: 0.01626

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.55316

Collected Steps per Second: 23,436.72113
Overall Steps per Second: 10,963.37244

Timestep Collection Time: 2.13451
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.56301

Cumulative Model Updates: 205,382
Cumulative Timesteps: 1,712,886,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.69754
Policy Entropy: 2.16990
Value Function Loss: 0.01561

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.56492

Collected Steps per Second: 22,986.72719
Overall Steps per Second: 10,767.38251

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.46868
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.64403

Cumulative Model Updates: 205,388
Cumulative Timesteps: 1,712,936,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1712936892...
Checkpoint 1712936892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.96657
Policy Entropy: 2.15167
Value Function Loss: 0.01548

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.55167

Collected Steps per Second: 23,123.43868
Overall Steps per Second: 10,878.82902

Timestep Collection Time: 2.16291
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.59737

Cumulative Model Updates: 205,394
Cumulative Timesteps: 1,712,986,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.28684
Policy Entropy: 2.13938
Value Function Loss: 0.01541

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.53090
Value Function Update Magnitude: 0.54481

Collected Steps per Second: 23,225.74172
Overall Steps per Second: 10,913.75408

Timestep Collection Time: 2.15296
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.58174

Cumulative Model Updates: 205,400
Cumulative Timesteps: 1,713,036,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1713036910...
Checkpoint 1713036910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.35631
Policy Entropy: 2.15109
Value Function Loss: 0.01645

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.55340

Collected Steps per Second: 23,495.69185
Overall Steps per Second: 11,039.46961

Timestep Collection Time: 2.12805
Timestep Consumption Time: 2.40115
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.52920

Cumulative Model Updates: 205,406
Cumulative Timesteps: 1,713,086,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.32724
Policy Entropy: 2.14906
Value Function Loss: 0.01669

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.54467
Value Function Update Magnitude: 0.55877

Collected Steps per Second: 23,424.39427
Overall Steps per Second: 10,995.10952

Timestep Collection Time: 2.13504
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.54857

Cumulative Model Updates: 205,412
Cumulative Timesteps: 1,713,136,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1713136922...
Checkpoint 1713136922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.96468
Policy Entropy: 2.15838
Value Function Loss: 0.01672

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 23,185.31235
Overall Steps per Second: 10,818.56354

Timestep Collection Time: 2.15697
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.62261

Cumulative Model Updates: 205,418
Cumulative Timesteps: 1,713,186,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.82879
Policy Entropy: 2.17267
Value Function Loss: 0.01564

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.53219
Value Function Update Magnitude: 0.55239

Collected Steps per Second: 23,160.17505
Overall Steps per Second: 11,098.71044

Timestep Collection Time: 2.16009
Timestep Consumption Time: 2.34746
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.50755

Cumulative Model Updates: 205,424
Cumulative Timesteps: 1,713,236,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1713236960...
Checkpoint 1713236960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.14941
Policy Entropy: 2.17275
Value Function Loss: 0.01491

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.52597
Value Function Update Magnitude: 0.54626

Collected Steps per Second: 22,457.95757
Overall Steps per Second: 10,772.45871

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.41537
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.64202

Cumulative Model Updates: 205,430
Cumulative Timesteps: 1,713,286,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.78272
Policy Entropy: 2.16829
Value Function Loss: 0.01540

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.53314
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 23,671.50291
Overall Steps per Second: 10,815.62256

Timestep Collection Time: 2.11326
Timestep Consumption Time: 2.51190
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.62516

Cumulative Model Updates: 205,436
Cumulative Timesteps: 1,713,336,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1713336990...
Checkpoint 1713336990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.19743
Policy Entropy: 2.17370
Value Function Loss: 0.01504

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.52927
Value Function Update Magnitude: 0.52583

Collected Steps per Second: 23,279.54203
Overall Steps per Second: 10,828.50938

Timestep Collection Time: 2.14798
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.61781

Cumulative Model Updates: 205,442
Cumulative Timesteps: 1,713,386,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.24237
Policy Entropy: 2.18127
Value Function Loss: 0.01624

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.51370

Collected Steps per Second: 23,436.79892
Overall Steps per Second: 11,165.34411

Timestep Collection Time: 2.13399
Timestep Consumption Time: 2.34540
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.47940

Cumulative Model Updates: 205,448
Cumulative Timesteps: 1,713,437,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1713437008...
Checkpoint 1713437008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.98723
Policy Entropy: 2.18356
Value Function Loss: 0.01541

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.52454
Value Function Update Magnitude: 0.51599

Collected Steps per Second: 23,435.13079
Overall Steps per Second: 10,721.16823

Timestep Collection Time: 2.13415
Timestep Consumption Time: 2.53083
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.66498

Cumulative Model Updates: 205,454
Cumulative Timesteps: 1,713,487,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.11517
Policy Entropy: 2.18470
Value Function Loss: 0.01635

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.51254
Value Function Update Magnitude: 0.52245

Collected Steps per Second: 23,591.05912
Overall Steps per Second: 10,861.45227

Timestep Collection Time: 2.11953
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.60362

Cumulative Model Updates: 205,460
Cumulative Timesteps: 1,713,537,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1713537024...
Checkpoint 1713537024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.04816
Policy Entropy: 2.19079
Value Function Loss: 0.01613

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.18257
Policy Update Magnitude: 0.50788
Value Function Update Magnitude: 0.52418

Collected Steps per Second: 23,447.63182
Overall Steps per Second: 10,995.49949

Timestep Collection Time: 2.13267
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.54786

Cumulative Model Updates: 205,466
Cumulative Timesteps: 1,713,587,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.96927
Policy Entropy: 2.17228
Value Function Loss: 0.01641

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.17413
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.55243

Collected Steps per Second: 23,100.71134
Overall Steps per Second: 10,940.11485

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.57125

Cumulative Model Updates: 205,472
Cumulative Timesteps: 1,713,637,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1713637040...
Checkpoint 1713637040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.73092
Policy Entropy: 2.16823
Value Function Loss: 0.01550

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.17527
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.55622

Collected Steps per Second: 22,984.31597
Overall Steps per Second: 10,915.63615

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.58315

Cumulative Model Updates: 205,478
Cumulative Timesteps: 1,713,687,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.45636
Policy Entropy: 2.15733
Value Function Loss: 0.01627

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 23,543.96594
Overall Steps per Second: 10,916.04943

Timestep Collection Time: 2.12496
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.58316

Cumulative Model Updates: 205,484
Cumulative Timesteps: 1,713,737,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1713737098...
Checkpoint 1713737098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.24603
Policy Entropy: 2.18721
Value Function Loss: 0.01605

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.17140
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.57130

Collected Steps per Second: 23,328.00097
Overall Steps per Second: 10,912.28205

Timestep Collection Time: 2.14420
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.58383

Cumulative Model Updates: 205,490
Cumulative Timesteps: 1,713,787,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.68407
Policy Entropy: 2.18890
Value Function Loss: 0.01663

Mean KL Divergence: 0.03024
SB3 Clip Fraction: 0.18978
Policy Update Magnitude: 0.49762
Value Function Update Magnitude: 0.56294

Collected Steps per Second: 23,291.41819
Overall Steps per Second: 10,892.58760

Timestep Collection Time: 2.14731
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.59156

Cumulative Model Updates: 205,496
Cumulative Timesteps: 1,713,837,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1713837132...
Checkpoint 1713837132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.73859
Policy Entropy: 2.20477
Value Function Loss: 0.01584

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.52059
Value Function Update Magnitude: 0.55710

Collected Steps per Second: 23,205.72381
Overall Steps per Second: 10,999.89392

Timestep Collection Time: 2.15602
Timestep Consumption Time: 2.39239
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.54841

Cumulative Model Updates: 205,502
Cumulative Timesteps: 1,713,887,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.66482
Policy Entropy: 2.21168
Value Function Loss: 0.01532

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.52763
Value Function Update Magnitude: 0.55024

Collected Steps per Second: 23,936.76971
Overall Steps per Second: 11,043.20096

Timestep Collection Time: 2.08950
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.52912

Cumulative Model Updates: 205,508
Cumulative Timesteps: 1,713,937,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1713937180...
Checkpoint 1713937180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.28520
Policy Entropy: 2.21972
Value Function Loss: 0.01514

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 23,287.44407
Overall Steps per Second: 10,836.09012

Timestep Collection Time: 2.14742
Timestep Consumption Time: 2.46753
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.61495

Cumulative Model Updates: 205,514
Cumulative Timesteps: 1,713,987,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.31838
Policy Entropy: 2.20486
Value Function Loss: 0.01545

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 23,002.99179
Overall Steps per Second: 10,665.64981

Timestep Collection Time: 2.17459
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.69001

Cumulative Model Updates: 205,520
Cumulative Timesteps: 1,714,037,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1714037210...
Checkpoint 1714037210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.92991
Policy Entropy: 2.22399
Value Function Loss: 0.01458

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.58423

Collected Steps per Second: 23,107.25391
Overall Steps per Second: 10,826.01738

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.45547
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.61998

Cumulative Model Updates: 205,526
Cumulative Timesteps: 1,714,087,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.09396
Policy Entropy: 2.21714
Value Function Loss: 0.01493

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.53197
Value Function Update Magnitude: 0.57012

Collected Steps per Second: 23,397.24783
Overall Steps per Second: 10,857.91200

Timestep Collection Time: 2.13820
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.60752

Cumulative Model Updates: 205,532
Cumulative Timesteps: 1,714,137,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1714137254...
Checkpoint 1714137254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.56632
Policy Entropy: 2.22726
Value Function Loss: 0.01479

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.54873

Collected Steps per Second: 23,362.28539
Overall Steps per Second: 10,998.41072

Timestep Collection Time: 2.14046
Timestep Consumption Time: 2.40620
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.54666

Cumulative Model Updates: 205,538
Cumulative Timesteps: 1,714,187,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.75997
Policy Entropy: 2.22976
Value Function Loss: 0.01496

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.51893
Value Function Update Magnitude: 0.52633

Collected Steps per Second: 23,561.48112
Overall Steps per Second: 10,890.46078

Timestep Collection Time: 2.12253
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.59209

Cumulative Model Updates: 205,544
Cumulative Timesteps: 1,714,237,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1714237270...
Checkpoint 1714237270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.65632
Policy Entropy: 2.22394
Value Function Loss: 0.01453

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.52650

Collected Steps per Second: 23,057.99915
Overall Steps per Second: 10,720.48021

Timestep Collection Time: 2.16966
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66658

Cumulative Model Updates: 205,550
Cumulative Timesteps: 1,714,287,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.81468
Policy Entropy: 2.20936
Value Function Loss: 0.01481

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.52044
Value Function Update Magnitude: 0.52871

Collected Steps per Second: 23,462.09820
Overall Steps per Second: 10,821.68122

Timestep Collection Time: 2.13246
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.62331

Cumulative Model Updates: 205,556
Cumulative Timesteps: 1,714,337,330

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1714337330...
Checkpoint 1714337330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.68502
Policy Entropy: 2.18600
Value Function Loss: 0.01612

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.53864

Collected Steps per Second: 24,078.50355
Overall Steps per Second: 11,144.29787

Timestep Collection Time: 2.07721
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.48804

Cumulative Model Updates: 205,562
Cumulative Timesteps: 1,714,387,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.13237
Policy Entropy: 2.18924
Value Function Loss: 0.01530

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.53442
Value Function Update Magnitude: 0.56512

Collected Steps per Second: 23,260.75811
Overall Steps per Second: 10,939.19479

Timestep Collection Time: 2.15006
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.57182

Cumulative Model Updates: 205,568
Cumulative Timesteps: 1,714,437,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1714437358...
Checkpoint 1714437358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.99531
Policy Entropy: 2.18525
Value Function Loss: 0.01563

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.52711
Value Function Update Magnitude: 0.57448

Collected Steps per Second: 23,367.27693
Overall Steps per Second: 10,854.10430

Timestep Collection Time: 2.14060
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.60840

Cumulative Model Updates: 205,574
Cumulative Timesteps: 1,714,487,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.12125
Policy Entropy: 2.20315
Value Function Loss: 0.01570

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.52508
Value Function Update Magnitude: 0.58528

Collected Steps per Second: 23,430.61388
Overall Steps per Second: 11,046.69354

Timestep Collection Time: 2.13439
Timestep Consumption Time: 2.39276
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.52715

Cumulative Model Updates: 205,580
Cumulative Timesteps: 1,714,537,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1714537388...
Checkpoint 1714537388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.90247
Policy Entropy: 2.18090
Value Function Loss: 0.01787

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 23,126.70265
Overall Steps per Second: 11,115.17082

Timestep Collection Time: 2.16321
Timestep Consumption Time: 2.33766
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.50088

Cumulative Model Updates: 205,586
Cumulative Timesteps: 1,714,587,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.40946
Policy Entropy: 2.19409
Value Function Loss: 0.01858

Mean KL Divergence: 0.03731
SB3 Clip Fraction: 0.21141
Policy Update Magnitude: 0.50339
Value Function Update Magnitude: 0.63240

Collected Steps per Second: 23,372.70683
Overall Steps per Second: 10,950.42485

Timestep Collection Time: 2.14010
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.56786

Cumulative Model Updates: 205,592
Cumulative Timesteps: 1,714,637,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1714637436...
Checkpoint 1714637436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.30826
Policy Entropy: 2.17493
Value Function Loss: 0.01806

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.17999
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 22,748.44024
Overall Steps per Second: 10,678.37670

Timestep Collection Time: 2.19848
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.68348

Cumulative Model Updates: 205,598
Cumulative Timesteps: 1,714,687,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.41844
Policy Entropy: 2.17004
Value Function Loss: 0.01637

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.16309
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 23,264.54198
Overall Steps per Second: 10,929.08834

Timestep Collection Time: 2.14945
Timestep Consumption Time: 2.42604
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.57550

Cumulative Model Updates: 205,604
Cumulative Timesteps: 1,714,737,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1714737454...
Checkpoint 1714737454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.64060
Policy Entropy: 2.20238
Value Function Loss: 0.01589

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.60020

Collected Steps per Second: 23,315.16757
Overall Steps per Second: 11,124.43921

Timestep Collection Time: 2.14556
Timestep Consumption Time: 2.35121
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.49677

Cumulative Model Updates: 205,610
Cumulative Timesteps: 1,714,787,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.37675
Policy Entropy: 2.20532
Value Function Loss: 0.01580

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 23,437.18802
Overall Steps per Second: 10,911.05165

Timestep Collection Time: 2.13353
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.58288

Cumulative Model Updates: 205,616
Cumulative Timesteps: 1,714,837,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1714837482...
Checkpoint 1714837482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.45757
Policy Entropy: 2.20241
Value Function Loss: 0.01702

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.58997

Collected Steps per Second: 23,361.91638
Overall Steps per Second: 10,982.66714

Timestep Collection Time: 2.14041
Timestep Consumption Time: 2.41259
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.55299

Cumulative Model Updates: 205,622
Cumulative Timesteps: 1,714,887,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.48502
Policy Entropy: 2.17792
Value Function Loss: 0.01612

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.59875

Collected Steps per Second: 23,090.41834
Overall Steps per Second: 10,932.76111

Timestep Collection Time: 2.16566
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.57396

Cumulative Model Updates: 205,628
Cumulative Timesteps: 1,714,937,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1714937492...
Checkpoint 1714937492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.58481
Policy Entropy: 2.18625
Value Function Loss: 0.01643

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.59767

Collected Steps per Second: 23,158.53424
Overall Steps per Second: 11,107.62076

Timestep Collection Time: 2.15989
Timestep Consumption Time: 2.34332
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.50321

Cumulative Model Updates: 205,634
Cumulative Timesteps: 1,714,987,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.91786
Policy Entropy: 2.17769
Value Function Loss: 0.01580

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.59315

Collected Steps per Second: 23,362.05051
Overall Steps per Second: 10,929.07063

Timestep Collection Time: 2.14125
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.57715

Cumulative Model Updates: 205,640
Cumulative Timesteps: 1,715,037,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1715037536...
Checkpoint 1715037536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.54001
Policy Entropy: 2.16512
Value Function Loss: 0.01622

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 23,261.83942
Overall Steps per Second: 10,764.59063

Timestep Collection Time: 2.15056
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.64727

Cumulative Model Updates: 205,646
Cumulative Timesteps: 1,715,087,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.29011
Policy Entropy: 2.18243
Value Function Loss: 0.01626

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.59179

Collected Steps per Second: 23,470.08932
Overall Steps per Second: 10,857.01616

Timestep Collection Time: 2.13037
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.60532

Cumulative Model Updates: 205,652
Cumulative Timesteps: 1,715,137,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1715137562...
Checkpoint 1715137562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.88997
Policy Entropy: 2.21043
Value Function Loss: 0.01646

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 23,320.61386
Overall Steps per Second: 11,056.99940

Timestep Collection Time: 2.14445
Timestep Consumption Time: 2.37847
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.52293

Cumulative Model Updates: 205,658
Cumulative Timesteps: 1,715,187,572

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.06762
Policy Entropy: 2.22051
Value Function Loss: 0.01628

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.60030

Collected Steps per Second: 23,525.00969
Overall Steps per Second: 10,991.68480

Timestep Collection Time: 2.12574
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.54962

Cumulative Model Updates: 205,664
Cumulative Timesteps: 1,715,237,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1715237580...
Checkpoint 1715237580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.64978
Policy Entropy: 2.20309
Value Function Loss: 0.01647

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.58411

Collected Steps per Second: 23,438.29781
Overall Steps per Second: 10,972.24460

Timestep Collection Time: 2.13377
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.55805

Cumulative Model Updates: 205,670
Cumulative Timesteps: 1,715,287,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.27146
Policy Entropy: 2.17853
Value Function Loss: 0.01700

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.57929

Collected Steps per Second: 22,894.15579
Overall Steps per Second: 10,713.83100

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.66854

Cumulative Model Updates: 205,676
Cumulative Timesteps: 1,715,337,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1715337610...
Checkpoint 1715337610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.89226
Policy Entropy: 2.17359
Value Function Loss: 0.01729

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.60491

Collected Steps per Second: 23,420.02421
Overall Steps per Second: 10,941.05094

Timestep Collection Time: 2.13510
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.57031

Cumulative Model Updates: 205,682
Cumulative Timesteps: 1,715,387,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.81313
Policy Entropy: 2.18063
Value Function Loss: 0.01666

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.16578
Policy Update Magnitude: 0.53477
Value Function Update Magnitude: 0.61465

Collected Steps per Second: 23,107.27651
Overall Steps per Second: 10,884.01796

Timestep Collection Time: 2.16503
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.59646

Cumulative Model Updates: 205,688
Cumulative Timesteps: 1,715,437,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1715437642...
Checkpoint 1715437642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.79430
Policy Entropy: 2.19659
Value Function Loss: 0.01563

Mean KL Divergence: 0.02855
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.51826
Value Function Update Magnitude: 0.60169

Collected Steps per Second: 23,415.13269
Overall Steps per Second: 10,853.51429

Timestep Collection Time: 2.13537
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.60680

Cumulative Model Updates: 205,694
Cumulative Timesteps: 1,715,487,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.13013
Policy Entropy: 2.19415
Value Function Loss: 0.01525

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.17115
Policy Update Magnitude: 0.53972
Value Function Update Magnitude: 0.58667

Collected Steps per Second: 23,388.87392
Overall Steps per Second: 10,814.27568

Timestep Collection Time: 2.13785
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.62370

Cumulative Model Updates: 205,700
Cumulative Timesteps: 1,715,537,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1715537644...
Checkpoint 1715537644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.23578
Policy Entropy: 2.21147
Value Function Loss: 0.01486

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.14901
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.57118

Collected Steps per Second: 23,379.38503
Overall Steps per Second: 11,011.00297

Timestep Collection Time: 2.13932
Timestep Consumption Time: 2.40304
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.54237

Cumulative Model Updates: 205,706
Cumulative Timesteps: 1,715,587,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.47795
Policy Entropy: 2.19047
Value Function Loss: 0.01507

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.56359

Collected Steps per Second: 23,046.84467
Overall Steps per Second: 10,887.22929

Timestep Collection Time: 2.16984
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.59327

Cumulative Model Updates: 205,712
Cumulative Timesteps: 1,715,637,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1715637668...
Checkpoint 1715637668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.09206
Policy Entropy: 2.19176
Value Function Loss: 0.01619

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.56580

Collected Steps per Second: 23,107.21905
Overall Steps per Second: 11,129.58648

Timestep Collection Time: 2.16409
Timestep Consumption Time: 2.32898
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.49307

Cumulative Model Updates: 205,718
Cumulative Timesteps: 1,715,687,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.59910
Policy Entropy: 2.16802
Value Function Loss: 0.01684

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.60601

Collected Steps per Second: 23,364.87576
Overall Steps per Second: 10,900.52484

Timestep Collection Time: 2.13996
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.58694

Cumulative Model Updates: 205,724
Cumulative Timesteps: 1,715,737,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1715737674...
Checkpoint 1715737674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.17586
Policy Entropy: 2.18551
Value Function Loss: 0.01740

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.15336
Policy Update Magnitude: 0.55291
Value Function Update Magnitude: 0.61791

Collected Steps per Second: 23,379.65751
Overall Steps per Second: 10,879.37078

Timestep Collection Time: 2.13955
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.59788

Cumulative Model Updates: 205,730
Cumulative Timesteps: 1,715,787,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.03919
Policy Entropy: 2.19149
Value Function Loss: 0.01684

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.54720
Value Function Update Magnitude: 0.63705

Collected Steps per Second: 23,050.39491
Overall Steps per Second: 10,719.70461

Timestep Collection Time: 2.16925
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66449

Cumulative Model Updates: 205,736
Cumulative Timesteps: 1,715,837,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1715837698...
Checkpoint 1715837698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.96864
Policy Entropy: 2.18106
Value Function Loss: 0.01643

Mean KL Divergence: 0.02227
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 22,994.82936
Overall Steps per Second: 10,948.75209

Timestep Collection Time: 2.17466
Timestep Consumption Time: 2.39262
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.56728

Cumulative Model Updates: 205,742
Cumulative Timesteps: 1,715,887,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.90402
Policy Entropy: 2.17870
Value Function Loss: 0.01613

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.16612
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.61045

Collected Steps per Second: 22,980.76829
Overall Steps per Second: 11,059.67104

Timestep Collection Time: 2.17660
Timestep Consumption Time: 2.34614
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.52274

Cumulative Model Updates: 205,748
Cumulative Timesteps: 1,715,937,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1715937724...
Checkpoint 1715937724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.46616
Policy Entropy: 2.19200
Value Function Loss: 0.01611

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.59314

Collected Steps per Second: 23,344.22668
Overall Steps per Second: 10,957.63963

Timestep Collection Time: 2.14186
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.56303

Cumulative Model Updates: 205,754
Cumulative Timesteps: 1,715,987,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.82724
Policy Entropy: 2.20254
Value Function Loss: 0.01631

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.59440

Collected Steps per Second: 22,728.35908
Overall Steps per Second: 10,675.43181

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.68571

Cumulative Model Updates: 205,760
Cumulative Timesteps: 1,716,037,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1716037746...
Checkpoint 1716037746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.96654
Policy Entropy: 2.20273
Value Function Loss: 0.01589

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.54605
Value Function Update Magnitude: 0.58687

Collected Steps per Second: 23,056.19320
Overall Steps per Second: 10,977.93470

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.38636
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.55532

Cumulative Model Updates: 205,766
Cumulative Timesteps: 1,716,087,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.48361
Policy Entropy: 2.18203
Value Function Loss: 0.01630

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.59705

Collected Steps per Second: 23,288.48686
Overall Steps per Second: 10,956.98397

Timestep Collection Time: 2.14793
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.56531

Cumulative Model Updates: 205,772
Cumulative Timesteps: 1,716,137,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1716137776...
Checkpoint 1716137776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.26476
Policy Entropy: 2.21836
Value Function Loss: 0.01524

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 23,313.31059
Overall Steps per Second: 10,969.80184

Timestep Collection Time: 2.14573
Timestep Consumption Time: 2.41443
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.56016

Cumulative Model Updates: 205,778
Cumulative Timesteps: 1,716,187,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.27443
Policy Entropy: 2.21324
Value Function Loss: 0.01547

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 23,126.00706
Overall Steps per Second: 10,885.30325

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.59555

Cumulative Model Updates: 205,784
Cumulative Timesteps: 1,716,237,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1716237824...
Checkpoint 1716237824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.40314
Policy Entropy: 2.23429
Value Function Loss: 0.01538

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.53581
Value Function Update Magnitude: 0.57900

Collected Steps per Second: 22,988.15490
Overall Steps per Second: 10,765.05837

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.64540

Cumulative Model Updates: 205,790
Cumulative Timesteps: 1,716,287,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.39111
Policy Entropy: 2.23097
Value Function Loss: 0.01604

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.56696

Collected Steps per Second: 23,183.32577
Overall Steps per Second: 10,900.57227

Timestep Collection Time: 2.15724
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.58802

Cumulative Model Updates: 205,796
Cumulative Timesteps: 1,716,337,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1716337844...
Checkpoint 1716337844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.75466
Policy Entropy: 2.23388
Value Function Loss: 0.01712

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 23,355.92206
Overall Steps per Second: 11,169.22896

Timestep Collection Time: 2.14113
Timestep Consumption Time: 2.33617
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.47730

Cumulative Model Updates: 205,802
Cumulative Timesteps: 1,716,387,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.36406
Policy Entropy: 2.20731
Value Function Loss: 0.01814

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.55163
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 22,700.71295
Overall Steps per Second: 10,797.50794

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.63107

Cumulative Model Updates: 205,808
Cumulative Timesteps: 1,716,437,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1716437856...
Checkpoint 1716437856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.69888
Policy Entropy: 2.16939
Value Function Loss: 0.01750

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.62715

Collected Steps per Second: 23,190.15538
Overall Steps per Second: 10,756.74712

Timestep Collection Time: 2.15704
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.65029

Cumulative Model Updates: 205,814
Cumulative Timesteps: 1,716,487,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.78838
Policy Entropy: 2.15711
Value Function Loss: 0.01695

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.60676

Collected Steps per Second: 23,092.63110
Overall Steps per Second: 10,828.60433

Timestep Collection Time: 2.16563
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.61832

Cumulative Model Updates: 205,820
Cumulative Timesteps: 1,716,537,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1716537888...
Checkpoint 1716537888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.29135
Policy Entropy: 2.15335
Value Function Loss: 0.01677

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 23,178.60539
Overall Steps per Second: 11,160.45902

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.32368
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.48154

Cumulative Model Updates: 205,826
Cumulative Timesteps: 1,716,587,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.41373
Policy Entropy: 2.18462
Value Function Loss: 0.01627

Mean KL Divergence: 0.02843
SB3 Clip Fraction: 0.18769
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.59982

Collected Steps per Second: 23,385.52168
Overall Steps per Second: 10,863.84868

Timestep Collection Time: 2.13833
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.60297

Cumulative Model Updates: 205,832
Cumulative Timesteps: 1,716,637,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1716637910...
Checkpoint 1716637910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.26648
Policy Entropy: 2.17976
Value Function Loss: 0.01619

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.16223
Policy Update Magnitude: 0.52562
Value Function Update Magnitude: 0.60233

Collected Steps per Second: 23,333.39182
Overall Steps per Second: 10,867.98027

Timestep Collection Time: 2.14302
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.60104

Cumulative Model Updates: 205,838
Cumulative Timesteps: 1,716,687,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.14861
Policy Entropy: 2.19651
Value Function Loss: 0.01635

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.60969

Collected Steps per Second: 22,673.71432
Overall Steps per Second: 10,714.62889

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66652

Cumulative Model Updates: 205,844
Cumulative Timesteps: 1,716,737,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1716737914...
Checkpoint 1716737914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.36848
Policy Entropy: 2.17635
Value Function Loss: 0.01753

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.61890

Collected Steps per Second: 23,130.23650
Overall Steps per Second: 10,832.02630

Timestep Collection Time: 2.16185
Timestep Consumption Time: 2.45447
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.61631

Cumulative Model Updates: 205,850
Cumulative Timesteps: 1,716,787,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.48398
Policy Entropy: 2.18620
Value Function Loss: 0.01702

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.56272
Value Function Update Magnitude: 0.62044

Collected Steps per Second: 23,326.06868
Overall Steps per Second: 11,155.10792

Timestep Collection Time: 2.14412
Timestep Consumption Time: 2.33938
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.48351

Cumulative Model Updates: 205,856
Cumulative Timesteps: 1,716,837,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1716837932...
Checkpoint 1716837932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.61707
Policy Entropy: 2.17360
Value Function Loss: 0.01619

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 23,111.11497
Overall Steps per Second: 10,813.63117

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.62583

Cumulative Model Updates: 205,862
Cumulative Timesteps: 1,716,887,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.73054
Policy Entropy: 2.16800
Value Function Loss: 0.01527

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.54511
Value Function Update Magnitude: 0.55953

Collected Steps per Second: 23,566.33902
Overall Steps per Second: 10,820.75826

Timestep Collection Time: 2.12176
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.62093

Cumulative Model Updates: 205,868
Cumulative Timesteps: 1,716,937,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1716937956...
Checkpoint 1716937956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.57996
Policy Entropy: 2.14821
Value Function Loss: 0.01657

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.58417

Collected Steps per Second: 23,004.03850
Overall Steps per Second: 10,928.90919

Timestep Collection Time: 2.17353
Timestep Consumption Time: 2.40149
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.57502

Cumulative Model Updates: 205,874
Cumulative Timesteps: 1,716,987,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.25723
Policy Entropy: 2.15564
Value Function Loss: 0.01668

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.56310
Value Function Update Magnitude: 0.60873

Collected Steps per Second: 23,142.88333
Overall Steps per Second: 10,992.26658

Timestep Collection Time: 2.16101
Timestep Consumption Time: 2.38873
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.54974

Cumulative Model Updates: 205,880
Cumulative Timesteps: 1,717,037,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1717037968...
Checkpoint 1717037968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.13278
Policy Entropy: 2.18164
Value Function Loss: 0.01718

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.62002

Collected Steps per Second: 23,169.81964
Overall Steps per Second: 10,829.99400

Timestep Collection Time: 2.15807
Timestep Consumption Time: 2.45893
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.61699

Cumulative Model Updates: 205,886
Cumulative Timesteps: 1,717,087,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.62905
Policy Entropy: 2.19730
Value Function Loss: 0.01689

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.61024

Collected Steps per Second: 23,630.85007
Overall Steps per Second: 10,901.90655

Timestep Collection Time: 2.11689
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.58856

Cumulative Model Updates: 205,892
Cumulative Timesteps: 1,717,137,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1717137994...
Checkpoint 1717137994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.10346
Policy Entropy: 2.18844
Value Function Loss: 0.01677

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.58559

Collected Steps per Second: 23,042.92094
Overall Steps per Second: 10,971.96032

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.38721
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.55707

Cumulative Model Updates: 205,898
Cumulative Timesteps: 1,717,187,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.11393
Policy Entropy: 2.18647
Value Function Loss: 0.01656

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.56023
Value Function Update Magnitude: 0.58190

Collected Steps per Second: 23,392.63675
Overall Steps per Second: 11,008.67672

Timestep Collection Time: 2.13794
Timestep Consumption Time: 2.40502
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.54296

Cumulative Model Updates: 205,904
Cumulative Timesteps: 1,717,238,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1717238006...
Checkpoint 1717238006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.28662
Policy Entropy: 2.16692
Value Function Loss: 0.01618

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 23,263.46217
Overall Steps per Second: 10,972.59490

Timestep Collection Time: 2.15007
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.55845

Cumulative Model Updates: 205,910
Cumulative Timesteps: 1,717,288,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.83440
Policy Entropy: 2.18152
Value Function Loss: 0.01619

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.55217

Collected Steps per Second: 23,472.90342
Overall Steps per Second: 10,917.42911

Timestep Collection Time: 2.13020
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.58002

Cumulative Model Updates: 205,916
Cumulative Timesteps: 1,717,338,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1717338026...
Checkpoint 1717338026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.89313
Policy Entropy: 2.18889
Value Function Loss: 0.01667

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.54887

Collected Steps per Second: 23,070.63062
Overall Steps per Second: 10,992.58776

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.38145
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.54888

Cumulative Model Updates: 205,922
Cumulative Timesteps: 1,717,388,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.54186
Policy Entropy: 2.18125
Value Function Loss: 0.01654

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.55373

Collected Steps per Second: 23,105.58185
Overall Steps per Second: 10,947.24395

Timestep Collection Time: 2.16433
Timestep Consumption Time: 2.40376
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.56809

Cumulative Model Updates: 205,928
Cumulative Timesteps: 1,717,438,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1717438038...
Checkpoint 1717438038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.50785
Policy Entropy: 2.13653
Value Function Loss: 0.01556

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 22,919.96063
Overall Steps per Second: 11,045.43791

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.34553
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.52730

Cumulative Model Updates: 205,934
Cumulative Timesteps: 1,717,488,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.49155
Policy Entropy: 2.13284
Value Function Loss: 0.01484

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.52248
Value Function Update Magnitude: 0.56518

Collected Steps per Second: 23,142.44303
Overall Steps per Second: 10,791.20083

Timestep Collection Time: 2.16140
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.63526

Cumulative Model Updates: 205,940
Cumulative Timesteps: 1,717,538,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1717538064...
Checkpoint 1717538064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.61835
Policy Entropy: 2.13588
Value Function Loss: 0.01482

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.53420
Value Function Update Magnitude: 0.56637

Collected Steps per Second: 22,863.68866
Overall Steps per Second: 10,849.72031

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.42280
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.61081

Cumulative Model Updates: 205,946
Cumulative Timesteps: 1,717,588,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.18551
Policy Entropy: 2.14037
Value Function Loss: 0.01668

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.56583

Collected Steps per Second: 22,736.18798
Overall Steps per Second: 10,873.61332

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.39982
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59958

Cumulative Model Updates: 205,952
Cumulative Timesteps: 1,717,638,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1717638104...
Checkpoint 1717638104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.72716
Policy Entropy: 2.13233
Value Function Loss: 0.01702

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.57230

Collected Steps per Second: 22,958.25142
Overall Steps per Second: 11,055.97074

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.34580
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.52479

Cumulative Model Updates: 205,958
Cumulative Timesteps: 1,717,688,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.37279
Policy Entropy: 2.14073
Value Function Loss: 0.01722

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.56616

Collected Steps per Second: 23,643.03136
Overall Steps per Second: 11,048.83905

Timestep Collection Time: 2.11521
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.52627

Cumulative Model Updates: 205,964
Cumulative Timesteps: 1,717,738,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1717738140...
Checkpoint 1717738140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.16311
Policy Entropy: 2.13099
Value Function Loss: 0.01702

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.54830

Collected Steps per Second: 22,907.70277
Overall Steps per Second: 10,601.30160

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.53464
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71810

Cumulative Model Updates: 205,970
Cumulative Timesteps: 1,717,788,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.07025
Policy Entropy: 2.13526
Value Function Loss: 0.01651

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.55431

Collected Steps per Second: 23,349.74194
Overall Steps per Second: 10,951.01883

Timestep Collection Time: 2.14264
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.56852

Cumulative Model Updates: 205,976
Cumulative Timesteps: 1,717,838,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1717838188...
Checkpoint 1717838188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.62177
Policy Entropy: 2.14121
Value Function Loss: 0.01631

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.55012

Collected Steps per Second: 22,782.75836
Overall Steps per Second: 11,004.90712

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.34926
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.54434

Cumulative Model Updates: 205,982
Cumulative Timesteps: 1,717,888,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.70050
Policy Entropy: 2.17237
Value Function Loss: 0.01661

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.54146
Value Function Update Magnitude: 0.54039

Collected Steps per Second: 23,440.47939
Overall Steps per Second: 10,962.86716

Timestep Collection Time: 2.13315
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.56103

Cumulative Model Updates: 205,988
Cumulative Timesteps: 1,717,938,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1717938200...
Checkpoint 1717938200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.73130
Policy Entropy: 2.17267
Value Function Loss: 0.01667

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.54470

Collected Steps per Second: 23,157.75585
Overall Steps per Second: 10,793.71108

Timestep Collection Time: 2.15997
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.63418

Cumulative Model Updates: 205,994
Cumulative Timesteps: 1,717,988,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.20449
Policy Entropy: 2.15585
Value Function Loss: 0.01638

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.56867

Collected Steps per Second: 23,317.99768
Overall Steps per Second: 10,785.34204

Timestep Collection Time: 2.14615
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.64000

Cumulative Model Updates: 206,000
Cumulative Timesteps: 1,718,038,264

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1718038264...
Checkpoint 1718038264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.63464
Policy Entropy: 2.11984
Value Function Loss: 0.01606

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.57673

Collected Steps per Second: 22,957.05603
Overall Steps per Second: 10,786.33620

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.63828

Cumulative Model Updates: 206,006
Cumulative Timesteps: 1,718,088,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.10219
Policy Entropy: 2.10306
Value Function Loss: 0.01607

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.57612

Collected Steps per Second: 23,448.68034
Overall Steps per Second: 11,180.00060

Timestep Collection Time: 2.13300
Timestep Consumption Time: 2.34070
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.47370

Cumulative Model Updates: 206,012
Cumulative Timesteps: 1,718,138,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1718138310...
Checkpoint 1718138310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.28913
Policy Entropy: 2.10189
Value Function Loss: 0.01711

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.59006

Collected Steps per Second: 23,108.95650
Overall Steps per Second: 10,731.82127

Timestep Collection Time: 2.16375
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.65923

Cumulative Model Updates: 206,018
Cumulative Timesteps: 1,718,188,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.07668
Policy Entropy: 2.12582
Value Function Loss: 0.01703

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 23,391.16872
Overall Steps per Second: 10,868.66204

Timestep Collection Time: 2.13893
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.60333

Cumulative Model Updates: 206,024
Cumulative Timesteps: 1,718,238,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1718238344...
Checkpoint 1718238344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.79840
Policy Entropy: 2.11441
Value Function Loss: 0.01778

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.62549

Collected Steps per Second: 22,791.07584
Overall Steps per Second: 10,729.68461

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.46751
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66258

Cumulative Model Updates: 206,030
Cumulative Timesteps: 1,718,288,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.93394
Policy Entropy: 2.15026
Value Function Loss: 0.01765

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.61853

Collected Steps per Second: 23,270.95878
Overall Steps per Second: 10,832.35088

Timestep Collection Time: 2.14963
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.61802

Cumulative Model Updates: 206,036
Cumulative Timesteps: 1,718,338,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1718338396...
Checkpoint 1718338396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.19359
Policy Entropy: 2.14340
Value Function Loss: 0.01680

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.61647

Collected Steps per Second: 22,902.65324
Overall Steps per Second: 11,048.81903

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.34269
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.52628

Cumulative Model Updates: 206,042
Cumulative Timesteps: 1,718,388,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.54657
Policy Entropy: 2.16510
Value Function Loss: 0.01680

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.60673

Collected Steps per Second: 23,740.32105
Overall Steps per Second: 10,953.25828

Timestep Collection Time: 2.10654
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.56576

Cumulative Model Updates: 206,048
Cumulative Timesteps: 1,718,438,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1718438416...
Checkpoint 1718438416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.79239
Policy Entropy: 2.16114
Value Function Loss: 0.01726

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15559
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.60174

Collected Steps per Second: 22,869.79491
Overall Steps per Second: 10,672.76137

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.49983
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.68726

Cumulative Model Updates: 206,054
Cumulative Timesteps: 1,718,488,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.85914
Policy Entropy: 2.15238
Value Function Loss: 0.01782

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.59604

Collected Steps per Second: 23,262.75977
Overall Steps per Second: 10,928.90490

Timestep Collection Time: 2.14953
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.57539

Cumulative Model Updates: 206,060
Cumulative Timesteps: 1,718,538,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1718538446...
Checkpoint 1718538446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.27000
Policy Entropy: 2.19148
Value Function Loss: 0.01748

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.59317

Collected Steps per Second: 23,262.28087
Overall Steps per Second: 11,103.92145

Timestep Collection Time: 2.14940
Timestep Consumption Time: 2.35351
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.50291

Cumulative Model Updates: 206,066
Cumulative Timesteps: 1,718,588,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.44875
Policy Entropy: 2.22016
Value Function Loss: 0.01606

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.52784
Value Function Update Magnitude: 0.56915

Collected Steps per Second: 23,455.07588
Overall Steps per Second: 10,961.23083

Timestep Collection Time: 2.13267
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.56354

Cumulative Model Updates: 206,072
Cumulative Timesteps: 1,718,638,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1718638468...
Checkpoint 1718638468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.94321
Policy Entropy: 2.22132
Value Function Loss: 0.01569

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.52395
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 23,098.39099
Overall Steps per Second: 10,801.90527

Timestep Collection Time: 2.16491
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.62937

Cumulative Model Updates: 206,078
Cumulative Timesteps: 1,718,688,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.65001
Policy Entropy: 2.21366
Value Function Loss: 0.01495

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.53971

Collected Steps per Second: 23,543.94991
Overall Steps per Second: 11,083.80752

Timestep Collection Time: 2.12488
Timestep Consumption Time: 2.38873
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.51361

Cumulative Model Updates: 206,084
Cumulative Timesteps: 1,718,738,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1718738502...
Checkpoint 1718738502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.48786
Policy Entropy: 2.20161
Value Function Loss: 0.01606

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.52666

Collected Steps per Second: 23,313.43758
Overall Steps per Second: 10,870.16556

Timestep Collection Time: 2.14511
Timestep Consumption Time: 2.45555
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.60067

Cumulative Model Updates: 206,090
Cumulative Timesteps: 1,718,788,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.51486
Policy Entropy: 2.21800
Value Function Loss: 0.01676

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.54230

Collected Steps per Second: 23,562.08969
Overall Steps per Second: 11,176.77900

Timestep Collection Time: 2.12333
Timestep Consumption Time: 2.35292
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.47624

Cumulative Model Updates: 206,096
Cumulative Timesteps: 1,718,838,542

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1718838542...
Checkpoint 1718838542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.76789
Policy Entropy: 2.22584
Value Function Loss: 0.01675

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.56834

Collected Steps per Second: 22,918.75822
Overall Steps per Second: 10,709.27716

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.66922

Cumulative Model Updates: 206,102
Cumulative Timesteps: 1,718,888,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.20883
Policy Entropy: 2.22643
Value Function Loss: 0.01610

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.57246

Collected Steps per Second: 23,252.43532
Overall Steps per Second: 10,923.79829

Timestep Collection Time: 2.15100
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.57863

Cumulative Model Updates: 206,108
Cumulative Timesteps: 1,718,938,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1718938562...
Checkpoint 1718938562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.35664
Policy Entropy: 2.20563
Value Function Loss: 0.01539

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.55888

Collected Steps per Second: 23,013.74690
Overall Steps per Second: 10,814.52931

Timestep Collection Time: 2.17279
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.62378

Cumulative Model Updates: 206,114
Cumulative Timesteps: 1,718,988,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.36741
Policy Entropy: 2.20873
Value Function Loss: 0.01606

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.56428

Collected Steps per Second: 24,482.67809
Overall Steps per Second: 11,223.00956

Timestep Collection Time: 2.04259
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.45585

Cumulative Model Updates: 206,120
Cumulative Timesteps: 1,719,038,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1719038574...
Checkpoint 1719038574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.22275
Policy Entropy: 2.22114
Value Function Loss: 0.01643

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.59094

Collected Steps per Second: 23,191.43883
Overall Steps per Second: 10,806.88598

Timestep Collection Time: 2.15597
Timestep Consumption Time: 2.47071
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.62668

Cumulative Model Updates: 206,126
Cumulative Timesteps: 1,719,088,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.19903
Policy Entropy: 2.22956
Value Function Loss: 0.01617

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.53486
Value Function Update Magnitude: 0.58765

Collected Steps per Second: 23,551.08672
Overall Steps per Second: 10,871.47240

Timestep Collection Time: 2.12389
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.60103

Cumulative Model Updates: 206,132
Cumulative Timesteps: 1,719,138,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1719138594...
Checkpoint 1719138594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.31524
Policy Entropy: 2.21679
Value Function Loss: 0.01649

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 23,144.86286
Overall Steps per Second: 10,947.39573

Timestep Collection Time: 2.16031
Timestep Consumption Time: 2.40699
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.56730

Cumulative Model Updates: 206,138
Cumulative Timesteps: 1,719,188,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.46905
Policy Entropy: 2.22314
Value Function Loss: 0.01606

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.53358
Value Function Update Magnitude: 0.55467

Collected Steps per Second: 23,467.99571
Overall Steps per Second: 10,985.59199

Timestep Collection Time: 2.13150
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.55342

Cumulative Model Updates: 206,144
Cumulative Timesteps: 1,719,238,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1719238616...
Checkpoint 1719238616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.13245
Policy Entropy: 2.23139
Value Function Loss: 0.01677

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.56279

Collected Steps per Second: 23,032.69851
Overall Steps per Second: 10,809.31533

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.45530
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.62657

Cumulative Model Updates: 206,150
Cumulative Timesteps: 1,719,288,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.15698
Policy Entropy: 2.22272
Value Function Loss: 0.01665

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.54103
Value Function Update Magnitude: 0.56315

Collected Steps per Second: 23,118.70488
Overall Steps per Second: 10,777.91308

Timestep Collection Time: 2.16353
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.64079

Cumulative Model Updates: 206,156
Cumulative Timesteps: 1,719,338,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1719338644...
Checkpoint 1719338644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.47961
Policy Entropy: 2.22098
Value Function Loss: 0.01768

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.57838

Collected Steps per Second: 23,156.75306
Overall Steps per Second: 10,960.51770

Timestep Collection Time: 2.15989
Timestep Consumption Time: 2.40340
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.56329

Cumulative Model Updates: 206,162
Cumulative Timesteps: 1,719,388,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.75013
Policy Entropy: 2.20385
Value Function Loss: 0.01773

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.60251

Collected Steps per Second: 23,436.57968
Overall Steps per Second: 10,975.74134

Timestep Collection Time: 2.13410
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.55696

Cumulative Model Updates: 206,168
Cumulative Timesteps: 1,719,438,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1719438676...
Checkpoint 1719438676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.78984
Policy Entropy: 2.21636
Value Function Loss: 0.01782

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.61280

Collected Steps per Second: 23,157.14081
Overall Steps per Second: 10,834.03040

Timestep Collection Time: 2.16020
Timestep Consumption Time: 2.45711
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.61730

Cumulative Model Updates: 206,174
Cumulative Timesteps: 1,719,488,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.58305
Policy Entropy: 2.19133
Value Function Loss: 0.01622

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.62777

Collected Steps per Second: 23,575.19985
Overall Steps per Second: 10,886.80477

Timestep Collection Time: 2.12113
Timestep Consumption Time: 2.47214
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.59327

Cumulative Model Updates: 206,180
Cumulative Timesteps: 1,719,538,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1719538706...
Checkpoint 1719538706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.19909
Policy Entropy: 2.17865
Value Function Loss: 0.01579

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 22,982.12188
Overall Steps per Second: 10,915.75928

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.40628
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.58310

Cumulative Model Updates: 206,186
Cumulative Timesteps: 1,719,588,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.03389
Policy Entropy: 2.18039
Value Function Loss: 0.01616

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.53348
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 23,311.99802
Overall Steps per Second: 10,915.52683

Timestep Collection Time: 2.14602
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.58320

Cumulative Model Updates: 206,192
Cumulative Timesteps: 1,719,638,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1719638762...
Checkpoint 1719638762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.48911
Policy Entropy: 2.19613
Value Function Loss: 0.01720

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.58821

Collected Steps per Second: 23,640.74800
Overall Steps per Second: 11,037.40748

Timestep Collection Time: 2.11516
Timestep Consumption Time: 2.41525
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.53041

Cumulative Model Updates: 206,198
Cumulative Timesteps: 1,719,688,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.46495
Policy Entropy: 2.19481
Value Function Loss: 0.01794

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.18105
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 23,507.19488
Overall Steps per Second: 11,025.16337

Timestep Collection Time: 2.12726
Timestep Consumption Time: 2.40836
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.53562

Cumulative Model Updates: 206,204
Cumulative Timesteps: 1,719,738,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1719738772...
Checkpoint 1719738772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.32299
Policy Entropy: 2.20300
Value Function Loss: 0.01763

Mean KL Divergence: 0.02589
SB3 Clip Fraction: 0.17657
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 23,192.71228
Overall Steps per Second: 10,957.94791

Timestep Collection Time: 2.15732
Timestep Consumption Time: 2.40869
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.56600

Cumulative Model Updates: 206,210
Cumulative Timesteps: 1,719,788,806

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.56704
Policy Entropy: 2.20733
Value Function Loss: 0.01667

Mean KL Divergence: 0.02732
SB3 Clip Fraction: 0.18597
Policy Update Magnitude: 0.51655
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 23,379.86849
Overall Steps per Second: 11,028.11598

Timestep Collection Time: 2.13876
Timestep Consumption Time: 2.39547
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.53423

Cumulative Model Updates: 206,216
Cumulative Timesteps: 1,719,838,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1719838810...
Checkpoint 1719838810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.28270
Policy Entropy: 2.20871
Value Function Loss: 0.01678

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.19185
Policy Update Magnitude: 0.50339
Value Function Update Magnitude: 0.59350

Collected Steps per Second: 22,902.46299
Overall Steps per Second: 10,779.85467

Timestep Collection Time: 2.18413
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.64032

Cumulative Model Updates: 206,222
Cumulative Timesteps: 1,719,888,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.50791
Policy Entropy: 2.20398
Value Function Loss: 0.01701

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.62664

Collected Steps per Second: 23,409.29728
Overall Steps per Second: 11,169.19115

Timestep Collection Time: 2.13590
Timestep Consumption Time: 2.34070
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.47660

Cumulative Model Updates: 206,228
Cumulative Timesteps: 1,719,938,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1719938832...
Checkpoint 1719938832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.63435
Policy Entropy: 2.19517
Value Function Loss: 0.01769

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.16456
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.63275

Collected Steps per Second: 22,524.70345
Overall Steps per Second: 10,715.48740

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.66726

Cumulative Model Updates: 206,234
Cumulative Timesteps: 1,719,988,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.81367
Policy Entropy: 2.18605
Value Function Loss: 0.01721

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.57291
Value Function Update Magnitude: 0.63927

Collected Steps per Second: 23,438.15410
Overall Steps per Second: 10,885.25904

Timestep Collection Time: 2.13438
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.59576

Cumulative Model Updates: 206,240
Cumulative Timesteps: 1,720,038,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1720038870...
Checkpoint 1720038870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.31712
Policy Entropy: 2.19088
Value Function Loss: 0.01702

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.60800

Collected Steps per Second: 22,635.29207
Overall Steps per Second: 10,649.66535

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69724

Cumulative Model Updates: 206,246
Cumulative Timesteps: 1,720,088,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.71766
Policy Entropy: 2.19686
Value Function Loss: 0.01687

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 23,349.92450
Overall Steps per Second: 10,968.24159

Timestep Collection Time: 2.14142
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.55880

Cumulative Model Updates: 206,252
Cumulative Timesteps: 1,720,138,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1720138896...
Checkpoint 1720138896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.22277
Policy Entropy: 2.20215
Value Function Loss: 0.01615

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.59234

Collected Steps per Second: 23,035.87738
Overall Steps per Second: 10,818.94191

Timestep Collection Time: 2.17148
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.62356

Cumulative Model Updates: 206,258
Cumulative Timesteps: 1,720,188,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.32110
Policy Entropy: 2.21238
Value Function Loss: 0.01598

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.57730

Collected Steps per Second: 23,522.33359
Overall Steps per Second: 10,838.75984

Timestep Collection Time: 2.12717
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.61640

Cumulative Model Updates: 206,264
Cumulative Timesteps: 1,720,238,954

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1720238954...
Checkpoint 1720238954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.91258
Policy Entropy: 2.19516
Value Function Loss: 0.01546

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.57871

Collected Steps per Second: 22,842.78730
Overall Steps per Second: 10,896.42832

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.58921

Cumulative Model Updates: 206,270
Cumulative Timesteps: 1,720,288,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.05110
Policy Entropy: 2.20358
Value Function Loss: 0.01662

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 23,471.73254
Overall Steps per Second: 10,936.31259

Timestep Collection Time: 2.13065
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.57284

Cumulative Model Updates: 206,276
Cumulative Timesteps: 1,720,338,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1720338970...
Checkpoint 1720338970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.10981
Policy Entropy: 2.20657
Value Function Loss: 0.01627

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.57349

Collected Steps per Second: 23,269.66628
Overall Steps per Second: 10,852.21166

Timestep Collection Time: 2.14975
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.60957

Cumulative Model Updates: 206,282
Cumulative Timesteps: 1,720,388,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.94994
Policy Entropy: 2.21722
Value Function Loss: 0.01647

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.56611

Collected Steps per Second: 23,538.84606
Overall Steps per Second: 10,837.97893

Timestep Collection Time: 2.12491
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.61507

Cumulative Model Updates: 206,288
Cumulative Timesteps: 1,720,439,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1720439012...
Checkpoint 1720439012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.46258
Policy Entropy: 2.21963
Value Function Loss: 0.01567

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.57396

Collected Steps per Second: 23,075.21600
Overall Steps per Second: 10,916.55700

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.41356
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58057

Cumulative Model Updates: 206,294
Cumulative Timesteps: 1,720,489,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.81023
Policy Entropy: 2.20897
Value Function Loss: 0.01651

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.57020

Collected Steps per Second: 23,462.76408
Overall Steps per Second: 10,985.59679

Timestep Collection Time: 2.13121
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.55178

Cumulative Model Updates: 206,300
Cumulative Timesteps: 1,720,539,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1720539020...
Checkpoint 1720539020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.35434
Policy Entropy: 2.19909
Value Function Loss: 0.01752

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.55707

Collected Steps per Second: 21,860.13959
Overall Steps per Second: 10,605.70374

Timestep Collection Time: 2.28827
Timestep Consumption Time: 2.42824
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71652

Cumulative Model Updates: 206,306
Cumulative Timesteps: 1,720,589,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.21535
Policy Entropy: 2.19354
Value Function Loss: 0.01764

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.57109

Collected Steps per Second: 23,689.74589
Overall Steps per Second: 10,953.74043

Timestep Collection Time: 2.11121
Timestep Consumption Time: 2.45472
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.56593

Cumulative Model Updates: 206,312
Cumulative Timesteps: 1,720,639,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1720639056...
Checkpoint 1720639056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.57091
Policy Entropy: 2.20556
Value Function Loss: 0.01726

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.56832

Collected Steps per Second: 22,905.19682
Overall Steps per Second: 10,701.11589

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.67316

Cumulative Model Updates: 206,318
Cumulative Timesteps: 1,720,689,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.75096
Policy Entropy: 2.23319
Value Function Loss: 0.01635

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.57281

Collected Steps per Second: 23,324.72487
Overall Steps per Second: 10,843.48142

Timestep Collection Time: 2.14382
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.61143

Cumulative Model Updates: 206,324
Cumulative Timesteps: 1,720,739,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1720739068...
Checkpoint 1720739068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.98066
Policy Entropy: 2.22050
Value Function Loss: 0.01689

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.57616

Collected Steps per Second: 23,142.12742
Overall Steps per Second: 11,162.60412

Timestep Collection Time: 2.16151
Timestep Consumption Time: 2.31970
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.48121

Cumulative Model Updates: 206,330
Cumulative Timesteps: 1,720,789,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.21759
Policy Entropy: 2.21961
Value Function Loss: 0.01611

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.58352

Collected Steps per Second: 23,459.62799
Overall Steps per Second: 10,859.23961

Timestep Collection Time: 2.13149
Timestep Consumption Time: 2.47325
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.60474

Cumulative Model Updates: 206,336
Cumulative Timesteps: 1,720,839,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1720839094...
Checkpoint 1720839094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.65449
Policy Entropy: 2.20451
Value Function Loss: 0.01699

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.53013
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 22,490.49118
Overall Steps per Second: 10,639.81995

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.70102

Cumulative Model Updates: 206,342
Cumulative Timesteps: 1,720,889,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.47360
Policy Entropy: 2.22003
Value Function Loss: 0.01775

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.17229
Policy Update Magnitude: 0.50657
Value Function Update Magnitude: 0.60046

Collected Steps per Second: 23,209.13436
Overall Steps per Second: 10,878.23923

Timestep Collection Time: 2.15467
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.59707

Cumulative Model Updates: 206,348
Cumulative Timesteps: 1,720,939,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1720939120...
Checkpoint 1720939120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.34130
Policy Entropy: 2.20802
Value Function Loss: 0.01852

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 23,176.35719
Overall Steps per Second: 11,102.42800

Timestep Collection Time: 2.15841
Timestep Consumption Time: 2.34727
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.50568

Cumulative Model Updates: 206,354
Cumulative Timesteps: 1,720,989,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.78907
Policy Entropy: 2.18414
Value Function Loss: 0.01847

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.16355
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.65233

Collected Steps per Second: 23,653.69895
Overall Steps per Second: 10,948.30628

Timestep Collection Time: 2.11400
Timestep Consumption Time: 2.45328
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.56728

Cumulative Model Updates: 206,360
Cumulative Timesteps: 1,721,039,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1721039148...
Checkpoint 1721039148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.43613
Policy Entropy: 2.18411
Value Function Loss: 0.01805

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.62718

Collected Steps per Second: 23,045.28357
Overall Steps per Second: 10,719.77457

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.49563
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.66614

Cumulative Model Updates: 206,366
Cumulative Timesteps: 1,721,089,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.35628
Policy Entropy: 2.19477
Value Function Loss: 0.01782

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.62015

Collected Steps per Second: 23,518.26558
Overall Steps per Second: 10,878.52340

Timestep Collection Time: 2.12703
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.59842

Cumulative Model Updates: 206,372
Cumulative Timesteps: 1,721,139,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1721139192...
Checkpoint 1721139192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.04169
Policy Entropy: 2.21752
Value Function Loss: 0.01757

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 23,112.03073
Overall Steps per Second: 10,988.88858

Timestep Collection Time: 2.16398
Timestep Consumption Time: 2.38734
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.55132

Cumulative Model Updates: 206,378
Cumulative Timesteps: 1,721,189,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.90645
Policy Entropy: 2.20494
Value Function Loss: 0.01713

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.60984

Collected Steps per Second: 23,950.44169
Overall Steps per Second: 11,039.66589

Timestep Collection Time: 2.08806
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.53003

Cumulative Model Updates: 206,384
Cumulative Timesteps: 1,721,239,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1721239216...
Checkpoint 1721239216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.43043
Policy Entropy: 2.20517
Value Function Loss: 0.01791

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 23,247.04673
Overall Steps per Second: 10,824.61419

Timestep Collection Time: 2.15098
Timestep Consumption Time: 2.46849
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.61947

Cumulative Model Updates: 206,390
Cumulative Timesteps: 1,721,289,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.02509
Policy Entropy: 2.20894
Value Function Loss: 0.01739

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.55849
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 23,202.36308
Overall Steps per Second: 10,763.31874

Timestep Collection Time: 2.15573
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.64708

Cumulative Model Updates: 206,396
Cumulative Timesteps: 1,721,339,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1721339238...
Checkpoint 1721339238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.63911
Policy Entropy: 2.19183
Value Function Loss: 0.01778

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.61203

Collected Steps per Second: 23,257.65846
Overall Steps per Second: 11,017.92976

Timestep Collection Time: 2.15095
Timestep Consumption Time: 2.38947
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.54042

Cumulative Model Updates: 206,402
Cumulative Timesteps: 1,721,389,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.36362
Policy Entropy: 2.17326
Value Function Loss: 0.01776

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.59521

Collected Steps per Second: 24,222.14782
Overall Steps per Second: 10,976.52966

Timestep Collection Time: 2.06456
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.55590

Cumulative Model Updates: 206,408
Cumulative Timesteps: 1,721,439,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1721439272...
Checkpoint 1721439272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.03748
Policy Entropy: 2.17471
Value Function Loss: 0.01811

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.61080

Collected Steps per Second: 22,854.64150
Overall Steps per Second: 10,718.25050

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.66662

Cumulative Model Updates: 206,414
Cumulative Timesteps: 1,721,489,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.53596
Policy Entropy: 2.16882
Value Function Loss: 0.01798

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.60863

Collected Steps per Second: 23,376.98698
Overall Steps per Second: 10,805.83591

Timestep Collection Time: 2.13945
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.62842

Cumulative Model Updates: 206,420
Cumulative Timesteps: 1,721,539,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1721539304...
Checkpoint 1721539304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.09465
Policy Entropy: 2.17706
Value Function Loss: 0.01848

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.60613

Collected Steps per Second: 23,045.54378
Overall Steps per Second: 10,813.56075

Timestep Collection Time: 2.16988
Timestep Consumption Time: 2.45450
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.62438

Cumulative Model Updates: 206,426
Cumulative Timesteps: 1,721,589,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.73718
Policy Entropy: 2.16458
Value Function Loss: 0.01815

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.59230

Collected Steps per Second: 23,592.74246
Overall Steps per Second: 11,182.03053

Timestep Collection Time: 2.11930
Timestep Consumption Time: 2.35216
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.47146

Cumulative Model Updates: 206,432
Cumulative Timesteps: 1,721,639,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1721639310...
Checkpoint 1721639310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.71186
Policy Entropy: 2.18320
Value Function Loss: 0.01767

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.55944

Collected Steps per Second: 23,043.43494
Overall Steps per Second: 10,758.93252

Timestep Collection Time: 2.16982
Timestep Consumption Time: 2.47749
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.64730

Cumulative Model Updates: 206,438
Cumulative Timesteps: 1,721,689,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.81489
Policy Entropy: 2.19186
Value Function Loss: 0.01692

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.54443
Value Function Update Magnitude: 0.52627

Collected Steps per Second: 23,457.67785
Overall Steps per Second: 10,769.17846

Timestep Collection Time: 2.13210
Timestep Consumption Time: 2.51208
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.64418

Cumulative Model Updates: 206,444
Cumulative Timesteps: 1,721,739,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1721739324...
Checkpoint 1721739324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.43882
Policy Entropy: 2.18488
Value Function Loss: 0.01821

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.52396

Collected Steps per Second: 23,031.86976
Overall Steps per Second: 10,863.52726

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.60385

Cumulative Model Updates: 206,450
Cumulative Timesteps: 1,721,789,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.71868
Policy Entropy: 2.17752
Value Function Loss: 0.01879

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.53925

Collected Steps per Second: 23,501.36621
Overall Steps per Second: 10,940.80345

Timestep Collection Time: 2.12830
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.57169

Cumulative Model Updates: 206,456
Cumulative Timesteps: 1,721,839,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1721839356...
Checkpoint 1721839356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.58829
Policy Entropy: 2.20963
Value Function Loss: 0.01810

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.53242

Collected Steps per Second: 23,395.99699
Overall Steps per Second: 10,856.15799

Timestep Collection Time: 2.13729
Timestep Consumption Time: 2.46876
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.60605

Cumulative Model Updates: 206,462
Cumulative Timesteps: 1,721,889,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.09624
Policy Entropy: 2.22227
Value Function Loss: 0.01711

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.52988
Value Function Update Magnitude: 0.52039

Collected Steps per Second: 23,501.44910
Overall Steps per Second: 10,917.36790

Timestep Collection Time: 2.12880
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.58261

Cumulative Model Updates: 206,468
Cumulative Timesteps: 1,721,939,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1721939390...
Checkpoint 1721939390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.91843
Policy Entropy: 2.21640
Value Function Loss: 0.01706

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.52017

Collected Steps per Second: 23,298.81829
Overall Steps per Second: 10,834.27796

Timestep Collection Time: 2.14689
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.61683

Cumulative Model Updates: 206,474
Cumulative Timesteps: 1,721,989,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.94523
Policy Entropy: 2.18328
Value Function Loss: 0.01779

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.53369

Collected Steps per Second: 23,487.00417
Overall Steps per Second: 10,921.80153

Timestep Collection Time: 2.13003
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.58056

Cumulative Model Updates: 206,480
Cumulative Timesteps: 1,722,039,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1722039438...
Checkpoint 1722039438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.32521
Policy Entropy: 2.16993
Value Function Loss: 0.01811

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.55935

Collected Steps per Second: 24,046.86537
Overall Steps per Second: 10,984.12955

Timestep Collection Time: 2.07952
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.55257

Cumulative Model Updates: 206,486
Cumulative Timesteps: 1,722,089,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.45028
Policy Entropy: 2.17609
Value Function Loss: 0.01707

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.54152
Value Function Update Magnitude: 0.55316

Collected Steps per Second: 23,679.82312
Overall Steps per Second: 10,862.97414

Timestep Collection Time: 2.11268
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.60537

Cumulative Model Updates: 206,492
Cumulative Timesteps: 1,722,139,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1722139472...
Checkpoint 1722139472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.95777
Policy Entropy: 2.18022
Value Function Loss: 0.01790

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 23,051.87681
Overall Steps per Second: 10,764.60844

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.47732
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.64764

Cumulative Model Updates: 206,498
Cumulative Timesteps: 1,722,189,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.00607
Policy Entropy: 2.17467
Value Function Loss: 0.01874

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.58762

Collected Steps per Second: 23,567.18762
Overall Steps per Second: 10,912.86478

Timestep Collection Time: 2.12168
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.58193

Cumulative Model Updates: 206,504
Cumulative Timesteps: 1,722,239,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1722239504...
Checkpoint 1722239504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.74430
Policy Entropy: 2.17166
Value Function Loss: 0.01852

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.55900
Value Function Update Magnitude: 0.59751

Collected Steps per Second: 22,967.78201
Overall Steps per Second: 10,944.26074

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.39250
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.57025

Cumulative Model Updates: 206,510
Cumulative Timesteps: 1,722,289,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.29369
Policy Entropy: 2.16049
Value Function Loss: 0.01783

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.15369
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.55914

Collected Steps per Second: 23,561.64471
Overall Steps per Second: 10,930.88109

Timestep Collection Time: 2.12337
Timestep Consumption Time: 2.45357
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.57694

Cumulative Model Updates: 206,516
Cumulative Timesteps: 1,722,339,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1722339552...
Checkpoint 1722339552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.80381
Policy Entropy: 2.14753
Value Function Loss: 0.01838

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.55786
Value Function Update Magnitude: 0.55627

Collected Steps per Second: 22,988.95918
Overall Steps per Second: 10,754.64529

Timestep Collection Time: 2.17496
Timestep Consumption Time: 2.47420
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.64915

Cumulative Model Updates: 206,522
Cumulative Timesteps: 1,722,389,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.09687
Policy Entropy: 2.13995
Value Function Loss: 0.01761

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 23,565.48459
Overall Steps per Second: 10,946.29139

Timestep Collection Time: 2.12192
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.56812

Cumulative Model Updates: 206,528
Cumulative Timesteps: 1,722,439,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1722439556...
Checkpoint 1722439556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.65681
Policy Entropy: 2.15206
Value Function Loss: 0.01720

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.56352
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 22,870.99060
Overall Steps per Second: 10,892.19939

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.59228

Cumulative Model Updates: 206,534
Cumulative Timesteps: 1,722,489,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.01232
Policy Entropy: 2.18762
Value Function Loss: 0.01622

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.59207

Collected Steps per Second: 23,314.80028
Overall Steps per Second: 10,964.39437

Timestep Collection Time: 2.14559
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.56240

Cumulative Model Updates: 206,540
Cumulative Timesteps: 1,722,539,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1722539600...
Checkpoint 1722539600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.45801
Policy Entropy: 2.18608
Value Function Loss: 0.01721

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 23,075.53669
Overall Steps per Second: 10,776.58423

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.47339
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.64062

Cumulative Model Updates: 206,546
Cumulative Timesteps: 1,722,589,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.76965
Policy Entropy: 2.21385
Value Function Loss: 0.01677

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.57596

Collected Steps per Second: 23,514.09950
Overall Steps per Second: 10,818.59115

Timestep Collection Time: 2.12655
Timestep Consumption Time: 2.49549
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.62204

Cumulative Model Updates: 206,552
Cumulative Timesteps: 1,722,639,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1722639614...
Checkpoint 1722639614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.12582
Policy Entropy: 2.21267
Value Function Loss: 0.01736

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.57419

Collected Steps per Second: 23,003.15082
Overall Steps per Second: 10,923.68671

Timestep Collection Time: 2.17483
Timestep Consumption Time: 2.40494
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.57977

Cumulative Model Updates: 206,558
Cumulative Timesteps: 1,722,689,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.83766
Policy Entropy: 2.22088
Value Function Loss: 0.01734

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.54120
Value Function Update Magnitude: 0.56925

Collected Steps per Second: 23,532.41361
Overall Steps per Second: 11,023.18827

Timestep Collection Time: 2.12575
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.53807

Cumulative Model Updates: 206,564
Cumulative Timesteps: 1,722,739,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1722739666...
Checkpoint 1722739666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.68910
Policy Entropy: 2.19282
Value Function Loss: 0.01767

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.57387

Collected Steps per Second: 23,069.53408
Overall Steps per Second: 10,808.05232

Timestep Collection Time: 2.16788
Timestep Consumption Time: 2.45941
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.62729

Cumulative Model Updates: 206,570
Cumulative Timesteps: 1,722,789,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.63928
Policy Entropy: 2.17919
Value Function Loss: 0.01768

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.59489

Collected Steps per Second: 23,547.88106
Overall Steps per Second: 10,839.31420

Timestep Collection Time: 2.12359
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.61339

Cumulative Model Updates: 206,576
Cumulative Timesteps: 1,722,839,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1722839684...
Checkpoint 1722839684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.59790
Policy Entropy: 2.19242
Value Function Loss: 0.01719

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.61490

Collected Steps per Second: 22,681.90512
Overall Steps per Second: 10,887.83367

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.38855
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.59357

Cumulative Model Updates: 206,582
Cumulative Timesteps: 1,722,889,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.20333
Policy Entropy: 2.18691
Value Function Loss: 0.01664

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.54764
Value Function Update Magnitude: 0.60460

Collected Steps per Second: 23,460.38139
Overall Steps per Second: 11,078.74966

Timestep Collection Time: 2.13168
Timestep Consumption Time: 2.38237
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.51405

Cumulative Model Updates: 206,588
Cumulative Timesteps: 1,722,939,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1722939708...
Checkpoint 1722939708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.02819
Policy Entropy: 2.18912
Value Function Loss: 0.01649

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.58294

Collected Steps per Second: 23,269.14725
Overall Steps per Second: 11,083.90082

Timestep Collection Time: 2.14954
Timestep Consumption Time: 2.36313
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.51267

Cumulative Model Updates: 206,594
Cumulative Timesteps: 1,722,989,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.52626
Policy Entropy: 2.17283
Value Function Loss: 0.01710

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.57877

Collected Steps per Second: 23,571.18316
Overall Steps per Second: 10,896.99145

Timestep Collection Time: 2.12208
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.59026

Cumulative Model Updates: 206,600
Cumulative Timesteps: 1,723,039,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1723039746...
Checkpoint 1723039746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.89747
Policy Entropy: 2.18018
Value Function Loss: 0.01772

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.59564

Collected Steps per Second: 22,969.32067
Overall Steps per Second: 10,705.92372

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.67143

Cumulative Model Updates: 206,606
Cumulative Timesteps: 1,723,089,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.79094
Policy Entropy: 2.17239
Value Function Loss: 0.01957

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.61775

Collected Steps per Second: 23,654.60698
Overall Steps per Second: 10,956.67600

Timestep Collection Time: 2.11418
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.56434

Cumulative Model Updates: 206,612
Cumulative Timesteps: 1,723,139,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1723139768...
Checkpoint 1723139768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.58764
Policy Entropy: 2.18322
Value Function Loss: 0.01885

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.55451
Value Function Update Magnitude: 0.63035

Collected Steps per Second: 23,118.62783
Overall Steps per Second: 11,018.33993

Timestep Collection Time: 2.16345
Timestep Consumption Time: 2.37589
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.53934

Cumulative Model Updates: 206,618
Cumulative Timesteps: 1,723,189,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.57119
Policy Entropy: 2.16933
Value Function Loss: 0.01896

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.52460
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 23,349.48710
Overall Steps per Second: 10,887.14470

Timestep Collection Time: 2.14206
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.59404

Cumulative Model Updates: 206,624
Cumulative Timesteps: 1,723,239,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1723239800...
Checkpoint 1723239800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.73754
Policy Entropy: 2.19783
Value Function Loss: 0.01789

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.16990
Policy Update Magnitude: 0.51609
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,996.44485
Overall Steps per Second: 10,737.51544

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.65918

Cumulative Model Updates: 206,630
Cumulative Timesteps: 1,723,289,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.99133
Policy Entropy: 2.20338
Value Function Loss: 0.01782

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.18330
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.62572

Collected Steps per Second: 23,323.56949
Overall Steps per Second: 10,830.28919

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.61890

Cumulative Model Updates: 206,636
Cumulative Timesteps: 1,723,339,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1723339852...
Checkpoint 1723339852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.71664
Policy Entropy: 2.21914
Value Function Loss: 0.01696

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16652
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 23,144.02014
Overall Steps per Second: 10,987.29035

Timestep Collection Time: 2.16116
Timestep Consumption Time: 2.39119
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.55235

Cumulative Model Updates: 206,642
Cumulative Timesteps: 1,723,389,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.62470
Policy Entropy: 2.20065
Value Function Loss: 0.01665

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15392
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.60895

Collected Steps per Second: 23,373.58857
Overall Steps per Second: 10,970.90586

Timestep Collection Time: 2.13942
Timestep Consumption Time: 2.41863
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.55806

Cumulative Model Updates: 206,648
Cumulative Timesteps: 1,723,439,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1723439876...
Checkpoint 1723439876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.57996
Policy Entropy: 2.20583
Value Function Loss: 0.01713

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.59509

Collected Steps per Second: 23,167.31557
Overall Steps per Second: 10,770.91769

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.64324

Cumulative Model Updates: 206,654
Cumulative Timesteps: 1,723,489,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.13914
Policy Entropy: 2.19219
Value Function Loss: 0.01764

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.58409

Collected Steps per Second: 23,185.03664
Overall Steps per Second: 10,814.62091

Timestep Collection Time: 2.15665
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.62356

Cumulative Model Updates: 206,660
Cumulative Timesteps: 1,723,539,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1723539890...
Checkpoint 1723539890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.19680
Policy Entropy: 2.20648
Value Function Loss: 0.01767

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.58750

Collected Steps per Second: 22,916.43142
Overall Steps per Second: 10,836.51193

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.61458

Cumulative Model Updates: 206,666
Cumulative Timesteps: 1,723,589,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.56359
Policy Entropy: 2.20886
Value Function Loss: 0.01681

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.59350

Collected Steps per Second: 23,525.72758
Overall Steps per Second: 11,035.95024

Timestep Collection Time: 2.12610
Timestep Consumption Time: 2.40618
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.53228

Cumulative Model Updates: 206,672
Cumulative Timesteps: 1,723,639,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1723639914...
Checkpoint 1723639914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.03244
Policy Entropy: 2.23645
Value Function Loss: 0.01740

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.58827

Collected Steps per Second: 22,893.20799
Overall Steps per Second: 10,783.36841

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.45399
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.63918

Cumulative Model Updates: 206,678
Cumulative Timesteps: 1,723,689,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.81899
Policy Entropy: 2.25924
Value Function Loss: 0.01674

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.58655

Collected Steps per Second: 23,521.55515
Overall Steps per Second: 10,928.19771

Timestep Collection Time: 2.12665
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.57733

Cumulative Model Updates: 206,684
Cumulative Timesteps: 1,723,739,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1723739962...
Checkpoint 1723739962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.48007
Policy Entropy: 2.23827
Value Function Loss: 0.01762

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.59122

Collected Steps per Second: 22,718.82476
Overall Steps per Second: 10,741.00197

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.45434
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.65525

Cumulative Model Updates: 206,690
Cumulative Timesteps: 1,723,789,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.64206
Policy Entropy: 2.21186
Value Function Loss: 0.01773

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 23,553.62642
Overall Steps per Second: 11,140.49621

Timestep Collection Time: 2.12307
Timestep Consumption Time: 2.36560
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.48867

Cumulative Model Updates: 206,696
Cumulative Timesteps: 1,723,839,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1723839970...
Checkpoint 1723839970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.17951
Policy Entropy: 2.18934
Value Function Loss: 0.01788

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.56187
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 22,797.59012
Overall Steps per Second: 10,729.18851

Timestep Collection Time: 2.19453
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.66298

Cumulative Model Updates: 206,702
Cumulative Timesteps: 1,723,890,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.34869
Policy Entropy: 2.18493
Value Function Loss: 0.01817

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.63216

Collected Steps per Second: 23,579.92293
Overall Steps per Second: 10,937.36346

Timestep Collection Time: 2.12053
Timestep Consumption Time: 2.45114
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.57167

Cumulative Model Updates: 206,708
Cumulative Timesteps: 1,723,940,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1723940002...
Checkpoint 1723940002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.34994
Policy Entropy: 2.17612
Value Function Loss: 0.01791

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.63210

Collected Steps per Second: 23,153.24600
Overall Steps per Second: 10,777.09371

Timestep Collection Time: 2.16004
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.64058

Cumulative Model Updates: 206,714
Cumulative Timesteps: 1,723,990,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.96451
Policy Entropy: 2.17739
Value Function Loss: 0.01655

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.60953

Collected Steps per Second: 23,362.15142
Overall Steps per Second: 10,818.77620

Timestep Collection Time: 2.14073
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.62270

Cumulative Model Updates: 206,720
Cumulative Timesteps: 1,724,040,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1724040026...
Checkpoint 1724040026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.96862
Policy Entropy: 2.20942
Value Function Loss: 0.01587

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.56182

Collected Steps per Second: 23,933.15899
Overall Steps per Second: 11,068.26818

Timestep Collection Time: 2.09041
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.52013

Cumulative Model Updates: 206,726
Cumulative Timesteps: 1,724,090,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.09745
Policy Entropy: 2.23078
Value Function Loss: 0.01565

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.53266

Collected Steps per Second: 23,459.24838
Overall Steps per Second: 10,914.73050

Timestep Collection Time: 2.13170
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.58170

Cumulative Model Updates: 206,732
Cumulative Timesteps: 1,724,140,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1724140064...
Checkpoint 1724140064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.44204
Policy Entropy: 2.24122
Value Function Loss: 0.01616

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 22,922.68442
Overall Steps per Second: 10,749.44963

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.65363

Cumulative Model Updates: 206,738
Cumulative Timesteps: 1,724,190,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.33032
Policy Entropy: 2.19696
Value Function Loss: 0.01642

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.53593

Collected Steps per Second: 23,409.00422
Overall Steps per Second: 11,019.81206

Timestep Collection Time: 2.13653
Timestep Consumption Time: 2.40202
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.53855

Cumulative Model Updates: 206,744
Cumulative Timesteps: 1,724,240,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1724240102...
Checkpoint 1724240102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.90158
Policy Entropy: 2.20605
Value Function Loss: 0.01782

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.53668

Collected Steps per Second: 23,309.90271
Overall Steps per Second: 10,928.90300

Timestep Collection Time: 2.14553
Timestep Consumption Time: 2.43060
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.57612

Cumulative Model Updates: 206,750
Cumulative Timesteps: 1,724,290,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.26296
Policy Entropy: 2.18741
Value Function Loss: 0.01842

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.55649

Collected Steps per Second: 23,395.64938
Overall Steps per Second: 10,918.08374

Timestep Collection Time: 2.13766
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.58066

Cumulative Model Updates: 206,756
Cumulative Timesteps: 1,724,340,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1724340126...
Checkpoint 1724340126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.61155
Policy Entropy: 2.20907
Value Function Loss: 0.01855

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.56969

Collected Steps per Second: 22,880.64828
Overall Steps per Second: 10,831.59315

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.61853

Cumulative Model Updates: 206,762
Cumulative Timesteps: 1,724,390,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.18112
Policy Entropy: 2.19285
Value Function Loss: 0.01772

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.57013

Collected Steps per Second: 23,435.63504
Overall Steps per Second: 10,955.27549

Timestep Collection Time: 2.13393
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.56492

Cumulative Model Updates: 206,768
Cumulative Timesteps: 1,724,440,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1724440162...
Checkpoint 1724440162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.32584
Policy Entropy: 2.19439
Value Function Loss: 0.01747

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 22,775.29638
Overall Steps per Second: 10,836.97700

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.41973
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.61623

Cumulative Model Updates: 206,774
Cumulative Timesteps: 1,724,490,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.00150
Policy Entropy: 2.20926
Value Function Loss: 0.01647

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.59008

Collected Steps per Second: 23,934.08591
Overall Steps per Second: 10,912.39518

Timestep Collection Time: 2.08907
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.58195

Cumulative Model Updates: 206,780
Cumulative Timesteps: 1,724,540,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1724540188...
Checkpoint 1724540188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.91524
Policy Entropy: 2.18266
Value Function Loss: 0.01726

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.59009

Collected Steps per Second: 23,373.56090
Overall Steps per Second: 10,864.30498

Timestep Collection Time: 2.14002
Timestep Consumption Time: 2.46404
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.60407

Cumulative Model Updates: 206,786
Cumulative Timesteps: 1,724,590,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.31192
Policy Entropy: 2.18482
Value Function Loss: 0.01652

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.60669

Collected Steps per Second: 23,245.71179
Overall Steps per Second: 10,883.79563

Timestep Collection Time: 2.15128
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.59472

Cumulative Model Updates: 206,792
Cumulative Timesteps: 1,724,640,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1724640216...
Checkpoint 1724640216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.16806
Policy Entropy: 2.19600
Value Function Loss: 0.01713

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 23,265.98794
Overall Steps per Second: 10,957.09771

Timestep Collection Time: 2.15026
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.56581

Cumulative Model Updates: 206,798
Cumulative Timesteps: 1,724,690,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.80743
Policy Entropy: 2.18786
Value Function Loss: 0.01812

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 23,633.96495
Overall Steps per Second: 10,852.67006

Timestep Collection Time: 2.11661
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.60937

Cumulative Model Updates: 206,804
Cumulative Timesteps: 1,724,740,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1724740268...
Checkpoint 1724740268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.79362
Policy Entropy: 2.20423
Value Function Loss: 0.01900

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.65522

Collected Steps per Second: 23,201.98527
Overall Steps per Second: 10,789.01445

Timestep Collection Time: 2.15628
Timestep Consumption Time: 2.48084
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.63712

Cumulative Model Updates: 206,810
Cumulative Timesteps: 1,724,790,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.37295
Policy Entropy: 2.18691
Value Function Loss: 0.01878

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.66930

Collected Steps per Second: 23,331.62831
Overall Steps per Second: 10,764.17205

Timestep Collection Time: 2.14327
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.64560

Cumulative Model Updates: 206,816
Cumulative Timesteps: 1,724,840,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1724840304...
Checkpoint 1724840304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.75393
Policy Entropy: 2.19905
Value Function Loss: 0.01879

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.56838
Value Function Update Magnitude: 0.68613

Collected Steps per Second: 22,943.66781
Overall Steps per Second: 9,616.95555

Timestep Collection Time: 2.18047
Timestep Consumption Time: 3.02159
PPO Batch Consumption Time: 0.38391
Total Iteration Time: 5.20206

Cumulative Model Updates: 206,822
Cumulative Timesteps: 1,724,890,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.73540
Policy Entropy: 2.20790
Value Function Loss: 0.01847

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.70570

Collected Steps per Second: 10,020.42696
Overall Steps per Second: 6,381.88870

Timestep Collection Time: 4.99081
Timestep Consumption Time: 2.84543
PPO Batch Consumption Time: 0.33760
Total Iteration Time: 7.83624

Cumulative Model Updates: 206,828
Cumulative Timesteps: 1,724,940,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1724940342...
Checkpoint 1724940342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.68906
Policy Entropy: 2.19770
Value Function Loss: 0.01738

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.16562
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.68132

Collected Steps per Second: 18,440.28051
Overall Steps per Second: 9,279.49268

Timestep Collection Time: 2.71146
Timestep Consumption Time: 2.67677
PPO Batch Consumption Time: 0.31279
Total Iteration Time: 5.38823

Cumulative Model Updates: 206,834
Cumulative Timesteps: 1,724,990,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.97130
Policy Entropy: 2.21635
Value Function Loss: 0.01645

Mean KL Divergence: 0.02499
SB3 Clip Fraction: 0.17327
Policy Update Magnitude: 0.48913
Value Function Update Magnitude: 0.64122

Collected Steps per Second: 21,425.78368
Overall Steps per Second: 9,977.70617

Timestep Collection Time: 2.33420
Timestep Consumption Time: 2.67818
PPO Batch Consumption Time: 0.31622
Total Iteration Time: 5.01237

Cumulative Model Updates: 206,840
Cumulative Timesteps: 1,725,040,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1725040354...
Checkpoint 1725040354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.88717
Policy Entropy: 2.18969
Value Function Loss: 0.01626

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.52795
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 21,623.24585
Overall Steps per Second: 10,295.83527

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.54543
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.85905

Cumulative Model Updates: 206,846
Cumulative Timesteps: 1,725,090,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.14469
Policy Entropy: 2.19391
Value Function Loss: 0.01724

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 21,843.91389
Overall Steps per Second: 10,425.80124

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.79714

Cumulative Model Updates: 206,852
Cumulative Timesteps: 1,725,140,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1725140396...
Checkpoint 1725140396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.17206
Policy Entropy: 2.20096
Value Function Loss: 0.01706

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.60569

Collected Steps per Second: 21,595.80943
Overall Steps per Second: 10,437.99209

Timestep Collection Time: 2.31619
Timestep Consumption Time: 2.47592
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.79211

Cumulative Model Updates: 206,858
Cumulative Timesteps: 1,725,190,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.96443
Policy Entropy: 2.20854
Value Function Loss: 0.01782

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,176.63224
Overall Steps per Second: 10,294.06782

Timestep Collection Time: 2.25508
Timestep Consumption Time: 2.60306
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.85814

Cumulative Model Updates: 206,864
Cumulative Timesteps: 1,725,240,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1725240426...
Checkpoint 1725240426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.23016
Policy Entropy: 2.21873
Value Function Loss: 0.01672

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 21,961.73241
Overall Steps per Second: 10,262.34594

Timestep Collection Time: 2.27760
Timestep Consumption Time: 2.59653
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 4.87413

Cumulative Model Updates: 206,870
Cumulative Timesteps: 1,725,290,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.49205
Policy Entropy: 2.22668
Value Function Loss: 0.01641

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.17401
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 21,887.55160
Overall Steps per Second: 10,377.86710

Timestep Collection Time: 2.28449
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.81814

Cumulative Model Updates: 206,876
Cumulative Timesteps: 1,725,340,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1725340448...
Checkpoint 1725340448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.17520
Policy Entropy: 2.20918
Value Function Loss: 0.01595

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.16110
Policy Update Magnitude: 0.54145
Value Function Update Magnitude: 0.64599

Collected Steps per Second: 21,783.70826
Overall Steps per Second: 10,325.66965

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.54772
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 4.84366

Cumulative Model Updates: 206,882
Cumulative Timesteps: 1,725,390,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.63635
Policy Entropy: 2.18849
Value Function Loss: 0.01674

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.17008
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 21,785.80036
Overall Steps per Second: 10,426.11099

Timestep Collection Time: 2.29507
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.79565

Cumulative Model Updates: 206,888
Cumulative Timesteps: 1,725,440,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1725440462...
Checkpoint 1725440462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.40417
Policy Entropy: 2.18301
Value Function Loss: 0.01681

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 21,633.63208
Overall Steps per Second: 10,212.69380

Timestep Collection Time: 2.31168
Timestep Consumption Time: 2.58517
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.89685

Cumulative Model Updates: 206,894
Cumulative Timesteps: 1,725,490,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.34886
Policy Entropy: 2.17958
Value Function Loss: 0.01795

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.17098
Policy Update Magnitude: 0.53656
Value Function Update Magnitude: 0.63398

Collected Steps per Second: 21,961.30755
Overall Steps per Second: 10,340.55749

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.55983
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.83765

Cumulative Model Updates: 206,900
Cumulative Timesteps: 1,725,540,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1725540496...
Checkpoint 1725540496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.33430
Policy Entropy: 2.20005
Value Function Loss: 0.01775

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.16725
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 21,876.37747
Overall Steps per Second: 10,408.24798

Timestep Collection Time: 2.28612
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.80504

Cumulative Model Updates: 206,906
Cumulative Timesteps: 1,725,590,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.59139
Policy Entropy: 2.18607
Value Function Loss: 0.01780

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.66240

Collected Steps per Second: 21,929.66590
Overall Steps per Second: 10,325.83806

Timestep Collection Time: 2.28065
Timestep Consumption Time: 2.56292
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 4.84358

Cumulative Model Updates: 206,912
Cumulative Timesteps: 1,725,640,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1725640522...
Checkpoint 1725640522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.29216
Policy Entropy: 2.19199
Value Function Loss: 0.01699

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.65586

Collected Steps per Second: 21,777.70236
Overall Steps per Second: 10,569.57068

Timestep Collection Time: 2.29712
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.73302

Cumulative Model Updates: 206,918
Cumulative Timesteps: 1,725,690,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.65429
Policy Entropy: 2.20962
Value Function Loss: 0.01674

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.61702

Collected Steps per Second: 21,920.68041
Overall Steps per Second: 10,411.85446

Timestep Collection Time: 2.28168
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.80376

Cumulative Model Updates: 206,924
Cumulative Timesteps: 1,725,740,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1725740564...
Checkpoint 1725740564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.07196
Policy Entropy: 2.22097
Value Function Loss: 0.01773

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 21,865.32368
Overall Steps per Second: 10,276.07048

Timestep Collection Time: 2.28764
Timestep Consumption Time: 2.57998
PPO Batch Consumption Time: 0.30369
Total Iteration Time: 4.86762

Cumulative Model Updates: 206,930
Cumulative Timesteps: 1,725,790,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.82502
Policy Entropy: 2.24199
Value Function Loss: 0.01766

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.57344

Collected Steps per Second: 21,803.74416
Overall Steps per Second: 10,359.00218

Timestep Collection Time: 2.29410
Timestep Consumption Time: 2.53455
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.82865

Cumulative Model Updates: 206,936
Cumulative Timesteps: 1,725,840,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1725840604...
Checkpoint 1725840604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.78245
Policy Entropy: 2.22167
Value Function Loss: 0.01791

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.55581

Collected Steps per Second: 21,924.99415
Overall Steps per Second: 10,317.54946

Timestep Collection Time: 2.28178
Timestep Consumption Time: 2.56705
PPO Batch Consumption Time: 0.30568
Total Iteration Time: 4.84883

Cumulative Model Updates: 206,942
Cumulative Timesteps: 1,725,890,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.13769
Policy Entropy: 2.22812
Value Function Loss: 0.01693

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.56456

Collected Steps per Second: 21,528.31494
Overall Steps per Second: 10,456.03132

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.46009
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.78327

Cumulative Model Updates: 206,948
Cumulative Timesteps: 1,725,940,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1725940646...
Checkpoint 1725940646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.53565
Policy Entropy: 2.20784
Value Function Loss: 0.01727

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.60231

Collected Steps per Second: 21,880.54763
Overall Steps per Second: 10,304.82112

Timestep Collection Time: 2.28577
Timestep Consumption Time: 2.56768
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.85346

Cumulative Model Updates: 206,954
Cumulative Timesteps: 1,725,990,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.25634
Policy Entropy: 2.21309
Value Function Loss: 0.01648

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 21,455.17811
Overall Steps per Second: 10,272.82199

Timestep Collection Time: 2.33174
Timestep Consumption Time: 2.53819
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.86994

Cumulative Model Updates: 206,960
Cumulative Timesteps: 1,726,040,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1726040688...
Checkpoint 1726040688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.73920
Policy Entropy: 2.22737
Value Function Loss: 0.01762

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.58700

Collected Steps per Second: 21,848.01983
Overall Steps per Second: 10,293.96484

Timestep Collection Time: 2.28982
Timestep Consumption Time: 2.57012
PPO Batch Consumption Time: 0.30504
Total Iteration Time: 4.85994

Cumulative Model Updates: 206,966
Cumulative Timesteps: 1,726,090,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.78063
Policy Entropy: 2.21066
Value Function Loss: 0.01660

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.57636

Collected Steps per Second: 21,956.67823
Overall Steps per Second: 10,472.84971

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.77578

Cumulative Model Updates: 206,972
Cumulative Timesteps: 1,726,140,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1726140732...
Checkpoint 1726140732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.63089
Policy Entropy: 2.20142
Value Function Loss: 0.01681

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.56569

Collected Steps per Second: 21,764.67743
Overall Steps per Second: 10,226.30799

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.59205
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.88935

Cumulative Model Updates: 206,978
Cumulative Timesteps: 1,726,190,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.88741
Policy Entropy: 2.20048
Value Function Loss: 0.01669

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.52728
Value Function Update Magnitude: 0.56195

Collected Steps per Second: 21,785.47699
Overall Steps per Second: 10,345.10681

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.53891
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.83475

Cumulative Model Updates: 206,984
Cumulative Timesteps: 1,726,240,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1726240748...
Checkpoint 1726240748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.06590
Policy Entropy: 2.21279
Value Function Loss: 0.01715

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.16972
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.57706

Collected Steps per Second: 21,504.43304
Overall Steps per Second: 10,216.75306

Timestep Collection Time: 2.32538
Timestep Consumption Time: 2.56913
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.89451

Cumulative Model Updates: 206,990
Cumulative Timesteps: 1,726,290,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.54521
Policy Entropy: 2.21203
Value Function Loss: 0.01804

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.17371
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.58611

Collected Steps per Second: 22,015.29089
Overall Steps per Second: 10,440.40664

Timestep Collection Time: 2.27188
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.79062

Cumulative Model Updates: 206,996
Cumulative Timesteps: 1,726,340,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1726340770...
Checkpoint 1726340770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.02696
Policy Entropy: 2.20308
Value Function Loss: 0.01810

Mean KL Divergence: 0.02731
SB3 Clip Fraction: 0.18240
Policy Update Magnitude: 0.52660
Value Function Update Magnitude: 0.60829

Collected Steps per Second: 21,912.78662
Overall Steps per Second: 10,582.71663

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72714

Cumulative Model Updates: 207,002
Cumulative Timesteps: 1,726,390,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.86303
Policy Entropy: 2.19046
Value Function Loss: 0.01934

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.17466
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 21,340.93852
Overall Steps per Second: 10,384.44065

Timestep Collection Time: 2.34366
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.81644

Cumulative Model Updates: 207,008
Cumulative Timesteps: 1,726,440,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1726440812...
Checkpoint 1726440812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.28077
Policy Entropy: 2.18750
Value Function Loss: 0.01897

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.56073
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 21,912.17663
Overall Steps per Second: 10,428.94938

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.79722

Cumulative Model Updates: 207,014
Cumulative Timesteps: 1,726,490,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.97944
Policy Entropy: 2.18182
Value Function Loss: 0.01827

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.16936
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.64278

Collected Steps per Second: 22,253.69974
Overall Steps per Second: 10,481.35063

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.77324

Cumulative Model Updates: 207,020
Cumulative Timesteps: 1,726,540,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1726540872...
Checkpoint 1726540872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.86062
Policy Entropy: 2.16382
Value Function Loss: 0.01712

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.18176
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.60686

Collected Steps per Second: 21,537.41185
Overall Steps per Second: 10,267.35720

Timestep Collection Time: 2.32303
Timestep Consumption Time: 2.54989
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.87292

Cumulative Model Updates: 207,026
Cumulative Timesteps: 1,726,590,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.88241
Policy Entropy: 2.17733
Value Function Loss: 0.01713

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.59926

Collected Steps per Second: 21,904.63360
Overall Steps per Second: 10,465.01195

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.30211
Total Iteration Time: 4.77916

Cumulative Model Updates: 207,032
Cumulative Timesteps: 1,726,640,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1726640918...
Checkpoint 1726640918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.51526
Policy Entropy: 2.17888
Value Function Loss: 0.01669

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 22,046.11547
Overall Steps per Second: 10,424.99589

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.79674

Cumulative Model Updates: 207,038
Cumulative Timesteps: 1,726,690,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.40999
Policy Entropy: 2.21609
Value Function Loss: 0.01631

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.56174
Value Function Update Magnitude: 0.61199

Collected Steps per Second: 22,165.37845
Overall Steps per Second: 10,464.49491

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.77997

Cumulative Model Updates: 207,044
Cumulative Timesteps: 1,726,740,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1726740944...
Checkpoint 1726740944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.18605
Policy Entropy: 2.22412
Value Function Loss: 0.01579

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.58008

Collected Steps per Second: 21,939.93745
Overall Steps per Second: 10,344.73678

Timestep Collection Time: 2.27931
Timestep Consumption Time: 2.55484
PPO Batch Consumption Time: 0.30443
Total Iteration Time: 4.83415

Cumulative Model Updates: 207,050
Cumulative Timesteps: 1,726,790,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.43816
Policy Entropy: 2.20705
Value Function Loss: 0.01684

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.57521

Collected Steps per Second: 21,954.22352
Overall Steps per Second: 10,414.99481

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.52391
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.80192

Cumulative Model Updates: 207,056
Cumulative Timesteps: 1,726,840,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1726840964...
Checkpoint 1726840964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.34234
Policy Entropy: 2.19364
Value Function Loss: 0.01755

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.59912

Collected Steps per Second: 21,610.43092
Overall Steps per Second: 10,505.25375

Timestep Collection Time: 2.31370
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.75952

Cumulative Model Updates: 207,062
Cumulative Timesteps: 1,726,890,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.89979
Policy Entropy: 2.19135
Value Function Loss: 0.01705

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.59436

Collected Steps per Second: 22,387.07579
Overall Steps per Second: 10,516.67415

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.52123
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.75493

Cumulative Model Updates: 207,068
Cumulative Timesteps: 1,726,940,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1726940970...
Checkpoint 1726940970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.25177
Policy Entropy: 2.20879
Value Function Loss: 0.01662

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.58837

Collected Steps per Second: 21,478.65693
Overall Steps per Second: 10,289.72171

Timestep Collection Time: 2.32910
Timestep Consumption Time: 2.53264
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.86174

Cumulative Model Updates: 207,074
Cumulative Timesteps: 1,726,990,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.66089
Policy Entropy: 2.20575
Value Function Loss: 0.01628

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.60759

Collected Steps per Second: 22,183.38358
Overall Steps per Second: 10,456.49082

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.52849
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.78306

Cumulative Model Updates: 207,080
Cumulative Timesteps: 1,727,041,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1727041010...
Checkpoint 1727041010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.70798
Policy Entropy: 2.22581
Value Function Loss: 0.01600

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.62746

Collected Steps per Second: 21,559.97005
Overall Steps per Second: 10,490.20262

Timestep Collection Time: 2.31985
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.76788

Cumulative Model Updates: 207,086
Cumulative Timesteps: 1,727,091,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.12422
Policy Entropy: 2.19958
Value Function Loss: 0.01650

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.63609

Collected Steps per Second: 22,393.81603
Overall Steps per Second: 10,488.35661

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76986

Cumulative Model Updates: 207,092
Cumulative Timesteps: 1,727,141,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1727141054...
Checkpoint 1727141054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.59549
Policy Entropy: 2.19325
Value Function Loss: 0.01642

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.63327

Collected Steps per Second: 21,440.81690
Overall Steps per Second: 10,337.88583

Timestep Collection Time: 2.33340
Timestep Consumption Time: 2.50608
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.83948

Cumulative Model Updates: 207,098
Cumulative Timesteps: 1,727,191,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.60900
Policy Entropy: 2.15850
Value Function Loss: 0.01659

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.63101

Collected Steps per Second: 21,903.43216
Overall Steps per Second: 10,466.82881

Timestep Collection Time: 2.28393
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.77948

Cumulative Model Updates: 207,104
Cumulative Timesteps: 1,727,241,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1727241110...
Checkpoint 1727241110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.58928
Policy Entropy: 2.19375
Value Function Loss: 0.01694

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.55282
Value Function Update Magnitude: 0.61574

Collected Steps per Second: 22,152.26263
Overall Steps per Second: 10,392.88060

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.55439
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.81195

Cumulative Model Updates: 207,110
Cumulative Timesteps: 1,727,291,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.96283
Policy Entropy: 2.21262
Value Function Loss: 0.01614

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 22,291.66834
Overall Steps per Second: 10,342.06731

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.59329
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.83772

Cumulative Model Updates: 207,116
Cumulative Timesteps: 1,727,341,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1727341152...
Checkpoint 1727341152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.53028
Policy Entropy: 2.24223
Value Function Loss: 0.01616

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.52761
Value Function Update Magnitude: 0.59727

Collected Steps per Second: 21,448.10477
Overall Steps per Second: 10,168.13059

Timestep Collection Time: 2.33158
Timestep Consumption Time: 2.58653
PPO Batch Consumption Time: 0.30457
Total Iteration Time: 4.91811

Cumulative Model Updates: 207,122
Cumulative Timesteps: 1,727,391,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.09823
Policy Entropy: 2.21708
Value Function Loss: 0.01554

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.59975

Collected Steps per Second: 21,180.81565
Overall Steps per Second: 10,271.00698

Timestep Collection Time: 2.36082
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.86846

Cumulative Model Updates: 207,128
Cumulative Timesteps: 1,727,441,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1727441164...
Checkpoint 1727441164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.67885
Policy Entropy: 2.24003
Value Function Loss: 0.01632

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.60840

Collected Steps per Second: 21,890.49232
Overall Steps per Second: 10,472.31830

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.77736

Cumulative Model Updates: 207,134
Cumulative Timesteps: 1,727,491,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.22592
Policy Entropy: 2.23203
Value Function Loss: 0.01733

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.63341

Collected Steps per Second: 22,007.72540
Overall Steps per Second: 10,343.22473

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.56338
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.83640

Cumulative Model Updates: 207,140
Cumulative Timesteps: 1,727,541,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1727541218...
Checkpoint 1727541218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.93074
Policy Entropy: 2.21050
Value Function Loss: 0.01723

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.64913

Collected Steps per Second: 21,558.43139
Overall Steps per Second: 10,198.32535

Timestep Collection Time: 2.31993
Timestep Consumption Time: 2.58421
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 4.90414

Cumulative Model Updates: 207,146
Cumulative Timesteps: 1,727,591,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.20836
Policy Entropy: 2.19486
Value Function Loss: 0.01610

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.65106

Collected Steps per Second: 21,956.65799
Overall Steps per Second: 10,468.32550

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.77784

Cumulative Model Updates: 207,152
Cumulative Timesteps: 1,727,641,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1727641248...
Checkpoint 1727641248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.43628
Policy Entropy: 2.18469
Value Function Loss: 0.01569

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.53535
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 21,760.62925
Overall Steps per Second: 10,549.22752

Timestep Collection Time: 2.29800
Timestep Consumption Time: 2.44225
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74025

Cumulative Model Updates: 207,158
Cumulative Timesteps: 1,727,691,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.84849
Policy Entropy: 2.19000
Value Function Loss: 0.01650

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.62925

Collected Steps per Second: 22,358.70475
Overall Steps per Second: 10,485.09367

Timestep Collection Time: 2.23662
Timestep Consumption Time: 2.53281
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.76944

Cumulative Model Updates: 207,164
Cumulative Timesteps: 1,727,741,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1727741262...
Checkpoint 1727741262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.91968
Policy Entropy: 2.16537
Value Function Loss: 0.01785

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.56230
Value Function Update Magnitude: 0.65169

Collected Steps per Second: 21,778.00987
Overall Steps per Second: 10,261.99555

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.57790
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.87508

Cumulative Model Updates: 207,170
Cumulative Timesteps: 1,727,791,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.80564
Policy Entropy: 2.15725
Value Function Loss: 0.01826

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.64778

Collected Steps per Second: 21,779.68150
Overall Steps per Second: 10,419.37136

Timestep Collection Time: 2.29608
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.79952

Cumulative Model Updates: 207,176
Cumulative Timesteps: 1,727,841,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1727841298...
Checkpoint 1727841298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.48281
Policy Entropy: 2.16669
Value Function Loss: 0.01835

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.56037
Value Function Update Magnitude: 0.63314

Collected Steps per Second: 21,746.59186
Overall Steps per Second: 10,319.11262

Timestep Collection Time: 2.29995
Timestep Consumption Time: 2.54698
PPO Batch Consumption Time: 0.30315
Total Iteration Time: 4.84693

Cumulative Model Updates: 207,182
Cumulative Timesteps: 1,727,891,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.93369
Policy Entropy: 2.18448
Value Function Loss: 0.01867

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.59551

Collected Steps per Second: 22,549.59707
Overall Steps per Second: 10,392.09383

Timestep Collection Time: 2.21760
Timestep Consumption Time: 2.59433
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 4.81193

Cumulative Model Updates: 207,188
Cumulative Timesteps: 1,727,941,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1727941320...
Checkpoint 1727941320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.60938
Policy Entropy: 2.20944
Value Function Loss: 0.01771

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.58298

Collected Steps per Second: 21,923.94162
Overall Steps per Second: 10,334.29100

Timestep Collection Time: 2.28098
Timestep Consumption Time: 2.55806
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.83904

Cumulative Model Updates: 207,194
Cumulative Timesteps: 1,727,991,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.08269
Policy Entropy: 2.20831
Value Function Loss: 0.01735

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.58451

Collected Steps per Second: 22,218.12503
Overall Steps per Second: 10,302.34212

Timestep Collection Time: 2.25086
Timestep Consumption Time: 2.60337
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.85424

Cumulative Model Updates: 207,200
Cumulative Timesteps: 1,728,041,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1728041338...
Checkpoint 1728041338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.23523
Policy Entropy: 2.20512
Value Function Loss: 0.01643

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.59301

Collected Steps per Second: 21,901.30466
Overall Steps per Second: 10,350.63131

Timestep Collection Time: 2.28434
Timestep Consumption Time: 2.54918
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.83352

Cumulative Model Updates: 207,206
Cumulative Timesteps: 1,728,091,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.23404
Policy Entropy: 2.19814
Value Function Loss: 0.01633

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.52704
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 22,489.85354
Overall Steps per Second: 10,420.27136

Timestep Collection Time: 2.22447
Timestep Consumption Time: 2.57656
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 4.80103

Cumulative Model Updates: 207,212
Cumulative Timesteps: 1,728,141,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1728141396...
Checkpoint 1728141396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.20224
Policy Entropy: 2.19641
Value Function Loss: 0.01722

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 21,842.57654
Overall Steps per Second: 10,342.16290

Timestep Collection Time: 2.29048
Timestep Consumption Time: 2.54700
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.83748

Cumulative Model Updates: 207,218
Cumulative Timesteps: 1,728,191,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.66243
Policy Entropy: 2.19461
Value Function Loss: 0.01765

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.60203

Collected Steps per Second: 21,892.06131
Overall Steps per Second: 10,250.67074

Timestep Collection Time: 2.28402
Timestep Consumption Time: 2.59390
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.87792

Cumulative Model Updates: 207,224
Cumulative Timesteps: 1,728,241,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1728241428...
Checkpoint 1728241428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.98640
Policy Entropy: 2.17488
Value Function Loss: 0.01759

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.55100
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 21,755.71396
Overall Steps per Second: 10,540.20556

Timestep Collection Time: 2.29825
Timestep Consumption Time: 2.44549
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.74374

Cumulative Model Updates: 207,230
Cumulative Timesteps: 1,728,291,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.24958
Policy Entropy: 2.16794
Value Function Loss: 0.01745

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 21,870.36487
Overall Steps per Second: 10,373.97159

Timestep Collection Time: 2.28675
Timestep Consumption Time: 2.53416
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.82091

Cumulative Model Updates: 207,236
Cumulative Timesteps: 1,728,341,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1728341440...
Checkpoint 1728341440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.91979
Policy Entropy: 2.16281
Value Function Loss: 0.01721

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 22,014.21627
Overall Steps per Second: 10,385.52718

Timestep Collection Time: 2.27162
Timestep Consumption Time: 2.54354
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.81516

Cumulative Model Updates: 207,242
Cumulative Timesteps: 1,728,391,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.55132
Policy Entropy: 2.17669
Value Function Loss: 0.01727

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.62011

Collected Steps per Second: 21,811.66443
Overall Steps per Second: 10,381.92716

Timestep Collection Time: 2.29272
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.81683

Cumulative Model Updates: 207,248
Cumulative Timesteps: 1,728,441,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1728441456...
Checkpoint 1728441456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.44781
Policy Entropy: 2.19136
Value Function Loss: 0.01619

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 21,850.04757
Overall Steps per Second: 10,316.18120

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.55956
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.84889

Cumulative Model Updates: 207,254
Cumulative Timesteps: 1,728,491,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.66570
Policy Entropy: 2.19106
Value Function Loss: 0.01537

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.59393

Collected Steps per Second: 21,527.77264
Overall Steps per Second: 10,412.49798

Timestep Collection Time: 2.32258
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.80192

Cumulative Model Updates: 207,260
Cumulative Timesteps: 1,728,541,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1728541478...
Checkpoint 1728541478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.99894
Policy Entropy: 2.16354
Value Function Loss: 0.01580

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.58745

Collected Steps per Second: 22,009.64011
Overall Steps per Second: 10,291.82513

Timestep Collection Time: 2.27300
Timestep Consumption Time: 2.58794
PPO Batch Consumption Time: 0.30429
Total Iteration Time: 4.86095

Cumulative Model Updates: 207,266
Cumulative Timesteps: 1,728,591,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.99264
Policy Entropy: 2.14059
Value Function Loss: 0.01625

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.59071

Collected Steps per Second: 22,014.05597
Overall Steps per Second: 10,385.41891

Timestep Collection Time: 2.27246
Timestep Consumption Time: 2.54449
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.81695

Cumulative Model Updates: 207,272
Cumulative Timesteps: 1,728,641,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1728641532...
Checkpoint 1728641532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.50453
Policy Entropy: 2.13825
Value Function Loss: 0.01716

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.54588
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 21,799.94565
Overall Steps per Second: 10,332.08435

Timestep Collection Time: 2.29358
Timestep Consumption Time: 2.54571
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.83929

Cumulative Model Updates: 207,278
Cumulative Timesteps: 1,728,691,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.14498
Policy Entropy: 2.15854
Value Function Loss: 0.01787

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.56037
Value Function Update Magnitude: 0.60598

Collected Steps per Second: 22,144.14956
Overall Steps per Second: 10,669.68438

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.68805

Cumulative Model Updates: 207,284
Cumulative Timesteps: 1,728,741,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1728741552...
Checkpoint 1728741552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.07263
Policy Entropy: 2.14607
Value Function Loss: 0.01769

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.64041

Collected Steps per Second: 22,416.49151
Overall Steps per Second: 10,516.59646

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.52389
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.75439

Cumulative Model Updates: 207,290
Cumulative Timesteps: 1,728,791,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.68169
Policy Entropy: 2.13976
Value Function Loss: 0.01888

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.67477

Collected Steps per Second: 22,638.93660
Overall Steps per Second: 10,550.27552

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.53296
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.74357

Cumulative Model Updates: 207,296
Cumulative Timesteps: 1,728,841,598

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1728841598...
Checkpoint 1728841598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.09080
Policy Entropy: 2.14209
Value Function Loss: 0.01839

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.59147
Value Function Update Magnitude: 0.66532

Collected Steps per Second: 21,945.53900
Overall Steps per Second: 10,343.93811

Timestep Collection Time: 2.28028
Timestep Consumption Time: 2.55753
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.83781

Cumulative Model Updates: 207,302
Cumulative Timesteps: 1,728,891,640

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.29979
Policy Entropy: 2.16631
Value Function Loss: 0.01838

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.62326

Collected Steps per Second: 22,131.56603
Overall Steps per Second: 10,510.82288

Timestep Collection Time: 2.26048
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.75967

Cumulative Model Updates: 207,308
Cumulative Timesteps: 1,728,941,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1728941668...
Checkpoint 1728941668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.33169
Policy Entropy: 2.17129
Value Function Loss: 0.01682

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.59124

Collected Steps per Second: 22,048.58846
Overall Steps per Second: 10,489.99640

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.76721

Cumulative Model Updates: 207,314
Cumulative Timesteps: 1,728,991,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.70519
Policy Entropy: 2.15476
Value Function Loss: 0.01561

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.56841

Collected Steps per Second: 22,114.68491
Overall Steps per Second: 10,448.20253

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.52538
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.78704

Cumulative Model Updates: 207,320
Cumulative Timesteps: 1,729,041,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1729041692...
Checkpoint 1729041692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.28815
Policy Entropy: 2.16107
Value Function Loss: 0.01613

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.56161

Collected Steps per Second: 22,011.22714
Overall Steps per Second: 10,301.38205

Timestep Collection Time: 2.27239
Timestep Consumption Time: 2.58308
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 4.85546

Cumulative Model Updates: 207,326
Cumulative Timesteps: 1,729,091,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.76244
Policy Entropy: 2.14942
Value Function Loss: 0.01622

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.55125
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 21,834.80825
Overall Steps per Second: 10,498.68083

Timestep Collection Time: 2.29120
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.76517

Cumulative Model Updates: 207,332
Cumulative Timesteps: 1,729,141,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1729141738...
Checkpoint 1729141738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.59209
Policy Entropy: 2.16638
Value Function Loss: 0.01707

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 22,813.96326
Overall Steps per Second: 10,609.62700

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.71459

Cumulative Model Updates: 207,338
Cumulative Timesteps: 1,729,191,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.14557
Policy Entropy: 2.14188
Value Function Loss: 0.01721

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 22,261.99316
Overall Steps per Second: 10,447.81339

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.54052
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.78722

Cumulative Model Updates: 207,344
Cumulative Timesteps: 1,729,241,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1729241774...
Checkpoint 1729241774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.10157
Policy Entropy: 2.15911
Value Function Loss: 0.01719

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.59959

Collected Steps per Second: 21,997.73083
Overall Steps per Second: 10,524.16972

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.47900
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.75287

Cumulative Model Updates: 207,350
Cumulative Timesteps: 1,729,291,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.52251
Policy Entropy: 2.14471
Value Function Loss: 0.01739

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.59485

Collected Steps per Second: 22,490.98495
Overall Steps per Second: 10,594.15503

Timestep Collection Time: 2.22400
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.30332
Total Iteration Time: 4.72147

Cumulative Model Updates: 207,356
Cumulative Timesteps: 1,729,341,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1729341814...
Checkpoint 1729341814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.46321
Policy Entropy: 2.15298
Value Function Loss: 0.01685

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.57120

Collected Steps per Second: 21,493.30798
Overall Steps per Second: 10,204.24128

Timestep Collection Time: 2.32742
Timestep Consumption Time: 2.57485
PPO Batch Consumption Time: 0.30412
Total Iteration Time: 4.90228

Cumulative Model Updates: 207,362
Cumulative Timesteps: 1,729,391,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.44665
Policy Entropy: 2.16149
Value Function Loss: 0.01786

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.56241

Collected Steps per Second: 22,213.28179
Overall Steps per Second: 10,456.79807

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.78273

Cumulative Model Updates: 207,368
Cumulative Timesteps: 1,729,441,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1729441850...
Checkpoint 1729441850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.20426
Policy Entropy: 2.17854
Value Function Loss: 0.01679

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.57321

Collected Steps per Second: 21,789.01450
Overall Steps per Second: 10,374.19515

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.52633
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.82235

Cumulative Model Updates: 207,374
Cumulative Timesteps: 1,729,491,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.54504
Policy Entropy: 2.18472
Value Function Loss: 0.01751

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.57988

Collected Steps per Second: 22,144.05781
Overall Steps per Second: 10,428.59194

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.53667
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.79470

Cumulative Model Updates: 207,380
Cumulative Timesteps: 1,729,541,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1729541880...
Checkpoint 1729541880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.93840
Policy Entropy: 2.17131
Value Function Loss: 0.01649

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.55893

Collected Steps per Second: 21,957.67153
Overall Steps per Second: 10,487.74582

Timestep Collection Time: 2.27756
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.76842

Cumulative Model Updates: 207,386
Cumulative Timesteps: 1,729,591,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.52466
Policy Entropy: 2.15448
Value Function Loss: 0.01721

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 22,195.04486
Overall Steps per Second: 10,464.52631

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.52650
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.78034

Cumulative Model Updates: 207,392
Cumulative Timesteps: 1,729,641,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1729641914...
Checkpoint 1729641914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.17510
Policy Entropy: 2.12636
Value Function Loss: 0.01812

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.53704

Collected Steps per Second: 21,654.91372
Overall Steps per Second: 10,234.56402

Timestep Collection Time: 2.30978
Timestep Consumption Time: 2.57739
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.88716

Cumulative Model Updates: 207,398
Cumulative Timesteps: 1,729,691,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.57326
Policy Entropy: 2.14834
Value Function Loss: 0.01887

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.54474
Value Function Update Magnitude: 0.55322

Collected Steps per Second: 22,082.76489
Overall Steps per Second: 10,426.50619

Timestep Collection Time: 2.26457
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.79624

Cumulative Model Updates: 207,404
Cumulative Timesteps: 1,729,741,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1729741940...
Checkpoint 1729741940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.73911
Policy Entropy: 2.13605
Value Function Loss: 0.01838

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.57522

Collected Steps per Second: 21,679.49165
Overall Steps per Second: 10,563.10567

Timestep Collection Time: 2.30660
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.73402

Cumulative Model Updates: 207,410
Cumulative Timesteps: 1,729,791,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.99145
Policy Entropy: 2.15931
Value Function Loss: 0.01716

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.58388

Collected Steps per Second: 22,356.75491
Overall Steps per Second: 10,524.49043

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.75234

Cumulative Model Updates: 207,416
Cumulative Timesteps: 1,729,841,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1729841962...
Checkpoint 1729841962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.73768
Policy Entropy: 2.16347
Value Function Loss: 0.01681

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.59286

Collected Steps per Second: 21,704.35851
Overall Steps per Second: 10,243.01780

Timestep Collection Time: 2.30415
Timestep Consumption Time: 2.57820
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 4.88235

Cumulative Model Updates: 207,422
Cumulative Timesteps: 1,729,891,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.87849
Policy Entropy: 2.15792
Value Function Loss: 0.01672

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,269.07731
Overall Steps per Second: 10,416.70420

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.55564
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.80171

Cumulative Model Updates: 207,428
Cumulative Timesteps: 1,729,941,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1729941990...
Checkpoint 1729941990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.89636
Policy Entropy: 2.17250
Value Function Loss: 0.01696

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 21,759.35461
Overall Steps per Second: 10,581.45099

Timestep Collection Time: 2.29805
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.72563

Cumulative Model Updates: 207,434
Cumulative Timesteps: 1,729,991,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.95977
Policy Entropy: 2.16648
Value Function Loss: 0.01738

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,343.89555
Overall Steps per Second: 10,508.93568

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.75862

Cumulative Model Updates: 207,440
Cumulative Timesteps: 1,730,042,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1730042002...
Checkpoint 1730042002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.34584
Policy Entropy: 2.16386
Value Function Loss: 0.01686

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.61758

Collected Steps per Second: 21,695.13320
Overall Steps per Second: 10,263.76640

Timestep Collection Time: 2.30568
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 4.87365

Cumulative Model Updates: 207,446
Cumulative Timesteps: 1,730,092,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.85948
Policy Entropy: 2.13989
Value Function Loss: 0.01739

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 21,605.66059
Overall Steps per Second: 10,419.17173

Timestep Collection Time: 2.31550
Timestep Consumption Time: 2.48603
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.80153

Cumulative Model Updates: 207,452
Cumulative Timesteps: 1,730,142,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1730142052...
Checkpoint 1730142052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.60401
Policy Entropy: 2.15224
Value Function Loss: 0.01683

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.60556

Collected Steps per Second: 21,692.14044
Overall Steps per Second: 10,563.48971

Timestep Collection Time: 2.30646
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.73631

Cumulative Model Updates: 207,458
Cumulative Timesteps: 1,730,192,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.21759
Policy Entropy: 2.13112
Value Function Loss: 0.01807

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.54988
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 22,285.63966
Overall Steps per Second: 10,540.93648

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.74360

Cumulative Model Updates: 207,464
Cumulative Timesteps: 1,730,242,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1730242086...
Checkpoint 1730242086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.26695
Policy Entropy: 2.12516
Value Function Loss: 0.01781

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.60711

Collected Steps per Second: 21,680.55888
Overall Steps per Second: 10,255.33437

Timestep Collection Time: 2.30695
Timestep Consumption Time: 2.57012
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 4.87707

Cumulative Model Updates: 207,470
Cumulative Timesteps: 1,730,292,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.84335
Policy Entropy: 2.10776
Value Function Loss: 0.01813

Mean KL Divergence: 0.03658
SB3 Clip Fraction: 0.20859
Policy Update Magnitude: 0.50989
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,245.82572
Overall Steps per Second: 10,437.31185

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.54330
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 4.79127

Cumulative Model Updates: 207,476
Cumulative Timesteps: 1,730,342,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1730342110...
Checkpoint 1730342110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.65058
Policy Entropy: 2.13529
Value Function Loss: 0.01697

Mean KL Divergence: 0.02960
SB3 Clip Fraction: 0.18620
Policy Update Magnitude: 0.50190
Value Function Update Magnitude: 0.63028

Collected Steps per Second: 21,896.89865
Overall Steps per Second: 10,168.84748

Timestep Collection Time: 2.28370
Timestep Consumption Time: 2.63387
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.91757

Cumulative Model Updates: 207,482
Cumulative Timesteps: 1,730,392,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.52305
Policy Entropy: 2.14244
Value Function Loss: 0.01693

Mean KL Divergence: 0.02464
SB3 Clip Fraction: 0.17393
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 20,981.54019
Overall Steps per Second: 10,290.33640

Timestep Collection Time: 2.38448
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.86184

Cumulative Model Updates: 207,488
Cumulative Timesteps: 1,730,442,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1730442146...
Checkpoint 1730442146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.34810
Policy Entropy: 2.14657
Value Function Loss: 0.01706

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 21,860.17880
Overall Steps per Second: 10,381.62199

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.52894
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.81620

Cumulative Model Updates: 207,494
Cumulative Timesteps: 1,730,492,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.60425
Policy Entropy: 2.12980
Value Function Loss: 0.01755

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.62912

Collected Steps per Second: 22,183.84146
Overall Steps per Second: 10,449.76978

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.78728

Cumulative Model Updates: 207,500
Cumulative Timesteps: 1,730,542,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1730542172...
Checkpoint 1730542172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.24601
Policy Entropy: 2.11583
Value Function Loss: 0.01721

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.63537

Collected Steps per Second: 21,749.91640
Overall Steps per Second: 10,377.91091

Timestep Collection Time: 2.29969
Timestep Consumption Time: 2.51997
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.81966

Cumulative Model Updates: 207,506
Cumulative Timesteps: 1,730,592,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.05901
Policy Entropy: 2.11570
Value Function Loss: 0.01678

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.64942

Collected Steps per Second: 22,474.32344
Overall Steps per Second: 10,716.39701

Timestep Collection Time: 2.22547
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.66724

Cumulative Model Updates: 207,512
Cumulative Timesteps: 1,730,642,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1730642206...
Checkpoint 1730642206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.31223
Policy Entropy: 2.14526
Value Function Loss: 0.01794

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 21,646.39528
Overall Steps per Second: 10,252.56590

Timestep Collection Time: 2.31004
Timestep Consumption Time: 2.56718
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.87722

Cumulative Model Updates: 207,518
Cumulative Timesteps: 1,730,692,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.60713
Policy Entropy: 2.13243
Value Function Loss: 0.01721

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.64344

Collected Steps per Second: 21,942.18046
Overall Steps per Second: 10,401.28152

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.52879
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.80787

Cumulative Model Updates: 207,524
Cumulative Timesteps: 1,730,742,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1730742218...
Checkpoint 1730742218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.04074
Policy Entropy: 2.13660
Value Function Loss: 0.01598

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 22,029.20030
Overall Steps per Second: 10,388.77673

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.54327
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.81308

Cumulative Model Updates: 207,530
Cumulative Timesteps: 1,730,792,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.71620
Policy Entropy: 2.13731
Value Function Loss: 0.01609

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.61263

Collected Steps per Second: 22,143.06523
Overall Steps per Second: 10,407.39648

Timestep Collection Time: 2.25931
Timestep Consumption Time: 2.54766
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.80697

Cumulative Model Updates: 207,536
Cumulative Timesteps: 1,730,842,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1730842248...
Checkpoint 1730842248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.44079
Policy Entropy: 2.17157
Value Function Loss: 0.01634

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 21,861.67172
Overall Steps per Second: 10,528.27525

Timestep Collection Time: 2.28830
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.75159

Cumulative Model Updates: 207,542
Cumulative Timesteps: 1,730,892,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.62491
Policy Entropy: 2.17159
Value Function Loss: 0.01674

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.60800

Collected Steps per Second: 22,185.47703
Overall Steps per Second: 10,472.25477

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.77719

Cumulative Model Updates: 207,548
Cumulative Timesteps: 1,730,942,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1730942302...
Checkpoint 1730942302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.77826
Policy Entropy: 2.18414
Value Function Loss: 0.01717

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.58562

Collected Steps per Second: 22,063.85848
Overall Steps per Second: 10,496.44525

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.76428

Cumulative Model Updates: 207,554
Cumulative Timesteps: 1,730,992,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.28924
Policy Entropy: 2.16456
Value Function Loss: 0.01718

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.56880

Collected Steps per Second: 22,065.79080
Overall Steps per Second: 10,499.32597

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.49766
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.76488

Cumulative Model Updates: 207,560
Cumulative Timesteps: 1,731,042,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1731042338...
Checkpoint 1731042338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.54136
Policy Entropy: 2.17345
Value Function Loss: 0.01759

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.56373

Collected Steps per Second: 21,970.69479
Overall Steps per Second: 10,622.45378

Timestep Collection Time: 2.27603
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70758

Cumulative Model Updates: 207,566
Cumulative Timesteps: 1,731,092,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.66354
Policy Entropy: 2.18271
Value Function Loss: 0.01684

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.57481

Collected Steps per Second: 22,475.37848
Overall Steps per Second: 10,552.75293

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.51375
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.73867

Cumulative Model Updates: 207,572
Cumulative Timesteps: 1,731,142,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1731142350...
Checkpoint 1731142350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.43004
Policy Entropy: 2.17152
Value Function Loss: 0.01689

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.55011
Value Function Update Magnitude: 0.60250

Collected Steps per Second: 21,893.64152
Overall Steps per Second: 10,311.66179

Timestep Collection Time: 2.28432
Timestep Consumption Time: 2.56573
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.85004

Cumulative Model Updates: 207,578
Cumulative Timesteps: 1,731,192,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.25883
Policy Entropy: 2.15134
Value Function Loss: 0.01693

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.60702

Collected Steps per Second: 22,001.61854
Overall Steps per Second: 10,354.40677

Timestep Collection Time: 2.27329
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.30174
Total Iteration Time: 4.83041

Cumulative Model Updates: 207,584
Cumulative Timesteps: 1,731,242,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1731242378...
Checkpoint 1731242378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.21231
Policy Entropy: 2.13418
Value Function Loss: 0.01688

Mean KL Divergence: 0.03295
SB3 Clip Fraction: 0.18475
Policy Update Magnitude: 0.59236
Value Function Update Magnitude: 0.62732

Collected Steps per Second: 21,908.58561
Overall Steps per Second: 10,412.75163

Timestep Collection Time: 2.28230
Timestep Consumption Time: 2.51970
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.80200

Cumulative Model Updates: 207,590
Cumulative Timesteps: 1,731,292,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.29824
Policy Entropy: 2.13842
Value Function Loss: 0.01679

Mean KL Divergence: 0.03815
SB3 Clip Fraction: 0.22031
Policy Update Magnitude: 0.59794
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 22,118.08568
Overall Steps per Second: 10,624.86156

Timestep Collection Time: 2.26186
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70858

Cumulative Model Updates: 207,596
Cumulative Timesteps: 1,731,342,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1731342408...
Checkpoint 1731342408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.93812
Policy Entropy: 2.14209
Value Function Loss: 0.01714

Mean KL Divergence: 0.02997
SB3 Clip Fraction: 0.18987
Policy Update Magnitude: 0.58876
Value Function Update Magnitude: 0.63921

Collected Steps per Second: 21,901.58897
Overall Steps per Second: 10,313.28272

Timestep Collection Time: 2.28303
Timestep Consumption Time: 2.56528
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.84831

Cumulative Model Updates: 207,602
Cumulative Timesteps: 1,731,392,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.23151
Policy Entropy: 2.13503
Value Function Loss: 0.01814

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.16454
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.64780

Collected Steps per Second: 21,847.55829
Overall Steps per Second: 10,413.30300

Timestep Collection Time: 2.28950
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.80347

Cumulative Model Updates: 207,608
Cumulative Timesteps: 1,731,442,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1731442430...
Checkpoint 1731442430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.66562
Policy Entropy: 2.13396
Value Function Loss: 0.01829

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.58343
Value Function Update Magnitude: 0.64368

Collected Steps per Second: 21,906.12649
Overall Steps per Second: 10,371.56349

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.53892
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.82184

Cumulative Model Updates: 207,614
Cumulative Timesteps: 1,731,492,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.00663
Policy Entropy: 2.12867
Value Function Loss: 0.01873

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 21,083.09412
Overall Steps per Second: 10,269.09559

Timestep Collection Time: 2.37261
Timestep Consumption Time: 2.49851
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.87112

Cumulative Model Updates: 207,620
Cumulative Timesteps: 1,731,542,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1731542462...
Checkpoint 1731542462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.01089
Policy Entropy: 2.16209
Value Function Loss: 0.01803

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.61792

Collected Steps per Second: 22,033.00872
Overall Steps per Second: 10,366.56720

Timestep Collection Time: 2.26996
Timestep Consumption Time: 2.55459
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.82455

Cumulative Model Updates: 207,626
Cumulative Timesteps: 1,731,592,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.78775
Policy Entropy: 2.18461
Value Function Loss: 0.01727

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.60162

Collected Steps per Second: 22,004.70372
Overall Steps per Second: 10,282.88752

Timestep Collection Time: 2.27360
Timestep Consumption Time: 2.59176
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.86536

Cumulative Model Updates: 207,632
Cumulative Timesteps: 1,731,642,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1731642506...
Checkpoint 1731642506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.08949
Policy Entropy: 2.17742
Value Function Loss: 0.01729

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.60007

Collected Steps per Second: 21,547.01260
Overall Steps per Second: 10,217.12546

Timestep Collection Time: 2.32097
Timestep Consumption Time: 2.57375
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.89472

Cumulative Model Updates: 207,638
Cumulative Timesteps: 1,731,692,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.27087
Policy Entropy: 2.12214
Value Function Loss: 0.01709

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 22,028.98346
Overall Steps per Second: 10,465.76001

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 4.77844

Cumulative Model Updates: 207,644
Cumulative Timesteps: 1,731,742,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1731742526...
Checkpoint 1731742526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.97723
Policy Entropy: 2.09387
Value Function Loss: 0.01773

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.62058

Collected Steps per Second: 22,007.32876
Overall Steps per Second: 10,349.77594

Timestep Collection Time: 2.27206
Timestep Consumption Time: 2.55915
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.83122

Cumulative Model Updates: 207,650
Cumulative Timesteps: 1,731,792,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.20421
Policy Entropy: 2.10350
Value Function Loss: 0.01828

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.57651
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 21,773.31549
Overall Steps per Second: 10,292.03717

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.56174
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.85812

Cumulative Model Updates: 207,656
Cumulative Timesteps: 1,731,842,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1731842528...
Checkpoint 1731842528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.28009
Policy Entropy: 2.10415
Value Function Loss: 0.01804

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.57225
Value Function Update Magnitude: 0.62497

Collected Steps per Second: 21,557.17908
Overall Steps per Second: 10,263.16545

Timestep Collection Time: 2.32034
Timestep Consumption Time: 2.55340
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.87374

Cumulative Model Updates: 207,662
Cumulative Timesteps: 1,731,892,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.60219
Policy Entropy: 2.12223
Value Function Loss: 0.01743

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.59075

Collected Steps per Second: 21,520.07016
Overall Steps per Second: 10,421.51419

Timestep Collection Time: 2.32341
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.79777

Cumulative Model Updates: 207,668
Cumulative Timesteps: 1,731,942,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1731942548...
Checkpoint 1731942548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.06871
Policy Entropy: 2.12875
Value Function Loss: 0.01666

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 21,762.67861
Overall Steps per Second: 10,244.56261

Timestep Collection Time: 2.29770
Timestep Consumption Time: 2.58333
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 4.88103

Cumulative Model Updates: 207,674
Cumulative Timesteps: 1,731,992,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.68422
Policy Entropy: 2.13882
Value Function Loss: 0.01684

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.55386

Collected Steps per Second: 21,752.32211
Overall Steps per Second: 10,351.01504

Timestep Collection Time: 2.29888
Timestep Consumption Time: 2.53214
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.83102

Cumulative Model Updates: 207,680
Cumulative Timesteps: 1,732,042,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1732042558...
Checkpoint 1732042558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.98182
Policy Entropy: 2.13033
Value Function Loss: 0.01629

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.55435

Collected Steps per Second: 21,670.45651
Overall Steps per Second: 10,259.23211

Timestep Collection Time: 2.30867
Timestep Consumption Time: 2.56791
PPO Batch Consumption Time: 0.30396
Total Iteration Time: 4.87658

Cumulative Model Updates: 207,686
Cumulative Timesteps: 1,732,092,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.48207
Policy Entropy: 2.12407
Value Function Loss: 0.01710

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.56599

Collected Steps per Second: 21,876.82552
Overall Steps per Second: 10,470.24646

Timestep Collection Time: 2.28616
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.77677

Cumulative Model Updates: 207,692
Cumulative Timesteps: 1,732,142,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1732142602...
Checkpoint 1732142602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.28145
Policy Entropy: 2.12645
Value Function Loss: 0.01642

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.54606
Value Function Update Magnitude: 0.57525

Collected Steps per Second: 21,815.03118
Overall Steps per Second: 10,476.90242

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.48160
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.77469

Cumulative Model Updates: 207,698
Cumulative Timesteps: 1,732,192,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.03648
Policy Entropy: 2.13834
Value Function Loss: 0.01707

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.57264

Collected Steps per Second: 21,937.33510
Overall Steps per Second: 10,328.25707

Timestep Collection Time: 2.28159
Timestep Consumption Time: 2.56453
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.84612

Cumulative Model Updates: 207,704
Cumulative Timesteps: 1,732,242,678

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1732242678...
Checkpoint 1732242678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.86946
Policy Entropy: 2.15339
Value Function Loss: 0.01605

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.53328
Value Function Update Magnitude: 0.56810

Collected Steps per Second: 21,615.29358
Overall Steps per Second: 10,244.27440

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.56873
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.88292

Cumulative Model Updates: 207,710
Cumulative Timesteps: 1,732,292,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.58612
Policy Entropy: 2.15110
Value Function Loss: 0.01636

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.56644

Collected Steps per Second: 21,904.70943
Overall Steps per Second: 10,306.28475

Timestep Collection Time: 2.28334
Timestep Consumption Time: 2.56962
PPO Batch Consumption Time: 0.30367
Total Iteration Time: 4.85296

Cumulative Model Updates: 207,716
Cumulative Timesteps: 1,732,342,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1732342716...
Checkpoint 1732342716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.54914
Policy Entropy: 2.16624
Value Function Loss: 0.01696

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54680
Value Function Update Magnitude: 0.58614

Collected Steps per Second: 21,720.34738
Overall Steps per Second: 10,567.77575

Timestep Collection Time: 2.30319
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.73382

Cumulative Model Updates: 207,722
Cumulative Timesteps: 1,732,392,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.61523
Policy Entropy: 2.14893
Value Function Loss: 0.01817

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.55740
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 22,001.90898
Overall Steps per Second: 10,435.36335

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.52048
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.79447

Cumulative Model Updates: 207,728
Cumulative Timesteps: 1,732,442,774

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1732442774...
Checkpoint 1732442774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.43454
Policy Entropy: 2.15364
Value Function Loss: 0.01812

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.62636

Collected Steps per Second: 21,872.20378
Overall Steps per Second: 10,279.83690

Timestep Collection Time: 2.28601
Timestep Consumption Time: 2.57788
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.86389

Cumulative Model Updates: 207,734
Cumulative Timesteps: 1,732,492,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.79306
Policy Entropy: 2.13556
Value Function Loss: 0.01701

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.61272

Collected Steps per Second: 21,929.66305
Overall Steps per Second: 10,416.05393

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.80259

Cumulative Model Updates: 207,740
Cumulative Timesteps: 1,732,542,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1732542798...
Checkpoint 1732542798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.76582
Policy Entropy: 2.14884
Value Function Loss: 0.01585

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.54700
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 21,746.64958
Overall Steps per Second: 10,263.41430

Timestep Collection Time: 2.30022
Timestep Consumption Time: 2.57360
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 4.87382

Cumulative Model Updates: 207,746
Cumulative Timesteps: 1,732,592,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.79738
Policy Entropy: 2.14586
Value Function Loss: 0.01510

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.56981

Collected Steps per Second: 23,019.97046
Overall Steps per Second: 10,511.32493

Timestep Collection Time: 2.17255
Timestep Consumption Time: 2.58537
PPO Batch Consumption Time: 0.30410
Total Iteration Time: 4.75792

Cumulative Model Updates: 207,752
Cumulative Timesteps: 1,732,642,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1732642832...
Checkpoint 1732642832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.13343
Policy Entropy: 2.13991
Value Function Loss: 0.01554

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.55581

Collected Steps per Second: 21,904.30539
Overall Steps per Second: 10,313.30824

Timestep Collection Time: 2.28311
Timestep Consumption Time: 2.56596
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.84907

Cumulative Model Updates: 207,758
Cumulative Timesteps: 1,732,692,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.60008
Policy Entropy: 2.09684
Value Function Loss: 0.01541

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.56174

Collected Steps per Second: 22,219.27383
Overall Steps per Second: 10,292.50951

Timestep Collection Time: 2.25057
Timestep Consumption Time: 2.60792
PPO Batch Consumption Time: 0.30611
Total Iteration Time: 4.85848

Cumulative Model Updates: 207,764
Cumulative Timesteps: 1,732,742,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1732742848...
Checkpoint 1732742848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.70027
Policy Entropy: 2.08414
Value Function Loss: 0.01600

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.57771

Collected Steps per Second: 21,600.57254
Overall Steps per Second: 10,284.19940

Timestep Collection Time: 2.31531
Timestep Consumption Time: 2.54768
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 4.86299

Cumulative Model Updates: 207,770
Cumulative Timesteps: 1,732,792,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.28058
Policy Entropy: 2.09740
Value Function Loss: 0.01643

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 21,965.11738
Overall Steps per Second: 10,366.82209

Timestep Collection Time: 2.27706
Timestep Consumption Time: 2.54756
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.82462

Cumulative Model Updates: 207,776
Cumulative Timesteps: 1,732,842,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1732842876...
Checkpoint 1732842876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.97841
Policy Entropy: 2.14609
Value Function Loss: 0.01712

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.53372
Value Function Update Magnitude: 0.61816

Collected Steps per Second: 22,720.42492
Overall Steps per Second: 10,588.72260

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.72295

Cumulative Model Updates: 207,782
Cumulative Timesteps: 1,732,892,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.49126
Policy Entropy: 2.14645
Value Function Loss: 0.01661

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.62320

Collected Steps per Second: 22,435.82974
Overall Steps per Second: 10,543.14054

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.74527

Cumulative Model Updates: 207,788
Cumulative Timesteps: 1,732,942,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1732942916...
Checkpoint 1732942916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.85564
Policy Entropy: 2.13470
Value Function Loss: 0.01544

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.52913
Value Function Update Magnitude: 0.60301

Collected Steps per Second: 21,644.41215
Overall Steps per Second: 10,205.00018

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.59157
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 4.90348

Cumulative Model Updates: 207,794
Cumulative Timesteps: 1,732,992,956

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.08140
Policy Entropy: 2.12757
Value Function Loss: 0.01502

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.57096

Collected Steps per Second: 21,949.76760
Overall Steps per Second: 10,417.91289

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.52241
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.80115

Cumulative Model Updates: 207,800
Cumulative Timesteps: 1,733,042,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1733042974...
Checkpoint 1733042974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.40158
Policy Entropy: 2.14187
Value Function Loss: 0.01597

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.58657

Collected Steps per Second: 21,695.22123
Overall Steps per Second: 10,541.09493

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.74467

Cumulative Model Updates: 207,806
Cumulative Timesteps: 1,733,092,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.35406
Policy Entropy: 2.14897
Value Function Loss: 0.01718

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.63324

Collected Steps per Second: 22,313.81498
Overall Steps per Second: 10,505.55747

Timestep Collection Time: 2.24076
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.75939

Cumulative Model Updates: 207,812
Cumulative Timesteps: 1,733,142,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1733142988...
Checkpoint 1733142988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.75861
Policy Entropy: 2.15329
Value Function Loss: 0.01743

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.65223

Collected Steps per Second: 21,664.39087
Overall Steps per Second: 10,291.54050

Timestep Collection Time: 2.30886
Timestep Consumption Time: 2.55144
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.86030

Cumulative Model Updates: 207,818
Cumulative Timesteps: 1,733,193,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.11339
Policy Entropy: 2.14052
Value Function Loss: 0.01779

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.65438

Collected Steps per Second: 21,757.00020
Overall Steps per Second: 10,412.42157

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.80407

Cumulative Model Updates: 207,824
Cumulative Timesteps: 1,733,243,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1733243030...
Checkpoint 1733243030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.03653
Policy Entropy: 2.12915
Value Function Loss: 0.01700

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.63573

Collected Steps per Second: 21,853.20488
Overall Steps per Second: 10,595.95862

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.72237

Cumulative Model Updates: 207,830
Cumulative Timesteps: 1,733,293,068

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.16996
Policy Entropy: 2.09766
Value Function Loss: 0.01709

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.63859

Collected Steps per Second: 22,162.17689
Overall Steps per Second: 10,459.12550

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.52543
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.78243

Cumulative Model Updates: 207,836
Cumulative Timesteps: 1,733,343,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1733343088...
Checkpoint 1733343088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.60847
Policy Entropy: 2.10138
Value Function Loss: 0.01643

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.63039

Collected Steps per Second: 21,876.16582
Overall Steps per Second: 10,294.03848

Timestep Collection Time: 2.28568
Timestep Consumption Time: 2.57169
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 4.85737

Cumulative Model Updates: 207,842
Cumulative Timesteps: 1,733,393,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.04992
Policy Entropy: 2.09060
Value Function Loss: 0.01663

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.61514

Collected Steps per Second: 22,031.86384
Overall Steps per Second: 10,461.02353

Timestep Collection Time: 2.27153
Timestep Consumption Time: 2.51252
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.78404

Cumulative Model Updates: 207,848
Cumulative Timesteps: 1,733,443,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1733443136...
Checkpoint 1733443136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.55690
Policy Entropy: 2.10718
Value Function Loss: 0.01540

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.59390

Collected Steps per Second: 21,647.49747
Overall Steps per Second: 10,273.60698

Timestep Collection Time: 2.31066
Timestep Consumption Time: 2.55813
PPO Batch Consumption Time: 0.30347
Total Iteration Time: 4.86879

Cumulative Model Updates: 207,854
Cumulative Timesteps: 1,733,493,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.85680
Policy Entropy: 2.10887
Value Function Loss: 0.01545

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.55531

Collected Steps per Second: 22,753.91195
Overall Steps per Second: 10,441.81148

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.59247
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 4.79112

Cumulative Model Updates: 207,860
Cumulative Timesteps: 1,733,543,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1733543184...
Checkpoint 1733543184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.35829
Policy Entropy: 2.10072
Value Function Loss: 0.01556

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.54861

Collected Steps per Second: 21,514.97429
Overall Steps per Second: 10,169.61906

Timestep Collection Time: 2.32554
Timestep Consumption Time: 2.59441
PPO Batch Consumption Time: 0.30578
Total Iteration Time: 4.91995

Cumulative Model Updates: 207,866
Cumulative Timesteps: 1,733,593,218

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.35593
Policy Entropy: 2.12605
Value Function Loss: 0.01661

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.57578

Collected Steps per Second: 21,862.38546
Overall Steps per Second: 10,371.23930

Timestep Collection Time: 2.28722
Timestep Consumption Time: 2.53419
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.82141

Cumulative Model Updates: 207,872
Cumulative Timesteps: 1,733,643,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1733643222...
Checkpoint 1733643222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.98348
Policy Entropy: 2.13705
Value Function Loss: 0.01725

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.61694

Collected Steps per Second: 21,714.46010
Overall Steps per Second: 10,262.21534

Timestep Collection Time: 2.30289
Timestep Consumption Time: 2.56994
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 4.87283

Cumulative Model Updates: 207,878
Cumulative Timesteps: 1,733,693,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.50761
Policy Entropy: 2.16436
Value Function Loss: 0.01734

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.63375

Collected Steps per Second: 22,740.09349
Overall Steps per Second: 10,484.27772

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.57039
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.76924

Cumulative Model Updates: 207,884
Cumulative Timesteps: 1,733,743,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1733743230...
Checkpoint 1733743230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.44313
Policy Entropy: 2.10345
Value Function Loss: 0.01680

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.62771

Collected Steps per Second: 21,695.21396
Overall Steps per Second: 10,205.05321

Timestep Collection Time: 2.30512
Timestep Consumption Time: 2.59540
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 4.90051

Cumulative Model Updates: 207,890
Cumulative Timesteps: 1,733,793,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.69577
Policy Entropy: 2.10704
Value Function Loss: 0.01571

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.54748
Value Function Update Magnitude: 0.60663

Collected Steps per Second: 22,139.74083
Overall Steps per Second: 10,458.52981

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.78213

Cumulative Model Updates: 207,896
Cumulative Timesteps: 1,733,843,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1733843254...
Checkpoint 1733843254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.33838
Policy Entropy: 2.12165
Value Function Loss: 0.01584

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.58872

Collected Steps per Second: 21,890.39894
Overall Steps per Second: 10,376.01822

Timestep Collection Time: 2.28484
Timestep Consumption Time: 2.53551
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.82035

Cumulative Model Updates: 207,902
Cumulative Timesteps: 1,733,893,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.05596
Policy Entropy: 2.15006
Value Function Loss: 0.01643

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.57065

Collected Steps per Second: 21,961.55454
Overall Steps per Second: 10,312.28185

Timestep Collection Time: 2.27689
Timestep Consumption Time: 2.57209
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 4.84898

Cumulative Model Updates: 207,908
Cumulative Timesteps: 1,733,943,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1733943274...
Checkpoint 1733943274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.78956
Policy Entropy: 2.14578
Value Function Loss: 0.01689

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.54948
Value Function Update Magnitude: 0.57488

Collected Steps per Second: 21,584.48655
Overall Steps per Second: 10,498.41835

Timestep Collection Time: 2.31703
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.76377

Cumulative Model Updates: 207,914
Cumulative Timesteps: 1,733,993,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.70652
Policy Entropy: 2.10753
Value Function Loss: 0.01753

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 22,200.00003
Overall Steps per Second: 10,477.42423

Timestep Collection Time: 2.25270
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.77312

Cumulative Model Updates: 207,920
Cumulative Timesteps: 1,734,043,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1734043296...
Checkpoint 1734043296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.63641
Policy Entropy: 2.11843
Value Function Loss: 0.01594

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.60452

Collected Steps per Second: 22,069.89987
Overall Steps per Second: 10,324.04735

Timestep Collection Time: 2.26689
Timestep Consumption Time: 2.57908
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 4.84597

Cumulative Model Updates: 207,926
Cumulative Timesteps: 1,734,093,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.32919
Policy Entropy: 2.11024
Value Function Loss: 0.01531

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.57754

Collected Steps per Second: 21,660.92679
Overall Steps per Second: 10,391.45006

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.50485
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.81454

Cumulative Model Updates: 207,932
Cumulative Timesteps: 1,734,143,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1734143356...
Checkpoint 1734143356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.21739
Policy Entropy: 2.12415
Value Function Loss: 0.01506

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.55876

Collected Steps per Second: 22,269.03899
Overall Steps per Second: 10,644.32297

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.45236
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.69790

Cumulative Model Updates: 207,938
Cumulative Timesteps: 1,734,193,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.75860
Policy Entropy: 2.12433
Value Function Loss: 0.01586

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.56530

Collected Steps per Second: 22,036.02799
Overall Steps per Second: 10,401.51906

Timestep Collection Time: 2.26937
Timestep Consumption Time: 2.53838
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.80776

Cumulative Model Updates: 207,944
Cumulative Timesteps: 1,734,243,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1734243370...
Checkpoint 1734243370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.06870
Policy Entropy: 2.13594
Value Function Loss: 0.01656

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.57238

Collected Steps per Second: 22,145.57080
Overall Steps per Second: 10,332.86178

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.58187
PPO Batch Consumption Time: 0.30238
Total Iteration Time: 4.84029

Cumulative Model Updates: 207,950
Cumulative Timesteps: 1,734,293,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.69843
Policy Entropy: 2.12057
Value Function Loss: 0.01741

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.57047

Collected Steps per Second: 21,882.21145
Overall Steps per Second: 10,475.54961

Timestep Collection Time: 2.28560
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.77436

Cumulative Model Updates: 207,956
Cumulative Timesteps: 1,734,343,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1734343398...
Checkpoint 1734343398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.72559
Policy Entropy: 2.11697
Value Function Loss: 0.01797

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.14946
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.56410

Collected Steps per Second: 21,711.57389
Overall Steps per Second: 10,536.81062

Timestep Collection Time: 2.30356
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.74660

Cumulative Model Updates: 207,962
Cumulative Timesteps: 1,734,393,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.90335
Policy Entropy: 2.11222
Value Function Loss: 0.01714

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.54726

Collected Steps per Second: 22,158.31841
Overall Steps per Second: 10,453.19074

Timestep Collection Time: 2.25676
Timestep Consumption Time: 2.52704
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78380

Cumulative Model Updates: 207,968
Cumulative Timesteps: 1,734,443,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1734443418...
Checkpoint 1734443418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.64821
Policy Entropy: 2.13974
Value Function Loss: 0.01647

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.54327
Value Function Update Magnitude: 0.53733

Collected Steps per Second: 21,918.85354
Overall Steps per Second: 10,290.35457

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.57912
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.86145

Cumulative Model Updates: 207,974
Cumulative Timesteps: 1,734,493,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.14319
Policy Entropy: 2.13787
Value Function Loss: 0.01646

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.55106

Collected Steps per Second: 21,593.71997
Overall Steps per Second: 10,363.80610

Timestep Collection Time: 2.31632
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.82622

Cumulative Model Updates: 207,980
Cumulative Timesteps: 1,734,543,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1734543462...
Checkpoint 1734543462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.39641
Policy Entropy: 2.11091
Value Function Loss: 0.01684

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 21,805.35430
Overall Steps per Second: 10,486.25467

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.77005

Cumulative Model Updates: 207,986
Cumulative Timesteps: 1,734,593,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.76437
Policy Entropy: 2.11768
Value Function Loss: 0.01668

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.57269

Collected Steps per Second: 21,620.10229
Overall Steps per Second: 10,285.83574

Timestep Collection Time: 2.31396
Timestep Consumption Time: 2.54982
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.86378

Cumulative Model Updates: 207,992
Cumulative Timesteps: 1,734,643,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1734643510...
Checkpoint 1734643510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.71906
Policy Entropy: 2.11575
Value Function Loss: 0.01732

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.57728

Collected Steps per Second: 21,744.25267
Overall Steps per Second: 10,236.41141

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.58600
PPO Batch Consumption Time: 0.30419
Total Iteration Time: 4.88628

Cumulative Model Updates: 207,998
Cumulative Timesteps: 1,734,693,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.87959
Policy Entropy: 2.13798
Value Function Loss: 0.01556

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.15711
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 21,758.65667
Overall Steps per Second: 10,416.94850

Timestep Collection Time: 2.29858
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.80121

Cumulative Model Updates: 208,004
Cumulative Timesteps: 1,734,743,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1734743542...
Checkpoint 1734743542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.32298
Policy Entropy: 2.14847
Value Function Loss: 0.01565

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.51808
Value Function Update Magnitude: 0.54288

Collected Steps per Second: 21,719.73721
Overall Steps per Second: 10,533.68479

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.44482
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.74706

Cumulative Model Updates: 208,010
Cumulative Timesteps: 1,734,793,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.63497
Policy Entropy: 2.12380
Value Function Loss: 0.01631

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.18662
Policy Update Magnitude: 0.51311
Value Function Update Magnitude: 0.52167

Collected Steps per Second: 22,374.43151
Overall Steps per Second: 10,522.66933

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.75241

Cumulative Model Updates: 208,016
Cumulative Timesteps: 1,734,843,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1734843554...
Checkpoint 1734843554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.29427
Policy Entropy: 2.11843
Value Function Loss: 0.01695

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.52084
Value Function Update Magnitude: 0.56384

Collected Steps per Second: 21,829.36769
Overall Steps per Second: 10,252.65843

Timestep Collection Time: 2.29159
Timestep Consumption Time: 2.58753
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.87912

Cumulative Model Updates: 208,022
Cumulative Timesteps: 1,734,893,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.07712
Policy Entropy: 2.11135
Value Function Loss: 0.01709

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 21,804.54395
Overall Steps per Second: 10,383.00662

Timestep Collection Time: 2.29420
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.81787

Cumulative Model Updates: 208,028
Cumulative Timesteps: 1,734,943,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1734943602...
Checkpoint 1734943602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.97317
Policy Entropy: 2.11723
Value Function Loss: 0.01673

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 21,875.99037
Overall Steps per Second: 10,298.68746

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.57061
PPO Batch Consumption Time: 0.30485
Total Iteration Time: 4.85732

Cumulative Model Updates: 208,034
Cumulative Timesteps: 1,734,993,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.02238
Policy Entropy: 2.10038
Value Function Loss: 0.01691

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.59801

Collected Steps per Second: 22,809.19530
Overall Steps per Second: 10,439.89413

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.59836
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.79143

Cumulative Model Updates: 208,040
Cumulative Timesteps: 1,735,043,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1735043648...
Checkpoint 1735043648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.44114
Policy Entropy: 2.12338
Value Function Loss: 0.01632

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.57820

Collected Steps per Second: 21,944.26369
Overall Steps per Second: 10,270.76488

Timestep Collection Time: 2.28014
Timestep Consumption Time: 2.59155
PPO Batch Consumption Time: 0.30451
Total Iteration Time: 4.87169

Cumulative Model Updates: 208,046
Cumulative Timesteps: 1,735,093,684

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.33424
Policy Entropy: 2.14816
Value Function Loss: 0.01622

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.56751

Collected Steps per Second: 21,892.74333
Overall Steps per Second: 10,363.63243

Timestep Collection Time: 2.28404
Timestep Consumption Time: 2.54090
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.82495

Cumulative Model Updates: 208,052
Cumulative Timesteps: 1,735,143,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1735143688...
Checkpoint 1735143688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.42667
Policy Entropy: 2.16788
Value Function Loss: 0.01637

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.56526

Collected Steps per Second: 21,830.56934
Overall Steps per Second: 10,278.46052

Timestep Collection Time: 2.29046
Timestep Consumption Time: 2.57428
PPO Batch Consumption Time: 0.30466
Total Iteration Time: 4.86474

Cumulative Model Updates: 208,058
Cumulative Timesteps: 1,735,193,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.24610
Policy Entropy: 2.16427
Value Function Loss: 0.01664

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 22,794.82159
Overall Steps per Second: 10,429.80675

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.60141
PPO Batch Consumption Time: 0.30306
Total Iteration Time: 4.79568

Cumulative Model Updates: 208,064
Cumulative Timesteps: 1,735,243,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1735243708...
Checkpoint 1735243708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.40993
Policy Entropy: 2.16063
Value Function Loss: 0.01674

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.57306

Collected Steps per Second: 21,804.71326
Overall Steps per Second: 10,249.71212

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.58552
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.87897

Cumulative Model Updates: 208,070
Cumulative Timesteps: 1,735,293,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.91001
Policy Entropy: 2.14369
Value Function Loss: 0.01618

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.56494

Collected Steps per Second: 22,032.34118
Overall Steps per Second: 10,416.00476

Timestep Collection Time: 2.26994
Timestep Consumption Time: 2.53152
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.80146

Cumulative Model Updates: 208,076
Cumulative Timesteps: 1,735,343,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1735343728...
Checkpoint 1735343728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.76420
Policy Entropy: 2.10822
Value Function Loss: 0.01642

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.56025

Collected Steps per Second: 21,508.22145
Overall Steps per Second: 10,237.66625

Timestep Collection Time: 2.32506
Timestep Consumption Time: 2.55964
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 4.88471

Cumulative Model Updates: 208,082
Cumulative Timesteps: 1,735,393,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.24467
Policy Entropy: 2.11627
Value Function Loss: 0.01674

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 22,038.79521
Overall Steps per Second: 10,472.80644

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 4.77599

Cumulative Model Updates: 208,088
Cumulative Timesteps: 1,735,443,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1735443754...
Checkpoint 1735443754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.23247
Policy Entropy: 2.13767
Value Function Loss: 0.01701

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.58183

Collected Steps per Second: 20,764.68034
Overall Steps per Second: 10,127.52839

Timestep Collection Time: 2.40919
Timestep Consumption Time: 2.53042
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.93961

Cumulative Model Updates: 208,094
Cumulative Timesteps: 1,735,493,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.29244
Policy Entropy: 2.16959
Value Function Loss: 0.01732

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.58741

Collected Steps per Second: 21,402.40117
Overall Steps per Second: 10,097.68023

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.61618
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.95302

Cumulative Model Updates: 208,100
Cumulative Timesteps: 1,735,543,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1735543794...
Checkpoint 1735543794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.23141
Policy Entropy: 2.16107
Value Function Loss: 0.01761

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.59267

Collected Steps per Second: 21,596.63709
Overall Steps per Second: 10,192.47410

Timestep Collection Time: 2.31564
Timestep Consumption Time: 2.59092
PPO Batch Consumption Time: 0.30354
Total Iteration Time: 4.90656

Cumulative Model Updates: 208,106
Cumulative Timesteps: 1,735,593,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.76940
Policy Entropy: 2.15244
Value Function Loss: 0.01749

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.56341
Value Function Update Magnitude: 0.58730

Collected Steps per Second: 22,022.26966
Overall Steps per Second: 10,448.03781

Timestep Collection Time: 2.27088
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.78654

Cumulative Model Updates: 208,112
Cumulative Timesteps: 1,735,643,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1735643814...
Checkpoint 1735643814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.97734
Policy Entropy: 2.15852
Value Function Loss: 0.01685

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 21,732.38381
Overall Steps per Second: 10,229.25160

Timestep Collection Time: 2.30163
Timestep Consumption Time: 2.58826
PPO Batch Consumption Time: 0.30266
Total Iteration Time: 4.88990

Cumulative Model Updates: 208,118
Cumulative Timesteps: 1,735,693,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.28065
Policy Entropy: 2.18225
Value Function Loss: 0.01613

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.58020

Collected Steps per Second: 21,926.35084
Overall Steps per Second: 10,386.52765

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.53418
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.81508

Cumulative Model Updates: 208,124
Cumulative Timesteps: 1,735,743,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1735743846...
Checkpoint 1735743846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.61035
Policy Entropy: 2.16224
Value Function Loss: 0.01624

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.57246

Collected Steps per Second: 21,422.46743
Overall Steps per Second: 10,276.84510

Timestep Collection Time: 2.33418
Timestep Consumption Time: 2.53151
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.86570

Cumulative Model Updates: 208,130
Cumulative Timesteps: 1,735,793,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.02857
Policy Entropy: 2.17238
Value Function Loss: 0.01635

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.57241

Collected Steps per Second: 22,058.12681
Overall Steps per Second: 10,430.16374

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.52725
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.79417

Cumulative Model Updates: 208,136
Cumulative Timesteps: 1,735,843,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1735843854...
Checkpoint 1735843854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.60247
Policy Entropy: 2.14524
Value Function Loss: 0.01718

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.56761

Collected Steps per Second: 21,424.05282
Overall Steps per Second: 10,361.09549

Timestep Collection Time: 2.33495
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 4.82806

Cumulative Model Updates: 208,142
Cumulative Timesteps: 1,735,893,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.09548
Policy Entropy: 2.15021
Value Function Loss: 0.01668

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.55805

Collected Steps per Second: 22,158.41753
Overall Steps per Second: 10,324.31937

Timestep Collection Time: 2.25720
Timestep Consumption Time: 2.58728
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 4.84448

Cumulative Model Updates: 208,148
Cumulative Timesteps: 1,735,943,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1735943894...
Checkpoint 1735943894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.02082
Policy Entropy: 2.12173
Value Function Loss: 0.01731

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.56248

Collected Steps per Second: 21,665.91847
Overall Steps per Second: 10,206.78081

Timestep Collection Time: 2.30777
Timestep Consumption Time: 2.59093
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 4.89870

Cumulative Model Updates: 208,154
Cumulative Timesteps: 1,735,993,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.16590
Policy Entropy: 2.13953
Value Function Loss: 0.01714

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.59303

Collected Steps per Second: 21,417.31717
Overall Steps per Second: 10,320.92024

Timestep Collection Time: 2.33531
Timestep Consumption Time: 2.51077
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.84608

Cumulative Model Updates: 208,160
Cumulative Timesteps: 1,736,043,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1736043910...
Checkpoint 1736043910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.15161
Policy Entropy: 2.15567
Value Function Loss: 0.01644

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.59048

Collected Steps per Second: 21,849.62253
Overall Steps per Second: 10,341.38735

Timestep Collection Time: 2.28928
Timestep Consumption Time: 2.54759
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.83688

Cumulative Model Updates: 208,166
Cumulative Timesteps: 1,736,093,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.18012
Policy Entropy: 2.18019
Value Function Loss: 0.01611

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.56267

Collected Steps per Second: 22,709.21343
Overall Steps per Second: 10,475.25724

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.57151
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.77334

Cumulative Model Updates: 208,172
Cumulative Timesteps: 1,736,143,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1736143932...
Checkpoint 1736143932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.64889
Policy Entropy: 2.15624
Value Function Loss: 0.01616

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.56163

Collected Steps per Second: 21,790.97857
Overall Steps per Second: 10,265.71072

Timestep Collection Time: 2.29462
Timestep Consumption Time: 2.57616
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.87078

Cumulative Model Updates: 208,178
Cumulative Timesteps: 1,736,193,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.76353
Policy Entropy: 2.15406
Value Function Loss: 0.01608

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.57148

Collected Steps per Second: 22,051.50510
Overall Steps per Second: 10,360.55202

Timestep Collection Time: 2.26814
Timestep Consumption Time: 2.55940
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.82754

Cumulative Model Updates: 208,184
Cumulative Timesteps: 1,736,243,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1736243950...
Checkpoint 1736243950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.66427
Policy Entropy: 2.15022
Value Function Loss: 0.01572

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.57006

Collected Steps per Second: 21,628.14518
Overall Steps per Second: 10,250.86331

Timestep Collection Time: 2.31245
Timestep Consumption Time: 2.56655
PPO Batch Consumption Time: 0.30446
Total Iteration Time: 4.87900

Cumulative Model Updates: 208,190
Cumulative Timesteps: 1,736,293,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.70725
Policy Entropy: 2.15379
Value Function Loss: 0.01533

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.56458

Collected Steps per Second: 21,877.51512
Overall Steps per Second: 10,446.99294

Timestep Collection Time: 2.28691
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.78913

Cumulative Model Updates: 208,196
Cumulative Timesteps: 1,736,343,996

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1736343996...
Checkpoint 1736343996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.36056
Policy Entropy: 2.14591
Value Function Loss: 0.01555

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.57803

Collected Steps per Second: 21,264.05025
Overall Steps per Second: 10,195.31660

Timestep Collection Time: 2.35195
Timestep Consumption Time: 2.55344
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.90539

Cumulative Model Updates: 208,202
Cumulative Timesteps: 1,736,394,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.08314
Policy Entropy: 2.13638
Value Function Loss: 0.01583

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.60401

Collected Steps per Second: 21,907.46536
Overall Steps per Second: 10,366.45987

Timestep Collection Time: 2.28251
Timestep Consumption Time: 2.54112
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.82363

Cumulative Model Updates: 208,208
Cumulative Timesteps: 1,736,444,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1736444012...
Checkpoint 1736444012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.96690
Policy Entropy: 2.15137
Value Function Loss: 0.01608

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.55324
Value Function Update Magnitude: 0.61691

Collected Steps per Second: 21,981.11210
Overall Steps per Second: 10,323.30146

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.57017
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 4.84612

Cumulative Model Updates: 208,214
Cumulative Timesteps: 1,736,494,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.11964
Policy Entropy: 2.14735
Value Function Loss: 0.01647

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.62247

Collected Steps per Second: 21,892.40076
Overall Steps per Second: 10,442.38000

Timestep Collection Time: 2.28499
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.79048

Cumulative Model Updates: 208,220
Cumulative Timesteps: 1,736,544,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1736544064...
Checkpoint 1736544064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.67666
Policy Entropy: 2.16101
Value Function Loss: 0.01507

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 21,749.62479
Overall Steps per Second: 10,544.36552

Timestep Collection Time: 2.29999
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.74415

Cumulative Model Updates: 208,226
Cumulative Timesteps: 1,736,594,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.16114
Policy Entropy: 2.16344
Value Function Loss: 0.01520

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.59298

Collected Steps per Second: 22,053.41461
Overall Steps per Second: 10,418.32470

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.79924

Cumulative Model Updates: 208,232
Cumulative Timesteps: 1,736,644,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1736644088...
Checkpoint 1736644088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.46149
Policy Entropy: 2.18149
Value Function Loss: 0.01445

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.52703
Value Function Update Magnitude: 0.59365

Collected Steps per Second: 21,866.91664
Overall Steps per Second: 10,281.87881

Timestep Collection Time: 2.28784
Timestep Consumption Time: 2.57781
PPO Batch Consumption Time: 0.29854
Total Iteration Time: 4.86565

Cumulative Model Updates: 208,238
Cumulative Timesteps: 1,736,694,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.10153
Policy Entropy: 2.17442
Value Function Loss: 0.01634

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.52971
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 21,807.57631
Overall Steps per Second: 10,516.47815

Timestep Collection Time: 2.29315
Timestep Consumption Time: 2.46206
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.75520

Cumulative Model Updates: 208,244
Cumulative Timesteps: 1,736,744,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1736744124...
Checkpoint 1736744124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.85359
Policy Entropy: 2.15803
Value Function Loss: 0.01651

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.59517

Collected Steps per Second: 22,000.73447
Overall Steps per Second: 10,334.68078

Timestep Collection Time: 2.27265
Timestep Consumption Time: 2.56543
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.83808

Cumulative Model Updates: 208,250
Cumulative Timesteps: 1,736,794,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.18467
Policy Entropy: 2.13337
Value Function Loss: 0.01722

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.59416

Collected Steps per Second: 21,893.83896
Overall Steps per Second: 10,318.11854

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.56271
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.84701

Cumulative Model Updates: 208,256
Cumulative Timesteps: 1,736,844,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1736844136...
Checkpoint 1736844136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.35982
Policy Entropy: 2.14551
Value Function Loss: 0.01670

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 21,661.16904
Overall Steps per Second: 10,293.59564

Timestep Collection Time: 2.30976
Timestep Consumption Time: 2.55074
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.86050

Cumulative Model Updates: 208,262
Cumulative Timesteps: 1,736,894,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.74013
Policy Entropy: 2.15174
Value Function Loss: 0.01711

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.60393

Collected Steps per Second: 21,881.43224
Overall Steps per Second: 10,392.27126

Timestep Collection Time: 2.28614
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.81358

Cumulative Model Updates: 208,268
Cumulative Timesteps: 1,736,944,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1736944192...
Checkpoint 1736944192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.39589
Policy Entropy: 2.14766
Value Function Loss: 0.01658

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.62489

Collected Steps per Second: 21,724.02770
Overall Steps per Second: 10,543.07615

Timestep Collection Time: 2.30206
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.74340

Cumulative Model Updates: 208,274
Cumulative Timesteps: 1,736,994,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.97808
Policy Entropy: 2.14055
Value Function Loss: 0.01618

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.61221

Collected Steps per Second: 22,004.18328
Overall Steps per Second: 10,453.53732

Timestep Collection Time: 2.27339
Timestep Consumption Time: 2.51198
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.78537

Cumulative Model Updates: 208,280
Cumulative Timesteps: 1,737,044,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1737044226...
Checkpoint 1737044226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.33184
Policy Entropy: 2.12636
Value Function Loss: 0.01523

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.53942
Value Function Update Magnitude: 0.59082

Collected Steps per Second: 21,856.84384
Overall Steps per Second: 10,256.96358

Timestep Collection Time: 2.28770
Timestep Consumption Time: 2.58723
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.87493

Cumulative Model Updates: 208,286
Cumulative Timesteps: 1,737,094,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.25432
Policy Entropy: 2.14075
Value Function Loss: 0.01570

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.58414

Collected Steps per Second: 21,583.30008
Overall Steps per Second: 10,368.81327

Timestep Collection Time: 2.31735
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.82370

Cumulative Model Updates: 208,292
Cumulative Timesteps: 1,737,144,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1737144244...
Checkpoint 1737144244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.64058
Policy Entropy: 2.14576
Value Function Loss: 0.01625

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.61263

Collected Steps per Second: 22,752.21543
Overall Steps per Second: 10,505.90478

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.56185
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.75961

Cumulative Model Updates: 208,298
Cumulative Timesteps: 1,737,194,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.05747
Policy Entropy: 2.15058
Value Function Loss: 0.01731

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.64517

Collected Steps per Second: 22,121.21184
Overall Steps per Second: 10,311.86963

Timestep Collection Time: 2.26109
Timestep Consumption Time: 2.58944
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.85053

Cumulative Model Updates: 208,304
Cumulative Timesteps: 1,737,244,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1737244266...
Checkpoint 1737244266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.16351
Policy Entropy: 2.11169
Value Function Loss: 0.01729

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.56230
Value Function Update Magnitude: 0.63361

Collected Steps per Second: 21,399.01444
Overall Steps per Second: 10,170.42968

Timestep Collection Time: 2.33880
Timestep Consumption Time: 2.58213
PPO Batch Consumption Time: 0.30166
Total Iteration Time: 4.92093

Cumulative Model Updates: 208,310
Cumulative Timesteps: 1,737,294,314

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.76232
Policy Entropy: 2.09815
Value Function Loss: 0.01782

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.60188

Collected Steps per Second: 21,772.14518
Overall Steps per Second: 10,415.02930

Timestep Collection Time: 2.29706
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.80191

Cumulative Model Updates: 208,316
Cumulative Timesteps: 1,737,344,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1737344326...
Checkpoint 1737344326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.87666
Policy Entropy: 2.09351
Value Function Loss: 0.01729

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,341.11038
Overall Steps per Second: 10,475.58345

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.77453

Cumulative Model Updates: 208,322
Cumulative Timesteps: 1,737,394,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.71178
Policy Entropy: 2.12015
Value Function Loss: 0.01739

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.51860
Value Function Update Magnitude: 0.60246

Collected Steps per Second: 21,874.79529
Overall Steps per Second: 10,232.74158

Timestep Collection Time: 2.28674
Timestep Consumption Time: 2.60168
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.88843

Cumulative Model Updates: 208,328
Cumulative Timesteps: 1,737,444,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1737444364...
Checkpoint 1737444364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.45320
Policy Entropy: 2.14399
Value Function Loss: 0.01726

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.60142

Collected Steps per Second: 21,760.67418
Overall Steps per Second: 10,230.23322

Timestep Collection Time: 2.29846
Timestep Consumption Time: 2.59058
PPO Batch Consumption Time: 0.30408
Total Iteration Time: 4.88904

Cumulative Model Updates: 208,334
Cumulative Timesteps: 1,737,494,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.74026
Policy Entropy: 2.13778
Value Function Loss: 0.01706

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 21,956.93366
Overall Steps per Second: 10,464.98461

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.77937

Cumulative Model Updates: 208,340
Cumulative Timesteps: 1,737,544,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1737544396...
Checkpoint 1737544396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.04611
Policy Entropy: 2.11524
Value Function Loss: 0.01598

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.54146
Value Function Update Magnitude: 0.58756

Collected Steps per Second: 21,421.31005
Overall Steps per Second: 10,406.39292

Timestep Collection Time: 2.33515
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.80685

Cumulative Model Updates: 208,346
Cumulative Timesteps: 1,737,594,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.56183
Policy Entropy: 2.08639
Value Function Loss: 0.01730

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.59059

Collected Steps per Second: 21,706.74937
Overall Steps per Second: 10,247.97707

Timestep Collection Time: 2.30435
Timestep Consumption Time: 2.57661
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.88096

Cumulative Model Updates: 208,352
Cumulative Timesteps: 1,737,644,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1737644438...
Checkpoint 1737644438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.78707
Policy Entropy: 2.07811
Value Function Loss: 0.01772

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.61975

Collected Steps per Second: 21,881.12034
Overall Steps per Second: 10,264.40085

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.58779
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 4.87432

Cumulative Model Updates: 208,358
Cumulative Timesteps: 1,737,694,470

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.38593
Policy Entropy: 2.07883
Value Function Loss: 0.01849

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.63468

Collected Steps per Second: 21,842.14333
Overall Steps per Second: 10,420.30733

Timestep Collection Time: 2.28979
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.79967

Cumulative Model Updates: 208,364
Cumulative Timesteps: 1,737,744,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1737744484...
Checkpoint 1737744484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.45455
Policy Entropy: 2.10327
Value Function Loss: 0.01684

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 21,953.11443
Overall Steps per Second: 10,621.06948

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.70951

Cumulative Model Updates: 208,370
Cumulative Timesteps: 1,737,794,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.12784
Policy Entropy: 2.08326
Value Function Loss: 0.01783

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.61859

Collected Steps per Second: 21,994.38961
Overall Steps per Second: 10,402.62822

Timestep Collection Time: 2.27385
Timestep Consumption Time: 2.53378
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.80763

Cumulative Model Updates: 208,376
Cumulative Timesteps: 1,737,844,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1737844516...
Checkpoint 1737844516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.76939
Policy Entropy: 2.08719
Value Function Loss: 0.01806

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.62867

Collected Steps per Second: 21,658.52426
Overall Steps per Second: 10,263.59433

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.56334
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.87217

Cumulative Model Updates: 208,382
Cumulative Timesteps: 1,737,894,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.15679
Policy Entropy: 2.08207
Value Function Loss: 0.01884

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.64821

Collected Steps per Second: 21,888.20357
Overall Steps per Second: 10,465.18770

Timestep Collection Time: 2.28461
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.77832

Cumulative Model Updates: 208,388
Cumulative Timesteps: 1,737,944,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1737944528...
Checkpoint 1737944528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.99242
Policy Entropy: 2.09218
Value Function Loss: 0.01786

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.17136
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.64183

Collected Steps per Second: 21,724.28441
Overall Steps per Second: 10,546.30363

Timestep Collection Time: 2.30277
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74346

Cumulative Model Updates: 208,394
Cumulative Timesteps: 1,737,994,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.12296
Policy Entropy: 2.10199
Value Function Loss: 0.01811

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.18999
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.64919

Collected Steps per Second: 22,137.78915
Overall Steps per Second: 10,445.05551

Timestep Collection Time: 2.25930
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.78849

Cumulative Model Updates: 208,400
Cumulative Timesteps: 1,738,044,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1738044570...
Checkpoint 1738044570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.60233
Policy Entropy: 2.08840
Value Function Loss: 0.01824

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.19413
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.64532

Collected Steps per Second: 21,636.82578
Overall Steps per Second: 10,310.95140

Timestep Collection Time: 2.31217
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.85193

Cumulative Model Updates: 208,406
Cumulative Timesteps: 1,738,094,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.08266
Policy Entropy: 2.07823
Value Function Loss: 0.01811

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.17350
Policy Update Magnitude: 0.55326
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 21,775.13420
Overall Steps per Second: 10,371.58463

Timestep Collection Time: 2.29620
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.82086

Cumulative Model Updates: 208,412
Cumulative Timesteps: 1,738,144,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1738144598...
Checkpoint 1738144598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.05529
Policy Entropy: 2.04909
Value Function Loss: 0.01739

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.65807

Collected Steps per Second: 21,744.54331
Overall Steps per Second: 10,296.51086

Timestep Collection Time: 2.30007
Timestep Consumption Time: 2.55730
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.85737

Cumulative Model Updates: 208,418
Cumulative Timesteps: 1,738,194,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.54877
Policy Entropy: 2.05908
Value Function Loss: 0.01758

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.63728

Collected Steps per Second: 21,953.70318
Overall Steps per Second: 10,414.78532

Timestep Collection Time: 2.27889
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.80375

Cumulative Model Updates: 208,424
Cumulative Timesteps: 1,738,244,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1738244642...
Checkpoint 1738244642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.62132
Policy Entropy: 2.06451
Value Function Loss: 0.01782

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 21,139.48297
Overall Steps per Second: 10,209.12207

Timestep Collection Time: 2.36590
Timestep Consumption Time: 2.53305
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.89895

Cumulative Model Updates: 208,430
Cumulative Timesteps: 1,738,294,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.64434
Policy Entropy: 2.07969
Value Function Loss: 0.01835

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.54988
Value Function Update Magnitude: 0.63531

Collected Steps per Second: 22,056.66442
Overall Steps per Second: 10,408.39677

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.53713
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.80420

Cumulative Model Updates: 208,436
Cumulative Timesteps: 1,738,344,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1738344660...
Checkpoint 1738344660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.59938
Policy Entropy: 2.08151
Value Function Loss: 0.01789

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.16057
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.65530

Collected Steps per Second: 21,634.58170
Overall Steps per Second: 10,320.86369

Timestep Collection Time: 2.31213
Timestep Consumption Time: 2.53456
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.84669

Cumulative Model Updates: 208,442
Cumulative Timesteps: 1,738,394,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.73202
Policy Entropy: 2.06283
Value Function Loss: 0.01850

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.63738

Collected Steps per Second: 21,785.27612
Overall Steps per Second: 10,460.19418

Timestep Collection Time: 2.29641
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.78270

Cumulative Model Updates: 208,448
Cumulative Timesteps: 1,738,444,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1738444710...
Checkpoint 1738444710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.38039
Policy Entropy: 2.05871
Value Function Loss: 0.01810

Mean KL Divergence: 0.03035
SB3 Clip Fraction: 0.19582
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 21,105.12992
Overall Steps per Second: 10,261.21100

Timestep Collection Time: 2.37004
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.30359
Total Iteration Time: 4.87467

Cumulative Model Updates: 208,454
Cumulative Timesteps: 1,738,494,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.19874
Policy Entropy: 2.05913
Value Function Loss: 0.01819

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.17480
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.62904

Collected Steps per Second: 21,935.63637
Overall Steps per Second: 10,417.78270

Timestep Collection Time: 2.28022
Timestep Consumption Time: 2.52100
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.80121

Cumulative Model Updates: 208,460
Cumulative Timesteps: 1,738,544,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1738544748...
Checkpoint 1738544748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.23227
Policy Entropy: 2.06747
Value Function Loss: 0.01781

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.19085
Policy Update Magnitude: 0.59873
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 21,609.43287
Overall Steps per Second: 10,211.88561

Timestep Collection Time: 2.31547
Timestep Consumption Time: 2.58431
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.89978

Cumulative Model Updates: 208,466
Cumulative Timesteps: 1,738,594,784

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.16921
Policy Entropy: 2.07591
Value Function Loss: 0.01658

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.18432
Policy Update Magnitude: 0.59581
Value Function Update Magnitude: 0.61201

Collected Steps per Second: 21,856.71887
Overall Steps per Second: 10,386.44642

Timestep Collection Time: 2.28808
Timestep Consumption Time: 2.52685
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.81493

Cumulative Model Updates: 208,472
Cumulative Timesteps: 1,738,644,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1738644794...
Checkpoint 1738644794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.37648
Policy Entropy: 2.08589
Value Function Loss: 0.01646

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.59026

Collected Steps per Second: 21,679.64133
Overall Steps per Second: 10,468.60297

Timestep Collection Time: 2.30751
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.77867

Cumulative Model Updates: 208,478
Cumulative Timesteps: 1,738,694,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.86927
Policy Entropy: 2.08920
Value Function Loss: 0.01636

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.59481

Collected Steps per Second: 22,168.16455
Overall Steps per Second: 10,311.18880

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.59476
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.85124

Cumulative Model Updates: 208,484
Cumulative Timesteps: 1,738,744,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1738744842...
Checkpoint 1738744842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.27547
Policy Entropy: 2.07384
Value Function Loss: 0.01697

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.56687
Value Function Update Magnitude: 0.61159

Collected Steps per Second: 21,414.97778
Overall Steps per Second: 10,171.18983

Timestep Collection Time: 2.33696
Timestep Consumption Time: 2.58341
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.92037

Cumulative Model Updates: 208,490
Cumulative Timesteps: 1,738,794,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.85271
Policy Entropy: 2.11115
Value Function Loss: 0.01763

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 21,895.60823
Overall Steps per Second: 10,459.26282

Timestep Collection Time: 2.28493
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.78332

Cumulative Model Updates: 208,496
Cumulative Timesteps: 1,738,844,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1738844918...
Checkpoint 1738844918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.17866
Policy Entropy: 2.12399
Value Function Loss: 0.01787

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.65547

Collected Steps per Second: 21,682.50105
Overall Steps per Second: 10,283.88672

Timestep Collection Time: 2.30684
Timestep Consumption Time: 2.55689
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 4.86373

Cumulative Model Updates: 208,502
Cumulative Timesteps: 1,738,894,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.04928
Policy Entropy: 2.14243
Value Function Loss: 0.01747

Mean KL Divergence: 0.02676
SB3 Clip Fraction: 0.17718
Policy Update Magnitude: 0.51180
Value Function Update Magnitude: 0.64871

Collected Steps per Second: 22,328.59065
Overall Steps per Second: 10,708.44750

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.67052

Cumulative Model Updates: 208,508
Cumulative Timesteps: 1,738,944,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1738944950...
Checkpoint 1738944950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.75738
Policy Entropy: 2.14402
Value Function Loss: 0.01708

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 21,796.16359
Overall Steps per Second: 10,321.00974

Timestep Collection Time: 2.29417
Timestep Consumption Time: 2.55071
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.84487

Cumulative Model Updates: 208,514
Cumulative Timesteps: 1,738,994,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.81704
Policy Entropy: 2.12244
Value Function Loss: 0.01746

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.16576
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.60852

Collected Steps per Second: 21,977.53897
Overall Steps per Second: 10,425.96843

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.52077
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.79591

Cumulative Model Updates: 208,520
Cumulative Timesteps: 1,739,044,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1739044956...
Checkpoint 1739044956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.50106
Policy Entropy: 2.10994
Value Function Loss: 0.01746

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 21,656.74582
Overall Steps per Second: 10,274.08034

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.55797
PPO Batch Consumption Time: 0.30419
Total Iteration Time: 4.86681

Cumulative Model Updates: 208,526
Cumulative Timesteps: 1,739,094,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.76673
Policy Entropy: 2.09189
Value Function Loss: 0.01756

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.63771

Collected Steps per Second: 21,932.31865
Overall Steps per Second: 10,423.76184

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.51820
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.79904

Cumulative Model Updates: 208,532
Cumulative Timesteps: 1,739,144,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1739144982...
Checkpoint 1739144982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.18132
Policy Entropy: 2.12384
Value Function Loss: 0.01695

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.62192

Collected Steps per Second: 21,590.70056
Overall Steps per Second: 10,195.62759

Timestep Collection Time: 2.31655
Timestep Consumption Time: 2.58908
PPO Batch Consumption Time: 0.30356
Total Iteration Time: 4.90563

Cumulative Model Updates: 208,538
Cumulative Timesteps: 1,739,194,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.10828
Policy Entropy: 2.11956
Value Function Loss: 0.01663

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.59335

Collected Steps per Second: 22,011.86917
Overall Steps per Second: 10,421.88544

Timestep Collection Time: 2.27168
Timestep Consumption Time: 2.52630
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.79798

Cumulative Model Updates: 208,544
Cumulative Timesteps: 1,739,245,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1739245002...
Checkpoint 1739245002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.86576
Policy Entropy: 2.12876
Value Function Loss: 0.01597

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.57403

Collected Steps per Second: 21,749.68668
Overall Steps per Second: 10,321.21570

Timestep Collection Time: 2.29990
Timestep Consumption Time: 2.54663
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 4.84652

Cumulative Model Updates: 208,550
Cumulative Timesteps: 1,739,295,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.07504
Policy Entropy: 2.12337
Value Function Loss: 0.01604

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.58355

Collected Steps per Second: 22,006.34324
Overall Steps per Second: 10,387.14053

Timestep Collection Time: 2.27244
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.81441

Cumulative Model Updates: 208,556
Cumulative Timesteps: 1,739,345,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1739345032...
Checkpoint 1739345032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.13372
Policy Entropy: 2.13608
Value Function Loss: 0.01726

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.60144

Collected Steps per Second: 21,678.40599
Overall Steps per Second: 10,512.45385

Timestep Collection Time: 2.30653
Timestep Consumption Time: 2.44992
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.75645

Cumulative Model Updates: 208,562
Cumulative Timesteps: 1,739,395,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.18759
Policy Entropy: 2.09763
Value Function Loss: 0.01700

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.62218

Collected Steps per Second: 21,706.54052
Overall Steps per Second: 10,247.06965

Timestep Collection Time: 2.30493
Timestep Consumption Time: 2.57764
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.88257

Cumulative Model Updates: 208,568
Cumulative Timesteps: 1,739,445,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1739445066...
Checkpoint 1739445066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.74206
Policy Entropy: 2.08341
Value Function Loss: 0.01639

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.55017
Value Function Update Magnitude: 0.63820

Collected Steps per Second: 21,882.38093
Overall Steps per Second: 10,411.18172

Timestep Collection Time: 2.28549
Timestep Consumption Time: 2.51819
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.80368

Cumulative Model Updates: 208,574
Cumulative Timesteps: 1,739,495,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.85079
Policy Entropy: 2.08132
Value Function Loss: 0.01579

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 21,931.74601
Overall Steps per Second: 10,469.99807

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77670

Cumulative Model Updates: 208,580
Cumulative Timesteps: 1,739,545,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1739545090...
Checkpoint 1739545090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.45752
Policy Entropy: 2.11673
Value Function Loss: 0.01648

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 21,807.24063
Overall Steps per Second: 10,492.39789

Timestep Collection Time: 2.29392
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.76764

Cumulative Model Updates: 208,586
Cumulative Timesteps: 1,739,595,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.99525
Policy Entropy: 2.13293
Value Function Loss: 0.01656

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.62169

Collected Steps per Second: 22,121.39615
Overall Steps per Second: 10,284.68648

Timestep Collection Time: 2.26053
Timestep Consumption Time: 2.60165
PPO Batch Consumption Time: 0.30414
Total Iteration Time: 4.86218

Cumulative Model Updates: 208,592
Cumulative Timesteps: 1,739,645,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1739645120...
Checkpoint 1739645120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.09317
Policy Entropy: 2.12116
Value Function Loss: 0.01706

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.61390

Collected Steps per Second: 21,832.39911
Overall Steps per Second: 10,264.44637

Timestep Collection Time: 2.29109
Timestep Consumption Time: 2.58204
PPO Batch Consumption Time: 0.30301
Total Iteration Time: 4.87313

Cumulative Model Updates: 208,598
Cumulative Timesteps: 1,739,695,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.08885
Policy Entropy: 2.09186
Value Function Loss: 0.01752

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.56725
Value Function Update Magnitude: 0.63770

Collected Steps per Second: 21,302.81004
Overall Steps per Second: 10,279.59081

Timestep Collection Time: 2.34767
Timestep Consumption Time: 2.51750
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.86517

Cumulative Model Updates: 208,604
Cumulative Timesteps: 1,739,745,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1739745152...
Checkpoint 1739745152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.28100
Policy Entropy: 2.06407
Value Function Loss: 0.01667

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.63363

Collected Steps per Second: 21,586.58182
Overall Steps per Second: 10,379.24430

Timestep Collection Time: 2.31625
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.81731

Cumulative Model Updates: 208,610
Cumulative Timesteps: 1,739,795,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.46211
Policy Entropy: 2.08338
Value Function Loss: 0.01702

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 21,996.02710
Overall Steps per Second: 10,413.02407

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.52945
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80341

Cumulative Model Updates: 208,616
Cumulative Timesteps: 1,739,845,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1739845170...
Checkpoint 1739845170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.02301
Policy Entropy: 2.09652
Value Function Loss: 0.01667

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.55137
Value Function Update Magnitude: 0.57998

Collected Steps per Second: 21,758.37718
Overall Steps per Second: 10,228.14999

Timestep Collection Time: 2.29898
Timestep Consumption Time: 2.59164
PPO Batch Consumption Time: 0.30364
Total Iteration Time: 4.89062

Cumulative Model Updates: 208,622
Cumulative Timesteps: 1,739,895,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.42162
Policy Entropy: 2.11949
Value Function Loss: 0.01754

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.55011

Collected Steps per Second: 21,656.55871
Overall Steps per Second: 10,369.94673

Timestep Collection Time: 2.30914
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.82240

Cumulative Model Updates: 208,628
Cumulative Timesteps: 1,739,945,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1739945200...
Checkpoint 1739945200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.73274
Policy Entropy: 2.12937
Value Function Loss: 0.01712

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.54047

Collected Steps per Second: 21,876.33433
Overall Steps per Second: 10,613.27028

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71297

Cumulative Model Updates: 208,634
Cumulative Timesteps: 1,739,995,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.77861
Policy Entropy: 2.11855
Value Function Loss: 0.01697

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.55315

Collected Steps per Second: 22,205.09395
Overall Steps per Second: 10,435.28129

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.54062
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.79316

Cumulative Model Updates: 208,640
Cumulative Timesteps: 1,740,045,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1740045238...
Checkpoint 1740045238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.47413
Policy Entropy: 2.13949
Value Function Loss: 0.01701

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 21,960.07281
Overall Steps per Second: 10,328.64274

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.56518
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.84304

Cumulative Model Updates: 208,646
Cumulative Timesteps: 1,740,095,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.32714
Policy Entropy: 2.13467
Value Function Loss: 0.01715

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 21,722.15549
Overall Steps per Second: 10,407.55531

Timestep Collection Time: 2.30263
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.80593

Cumulative Model Updates: 208,652
Cumulative Timesteps: 1,740,145,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1740145278...
Checkpoint 1740145278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.49625
Policy Entropy: 2.13927
Value Function Loss: 0.01636

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.58141

Collected Steps per Second: 21,920.64532
Overall Steps per Second: 10,593.56233

Timestep Collection Time: 2.28132
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.72060

Cumulative Model Updates: 208,658
Cumulative Timesteps: 1,740,195,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.01369
Policy Entropy: 2.13164
Value Function Loss: 0.01633

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 22,074.68404
Overall Steps per Second: 10,373.86885

Timestep Collection Time: 2.26613
Timestep Consumption Time: 2.55599
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.82212

Cumulative Model Updates: 208,664
Cumulative Timesteps: 1,740,245,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1740245310...
Checkpoint 1740245310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.50747
Policy Entropy: 2.13417
Value Function Loss: 0.01636

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.59077

Collected Steps per Second: 21,756.84501
Overall Steps per Second: 10,376.97870

Timestep Collection Time: 2.29877
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.81971

Cumulative Model Updates: 208,670
Cumulative Timesteps: 1,740,295,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.43039
Policy Entropy: 2.15668
Value Function Loss: 0.01659

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.53432
Value Function Update Magnitude: 0.59526

Collected Steps per Second: 21,818.27416
Overall Steps per Second: 10,438.16692

Timestep Collection Time: 2.29184
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.79050

Cumulative Model Updates: 208,676
Cumulative Timesteps: 1,740,345,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1740345328...
Checkpoint 1740345328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.46430
Policy Entropy: 2.16368
Value Function Loss: 0.01640

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.53086
Value Function Update Magnitude: 0.59990

Collected Steps per Second: 21,808.26936
Overall Steps per Second: 10,551.70840

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.73876

Cumulative Model Updates: 208,682
Cumulative Timesteps: 1,740,395,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.42712
Policy Entropy: 2.15628
Value Function Loss: 0.01652

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.58951

Collected Steps per Second: 22,483.29580
Overall Steps per Second: 10,521.00101

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.52863
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75259

Cumulative Model Updates: 208,688
Cumulative Timesteps: 1,740,445,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1740445332...
Checkpoint 1740445332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.61018
Policy Entropy: 2.12348
Value Function Loss: 0.01689

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.60178

Collected Steps per Second: 21,778.61664
Overall Steps per Second: 10,244.95616

Timestep Collection Time: 2.29601
Timestep Consumption Time: 2.58483
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.88084

Cumulative Model Updates: 208,694
Cumulative Timesteps: 1,740,495,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.98400
Policy Entropy: 2.10155
Value Function Loss: 0.01750

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 21,722.92424
Overall Steps per Second: 10,443.82649

Timestep Collection Time: 2.30199
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.78809

Cumulative Model Updates: 208,700
Cumulative Timesteps: 1,740,545,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1740545342...
Checkpoint 1740545342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.90920
Policy Entropy: 2.11634
Value Function Loss: 0.01665

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 21,636.45454
Overall Steps per Second: 10,526.55789

Timestep Collection Time: 2.31202
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.75217

Cumulative Model Updates: 208,706
Cumulative Timesteps: 1,740,595,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.05929
Policy Entropy: 2.13860
Value Function Loss: 0.01609

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.57334

Collected Steps per Second: 22,314.12051
Overall Steps per Second: 10,500.43694

Timestep Collection Time: 2.24190
Timestep Consumption Time: 2.52228
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.76418

Cumulative Model Updates: 208,712
Cumulative Timesteps: 1,740,645,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1740645392...
Checkpoint 1740645392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.64762
Policy Entropy: 2.13341
Value Function Loss: 0.01590

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.55664

Collected Steps per Second: 22,017.10440
Overall Steps per Second: 10,289.12761

Timestep Collection Time: 2.27223
Timestep Consumption Time: 2.58999
PPO Batch Consumption Time: 0.30486
Total Iteration Time: 4.86222

Cumulative Model Updates: 208,718
Cumulative Timesteps: 1,740,695,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.91905
Policy Entropy: 2.15592
Value Function Loss: 0.01587

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.55778

Collected Steps per Second: 21,806.74761
Overall Steps per Second: 10,369.35449

Timestep Collection Time: 2.29296
Timestep Consumption Time: 2.52913
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.82209

Cumulative Model Updates: 208,724
Cumulative Timesteps: 1,740,745,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1740745422...
Checkpoint 1740745422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.05671
Policy Entropy: 2.13221
Value Function Loss: 0.01695

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.57716

Collected Steps per Second: 21,897.75492
Overall Steps per Second: 10,605.30939

Timestep Collection Time: 2.28361
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71519

Cumulative Model Updates: 208,730
Cumulative Timesteps: 1,740,795,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.16661
Policy Entropy: 2.13997
Value Function Loss: 0.01651

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.60263

Collected Steps per Second: 22,097.63152
Overall Steps per Second: 10,458.98461

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.78230

Cumulative Model Updates: 208,736
Cumulative Timesteps: 1,740,845,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1740845446...
Checkpoint 1740845446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.72092
Policy Entropy: 2.11710
Value Function Loss: 0.01659

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.55271
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 21,959.64371
Overall Steps per Second: 10,334.62606

Timestep Collection Time: 2.27909
Timestep Consumption Time: 2.56366
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.84275

Cumulative Model Updates: 208,742
Cumulative Timesteps: 1,740,895,494

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.03682
Policy Entropy: 2.12439
Value Function Loss: 0.01630

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.63669

Collected Steps per Second: 20,990.67383
Overall Steps per Second: 10,145.95946

Timestep Collection Time: 2.38220
Timestep Consumption Time: 2.54626
PPO Batch Consumption Time: 0.30294
Total Iteration Time: 4.92846

Cumulative Model Updates: 208,748
Cumulative Timesteps: 1,740,945,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1740945498...
Checkpoint 1740945498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.82545
Policy Entropy: 2.11309
Value Function Loss: 0.01646

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.63788

Collected Steps per Second: 21,598.17326
Overall Steps per Second: 10,515.50648

Timestep Collection Time: 2.31529
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75545

Cumulative Model Updates: 208,754
Cumulative Timesteps: 1,740,995,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.58710
Policy Entropy: 2.09363
Value Function Loss: 0.01718

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.62524

Collected Steps per Second: 21,931.99660
Overall Steps per Second: 10,380.11202

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.53713
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.81690

Cumulative Model Updates: 208,760
Cumulative Timesteps: 1,741,045,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1741045504...
Checkpoint 1741045504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.00778
Policy Entropy: 2.09800
Value Function Loss: 0.01804

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 21,811.52062
Overall Steps per Second: 10,268.99705

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.57738
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.87039

Cumulative Model Updates: 208,766
Cumulative Timesteps: 1,741,095,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.40998
Policy Entropy: 2.12842
Value Function Loss: 0.01752

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 21,778.40452
Overall Steps per Second: 10,411.62366

Timestep Collection Time: 2.29640
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.80348

Cumulative Model Updates: 208,772
Cumulative Timesteps: 1,741,145,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1741145530...
Checkpoint 1741145530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.00988
Policy Entropy: 2.16573
Value Function Loss: 0.01654

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.55988
Value Function Update Magnitude: 0.64667

Collected Steps per Second: 21,701.43485
Overall Steps per Second: 10,470.34868

Timestep Collection Time: 2.30427
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.77596

Cumulative Model Updates: 208,778
Cumulative Timesteps: 1,741,195,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.46508
Policy Entropy: 2.16329
Value Function Loss: 0.01597

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.55217
Value Function Update Magnitude: 0.63553

Collected Steps per Second: 22,173.18095
Overall Steps per Second: 10,330.31121

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.58639
PPO Batch Consumption Time: 0.30429
Total Iteration Time: 4.84245

Cumulative Model Updates: 208,784
Cumulative Timesteps: 1,741,245,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1741245560...
Checkpoint 1741245560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.05023
Policy Entropy: 2.15385
Value Function Loss: 0.01615

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.63312

Collected Steps per Second: 21,482.51141
Overall Steps per Second: 10,167.07290

Timestep Collection Time: 2.32896
Timestep Consumption Time: 2.59202
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.92098

Cumulative Model Updates: 208,790
Cumulative Timesteps: 1,741,295,592

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.90811
Policy Entropy: 2.14088
Value Function Loss: 0.01683

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.63647

Collected Steps per Second: 21,676.44243
Overall Steps per Second: 10,366.59175

Timestep Collection Time: 2.30739
Timestep Consumption Time: 2.51734
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.82473

Cumulative Model Updates: 208,796
Cumulative Timesteps: 1,741,345,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1741345608...
Checkpoint 1741345608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.86131
Policy Entropy: 2.15150
Value Function Loss: 0.01818

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 21,622.34235
Overall Steps per Second: 10,431.37398

Timestep Collection Time: 2.31298
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.79438

Cumulative Model Updates: 208,802
Cumulative Timesteps: 1,741,395,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.46393
Policy Entropy: 2.16464
Value Function Loss: 0.01810

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.56408
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 22,180.13189
Overall Steps per Second: 10,308.27739

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.59703
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.85202

Cumulative Model Updates: 208,808
Cumulative Timesteps: 1,741,445,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1741445636...
Checkpoint 1741445636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.08121
Policy Entropy: 2.16711
Value Function Loss: 0.01745

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 21,710.28051
Overall Steps per Second: 10,203.88277

Timestep Collection Time: 2.30315
Timestep Consumption Time: 2.59714
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.90029

Cumulative Model Updates: 208,814
Cumulative Timesteps: 1,741,495,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.43099
Policy Entropy: 2.16615
Value Function Loss: 0.01674

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.60193

Collected Steps per Second: 21,939.03128
Overall Steps per Second: 10,476.24004

Timestep Collection Time: 2.28023
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.77519

Cumulative Model Updates: 208,820
Cumulative Timesteps: 1,741,545,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1741545664...
Checkpoint 1741545664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.49405
Policy Entropy: 2.15716
Value Function Loss: 0.01669

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.54268
Value Function Update Magnitude: 0.58126

Collected Steps per Second: 21,903.10705
Overall Steps per Second: 10,572.86948

Timestep Collection Time: 2.28315
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.72984

Cumulative Model Updates: 208,826
Cumulative Timesteps: 1,741,595,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.77257
Policy Entropy: 2.16393
Value Function Loss: 0.01761

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.58060

Collected Steps per Second: 22,416.33154
Overall Steps per Second: 10,525.63140

Timestep Collection Time: 2.23087
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.75107

Cumulative Model Updates: 208,832
Cumulative Timesteps: 1,741,645,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1741645680...
Checkpoint 1741645680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.59618
Policy Entropy: 2.15890
Value Function Loss: 0.01812

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.59594

Collected Steps per Second: 20,990.57271
Overall Steps per Second: 10,136.30341

Timestep Collection Time: 2.38259
Timestep Consumption Time: 2.55136
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.93395

Cumulative Model Updates: 208,838
Cumulative Timesteps: 1,741,695,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.93865
Policy Entropy: 2.15066
Value Function Loss: 0.01720

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.59093

Collected Steps per Second: 21,759.97277
Overall Steps per Second: 10,416.93112

Timestep Collection Time: 2.29862
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.80161

Cumulative Model Updates: 208,844
Cumulative Timesteps: 1,741,745,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1741745710...
Checkpoint 1741745710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.39554
Policy Entropy: 2.14024
Value Function Loss: 0.01685

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.59419

Collected Steps per Second: 21,750.66788
Overall Steps per Second: 10,457.55023

Timestep Collection Time: 2.29988
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.78353

Cumulative Model Updates: 208,850
Cumulative Timesteps: 1,741,795,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.51110
Policy Entropy: 2.13559
Value Function Loss: 0.01625

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.59633

Collected Steps per Second: 21,969.00344
Overall Steps per Second: 10,335.67344

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.56301
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.84013

Cumulative Model Updates: 208,856
Cumulative Timesteps: 1,741,845,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1741845760...
Checkpoint 1741845760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.13603
Policy Entropy: 2.13424
Value Function Loss: 0.01718

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.61011

Collected Steps per Second: 21,484.71502
Overall Steps per Second: 10,203.61826

Timestep Collection Time: 2.32807
Timestep Consumption Time: 2.57391
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.90199

Cumulative Model Updates: 208,862
Cumulative Timesteps: 1,741,895,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.83610
Policy Entropy: 2.13488
Value Function Loss: 0.01724

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.62741

Collected Steps per Second: 21,701.31393
Overall Steps per Second: 10,344.88636

Timestep Collection Time: 2.30438
Timestep Consumption Time: 2.52970
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.83408

Cumulative Model Updates: 208,868
Cumulative Timesteps: 1,741,945,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1741945786...
Checkpoint 1741945786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.11660
Policy Entropy: 2.13904
Value Function Loss: 0.01749

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 21,873.93154
Overall Steps per Second: 10,517.51671

Timestep Collection Time: 2.28628
Timestep Consumption Time: 2.46864
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.75492

Cumulative Model Updates: 208,874
Cumulative Timesteps: 1,741,995,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.76624
Policy Entropy: 2.16944
Value Function Loss: 0.01705

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,055.03342
Overall Steps per Second: 10,278.21363

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.59812
PPO Batch Consumption Time: 0.30493
Total Iteration Time: 4.86563

Cumulative Model Updates: 208,880
Cumulative Timesteps: 1,742,045,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1742045806...
Checkpoint 1742045806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.41245
Policy Entropy: 2.15843
Value Function Loss: 0.01784

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.62706

Collected Steps per Second: 21,343.42656
Overall Steps per Second: 10,185.35356

Timestep Collection Time: 2.34349
Timestep Consumption Time: 2.56729
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.91078

Cumulative Model Updates: 208,886
Cumulative Timesteps: 1,742,095,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.08435
Policy Entropy: 2.16008
Value Function Loss: 0.01765

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.62194

Collected Steps per Second: 21,795.37257
Overall Steps per Second: 10,376.73300

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.52532
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.82021

Cumulative Model Updates: 208,892
Cumulative Timesteps: 1,742,145,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1742145842...
Checkpoint 1742145842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.94131
Policy Entropy: 2.13582
Value Function Loss: 0.01705

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.59197

Collected Steps per Second: 21,771.77292
Overall Steps per Second: 10,288.55429

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.56404
PPO Batch Consumption Time: 0.30225
Total Iteration Time: 4.86132

Cumulative Model Updates: 208,898
Cumulative Timesteps: 1,742,195,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.42391
Policy Entropy: 2.15086
Value Function Loss: 0.01619

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.58114

Collected Steps per Second: 21,982.44525
Overall Steps per Second: 10,426.01466

Timestep Collection Time: 2.27518
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.79704

Cumulative Model Updates: 208,904
Cumulative Timesteps: 1,742,245,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1742245872...
Checkpoint 1742245872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.30403
Policy Entropy: 2.14104
Value Function Loss: 0.01528

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.53863
Value Function Update Magnitude: 0.57299

Collected Steps per Second: 21,173.31062
Overall Steps per Second: 10,265.41477

Timestep Collection Time: 2.36212
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.87209

Cumulative Model Updates: 208,910
Cumulative Timesteps: 1,742,295,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.82142
Policy Entropy: 2.17005
Value Function Loss: 0.01513

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.57075

Collected Steps per Second: 21,930.08699
Overall Steps per Second: 10,385.51475

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.53595
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.81729

Cumulative Model Updates: 208,916
Cumulative Timesteps: 1,742,345,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1742345916...
Checkpoint 1742345916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.23838
Policy Entropy: 2.16335
Value Function Loss: 0.01567

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.53316
Value Function Update Magnitude: 0.58359

Collected Steps per Second: 21,800.41319
Overall Steps per Second: 10,282.13835

Timestep Collection Time: 2.29418
Timestep Consumption Time: 2.56999
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.86416

Cumulative Model Updates: 208,922
Cumulative Timesteps: 1,742,395,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.07718
Policy Entropy: 2.17528
Value Function Loss: 0.01636

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.59009

Collected Steps per Second: 21,787.91680
Overall Steps per Second: 10,405.65841

Timestep Collection Time: 2.29577
Timestep Consumption Time: 2.51123
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.80700

Cumulative Model Updates: 208,928
Cumulative Timesteps: 1,742,445,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1742445950...
Checkpoint 1742445950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.14778
Policy Entropy: 2.15349
Value Function Loss: 0.01680

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 21,824.09162
Overall Steps per Second: 10,558.99755

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.73530

Cumulative Model Updates: 208,934
Cumulative Timesteps: 1,742,495,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.11426
Policy Entropy: 2.13255
Value Function Loss: 0.01663

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 22,594.31902
Overall Steps per Second: 10,623.46136

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.49501
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.70920

Cumulative Model Updates: 208,940
Cumulative Timesteps: 1,742,545,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1742545978...
Checkpoint 1742545978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.26113
Policy Entropy: 2.12451
Value Function Loss: 0.01583

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.55216
Value Function Update Magnitude: 0.60159

Collected Steps per Second: 21,895.92193
Overall Steps per Second: 10,330.67623

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.55755
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.84208

Cumulative Model Updates: 208,946
Cumulative Timesteps: 1,742,596,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.40683
Policy Entropy: 2.10689
Value Function Loss: 0.01548

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 22,005.15521
Overall Steps per Second: 10,337.16171

Timestep Collection Time: 2.27319
Timestep Consumption Time: 2.56585
PPO Batch Consumption Time: 0.30379
Total Iteration Time: 4.83905

Cumulative Model Updates: 208,952
Cumulative Timesteps: 1,742,646,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1742646022...
Checkpoint 1742646022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.58773
Policy Entropy: 2.10949
Value Function Loss: 0.01620

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.55516

Collected Steps per Second: 21,912.12991
Overall Steps per Second: 10,648.17248

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.41477
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.69752

Cumulative Model Updates: 208,958
Cumulative Timesteps: 1,742,696,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.92931
Policy Entropy: 2.09870
Value Function Loss: 0.01693

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.56051

Collected Steps per Second: 22,064.92269
Overall Steps per Second: 10,424.44920

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.79680

Cumulative Model Updates: 208,964
Cumulative Timesteps: 1,742,746,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1742746046...
Checkpoint 1742746046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.58134
Policy Entropy: 2.11759
Value Function Loss: 0.01657

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.54946
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 21,998.39918
Overall Steps per Second: 10,371.29755

Timestep Collection Time: 2.27371
Timestep Consumption Time: 2.54902
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.82273

Cumulative Model Updates: 208,970
Cumulative Timesteps: 1,742,796,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.50502
Policy Entropy: 2.12596
Value Function Loss: 0.01672

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.55062
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 21,953.43224
Overall Steps per Second: 10,287.96805

Timestep Collection Time: 2.27773
Timestep Consumption Time: 2.58270
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.86044

Cumulative Model Updates: 208,976
Cumulative Timesteps: 1,742,846,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1742846068...
Checkpoint 1742846068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.84622
Policy Entropy: 2.15534
Value Function Loss: 0.01645

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 21,745.96974
Overall Steps per Second: 10,324.47537

Timestep Collection Time: 2.29937
Timestep Consumption Time: 2.54369
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.84305

Cumulative Model Updates: 208,982
Cumulative Timesteps: 1,742,896,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.35405
Policy Entropy: 2.13511
Value Function Loss: 0.01716

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 22,184.40220
Overall Steps per Second: 10,700.55571

Timestep Collection Time: 2.25501
Timestep Consumption Time: 2.42008
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.67508

Cumulative Model Updates: 208,988
Cumulative Timesteps: 1,742,946,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1742946096...
Checkpoint 1742946096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.18112
Policy Entropy: 2.14689
Value Function Loss: 0.01664

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.57699

Collected Steps per Second: 22,281.99568
Overall Steps per Second: 10,447.55244

Timestep Collection Time: 2.24477
Timestep Consumption Time: 2.54276
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.78753

Cumulative Model Updates: 208,994
Cumulative Timesteps: 1,742,996,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.55335
Policy Entropy: 2.11830
Value Function Loss: 0.01662

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.54024
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 22,166.05946
Overall Steps per Second: 10,344.56687

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.57817
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.83423

Cumulative Model Updates: 209,000
Cumulative Timesteps: 1,743,046,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1743046122...
Checkpoint 1743046122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.26104
Policy Entropy: 2.11869
Value Function Loss: 0.01643

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.53656
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 20,524.28029
Overall Steps per Second: 10,094.56202

Timestep Collection Time: 2.43760
Timestep Consumption Time: 2.51853
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.95613

Cumulative Model Updates: 209,006
Cumulative Timesteps: 1,743,096,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.18577
Policy Entropy: 2.10971
Value Function Loss: 0.01725

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.56306

Collected Steps per Second: 21,881.81605
Overall Steps per Second: 10,461.18146

Timestep Collection Time: 2.28537
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.78034

Cumulative Model Updates: 209,012
Cumulative Timesteps: 1,743,146,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1743146160...
Checkpoint 1743146160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.80691
Policy Entropy: 2.12886
Value Function Loss: 0.01744

Mean KL Divergence: 0.03017
SB3 Clip Fraction: 0.18652
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.58683

Collected Steps per Second: 21,977.89160
Overall Steps per Second: 10,678.78914

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.68349

Cumulative Model Updates: 209,018
Cumulative Timesteps: 1,743,196,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.96356
Policy Entropy: 2.18016
Value Function Loss: 0.01796

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.16756
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.61634

Collected Steps per Second: 22,191.17467
Overall Steps per Second: 10,505.43763

Timestep Collection Time: 2.25432
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.76191

Cumulative Model Updates: 209,024
Cumulative Timesteps: 1,743,246,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1743246200...
Checkpoint 1743246200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.82013
Policy Entropy: 2.22093
Value Function Loss: 0.01760

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.63342

Collected Steps per Second: 21,934.96148
Overall Steps per Second: 10,365.96903

Timestep Collection Time: 2.28010
Timestep Consumption Time: 2.54472
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.82483

Cumulative Model Updates: 209,030
Cumulative Timesteps: 1,743,296,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.64191
Policy Entropy: 2.22894
Value Function Loss: 0.01737

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.14948
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.62248

Collected Steps per Second: 22,060.68564
Overall Steps per Second: 10,391.63422

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.54519
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.81176

Cumulative Model Updates: 209,036
Cumulative Timesteps: 1,743,346,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1743346216...
Checkpoint 1743346216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.57252
Policy Entropy: 2.22331
Value Function Loss: 0.01663

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 21,825.69563
Overall Steps per Second: 10,553.44537

Timestep Collection Time: 2.29289
Timestep Consumption Time: 2.44906
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.74196

Cumulative Model Updates: 209,042
Cumulative Timesteps: 1,743,396,260

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.78496
Policy Entropy: 2.17518
Value Function Loss: 0.01635

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.56428

Collected Steps per Second: 22,008.17272
Overall Steps per Second: 10,415.45344

Timestep Collection Time: 2.27261
Timestep Consumption Time: 2.52949
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.80210

Cumulative Model Updates: 209,048
Cumulative Timesteps: 1,743,446,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1743446276...
Checkpoint 1743446276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.07125
Policy Entropy: 2.17416
Value Function Loss: 0.01619

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.56763

Collected Steps per Second: 21,811.71153
Overall Steps per Second: 10,272.06158

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.57646
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 4.86991

Cumulative Model Updates: 209,054
Cumulative Timesteps: 1,743,496,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.69586
Policy Entropy: 2.16876
Value Function Loss: 0.01577

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.56127

Collected Steps per Second: 21,801.50103
Overall Steps per Second: 10,460.47571

Timestep Collection Time: 2.29425
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.78162

Cumulative Model Updates: 209,060
Cumulative Timesteps: 1,743,546,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1743546318...
Checkpoint 1743546318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.16661
Policy Entropy: 2.19571
Value Function Loss: 0.01533

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 21,894.24766
Overall Steps per Second: 10,622.58156

Timestep Collection Time: 2.28471
Timestep Consumption Time: 2.42432
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70902

Cumulative Model Updates: 209,066
Cumulative Timesteps: 1,743,596,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.34564
Policy Entropy: 2.22147
Value Function Loss: 0.01495

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.56706

Collected Steps per Second: 21,657.29501
Overall Steps per Second: 10,370.87643

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.82158

Cumulative Model Updates: 209,072
Cumulative Timesteps: 1,743,646,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1743646344...
Checkpoint 1743646344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.08659
Policy Entropy: 2.20588
Value Function Loss: 0.01562

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.52715
Value Function Update Magnitude: 0.55040

Collected Steps per Second: 22,038.20717
Overall Steps per Second: 10,351.21926

Timestep Collection Time: 2.26915
Timestep Consumption Time: 2.56197
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.83112

Cumulative Model Updates: 209,078
Cumulative Timesteps: 1,743,696,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.85347
Policy Entropy: 2.20900
Value Function Loss: 0.01612

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.53938
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 22,081.41999
Overall Steps per Second: 10,390.26120

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.54836
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 4.81316

Cumulative Model Updates: 209,084
Cumulative Timesteps: 1,743,746,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1743746362...
Checkpoint 1743746362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.97891
Policy Entropy: 2.19612
Value Function Loss: 0.01635

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.58825

Collected Steps per Second: 21,842.72305
Overall Steps per Second: 10,622.65744

Timestep Collection Time: 2.28955
Timestep Consumption Time: 2.41831
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.70786

Cumulative Model Updates: 209,090
Cumulative Timesteps: 1,743,796,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.75238
Policy Entropy: 2.21669
Value Function Loss: 0.01658

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 22,120.65870
Overall Steps per Second: 10,436.25843

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.53127
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79214

Cumulative Model Updates: 209,096
Cumulative Timesteps: 1,743,846,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1743846384...
Checkpoint 1743846384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.07942
Policy Entropy: 2.20323
Value Function Loss: 0.01687

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.53807
Value Function Update Magnitude: 0.57137

Collected Steps per Second: 21,805.49042
Overall Steps per Second: 10,287.38413

Timestep Collection Time: 2.29401
Timestep Consumption Time: 2.56845
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 4.86246

Cumulative Model Updates: 209,102
Cumulative Timesteps: 1,743,896,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.55666
Policy Entropy: 2.19766
Value Function Loss: 0.01799

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.58142

Collected Steps per Second: 22,070.43850
Overall Steps per Second: 10,414.43202

Timestep Collection Time: 2.26647
Timestep Consumption Time: 2.53667
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.80314

Cumulative Model Updates: 209,108
Cumulative Timesteps: 1,743,946,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1743946428...
Checkpoint 1743946428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.25726
Policy Entropy: 2.17726
Value Function Loss: 0.01676

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.56921

Collected Steps per Second: 22,093.92689
Overall Steps per Second: 10,515.10427

Timestep Collection Time: 2.26334
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.75564

Cumulative Model Updates: 209,114
Cumulative Timesteps: 1,743,996,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.17935
Policy Entropy: 2.18734
Value Function Loss: 0.01778

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.54555
Value Function Update Magnitude: 0.55739

Collected Steps per Second: 23,187.21107
Overall Steps per Second: 10,562.01236

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.57872
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.73603

Cumulative Model Updates: 209,120
Cumulative Timesteps: 1,744,046,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1744046456...
Checkpoint 1744046456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.71407
Policy Entropy: 2.20850
Value Function Loss: 0.01832

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.54344

Collected Steps per Second: 21,983.35575
Overall Steps per Second: 10,369.52997

Timestep Collection Time: 2.27454
Timestep Consumption Time: 2.54747
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.82201

Cumulative Model Updates: 209,126
Cumulative Timesteps: 1,744,096,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.91801
Policy Entropy: 2.21926
Value Function Loss: 0.01774

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 22,204.79068
Overall Steps per Second: 10,305.81510

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.59997
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.85182

Cumulative Model Updates: 209,132
Cumulative Timesteps: 1,744,146,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1744146460...
Checkpoint 1744146460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.41484
Policy Entropy: 2.22858
Value Function Loss: 0.01715

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.59249

Collected Steps per Second: 21,805.09678
Overall Steps per Second: 10,359.74188

Timestep Collection Time: 2.29442
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.82927

Cumulative Model Updates: 209,138
Cumulative Timesteps: 1,744,196,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.06193
Policy Entropy: 2.22874
Value Function Loss: 0.01709

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.53832
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 22,648.00040
Overall Steps per Second: 10,601.85066

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.50946
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.71804

Cumulative Model Updates: 209,144
Cumulative Timesteps: 1,744,246,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1744246510...
Checkpoint 1744246510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.71589
Policy Entropy: 2.24246
Value Function Loss: 0.01708

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.58375

Collected Steps per Second: 22,001.62040
Overall Steps per Second: 10,293.47095

Timestep Collection Time: 2.27301
Timestep Consumption Time: 2.58541
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 4.85842

Cumulative Model Updates: 209,150
Cumulative Timesteps: 1,744,296,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.89022
Policy Entropy: 2.24782
Value Function Loss: 0.01704

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 21,960.06629
Overall Steps per Second: 10,515.36005

Timestep Collection Time: 2.27814
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.75761

Cumulative Model Updates: 209,156
Cumulative Timesteps: 1,744,346,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1744346548...
Checkpoint 1744346548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.76628
Policy Entropy: 2.24609
Value Function Loss: 0.01598

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.58391

Collected Steps per Second: 21,650.98380
Overall Steps per Second: 10,297.27002

Timestep Collection Time: 2.31075
Timestep Consumption Time: 2.54782
PPO Batch Consumption Time: 0.30141
Total Iteration Time: 4.85857

Cumulative Model Updates: 209,162
Cumulative Timesteps: 1,744,396,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.46524
Policy Entropy: 2.22713
Value Function Loss: 0.01615

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.58921

Collected Steps per Second: 22,563.14126
Overall Steps per Second: 10,471.25134

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.55898
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.77498

Cumulative Model Updates: 209,168
Cumulative Timesteps: 1,744,446,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1744446578...
Checkpoint 1744446578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.86824
Policy Entropy: 2.24287
Value Function Loss: 0.01650

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 22,056.83564
Overall Steps per Second: 10,458.81234

Timestep Collection Time: 2.26814
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.78333

Cumulative Model Updates: 209,174
Cumulative Timesteps: 1,744,496,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.20968
Policy Entropy: 2.24493
Value Function Loss: 0.01732

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.54675
Value Function Update Magnitude: 0.57456

Collected Steps per Second: 22,112.13447
Overall Steps per Second: 10,542.15725

Timestep Collection Time: 2.26256
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.74571

Cumulative Model Updates: 209,180
Cumulative Timesteps: 1,744,546,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1744546636...
Checkpoint 1744546636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.86296
Policy Entropy: 2.24048
Value Function Loss: 0.01790

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.57010

Collected Steps per Second: 21,586.72529
Overall Steps per Second: 10,533.96355

Timestep Collection Time: 2.31735
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.74883

Cumulative Model Updates: 209,186
Cumulative Timesteps: 1,744,596,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.41325
Policy Entropy: 2.21450
Value Function Loss: 0.01695

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.54874
Value Function Update Magnitude: 0.58275

Collected Steps per Second: 22,211.13106
Overall Steps per Second: 10,494.84838

Timestep Collection Time: 2.25184
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.76577

Cumulative Model Updates: 209,192
Cumulative Timesteps: 1,744,646,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1744646676...
Checkpoint 1744646676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.62990
Policy Entropy: 2.19114
Value Function Loss: 0.01628

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 21,826.98934
Overall Steps per Second: 10,295.58076

Timestep Collection Time: 2.29184
Timestep Consumption Time: 2.56694
PPO Batch Consumption Time: 0.30348
Total Iteration Time: 4.85878

Cumulative Model Updates: 209,198
Cumulative Timesteps: 1,744,696,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.87936
Policy Entropy: 2.18781
Value Function Loss: 0.01694

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.59593

Collected Steps per Second: 21,982.30635
Overall Steps per Second: 10,385.13825

Timestep Collection Time: 2.27456
Timestep Consumption Time: 2.54002
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.81457

Cumulative Model Updates: 209,204
Cumulative Timesteps: 1,744,746,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1744746700...
Checkpoint 1744746700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.16358
Policy Entropy: 2.18202
Value Function Loss: 0.01758

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 21,066.12682
Overall Steps per Second: 10,258.78928

Timestep Collection Time: 2.37386
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.87465

Cumulative Model Updates: 209,210
Cumulative Timesteps: 1,744,796,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.88137
Policy Entropy: 2.17627
Value Function Loss: 0.01869

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.56713
Value Function Update Magnitude: 0.60541

Collected Steps per Second: 22,057.33230
Overall Steps per Second: 10,488.39472

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.76794

Cumulative Model Updates: 209,216
Cumulative Timesteps: 1,744,846,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1744846716...
Checkpoint 1744846716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.34263
Policy Entropy: 2.19536
Value Function Loss: 0.01792

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.59541

Collected Steps per Second: 21,993.02490
Overall Steps per Second: 10,446.30757

Timestep Collection Time: 2.27472
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.78906

Cumulative Model Updates: 209,222
Cumulative Timesteps: 1,744,896,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.40046
Policy Entropy: 2.19887
Value Function Loss: 0.01762

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.57875

Collected Steps per Second: 21,998.96138
Overall Steps per Second: 10,381.69548

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.54354
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.81655

Cumulative Model Updates: 209,228
Cumulative Timesteps: 1,744,946,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1744946748...
Checkpoint 1744946748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.61687
Policy Entropy: 2.24102
Value Function Loss: 0.01712

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.55483

Collected Steps per Second: 21,842.01519
Overall Steps per Second: 10,411.34038

Timestep Collection Time: 2.28962
Timestep Consumption Time: 2.51379
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.80342

Cumulative Model Updates: 209,234
Cumulative Timesteps: 1,744,996,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.01238
Policy Entropy: 2.23270
Value Function Loss: 0.01745

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.54871
Value Function Update Magnitude: 0.55082

Collected Steps per Second: 21,939.90239
Overall Steps per Second: 10,433.27986

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.30229
Total Iteration Time: 4.79332

Cumulative Model Updates: 209,240
Cumulative Timesteps: 1,745,046,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1745046768...
Checkpoint 1745046768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.10169
Policy Entropy: 2.22060
Value Function Loss: 0.01759

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.56537

Collected Steps per Second: 21,863.25806
Overall Steps per Second: 10,238.69531

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.59815
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.88656

Cumulative Model Updates: 209,246
Cumulative Timesteps: 1,745,096,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.03111
Policy Entropy: 2.19606
Value Function Loss: 0.01780

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.58871

Collected Steps per Second: 22,004.82297
Overall Steps per Second: 10,463.93493

Timestep Collection Time: 2.27341
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.78080

Cumulative Model Updates: 209,252
Cumulative Timesteps: 1,745,146,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1745146826...
Checkpoint 1745146826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.71055
Policy Entropy: 2.19643
Value Function Loss: 0.01721

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.60361

Collected Steps per Second: 21,588.91514
Overall Steps per Second: 10,323.98081

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.84329

Cumulative Model Updates: 209,258
Cumulative Timesteps: 1,745,196,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.00095
Policy Entropy: 2.22059
Value Function Loss: 0.01727

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.59792

Collected Steps per Second: 22,038.43396
Overall Steps per Second: 10,545.55904

Timestep Collection Time: 2.26940
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.74266

Cumulative Model Updates: 209,264
Cumulative Timesteps: 1,745,246,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1745246842...
Checkpoint 1745246842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.06267
Policy Entropy: 2.20169
Value Function Loss: 0.01717

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 21,849.97917
Overall Steps per Second: 10,448.93949

Timestep Collection Time: 2.28943
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.78747

Cumulative Model Updates: 209,270
Cumulative Timesteps: 1,745,296,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.06388
Policy Entropy: 2.19744
Value Function Loss: 0.01702

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.60444

Collected Steps per Second: 22,145.59683
Overall Steps per Second: 10,432.08409

Timestep Collection Time: 2.25806
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.79348

Cumulative Model Updates: 209,276
Cumulative Timesteps: 1,745,346,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1745346872...
Checkpoint 1745346872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.30464
Policy Entropy: 2.18563
Value Function Loss: 0.01712

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.54744
Value Function Update Magnitude: 0.59336

Collected Steps per Second: 21,760.79765
Overall Steps per Second: 10,371.17964

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.52465
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.82356

Cumulative Model Updates: 209,282
Cumulative Timesteps: 1,745,396,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.86878
Policy Entropy: 2.19499
Value Function Loss: 0.01700

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 21,936.95756
Overall Steps per Second: 10,599.49382

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71872

Cumulative Model Updates: 209,288
Cumulative Timesteps: 1,745,446,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1745446914...
Checkpoint 1745446914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.70036
Policy Entropy: 2.19002
Value Function Loss: 0.01718

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 22,349.74250
Overall Steps per Second: 10,443.68014

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.55073
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.78816

Cumulative Model Updates: 209,294
Cumulative Timesteps: 1,745,496,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.05157
Policy Entropy: 2.18789
Value Function Loss: 0.01764

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.58902

Collected Steps per Second: 22,030.50184
Overall Steps per Second: 10,355.46128

Timestep Collection Time: 2.27131
Timestep Consumption Time: 2.56073
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 4.83204

Cumulative Model Updates: 209,300
Cumulative Timesteps: 1,745,546,958

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1745546958...
Checkpoint 1745546958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.48271
Policy Entropy: 2.18414
Value Function Loss: 0.01710

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.60715

Collected Steps per Second: 20,772.99474
Overall Steps per Second: 10,128.17625

Timestep Collection Time: 2.40832
Timestep Consumption Time: 2.53117
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.93949

Cumulative Model Updates: 209,306
Cumulative Timesteps: 1,745,596,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.81831
Policy Entropy: 2.20202
Value Function Loss: 0.01574

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.59887

Collected Steps per Second: 21,722.95048
Overall Steps per Second: 10,515.95872

Timestep Collection Time: 2.30263
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.75658

Cumulative Model Updates: 209,312
Cumulative Timesteps: 1,745,647,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1745647006...
Checkpoint 1745647006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.96327
Policy Entropy: 2.21503
Value Function Loss: 0.01525

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.52919
Value Function Update Magnitude: 0.56056

Collected Steps per Second: 22,123.55515
Overall Steps per Second: 10,364.27049

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.56464
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 4.82504

Cumulative Model Updates: 209,318
Cumulative Timesteps: 1,745,697,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.15769
Policy Entropy: 2.21551
Value Function Loss: 0.01628

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.54839

Collected Steps per Second: 22,131.74215
Overall Steps per Second: 10,319.57438

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.58648
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.84613

Cumulative Model Updates: 209,324
Cumulative Timesteps: 1,745,747,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1745747024...
Checkpoint 1745747024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.57678
Policy Entropy: 2.22536
Value Function Loss: 0.01652

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 21,803.27751
Overall Steps per Second: 10,302.52684

Timestep Collection Time: 2.29415
Timestep Consumption Time: 2.56097
PPO Batch Consumption Time: 0.30246
Total Iteration Time: 4.85512

Cumulative Model Updates: 209,330
Cumulative Timesteps: 1,745,797,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.60852
Policy Entropy: 2.21640
Value Function Loss: 0.01657

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.58414

Collected Steps per Second: 21,882.15392
Overall Steps per Second: 10,366.97083

Timestep Collection Time: 2.28625
Timestep Consumption Time: 2.53946
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.82571

Cumulative Model Updates: 209,336
Cumulative Timesteps: 1,745,847,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1745847072...
Checkpoint 1745847072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.03116
Policy Entropy: 2.21216
Value Function Loss: 0.01541

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.58884

Collected Steps per Second: 22,021.05882
Overall Steps per Second: 10,648.38222

Timestep Collection Time: 2.27074
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.69592

Cumulative Model Updates: 209,342
Cumulative Timesteps: 1,745,897,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.32689
Policy Entropy: 2.17769
Value Function Loss: 0.01632

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.15356
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.59418

Collected Steps per Second: 22,021.98950
Overall Steps per Second: 10,458.89439

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.78272

Cumulative Model Updates: 209,348
Cumulative Timesteps: 1,745,947,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1745947098...
Checkpoint 1745947098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.42673
Policy Entropy: 2.16349
Value Function Loss: 0.01598

Mean KL Divergence: 0.03012
SB3 Clip Fraction: 0.18843
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.59395

Collected Steps per Second: 21,965.50420
Overall Steps per Second: 10,378.97903

Timestep Collection Time: 2.27702
Timestep Consumption Time: 2.54195
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.81897

Cumulative Model Updates: 209,354
Cumulative Timesteps: 1,745,997,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.80591
Policy Entropy: 2.18370
Value Function Loss: 0.01613

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 21,887.45760
Overall Steps per Second: 10,350.29564

Timestep Collection Time: 2.28533
Timestep Consumption Time: 2.54739
PPO Batch Consumption Time: 0.30211
Total Iteration Time: 4.83271

Cumulative Model Updates: 209,360
Cumulative Timesteps: 1,746,047,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1746047134...
Checkpoint 1746047134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.98391
Policy Entropy: 2.18988
Value Function Loss: 0.01549

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.56478

Collected Steps per Second: 22,135.80802
Overall Steps per Second: 10,578.49550

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.72733

Cumulative Model Updates: 209,366
Cumulative Timesteps: 1,746,097,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.46712
Policy Entropy: 2.22793
Value Function Loss: 0.01628

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 21,832.63460
Overall Steps per Second: 10,383.37667

Timestep Collection Time: 2.29125
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.81770

Cumulative Model Updates: 209,372
Cumulative Timesteps: 1,746,147,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1746147166...
Checkpoint 1746147166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.73083
Policy Entropy: 2.22674
Value Function Loss: 0.01699

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.55089
Value Function Update Magnitude: 0.59600

Collected Steps per Second: 21,756.31259
Overall Steps per Second: 10,272.60127

Timestep Collection Time: 2.29864
Timestep Consumption Time: 2.56965
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.86829

Cumulative Model Updates: 209,378
Cumulative Timesteps: 1,746,197,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.34079
Policy Entropy: 2.22418
Value Function Loss: 0.01767

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.61391

Collected Steps per Second: 22,013.95808
Overall Steps per Second: 10,406.50447

Timestep Collection Time: 2.27210
Timestep Consumption Time: 2.53431
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.80642

Cumulative Model Updates: 209,384
Cumulative Timesteps: 1,746,247,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1746247194...
Checkpoint 1746247194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.00858
Policy Entropy: 2.17626
Value Function Loss: 0.01686

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.57802
Value Function Update Magnitude: 0.63198

Collected Steps per Second: 21,911.73517
Overall Steps per Second: 10,384.66907

Timestep Collection Time: 2.28325
Timestep Consumption Time: 2.53443
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 4.81768

Cumulative Model Updates: 209,390
Cumulative Timesteps: 1,746,297,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.98133
Policy Entropy: 2.15375
Value Function Loss: 0.01715

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.57872
Value Function Update Magnitude: 0.60400

Collected Steps per Second: 21,942.59876
Overall Steps per Second: 10,500.14229

Timestep Collection Time: 2.27913
Timestep Consumption Time: 2.48366
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.76279

Cumulative Model Updates: 209,396
Cumulative Timesteps: 1,746,347,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1746347234...
Checkpoint 1746347234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.93374
Policy Entropy: 2.16592
Value Function Loss: 0.01666

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.59744

Collected Steps per Second: 22,071.92629
Overall Steps per Second: 10,519.68966

Timestep Collection Time: 2.26614
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.75470

Cumulative Model Updates: 209,402
Cumulative Timesteps: 1,746,397,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.67742
Policy Entropy: 2.17480
Value Function Loss: 0.01647

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 21,788.92055
Overall Steps per Second: 10,339.82192

Timestep Collection Time: 2.29603
Timestep Consumption Time: 2.54235
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.83838

Cumulative Model Updates: 209,408
Cumulative Timesteps: 1,746,447,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1746447280...
Checkpoint 1746447280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.27119
Policy Entropy: 2.18448
Value Function Loss: 0.01604

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.60144

Collected Steps per Second: 21,800.24225
Overall Steps per Second: 10,344.45030

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.54118
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.83583

Cumulative Model Updates: 209,414
Cumulative Timesteps: 1,746,497,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.99508
Policy Entropy: 2.18430
Value Function Loss: 0.01459

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.61368

Collected Steps per Second: 21,641.61775
Overall Steps per Second: 10,412.40516

Timestep Collection Time: 2.31083
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.80292

Cumulative Model Updates: 209,420
Cumulative Timesteps: 1,746,547,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1746547314...
Checkpoint 1746547314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.55026
Policy Entropy: 2.20634
Value Function Loss: 0.01490

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.59012

Collected Steps per Second: 22,030.41369
Overall Steps per Second: 10,478.44188

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.77170

Cumulative Model Updates: 209,426
Cumulative Timesteps: 1,746,597,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.35803
Policy Entropy: 2.19301
Value Function Loss: 0.01581

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 22,340.80757
Overall Steps per Second: 10,522.18028

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.75472

Cumulative Model Updates: 209,432
Cumulative Timesteps: 1,746,647,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1746647344...
Checkpoint 1746647344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.82536
Policy Entropy: 2.19941
Value Function Loss: 0.01674

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 21,931.00634
Overall Steps per Second: 10,420.32976

Timestep Collection Time: 2.28061
Timestep Consumption Time: 2.51924
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.79985

Cumulative Model Updates: 209,438
Cumulative Timesteps: 1,746,697,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.12342
Policy Entropy: 2.18079
Value Function Loss: 0.01683

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.64026

Collected Steps per Second: 21,876.36982
Overall Steps per Second: 10,604.64905

Timestep Collection Time: 2.28612
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71604

Cumulative Model Updates: 209,444
Cumulative Timesteps: 1,746,747,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1746747372...
Checkpoint 1746747372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.03320
Policy Entropy: 2.20471
Value Function Loss: 0.01673

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,095.63952
Overall Steps per Second: 10,305.90761

Timestep Collection Time: 2.26334
Timestep Consumption Time: 2.58921
PPO Batch Consumption Time: 0.30229
Total Iteration Time: 4.85256

Cumulative Model Updates: 209,450
Cumulative Timesteps: 1,746,797,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.31987
Policy Entropy: 2.20388
Value Function Loss: 0.01727

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.60458

Collected Steps per Second: 22,039.50956
Overall Steps per Second: 10,453.82108

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.51489
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.78409

Cumulative Model Updates: 209,456
Cumulative Timesteps: 1,746,847,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1746847394...
Checkpoint 1746847394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653.45938
Policy Entropy: 2.20858
Value Function Loss: 0.01751

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 21,902.94729
Overall Steps per Second: 10,440.28308

Timestep Collection Time: 2.28353
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.79067

Cumulative Model Updates: 209,462
Cumulative Timesteps: 1,746,897,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.72826
Policy Entropy: 2.21278
Value Function Loss: 0.01751

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.59343

Collected Steps per Second: 21,844.11038
Overall Steps per Second: 10,588.39970

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.43320
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.72215

Cumulative Model Updates: 209,468
Cumulative Timesteps: 1,746,947,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1746947410...
Checkpoint 1746947410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.73986
Policy Entropy: 2.18590
Value Function Loss: 0.01778

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 21,788.17935
Overall Steps per Second: 10,298.84254

Timestep Collection Time: 2.29491
Timestep Consumption Time: 2.56019
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.85511

Cumulative Model Updates: 209,474
Cumulative Timesteps: 1,746,997,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.33488
Policy Entropy: 2.18724
Value Function Loss: 0.01765

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.58306

Collected Steps per Second: 22,049.60001
Overall Steps per Second: 10,465.02269

Timestep Collection Time: 2.26898
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.78069

Cumulative Model Updates: 209,480
Cumulative Timesteps: 1,747,047,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1747047442...
Checkpoint 1747047442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.32131
Policy Entropy: 2.19462
Value Function Loss: 0.01749

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 21,968.44354
Overall Steps per Second: 10,337.98432

Timestep Collection Time: 2.27617
Timestep Consumption Time: 2.56075
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.83692

Cumulative Model Updates: 209,486
Cumulative Timesteps: 1,747,097,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.78177
Policy Entropy: 2.20702
Value Function Loss: 0.01641

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.62572

Collected Steps per Second: 21,811.09822
Overall Steps per Second: 10,495.26959

Timestep Collection Time: 2.29324
Timestep Consumption Time: 2.47253
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.76577

Cumulative Model Updates: 209,492
Cumulative Timesteps: 1,747,147,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1747147464...
Checkpoint 1747147464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.41478
Policy Entropy: 2.21986
Value Function Loss: 0.01619

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 21,923.29215
Overall Steps per Second: 10,443.63064

Timestep Collection Time: 2.28114
Timestep Consumption Time: 2.50743
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.78856

Cumulative Model Updates: 209,498
Cumulative Timesteps: 1,747,197,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.97096
Policy Entropy: 2.21875
Value Function Loss: 0.01589

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.57557

Collected Steps per Second: 21,766.14223
Overall Steps per Second: 10,150.25288

Timestep Collection Time: 2.29843
Timestep Consumption Time: 2.63031
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.92874

Cumulative Model Updates: 209,504
Cumulative Timesteps: 1,747,247,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1747247502...
Checkpoint 1747247502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.19901
Policy Entropy: 2.21916
Value Function Loss: 0.01637

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.55621

Collected Steps per Second: 21,446.95441
Overall Steps per Second: 10,211.76620

Timestep Collection Time: 2.33143
Timestep Consumption Time: 2.56508
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.89651

Cumulative Model Updates: 209,510
Cumulative Timesteps: 1,747,297,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.80168
Policy Entropy: 2.20429
Value Function Loss: 0.01698

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.55037

Collected Steps per Second: 21,999.46780
Overall Steps per Second: 10,350.10761

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.55942
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.83338

Cumulative Model Updates: 209,516
Cumulative Timesteps: 1,747,347,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1747347530...
Checkpoint 1747347530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.92966
Policy Entropy: 2.21694
Value Function Loss: 0.01737

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.56533

Collected Steps per Second: 21,678.03437
Overall Steps per Second: 10,549.59010

Timestep Collection Time: 2.30667
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.73990

Cumulative Model Updates: 209,522
Cumulative Timesteps: 1,747,397,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.90775
Policy Entropy: 2.22994
Value Function Loss: 0.01576

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.52629
Value Function Update Magnitude: 0.57484

Collected Steps per Second: 22,533.85519
Overall Steps per Second: 10,578.64131

Timestep Collection Time: 2.21933
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.72745

Cumulative Model Updates: 209,528
Cumulative Timesteps: 1,747,447,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1747447544...
Checkpoint 1747447544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.80174
Policy Entropy: 2.23782
Value Function Loss: 0.01543

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.52975
Value Function Update Magnitude: 0.57134

Collected Steps per Second: 21,029.54012
Overall Steps per Second: 10,202.26371

Timestep Collection Time: 2.37837
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.90244

Cumulative Model Updates: 209,534
Cumulative Timesteps: 1,747,497,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.30434
Policy Entropy: 2.19137
Value Function Loss: 0.01573

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 21,698.17154
Overall Steps per Second: 10,432.27109

Timestep Collection Time: 2.30480
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.30061
Total Iteration Time: 4.79378

Cumulative Model Updates: 209,540
Cumulative Timesteps: 1,747,547,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1747547570...
Checkpoint 1747547570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.32080
Policy Entropy: 2.18587
Value Function Loss: 0.01711

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.58622

Collected Steps per Second: 22,070.62414
Overall Steps per Second: 10,335.48888

Timestep Collection Time: 2.26627
Timestep Consumption Time: 2.57317
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.83944

Cumulative Model Updates: 209,546
Cumulative Timesteps: 1,747,597,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.58580
Policy Entropy: 2.18386
Value Function Loss: 0.01708

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.60453

Collected Steps per Second: 22,086.10889
Overall Steps per Second: 10,337.74892

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.57370
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.83838

Cumulative Model Updates: 209,552
Cumulative Timesteps: 1,747,647,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1747647606...
Checkpoint 1747647606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.65708
Policy Entropy: 2.20688
Value Function Loss: 0.01640

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.58459

Collected Steps per Second: 21,494.39331
Overall Steps per Second: 10,205.38501

Timestep Collection Time: 2.32656
Timestep Consumption Time: 2.57360
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.90016

Cumulative Model Updates: 209,558
Cumulative Timesteps: 1,747,697,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.75569
Policy Entropy: 2.20033
Value Function Loss: 0.01716

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.57819

Collected Steps per Second: 22,072.45334
Overall Steps per Second: 10,490.82198

Timestep Collection Time: 2.26617
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.30229
Total Iteration Time: 4.76798

Cumulative Model Updates: 209,564
Cumulative Timesteps: 1,747,747,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1747747634...
Checkpoint 1747747634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.98993
Policy Entropy: 2.21158
Value Function Loss: 0.01705

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.55077
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 20,867.09535
Overall Steps per Second: 10,223.27897

Timestep Collection Time: 2.39717
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 4.89295

Cumulative Model Updates: 209,570
Cumulative Timesteps: 1,747,797,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.44023
Policy Entropy: 2.22167
Value Function Loss: 0.01718

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 22,329.59484
Overall Steps per Second: 10,403.60066

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.56716
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.80661

Cumulative Model Updates: 209,576
Cumulative Timesteps: 1,747,847,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1747847662...
Checkpoint 1747847662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.15069
Policy Entropy: 2.22781
Value Function Loss: 0.01629

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.61889

Collected Steps per Second: 21,602.57210
Overall Steps per Second: 10,283.61834

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 4.86424

Cumulative Model Updates: 209,582
Cumulative Timesteps: 1,747,897,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.84528
Policy Entropy: 2.20809
Value Function Loss: 0.01684

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,010.70210
Overall Steps per Second: 10,403.88426

Timestep Collection Time: 2.27271
Timestep Consumption Time: 2.53549
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.80820

Cumulative Model Updates: 209,588
Cumulative Timesteps: 1,747,947,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1747947708...
Checkpoint 1747947708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.83090
Policy Entropy: 2.19870
Value Function Loss: 0.01654

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.65275

Collected Steps per Second: 21,684.54958
Overall Steps per Second: 10,554.79359

Timestep Collection Time: 2.30699
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.73965

Cumulative Model Updates: 209,594
Cumulative Timesteps: 1,747,997,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.61937
Policy Entropy: 2.16635
Value Function Loss: 0.01683

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.57457
Value Function Update Magnitude: 0.65363

Collected Steps per Second: 22,005.31893
Overall Steps per Second: 10,421.42128

Timestep Collection Time: 2.27309
Timestep Consumption Time: 2.52664
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.79973

Cumulative Model Updates: 209,600
Cumulative Timesteps: 1,748,047,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1748047754...
Checkpoint 1748047754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.89692
Policy Entropy: 2.20250
Value Function Loss: 0.01572

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.63712

Collected Steps per Second: 21,860.81618
Overall Steps per Second: 10,328.71323

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.55378
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.84107

Cumulative Model Updates: 209,606
Cumulative Timesteps: 1,748,097,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.30143
Policy Entropy: 2.20720
Value Function Loss: 0.01597

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 21,960.01085
Overall Steps per Second: 10,457.81952

Timestep Collection Time: 2.27832
Timestep Consumption Time: 2.50585
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.78417

Cumulative Model Updates: 209,612
Cumulative Timesteps: 1,748,147,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1748147788...
Checkpoint 1748147788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.49020
Policy Entropy: 2.22725
Value Function Loss: 0.01479

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 21,814.39513
Overall Steps per Second: 10,370.48865

Timestep Collection Time: 2.29243
Timestep Consumption Time: 2.52971
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.82215

Cumulative Model Updates: 209,618
Cumulative Timesteps: 1,748,197,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.31118
Policy Entropy: 2.20357
Value Function Loss: 0.01531

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.59502

Collected Steps per Second: 21,993.66617
Overall Steps per Second: 10,620.54152

Timestep Collection Time: 2.27420
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70955

Cumulative Model Updates: 209,624
Cumulative Timesteps: 1,748,247,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1748247814...
Checkpoint 1748247814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.29611
Policy Entropy: 2.19600
Value Function Loss: 0.01549

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.58688

Collected Steps per Second: 22,078.09203
Overall Steps per Second: 10,348.97107

Timestep Collection Time: 2.26650
Timestep Consumption Time: 2.56876
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.83526

Cumulative Model Updates: 209,630
Cumulative Timesteps: 1,748,297,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.85982
Policy Entropy: 2.19334
Value Function Loss: 0.01620

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.58448

Collected Steps per Second: 22,210.23600
Overall Steps per Second: 10,417.22275

Timestep Collection Time: 2.25184
Timestep Consumption Time: 2.54924
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.80109

Cumulative Model Updates: 209,636
Cumulative Timesteps: 1,748,347,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1748347868...
Checkpoint 1748347868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.34354
Policy Entropy: 2.18909
Value Function Loss: 0.01622

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.56617

Collected Steps per Second: 21,777.09928
Overall Steps per Second: 10,360.63957

Timestep Collection Time: 2.29599
Timestep Consumption Time: 2.52997
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.82596

Cumulative Model Updates: 209,642
Cumulative Timesteps: 1,748,397,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.95233
Policy Entropy: 2.17826
Value Function Loss: 0.01643

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 22,145.62647
Overall Steps per Second: 10,441.17416

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.78969

Cumulative Model Updates: 209,648
Cumulative Timesteps: 1,748,447,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1748447878...
Checkpoint 1748447878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.18294
Policy Entropy: 2.18484
Value Function Loss: 0.01629

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 22,568.05595
Overall Steps per Second: 10,496.14872

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.54854
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.76441

Cumulative Model Updates: 209,654
Cumulative Timesteps: 1,748,497,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.12604
Policy Entropy: 2.20589
Value Function Loss: 0.01654

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.59510

Collected Steps per Second: 21,808.72624
Overall Steps per Second: 10,370.92372

Timestep Collection Time: 2.29321
Timestep Consumption Time: 2.52912
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.82233

Cumulative Model Updates: 209,660
Cumulative Timesteps: 1,748,547,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1748547898...
Checkpoint 1748547898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.98086
Policy Entropy: 2.18837
Value Function Loss: 0.01643

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.55988
Value Function Update Magnitude: 0.58350

Collected Steps per Second: 21,823.15079
Overall Steps per Second: 10,301.49113

Timestep Collection Time: 2.29160
Timestep Consumption Time: 2.56303
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.85464

Cumulative Model Updates: 209,666
Cumulative Timesteps: 1,748,597,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.55574
Policy Entropy: 2.18729
Value Function Loss: 0.01679

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.56695

Collected Steps per Second: 20,591.56102
Overall Steps per Second: 9,960.41675

Timestep Collection Time: 2.42964
Timestep Consumption Time: 2.59325
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 5.02288

Cumulative Model Updates: 209,672
Cumulative Timesteps: 1,748,647,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1748647938...
Checkpoint 1748647938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.95064
Policy Entropy: 2.18486
Value Function Loss: 0.01750

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 22,134.99068
Overall Steps per Second: 10,311.86503

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.58992
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.84878

Cumulative Model Updates: 209,678
Cumulative Timesteps: 1,748,697,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.57538
Policy Entropy: 2.23715
Value Function Loss: 0.01779

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.56042
Value Function Update Magnitude: 0.58741

Collected Steps per Second: 22,016.27379
Overall Steps per Second: 10,416.21224

Timestep Collection Time: 2.27205
Timestep Consumption Time: 2.53027
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.80232

Cumulative Model Updates: 209,684
Cumulative Timesteps: 1,748,747,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1748747960...
Checkpoint 1748747960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.22265
Policy Entropy: 2.24671
Value Function Loss: 0.01751

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.16634
Policy Update Magnitude: 0.52155
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 20,742.83542
Overall Steps per Second: 9,928.28430

Timestep Collection Time: 2.41076
Timestep Consumption Time: 2.62596
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 5.03672

Cumulative Model Updates: 209,690
Cumulative Timesteps: 1,748,797,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.66413
Policy Entropy: 2.26455
Value Function Loss: 0.01678

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.49876
Value Function Update Magnitude: 0.61250

Collected Steps per Second: 20,870.23871
Overall Steps per Second: 10,338.73091

Timestep Collection Time: 2.39633
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.83734

Cumulative Model Updates: 209,696
Cumulative Timesteps: 1,748,847,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1748847978...
Checkpoint 1748847978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.79676
Policy Entropy: 2.23719
Value Function Loss: 0.01675

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 21,883.22414
Overall Steps per Second: 10,297.44197

Timestep Collection Time: 2.28595
Timestep Consumption Time: 2.57195
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.85791

Cumulative Model Updates: 209,702
Cumulative Timesteps: 1,748,898,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.70486
Policy Entropy: 2.20508
Value Function Loss: 0.01710

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.59993

Collected Steps per Second: 21,631.17335
Overall Steps per Second: 10,316.90675

Timestep Collection Time: 2.31185
Timestep Consumption Time: 2.53534
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.84719

Cumulative Model Updates: 209,708
Cumulative Timesteps: 1,748,948,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1748948010...
Checkpoint 1748948010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.63730
Policy Entropy: 2.19344
Value Function Loss: 0.01742

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.56403
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 20,210.39839
Overall Steps per Second: 9,875.22968

Timestep Collection Time: 2.47516
Timestep Consumption Time: 2.59044
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 5.06560

Cumulative Model Updates: 209,714
Cumulative Timesteps: 1,748,998,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.18035
Policy Entropy: 2.18487
Value Function Loss: 0.01773

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.56222
Value Function Update Magnitude: 0.64140

Collected Steps per Second: 21,555.70151
Overall Steps per Second: 10,371.07772

Timestep Collection Time: 2.32078
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.82361

Cumulative Model Updates: 209,720
Cumulative Timesteps: 1,749,048,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1749048060...
Checkpoint 1749048060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.88709
Policy Entropy: 2.21398
Value Function Loss: 0.01739

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 21,940.38096
Overall Steps per Second: 10,574.06403

Timestep Collection Time: 2.27890
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.72855

Cumulative Model Updates: 209,726
Cumulative Timesteps: 1,749,098,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.42754
Policy Entropy: 2.19218
Value Function Loss: 0.01679

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 22,027.52970
Overall Steps per Second: 10,307.85161

Timestep Collection Time: 2.27089
Timestep Consumption Time: 2.58192
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.85281

Cumulative Model Updates: 209,732
Cumulative Timesteps: 1,749,148,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1749148082...
Checkpoint 1749148082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.82141
Policy Entropy: 2.19144
Value Function Loss: 0.01683

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.56551
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 21,822.68789
Overall Steps per Second: 10,374.31451

Timestep Collection Time: 2.29202
Timestep Consumption Time: 2.52931
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.82133

Cumulative Model Updates: 209,738
Cumulative Timesteps: 1,749,198,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.45077
Policy Entropy: 2.18350
Value Function Loss: 0.01671

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.59025

Collected Steps per Second: 21,787.40937
Overall Steps per Second: 10,313.07645

Timestep Collection Time: 2.29509
Timestep Consumption Time: 2.55351
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.84860

Cumulative Model Updates: 209,744
Cumulative Timesteps: 1,749,248,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1749248104...
Checkpoint 1749248104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.29272
Policy Entropy: 2.21553
Value Function Loss: 0.01643

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 21,825.34920
Overall Steps per Second: 10,509.10703

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.75835

Cumulative Model Updates: 209,750
Cumulative Timesteps: 1,749,298,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.17283
Policy Entropy: 2.23368
Value Function Loss: 0.01494

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 21,883.66045
Overall Steps per Second: 10,371.19198

Timestep Collection Time: 2.28499
Timestep Consumption Time: 2.53644
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.82143

Cumulative Model Updates: 209,756
Cumulative Timesteps: 1,749,348,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1749348114...
Checkpoint 1749348114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.90425
Policy Entropy: 2.21096
Value Function Loss: 0.01523

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.53941
Value Function Update Magnitude: 0.59351

Collected Steps per Second: 21,301.37222
Overall Steps per Second: 10,279.42589

Timestep Collection Time: 2.34849
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.86661

Cumulative Model Updates: 209,762
Cumulative Timesteps: 1,749,398,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.55057
Policy Entropy: 2.18199
Value Function Loss: 0.01513

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.57087

Collected Steps per Second: 21,695.07736
Overall Steps per Second: 10,419.61623

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.79979

Cumulative Model Updates: 209,768
Cumulative Timesteps: 1,749,448,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1749448152...
Checkpoint 1749448152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.48056
Policy Entropy: 2.17207
Value Function Loss: 0.01641

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.57140

Collected Steps per Second: 21,797.87302
Overall Steps per Second: 10,279.57099

Timestep Collection Time: 2.29454
Timestep Consumption Time: 2.57104
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 4.86557

Cumulative Model Updates: 209,774
Cumulative Timesteps: 1,749,498,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.27436
Policy Entropy: 2.17434
Value Function Loss: 0.01639

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.56803

Collected Steps per Second: 22,712.36933
Overall Steps per Second: 10,449.69216

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.58411
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.78617

Cumulative Model Updates: 209,780
Cumulative Timesteps: 1,749,548,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1749548182...
Checkpoint 1749548182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.49309
Policy Entropy: 2.17907
Value Function Loss: 0.01634

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.57007

Collected Steps per Second: 21,839.94340
Overall Steps per Second: 10,271.71223

Timestep Collection Time: 2.29021
Timestep Consumption Time: 2.57928
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.86949

Cumulative Model Updates: 209,786
Cumulative Timesteps: 1,749,598,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.90134
Policy Entropy: 2.15881
Value Function Loss: 0.01687

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.55212
Value Function Update Magnitude: 0.59018

Collected Steps per Second: 21,987.92067
Overall Steps per Second: 10,378.61006

Timestep Collection Time: 2.27425
Timestep Consumption Time: 2.54393
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.81818

Cumulative Model Updates: 209,792
Cumulative Timesteps: 1,749,648,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1749648206...
Checkpoint 1749648206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.17082
Policy Entropy: 2.16915
Value Function Loss: 0.01754

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.58956

Collected Steps per Second: 21,646.81265
Overall Steps per Second: 10,287.35025

Timestep Collection Time: 2.31073
Timestep Consumption Time: 2.55155
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 4.86228

Cumulative Model Updates: 209,798
Cumulative Timesteps: 1,749,698,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.65417
Policy Entropy: 2.17863
Value Function Loss: 0.01757

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 22,864.59542
Overall Steps per Second: 10,514.69305

Timestep Collection Time: 2.18801
Timestep Consumption Time: 2.56990
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.75791

Cumulative Model Updates: 209,804
Cumulative Timesteps: 1,749,748,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1749748254...
Checkpoint 1749748254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.84334
Policy Entropy: 2.20277
Value Function Loss: 0.01656

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.53675
Value Function Update Magnitude: 0.55795

Collected Steps per Second: 21,323.21091
Overall Steps per Second: 10,148.95856

Timestep Collection Time: 2.34505
Timestep Consumption Time: 2.58196
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.92701

Cumulative Model Updates: 209,810
Cumulative Timesteps: 1,749,798,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.85485
Policy Entropy: 2.17353
Value Function Loss: 0.01613

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.16572
Policy Update Magnitude: 0.49644
Value Function Update Magnitude: 0.54463

Collected Steps per Second: 21,903.65282
Overall Steps per Second: 10,386.06482

Timestep Collection Time: 2.28400
Timestep Consumption Time: 2.53284
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.81684

Cumulative Model Updates: 209,816
Cumulative Timesteps: 1,749,848,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1749848286...
Checkpoint 1749848286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.79506
Policy Entropy: 2.15547
Value Function Loss: 0.01699

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.51476
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 21,552.83000
Overall Steps per Second: 10,509.49474

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.43899
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76008

Cumulative Model Updates: 209,822
Cumulative Timesteps: 1,749,898,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.05846
Policy Entropy: 2.13470
Value Function Loss: 0.01796

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 22,589.44614
Overall Steps per Second: 10,575.01300

Timestep Collection Time: 2.21387
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.72907

Cumulative Model Updates: 209,828
Cumulative Timesteps: 1,749,948,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1749948322...
Checkpoint 1749948322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.00891
Policy Entropy: 2.13078
Value Function Loss: 0.01882

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14742
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.59788

Collected Steps per Second: 21,507.88196
Overall Steps per Second: 10,229.95929

Timestep Collection Time: 2.32510
Timestep Consumption Time: 2.56329
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.88839

Cumulative Model Updates: 209,834
Cumulative Timesteps: 1,749,998,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.16126
Policy Entropy: 2.12607
Value Function Loss: 0.01742

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 21,961.24132
Overall Steps per Second: 10,394.62957

Timestep Collection Time: 2.27774
Timestep Consumption Time: 2.53455
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.81229

Cumulative Model Updates: 209,840
Cumulative Timesteps: 1,750,048,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1750048352...
Checkpoint 1750048352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.81304
Policy Entropy: 2.12549
Value Function Loss: 0.01730

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 21,484.80711
Overall Steps per Second: 10,419.52036

Timestep Collection Time: 2.32825
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.80080

Cumulative Model Updates: 209,846
Cumulative Timesteps: 1,750,098,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.26028
Policy Entropy: 2.14389
Value Function Loss: 0.01725

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.59697

Collected Steps per Second: 22,125.02337
Overall Steps per Second: 10,304.08805

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.59297
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.85322

Cumulative Model Updates: 209,852
Cumulative Timesteps: 1,750,148,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1750148382...
Checkpoint 1750148382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.83633
Policy Entropy: 2.14872
Value Function Loss: 0.01771

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.59147

Collected Steps per Second: 21,541.47099
Overall Steps per Second: 10,190.91487

Timestep Collection Time: 2.32120
Timestep Consumption Time: 2.58533
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.90653

Cumulative Model Updates: 209,858
Cumulative Timesteps: 1,750,198,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.46750
Policy Entropy: 2.18115
Value Function Loss: 0.01663

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.59815

Collected Steps per Second: 22,062.69083
Overall Steps per Second: 10,421.81006

Timestep Collection Time: 2.26636
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.79782

Cumulative Model Updates: 209,864
Cumulative Timesteps: 1,750,248,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1750248386...
Checkpoint 1750248386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.71317
Policy Entropy: 2.18552
Value Function Loss: 0.01733

Mean KL Divergence: 0.02878
SB3 Clip Fraction: 0.18476
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.57735

Collected Steps per Second: 21,536.92494
Overall Steps per Second: 10,250.36447

Timestep Collection Time: 2.32262
Timestep Consumption Time: 2.55741
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 4.88002

Cumulative Model Updates: 209,870
Cumulative Timesteps: 1,750,298,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.95588
Policy Entropy: 2.18752
Value Function Loss: 0.01740

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.16559
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.58404

Collected Steps per Second: 21,122.48533
Overall Steps per Second: 10,389.95758

Timestep Collection Time: 2.36838
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.81484

Cumulative Model Updates: 209,876
Cumulative Timesteps: 1,750,348,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1750348434...
Checkpoint 1750348434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.26996
Policy Entropy: 2.18300
Value Function Loss: 0.01722

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.59207

Collected Steps per Second: 21,255.18812
Overall Steps per Second: 10,222.70245

Timestep Collection Time: 2.35331
Timestep Consumption Time: 2.53972
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.89303

Cumulative Model Updates: 209,882
Cumulative Timesteps: 1,750,398,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.89676
Policy Entropy: 2.19645
Value Function Loss: 0.01649

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.57854

Collected Steps per Second: 22,159.46931
Overall Steps per Second: 10,448.81254

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.52937
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.78619

Cumulative Model Updates: 209,888
Cumulative Timesteps: 1,750,448,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1750448464...
Checkpoint 1750448464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.50310
Policy Entropy: 2.18064
Value Function Loss: 0.01611

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.57761

Collected Steps per Second: 21,377.32791
Overall Steps per Second: 10,278.85097

Timestep Collection Time: 2.34014
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.86689

Cumulative Model Updates: 209,894
Cumulative Timesteps: 1,750,498,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.98042
Policy Entropy: 2.17475
Value Function Loss: 0.01590

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.56846

Collected Steps per Second: 20,451.53889
Overall Steps per Second: 10,016.27384

Timestep Collection Time: 2.44480
Timestep Consumption Time: 2.54707
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.99188

Cumulative Model Updates: 209,900
Cumulative Timesteps: 1,750,548,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1750548490...
Checkpoint 1750548490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.36782
Policy Entropy: 2.17900
Value Function Loss: 0.01610

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.53401
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 20,895.22393
Overall Steps per Second: 10,133.03268

Timestep Collection Time: 2.39337
Timestep Consumption Time: 2.54197
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.93534

Cumulative Model Updates: 209,906
Cumulative Timesteps: 1,750,598,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.21432
Policy Entropy: 2.18897
Value Function Loss: 0.01610

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.18071
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.59333

Collected Steps per Second: 21,401.93406
Overall Steps per Second: 10,148.48401

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.59195
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.92941

Cumulative Model Updates: 209,912
Cumulative Timesteps: 1,750,648,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1750648526...
Checkpoint 1750648526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.76791
Policy Entropy: 2.19031
Value Function Loss: 0.01692

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 21,486.33247
Overall Steps per Second: 10,209.36340

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.57102
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.89864

Cumulative Model Updates: 209,918
Cumulative Timesteps: 1,750,698,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.35840
Policy Entropy: 2.16523
Value Function Loss: 0.01724

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.58182

Collected Steps per Second: 21,858.82736
Overall Steps per Second: 10,388.61471

Timestep Collection Time: 2.28768
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.81354

Cumulative Model Updates: 209,924
Cumulative Timesteps: 1,750,748,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1750748544...
Checkpoint 1750748544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.03854
Policy Entropy: 2.17715
Value Function Loss: 0.01690

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 22,387.68948
Overall Steps per Second: 10,413.62558

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.56813
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.80159

Cumulative Model Updates: 209,930
Cumulative Timesteps: 1,750,798,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.86819
Policy Entropy: 2.16684
Value Function Loss: 0.01696

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 22,004.24893
Overall Steps per Second: 10,327.37306

Timestep Collection Time: 2.27356
Timestep Consumption Time: 2.57065
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.84421

Cumulative Model Updates: 209,936
Cumulative Timesteps: 1,750,848,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1750848574...
Checkpoint 1750848574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.99429
Policy Entropy: 2.17000
Value Function Loss: 0.01574

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 21,596.13611
Overall Steps per Second: 10,174.74910

Timestep Collection Time: 2.31653
Timestep Consumption Time: 2.60035
PPO Batch Consumption Time: 0.30377
Total Iteration Time: 4.91688

Cumulative Model Updates: 209,942
Cumulative Timesteps: 1,750,898,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.39478
Policy Entropy: 2.14838
Value Function Loss: 0.01639

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.56722

Collected Steps per Second: 21,628.68353
Overall Steps per Second: 10,393.07166

Timestep Collection Time: 2.31313
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.81378

Cumulative Model Updates: 209,948
Cumulative Timesteps: 1,750,948,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1750948632...
Checkpoint 1750948632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.20243
Policy Entropy: 2.13980
Value Function Loss: 0.01696

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.57335

Collected Steps per Second: 21,971.14049
Overall Steps per Second: 10,631.24873

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.42828
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70481

Cumulative Model Updates: 209,954
Cumulative Timesteps: 1,750,998,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.27741
Policy Entropy: 2.13291
Value Function Loss: 0.01800

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.60860

Collected Steps per Second: 22,381.86599
Overall Steps per Second: 10,508.53344

Timestep Collection Time: 2.23493
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.76013

Cumulative Model Updates: 209,960
Cumulative Timesteps: 1,751,048,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1751048672...
Checkpoint 1751048672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.51390
Policy Entropy: 2.12810
Value Function Loss: 0.01810

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.57878
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 21,973.10233
Overall Steps per Second: 10,320.11531

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.56960
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.84529

Cumulative Model Updates: 209,966
Cumulative Timesteps: 1,751,098,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.12959
Policy Entropy: 2.14970
Value Function Loss: 0.01759

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.57898
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 21,747.24769
Overall Steps per Second: 10,436.35347

Timestep Collection Time: 2.30052
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.79382

Cumulative Model Updates: 209,972
Cumulative Timesteps: 1,751,148,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1751148706...
Checkpoint 1751148706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.72307
Policy Entropy: 2.16154
Value Function Loss: 0.01738

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.56685
Value Function Update Magnitude: 0.64004

Collected Steps per Second: 21,814.06227
Overall Steps per Second: 10,561.59438

Timestep Collection Time: 2.29292
Timestep Consumption Time: 2.44291
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.73584

Cumulative Model Updates: 209,978
Cumulative Timesteps: 1,751,198,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.23136
Policy Entropy: 2.17059
Value Function Loss: 0.01659

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 21,987.88253
Overall Steps per Second: 10,435.80927

Timestep Collection Time: 2.27480
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79292

Cumulative Model Updates: 209,984
Cumulative Timesteps: 1,751,248,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1751248742...
Checkpoint 1751248742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.81390
Policy Entropy: 2.16607
Value Function Loss: 0.01652

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.58020

Collected Steps per Second: 21,998.11859
Overall Steps per Second: 10,328.26816

Timestep Collection Time: 2.27319
Timestep Consumption Time: 2.56847
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.84166

Cumulative Model Updates: 209,990
Cumulative Timesteps: 1,751,298,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.87328
Policy Entropy: 2.15589
Value Function Loss: 0.01716

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.55821
Value Function Update Magnitude: 0.56184

Collected Steps per Second: 21,333.30011
Overall Steps per Second: 10,278.33960

Timestep Collection Time: 2.34403
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.86518

Cumulative Model Updates: 209,996
Cumulative Timesteps: 1,751,348,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1751348754...
Checkpoint 1751348754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.14282
Policy Entropy: 2.16084
Value Function Loss: 0.01685

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.57592

Collected Steps per Second: 22,054.56481
Overall Steps per Second: 10,660.88492

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.69192

Cumulative Model Updates: 210,002
Cumulative Timesteps: 1,751,398,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.48058
Policy Entropy: 2.15184
Value Function Loss: 0.01731

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.57962

Collected Steps per Second: 21,931.13585
Overall Steps per Second: 10,358.48499

Timestep Collection Time: 2.28114
Timestep Consumption Time: 2.54852
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.82966

Cumulative Model Updates: 210,008
Cumulative Timesteps: 1,751,448,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1751448802...
Checkpoint 1751448802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.50730
Policy Entropy: 2.14339
Value Function Loss: 0.01634

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 21,875.53491
Overall Steps per Second: 10,465.68095

Timestep Collection Time: 2.28602
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.77828

Cumulative Model Updates: 210,014
Cumulative Timesteps: 1,751,498,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.81200
Policy Entropy: 2.14298
Value Function Loss: 0.01572

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.53380

Collected Steps per Second: 22,000.98627
Overall Steps per Second: 10,420.53346

Timestep Collection Time: 2.27281
Timestep Consumption Time: 2.52580
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79860

Cumulative Model Updates: 210,020
Cumulative Timesteps: 1,751,548,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1751548814...
Checkpoint 1751548814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.80972
Policy Entropy: 2.11822
Value Function Loss: 0.01571

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.52669

Collected Steps per Second: 21,944.23944
Overall Steps per Second: 10,436.61603

Timestep Collection Time: 2.27987
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.79370

Cumulative Model Updates: 210,026
Cumulative Timesteps: 1,751,598,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.98353
Policy Entropy: 2.14216
Value Function Loss: 0.01624

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.53814

Collected Steps per Second: 22,558.92362
Overall Steps per Second: 10,568.81378

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.73355

Cumulative Model Updates: 210,032
Cumulative Timesteps: 1,751,648,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1751648872...
Checkpoint 1751648872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.55412
Policy Entropy: 2.13730
Value Function Loss: 0.01603

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.57298

Collected Steps per Second: 22,330.62033
Overall Steps per Second: 10,467.40609

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.53867
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.77864

Cumulative Model Updates: 210,038
Cumulative Timesteps: 1,751,698,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.86623
Policy Entropy: 2.15613
Value Function Loss: 0.01650

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.57706

Collected Steps per Second: 21,661.68416
Overall Steps per Second: 10,297.80036

Timestep Collection Time: 2.30915
Timestep Consumption Time: 2.54820
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.85735

Cumulative Model Updates: 210,044
Cumulative Timesteps: 1,751,748,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1751748912...
Checkpoint 1751748912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.49814
Policy Entropy: 2.16327
Value Function Loss: 0.01672

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.55742

Collected Steps per Second: 21,790.32703
Overall Steps per Second: 10,577.05479

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.72986

Cumulative Model Updates: 210,050
Cumulative Timesteps: 1,751,798,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.69611
Policy Entropy: 2.15597
Value Function Loss: 0.01681

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.54314

Collected Steps per Second: 22,007.04264
Overall Steps per Second: 10,431.37465

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.79572

Cumulative Model Updates: 210,056
Cumulative Timesteps: 1,751,848,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1751848966...
Checkpoint 1751848966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.42192
Policy Entropy: 2.15916
Value Function Loss: 0.01764

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.55010

Collected Steps per Second: 21,939.27278
Overall Steps per Second: 10,284.43517

Timestep Collection Time: 2.28020
Timestep Consumption Time: 2.58404
PPO Batch Consumption Time: 0.30414
Total Iteration Time: 4.86424

Cumulative Model Updates: 210,062
Cumulative Timesteps: 1,751,898,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.31279
Policy Entropy: 2.15173
Value Function Loss: 0.01737

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.55981
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 21,832.33110
Overall Steps per Second: 10,474.95556

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.77424

Cumulative Model Updates: 210,068
Cumulative Timesteps: 1,751,949,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1751949002...
Checkpoint 1751949002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.21554
Policy Entropy: 2.18606
Value Function Loss: 0.01710

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.57987

Collected Steps per Second: 21,764.81938
Overall Steps per Second: 10,541.72034

Timestep Collection Time: 2.29747
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74344

Cumulative Model Updates: 210,074
Cumulative Timesteps: 1,751,999,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.44742
Policy Entropy: 2.18835
Value Function Loss: 0.01699

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.55817
Value Function Update Magnitude: 0.57704

Collected Steps per Second: 21,927.95086
Overall Steps per Second: 10,417.19621

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.80168

Cumulative Model Updates: 210,080
Cumulative Timesteps: 1,752,049,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1752049026...
Checkpoint 1752049026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.89706
Policy Entropy: 2.18530
Value Function Loss: 0.01712

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.58445

Collected Steps per Second: 22,221.12706
Overall Steps per Second: 10,346.04525

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.58286
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.83315

Cumulative Model Updates: 210,086
Cumulative Timesteps: 1,752,099,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.10864
Policy Entropy: 2.14973
Value Function Loss: 0.01771

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.56270
Value Function Update Magnitude: 0.58229

Collected Steps per Second: 21,935.76578
Overall Steps per Second: 10,376.26390

Timestep Collection Time: 2.28075
Timestep Consumption Time: 2.54083
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.82158

Cumulative Model Updates: 210,092
Cumulative Timesteps: 1,752,149,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1752149060...
Checkpoint 1752149060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.56609
Policy Entropy: 2.15297
Value Function Loss: 0.01724

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.56592

Collected Steps per Second: 21,828.82380
Overall Steps per Second: 10,360.18132

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.53593
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.82675

Cumulative Model Updates: 210,098
Cumulative Timesteps: 1,752,199,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.84488
Policy Entropy: 2.15606
Value Function Loss: 0.01768

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.57063

Collected Steps per Second: 21,925.11489
Overall Steps per Second: 10,492.01869

Timestep Collection Time: 2.28067
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.76591

Cumulative Model Updates: 210,104
Cumulative Timesteps: 1,752,249,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1752249070...
Checkpoint 1752249070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.39605
Policy Entropy: 2.16378
Value Function Loss: 0.01704

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.56788

Collected Steps per Second: 22,164.35572
Overall Steps per Second: 10,525.43274

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.75268

Cumulative Model Updates: 210,110
Cumulative Timesteps: 1,752,299,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.59964
Policy Entropy: 2.13549
Value Function Loss: 0.01779

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.57623

Collected Steps per Second: 21,834.12786
Overall Steps per Second: 10,387.75532

Timestep Collection Time: 2.29045
Timestep Consumption Time: 2.52387
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.81432

Cumulative Model Updates: 210,116
Cumulative Timesteps: 1,752,349,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1752349104...
Checkpoint 1752349104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.96981
Policy Entropy: 2.13424
Value Function Loss: 0.01807

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.58498

Collected Steps per Second: 21,827.97012
Overall Steps per Second: 10,259.45491

Timestep Collection Time: 2.29201
Timestep Consumption Time: 2.58446
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 4.87648

Cumulative Model Updates: 210,122
Cumulative Timesteps: 1,752,399,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.47888
Policy Entropy: 2.12608
Value Function Loss: 0.01752

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 21,911.29696
Overall Steps per Second: 10,448.04303

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.50456
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.78731

Cumulative Model Updates: 210,128
Cumulative Timesteps: 1,752,449,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1752449152...
Checkpoint 1752449152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.37053
Policy Entropy: 2.14684
Value Function Loss: 0.01792

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 21,887.59977
Overall Steps per Second: 10,594.84253

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.72003

Cumulative Model Updates: 210,134
Cumulative Timesteps: 1,752,499,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.40563
Policy Entropy: 2.12149
Value Function Loss: 0.01762

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.60433

Collected Steps per Second: 22,026.72183
Overall Steps per Second: 10,435.54066

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.52155
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.79170

Cumulative Model Updates: 210,140
Cumulative Timesteps: 1,752,549,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1752549164...
Checkpoint 1752549164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.32516
Policy Entropy: 2.11075
Value Function Loss: 0.01754

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.18280
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.61172

Collected Steps per Second: 21,517.82500
Overall Steps per Second: 10,282.08484

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.53978
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.86399

Cumulative Model Updates: 210,146
Cumulative Timesteps: 1,752,599,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.88089
Policy Entropy: 2.09189
Value Function Loss: 0.01786

Mean KL Divergence: 0.03257
SB3 Clip Fraction: 0.19214
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.58787

Collected Steps per Second: 21,920.52545
Overall Steps per Second: 10,484.25326

Timestep Collection Time: 2.28234
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.77192

Cumulative Model Updates: 210,152
Cumulative Timesteps: 1,752,649,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1752649206...
Checkpoint 1752649206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.15219
Policy Entropy: 2.08643
Value Function Loss: 0.01815

Mean KL Divergence: 0.03026
SB3 Clip Fraction: 0.19006
Policy Update Magnitude: 0.57684
Value Function Update Magnitude: 0.59056

Collected Steps per Second: 21,773.92857
Overall Steps per Second: 10,563.83648

Timestep Collection Time: 2.29660
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.73370

Cumulative Model Updates: 210,158
Cumulative Timesteps: 1,752,699,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.30587
Policy Entropy: 2.11533
Value Function Loss: 0.01770

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.17475
Policy Update Magnitude: 0.59364
Value Function Update Magnitude: 0.59411

Collected Steps per Second: 22,096.31340
Overall Steps per Second: 10,456.93944

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.78285

Cumulative Model Updates: 210,164
Cumulative Timesteps: 1,752,749,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1752749226...
Checkpoint 1752749226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.96761
Policy Entropy: 2.14181
Value Function Loss: 0.01738

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.59003

Collected Steps per Second: 21,678.13222
Overall Steps per Second: 10,239.68641

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.57742
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.88472

Cumulative Model Updates: 210,170
Cumulative Timesteps: 1,752,799,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.33211
Policy Entropy: 2.16312
Value Function Loss: 0.01695

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.56809
Value Function Update Magnitude: 0.58545

Collected Steps per Second: 21,997.53560
Overall Steps per Second: 10,430.30851

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.79583

Cumulative Model Updates: 210,176
Cumulative Timesteps: 1,752,849,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1752849266...
Checkpoint 1752849266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.71989
Policy Entropy: 2.15144
Value Function Loss: 0.01674

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.58016

Collected Steps per Second: 21,724.19350
Overall Steps per Second: 10,272.72327

Timestep Collection Time: 2.30287
Timestep Consumption Time: 2.56711
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 4.86998

Cumulative Model Updates: 210,182
Cumulative Timesteps: 1,752,899,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.81413
Policy Entropy: 2.10575
Value Function Loss: 0.01641

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.56337

Collected Steps per Second: 21,825.06641
Overall Steps per Second: 10,439.73468

Timestep Collection Time: 2.29149
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.79054

Cumulative Model Updates: 210,188
Cumulative Timesteps: 1,752,949,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1752949306...
Checkpoint 1752949306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.13698
Policy Entropy: 2.10051
Value Function Loss: 0.01674

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.54186

Collected Steps per Second: 21,842.84245
Overall Steps per Second: 10,298.58951

Timestep Collection Time: 2.28999
Timestep Consumption Time: 2.56698
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.85698

Cumulative Model Updates: 210,194
Cumulative Timesteps: 1,752,999,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.65184
Policy Entropy: 2.13682
Value Function Loss: 0.01740

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.56171
Value Function Update Magnitude: 0.54770

Collected Steps per Second: 21,983.80364
Overall Steps per Second: 10,395.68557

Timestep Collection Time: 2.27586
Timestep Consumption Time: 2.53691
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.81277

Cumulative Model Updates: 210,200
Cumulative Timesteps: 1,753,049,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1753049358...
Checkpoint 1753049358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.24051
Policy Entropy: 2.15813
Value Function Loss: 0.01726

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 21,680.59559
Overall Steps per Second: 10,344.73400

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.83415

Cumulative Model Updates: 210,206
Cumulative Timesteps: 1,753,099,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.26489
Policy Entropy: 2.14719
Value Function Loss: 0.01673

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 22,252.15280
Overall Steps per Second: 10,657.88686

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.69587

Cumulative Model Updates: 210,212
Cumulative Timesteps: 1,753,149,414

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1753149414...
Checkpoint 1753149414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.90136
Policy Entropy: 2.12474
Value Function Loss: 0.01594

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.52814

Collected Steps per Second: 21,775.43121
Overall Steps per Second: 10,287.17905

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.56518
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.86217

Cumulative Model Updates: 210,218
Cumulative Timesteps: 1,753,199,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.43484
Policy Entropy: 2.15188
Value Function Loss: 0.01587

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.53938

Collected Steps per Second: 22,104.87752
Overall Steps per Second: 10,461.94021

Timestep Collection Time: 2.26203
Timestep Consumption Time: 2.51738
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.77942

Cumulative Model Updates: 210,224
Cumulative Timesteps: 1,753,249,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1753249434...
Checkpoint 1753249434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.21371
Policy Entropy: 2.15439
Value Function Loss: 0.01707

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.54696

Collected Steps per Second: 21,573.55626
Overall Steps per Second: 10,219.41974

Timestep Collection Time: 2.31774
Timestep Consumption Time: 2.57510
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.89284

Cumulative Model Updates: 210,230
Cumulative Timesteps: 1,753,299,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.56799
Policy Entropy: 2.17107
Value Function Loss: 0.01686

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.54888

Collected Steps per Second: 22,207.20127
Overall Steps per Second: 10,420.69535

Timestep Collection Time: 2.25152
Timestep Consumption Time: 2.54662
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.79814

Cumulative Model Updates: 210,236
Cumulative Timesteps: 1,753,349,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1753349436...
Checkpoint 1753349436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.06762
Policy Entropy: 2.14698
Value Function Loss: 0.01684

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.55640

Collected Steps per Second: 21,747.05265
Overall Steps per Second: 10,546.86619

Timestep Collection Time: 2.30008
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.74264

Cumulative Model Updates: 210,242
Cumulative Timesteps: 1,753,399,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.41949
Policy Entropy: 2.16433
Value Function Loss: 0.01621

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.55150

Collected Steps per Second: 21,766.12181
Overall Steps per Second: 10,275.96900

Timestep Collection Time: 2.29880
Timestep Consumption Time: 2.57042
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 4.86922

Cumulative Model Updates: 210,248
Cumulative Timesteps: 1,753,449,492

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1753449492...
Checkpoint 1753449492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.75674
Policy Entropy: 2.15112
Value Function Loss: 0.01618

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 21,454.23098
Overall Steps per Second: 10,237.08161

Timestep Collection Time: 2.33082
Timestep Consumption Time: 2.55397
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.88479

Cumulative Model Updates: 210,254
Cumulative Timesteps: 1,753,499,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.02948
Policy Entropy: 2.15095
Value Function Loss: 0.01644

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.54474
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 22,024.01005
Overall Steps per Second: 10,368.41065

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.55311
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.82427

Cumulative Model Updates: 210,260
Cumulative Timesteps: 1,753,549,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1753549518...
Checkpoint 1753549518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.65773
Policy Entropy: 2.12799
Value Function Loss: 0.01644

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.54561

Collected Steps per Second: 21,758.69924
Overall Steps per Second: 10,570.46943

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.73035

Cumulative Model Updates: 210,266
Cumulative Timesteps: 1,753,599,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.70691
Policy Entropy: 2.11230
Value Function Loss: 0.01813

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.54209

Collected Steps per Second: 22,323.04808
Overall Steps per Second: 10,451.18786

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.54573
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.78682

Cumulative Model Updates: 210,272
Cumulative Timesteps: 1,753,649,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1753649548...
Checkpoint 1753649548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.38483
Policy Entropy: 2.11427
Value Function Loss: 0.01785

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.55177

Collected Steps per Second: 21,370.42270
Overall Steps per Second: 10,207.07427

Timestep Collection Time: 2.33978
Timestep Consumption Time: 2.55898
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.89876

Cumulative Model Updates: 210,278
Cumulative Timesteps: 1,753,699,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.01721
Policy Entropy: 2.12943
Value Function Loss: 0.01811

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.55504

Collected Steps per Second: 21,990.93853
Overall Steps per Second: 10,464.16982

Timestep Collection Time: 2.27394
Timestep Consumption Time: 2.50485
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.77878

Cumulative Model Updates: 210,284
Cumulative Timesteps: 1,753,749,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1753749556...
Checkpoint 1753749556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.31836
Policy Entropy: 2.15635
Value Function Loss: 0.01671

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.56064

Collected Steps per Second: 21,684.04512
Overall Steps per Second: 10,542.65497

Timestep Collection Time: 2.30630
Timestep Consumption Time: 2.43728
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.74359

Cumulative Model Updates: 210,290
Cumulative Timesteps: 1,753,799,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.29211
Policy Entropy: 2.16970
Value Function Loss: 0.01664

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.53847
Value Function Update Magnitude: 0.55956

Collected Steps per Second: 22,121.22479
Overall Steps per Second: 10,489.29793

Timestep Collection Time: 2.26045
Timestep Consumption Time: 2.50669
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.76714

Cumulative Model Updates: 210,296
Cumulative Timesteps: 1,753,849,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1753849570...
Checkpoint 1753849570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.79986
Policy Entropy: 2.17160
Value Function Loss: 0.01686

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.55583

Collected Steps per Second: 21,653.90618
Overall Steps per Second: 10,275.26347

Timestep Collection Time: 2.30933
Timestep Consumption Time: 2.55731
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.86664

Cumulative Model Updates: 210,302
Cumulative Timesteps: 1,753,899,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.15716
Policy Entropy: 2.14979
Value Function Loss: 0.01697

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.54851

Collected Steps per Second: 21,934.77118
Overall Steps per Second: 10,446.46232

Timestep Collection Time: 2.28049
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.78842

Cumulative Model Updates: 210,308
Cumulative Timesteps: 1,753,949,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1753949598...
Checkpoint 1753949598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.10341
Policy Entropy: 2.14107
Value Function Loss: 0.01686

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.55386

Collected Steps per Second: 21,708.81360
Overall Steps per Second: 10,541.54199

Timestep Collection Time: 2.30321
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.74314

Cumulative Model Updates: 210,314
Cumulative Timesteps: 1,753,999,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.50130
Policy Entropy: 2.14039
Value Function Loss: 0.01591

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.55837

Collected Steps per Second: 22,247.94076
Overall Steps per Second: 10,517.03497

Timestep Collection Time: 2.24758
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.75457

Cumulative Model Updates: 210,320
Cumulative Timesteps: 1,754,049,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1754049602...
Checkpoint 1754049602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.11446
Policy Entropy: 2.14788
Value Function Loss: 0.01646

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.56164

Collected Steps per Second: 21,665.48909
Overall Steps per Second: 10,241.87223

Timestep Collection Time: 2.30828
Timestep Consumption Time: 2.57462
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 4.88290

Cumulative Model Updates: 210,326
Cumulative Timesteps: 1,754,099,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.97552
Policy Entropy: 2.14403
Value Function Loss: 0.01706

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.57611

Collected Steps per Second: 21,973.05851
Overall Steps per Second: 10,454.52386

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.50761
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.78358

Cumulative Model Updates: 210,332
Cumulative Timesteps: 1,754,149,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1754149622...
Checkpoint 1754149622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.78052
Policy Entropy: 2.13992
Value Function Loss: 0.01808

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.57924

Collected Steps per Second: 21,807.73482
Overall Steps per Second: 10,583.82578

Timestep Collection Time: 2.29286
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.72438

Cumulative Model Updates: 210,338
Cumulative Timesteps: 1,754,199,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.34529
Policy Entropy: 2.13428
Value Function Loss: 0.01746

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.57357

Collected Steps per Second: 22,032.19083
Overall Steps per Second: 10,469.17113

Timestep Collection Time: 2.27068
Timestep Consumption Time: 2.50792
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.77860

Cumulative Model Updates: 210,344
Cumulative Timesteps: 1,754,249,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1754249652...
Checkpoint 1754249652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.05062
Policy Entropy: 2.14009
Value Function Loss: 0.01790

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.57936

Collected Steps per Second: 21,893.99090
Overall Steps per Second: 10,297.42627

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.57216
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.85616

Cumulative Model Updates: 210,350
Cumulative Timesteps: 1,754,299,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.83017
Policy Entropy: 2.15072
Value Function Loss: 0.01780

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.57848

Collected Steps per Second: 22,122.54758
Overall Steps per Second: 10,408.52081

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.54494
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.80625

Cumulative Model Updates: 210,356
Cumulative Timesteps: 1,754,349,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1754349684...
Checkpoint 1754349684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.87847
Policy Entropy: 2.13879
Value Function Loss: 0.01831

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.57487

Collected Steps per Second: 21,902.04091
Overall Steps per Second: 10,412.45639

Timestep Collection Time: 2.28362
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.80348

Cumulative Model Updates: 210,362
Cumulative Timesteps: 1,754,399,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.26965
Policy Entropy: 2.15690
Value Function Loss: 0.01861

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.56833

Collected Steps per Second: 22,736.72753
Overall Steps per Second: 10,603.85312

Timestep Collection Time: 2.19970
Timestep Consumption Time: 2.51689
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.71659

Cumulative Model Updates: 210,368
Cumulative Timesteps: 1,754,449,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1754449714...
Checkpoint 1754449714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.89042
Policy Entropy: 2.13945
Value Function Loss: 0.01890

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.58271

Collected Steps per Second: 22,043.47170
Overall Steps per Second: 10,372.82841

Timestep Collection Time: 2.26870
Timestep Consumption Time: 2.55255
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.82125

Cumulative Model Updates: 210,374
Cumulative Timesteps: 1,754,499,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.95734
Policy Entropy: 2.14181
Value Function Loss: 0.01843

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 20,782.21985
Overall Steps per Second: 9,953.97679

Timestep Collection Time: 2.40629
Timestep Consumption Time: 2.61763
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 5.02392

Cumulative Model Updates: 210,380
Cumulative Timesteps: 1,754,549,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1754549732...
Checkpoint 1754549732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.83033
Policy Entropy: 2.14862
Value Function Loss: 0.01782

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 21,720.54271
Overall Steps per Second: 10,349.67394

Timestep Collection Time: 2.30224
Timestep Consumption Time: 2.52941
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.83165

Cumulative Model Updates: 210,386
Cumulative Timesteps: 1,754,599,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.39891
Policy Entropy: 2.14115
Value Function Loss: 0.01831

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.55752
Value Function Update Magnitude: 0.57187

Collected Steps per Second: 21,927.68950
Overall Steps per Second: 10,566.65461

Timestep Collection Time: 2.28022
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73187

Cumulative Model Updates: 210,392
Cumulative Timesteps: 1,754,649,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1754649738...
Checkpoint 1754649738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.93478
Policy Entropy: 2.16591
Value Function Loss: 0.01786

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.55137

Collected Steps per Second: 22,114.41655
Overall Steps per Second: 10,420.69472

Timestep Collection Time: 2.26205
Timestep Consumption Time: 2.53839
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.80045

Cumulative Model Updates: 210,398
Cumulative Timesteps: 1,754,699,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.11858
Policy Entropy: 2.16184
Value Function Loss: 0.01825

Mean KL Divergence: 0.02858
SB3 Clip Fraction: 0.17740
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 22,126.73590
Overall Steps per Second: 10,423.31365

Timestep Collection Time: 2.25980
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.79713

Cumulative Model Updates: 210,404
Cumulative Timesteps: 1,754,749,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1754749764...
Checkpoint 1754749764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.95261
Policy Entropy: 2.16142
Value Function Loss: 0.01904

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.18893
Policy Update Magnitude: 0.51774
Value Function Update Magnitude: 0.56392

Collected Steps per Second: 21,773.93153
Overall Steps per Second: 10,271.32278

Timestep Collection Time: 2.29697
Timestep Consumption Time: 2.57232
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 4.86929

Cumulative Model Updates: 210,410
Cumulative Timesteps: 1,754,799,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.57234
Policy Entropy: 2.11580
Value Function Loss: 0.01858

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.18582
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.60607

Collected Steps per Second: 21,439.42766
Overall Steps per Second: 10,347.24147

Timestep Collection Time: 2.33355
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.83511

Cumulative Model Updates: 210,416
Cumulative Timesteps: 1,754,849,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1754849808...
Checkpoint 1754849808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.87610
Policy Entropy: 2.09792
Value Function Loss: 0.01797

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.16943
Policy Update Magnitude: 0.57963
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 21,761.87567
Overall Steps per Second: 10,602.31655

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.41913
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.71746

Cumulative Model Updates: 210,422
Cumulative Timesteps: 1,754,899,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.30683
Policy Entropy: 2.11100
Value Function Loss: 0.01703

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.58920

Collected Steps per Second: 22,108.74741
Overall Steps per Second: 10,436.90308

Timestep Collection Time: 2.26272
Timestep Consumption Time: 2.53046
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.79318

Cumulative Model Updates: 210,428
Cumulative Timesteps: 1,754,949,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1754949850...
Checkpoint 1754949850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.27482
Policy Entropy: 2.12163
Value Function Loss: 0.01837

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.58096

Collected Steps per Second: 22,133.71941
Overall Steps per Second: 10,341.71797

Timestep Collection Time: 2.25954
Timestep Consumption Time: 2.57641
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 4.83595

Cumulative Model Updates: 210,434
Cumulative Timesteps: 1,754,999,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.77140
Policy Entropy: 2.12961
Value Function Loss: 0.01768

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.57744

Collected Steps per Second: 20,421.15781
Overall Steps per Second: 10,018.01970

Timestep Collection Time: 2.45001
Timestep Consumption Time: 2.54419
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.99420

Cumulative Model Updates: 210,440
Cumulative Timesteps: 1,755,049,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1755049894...
Checkpoint 1755049894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.23658
Policy Entropy: 2.12377
Value Function Loss: 0.01716

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 21,395.87716
Overall Steps per Second: 10,394.77168

Timestep Collection Time: 2.33774
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.81184

Cumulative Model Updates: 210,446
Cumulative Timesteps: 1,755,099,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.18635
Policy Entropy: 2.13908
Value Function Loss: 0.01637

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 22,248.30399
Overall Steps per Second: 10,352.32670

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.58278
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 4.83041

Cumulative Model Updates: 210,452
Cumulative Timesteps: 1,755,149,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1755149918...
Checkpoint 1755149918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.89687
Policy Entropy: 2.14298
Value Function Loss: 0.01741

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.56317
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 22,007.56705
Overall Steps per Second: 10,449.99273

Timestep Collection Time: 2.27285
Timestep Consumption Time: 2.51375
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.78661

Cumulative Model Updates: 210,458
Cumulative Timesteps: 1,755,199,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.75941
Policy Entropy: 2.13552
Value Function Loss: 0.01883

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.57303

Collected Steps per Second: 21,905.91443
Overall Steps per Second: 10,331.49650

Timestep Collection Time: 2.28276
Timestep Consumption Time: 2.55739
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.84015

Cumulative Model Updates: 210,464
Cumulative Timesteps: 1,755,249,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1755249944...
Checkpoint 1755249944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.67714
Policy Entropy: 2.14853
Value Function Loss: 0.01921

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.56935
Value Function Update Magnitude: 0.57962

Collected Steps per Second: 22,047.09664
Overall Steps per Second: 10,459.23972

Timestep Collection Time: 2.26842
Timestep Consumption Time: 2.51319
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.78161

Cumulative Model Updates: 210,470
Cumulative Timesteps: 1,755,299,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.46425
Policy Entropy: 2.15677
Value Function Loss: 0.01841

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.59586

Collected Steps per Second: 23,012.08952
Overall Steps per Second: 10,569.75338

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.55802
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.73105

Cumulative Model Updates: 210,476
Cumulative Timesteps: 1,755,349,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1755349962...
Checkpoint 1755349962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.38178
Policy Entropy: 2.16420
Value Function Loss: 0.01910

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.56786
Value Function Update Magnitude: 0.59430

Collected Steps per Second: 21,338.88038
Overall Steps per Second: 10,152.31640

Timestep Collection Time: 2.34445
Timestep Consumption Time: 2.58329
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.92774

Cumulative Model Updates: 210,482
Cumulative Timesteps: 1,755,399,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.44000
Policy Entropy: 2.14053
Value Function Loss: 0.01881

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 21,983.55813
Overall Steps per Second: 10,393.72834

Timestep Collection Time: 2.27515
Timestep Consumption Time: 2.53698
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.81213

Cumulative Model Updates: 210,488
Cumulative Timesteps: 1,755,450,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1755450006...
Checkpoint 1755450006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.82947
Policy Entropy: 2.13167
Value Function Loss: 0.01905

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 21,696.58781
Overall Steps per Second: 10,555.24305

Timestep Collection Time: 2.30562
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.73926

Cumulative Model Updates: 210,494
Cumulative Timesteps: 1,755,500,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.64238
Policy Entropy: 2.13127
Value Function Loss: 0.01727

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 21,894.04166
Overall Steps per Second: 10,399.79793

Timestep Collection Time: 2.28437
Timestep Consumption Time: 2.52477
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.80913

Cumulative Model Updates: 210,500
Cumulative Timesteps: 1,755,550,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1755550044...
Checkpoint 1755550044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.62410
Policy Entropy: 2.14437
Value Function Loss: 0.01680

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.55157

Collected Steps per Second: 22,021.64418
Overall Steps per Second: 10,322.58736

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.57377
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.84472

Cumulative Model Updates: 210,506
Cumulative Timesteps: 1,755,600,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.19039
Policy Entropy: 2.12712
Value Function Loss: 0.01659

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 21,926.44670
Overall Steps per Second: 10,403.60919

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.52608
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.80679

Cumulative Model Updates: 210,512
Cumulative Timesteps: 1,755,650,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1755650062...
Checkpoint 1755650062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.70667
Policy Entropy: 2.12375
Value Function Loss: 0.01776

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 21,587.18929
Overall Steps per Second: 10,243.98612

Timestep Collection Time: 2.31693
Timestep Consumption Time: 2.56554
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 4.88247

Cumulative Model Updates: 210,518
Cumulative Timesteps: 1,755,700,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.32621
Policy Entropy: 2.12973
Value Function Loss: 0.01694

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.56370

Collected Steps per Second: 22,065.71668
Overall Steps per Second: 10,451.11668

Timestep Collection Time: 2.26696
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.78628

Cumulative Model Updates: 210,524
Cumulative Timesteps: 1,755,750,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1755750100...
Checkpoint 1755750100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.74483
Policy Entropy: 2.15951
Value Function Loss: 0.01745

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.57889

Collected Steps per Second: 21,517.21394
Overall Steps per Second: 10,200.22562

Timestep Collection Time: 2.32465
Timestep Consumption Time: 2.57916
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.90381

Cumulative Model Updates: 210,530
Cumulative Timesteps: 1,755,800,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.48150
Policy Entropy: 2.17589
Value Function Loss: 0.01657

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.59028

Collected Steps per Second: 22,026.89528
Overall Steps per Second: 10,412.05151

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.53359
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.80482

Cumulative Model Updates: 210,536
Cumulative Timesteps: 1,755,850,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1755850148...
Checkpoint 1755850148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.37858
Policy Entropy: 2.17788
Value Function Loss: 0.01746

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.54027
Value Function Update Magnitude: 0.58592

Collected Steps per Second: 21,923.91614
Overall Steps per Second: 10,326.45916

Timestep Collection Time: 2.28116
Timestep Consumption Time: 2.56193
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 4.84309

Cumulative Model Updates: 210,542
Cumulative Timesteps: 1,755,900,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.37003
Policy Entropy: 2.16384
Value Function Loss: 0.01659

Mean KL Divergence: 0.02894
SB3 Clip Fraction: 0.17887
Policy Update Magnitude: 0.50115
Value Function Update Magnitude: 0.57920

Collected Steps per Second: 21,951.42857
Overall Steps per Second: 10,430.44349

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.51802
PPO Batch Consumption Time: 0.30391
Total Iteration Time: 4.79769

Cumulative Model Updates: 210,548
Cumulative Timesteps: 1,755,950,202

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1755950202...
Checkpoint 1755950202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.83545
Policy Entropy: 2.14600
Value Function Loss: 0.01693

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.57759

Collected Steps per Second: 21,617.43816
Overall Steps per Second: 10,189.41101

Timestep Collection Time: 2.31387
Timestep Consumption Time: 2.59515
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 4.90902

Cumulative Model Updates: 210,554
Cumulative Timesteps: 1,756,000,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.70274
Policy Entropy: 2.14608
Value Function Loss: 0.01731

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 21,878.29807
Overall Steps per Second: 10,387.03715

Timestep Collection Time: 2.28647
Timestep Consumption Time: 2.52954
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.81600

Cumulative Model Updates: 210,560
Cumulative Timesteps: 1,756,050,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1756050246...
Checkpoint 1756050246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.95011
Policy Entropy: 2.14844
Value Function Loss: 0.01771

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.59235

Collected Steps per Second: 21,951.89713
Overall Steps per Second: 10,332.35010

Timestep Collection Time: 2.27807
Timestep Consumption Time: 2.56187
PPO Batch Consumption Time: 0.30341
Total Iteration Time: 4.83994

Cumulative Model Updates: 210,566
Cumulative Timesteps: 1,756,100,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.16179
Policy Entropy: 2.13646
Value Function Loss: 0.01762

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.58569

Collected Steps per Second: 21,953.24047
Overall Steps per Second: 10,458.49454

Timestep Collection Time: 2.27784
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.30431
Total Iteration Time: 4.78138

Cumulative Model Updates: 210,572
Cumulative Timesteps: 1,756,150,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1756150260...
Checkpoint 1756150260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.51174
Policy Entropy: 2.11892
Value Function Loss: 0.01799

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.57837

Collected Steps per Second: 21,055.48692
Overall Steps per Second: 10,129.61774

Timestep Collection Time: 2.37487
Timestep Consumption Time: 2.56155
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.93642

Cumulative Model Updates: 210,578
Cumulative Timesteps: 1,756,200,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.75343
Policy Entropy: 2.12551
Value Function Loss: 0.01736

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,137.18088
Overall Steps per Second: 10,429.26439

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.53708
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.79708

Cumulative Model Updates: 210,584
Cumulative Timesteps: 1,756,250,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1756250294...
Checkpoint 1756250294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.04270
Policy Entropy: 2.09041
Value Function Loss: 0.01793

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.19027
Policy Update Magnitude: 0.51830
Value Function Update Magnitude: 0.62119

Collected Steps per Second: 21,387.79987
Overall Steps per Second: 10,264.69029

Timestep Collection Time: 2.33806
Timestep Consumption Time: 2.53359
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.87165

Cumulative Model Updates: 210,590
Cumulative Timesteps: 1,756,300,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.61933
Policy Entropy: 2.09797
Value Function Loss: 0.01715

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.16896
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.62121

Collected Steps per Second: 21,917.75253
Overall Steps per Second: 10,421.86123

Timestep Collection Time: 2.28253
Timestep Consumption Time: 2.51776
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.80029

Cumulative Model Updates: 210,596
Cumulative Timesteps: 1,756,350,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1756350328...
Checkpoint 1756350328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.91393
Policy Entropy: 2.09057
Value Function Loss: 0.01771

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.16013
Policy Update Magnitude: 0.57732
Value Function Update Magnitude: 0.62476

Collected Steps per Second: 21,274.06972
Overall Steps per Second: 10,318.92412

Timestep Collection Time: 2.35084
Timestep Consumption Time: 2.49579
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.84663

Cumulative Model Updates: 210,602
Cumulative Timesteps: 1,756,400,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.73971
Policy Entropy: 2.11938
Value Function Loss: 0.01836

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.59904
Value Function Update Magnitude: 0.62142

Collected Steps per Second: 21,948.96217
Overall Steps per Second: 10,398.61784

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.53113
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80987

Cumulative Model Updates: 210,608
Cumulative Timesteps: 1,756,450,356

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1756450356...
Checkpoint 1756450356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.44478
Policy Entropy: 2.09784
Value Function Loss: 0.01961

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.59499
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 21,404.13928
Overall Steps per Second: 10,197.16261

Timestep Collection Time: 2.33609
Timestep Consumption Time: 2.56743
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.90352

Cumulative Model Updates: 210,614
Cumulative Timesteps: 1,756,500,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.39719
Policy Entropy: 2.09832
Value Function Loss: 0.01933

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.62725

Collected Steps per Second: 21,792.47177
Overall Steps per Second: 10,317.11002

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.55236
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.84709

Cumulative Model Updates: 210,620
Cumulative Timesteps: 1,756,550,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1756550366...
Checkpoint 1756550366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.14712
Policy Entropy: 2.10881
Value Function Loss: 0.01838

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 21,688.34923
Overall Steps per Second: 10,332.63239

Timestep Collection Time: 2.30640
Timestep Consumption Time: 2.53477
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.84117

Cumulative Model Updates: 210,626
Cumulative Timesteps: 1,756,600,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.74969
Policy Entropy: 2.12993
Value Function Loss: 0.01792

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.60887

Collected Steps per Second: 21,714.46991
Overall Steps per Second: 10,472.28489

Timestep Collection Time: 2.30372
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.77680

Cumulative Model Updates: 210,632
Cumulative Timesteps: 1,756,650,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1756650412...
Checkpoint 1756650412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.15055
Policy Entropy: 2.10943
Value Function Loss: 0.01715

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.61456

Collected Steps per Second: 21,614.93905
Overall Steps per Second: 10,194.75242

Timestep Collection Time: 2.31405
Timestep Consumption Time: 2.59220
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 4.90625

Cumulative Model Updates: 210,638
Cumulative Timesteps: 1,756,700,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.61903
Policy Entropy: 2.11086
Value Function Loss: 0.01790

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.62533

Collected Steps per Second: 21,625.04762
Overall Steps per Second: 10,337.53329

Timestep Collection Time: 2.31426
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.84119

Cumulative Model Updates: 210,644
Cumulative Timesteps: 1,756,750,476

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1756750476...
Checkpoint 1756750476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.03901
Policy Entropy: 2.09057
Value Function Loss: 0.01796

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.16808
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 21,088.90458
Overall Steps per Second: 10,213.91583

Timestep Collection Time: 2.37120
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.89587

Cumulative Model Updates: 210,650
Cumulative Timesteps: 1,756,800,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.49922
Policy Entropy: 2.11599
Value Function Loss: 0.01822

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.19788
Policy Update Magnitude: 0.50921
Value Function Update Magnitude: 0.59959

Collected Steps per Second: 21,748.61851
Overall Steps per Second: 10,332.06812

Timestep Collection Time: 2.29900
Timestep Consumption Time: 2.54031
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.83930

Cumulative Model Updates: 210,656
Cumulative Timesteps: 1,756,850,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1756850482...
Checkpoint 1756850482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.28783
Policy Entropy: 2.11637
Value Function Loss: 0.01664

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.15173
Policy Update Magnitude: 0.52138
Value Function Update Magnitude: 0.57302

Collected Steps per Second: 21,782.58211
Overall Steps per Second: 10,463.11888

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.77888

Cumulative Model Updates: 210,662
Cumulative Timesteps: 1,756,900,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.79934
Policy Entropy: 2.16410
Value Function Loss: 0.01600

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.54720

Collected Steps per Second: 21,727.33296
Overall Steps per Second: 10,306.50635

Timestep Collection Time: 2.30171
Timestep Consumption Time: 2.55057
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.85227

Cumulative Model Updates: 210,668
Cumulative Timesteps: 1,756,950,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1756950494...
Checkpoint 1756950494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.93219
Policy Entropy: 2.14725
Value Function Loss: 0.01629

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.56830

Collected Steps per Second: 22,170.44401
Overall Steps per Second: 10,341.48954

Timestep Collection Time: 2.25625
Timestep Consumption Time: 2.58077
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.83702

Cumulative Model Updates: 210,674
Cumulative Timesteps: 1,757,000,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.96809
Policy Entropy: 2.15743
Value Function Loss: 0.01686

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15024
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.58968

Collected Steps per Second: 21,707.86318
Overall Steps per Second: 10,352.36691

Timestep Collection Time: 2.30405
Timestep Consumption Time: 2.52731
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.83136

Cumulative Model Updates: 210,680
Cumulative Timesteps: 1,757,050,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1757050532...
Checkpoint 1757050532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.56096
Policy Entropy: 2.14369
Value Function Loss: 0.01777

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.58762

Collected Steps per Second: 21,078.22201
Overall Steps per Second: 10,255.71657

Timestep Collection Time: 2.37326
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.87767

Cumulative Model Updates: 210,686
Cumulative Timesteps: 1,757,100,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.96854
Policy Entropy: 2.14004
Value Function Loss: 0.01820

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.60918

Collected Steps per Second: 21,988.31004
Overall Steps per Second: 10,512.57285

Timestep Collection Time: 2.27448
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.75735

Cumulative Model Updates: 210,692
Cumulative Timesteps: 1,757,150,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1757150568...
Checkpoint 1757150568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.31152
Policy Entropy: 2.11008
Value Function Loss: 0.01765

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.63373

Collected Steps per Second: 21,738.89337
Overall Steps per Second: 10,224.92861

Timestep Collection Time: 2.30168
Timestep Consumption Time: 2.59185
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 4.89353

Cumulative Model Updates: 210,698
Cumulative Timesteps: 1,757,200,604

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.31896
Policy Entropy: 2.09793
Value Function Loss: 0.01685

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.63474

Collected Steps per Second: 21,790.27813
Overall Steps per Second: 10,337.90003

Timestep Collection Time: 2.29561
Timestep Consumption Time: 2.54309
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.83870

Cumulative Model Updates: 210,704
Cumulative Timesteps: 1,757,250,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1757250626...
Checkpoint 1757250626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.88287
Policy Entropy: 2.11397
Value Function Loss: 0.01678

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.56579
Value Function Update Magnitude: 0.64463

Collected Steps per Second: 21,753.87616
Overall Steps per Second: 10,332.40722

Timestep Collection Time: 2.30000
Timestep Consumption Time: 2.54243
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.84243

Cumulative Model Updates: 210,710
Cumulative Timesteps: 1,757,300,660

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.02852
Policy Entropy: 2.14229
Value Function Loss: 0.01657

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 21,585.75918
Overall Steps per Second: 10,476.08403

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77678

Cumulative Model Updates: 210,716
Cumulative Timesteps: 1,757,350,702

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1757350702...
Checkpoint 1757350702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.30205
Policy Entropy: 2.11376
Value Function Loss: 0.01715

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.56477
Value Function Update Magnitude: 0.61111

Collected Steps per Second: 21,694.85280
Overall Steps per Second: 10,209.81202

Timestep Collection Time: 2.30571
Timestep Consumption Time: 2.59370
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 4.89940

Cumulative Model Updates: 210,722
Cumulative Timesteps: 1,757,400,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.48400
Policy Entropy: 2.09427
Value Function Loss: 0.01683

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.60299

Collected Steps per Second: 21,754.66462
Overall Steps per Second: 10,333.09951

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.54148
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.84075

Cumulative Model Updates: 210,728
Cumulative Timesteps: 1,757,450,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1757450744...
Checkpoint 1757450744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.54951
Policy Entropy: 2.09748
Value Function Loss: 0.01739

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.18539
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.61616

Collected Steps per Second: 21,971.07167
Overall Steps per Second: 10,330.59751

Timestep Collection Time: 2.27581
Timestep Consumption Time: 2.56437
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.84018

Cumulative Model Updates: 210,734
Cumulative Timesteps: 1,757,500,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.03026
Policy Entropy: 2.12067
Value Function Loss: 0.01695

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.62898

Collected Steps per Second: 21,570.66307
Overall Steps per Second: 10,327.18976

Timestep Collection Time: 2.31870
Timestep Consumption Time: 2.52443
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.84314

Cumulative Model Updates: 210,740
Cumulative Timesteps: 1,757,550,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1757550762...
Checkpoint 1757550762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.76680
Policy Entropy: 2.13428
Value Function Loss: 0.01678

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.57097
Value Function Update Magnitude: 0.62270

Collected Steps per Second: 21,696.18257
Overall Steps per Second: 10,399.81747

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.30294
Total Iteration Time: 4.80970

Cumulative Model Updates: 210,746
Cumulative Timesteps: 1,757,600,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.33152
Policy Entropy: 2.14180
Value Function Loss: 0.01643

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 21,798.29340
Overall Steps per Second: 10,354.17565

Timestep Collection Time: 2.29477
Timestep Consumption Time: 2.53633
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.83109

Cumulative Model Updates: 210,752
Cumulative Timesteps: 1,757,650,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1757650804...
Checkpoint 1757650804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.43063
Policy Entropy: 2.14834
Value Function Loss: 0.01667

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.61612

Collected Steps per Second: 21,671.47889
Overall Steps per Second: 10,253.73798

Timestep Collection Time: 2.30773
Timestep Consumption Time: 2.56971
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.87744

Cumulative Model Updates: 210,758
Cumulative Timesteps: 1,757,700,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.92264
Policy Entropy: 2.17382
Value Function Loss: 0.01580

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.55265
Value Function Update Magnitude: 0.61465

Collected Steps per Second: 21,592.91024
Overall Steps per Second: 10,367.01169

Timestep Collection Time: 2.31696
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.82588

Cumulative Model Updates: 210,764
Cumulative Timesteps: 1,757,750,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1757750846...
Checkpoint 1757750846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.40196
Policy Entropy: 2.15201
Value Function Loss: 0.01661

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 21,779.03295
Overall Steps per Second: 10,433.50770

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.30258
Total Iteration Time: 4.79379

Cumulative Model Updates: 210,770
Cumulative Timesteps: 1,757,800,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.19468
Policy Entropy: 2.14024
Value Function Loss: 0.01704

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.61134

Collected Steps per Second: 21,876.23416
Overall Steps per Second: 10,341.71239

Timestep Collection Time: 2.28623
Timestep Consumption Time: 2.54992
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.83614

Cumulative Model Updates: 210,776
Cumulative Timesteps: 1,757,850,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1757850876...
Checkpoint 1757850876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.37239
Policy Entropy: 2.11631
Value Function Loss: 0.01778

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.16646
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.62885

Collected Steps per Second: 21,575.21403
Overall Steps per Second: 10,199.85921

Timestep Collection Time: 2.31868
Timestep Consumption Time: 2.58590
PPO Batch Consumption Time: 0.30205
Total Iteration Time: 4.90458

Cumulative Model Updates: 210,782
Cumulative Timesteps: 1,757,900,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.69205
Policy Entropy: 2.11555
Value Function Loss: 0.01864

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.17207
Policy Update Magnitude: 0.56800
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 21,429.23761
Overall Steps per Second: 10,134.94819

Timestep Collection Time: 2.33419
Timestep Consumption Time: 2.60120
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.93540

Cumulative Model Updates: 210,788
Cumulative Timesteps: 1,757,950,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1757950922...
Checkpoint 1757950922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.20634
Policy Entropy: 2.12689
Value Function Loss: 0.01824

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.17443
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.61434

Collected Steps per Second: 21,616.32081
Overall Steps per Second: 10,530.39410

Timestep Collection Time: 2.31316
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.74835

Cumulative Model Updates: 210,794
Cumulative Timesteps: 1,758,000,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.06230
Policy Entropy: 2.15356
Value Function Loss: 0.01836

Mean KL Divergence: 0.02180
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.61780

Collected Steps per Second: 21,898.46438
Overall Steps per Second: 10,379.42787

Timestep Collection Time: 2.28409
Timestep Consumption Time: 2.53487
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.81896

Cumulative Model Updates: 210,800
Cumulative Timesteps: 1,758,050,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1758050942...
Checkpoint 1758050942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.93722
Policy Entropy: 2.16771
Value Function Loss: 0.01767

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 21,906.49867
Overall Steps per Second: 10,276.34387

Timestep Collection Time: 2.28334
Timestep Consumption Time: 2.58415
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 4.86749

Cumulative Model Updates: 210,806
Cumulative Timesteps: 1,758,100,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.65526
Policy Entropy: 2.18298
Value Function Loss: 0.01599

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.60221

Collected Steps per Second: 21,050.92685
Overall Steps per Second: 10,038.02803

Timestep Collection Time: 2.37605
Timestep Consumption Time: 2.60680
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 4.98285

Cumulative Model Updates: 210,812
Cumulative Timesteps: 1,758,150,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1758150980...
Checkpoint 1758150980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.85343
Policy Entropy: 2.16470
Value Function Loss: 0.01550

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.58117

Collected Steps per Second: 21,526.72346
Overall Steps per Second: 10,205.51632

Timestep Collection Time: 2.32390
Timestep Consumption Time: 2.57796
PPO Batch Consumption Time: 0.30285
Total Iteration Time: 4.90186

Cumulative Model Updates: 210,818
Cumulative Timesteps: 1,758,201,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.72391
Policy Entropy: 2.17435
Value Function Loss: 0.01588

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 22,750.13112
Overall Steps per Second: 10,484.94067

Timestep Collection Time: 2.19832
Timestep Consumption Time: 2.57157
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.76989

Cumulative Model Updates: 210,824
Cumulative Timesteps: 1,758,251,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1758251018...
Checkpoint 1758251018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.73726
Policy Entropy: 2.17217
Value Function Loss: 0.01711

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.58816

Collected Steps per Second: 21,439.33661
Overall Steps per Second: 10,183.98943

Timestep Collection Time: 2.33225
Timestep Consumption Time: 2.57761
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.90986

Cumulative Model Updates: 210,830
Cumulative Timesteps: 1,758,301,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.11374
Policy Entropy: 2.17533
Value Function Loss: 0.01787

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.57861

Collected Steps per Second: 21,784.06681
Overall Steps per Second: 10,339.22593

Timestep Collection Time: 2.29581
Timestep Consumption Time: 2.54131
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.83711

Cumulative Model Updates: 210,836
Cumulative Timesteps: 1,758,351,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1758351032...
Checkpoint 1758351032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.88327
Policy Entropy: 2.17593
Value Function Loss: 0.01708

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 21,916.44038
Overall Steps per Second: 10,325.80105

Timestep Collection Time: 2.28258
Timestep Consumption Time: 2.56218
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 4.84476

Cumulative Model Updates: 210,842
Cumulative Timesteps: 1,758,401,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.56978
Policy Entropy: 2.16737
Value Function Loss: 0.01629

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.58353

Collected Steps per Second: 21,927.56365
Overall Steps per Second: 10,466.78089

Timestep Collection Time: 2.28133
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.77931

Cumulative Model Updates: 210,848
Cumulative Timesteps: 1,758,451,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1758451082...
Checkpoint 1758451082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.97755
Policy Entropy: 2.18132
Value Function Loss: 0.01626

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.59979

Collected Steps per Second: 21,475.87060
Overall Steps per Second: 10,208.69412

Timestep Collection Time: 2.32913
Timestep Consumption Time: 2.57062
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.89975

Cumulative Model Updates: 210,854
Cumulative Timesteps: 1,758,501,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.25233
Policy Entropy: 2.17829
Value Function Loss: 0.01653

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.59772

Collected Steps per Second: 21,874.78094
Overall Steps per Second: 10,345.33058

Timestep Collection Time: 2.28674
Timestep Consumption Time: 2.54848
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.83522

Cumulative Model Updates: 210,860
Cumulative Timesteps: 1,758,551,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1758551124...
Checkpoint 1758551124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.15210
Policy Entropy: 2.16619
Value Function Loss: 0.01794

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.60659

Collected Steps per Second: 21,426.91880
Overall Steps per Second: 10,329.72759

Timestep Collection Time: 2.33351
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.84040

Cumulative Model Updates: 210,866
Cumulative Timesteps: 1,758,601,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.30441
Policy Entropy: 2.17041
Value Function Loss: 0.01749

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 21,751.69011
Overall Steps per Second: 10,468.99625

Timestep Collection Time: 2.29876
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.77620

Cumulative Model Updates: 210,872
Cumulative Timesteps: 1,758,651,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1758651126...
Checkpoint 1758651126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.88235
Policy Entropy: 2.17282
Value Function Loss: 0.01678

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.59846

Collected Steps per Second: 21,687.53873
Overall Steps per Second: 10,217.71776

Timestep Collection Time: 2.30602
Timestep Consumption Time: 2.58861
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.89464

Cumulative Model Updates: 210,878
Cumulative Timesteps: 1,758,701,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.80366
Policy Entropy: 2.18323
Value Function Loss: 0.01685

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.53394
Value Function Update Magnitude: 0.57045

Collected Steps per Second: 21,809.54515
Overall Steps per Second: 10,344.86032

Timestep Collection Time: 2.29331
Timestep Consumption Time: 2.54156
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.83486

Cumulative Model Updates: 210,884
Cumulative Timesteps: 1,758,751,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1758751154...
Checkpoint 1758751154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.29857
Policy Entropy: 2.14916
Value Function Loss: 0.01739

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.55447

Collected Steps per Second: 21,518.99992
Overall Steps per Second: 10,312.30604

Timestep Collection Time: 2.32409
Timestep Consumption Time: 2.52565
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.84974

Cumulative Model Updates: 210,890
Cumulative Timesteps: 1,758,801,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.97237
Policy Entropy: 2.13467
Value Function Loss: 0.01756

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.56436

Collected Steps per Second: 22,019.47391
Overall Steps per Second: 10,463.74436

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.78051

Cumulative Model Updates: 210,896
Cumulative Timesteps: 1,758,851,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1758851188...
Checkpoint 1758851188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.11654
Policy Entropy: 2.13883
Value Function Loss: 0.01659

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.55533
Value Function Update Magnitude: 0.56784

Collected Steps per Second: 20,865.10259
Overall Steps per Second: 10,204.15511

Timestep Collection Time: 2.39750
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 4.90232

Cumulative Model Updates: 210,902
Cumulative Timesteps: 1,758,901,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.29244
Policy Entropy: 2.17755
Value Function Loss: 0.01637

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.57825

Collected Steps per Second: 21,935.83455
Overall Steps per Second: 10,381.50376

Timestep Collection Time: 2.27983
Timestep Consumption Time: 2.53739
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.81722

Cumulative Model Updates: 210,908
Cumulative Timesteps: 1,758,951,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1758951222...
Checkpoint 1758951222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.39019
Policy Entropy: 2.20649
Value Function Loss: 0.01574

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 21,602.43013
Overall Steps per Second: 10,282.80531

Timestep Collection Time: 2.31567
Timestep Consumption Time: 2.54915
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.86482

Cumulative Model Updates: 210,914
Cumulative Timesteps: 1,759,001,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.19545
Policy Entropy: 2.19689
Value Function Loss: 0.01536

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.52601
Value Function Update Magnitude: 0.55456

Collected Steps per Second: 22,182.75980
Overall Steps per Second: 10,475.01943

Timestep Collection Time: 2.25508
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.77555

Cumulative Model Updates: 210,920
Cumulative Timesteps: 1,759,051,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1759051270...
Checkpoint 1759051270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.76097
Policy Entropy: 2.18368
Value Function Loss: 0.01586

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.53593

Collected Steps per Second: 21,419.30102
Overall Steps per Second: 10,387.49700

Timestep Collection Time: 2.33546
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.81579

Cumulative Model Updates: 210,926
Cumulative Timesteps: 1,759,101,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.17833
Policy Entropy: 2.17383
Value Function Loss: 0.01669

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.55002

Collected Steps per Second: 21,941.61444
Overall Steps per Second: 10,267.49952

Timestep Collection Time: 2.27987
Timestep Consumption Time: 2.59220
PPO Batch Consumption Time: 0.30159
Total Iteration Time: 4.87207

Cumulative Model Updates: 210,932
Cumulative Timesteps: 1,759,151,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1759151318...
Checkpoint 1759151318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.71755
Policy Entropy: 2.17635
Value Function Loss: 0.01779

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.55959

Collected Steps per Second: 21,663.05363
Overall Steps per Second: 10,197.18853

Timestep Collection Time: 2.30891
Timestep Consumption Time: 2.59617
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.90508

Cumulative Model Updates: 210,938
Cumulative Timesteps: 1,759,201,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.08654
Policy Entropy: 2.17987
Value Function Loss: 0.01755

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.57446

Collected Steps per Second: 22,042.78513
Overall Steps per Second: 10,502.96979

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.49224
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.76056

Cumulative Model Updates: 210,944
Cumulative Timesteps: 1,759,251,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1759251336...
Checkpoint 1759251336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.61040
Policy Entropy: 2.17878
Value Function Loss: 0.01695

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.54315
Value Function Update Magnitude: 0.59334

Collected Steps per Second: 21,672.63782
Overall Steps per Second: 10,537.27576

Timestep Collection Time: 2.30863
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.74829

Cumulative Model Updates: 210,950
Cumulative Timesteps: 1,759,301,370

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.57144
Policy Entropy: 2.18456
Value Function Loss: 0.01756

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.54942
Value Function Update Magnitude: 0.60876

Collected Steps per Second: 22,130.41921
Overall Steps per Second: 10,425.18110

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.53756
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.79761

Cumulative Model Updates: 210,956
Cumulative Timesteps: 1,759,351,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1759351386...
Checkpoint 1759351386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.98510
Policy Entropy: 2.19639
Value Function Loss: 0.01684

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 21,763.36629
Overall Steps per Second: 10,306.30388

Timestep Collection Time: 2.29753
Timestep Consumption Time: 2.55406
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.85159

Cumulative Model Updates: 210,962
Cumulative Timesteps: 1,759,401,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.01217
Policy Entropy: 2.17417
Value Function Loss: 0.01717

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 21,527.07830
Overall Steps per Second: 10,349.54605

Timestep Collection Time: 2.32396
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.83384

Cumulative Model Updates: 210,968
Cumulative Timesteps: 1,759,451,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1759451416...
Checkpoint 1759451416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.16019
Policy Entropy: 2.19226
Value Function Loss: 0.01617

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.54871
Value Function Update Magnitude: 0.61950

Collected Steps per Second: 21,705.35936
Overall Steps per Second: 10,418.96806

Timestep Collection Time: 2.30478
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.80144

Cumulative Model Updates: 210,974
Cumulative Timesteps: 1,759,501,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.53600
Policy Entropy: 2.18096
Value Function Loss: 0.01759

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 22,103.90915
Overall Steps per Second: 10,360.38655

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.56413
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.82627

Cumulative Model Updates: 210,980
Cumulative Timesteps: 1,759,551,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1759551444...
Checkpoint 1759551444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.80613
Policy Entropy: 2.18799
Value Function Loss: 0.01726

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 21,889.41620
Overall Steps per Second: 10,298.88157

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.57079
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 4.85509

Cumulative Model Updates: 210,986
Cumulative Timesteps: 1,759,601,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.98685
Policy Entropy: 2.14766
Value Function Loss: 0.01806

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.59439

Collected Steps per Second: 21,086.38645
Overall Steps per Second: 10,116.84364

Timestep Collection Time: 2.37234
Timestep Consumption Time: 2.57229
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.94463

Cumulative Model Updates: 210,992
Cumulative Timesteps: 1,759,651,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1759651470...
Checkpoint 1759651470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.15945
Policy Entropy: 2.13896
Value Function Loss: 0.01765

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.58964

Collected Steps per Second: 21,847.54460
Overall Steps per Second: 10,376.68724

Timestep Collection Time: 2.28859
Timestep Consumption Time: 2.52991
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.81849

Cumulative Model Updates: 210,998
Cumulative Timesteps: 1,759,701,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.87579
Policy Entropy: 2.15168
Value Function Loss: 0.01714

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.58150

Collected Steps per Second: 22,111.08680
Overall Steps per Second: 10,509.89217

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.75990

Cumulative Model Updates: 211,004
Cumulative Timesteps: 1,759,751,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1759751496...
Checkpoint 1759751496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.92712
Policy Entropy: 2.17859
Value Function Loss: 0.01668

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.57572

Collected Steps per Second: 21,923.53723
Overall Steps per Second: 10,275.82990

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.58565
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 4.86676

Cumulative Model Updates: 211,010
Cumulative Timesteps: 1,759,801,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.64738
Policy Entropy: 2.19796
Value Function Loss: 0.01642

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.57491

Collected Steps per Second: 21,414.80770
Overall Steps per Second: 10,169.02496

Timestep Collection Time: 2.33502
Timestep Consumption Time: 2.58227
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.91729

Cumulative Model Updates: 211,016
Cumulative Timesteps: 1,759,851,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1759851510...
Checkpoint 1759851510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.80713
Policy Entropy: 2.19476
Value Function Loss: 0.01706

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 21,551.07242
Overall Steps per Second: 10,378.77466

Timestep Collection Time: 2.32146
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.82041

Cumulative Model Updates: 211,022
Cumulative Timesteps: 1,759,901,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.13849
Policy Entropy: 2.20415
Value Function Loss: 0.01662

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.59279

Collected Steps per Second: 21,877.59700
Overall Steps per Second: 10,529.67047

Timestep Collection Time: 2.28617
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.75001

Cumulative Model Updates: 211,028
Cumulative Timesteps: 1,759,951,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1759951556...
Checkpoint 1759951556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.22241
Policy Entropy: 2.20963
Value Function Loss: 0.01649

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.58929

Collected Steps per Second: 21,781.38822
Overall Steps per Second: 10,258.47289

Timestep Collection Time: 2.29554
Timestep Consumption Time: 2.57848
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.87402

Cumulative Model Updates: 211,034
Cumulative Timesteps: 1,760,001,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.30909
Policy Entropy: 2.21793
Value Function Loss: 0.01628

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.54051
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 21,620.42631
Overall Steps per Second: 10,250.61945

Timestep Collection Time: 2.31355
Timestep Consumption Time: 2.56615
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.87971

Cumulative Model Updates: 211,040
Cumulative Timesteps: 1,760,051,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1760051576...
Checkpoint 1760051576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.35045
Policy Entropy: 2.19805
Value Function Loss: 0.01711

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.60062

Collected Steps per Second: 21,363.41466
Overall Steps per Second: 10,280.56086

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.86549

Cumulative Model Updates: 211,046
Cumulative Timesteps: 1,760,101,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.10667
Policy Entropy: 2.17513
Value Function Loss: 0.01726

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.61684

Collected Steps per Second: 21,597.49637
Overall Steps per Second: 10,478.43476

Timestep Collection Time: 2.31638
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.77438

Cumulative Model Updates: 211,052
Cumulative Timesteps: 1,760,151,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1760151624...
Checkpoint 1760151624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.39929
Policy Entropy: 2.17794
Value Function Loss: 0.01726

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.62135

Collected Steps per Second: 21,844.75467
Overall Steps per Second: 10,261.65918

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.58383
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 4.87290

Cumulative Model Updates: 211,058
Cumulative Timesteps: 1,760,201,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.72960
Policy Entropy: 2.18643
Value Function Loss: 0.01730

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.60426

Collected Steps per Second: 21,776.55670
Overall Steps per Second: 10,372.18052

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.52525
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.82194

Cumulative Model Updates: 211,064
Cumulative Timesteps: 1,760,251,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1760251642...
Checkpoint 1760251642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.86991
Policy Entropy: 2.19433
Value Function Loss: 0.01660

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.59070

Collected Steps per Second: 21,782.69829
Overall Steps per Second: 10,305.74394

Timestep Collection Time: 2.29632
Timestep Consumption Time: 2.55729
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.85360

Cumulative Model Updates: 211,070
Cumulative Timesteps: 1,760,301,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.06620
Policy Entropy: 2.19087
Value Function Loss: 0.01682

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.56595

Collected Steps per Second: 21,680.57859
Overall Steps per Second: 10,450.21673

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.47937
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.78650

Cumulative Model Updates: 211,076
Cumulative Timesteps: 1,760,351,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1760351682...
Checkpoint 1760351682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.55478
Policy Entropy: 2.18750
Value Function Loss: 0.01671

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.56537

Collected Steps per Second: 21,676.42799
Overall Steps per Second: 10,208.20327

Timestep Collection Time: 2.30804
Timestep Consumption Time: 2.59292
PPO Batch Consumption Time: 0.30344
Total Iteration Time: 4.90096

Cumulative Model Updates: 211,082
Cumulative Timesteps: 1,760,401,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.15963
Policy Entropy: 2.20497
Value Function Loss: 0.01670

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.57016

Collected Steps per Second: 21,643.61056
Overall Steps per Second: 10,238.19017

Timestep Collection Time: 2.31163
Timestep Consumption Time: 2.57517
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.88680

Cumulative Model Updates: 211,088
Cumulative Timesteps: 1,760,451,744

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1760451744...
Checkpoint 1760451744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.15125
Policy Entropy: 2.19359
Value Function Loss: 0.01664

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.57603

Collected Steps per Second: 21,814.63874
Overall Steps per Second: 10,382.78958

Timestep Collection Time: 2.29241
Timestep Consumption Time: 2.52403
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.81643

Cumulative Model Updates: 211,094
Cumulative Timesteps: 1,760,501,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.88908
Policy Entropy: 2.21601
Value Function Loss: 0.01677

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 21,640.85605
Overall Steps per Second: 10,528.04129

Timestep Collection Time: 2.31072
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.74979

Cumulative Model Updates: 211,100
Cumulative Timesteps: 1,760,551,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1760551758...
Checkpoint 1760551758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.07536
Policy Entropy: 2.20483
Value Function Loss: 0.01708

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 21,805.45601
Overall Steps per Second: 10,260.33413

Timestep Collection Time: 2.29392
Timestep Consumption Time: 2.58116
PPO Batch Consumption Time: 0.30290
Total Iteration Time: 4.87508

Cumulative Model Updates: 211,106
Cumulative Timesteps: 1,760,601,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.95120
Policy Entropy: 2.22784
Value Function Loss: 0.01772

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.58286

Collected Steps per Second: 21,482.11194
Overall Steps per Second: 10,285.27964

Timestep Collection Time: 2.32798
Timestep Consumption Time: 2.53431
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.86229

Cumulative Model Updates: 211,112
Cumulative Timesteps: 1,760,651,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1760651788...
Checkpoint 1760651788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.20930
Policy Entropy: 2.21779
Value Function Loss: 0.01827

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.60257

Collected Steps per Second: 21,566.72341
Overall Steps per Second: 10,339.96934

Timestep Collection Time: 2.31922
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.83735

Cumulative Model Updates: 211,118
Cumulative Timesteps: 1,760,701,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.91413
Policy Entropy: 2.20324
Value Function Loss: 0.01882

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.61867

Collected Steps per Second: 21,792.07643
Overall Steps per Second: 10,382.95780

Timestep Collection Time: 2.29450
Timestep Consumption Time: 2.52127
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.81578

Cumulative Model Updates: 211,124
Cumulative Timesteps: 1,760,751,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1760751808...
Checkpoint 1760751808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.92114
Policy Entropy: 2.21609
Value Function Loss: 0.01867

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.60944

Collected Steps per Second: 22,330.36427
Overall Steps per Second: 10,417.29811

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.56102
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.80048

Cumulative Model Updates: 211,130
Cumulative Timesteps: 1,760,801,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.25660
Policy Entropy: 2.19750
Value Function Loss: 0.01792

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 21,924.90957
Overall Steps per Second: 10,307.61868

Timestep Collection Time: 2.28133
Timestep Consumption Time: 2.57120
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.85253

Cumulative Model Updates: 211,136
Cumulative Timesteps: 1,760,851,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1760851834...
Checkpoint 1760851834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.87066
Policy Entropy: 2.20906
Value Function Loss: 0.01722

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.62829

Collected Steps per Second: 21,725.93274
Overall Steps per Second: 10,302.62785

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.55235
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.85430

Cumulative Model Updates: 211,142
Cumulative Timesteps: 1,760,901,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.83854
Policy Entropy: 2.20203
Value Function Loss: 0.01609

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 21,840.63888
Overall Steps per Second: 10,322.00759

Timestep Collection Time: 2.29004
Timestep Consumption Time: 2.55553
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.84557

Cumulative Model Updates: 211,148
Cumulative Timesteps: 1,760,951,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1760951862...
Checkpoint 1760951862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.53038
Policy Entropy: 2.20822
Value Function Loss: 0.01658

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.55545
Value Function Update Magnitude: 0.58315

Collected Steps per Second: 22,266.88379
Overall Steps per Second: 10,381.32817

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.57198
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.81846

Cumulative Model Updates: 211,154
Cumulative Timesteps: 1,761,001,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.37897
Policy Entropy: 2.20653
Value Function Loss: 0.01780

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.57645

Collected Steps per Second: 22,043.54022
Overall Steps per Second: 10,321.52436

Timestep Collection Time: 2.26824
Timestep Consumption Time: 2.57601
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.84425

Cumulative Model Updates: 211,160
Cumulative Timesteps: 1,761,051,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1761051884...
Checkpoint 1761051884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.33201
Policy Entropy: 2.20372
Value Function Loss: 0.01907

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 21,628.89434
Overall Steps per Second: 10,213.53514

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.58581
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.89938

Cumulative Model Updates: 211,166
Cumulative Timesteps: 1,761,101,924

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.19753
Policy Entropy: 2.19769
Value Function Loss: 0.01818

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 21,870.62695
Overall Steps per Second: 10,404.88566

Timestep Collection Time: 2.28809
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.80947

Cumulative Model Updates: 211,172
Cumulative Timesteps: 1,761,151,966

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1761151966...
Checkpoint 1761151966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.51860
Policy Entropy: 2.19184
Value Function Loss: 0.01728

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.61639

Collected Steps per Second: 22,004.99642
Overall Steps per Second: 10,319.57032

Timestep Collection Time: 2.27403
Timestep Consumption Time: 2.57501
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.84904

Cumulative Model Updates: 211,178
Cumulative Timesteps: 1,761,202,006

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.89065
Policy Entropy: 2.19613
Value Function Loss: 0.01586

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 21,349.35539
Overall Steps per Second: 10,172.19182

Timestep Collection Time: 2.34330
Timestep Consumption Time: 2.57481
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.91811

Cumulative Model Updates: 211,184
Cumulative Timesteps: 1,761,252,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1761252034...
Checkpoint 1761252034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.58694
Policy Entropy: 2.18089
Value Function Loss: 0.01630

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.62315

Collected Steps per Second: 21,842.99160
Overall Steps per Second: 10,365.04627

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.53494
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.82410

Cumulative Model Updates: 211,190
Cumulative Timesteps: 1,761,302,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.90416
Policy Entropy: 2.18010
Value Function Loss: 0.01595

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.55022
Value Function Update Magnitude: 0.62195

Collected Steps per Second: 22,282.88425
Overall Steps per Second: 10,489.47121

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.77088

Cumulative Model Updates: 211,196
Cumulative Timesteps: 1,761,352,080

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1761352080...
Checkpoint 1761352080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.43835
Policy Entropy: 2.17140
Value Function Loss: 0.01722

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.54365
Value Function Update Magnitude: 0.61031

Collected Steps per Second: 21,465.93120
Overall Steps per Second: 10,395.97216

Timestep Collection Time: 2.33039
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.81186

Cumulative Model Updates: 211,202
Cumulative Timesteps: 1,761,402,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.44279
Policy Entropy: 2.17835
Value Function Loss: 0.01709

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 21,820.33875
Overall Steps per Second: 10,328.63602

Timestep Collection Time: 2.29282
Timestep Consumption Time: 2.55100
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.84381

Cumulative Model Updates: 211,208
Cumulative Timesteps: 1,761,452,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1761452134...
Checkpoint 1761452134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.44705
Policy Entropy: 2.18206
Value Function Loss: 0.01722

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.64137

Collected Steps per Second: 21,664.81916
Overall Steps per Second: 10,198.78846

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.59465
PPO Batch Consumption Time: 0.30426
Total Iteration Time: 4.90254

Cumulative Model Updates: 211,214
Cumulative Timesteps: 1,761,502,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.18824
Policy Entropy: 2.17384
Value Function Loss: 0.01703

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 21,856.13325
Overall Steps per Second: 10,455.00994

Timestep Collection Time: 2.28805
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.78316

Cumulative Model Updates: 211,220
Cumulative Timesteps: 1,761,552,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1761552142...
Checkpoint 1761552142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.31896
Policy Entropy: 2.18429
Value Function Loss: 0.01713

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 21,828.84381
Overall Steps per Second: 10,232.62724

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.59609
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.88692

Cumulative Model Updates: 211,226
Cumulative Timesteps: 1,761,602,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.37886
Policy Entropy: 2.19319
Value Function Loss: 0.01752

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.57446

Collected Steps per Second: 21,704.66284
Overall Steps per Second: 10,329.87167

Timestep Collection Time: 2.30513
Timestep Consumption Time: 2.53830
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.84343

Cumulative Model Updates: 211,232
Cumulative Timesteps: 1,761,652,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1761652180...
Checkpoint 1761652180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.14371
Policy Entropy: 2.19034
Value Function Loss: 0.01810

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 21,928.19540
Overall Steps per Second: 10,317.44880

Timestep Collection Time: 2.28026
Timestep Consumption Time: 2.56609
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.84635

Cumulative Model Updates: 211,238
Cumulative Timesteps: 1,761,702,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.95097
Policy Entropy: 2.19778
Value Function Loss: 0.01883

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.61139

Collected Steps per Second: 21,833.43672
Overall Steps per Second: 10,408.80268

Timestep Collection Time: 2.29034
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.80420

Cumulative Model Updates: 211,244
Cumulative Timesteps: 1,761,752,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1761752188...
Checkpoint 1761752188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.56191
Policy Entropy: 2.18464
Value Function Loss: 0.01891

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.60390

Collected Steps per Second: 22,102.86158
Overall Steps per Second: 10,355.79285

Timestep Collection Time: 2.26233
Timestep Consumption Time: 2.56627
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 4.82860

Cumulative Model Updates: 211,250
Cumulative Timesteps: 1,761,802,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.04133
Policy Entropy: 2.18995
Value Function Loss: 0.01897

Mean KL Divergence: 0.02514
SB3 Clip Fraction: 0.16963
Policy Update Magnitude: 0.53181
Value Function Update Magnitude: 0.60274

Collected Steps per Second: 21,899.81749
Overall Steps per Second: 10,360.61323

Timestep Collection Time: 2.28367
Timestep Consumption Time: 2.54346
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.82713

Cumulative Model Updates: 211,256
Cumulative Timesteps: 1,761,852,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1761852204...
Checkpoint 1761852204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.40137
Policy Entropy: 2.16776
Value Function Loss: 0.01799

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.52034
Value Function Update Magnitude: 0.62245

Collected Steps per Second: 21,459.19249
Overall Steps per Second: 10,214.53880

Timestep Collection Time: 2.33103
Timestep Consumption Time: 2.56611
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.89714

Cumulative Model Updates: 211,262
Cumulative Timesteps: 1,761,902,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.20942
Policy Entropy: 2.17273
Value Function Loss: 0.01839

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 21,839.45135
Overall Steps per Second: 10,389.84930

Timestep Collection Time: 2.29026
Timestep Consumption Time: 2.52386
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.81412

Cumulative Model Updates: 211,268
Cumulative Timesteps: 1,761,952,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1761952244...
Checkpoint 1761952244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.52340
Policy Entropy: 2.16388
Value Function Loss: 0.01820

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.56565
Value Function Update Magnitude: 0.63293

Collected Steps per Second: 21,285.14251
Overall Steps per Second: 10,331.64199

Timestep Collection Time: 2.34953
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.84047

Cumulative Model Updates: 211,274
Cumulative Timesteps: 1,762,002,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.79895
Policy Entropy: 2.18085
Value Function Loss: 0.01808

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.64289

Collected Steps per Second: 22,006.84939
Overall Steps per Second: 10,414.02809

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.53031
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.80333

Cumulative Model Updates: 211,280
Cumulative Timesteps: 1,762,052,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1762052276...
Checkpoint 1762052276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.75789
Policy Entropy: 2.17361
Value Function Loss: 0.01847

Mean KL Divergence: 0.02372
SB3 Clip Fraction: 0.16615
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 21,467.64230
Overall Steps per Second: 10,199.22898

Timestep Collection Time: 2.32983
Timestep Consumption Time: 2.57407
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 4.90390

Cumulative Model Updates: 211,286
Cumulative Timesteps: 1,762,102,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.69688
Policy Entropy: 2.18642
Value Function Loss: 0.01803

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.51188
Value Function Update Magnitude: 0.63222

Collected Steps per Second: 21,699.75640
Overall Steps per Second: 10,383.96396

Timestep Collection Time: 2.30482
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.81647

Cumulative Model Updates: 211,292
Cumulative Timesteps: 1,762,152,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1762152306...
Checkpoint 1762152306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.05187
Policy Entropy: 2.18284
Value Function Loss: 0.01836

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 21,523.45283
Overall Steps per Second: 10,411.16959

Timestep Collection Time: 2.32370
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.80388

Cumulative Model Updates: 211,298
Cumulative Timesteps: 1,762,202,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.50709
Policy Entropy: 2.20089
Value Function Loss: 0.01694

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.63491

Collected Steps per Second: 21,774.75054
Overall Steps per Second: 10,317.67211

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.55135
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.84896

Cumulative Model Updates: 211,304
Cumulative Timesteps: 1,762,252,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1762252350...
Checkpoint 1762252350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.46422
Policy Entropy: 2.20878
Value Function Loss: 0.01689

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.52415
Value Function Update Magnitude: 0.65342

Collected Steps per Second: 21,708.88200
Overall Steps per Second: 10,212.64644

Timestep Collection Time: 2.30339
Timestep Consumption Time: 2.59289
PPO Batch Consumption Time: 0.30339
Total Iteration Time: 4.89628

Cumulative Model Updates: 211,310
Cumulative Timesteps: 1,762,302,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.00550
Policy Entropy: 2.20463
Value Function Loss: 0.01654

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.17945
Policy Update Magnitude: 0.49302
Value Function Update Magnitude: 0.66507

Collected Steps per Second: 21,704.89654
Overall Steps per Second: 10,370.95292

Timestep Collection Time: 2.30473
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.82347

Cumulative Model Updates: 211,316
Cumulative Timesteps: 1,762,352,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1762352378...
Checkpoint 1762352378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.18005
Policy Entropy: 2.21529
Value Function Loss: 0.01640

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.52285
Value Function Update Magnitude: 0.65785

Collected Steps per Second: 21,835.36597
Overall Steps per Second: 10,478.03028

Timestep Collection Time: 2.29078
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.77380

Cumulative Model Updates: 211,322
Cumulative Timesteps: 1,762,402,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.98491
Policy Entropy: 2.21985
Value Function Loss: 0.01607

Mean KL Divergence: 0.02479
SB3 Clip Fraction: 0.17080
Policy Update Magnitude: 0.50996
Value Function Update Magnitude: 0.64148

Collected Steps per Second: 22,171.98751
Overall Steps per Second: 10,323.36603

Timestep Collection Time: 2.25537
Timestep Consumption Time: 2.58859
PPO Batch Consumption Time: 0.30229
Total Iteration Time: 4.84396

Cumulative Model Updates: 211,328
Cumulative Timesteps: 1,762,452,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1762452404...
Checkpoint 1762452404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.47304
Policy Entropy: 2.21009
Value Function Loss: 0.01653

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.17177
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 21,725.89004
Overall Steps per Second: 10,243.01074

Timestep Collection Time: 2.30159
Timestep Consumption Time: 2.58018
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.88177

Cumulative Model Updates: 211,334
Cumulative Timesteps: 1,762,502,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.99186
Policy Entropy: 2.18040
Value Function Loss: 0.01657

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.16430
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.65091

Collected Steps per Second: 21,434.94399
Overall Steps per Second: 10,296.03732

Timestep Collection Time: 2.33367
Timestep Consumption Time: 2.52471
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.85837

Cumulative Model Updates: 211,340
Cumulative Timesteps: 1,762,552,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1762552430...
Checkpoint 1762552430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.50349
Policy Entropy: 2.18014
Value Function Loss: 0.01637

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.15071
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.65585

Collected Steps per Second: 21,686.47671
Overall Steps per Second: 10,283.80764

Timestep Collection Time: 2.30641
Timestep Consumption Time: 2.55735
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.86376

Cumulative Model Updates: 211,346
Cumulative Timesteps: 1,762,602,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.12732
Policy Entropy: 2.19222
Value Function Loss: 0.01703

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.65609

Collected Steps per Second: 21,650.92456
Overall Steps per Second: 10,466.05440

Timestep Collection Time: 2.30974
Timestep Consumption Time: 2.46837
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.77811

Cumulative Model Updates: 211,352
Cumulative Timesteps: 1,762,652,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1762652456...
Checkpoint 1762652456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.01015
Policy Entropy: 2.20818
Value Function Loss: 0.01833

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.56142
Value Function Update Magnitude: 0.66280

Collected Steps per Second: 21,568.02501
Overall Steps per Second: 10,193.49995

Timestep Collection Time: 2.31834
Timestep Consumption Time: 2.58694
PPO Batch Consumption Time: 0.30379
Total Iteration Time: 4.90528

Cumulative Model Updates: 211,358
Cumulative Timesteps: 1,762,702,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.88132
Policy Entropy: 2.18986
Value Function Loss: 0.01783

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.67774

Collected Steps per Second: 21,736.90512
Overall Steps per Second: 10,346.45650

Timestep Collection Time: 2.30060
Timestep Consumption Time: 2.53274
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.83335

Cumulative Model Updates: 211,364
Cumulative Timesteps: 1,762,752,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1762752466...
Checkpoint 1762752466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.28699
Policy Entropy: 2.21160
Value Function Loss: 0.01685

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.65481

Collected Steps per Second: 21,785.33494
Overall Steps per Second: 10,318.43791

Timestep Collection Time: 2.29641
Timestep Consumption Time: 2.55200
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 4.84841

Cumulative Model Updates: 211,370
Cumulative Timesteps: 1,762,802,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.62526
Policy Entropy: 2.19176
Value Function Loss: 0.01641

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.60795

Collected Steps per Second: 21,946.38060
Overall Steps per Second: 10,471.31946

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.77800

Cumulative Model Updates: 211,376
Cumulative Timesteps: 1,762,852,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1762852526...
Checkpoint 1762852526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.49916
Policy Entropy: 2.19490
Value Function Loss: 0.01633

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 21,709.23299
Overall Steps per Second: 10,235.56219

Timestep Collection Time: 2.30418
Timestep Consumption Time: 2.58290
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.88708

Cumulative Model Updates: 211,382
Cumulative Timesteps: 1,762,902,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.36176
Policy Entropy: 2.17881
Value Function Loss: 0.01647

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 21,888.49169
Overall Steps per Second: 10,359.71590

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.82716

Cumulative Model Updates: 211,388
Cumulative Timesteps: 1,762,952,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1762952556...
Checkpoint 1762952556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.84375
Policy Entropy: 2.20757
Value Function Loss: 0.01684

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 21,669.11444
Overall Steps per Second: 10,257.75785

Timestep Collection Time: 2.30835
Timestep Consumption Time: 2.56795
PPO Batch Consumption Time: 0.30223
Total Iteration Time: 4.87631

Cumulative Model Updates: 211,394
Cumulative Timesteps: 1,763,002,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.96678
Policy Entropy: 2.21844
Value Function Loss: 0.01642

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.59638

Collected Steps per Second: 21,641.79647
Overall Steps per Second: 10,487.63740

Timestep Collection Time: 2.31136
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.76962

Cumulative Model Updates: 211,400
Cumulative Timesteps: 1,763,052,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1763052598...
Checkpoint 1763052598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.84208
Policy Entropy: 2.22328
Value Function Loss: 0.01685

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.59857

Collected Steps per Second: 21,872.31322
Overall Steps per Second: 10,316.50370

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.56122
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.84777

Cumulative Model Updates: 211,406
Cumulative Timesteps: 1,763,102,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.56343
Policy Entropy: 2.20303
Value Function Loss: 0.01663

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.61102

Collected Steps per Second: 21,472.79104
Overall Steps per Second: 10,298.94569

Timestep Collection Time: 2.32983
Timestep Consumption Time: 2.52775
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.85758

Cumulative Model Updates: 211,412
Cumulative Timesteps: 1,763,152,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1763152638...
Checkpoint 1763152638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.25866
Policy Entropy: 2.19695
Value Function Loss: 0.01717

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.17775
Policy Update Magnitude: 0.51705
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 21,325.85752
Overall Steps per Second: 10,223.77402

Timestep Collection Time: 2.34570
Timestep Consumption Time: 2.54721
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.89291

Cumulative Model Updates: 211,418
Cumulative Timesteps: 1,763,202,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.99429
Policy Entropy: 2.19163
Value Function Loss: 0.01705

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.16630
Policy Update Magnitude: 0.52644
Value Function Update Magnitude: 0.62161

Collected Steps per Second: 21,927.30641
Overall Steps per Second: 10,489.16876

Timestep Collection Time: 2.28081
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.76797

Cumulative Model Updates: 211,424
Cumulative Timesteps: 1,763,252,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1763252674...
Checkpoint 1763252674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.98794
Policy Entropy: 2.19992
Value Function Loss: 0.01739

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.55259
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 21,041.06322
Overall Steps per Second: 10,225.08723

Timestep Collection Time: 2.37745
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.89228

Cumulative Model Updates: 211,430
Cumulative Timesteps: 1,763,302,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.46970
Policy Entropy: 2.19203
Value Function Loss: 0.01700

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.59065

Collected Steps per Second: 21,488.90204
Overall Steps per Second: 10,296.16366

Timestep Collection Time: 2.32725
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.85715

Cumulative Model Updates: 211,436
Cumulative Timesteps: 1,763,352,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1763352708...
Checkpoint 1763352708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.75949
Policy Entropy: 2.18323
Value Function Loss: 0.01624

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.59168

Collected Steps per Second: 21,540.08694
Overall Steps per Second: 10,293.14032

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.53777
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.86032

Cumulative Model Updates: 211,442
Cumulative Timesteps: 1,763,402,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.61477
Policy Entropy: 2.16817
Value Function Loss: 0.01522

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.53785
Value Function Update Magnitude: 0.58494

Collected Steps per Second: 21,478.10053
Overall Steps per Second: 10,279.66074

Timestep Collection Time: 2.32898
Timestep Consumption Time: 2.53714
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.86611

Cumulative Model Updates: 211,448
Cumulative Timesteps: 1,763,452,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1763452758...
Checkpoint 1763452758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.76400
Policy Entropy: 2.14801
Value Function Loss: 0.01488

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.57969

Collected Steps per Second: 21,224.78135
Overall Steps per Second: 10,430.99763

Timestep Collection Time: 2.35583
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.79360

Cumulative Model Updates: 211,454
Cumulative Timesteps: 1,763,502,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.88334
Policy Entropy: 2.14431
Value Function Loss: 0.01532

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.56810

Collected Steps per Second: 21,950.59413
Overall Steps per Second: 10,380.79071

Timestep Collection Time: 2.27802
Timestep Consumption Time: 2.53895
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.81697

Cumulative Model Updates: 211,460
Cumulative Timesteps: 1,763,552,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1763552764...
Checkpoint 1763552764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.94595
Policy Entropy: 2.16966
Value Function Loss: 0.01540

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.56492

Collected Steps per Second: 21,671.64618
Overall Steps per Second: 10,278.11646

Timestep Collection Time: 2.30762
Timestep Consumption Time: 2.55805
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.86568

Cumulative Model Updates: 211,466
Cumulative Timesteps: 1,763,602,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.60977
Policy Entropy: 2.19360
Value Function Loss: 0.01546

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.56717

Collected Steps per Second: 21,661.09423
Overall Steps per Second: 10,419.82163

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79931

Cumulative Model Updates: 211,472
Cumulative Timesteps: 1,763,652,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1763652782...
Checkpoint 1763652782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.68641
Policy Entropy: 2.19413
Value Function Loss: 0.01577

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.56596

Collected Steps per Second: 21,562.67146
Overall Steps per Second: 10,408.99962

Timestep Collection Time: 2.31910
Timestep Consumption Time: 2.48501
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.80411

Cumulative Model Updates: 211,478
Cumulative Timesteps: 1,763,702,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.53173
Policy Entropy: 2.18640
Value Function Loss: 0.01631

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 22,086.58235
Overall Steps per Second: 10,289.88801

Timestep Collection Time: 2.26454
Timestep Consumption Time: 2.59615
PPO Batch Consumption Time: 0.30373
Total Iteration Time: 4.86069

Cumulative Model Updates: 211,484
Cumulative Timesteps: 1,763,752,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1763752804...
Checkpoint 1763752804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.62151
Policy Entropy: 2.17978
Value Function Loss: 0.01613

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.57342

Collected Steps per Second: 21,513.43437
Overall Steps per Second: 10,194.31993

Timestep Collection Time: 2.32534
Timestep Consumption Time: 2.58190
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.90724

Cumulative Model Updates: 211,490
Cumulative Timesteps: 1,763,802,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.09158
Policy Entropy: 2.17364
Value Function Loss: 0.01668

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.59214

Collected Steps per Second: 21,960.21706
Overall Steps per Second: 10,396.37505

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.53263
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.80956

Cumulative Model Updates: 211,496
Cumulative Timesteps: 1,763,852,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1763852832...
Checkpoint 1763852832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.68401
Policy Entropy: 2.16737
Value Function Loss: 0.01727

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.63145

Collected Steps per Second: 21,601.90907
Overall Steps per Second: 10,292.29848

Timestep Collection Time: 2.31665
Timestep Consumption Time: 2.54563
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.86228

Cumulative Model Updates: 211,502
Cumulative Timesteps: 1,763,902,876

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.94297
Policy Entropy: 2.17481
Value Function Loss: 0.01771

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 21,850.16566
Overall Steps per Second: 10,452.96488

Timestep Collection Time: 2.28868
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 4.78410

Cumulative Model Updates: 211,508
Cumulative Timesteps: 1,763,952,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1763952884...
Checkpoint 1763952884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.27514
Policy Entropy: 2.18960
Value Function Loss: 0.01760

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.64437

Collected Steps per Second: 21,606.41813
Overall Steps per Second: 10,195.56894

Timestep Collection Time: 2.31440
Timestep Consumption Time: 2.59027
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.90468

Cumulative Model Updates: 211,514
Cumulative Timesteps: 1,764,002,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.21733
Policy Entropy: 2.19710
Value Function Loss: 0.01783

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.65172

Collected Steps per Second: 22,093.07804
Overall Steps per Second: 10,469.07425

Timestep Collection Time: 2.26460
Timestep Consumption Time: 2.51443
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.77903

Cumulative Model Updates: 211,520
Cumulative Timesteps: 1,764,052,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1764052922...
Checkpoint 1764052922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.71979
Policy Entropy: 2.19365
Value Function Loss: 0.01741

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.56153
Value Function Update Magnitude: 0.64968

Collected Steps per Second: 21,176.22365
Overall Steps per Second: 10,206.94239

Timestep Collection Time: 2.36208
Timestep Consumption Time: 2.53850
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.90059

Cumulative Model Updates: 211,526
Cumulative Timesteps: 1,764,102,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.17705
Policy Entropy: 2.18564
Value Function Loss: 0.01740

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.62482

Collected Steps per Second: 21,929.86783
Overall Steps per Second: 10,444.19509

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.78850

Cumulative Model Updates: 211,532
Cumulative Timesteps: 1,764,152,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1764152954...
Checkpoint 1764152954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.56328
Policy Entropy: 2.20002
Value Function Loss: 0.01686

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.57210

Collected Steps per Second: 21,654.69082
Overall Steps per Second: 10,203.83576

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.59177
PPO Batch Consumption Time: 0.30369
Total Iteration Time: 4.90129

Cumulative Model Updates: 211,538
Cumulative Timesteps: 1,764,202,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.74509
Policy Entropy: 2.17906
Value Function Loss: 0.01762

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.57071

Collected Steps per Second: 21,805.04255
Overall Steps per Second: 10,343.58869

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.54097
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.83411

Cumulative Model Updates: 211,544
Cumulative Timesteps: 1,764,252,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1764252968...
Checkpoint 1764252968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.80787
Policy Entropy: 2.18706
Value Function Loss: 0.01686

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 21,736.54345
Overall Steps per Second: 10,328.94799

Timestep Collection Time: 2.30165
Timestep Consumption Time: 2.54201
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.84367

Cumulative Model Updates: 211,550
Cumulative Timesteps: 1,764,302,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.23321
Policy Entropy: 2.15984
Value Function Loss: 0.01661

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.62456

Collected Steps per Second: 21,964.47695
Overall Steps per Second: 10,431.86485

Timestep Collection Time: 2.27649
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.79320

Cumulative Model Updates: 211,556
Cumulative Timesteps: 1,764,353,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1764353000...
Checkpoint 1764353000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.77574
Policy Entropy: 2.15510
Value Function Loss: 0.01665

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 21,602.31745
Overall Steps per Second: 10,205.66090

Timestep Collection Time: 2.31503
Timestep Consumption Time: 2.58519
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.90022

Cumulative Model Updates: 211,562
Cumulative Timesteps: 1,764,403,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.69848
Policy Entropy: 2.16604
Value Function Loss: 0.01700

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.58436

Collected Steps per Second: 21,913.49678
Overall Steps per Second: 10,395.18306

Timestep Collection Time: 2.28179
Timestep Consumption Time: 2.52832
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.81011

Cumulative Model Updates: 211,568
Cumulative Timesteps: 1,764,453,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1764453012...
Checkpoint 1764453012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.68713
Policy Entropy: 2.17555
Value Function Loss: 0.01786

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.59455

Collected Steps per Second: 21,826.81887
Overall Steps per Second: 10,308.24568

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.56095
PPO Batch Consumption Time: 0.30440
Total Iteration Time: 4.85281

Cumulative Model Updates: 211,574
Cumulative Timesteps: 1,764,503,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.98992
Policy Entropy: 2.20031
Value Function Loss: 0.01737

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 22,022.49622
Overall Steps per Second: 10,461.81653

Timestep Collection Time: 2.27177
Timestep Consumption Time: 2.51038
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 4.78215

Cumulative Model Updates: 211,580
Cumulative Timesteps: 1,764,553,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1764553066...
Checkpoint 1764553066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.37042
Policy Entropy: 2.17703
Value Function Loss: 0.01729

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.61096

Collected Steps per Second: 21,660.80523
Overall Steps per Second: 10,214.79207

Timestep Collection Time: 2.30896
Timestep Consumption Time: 2.58727
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.89623

Cumulative Model Updates: 211,586
Cumulative Timesteps: 1,764,603,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.38194
Policy Entropy: 2.16538
Value Function Loss: 0.01751

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 21,775.92681
Overall Steps per Second: 10,387.19253

Timestep Collection Time: 2.29648
Timestep Consumption Time: 2.51791
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.81439

Cumulative Model Updates: 211,592
Cumulative Timesteps: 1,764,653,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1764653088...
Checkpoint 1764653088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.83575
Policy Entropy: 2.15405
Value Function Loss: 0.01784

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.55922
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 21,424.42532
Overall Steps per Second: 10,256.77851

Timestep Collection Time: 2.33472
Timestep Consumption Time: 2.54206
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.87677

Cumulative Model Updates: 211,598
Cumulative Timesteps: 1,764,703,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.02345
Policy Entropy: 2.15781
Value Function Loss: 0.01750

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.63271

Collected Steps per Second: 21,913.86745
Overall Steps per Second: 10,452.85414

Timestep Collection Time: 2.28285
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.78587

Cumulative Model Updates: 211,604
Cumulative Timesteps: 1,764,753,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1764753134...
Checkpoint 1764753134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.73903
Policy Entropy: 2.16847
Value Function Loss: 0.01822

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.61953

Collected Steps per Second: 21,771.01040
Overall Steps per Second: 10,244.72536

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.58434
PPO Batch Consumption Time: 0.30462
Total Iteration Time: 4.88134

Cumulative Model Updates: 211,610
Cumulative Timesteps: 1,764,803,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.77824
Policy Entropy: 2.19514
Value Function Loss: 0.01842

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.62908

Collected Steps per Second: 21,920.11670
Overall Steps per Second: 10,387.25752

Timestep Collection Time: 2.28247
Timestep Consumption Time: 2.53420
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.81667

Cumulative Model Updates: 211,616
Cumulative Timesteps: 1,764,853,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1764853174...
Checkpoint 1764853174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.50841
Policy Entropy: 2.19577
Value Function Loss: 0.01795

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.62210

Collected Steps per Second: 21,717.06200
Overall Steps per Second: 10,245.25611

Timestep Collection Time: 2.30252
Timestep Consumption Time: 2.57818
PPO Batch Consumption Time: 0.30194
Total Iteration Time: 4.88070

Cumulative Model Updates: 211,622
Cumulative Timesteps: 1,764,903,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.18221
Policy Entropy: 2.16943
Value Function Loss: 0.01765

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.16319
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.61030

Collected Steps per Second: 21,825.64215
Overall Steps per Second: 10,426.01720

Timestep Collection Time: 2.29207
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.79819

Cumulative Model Updates: 211,628
Cumulative Timesteps: 1,764,953,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1764953204...
Checkpoint 1764953204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.10052
Policy Entropy: 2.14997
Value Function Loss: 0.01821

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.17533
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 21,712.91612
Overall Steps per Second: 10,558.33860

Timestep Collection Time: 2.30342
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.73692

Cumulative Model Updates: 211,634
Cumulative Timesteps: 1,765,003,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.93797
Policy Entropy: 2.13161
Value Function Loss: 0.01843

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.16446
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.64630

Collected Steps per Second: 21,759.19654
Overall Steps per Second: 10,233.52060

Timestep Collection Time: 2.29871
Timestep Consumption Time: 2.58896
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.88766

Cumulative Model Updates: 211,640
Cumulative Timesteps: 1,765,053,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1765053236...
Checkpoint 1765053236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.96221
Policy Entropy: 2.15978
Value Function Loss: 0.01730

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.18081
Policy Update Magnitude: 0.55238
Value Function Update Magnitude: 0.63219

Collected Steps per Second: 21,822.27567
Overall Steps per Second: 10,293.36078

Timestep Collection Time: 2.29133
Timestep Consumption Time: 2.56637
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.85769

Cumulative Model Updates: 211,646
Cumulative Timesteps: 1,765,103,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.07959
Policy Entropy: 2.16582
Value Function Loss: 0.01603

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.17200
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 21,926.34728
Overall Steps per Second: 10,306.72339

Timestep Collection Time: 2.28173
Timestep Consumption Time: 2.57238
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 4.85411

Cumulative Model Updates: 211,652
Cumulative Timesteps: 1,765,153,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1765153268...
Checkpoint 1765153268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.94230
Policy Entropy: 2.20429
Value Function Loss: 0.01562

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 21,789.40701
Overall Steps per Second: 10,335.01342

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.54333
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.83812

Cumulative Model Updates: 211,658
Cumulative Timesteps: 1,765,203,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.05387
Policy Entropy: 2.20035
Value Function Loss: 0.01569

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.17501
Policy Update Magnitude: 0.49901
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 22,567.72223
Overall Steps per Second: 10,456.79775

Timestep Collection Time: 2.21644
Timestep Consumption Time: 2.56705
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.78349

Cumulative Model Updates: 211,664
Cumulative Timesteps: 1,765,253,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1765253290...
Checkpoint 1765253290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.22833
Policy Entropy: 2.18549
Value Function Loss: 0.01702

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.17164
Policy Update Magnitude: 0.50087
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 21,927.84560
Overall Steps per Second: 10,426.49598

Timestep Collection Time: 2.28057
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.79624

Cumulative Model Updates: 211,670
Cumulative Timesteps: 1,765,303,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.14689
Policy Entropy: 2.15143
Value Function Loss: 0.01766

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.18244
Policy Update Magnitude: 0.51984
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 21,690.43007
Overall Steps per Second: 10,250.93283

Timestep Collection Time: 2.30563
Timestep Consumption Time: 2.57296
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.87858

Cumulative Model Updates: 211,676
Cumulative Timesteps: 1,765,353,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1765353308...
Checkpoint 1765353308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.78535
Policy Entropy: 2.16137
Value Function Loss: 0.01809

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.16784
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.60449

Collected Steps per Second: 21,754.15638
Overall Steps per Second: 10,398.31469

Timestep Collection Time: 2.29979
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.81136

Cumulative Model Updates: 211,682
Cumulative Timesteps: 1,765,403,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.43121
Policy Entropy: 2.16758
Value Function Loss: 0.01694

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 21,693.06268
Overall Steps per Second: 10,554.33094

Timestep Collection Time: 2.30525
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.73815

Cumulative Model Updates: 211,688
Cumulative Timesteps: 1,765,453,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1765453346...
Checkpoint 1765453346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.17487
Policy Entropy: 2.19576
Value Function Loss: 0.01630

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 21,877.84916
Overall Steps per Second: 10,308.47379

Timestep Collection Time: 2.28642
Timestep Consumption Time: 2.56609
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.85251

Cumulative Model Updates: 211,694
Cumulative Timesteps: 1,765,503,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.89348
Policy Entropy: 2.18727
Value Function Loss: 0.01583

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.62355

Collected Steps per Second: 21,885.93728
Overall Steps per Second: 10,332.16060

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.55602
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.84178

Cumulative Model Updates: 211,700
Cumulative Timesteps: 1,765,553,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1765553394...
Checkpoint 1765553394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.89329
Policy Entropy: 2.18636
Value Function Loss: 0.01681

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 20,346.55630
Overall Steps per Second: 10,062.61151

Timestep Collection Time: 2.45771
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.96949

Cumulative Model Updates: 211,706
Cumulative Timesteps: 1,765,603,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.99232
Policy Entropy: 2.17376
Value Function Loss: 0.01724

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.18046
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.62462

Collected Steps per Second: 21,891.26103
Overall Steps per Second: 10,547.61820

Timestep Collection Time: 2.28456
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74154

Cumulative Model Updates: 211,712
Cumulative Timesteps: 1,765,653,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1765653412...
Checkpoint 1765653412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.95604
Policy Entropy: 2.18597
Value Function Loss: 0.01744

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.16456
Policy Update Magnitude: 0.56262
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 21,829.39726
Overall Steps per Second: 10,251.34681

Timestep Collection Time: 2.29067
Timestep Consumption Time: 2.58713
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.87780

Cumulative Model Updates: 211,718
Cumulative Timesteps: 1,765,703,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.27534
Policy Entropy: 2.19690
Value Function Loss: 0.01820

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16495
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.63215

Collected Steps per Second: 21,677.24122
Overall Steps per Second: 10,341.75296

Timestep Collection Time: 2.30749
Timestep Consumption Time: 2.52921
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.83670

Cumulative Model Updates: 211,724
Cumulative Timesteps: 1,765,753,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1765753436...
Checkpoint 1765753436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.07614
Policy Entropy: 2.18839
Value Function Loss: 0.01825

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.64556

Collected Steps per Second: 21,970.61681
Overall Steps per Second: 10,321.04488

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.56942
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.84583

Cumulative Model Updates: 211,730
Cumulative Timesteps: 1,765,803,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.17291
Policy Entropy: 2.20444
Value Function Loss: 0.01878

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.64902

Collected Steps per Second: 21,560.77826
Overall Steps per Second: 10,351.08274

Timestep Collection Time: 2.31986
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.83215

Cumulative Model Updates: 211,736
Cumulative Timesteps: 1,765,853,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1765853468...
Checkpoint 1765853468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.36190
Policy Entropy: 2.21717
Value Function Loss: 0.01754

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.57037
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 21,989.62771
Overall Steps per Second: 10,487.18846

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.76810

Cumulative Model Updates: 211,742
Cumulative Timesteps: 1,765,903,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.13946
Policy Entropy: 2.23390
Value Function Loss: 0.01694

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.61698

Collected Steps per Second: 21,844.43075
Overall Steps per Second: 10,282.74231

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.57391
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.86310

Cumulative Model Updates: 211,748
Cumulative Timesteps: 1,765,953,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1765953478...
Checkpoint 1765953478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.20694
Policy Entropy: 2.22174
Value Function Loss: 0.01661

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.59641

Collected Steps per Second: 21,711.15200
Overall Steps per Second: 10,210.91819

Timestep Collection Time: 2.30379
Timestep Consumption Time: 2.59469
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.89848

Cumulative Model Updates: 211,754
Cumulative Timesteps: 1,766,003,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.88065
Policy Entropy: 2.23393
Value Function Loss: 0.01661

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 22,007.75786
Overall Steps per Second: 10,410.14671

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.53118
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.80320

Cumulative Model Updates: 211,760
Cumulative Timesteps: 1,766,053,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1766053498...
Checkpoint 1766053498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.31493
Policy Entropy: 2.24561
Value Function Loss: 0.01779

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 21,634.82559
Overall Steps per Second: 10,260.92278

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.56187
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 4.87305

Cumulative Model Updates: 211,766
Cumulative Timesteps: 1,766,103,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.91206
Policy Entropy: 2.23459
Value Function Loss: 0.01766

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.57078

Collected Steps per Second: 22,069.82560
Overall Steps per Second: 10,456.41418

Timestep Collection Time: 2.26635
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.78348

Cumulative Model Updates: 211,772
Cumulative Timesteps: 1,766,153,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1766153518...
Checkpoint 1766153518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.91337
Policy Entropy: 2.21211
Value Function Loss: 0.01780

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.54920
Value Function Update Magnitude: 0.56683

Collected Steps per Second: 21,753.32760
Overall Steps per Second: 10,231.02976

Timestep Collection Time: 2.29960
Timestep Consumption Time: 2.58984
PPO Batch Consumption Time: 0.30349
Total Iteration Time: 4.88944

Cumulative Model Updates: 211,778
Cumulative Timesteps: 1,766,203,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.76649
Policy Entropy: 2.19588
Value Function Loss: 0.01714

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 22,135.96527
Overall Steps per Second: 10,437.31463

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.53204
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.79108

Cumulative Model Updates: 211,784
Cumulative Timesteps: 1,766,253,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1766253548...
Checkpoint 1766253548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.88386
Policy Entropy: 2.23109
Value Function Loss: 0.01732

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.56377

Collected Steps per Second: 21,517.23796
Overall Steps per Second: 10,183.47227

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.58765
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 4.91267

Cumulative Model Updates: 211,790
Cumulative Timesteps: 1,766,303,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.74528
Policy Entropy: 2.25190
Value Function Loss: 0.01700

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.57932

Collected Steps per Second: 22,096.08776
Overall Steps per Second: 10,453.70702

Timestep Collection Time: 2.26339
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.78414

Cumulative Model Updates: 211,796
Cumulative Timesteps: 1,766,353,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1766353588...
Checkpoint 1766353588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.70279
Policy Entropy: 2.23878
Value Function Loss: 0.01625

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.53602
Value Function Update Magnitude: 0.57927

Collected Steps per Second: 21,584.34439
Overall Steps per Second: 10,510.02204

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.75927

Cumulative Model Updates: 211,802
Cumulative Timesteps: 1,766,403,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.70189
Policy Entropy: 2.23120
Value Function Loss: 0.01576

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.58236

Collected Steps per Second: 22,339.49721
Overall Steps per Second: 10,509.12560

Timestep Collection Time: 2.23935
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.76024

Cumulative Model Updates: 211,808
Cumulative Timesteps: 1,766,453,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1766453634...
Checkpoint 1766453634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.10724
Policy Entropy: 2.22453
Value Function Loss: 0.01653

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 21,860.26071
Overall Steps per Second: 10,273.85095

Timestep Collection Time: 2.28753
Timestep Consumption Time: 2.57978
PPO Batch Consumption Time: 0.30224
Total Iteration Time: 4.86731

Cumulative Model Updates: 211,814
Cumulative Timesteps: 1,766,503,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.69856
Policy Entropy: 2.21958
Value Function Loss: 0.01657

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.58267

Collected Steps per Second: 21,936.81008
Overall Steps per Second: 10,413.28357

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.52319
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.80329

Cumulative Model Updates: 211,820
Cumulative Timesteps: 1,766,553,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1766553658...
Checkpoint 1766553658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.98824
Policy Entropy: 2.18795
Value Function Loss: 0.01717

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.58396

Collected Steps per Second: 21,404.61355
Overall Steps per Second: 10,256.50493

Timestep Collection Time: 2.33595
Timestep Consumption Time: 2.53901
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.87496

Cumulative Model Updates: 211,826
Cumulative Timesteps: 1,766,603,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.98088
Policy Entropy: 2.19590
Value Function Loss: 0.01572

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.55121
Value Function Update Magnitude: 0.57895

Collected Steps per Second: 22,102.81405
Overall Steps per Second: 10,475.52383

Timestep Collection Time: 2.26342
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.30434
Total Iteration Time: 4.77570

Cumulative Model Updates: 211,832
Cumulative Timesteps: 1,766,653,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1766653686...
Checkpoint 1766653686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.69780
Policy Entropy: 2.19515
Value Function Loss: 0.01600

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.57979

Collected Steps per Second: 21,780.51343
Overall Steps per Second: 10,209.23586

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.60273
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 4.89909

Cumulative Model Updates: 211,838
Cumulative Timesteps: 1,766,703,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.28408
Policy Entropy: 2.22304
Value Function Loss: 0.01603

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.56354

Collected Steps per Second: 22,368.77382
Overall Steps per Second: 10,460.45818

Timestep Collection Time: 2.23642
Timestep Consumption Time: 2.54597
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.78239

Cumulative Model Updates: 211,844
Cumulative Timesteps: 1,766,753,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1766753728...
Checkpoint 1766753728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.03037
Policy Entropy: 2.21169
Value Function Loss: 0.01613

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.53674
Value Function Update Magnitude: 0.55345

Collected Steps per Second: 21,443.23639
Overall Steps per Second: 10,240.34490

Timestep Collection Time: 2.33258
Timestep Consumption Time: 2.55183
PPO Batch Consumption Time: 0.30433
Total Iteration Time: 4.88441

Cumulative Model Updates: 211,850
Cumulative Timesteps: 1,766,803,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.64724
Policy Entropy: 2.20503
Value Function Loss: 0.01633

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.55770

Collected Steps per Second: 21,948.84161
Overall Steps per Second: 10,444.79514

Timestep Collection Time: 2.27912
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.78937

Cumulative Model Updates: 211,856
Cumulative Timesteps: 1,766,853,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1766853770...
Checkpoint 1766853770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.79836
Policy Entropy: 2.21755
Value Function Loss: 0.01638

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.57169

Collected Steps per Second: 21,605.05931
Overall Steps per Second: 10,178.10814

Timestep Collection Time: 2.31538
Timestep Consumption Time: 2.59948
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.91486

Cumulative Model Updates: 211,862
Cumulative Timesteps: 1,766,903,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.65937
Policy Entropy: 2.24126
Value Function Loss: 0.01605

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.58456

Collected Steps per Second: 22,226.46546
Overall Steps per Second: 10,448.40948

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.53676
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.78714

Cumulative Model Updates: 211,868
Cumulative Timesteps: 1,766,953,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1766953812...
Checkpoint 1766953812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.28469
Policy Entropy: 2.25505
Value Function Loss: 0.01655

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.58852

Collected Steps per Second: 21,600.60295
Overall Steps per Second: 10,251.05640

Timestep Collection Time: 2.31568
Timestep Consumption Time: 2.56382
PPO Batch Consumption Time: 0.30532
Total Iteration Time: 4.87950

Cumulative Model Updates: 211,874
Cumulative Timesteps: 1,767,003,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.48307
Policy Entropy: 2.22561
Value Function Loss: 0.01680

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.60025

Collected Steps per Second: 21,963.70851
Overall Steps per Second: 10,452.44782

Timestep Collection Time: 2.27758
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.30510
Total Iteration Time: 4.78586

Cumulative Model Updates: 211,880
Cumulative Timesteps: 1,767,053,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1767053856...
Checkpoint 1767053856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.28928
Policy Entropy: 2.20641
Value Function Loss: 0.01660

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.60421

Collected Steps per Second: 21,519.62885
Overall Steps per Second: 10,200.56508

Timestep Collection Time: 2.32383
Timestep Consumption Time: 2.57864
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.90247

Cumulative Model Updates: 211,886
Cumulative Timesteps: 1,767,103,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.54770
Policy Entropy: 2.19577
Value Function Loss: 0.01673

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.60973

Collected Steps per Second: 22,108.59730
Overall Steps per Second: 10,418.95752

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.53860
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.80125

Cumulative Model Updates: 211,892
Cumulative Timesteps: 1,767,153,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1767153888...
Checkpoint 1767153888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.41043
Policy Entropy: 2.21255
Value Function Loss: 0.01660

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.60438

Collected Steps per Second: 21,574.45297
Overall Steps per Second: 10,242.20233

Timestep Collection Time: 2.31904
Timestep Consumption Time: 2.56585
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.88489

Cumulative Model Updates: 211,898
Cumulative Timesteps: 1,767,203,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.36925
Policy Entropy: 2.21491
Value Function Loss: 0.01743

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.62885

Collected Steps per Second: 21,827.97202
Overall Steps per Second: 10,400.02470

Timestep Collection Time: 2.29201
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.81057

Cumulative Model Updates: 211,904
Cumulative Timesteps: 1,767,253,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1767253950...
Checkpoint 1767253950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.08638
Policy Entropy: 2.20071
Value Function Loss: 0.01609

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.63484

Collected Steps per Second: 19,054.27413
Overall Steps per Second: 9,797.22640

Timestep Collection Time: 2.62513
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 5.10553

Cumulative Model Updates: 211,910
Cumulative Timesteps: 1,767,303,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.93237
Policy Entropy: 2.17705
Value Function Loss: 0.01624

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.61731

Collected Steps per Second: 21,132.86022
Overall Steps per Second: 10,120.10539

Timestep Collection Time: 2.36702
Timestep Consumption Time: 2.57581
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.94283

Cumulative Model Updates: 211,916
Cumulative Timesteps: 1,767,353,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1767353992...
Checkpoint 1767353992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.59780
Policy Entropy: 2.17681
Value Function Loss: 0.01667

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.60551

Collected Steps per Second: 21,573.54509
Overall Steps per Second: 10,203.59396

Timestep Collection Time: 2.31775
Timestep Consumption Time: 2.58268
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.90043

Cumulative Model Updates: 211,922
Cumulative Timesteps: 1,767,403,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.25504
Policy Entropy: 2.17347
Value Function Loss: 0.01816

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 21,741.22054
Overall Steps per Second: 10,415.33209

Timestep Collection Time: 2.30070
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80254

Cumulative Model Updates: 211,928
Cumulative Timesteps: 1,767,454,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1767454014...
Checkpoint 1767454014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.91693
Policy Entropy: 2.19276
Value Function Loss: 0.01734

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.63090

Collected Steps per Second: 21,637.42440
Overall Steps per Second: 10,264.41992

Timestep Collection Time: 2.31201
Timestep Consumption Time: 2.56172
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 4.87373

Cumulative Model Updates: 211,934
Cumulative Timesteps: 1,767,504,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.55940
Policy Entropy: 2.20922
Value Function Loss: 0.01669

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.55125
Value Function Update Magnitude: 0.62753

Collected Steps per Second: 22,466.38294
Overall Steps per Second: 10,468.42520

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.55215
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.77894

Cumulative Model Updates: 211,940
Cumulative Timesteps: 1,767,554,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1767554068...
Checkpoint 1767554068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.77914
Policy Entropy: 2.21420
Value Function Loss: 0.01646

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.61623

Collected Steps per Second: 21,719.91387
Overall Steps per Second: 10,218.94893

Timestep Collection Time: 2.30259
Timestep Consumption Time: 2.59146
PPO Batch Consumption Time: 0.30459
Total Iteration Time: 4.89405

Cumulative Model Updates: 211,946
Cumulative Timesteps: 1,767,604,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.42392
Policy Entropy: 2.21281
Value Function Loss: 0.01675

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.55258
Value Function Update Magnitude: 0.60487

Collected Steps per Second: 21,348.95274
Overall Steps per Second: 10,156.65739

Timestep Collection Time: 2.34232
Timestep Consumption Time: 2.58115
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.92347

Cumulative Model Updates: 211,952
Cumulative Timesteps: 1,767,654,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1767654086...
Checkpoint 1767654086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.78374
Policy Entropy: 2.15580
Value Function Loss: 0.01754

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.56290
Value Function Update Magnitude: 0.59189

Collected Steps per Second: 21,657.26593
Overall Steps per Second: 10,419.19507

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.49034
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.79922

Cumulative Model Updates: 211,958
Cumulative Timesteps: 1,767,704,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.56554
Policy Entropy: 2.16274
Value Function Loss: 0.01723

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.56812
Value Function Update Magnitude: 0.58272

Collected Steps per Second: 22,038.00465
Overall Steps per Second: 10,519.86556

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.75348

Cumulative Model Updates: 211,964
Cumulative Timesteps: 1,767,754,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1767754096...
Checkpoint 1767754096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.31325
Policy Entropy: 2.16945
Value Function Loss: 0.01673

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.56067

Collected Steps per Second: 21,655.82000
Overall Steps per Second: 10,208.94938

Timestep Collection Time: 2.30996
Timestep Consumption Time: 2.59006
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.90001

Cumulative Model Updates: 211,970
Cumulative Timesteps: 1,767,804,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.04766
Policy Entropy: 2.21653
Value Function Loss: 0.01598

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 21,534.86610
Overall Steps per Second: 10,244.02722

Timestep Collection Time: 2.32200
Timestep Consumption Time: 2.55928
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.88128

Cumulative Model Updates: 211,976
Cumulative Timesteps: 1,767,854,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1767854124...
Checkpoint 1767854124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.63120
Policy Entropy: 2.18514
Value Function Loss: 0.01660

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.55628

Collected Steps per Second: 21,873.72045
Overall Steps per Second: 10,428.40863

Timestep Collection Time: 2.28695
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.79690

Cumulative Model Updates: 211,982
Cumulative Timesteps: 1,767,904,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.45130
Policy Entropy: 2.18449
Value Function Loss: 0.01757

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.56735

Collected Steps per Second: 22,069.94143
Overall Steps per Second: 10,450.92738

Timestep Collection Time: 2.26589
Timestep Consumption Time: 2.51914
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.78503

Cumulative Model Updates: 211,988
Cumulative Timesteps: 1,767,954,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1767954156...
Checkpoint 1767954156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.98466
Policy Entropy: 2.19262
Value Function Loss: 0.01809

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.57958

Collected Steps per Second: 21,763.22117
Overall Steps per Second: 10,556.74417

Timestep Collection Time: 2.29856
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.73858

Cumulative Model Updates: 211,994
Cumulative Timesteps: 1,768,004,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.99298
Policy Entropy: 2.21018
Value Function Loss: 0.01702

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.58793

Collected Steps per Second: 22,225.69891
Overall Steps per Second: 10,491.51313

Timestep Collection Time: 2.25055
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.76766

Cumulative Model Updates: 212,000
Cumulative Timesteps: 1,768,054,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1768054200...
Checkpoint 1768054200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.08937
Policy Entropy: 2.19880
Value Function Loss: 0.01613

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.57993

Collected Steps per Second: 21,814.93469
Overall Steps per Second: 10,264.12491

Timestep Collection Time: 2.29237
Timestep Consumption Time: 2.57974
PPO Batch Consumption Time: 0.30144
Total Iteration Time: 4.87212

Cumulative Model Updates: 212,006
Cumulative Timesteps: 1,768,104,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.18807
Policy Entropy: 2.17395
Value Function Loss: 0.01590

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.56015

Collected Steps per Second: 21,546.91512
Overall Steps per Second: 10,366.65346

Timestep Collection Time: 2.32098
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.82412

Cumulative Model Updates: 212,012
Cumulative Timesteps: 1,768,154,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1768154218...
Checkpoint 1768154218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.09798
Policy Entropy: 2.16203
Value Function Loss: 0.01653

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.54992

Collected Steps per Second: 22,205.58985
Overall Steps per Second: 10,618.02374

Timestep Collection Time: 2.25304
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71180

Cumulative Model Updates: 212,018
Cumulative Timesteps: 1,768,204,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.54394
Policy Entropy: 2.15533
Value Function Loss: 0.01748

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54584
Value Function Update Magnitude: 0.56864

Collected Steps per Second: 22,017.62871
Overall Steps per Second: 10,337.14625

Timestep Collection Time: 2.27245
Timestep Consumption Time: 2.56776
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.84021

Cumulative Model Updates: 212,024
Cumulative Timesteps: 1,768,254,282

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1768254282...
Checkpoint 1768254282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.76624
Policy Entropy: 2.17736
Value Function Loss: 0.01766

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.59255

Collected Steps per Second: 22,213.89054
Overall Steps per Second: 10,451.47658

Timestep Collection Time: 2.25111
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.78459

Cumulative Model Updates: 212,030
Cumulative Timesteps: 1,768,304,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.58057
Policy Entropy: 2.18406
Value Function Loss: 0.01779

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.60482

Collected Steps per Second: 21,717.94002
Overall Steps per Second: 10,395.57419

Timestep Collection Time: 2.30344
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.81224

Cumulative Model Updates: 212,036
Cumulative Timesteps: 1,768,354,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1768354314...
Checkpoint 1768354314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.61618
Policy Entropy: 2.18377
Value Function Loss: 0.01625

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 21,795.06296
Overall Steps per Second: 10,555.34320

Timestep Collection Time: 2.29492
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.73864

Cumulative Model Updates: 212,042
Cumulative Timesteps: 1,768,404,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.12325
Policy Entropy: 2.18746
Value Function Loss: 0.01723

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 22,250.48471
Overall Steps per Second: 10,464.03614

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.53224
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.78037

Cumulative Model Updates: 212,048
Cumulative Timesteps: 1,768,454,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1768454354...
Checkpoint 1768454354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.98557
Policy Entropy: 2.19826
Value Function Loss: 0.01701

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.61565

Collected Steps per Second: 22,064.90760
Overall Steps per Second: 10,337.81117

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.57139
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.83816

Cumulative Model Updates: 212,054
Cumulative Timesteps: 1,768,504,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.42039
Policy Entropy: 2.23003
Value Function Loss: 0.01717

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.52417
Value Function Update Magnitude: 0.59327

Collected Steps per Second: 21,603.68472
Overall Steps per Second: 10,366.36732

Timestep Collection Time: 2.31442
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.82329

Cumulative Model Updates: 212,060
Cumulative Timesteps: 1,768,554,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1768554370...
Checkpoint 1768554370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.18671
Policy Entropy: 2.22837
Value Function Loss: 0.01661

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.52109
Value Function Update Magnitude: 0.56583

Collected Steps per Second: 21,949.61548
Overall Steps per Second: 10,575.64998

Timestep Collection Time: 2.27931
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73068

Cumulative Model Updates: 212,066
Cumulative Timesteps: 1,768,604,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.99240
Policy Entropy: 2.21256
Value Function Loss: 0.01631

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.56434

Collected Steps per Second: 22,203.89337
Overall Steps per Second: 10,392.51410

Timestep Collection Time: 2.25231
Timestep Consumption Time: 2.55981
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.81212

Cumulative Model Updates: 212,072
Cumulative Timesteps: 1,768,654,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1768654410...
Checkpoint 1768654410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.92377
Policy Entropy: 2.20048
Value Function Loss: 0.01688

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.57850

Collected Steps per Second: 22,047.23549
Overall Steps per Second: 10,421.11022

Timestep Collection Time: 2.26895
Timestep Consumption Time: 2.53131
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.80026

Cumulative Model Updates: 212,078
Cumulative Timesteps: 1,768,704,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.82904
Policy Entropy: 2.18531
Value Function Loss: 0.01743

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 21,746.35083
Overall Steps per Second: 10,352.00993

Timestep Collection Time: 2.30025
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.83211

Cumulative Model Updates: 212,084
Cumulative Timesteps: 1,768,754,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1768754456...
Checkpoint 1768754456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.49056
Policy Entropy: 2.15861
Value Function Loss: 0.01760

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.60181

Collected Steps per Second: 21,868.13205
Overall Steps per Second: 10,305.00304

Timestep Collection Time: 2.28716
Timestep Consumption Time: 2.56640
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.85356

Cumulative Model Updates: 212,090
Cumulative Timesteps: 1,768,804,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.96360
Policy Entropy: 2.13455
Value Function Loss: 0.01785

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.59847

Collected Steps per Second: 22,037.57860
Overall Steps per Second: 10,476.00656

Timestep Collection Time: 2.26985
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 4.77491

Cumulative Model Updates: 212,096
Cumulative Timesteps: 1,768,854,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1768854494...
Checkpoint 1768854494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.97609
Policy Entropy: 2.14439
Value Function Loss: 0.01763

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.60063

Collected Steps per Second: 21,758.23413
Overall Steps per Second: 10,229.66215

Timestep Collection Time: 2.29844
Timestep Consumption Time: 2.59028
PPO Batch Consumption Time: 0.30458
Total Iteration Time: 4.88872

Cumulative Model Updates: 212,102
Cumulative Timesteps: 1,768,904,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.92321
Policy Entropy: 2.13498
Value Function Loss: 0.01781

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.60329

Collected Steps per Second: 22,173.68145
Overall Steps per Second: 10,423.20901

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.54247
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.79775

Cumulative Model Updates: 212,108
Cumulative Timesteps: 1,768,954,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1768954512...
Checkpoint 1768954512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.90239
Policy Entropy: 2.12961
Value Function Loss: 0.01763

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 21,600.44767
Overall Steps per Second: 10,255.37819

Timestep Collection Time: 2.31616
Timestep Consumption Time: 2.56226
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.87842

Cumulative Model Updates: 212,114
Cumulative Timesteps: 1,769,004,542

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.39432
Policy Entropy: 2.09377
Value Function Loss: 0.01853

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.58135

Collected Steps per Second: 21,574.68452
Overall Steps per Second: 10,433.87644

Timestep Collection Time: 2.31818
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.79342

Cumulative Model Updates: 212,120
Cumulative Timesteps: 1,769,054,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1769054556...
Checkpoint 1769054556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.84526
Policy Entropy: 2.11121
Value Function Loss: 0.01747

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.58039

Collected Steps per Second: 21,281.36892
Overall Steps per Second: 10,201.95180

Timestep Collection Time: 2.34957
Timestep Consumption Time: 2.55165
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.90122

Cumulative Model Updates: 212,126
Cumulative Timesteps: 1,769,104,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.62795
Policy Entropy: 2.10957
Value Function Loss: 0.01679

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.57070

Collected Steps per Second: 22,207.50011
Overall Steps per Second: 10,459.86905

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.52919
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.78113

Cumulative Model Updates: 212,132
Cumulative Timesteps: 1,769,154,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1769154568...
Checkpoint 1769154568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.79421
Policy Entropy: 2.13138
Value Function Loss: 0.01691

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.53797
Value Function Update Magnitude: 0.55058

Collected Steps per Second: 21,680.36906
Overall Steps per Second: 10,203.07448

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.59487
PPO Batch Consumption Time: 0.30381
Total Iteration Time: 4.90166

Cumulative Model Updates: 212,138
Cumulative Timesteps: 1,769,204,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.37521
Policy Entropy: 2.12259
Value Function Loss: 0.01791

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,112.42002
Overall Steps per Second: 10,469.51564

Timestep Collection Time: 2.26199
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.77749

Cumulative Model Updates: 212,144
Cumulative Timesteps: 1,769,254,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1769254598...
Checkpoint 1769254598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.50063
Policy Entropy: 2.11927
Value Function Loss: 0.01814

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.55157
Value Function Update Magnitude: 0.55747

Collected Steps per Second: 22,411.62073
Overall Steps per Second: 10,514.17959

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.52460
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.75567

Cumulative Model Updates: 212,150
Cumulative Timesteps: 1,769,304,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.91735
Policy Entropy: 2.10606
Value Function Loss: 0.01832

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.57097

Collected Steps per Second: 21,634.26903
Overall Steps per Second: 10,197.82933

Timestep Collection Time: 2.31253
Timestep Consumption Time: 2.59341
PPO Batch Consumption Time: 0.30384
Total Iteration Time: 4.90595

Cumulative Model Updates: 212,156
Cumulative Timesteps: 1,769,354,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1769354630...
Checkpoint 1769354630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.05725
Policy Entropy: 2.10188
Value Function Loss: 0.01795

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.56623

Collected Steps per Second: 21,705.50479
Overall Steps per Second: 10,319.39931

Timestep Collection Time: 2.30485
Timestep Consumption Time: 2.54310
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.84796

Cumulative Model Updates: 212,162
Cumulative Timesteps: 1,769,404,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.62683
Policy Entropy: 2.12776
Value Function Loss: 0.01814

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.57020

Collected Steps per Second: 22,157.11381
Overall Steps per Second: 10,664.36604

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69114

Cumulative Model Updates: 212,168
Cumulative Timesteps: 1,769,454,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1769454686...
Checkpoint 1769454686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.77982
Policy Entropy: 2.15240
Value Function Loss: 0.01708

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.58822

Collected Steps per Second: 21,941.62877
Overall Steps per Second: 10,281.94935

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.58412
PPO Batch Consumption Time: 0.30433
Total Iteration Time: 4.86289

Cumulative Model Updates: 212,174
Cumulative Timesteps: 1,769,504,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.31884
Policy Entropy: 2.15900
Value Function Loss: 0.01691

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.54080
Value Function Update Magnitude: 0.59071

Collected Steps per Second: 21,853.77347
Overall Steps per Second: 10,368.42038

Timestep Collection Time: 2.28848
Timestep Consumption Time: 2.53501
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.82349

Cumulative Model Updates: 212,180
Cumulative Timesteps: 1,769,554,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1769554698...
Checkpoint 1769554698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.55410
Policy Entropy: 2.14731
Value Function Loss: 0.01702

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.60745

Collected Steps per Second: 21,798.45632
Overall Steps per Second: 10,290.60699

Timestep Collection Time: 2.29466
Timestep Consumption Time: 2.56609
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.86074

Cumulative Model Updates: 212,186
Cumulative Timesteps: 1,769,604,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.48001
Policy Entropy: 2.11761
Value Function Loss: 0.01797

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.62847

Collected Steps per Second: 21,889.48436
Overall Steps per Second: 10,425.98094

Timestep Collection Time: 2.28512
Timestep Consumption Time: 2.51251
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.79763

Cumulative Model Updates: 212,192
Cumulative Timesteps: 1,769,654,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1769654738...
Checkpoint 1769654738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.19502
Policy Entropy: 2.09919
Value Function Loss: 0.01738

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.63575

Collected Steps per Second: 21,758.11788
Overall Steps per Second: 10,547.22714

Timestep Collection Time: 2.29854
Timestep Consumption Time: 2.44318
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.74172

Cumulative Model Updates: 212,198
Cumulative Timesteps: 1,769,704,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.97109
Policy Entropy: 2.11712
Value Function Loss: 0.01779

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.62538

Collected Steps per Second: 22,107.90820
Overall Steps per Second: 10,380.62399

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.55575
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.81801

Cumulative Model Updates: 212,204
Cumulative Timesteps: 1,769,754,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1769754764...
Checkpoint 1769754764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.64790
Policy Entropy: 2.13360
Value Function Loss: 0.01776

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.61395

Collected Steps per Second: 21,887.10228
Overall Steps per Second: 10,374.83434

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.53592
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.82128

Cumulative Model Updates: 212,210
Cumulative Timesteps: 1,769,804,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.94732
Policy Entropy: 2.14979
Value Function Loss: 0.01812

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 21,918.78486
Overall Steps per Second: 10,415.67982

Timestep Collection Time: 2.28124
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.80065

Cumulative Model Updates: 212,216
Cumulative Timesteps: 1,769,854,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1769854786...
Checkpoint 1769854786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.32945
Policy Entropy: 2.12620
Value Function Loss: 0.01800

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.56070
Value Function Update Magnitude: 0.60741

Collected Steps per Second: 21,525.21988
Overall Steps per Second: 10,272.23856

Timestep Collection Time: 2.32323
Timestep Consumption Time: 2.54504
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.86827

Cumulative Model Updates: 212,222
Cumulative Timesteps: 1,769,904,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.10303
Policy Entropy: 2.12428
Value Function Loss: 0.01748

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.57733

Collected Steps per Second: 22,019.59964
Overall Steps per Second: 10,441.49182

Timestep Collection Time: 2.27161
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.79050

Cumulative Model Updates: 212,228
Cumulative Timesteps: 1,769,954,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1769954814...
Checkpoint 1769954814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.10760
Policy Entropy: 2.13128
Value Function Loss: 0.01643

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.55178

Collected Steps per Second: 21,948.09097
Overall Steps per Second: 10,301.94609

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.57638
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.85539

Cumulative Model Updates: 212,234
Cumulative Timesteps: 1,770,004,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.96495
Policy Entropy: 2.14539
Value Function Loss: 0.01695

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.55154

Collected Steps per Second: 22,010.17523
Overall Steps per Second: 10,392.35537

Timestep Collection Time: 2.27195
Timestep Consumption Time: 2.53986
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.81181

Cumulative Model Updates: 212,240
Cumulative Timesteps: 1,770,054,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1770054840...
Checkpoint 1770054840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.69361
Policy Entropy: 2.13843
Value Function Loss: 0.01797

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.57353

Collected Steps per Second: 21,602.35603
Overall Steps per Second: 10,290.82180

Timestep Collection Time: 2.31484
Timestep Consumption Time: 2.54444
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 4.85928

Cumulative Model Updates: 212,246
Cumulative Timesteps: 1,770,104,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.87133
Policy Entropy: 2.11523
Value Function Loss: 0.01826

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.57771

Collected Steps per Second: 21,820.98963
Overall Steps per Second: 10,407.32618

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.80681

Cumulative Model Updates: 212,252
Cumulative Timesteps: 1,770,154,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1770154872...
Checkpoint 1770154872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.33196
Policy Entropy: 2.12517
Value Function Loss: 0.01736

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.55242

Collected Steps per Second: 21,761.67710
Overall Steps per Second: 10,211.43246

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.60031
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 4.89921

Cumulative Model Updates: 212,258
Cumulative Timesteps: 1,770,204,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.82732
Policy Entropy: 2.13699
Value Function Loss: 0.01670

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.54308
Value Function Update Magnitude: 0.52848

Collected Steps per Second: 21,836.53102
Overall Steps per Second: 10,331.74110

Timestep Collection Time: 2.29047
Timestep Consumption Time: 2.55053
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.84100

Cumulative Model Updates: 212,264
Cumulative Timesteps: 1,770,254,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1770254916...
Checkpoint 1770254916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.56168
Policy Entropy: 2.16297
Value Function Loss: 0.01685

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.53783

Collected Steps per Second: 21,979.55390
Overall Steps per Second: 10,338.43426

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.56210
PPO Batch Consumption Time: 0.30390
Total Iteration Time: 4.83748

Cumulative Model Updates: 212,270
Cumulative Timesteps: 1,770,304,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.02123
Policy Entropy: 2.15486
Value Function Loss: 0.01711

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.55076

Collected Steps per Second: 22,585.20307
Overall Steps per Second: 10,404.46213

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.59324
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.80832

Cumulative Model Updates: 212,276
Cumulative Timesteps: 1,770,354,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1770354956...
Checkpoint 1770354956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.20553
Policy Entropy: 2.14619
Value Function Loss: 0.01739

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.54634

Collected Steps per Second: 21,718.35522
Overall Steps per Second: 10,214.72633

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.59373
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 4.89685

Cumulative Model Updates: 212,282
Cumulative Timesteps: 1,770,404,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.97561
Policy Entropy: 2.15317
Value Function Loss: 0.01836

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.55630

Collected Steps per Second: 21,756.82088
Overall Steps per Second: 10,391.74821

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.51428
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.81324

Cumulative Model Updates: 212,288
Cumulative Timesteps: 1,770,454,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1770454994...
Checkpoint 1770454994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.50542
Policy Entropy: 2.13637
Value Function Loss: 0.01867

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.58265

Collected Steps per Second: 21,844.51311
Overall Steps per Second: 10,582.91881

Timestep Collection Time: 2.28890
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.72459

Cumulative Model Updates: 212,294
Cumulative Timesteps: 1,770,504,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.38420
Policy Entropy: 2.13611
Value Function Loss: 0.01769

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.58435

Collected Steps per Second: 22,522.31973
Overall Steps per Second: 10,500.69694

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.54299
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.76426

Cumulative Model Updates: 212,300
Cumulative Timesteps: 1,770,555,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1770555022...
Checkpoint 1770555022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.36454
Policy Entropy: 2.12678
Value Function Loss: 0.01783

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.55853

Collected Steps per Second: 22,302.54238
Overall Steps per Second: 10,378.51162

Timestep Collection Time: 2.24217
Timestep Consumption Time: 2.57606
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.81822

Cumulative Model Updates: 212,306
Cumulative Timesteps: 1,770,605,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.21503
Policy Entropy: 2.13931
Value Function Loss: 0.01760

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.15392
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.55848

Collected Steps per Second: 21,724.21629
Overall Steps per Second: 10,354.52463

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.82881

Cumulative Model Updates: 212,312
Cumulative Timesteps: 1,770,655,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1770655028...
Checkpoint 1770655028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.27655
Policy Entropy: 2.12591
Value Function Loss: 0.01725

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.57254

Collected Steps per Second: 21,777.12881
Overall Steps per Second: 10,573.38294

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.73131

Cumulative Model Updates: 212,318
Cumulative Timesteps: 1,770,705,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.08079
Policy Entropy: 2.12307
Value Function Loss: 0.01712

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.57657

Collected Steps per Second: 22,250.22276
Overall Steps per Second: 10,426.15604

Timestep Collection Time: 2.24726
Timestep Consumption Time: 2.54856
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.79582

Cumulative Model Updates: 212,324
Cumulative Timesteps: 1,770,755,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1770755056...
Checkpoint 1770755056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.66214
Policy Entropy: 2.12271
Value Function Loss: 0.01813

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,191.46485
Overall Steps per Second: 10,337.41680

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.58368
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 4.83680

Cumulative Model Updates: 212,330
Cumulative Timesteps: 1,770,805,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.47761
Policy Entropy: 2.12280
Value Function Loss: 0.01766

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.58885

Collected Steps per Second: 21,724.72441
Overall Steps per Second: 10,359.10608

Timestep Collection Time: 2.30263
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.82899

Cumulative Model Updates: 212,336
Cumulative Timesteps: 1,770,855,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1770855080...
Checkpoint 1770855080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.31933
Policy Entropy: 2.11632
Value Function Loss: 0.01813

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.59063

Collected Steps per Second: 21,804.99362
Overall Steps per Second: 10,583.27748

Timestep Collection Time: 2.29379
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.72595

Cumulative Model Updates: 212,342
Cumulative Timesteps: 1,770,905,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.95502
Policy Entropy: 2.09156
Value Function Loss: 0.01739

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.17347
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 22,258.78823
Overall Steps per Second: 10,463.13206

Timestep Collection Time: 2.24738
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.78098

Cumulative Model Updates: 212,348
Cumulative Timesteps: 1,770,955,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1770955120...
Checkpoint 1770955120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.35006
Policy Entropy: 2.12084
Value Function Loss: 0.01855

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.51256
Value Function Update Magnitude: 0.57425

Collected Steps per Second: 22,062.67290
Overall Steps per Second: 10,323.94952

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.57787
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.84505

Cumulative Model Updates: 212,354
Cumulative Timesteps: 1,771,005,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.60705
Policy Entropy: 2.14556
Value Function Loss: 0.01840

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.59668

Collected Steps per Second: 21,748.96476
Overall Steps per Second: 10,338.56015

Timestep Collection Time: 2.30006
Timestep Consumption Time: 2.53852
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.83858

Cumulative Model Updates: 212,360
Cumulative Timesteps: 1,771,055,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1771055164...
Checkpoint 1771055164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.79351
Policy Entropy: 2.16219
Value Function Loss: 0.01814

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.17289
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.60091

Collected Steps per Second: 21,844.47990
Overall Steps per Second: 10,320.83537

Timestep Collection Time: 2.28991
Timestep Consumption Time: 2.55679
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.84670

Cumulative Model Updates: 212,366
Cumulative Timesteps: 1,771,105,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.91070
Policy Entropy: 2.12568
Value Function Loss: 0.01907

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.15994
Policy Update Magnitude: 0.57924
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 20,890.35530
Overall Steps per Second: 10,234.39005

Timestep Collection Time: 2.39345
Timestep Consumption Time: 2.49204
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.88549

Cumulative Model Updates: 212,372
Cumulative Timesteps: 1,771,155,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1771155186...
Checkpoint 1771155186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.88844
Policy Entropy: 2.13788
Value Function Loss: 0.01826

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.15599
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.60977

Collected Steps per Second: 22,041.56539
Overall Steps per Second: 10,426.99639

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.52701
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.79563

Cumulative Model Updates: 212,378
Cumulative Timesteps: 1,771,205,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.80802
Policy Entropy: 2.12085
Value Function Loss: 0.01911

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.60964

Collected Steps per Second: 21,991.71516
Overall Steps per Second: 10,414.79492

Timestep Collection Time: 2.27449
Timestep Consumption Time: 2.52829
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.80278

Cumulative Model Updates: 212,384
Cumulative Timesteps: 1,771,255,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1771255210...
Checkpoint 1771255210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.71942
Policy Entropy: 2.15063
Value Function Loss: 0.01894

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.59361

Collected Steps per Second: 21,759.82639
Overall Steps per Second: 10,305.75632

Timestep Collection Time: 2.29892
Timestep Consumption Time: 2.55507
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.85399

Cumulative Model Updates: 212,390
Cumulative Timesteps: 1,771,305,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.36119
Policy Entropy: 2.14522
Value Function Loss: 0.01920

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.59828

Collected Steps per Second: 21,817.75744
Overall Steps per Second: 10,384.32226

Timestep Collection Time: 2.29299
Timestep Consumption Time: 2.52465
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.81765

Cumulative Model Updates: 212,396
Cumulative Timesteps: 1,771,355,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1771355262...
Checkpoint 1771355262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.07143
Policy Entropy: 2.16473
Value Function Loss: 0.01778

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.62046

Collected Steps per Second: 21,811.13725
Overall Steps per Second: 10,243.04877

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.58978
PPO Batch Consumption Time: 0.30450
Total Iteration Time: 4.88292

Cumulative Model Updates: 212,402
Cumulative Timesteps: 1,771,405,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.14498
Policy Entropy: 2.14955
Value Function Loss: 0.01693

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.60631

Collected Steps per Second: 22,119.49473
Overall Steps per Second: 10,468.49772

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.77662

Cumulative Model Updates: 212,408
Cumulative Timesteps: 1,771,455,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1771455282...
Checkpoint 1771455282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.22161
Policy Entropy: 2.12626
Value Function Loss: 0.01631

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.53945
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 21,800.46009
Overall Steps per Second: 10,327.69244

Timestep Collection Time: 2.29380
Timestep Consumption Time: 2.54813
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 4.84193

Cumulative Model Updates: 212,414
Cumulative Timesteps: 1,771,505,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.57472
Policy Entropy: 2.11443
Value Function Loss: 0.01693

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.60334

Collected Steps per Second: 22,059.25520
Overall Steps per Second: 10,350.98409

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.56445
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.83162

Cumulative Model Updates: 212,420
Cumulative Timesteps: 1,771,555,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1771555300...
Checkpoint 1771555300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.28845
Policy Entropy: 2.11929
Value Function Loss: 0.01692

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.59927

Collected Steps per Second: 22,255.16120
Overall Steps per Second: 10,482.78211

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.52447
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77240

Cumulative Model Updates: 212,426
Cumulative Timesteps: 1,771,605,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.89077
Policy Entropy: 2.13594
Value Function Loss: 0.01687

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 22,164.22074
Overall Steps per Second: 10,381.27302

Timestep Collection Time: 2.25787
Timestep Consumption Time: 2.56273
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.82060

Cumulative Model Updates: 212,432
Cumulative Timesteps: 1,771,655,372

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1771655372...
Checkpoint 1771655372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.82058
Policy Entropy: 2.16645
Value Function Loss: 0.01685

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.59413

Collected Steps per Second: 21,870.63177
Overall Steps per Second: 10,417.85541

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.51368
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.80022

Cumulative Model Updates: 212,438
Cumulative Timesteps: 1,771,705,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.18925
Policy Entropy: 2.14567
Value Function Loss: 0.01729

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.55653
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 22,309.06842
Overall Steps per Second: 10,550.94082

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.74062

Cumulative Model Updates: 212,444
Cumulative Timesteps: 1,771,755,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1771755398...
Checkpoint 1771755398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.42144
Policy Entropy: 2.14154
Value Function Loss: 0.01774

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.59985

Collected Steps per Second: 21,777.25689
Overall Steps per Second: 10,281.99639

Timestep Collection Time: 2.29625
Timestep Consumption Time: 2.56720
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.86345

Cumulative Model Updates: 212,450
Cumulative Timesteps: 1,771,805,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.71442
Policy Entropy: 2.11867
Value Function Loss: 0.01737

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.60185

Collected Steps per Second: 22,298.10254
Overall Steps per Second: 10,347.42932

Timestep Collection Time: 2.24324
Timestep Consumption Time: 2.59081
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 4.83405

Cumulative Model Updates: 212,456
Cumulative Timesteps: 1,771,855,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1771855424...
Checkpoint 1771855424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.64847
Policy Entropy: 2.12290
Value Function Loss: 0.01745

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.55699
Value Function Update Magnitude: 0.59867

Collected Steps per Second: 21,350.99838
Overall Steps per Second: 10,135.54477

Timestep Collection Time: 2.34237
Timestep Consumption Time: 2.59195
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.93432

Cumulative Model Updates: 212,462
Cumulative Timesteps: 1,771,905,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.71700
Policy Entropy: 2.09549
Value Function Loss: 0.01806

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 22,099.51586
Overall Steps per Second: 10,480.27615

Timestep Collection Time: 2.26340
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.77277

Cumulative Model Updates: 212,468
Cumulative Timesteps: 1,771,955,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1771955456...
Checkpoint 1771955456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.62172
Policy Entropy: 2.10191
Value Function Loss: 0.01805

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.63622

Collected Steps per Second: 21,546.58175
Overall Steps per Second: 10,499.83366

Timestep Collection Time: 2.32055
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.76198

Cumulative Model Updates: 212,474
Cumulative Timesteps: 1,772,005,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.25067
Policy Entropy: 2.11402
Value Function Loss: 0.01814

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.55475
Value Function Update Magnitude: 0.63714

Collected Steps per Second: 22,275.49731
Overall Steps per Second: 10,483.15382

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.77204

Cumulative Model Updates: 212,480
Cumulative Timesteps: 1,772,055,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1772055482...
Checkpoint 1772055482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.37846
Policy Entropy: 2.15830
Value Function Loss: 0.01746

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.62598

Collected Steps per Second: 21,989.09486
Overall Steps per Second: 10,310.27761

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.57701
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.85205

Cumulative Model Updates: 212,486
Cumulative Timesteps: 1,772,105,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.67847
Policy Entropy: 2.16104
Value Function Loss: 0.01850

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 21,387.10872
Overall Steps per Second: 10,327.94348

Timestep Collection Time: 2.33907
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.84375

Cumulative Model Updates: 212,492
Cumulative Timesteps: 1,772,155,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1772155534...
Checkpoint 1772155534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.32710
Policy Entropy: 2.14747
Value Function Loss: 0.01939

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.62218

Collected Steps per Second: 21,736.96912
Overall Steps per Second: 10,399.26319

Timestep Collection Time: 2.30133
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.81034

Cumulative Model Updates: 212,498
Cumulative Timesteps: 1,772,205,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.02891
Policy Entropy: 2.11709
Value Function Loss: 0.01969

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.16691
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 21,780.43567
Overall Steps per Second: 10,351.82142

Timestep Collection Time: 2.29674
Timestep Consumption Time: 2.53565
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.83239

Cumulative Model Updates: 212,504
Cumulative Timesteps: 1,772,255,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1772255582...
Checkpoint 1772255582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.51729
Policy Entropy: 2.13598
Value Function Loss: 0.01897

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.61771

Collected Steps per Second: 21,563.51661
Overall Steps per Second: 10,270.08146

Timestep Collection Time: 2.31975
Timestep Consumption Time: 2.55090
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.87065

Cumulative Model Updates: 212,510
Cumulative Timesteps: 1,772,305,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.09432
Policy Entropy: 2.17991
Value Function Loss: 0.01823

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 21,907.45818
Overall Steps per Second: 10,412.57296

Timestep Collection Time: 2.28315
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.80362

Cumulative Model Updates: 212,516
Cumulative Timesteps: 1,772,355,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1772355622...
Checkpoint 1772355622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.53305
Policy Entropy: 2.21560
Value Function Loss: 0.01783

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,405.26534
Overall Steps per Second: 10,489.45968

Timestep Collection Time: 2.23287
Timestep Consumption Time: 2.53649
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.76936

Cumulative Model Updates: 212,522
Cumulative Timesteps: 1,772,405,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.84899
Policy Entropy: 2.20738
Value Function Loss: 0.01884

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.60316

Collected Steps per Second: 22,297.87639
Overall Steps per Second: 10,402.09911

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.56446
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.80691

Cumulative Model Updates: 212,528
Cumulative Timesteps: 1,772,455,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1772455652...
Checkpoint 1772455652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.18817
Policy Entropy: 2.15397
Value Function Loss: 0.01855

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.61030

Collected Steps per Second: 21,724.62275
Overall Steps per Second: 10,338.83643

Timestep Collection Time: 2.30163
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.83633

Cumulative Model Updates: 212,534
Cumulative Timesteps: 1,772,505,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.12908
Policy Entropy: 2.08087
Value Function Loss: 0.01856

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.59889

Collected Steps per Second: 22,303.41808
Overall Steps per Second: 10,513.63980

Timestep Collection Time: 2.24262
Timestep Consumption Time: 2.51482
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.75744

Cumulative Model Updates: 212,540
Cumulative Timesteps: 1,772,555,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1772555672...
Checkpoint 1772555672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.15636
Policy Entropy: 2.08536
Value Function Loss: 0.01763

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.58230

Collected Steps per Second: 21,643.60316
Overall Steps per Second: 10,491.95348

Timestep Collection Time: 2.31024
Timestep Consumption Time: 2.45550
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.76575

Cumulative Model Updates: 212,546
Cumulative Timesteps: 1,772,605,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.87899
Policy Entropy: 2.08146
Value Function Loss: 0.01839

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.57878

Collected Steps per Second: 22,151.89018
Overall Steps per Second: 10,376.43849

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.56167
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.81899

Cumulative Model Updates: 212,552
Cumulative Timesteps: 1,772,655,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1772655678...
Checkpoint 1772655678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.11064
Policy Entropy: 2.13752
Value Function Loss: 0.01784

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.55852
Value Function Update Magnitude: 0.57776

Collected Steps per Second: 21,582.49353
Overall Steps per Second: 10,312.45910

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.85006

Cumulative Model Updates: 212,558
Cumulative Timesteps: 1,772,705,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.55911
Policy Entropy: 2.11900
Value Function Loss: 0.01890

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.57604

Collected Steps per Second: 22,238.38097
Overall Steps per Second: 10,535.74521

Timestep Collection Time: 2.24962
Timestep Consumption Time: 2.49878
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.74841

Cumulative Model Updates: 212,564
Cumulative Timesteps: 1,772,755,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1772755722...
Checkpoint 1772755722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.00009
Policy Entropy: 2.16150
Value Function Loss: 0.01909

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.57814

Collected Steps per Second: 21,710.27339
Overall Steps per Second: 10,415.43823

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.49781
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 4.80114

Cumulative Model Updates: 212,570
Cumulative Timesteps: 1,772,805,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.26562
Policy Entropy: 2.15689
Value Function Loss: 0.01888

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.59185

Collected Steps per Second: 22,065.31177
Overall Steps per Second: 10,318.72248

Timestep Collection Time: 2.26609
Timestep Consumption Time: 2.57966
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.84575

Cumulative Model Updates: 212,576
Cumulative Timesteps: 1,772,855,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1772855730...
Checkpoint 1772855730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.78701
Policy Entropy: 2.17762
Value Function Loss: 0.01911

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 21,780.54757
Overall Steps per Second: 10,228.84525

Timestep Collection Time: 2.29599
Timestep Consumption Time: 2.59293
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 4.88892

Cumulative Model Updates: 212,582
Cumulative Timesteps: 1,772,905,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.84600
Policy Entropy: 2.14914
Value Function Loss: 0.01893

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.60034

Collected Steps per Second: 21,912.31463
Overall Steps per Second: 10,449.35442

Timestep Collection Time: 2.28191
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.78518

Cumulative Model Updates: 212,588
Cumulative Timesteps: 1,772,955,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1772955740...
Checkpoint 1772955740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.79454
Policy Entropy: 2.14757
Value Function Loss: 0.01790

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.58987

Collected Steps per Second: 21,511.74178
Overall Steps per Second: 10,499.14121

Timestep Collection Time: 2.32506
Timestep Consumption Time: 2.43876
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.76382

Cumulative Model Updates: 212,594
Cumulative Timesteps: 1,773,005,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.62847
Policy Entropy: 2.12820
Value Function Loss: 0.01730

Mean KL Divergence: 0.02115
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.58169

Collected Steps per Second: 22,248.05217
Overall Steps per Second: 10,468.06002

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.53026
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.77873

Cumulative Model Updates: 212,600
Cumulative Timesteps: 1,773,055,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1773055780...
Checkpoint 1773055780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.70090
Policy Entropy: 2.11959
Value Function Loss: 0.01710

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.17935
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.56664

Collected Steps per Second: 21,908.89723
Overall Steps per Second: 10,320.56746

Timestep Collection Time: 2.28254
Timestep Consumption Time: 2.56293
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.84547

Cumulative Model Updates: 212,606
Cumulative Timesteps: 1,773,105,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.96908
Policy Entropy: 2.11900
Value Function Loss: 0.01794

Mean KL Divergence: 0.02943
SB3 Clip Fraction: 0.18401
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.57053

Collected Steps per Second: 21,687.01243
Overall Steps per Second: 10,329.95772

Timestep Collection Time: 2.30580
Timestep Consumption Time: 2.53507
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.84087

Cumulative Model Updates: 212,612
Cumulative Timesteps: 1,773,155,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1773155794...
Checkpoint 1773155794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.92022
Policy Entropy: 2.12502
Value Function Loss: 0.01852

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.57848

Collected Steps per Second: 21,596.18078
Overall Steps per Second: 10,324.60444

Timestep Collection Time: 2.31643
Timestep Consumption Time: 2.52889
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.84532

Cumulative Model Updates: 212,618
Cumulative Timesteps: 1,773,205,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.51375
Policy Entropy: 2.16451
Value Function Loss: 0.01849

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 21,617.60630
Overall Steps per Second: 10,471.11890

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.77580

Cumulative Model Updates: 212,624
Cumulative Timesteps: 1,773,255,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1773255828...
Checkpoint 1773255828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.70718
Policy Entropy: 2.16336
Value Function Loss: 0.01841

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.56558
Value Function Update Magnitude: 0.62628

Collected Steps per Second: 21,901.03199
Overall Steps per Second: 10,298.25073

Timestep Collection Time: 2.28418
Timestep Consumption Time: 2.57353
PPO Batch Consumption Time: 0.30254
Total Iteration Time: 4.85772

Cumulative Model Updates: 212,630
Cumulative Timesteps: 1,773,305,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.80227
Policy Entropy: 2.18326
Value Function Loss: 0.01913

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.62410

Collected Steps per Second: 21,646.47699
Overall Steps per Second: 10,297.87727

Timestep Collection Time: 2.31123
Timestep Consumption Time: 2.54705
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.85828

Cumulative Model Updates: 212,636
Cumulative Timesteps: 1,773,355,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1773355884...
Checkpoint 1773355884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.21953
Policy Entropy: 2.16301
Value Function Loss: 0.01854

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 21,698.36462
Overall Steps per Second: 10,256.33077

Timestep Collection Time: 2.30543
Timestep Consumption Time: 2.57195
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.87738

Cumulative Model Updates: 212,642
Cumulative Timesteps: 1,773,405,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.38672
Policy Entropy: 2.15466
Value Function Loss: 0.01818

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 21,927.55605
Overall Steps per Second: 10,421.67537

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.51877
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.80019

Cumulative Model Updates: 212,648
Cumulative Timesteps: 1,773,455,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1773455934...
Checkpoint 1773455934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.60903
Policy Entropy: 2.14570
Value Function Loss: 0.01638

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.52753
Value Function Update Magnitude: 0.55099

Collected Steps per Second: 22,487.15506
Overall Steps per Second: 10,528.07087

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.52652
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.75073

Cumulative Model Updates: 212,654
Cumulative Timesteps: 1,773,505,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.04171
Policy Entropy: 2.11504
Value Function Loss: 0.01743

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.53261
Value Function Update Magnitude: 0.54320

Collected Steps per Second: 21,698.96003
Overall Steps per Second: 10,187.76030

Timestep Collection Time: 2.30518
Timestep Consumption Time: 2.60463
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 4.90981

Cumulative Model Updates: 212,660
Cumulative Timesteps: 1,773,555,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1773555970...
Checkpoint 1773555970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.60690
Policy Entropy: 2.13719
Value Function Loss: 0.01747

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.15692
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.56098

Collected Steps per Second: 21,766.59912
Overall Steps per Second: 10,228.33254

Timestep Collection Time: 2.29756
Timestep Consumption Time: 2.59180
PPO Batch Consumption Time: 0.30441
Total Iteration Time: 4.88936

Cumulative Model Updates: 212,666
Cumulative Timesteps: 1,773,605,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.82127
Policy Entropy: 2.15370
Value Function Loss: 0.01766

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.59291

Collected Steps per Second: 21,800.87788
Overall Steps per Second: 10,421.86160

Timestep Collection Time: 2.29413
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.79895

Cumulative Model Updates: 212,672
Cumulative Timesteps: 1,773,655,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1773655994...
Checkpoint 1773655994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.14890
Policy Entropy: 2.19066
Value Function Loss: 0.01787

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.56062
Value Function Update Magnitude: 0.61937

Collected Steps per Second: 22,632.30473
Overall Steps per Second: 10,585.16080

Timestep Collection Time: 2.21003
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.72529

Cumulative Model Updates: 212,678
Cumulative Timesteps: 1,773,706,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.82603
Policy Entropy: 2.14973
Value Function Loss: 0.01876

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 21,988.44053
Overall Steps per Second: 10,414.02548

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.52861
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.80371

Cumulative Model Updates: 212,684
Cumulative Timesteps: 1,773,756,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1773756038...
Checkpoint 1773756038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.26713
Policy Entropy: 2.13937
Value Function Loss: 0.01876

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.15294
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 22,029.65834
Overall Steps per Second: 10,332.86202

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.57019
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.84067

Cumulative Model Updates: 212,690
Cumulative Timesteps: 1,773,806,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.83589
Policy Entropy: 2.11772
Value Function Loss: 0.01847

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.19093
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 21,730.73238
Overall Steps per Second: 10,370.73727

Timestep Collection Time: 2.30126
Timestep Consumption Time: 2.52077
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.82203

Cumulative Model Updates: 212,696
Cumulative Timesteps: 1,773,856,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1773856064...
Checkpoint 1773856064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.62112
Policy Entropy: 2.13128
Value Function Loss: 0.01823

Mean KL Divergence: 0.02677
SB3 Clip Fraction: 0.18129
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.56794

Collected Steps per Second: 22,137.50271
Overall Steps per Second: 10,641.27327

Timestep Collection Time: 2.25988
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.70132

Cumulative Model Updates: 212,702
Cumulative Timesteps: 1,773,906,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.67703
Policy Entropy: 2.14342
Value Function Loss: 0.01785

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.56983

Collected Steps per Second: 21,399.82218
Overall Steps per Second: 10,127.61134

Timestep Collection Time: 2.33740
Timestep Consumption Time: 2.60157
PPO Batch Consumption Time: 0.30429
Total Iteration Time: 4.93897

Cumulative Model Updates: 212,708
Cumulative Timesteps: 1,773,956,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1773956112...
Checkpoint 1773956112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.23218
Policy Entropy: 2.15051
Value Function Loss: 0.01819

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.58230

Collected Steps per Second: 21,919.64480
Overall Steps per Second: 10,268.05145

Timestep Collection Time: 2.28179
Timestep Consumption Time: 2.58924
PPO Batch Consumption Time: 0.30201
Total Iteration Time: 4.87103

Cumulative Model Updates: 212,714
Cumulative Timesteps: 1,774,006,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.28038
Policy Entropy: 2.12514
Value Function Loss: 0.01773

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.56316
Value Function Update Magnitude: 0.59699

Collected Steps per Second: 22,098.45560
Overall Steps per Second: 10,367.52140

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.56128
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.82488

Cumulative Model Updates: 212,720
Cumulative Timesteps: 1,774,056,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1774056150...
Checkpoint 1774056150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.16726
Policy Entropy: 2.13240
Value Function Loss: 0.01763

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.60395

Collected Steps per Second: 21,465.14732
Overall Steps per Second: 10,222.11651

Timestep Collection Time: 2.33085
Timestep Consumption Time: 2.56364
PPO Batch Consumption Time: 0.30489
Total Iteration Time: 4.89449

Cumulative Model Updates: 212,726
Cumulative Timesteps: 1,774,106,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.01190
Policy Entropy: 2.15026
Value Function Loss: 0.01741

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 22,599.60308
Overall Steps per Second: 10,503.60818

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.54917
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.76274

Cumulative Model Updates: 212,732
Cumulative Timesteps: 1,774,156,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1774156208...
Checkpoint 1774156208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.85197
Policy Entropy: 2.17052
Value Function Loss: 0.01794

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.56721

Collected Steps per Second: 22,116.19712
Overall Steps per Second: 10,348.69168

Timestep Collection Time: 2.26106
Timestep Consumption Time: 2.57105
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.83211

Cumulative Model Updates: 212,738
Cumulative Timesteps: 1,774,206,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.44952
Policy Entropy: 2.13433
Value Function Loss: 0.01790

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.57339

Collected Steps per Second: 22,059.69741
Overall Steps per Second: 10,258.00449

Timestep Collection Time: 2.26676
Timestep Consumption Time: 2.60787
PPO Batch Consumption Time: 0.30519
Total Iteration Time: 4.87463

Cumulative Model Updates: 212,744
Cumulative Timesteps: 1,774,256,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1774256218...
Checkpoint 1774256218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.37816
Policy Entropy: 2.14194
Value Function Loss: 0.01743

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 22,017.21847
Overall Steps per Second: 10,409.51068

Timestep Collection Time: 2.27168
Timestep Consumption Time: 2.53316
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.80484

Cumulative Model Updates: 212,750
Cumulative Timesteps: 1,774,306,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.21253
Policy Entropy: 2.16410
Value Function Loss: 0.01674

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.58684

Collected Steps per Second: 21,845.69150
Overall Steps per Second: 10,564.86796

Timestep Collection Time: 2.28997
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.73513

Cumulative Model Updates: 212,756
Cumulative Timesteps: 1,774,356,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1774356260...
Checkpoint 1774356260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.28229
Policy Entropy: 2.17821
Value Function Loss: 0.01737

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 21,840.21282
Overall Steps per Second: 10,349.32864

Timestep Collection Time: 2.29000
Timestep Consumption Time: 2.54259
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.83258

Cumulative Model Updates: 212,762
Cumulative Timesteps: 1,774,406,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.85052
Policy Entropy: 2.16876
Value Function Loss: 0.01764

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.54201
Value Function Update Magnitude: 0.56064

Collected Steps per Second: 21,910.12563
Overall Steps per Second: 10,378.23498

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.81777

Cumulative Model Updates: 212,768
Cumulative Timesteps: 1,774,456,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1774456274...
Checkpoint 1774456274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.11962
Policy Entropy: 2.16394
Value Function Loss: 0.01768

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.53621
Value Function Update Magnitude: 0.55727

Collected Steps per Second: 21,889.73855
Overall Steps per Second: 10,326.96688

Timestep Collection Time: 2.28555
Timestep Consumption Time: 2.55905
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.84460

Cumulative Model Updates: 212,774
Cumulative Timesteps: 1,774,506,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.77729
Policy Entropy: 2.13557
Value Function Loss: 0.01783

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.55419

Collected Steps per Second: 21,701.27459
Overall Steps per Second: 10,402.55920

Timestep Collection Time: 2.30503
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.80862

Cumulative Model Updates: 212,780
Cumulative Timesteps: 1,774,556,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1774556326...
Checkpoint 1774556326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.86161
Policy Entropy: 2.12217
Value Function Loss: 0.01756

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.57076

Collected Steps per Second: 21,969.73950
Overall Steps per Second: 10,313.28968

Timestep Collection Time: 2.27622
Timestep Consumption Time: 2.57267
PPO Batch Consumption Time: 0.30301
Total Iteration Time: 4.84889

Cumulative Model Updates: 212,786
Cumulative Timesteps: 1,774,606,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.28756
Policy Entropy: 2.12041
Value Function Loss: 0.01689

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.58615

Collected Steps per Second: 22,067.86774
Overall Steps per Second: 10,368.65459

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.55751
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.82416

Cumulative Model Updates: 212,792
Cumulative Timesteps: 1,774,656,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1774656354...
Checkpoint 1774656354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.62843
Policy Entropy: 2.14455
Value Function Loss: 0.01725

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.58314

Collected Steps per Second: 21,389.79183
Overall Steps per Second: 10,207.09463

Timestep Collection Time: 2.33915
Timestep Consumption Time: 2.56273
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 4.90188

Cumulative Model Updates: 212,798
Cumulative Timesteps: 1,774,706,388

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.35121
Policy Entropy: 2.15451
Value Function Loss: 0.01709

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.59111

Collected Steps per Second: 22,028.25715
Overall Steps per Second: 10,459.90065

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 4.78245

Cumulative Model Updates: 212,804
Cumulative Timesteps: 1,774,756,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1774756412...
Checkpoint 1774756412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.77295
Policy Entropy: 2.14421
Value Function Loss: 0.01800

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.54841
Value Function Update Magnitude: 0.59412

Collected Steps per Second: 21,923.67151
Overall Steps per Second: 10,307.99293

Timestep Collection Time: 2.28064
Timestep Consumption Time: 2.56996
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 4.85060

Cumulative Model Updates: 212,810
Cumulative Timesteps: 1,774,806,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.50136
Policy Entropy: 2.13706
Value Function Loss: 0.01772

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.59402

Collected Steps per Second: 22,038.66943
Overall Steps per Second: 10,357.72902

Timestep Collection Time: 2.27001
Timestep Consumption Time: 2.56001
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.83002

Cumulative Model Updates: 212,816
Cumulative Timesteps: 1,774,856,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1774856440...
Checkpoint 1774856440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.69748
Policy Entropy: 2.11388
Value Function Loss: 0.01789

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 21,495.13026
Overall Steps per Second: 10,220.88180

Timestep Collection Time: 2.32788
Timestep Consumption Time: 2.56779
PPO Batch Consumption Time: 0.30437
Total Iteration Time: 4.89566

Cumulative Model Updates: 212,822
Cumulative Timesteps: 1,774,906,478

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.86653
Policy Entropy: 2.09609
Value Function Loss: 0.01871

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.56142
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 22,038.89580
Overall Steps per Second: 10,446.61341

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.30419
Total Iteration Time: 4.78662

Cumulative Model Updates: 212,828
Cumulative Timesteps: 1,774,956,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1774956482...
Checkpoint 1774956482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.50741
Policy Entropy: 2.08635
Value Function Loss: 0.01873

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.58627

Collected Steps per Second: 21,593.80431
Overall Steps per Second: 10,216.70606

Timestep Collection Time: 2.31557
Timestep Consumption Time: 2.57857
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 4.89414

Cumulative Model Updates: 212,834
Cumulative Timesteps: 1,775,006,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.70731
Policy Entropy: 2.08621
Value Function Loss: 0.01898

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.58285
Value Function Update Magnitude: 0.58521

Collected Steps per Second: 22,003.57636
Overall Steps per Second: 10,404.16087

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.53473
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.80827

Cumulative Model Updates: 212,840
Cumulative Timesteps: 1,775,056,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1775056510...
Checkpoint 1775056510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.55769
Policy Entropy: 2.09916
Value Function Loss: 0.01803

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.60664

Collected Steps per Second: 21,620.49925
Overall Steps per Second: 10,279.12123

Timestep Collection Time: 2.31364
Timestep Consumption Time: 2.55273
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.86637

Cumulative Model Updates: 212,846
Cumulative Timesteps: 1,775,106,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.75520
Policy Entropy: 2.11754
Value Function Loss: 0.01722

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.60108

Collected Steps per Second: 21,750.62289
Overall Steps per Second: 10,394.83367

Timestep Collection Time: 2.29943
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.81143

Cumulative Model Updates: 212,852
Cumulative Timesteps: 1,775,156,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1775156546...
Checkpoint 1775156546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.91253
Policy Entropy: 2.11092
Value Function Loss: 0.01718

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.57238

Collected Steps per Second: 21,605.40283
Overall Steps per Second: 10,440.33801

Timestep Collection Time: 2.31470
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.79007

Cumulative Model Updates: 212,858
Cumulative Timesteps: 1,775,206,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.49921
Policy Entropy: 2.10887
Value Function Loss: 0.01715

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.55350

Collected Steps per Second: 22,254.53597
Overall Steps per Second: 10,358.15648

Timestep Collection Time: 2.24727
Timestep Consumption Time: 2.58100
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.82827

Cumulative Model Updates: 212,864
Cumulative Timesteps: 1,775,256,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1775256568...
Checkpoint 1775256568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.56771
Policy Entropy: 2.11367
Value Function Loss: 0.01716

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.56418

Collected Steps per Second: 21,721.28197
Overall Steps per Second: 10,194.02957

Timestep Collection Time: 2.30272
Timestep Consumption Time: 2.60388
PPO Batch Consumption Time: 0.30275
Total Iteration Time: 4.90660

Cumulative Model Updates: 212,870
Cumulative Timesteps: 1,775,306,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.63081
Policy Entropy: 2.12278
Value Function Loss: 0.01647

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.59148

Collected Steps per Second: 22,011.69282
Overall Steps per Second: 10,363.84637

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.55315
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.82485

Cumulative Model Updates: 212,876
Cumulative Timesteps: 1,775,356,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1775356590...
Checkpoint 1775356590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.07489
Policy Entropy: 2.14171
Value Function Loss: 0.01665

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 21,672.10643
Overall Steps per Second: 10,256.20354

Timestep Collection Time: 2.30813
Timestep Consumption Time: 2.56912
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.87724

Cumulative Model Updates: 212,882
Cumulative Timesteps: 1,775,406,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.54519
Policy Entropy: 2.14031
Value Function Loss: 0.01709

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.64967

Collected Steps per Second: 22,220.36729
Overall Steps per Second: 10,527.45592

Timestep Collection Time: 2.25226
Timestep Consumption Time: 2.50160
PPO Batch Consumption Time: 0.30258
Total Iteration Time: 4.75386

Cumulative Model Updates: 212,888
Cumulative Timesteps: 1,775,456,658

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1775456658...
Checkpoint 1775456658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.34687
Policy Entropy: 2.12229
Value Function Loss: 0.01743

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.64704

Collected Steps per Second: 20,942.92410
Overall Steps per Second: 10,135.12329

Timestep Collection Time: 2.38773
Timestep Consumption Time: 2.54620
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.93393

Cumulative Model Updates: 212,894
Cumulative Timesteps: 1,775,506,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.62896
Policy Entropy: 2.11292
Value Function Loss: 0.01785

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 22,028.94201
Overall Steps per Second: 10,384.57168

Timestep Collection Time: 2.27083
Timestep Consumption Time: 2.54632
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.81715

Cumulative Model Updates: 212,900
Cumulative Timesteps: 1,775,556,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1775556688...
Checkpoint 1775556688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.10753
Policy Entropy: 2.09834
Value Function Loss: 0.01742

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 21,589.19514
Overall Steps per Second: 10,276.69451

Timestep Collection Time: 2.31616
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.86577

Cumulative Model Updates: 212,906
Cumulative Timesteps: 1,775,606,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.21863
Policy Entropy: 2.13073
Value Function Loss: 0.01729

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.55424
Value Function Update Magnitude: 0.62510

Collected Steps per Second: 21,846.25730
Overall Steps per Second: 10,473.96109

Timestep Collection Time: 2.28918
Timestep Consumption Time: 2.48552
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.77470

Cumulative Model Updates: 212,912
Cumulative Timesteps: 1,775,656,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1775656702...
Checkpoint 1775656702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.42303
Policy Entropy: 2.12129
Value Function Loss: 0.01742

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.63152

Collected Steps per Second: 21,714.55180
Overall Steps per Second: 10,238.48812

Timestep Collection Time: 2.30343
Timestep Consumption Time: 2.58186
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.88529

Cumulative Model Updates: 212,918
Cumulative Timesteps: 1,775,706,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.57925
Policy Entropy: 2.13768
Value Function Loss: 0.01833

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.56019
Value Function Update Magnitude: 0.63049

Collected Steps per Second: 22,336.75955
Overall Steps per Second: 10,389.36127

Timestep Collection Time: 2.23855
Timestep Consumption Time: 2.57426
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.81281

Cumulative Model Updates: 212,924
Cumulative Timesteps: 1,775,756,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1775756722...
Checkpoint 1775756722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.26904
Policy Entropy: 2.08797
Value Function Loss: 0.01794

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.16364
Policy Update Magnitude: 0.53685
Value Function Update Magnitude: 0.63304

Collected Steps per Second: 21,664.56727
Overall Steps per Second: 10,221.06466

Timestep Collection Time: 2.30829
Timestep Consumption Time: 2.58436
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 4.89264

Cumulative Model Updates: 212,930
Cumulative Timesteps: 1,775,806,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.58916
Policy Entropy: 2.09205
Value Function Loss: 0.01855

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.18073
Policy Update Magnitude: 0.51625
Value Function Update Magnitude: 0.63364

Collected Steps per Second: 21,763.68599
Overall Steps per Second: 10,414.50665

Timestep Collection Time: 2.29869
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.80368

Cumulative Model Updates: 212,936
Cumulative Timesteps: 1,775,856,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1775856758...
Checkpoint 1775856758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.39111
Policy Entropy: 2.08139
Value Function Loss: 0.01791

Mean KL Divergence: 0.03111
SB3 Clip Fraction: 0.19298
Policy Update Magnitude: 0.51431
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 21,635.06188
Overall Steps per Second: 10,474.98344

Timestep Collection Time: 2.31125
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.77366

Cumulative Model Updates: 212,942
Cumulative Timesteps: 1,775,906,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.96910
Policy Entropy: 2.11162
Value Function Loss: 0.01809

Mean KL Divergence: 0.02733
SB3 Clip Fraction: 0.17854
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.62779

Collected Steps per Second: 21,831.75476
Overall Steps per Second: 10,230.62098

Timestep Collection Time: 2.29097
Timestep Consumption Time: 2.59788
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 4.88885

Cumulative Model Updates: 212,948
Cumulative Timesteps: 1,775,956,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1775956778...
Checkpoint 1775956778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.59617
Policy Entropy: 2.13725
Value Function Loss: 0.01788

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.16721
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.63389

Collected Steps per Second: 21,623.54414
Overall Steps per Second: 10,214.68126

Timestep Collection Time: 2.31340
Timestep Consumption Time: 2.58386
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.89726

Cumulative Model Updates: 212,954
Cumulative Timesteps: 1,776,006,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.47916
Policy Entropy: 2.14704
Value Function Loss: 0.01684

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.64675

Collected Steps per Second: 21,899.85247
Overall Steps per Second: 10,443.51499

Timestep Collection Time: 2.28458
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.79072

Cumulative Model Updates: 212,960
Cumulative Timesteps: 1,776,056,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1776056834...
Checkpoint 1776056834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.22949
Policy Entropy: 2.12815
Value Function Loss: 0.01634

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.62934

Collected Steps per Second: 21,651.86623
Overall Steps per Second: 10,488.57580

Timestep Collection Time: 2.31010
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.76881

Cumulative Model Updates: 212,966
Cumulative Timesteps: 1,776,106,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.84625
Policy Entropy: 2.11881
Value Function Loss: 0.01638

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 22,180.06963
Overall Steps per Second: 10,350.46178

Timestep Collection Time: 2.25509
Timestep Consumption Time: 2.57735
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.83244

Cumulative Model Updates: 212,972
Cumulative Timesteps: 1,776,156,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1776156870...
Checkpoint 1776156870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.50875
Policy Entropy: 2.11321
Value Function Loss: 0.01844

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 21,609.89763
Overall Steps per Second: 10,294.02658

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.54445
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.85913

Cumulative Model Updates: 212,978
Cumulative Timesteps: 1,776,206,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.38244
Policy Entropy: 2.12468
Value Function Loss: 0.01865

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.62925

Collected Steps per Second: 21,959.25092
Overall Steps per Second: 10,548.70503

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.46297
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.73992

Cumulative Model Updates: 212,984
Cumulative Timesteps: 1,776,256,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1776256890...
Checkpoint 1776256890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.93217
Policy Entropy: 2.10860
Value Function Loss: 0.01798

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.54748
Value Function Update Magnitude: 0.64794

Collected Steps per Second: 22,001.64660
Overall Steps per Second: 10,321.81865

Timestep Collection Time: 2.27328
Timestep Consumption Time: 2.57237
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.84566

Cumulative Model Updates: 212,990
Cumulative Timesteps: 1,776,306,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.68666
Policy Entropy: 2.09763
Value Function Loss: 0.01642

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.63980

Collected Steps per Second: 22,172.13035
Overall Steps per Second: 10,403.94074

Timestep Collection Time: 2.25617
Timestep Consumption Time: 2.55201
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.80818

Cumulative Model Updates: 212,996
Cumulative Timesteps: 1,776,356,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1776356930...
Checkpoint 1776356930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.32301
Policy Entropy: 2.09428
Value Function Loss: 0.01742

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 21,672.14205
Overall Steps per Second: 10,240.70657

Timestep Collection Time: 2.30757
Timestep Consumption Time: 2.57588
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.88345

Cumulative Model Updates: 213,002
Cumulative Timesteps: 1,776,406,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.62056
Policy Entropy: 2.11197
Value Function Loss: 0.01659

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.62577

Collected Steps per Second: 21,723.37344
Overall Steps per Second: 10,448.45290

Timestep Collection Time: 2.30305
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.78827

Cumulative Model Updates: 213,008
Cumulative Timesteps: 1,776,456,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1776456970...
Checkpoint 1776456970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.23346
Policy Entropy: 2.11990
Value Function Loss: 0.01779

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.62234

Collected Steps per Second: 21,923.53660
Overall Steps per Second: 10,262.99489

Timestep Collection Time: 2.28193
Timestep Consumption Time: 2.59267
PPO Batch Consumption Time: 0.30450
Total Iteration Time: 4.87460

Cumulative Model Updates: 213,014
Cumulative Timesteps: 1,776,506,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.63161
Policy Entropy: 2.11365
Value Function Loss: 0.01705

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.63242

Collected Steps per Second: 21,788.14471
Overall Steps per Second: 10,333.69257

Timestep Collection Time: 2.29556
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.84009

Cumulative Model Updates: 213,020
Cumulative Timesteps: 1,776,557,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1776557014...
Checkpoint 1776557014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.21826
Policy Entropy: 2.12171
Value Function Loss: 0.01762

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.64484

Collected Steps per Second: 21,991.29043
Overall Steps per Second: 10,314.40888

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.57561
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.85069

Cumulative Model Updates: 213,026
Cumulative Timesteps: 1,776,607,046

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.56727
Policy Entropy: 2.12202
Value Function Loss: 0.01687

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.63106

Collected Steps per Second: 21,882.87403
Overall Steps per Second: 10,376.46535

Timestep Collection Time: 2.28544
Timestep Consumption Time: 2.53431
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.81975

Cumulative Model Updates: 213,032
Cumulative Timesteps: 1,776,657,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1776657058...
Checkpoint 1776657058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.32247
Policy Entropy: 2.11228
Value Function Loss: 0.01626

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.52574
Value Function Update Magnitude: 0.59547

Collected Steps per Second: 21,765.42127
Overall Steps per Second: 10,474.87569

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.47690
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.77485

Cumulative Model Updates: 213,038
Cumulative Timesteps: 1,776,707,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.65989
Policy Entropy: 2.08954
Value Function Loss: 0.01608

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.59064

Collected Steps per Second: 21,981.40197
Overall Steps per Second: 10,279.27001

Timestep Collection Time: 2.27583
Timestep Consumption Time: 2.59086
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 4.86669

Cumulative Model Updates: 213,044
Cumulative Timesteps: 1,776,757,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1776757100...
Checkpoint 1776757100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.53247
Policy Entropy: 2.10357
Value Function Loss: 0.01639

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.60145

Collected Steps per Second: 21,883.20905
Overall Steps per Second: 10,243.98738

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.59689
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.88247

Cumulative Model Updates: 213,050
Cumulative Timesteps: 1,776,807,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.31911
Policy Entropy: 2.13027
Value Function Loss: 0.01642

Mean KL Divergence: 0.02591
SB3 Clip Fraction: 0.17356
Policy Update Magnitude: 0.49863
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 21,823.35968
Overall Steps per Second: 10,376.51957

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.82011

Cumulative Model Updates: 213,056
Cumulative Timesteps: 1,776,857,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1776857132...
Checkpoint 1776857132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.45143
Policy Entropy: 2.13240
Value Function Loss: 0.01611

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.17414
Policy Update Magnitude: 0.49237
Value Function Update Magnitude: 0.59813

Collected Steps per Second: 21,485.18719
Overall Steps per Second: 10,407.66006

Timestep Collection Time: 2.32756
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.80492

Cumulative Model Updates: 213,062
Cumulative Timesteps: 1,776,907,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.49954
Policy Entropy: 2.11864
Value Function Loss: 0.01549

Mean KL Divergence: 0.02628
SB3 Clip Fraction: 0.17816
Policy Update Magnitude: 0.50171
Value Function Update Magnitude: 0.58596

Collected Steps per Second: 22,225.44699
Overall Steps per Second: 10,294.69284

Timestep Collection Time: 2.24994
Timestep Consumption Time: 2.60751
PPO Batch Consumption Time: 0.30453
Total Iteration Time: 4.85745

Cumulative Model Updates: 213,068
Cumulative Timesteps: 1,776,957,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1776957146...
Checkpoint 1776957146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.66727
Policy Entropy: 2.08682
Value Function Loss: 0.01662

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.52536
Value Function Update Magnitude: 0.57744

Collected Steps per Second: 21,827.43046
Overall Steps per Second: 10,222.36035

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.60148
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 4.89300

Cumulative Model Updates: 213,074
Cumulative Timesteps: 1,777,007,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.80079
Policy Entropy: 2.11031
Value Function Loss: 0.01739

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.18492
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.59462

Collected Steps per Second: 21,893.37593
Overall Steps per Second: 10,454.00423

Timestep Collection Time: 2.28380
Timestep Consumption Time: 2.49906
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78286

Cumulative Model Updates: 213,080
Cumulative Timesteps: 1,777,057,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1777057164...
Checkpoint 1777057164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.82619
Policy Entropy: 2.10433
Value Function Loss: 0.01769

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.17848
Policy Update Magnitude: 0.54554
Value Function Update Magnitude: 0.61801

Collected Steps per Second: 21,630.26157
Overall Steps per Second: 10,537.15042

Timestep Collection Time: 2.31158
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.74512

Cumulative Model Updates: 213,086
Cumulative Timesteps: 1,777,107,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.20856
Policy Entropy: 2.14121
Value Function Loss: 0.01787

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.15896
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 22,229.22396
Overall Steps per Second: 10,472.65025

Timestep Collection Time: 2.25055
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.77701

Cumulative Model Updates: 213,092
Cumulative Timesteps: 1,777,157,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1777157192...
Checkpoint 1777157192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.28732
Policy Entropy: 2.13561
Value Function Loss: 0.01797

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 21,589.20089
Overall Steps per Second: 10,304.10863

Timestep Collection Time: 2.31644
Timestep Consumption Time: 2.53697
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.85340

Cumulative Model Updates: 213,098
Cumulative Timesteps: 1,777,207,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.63102
Policy Entropy: 2.14129
Value Function Loss: 0.01886

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.55319
Value Function Update Magnitude: 0.60343

Collected Steps per Second: 22,107.52381
Overall Steps per Second: 10,485.73681

Timestep Collection Time: 2.26185
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.76876

Cumulative Model Updates: 213,104
Cumulative Timesteps: 1,777,257,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1777257206...
Checkpoint 1777257206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.11852
Policy Entropy: 2.14043
Value Function Loss: 0.01764

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 21,758.67227
Overall Steps per Second: 10,326.27289

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.54449
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.84279

Cumulative Model Updates: 213,110
Cumulative Timesteps: 1,777,307,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.54320
Policy Entropy: 2.12747
Value Function Loss: 0.01684

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.53947
Value Function Update Magnitude: 0.58126

Collected Steps per Second: 22,977.78156
Overall Steps per Second: 10,614.23153

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.53535
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71198

Cumulative Model Updates: 213,116
Cumulative Timesteps: 1,777,357,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1777357228...
Checkpoint 1777357228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.75224
Policy Entropy: 2.10369
Value Function Loss: 0.01740

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.57888

Collected Steps per Second: 21,782.91941
Overall Steps per Second: 10,345.28977

Timestep Collection Time: 2.29574
Timestep Consumption Time: 2.53815
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.83389

Cumulative Model Updates: 213,122
Cumulative Timesteps: 1,777,407,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.13649
Policy Entropy: 2.10142
Value Function Loss: 0.01792

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15773
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.58324

Collected Steps per Second: 21,775.44133
Overall Steps per Second: 10,366.48450

Timestep Collection Time: 2.29653
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.82401

Cumulative Model Updates: 213,128
Cumulative Timesteps: 1,777,457,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1777457244...
Checkpoint 1777457244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.61314
Policy Entropy: 2.10479
Value Function Loss: 0.01788

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.18694
Policy Update Magnitude: 0.51440
Value Function Update Magnitude: 0.59965

Collected Steps per Second: 21,621.70855
Overall Steps per Second: 10,305.57406

Timestep Collection Time: 2.31314
Timestep Consumption Time: 2.53996
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.85310

Cumulative Model Updates: 213,134
Cumulative Timesteps: 1,777,507,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.06524
Policy Entropy: 2.12218
Value Function Loss: 0.01689

Mean KL Divergence: 0.03399
SB3 Clip Fraction: 0.21219
Policy Update Magnitude: 0.49398
Value Function Update Magnitude: 0.61144

Collected Steps per Second: 21,887.06140
Overall Steps per Second: 10,469.07344

Timestep Collection Time: 2.28482
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.77674

Cumulative Model Updates: 213,140
Cumulative Timesteps: 1,777,557,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1777557266...
Checkpoint 1777557266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.50179
Policy Entropy: 2.10596
Value Function Loss: 0.01759

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.18617
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 22,569.14220
Overall Steps per Second: 10,522.40720

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.53706
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.75309

Cumulative Model Updates: 213,146
Cumulative Timesteps: 1,777,607,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.99842
Policy Entropy: 2.09638
Value Function Loss: 0.01796

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.17217
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.63841

Collected Steps per Second: 21,899.38091
Overall Steps per Second: 10,353.98668

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.54640
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.83002

Cumulative Model Updates: 213,152
Cumulative Timesteps: 1,777,657,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1777657290...
Checkpoint 1777657290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.77652
Policy Entropy: 2.12221
Value Function Loss: 0.01770

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 21,713.63938
Overall Steps per Second: 10,361.38854

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.82754

Cumulative Model Updates: 213,158
Cumulative Timesteps: 1,777,707,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.86480
Policy Entropy: 2.11671
Value Function Loss: 0.01708

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 22,045.53683
Overall Steps per Second: 10,448.74401

Timestep Collection Time: 2.26858
Timestep Consumption Time: 2.51784
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.78641

Cumulative Model Updates: 213,164
Cumulative Timesteps: 1,777,757,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1777757322...
Checkpoint 1777757322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.76486
Policy Entropy: 2.13654
Value Function Loss: 0.01652

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.56949

Collected Steps per Second: 21,694.72970
Overall Steps per Second: 10,449.47584

Timestep Collection Time: 2.30480
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.78512

Cumulative Model Updates: 213,170
Cumulative Timesteps: 1,777,807,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.69075
Policy Entropy: 2.09419
Value Function Loss: 0.01629

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.53761
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 22,092.51139
Overall Steps per Second: 10,326.48184

Timestep Collection Time: 2.26439
Timestep Consumption Time: 2.58005
PPO Batch Consumption Time: 0.30295
Total Iteration Time: 4.84444

Cumulative Model Updates: 213,176
Cumulative Timesteps: 1,777,857,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1777857350...
Checkpoint 1777857350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.94886
Policy Entropy: 2.08806
Value Function Loss: 0.01653

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 21,541.98532
Overall Steps per Second: 10,168.24252

Timestep Collection Time: 2.32207
Timestep Consumption Time: 2.59736
PPO Batch Consumption Time: 0.30462
Total Iteration Time: 4.91943

Cumulative Model Updates: 213,182
Cumulative Timesteps: 1,777,907,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.52393
Policy Entropy: 2.07555
Value Function Loss: 0.01694

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.58439

Collected Steps per Second: 22,057.69867
Overall Steps per Second: 10,456.12586

Timestep Collection Time: 2.26760
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78361

Cumulative Model Updates: 213,188
Cumulative Timesteps: 1,777,957,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1777957390...
Checkpoint 1777957390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.31015
Policy Entropy: 2.10116
Value Function Loss: 0.01690

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 21,559.00094
Overall Steps per Second: 10,212.18603

Timestep Collection Time: 2.31931
Timestep Consumption Time: 2.57700
PPO Batch Consumption Time: 0.30568
Total Iteration Time: 4.89631

Cumulative Model Updates: 213,194
Cumulative Timesteps: 1,778,007,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.84492
Policy Entropy: 2.12724
Value Function Loss: 0.01655

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.60131

Collected Steps per Second: 21,767.74392
Overall Steps per Second: 10,466.00961

Timestep Collection Time: 2.29817
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.77985

Cumulative Model Updates: 213,200
Cumulative Timesteps: 1,778,057,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1778057418...
Checkpoint 1778057418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.94596
Policy Entropy: 2.16599
Value Function Loss: 0.01627

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 21,834.11641
Overall Steps per Second: 10,292.57014

Timestep Collection Time: 2.29100
Timestep Consumption Time: 2.56901
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.86001

Cumulative Model Updates: 213,206
Cumulative Timesteps: 1,778,107,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.16762
Policy Entropy: 2.16523
Value Function Loss: 0.01614

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.53010
Value Function Update Magnitude: 0.55145

Collected Steps per Second: 21,746.35758
Overall Steps per Second: 10,331.03757

Timestep Collection Time: 2.29960
Timestep Consumption Time: 2.54096
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.84056

Cumulative Model Updates: 213,212
Cumulative Timesteps: 1,778,157,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1778157448...
Checkpoint 1778157448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.54360
Policy Entropy: 2.15865
Value Function Loss: 0.01766

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.52610
Value Function Update Magnitude: 0.55226

Collected Steps per Second: 21,477.50197
Overall Steps per Second: 10,244.14257

Timestep Collection Time: 2.32811
Timestep Consumption Time: 2.55292
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.88103

Cumulative Model Updates: 213,218
Cumulative Timesteps: 1,778,207,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.24016
Policy Entropy: 2.12242
Value Function Loss: 0.01745

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.58713

Collected Steps per Second: 22,053.11377
Overall Steps per Second: 10,460.47808

Timestep Collection Time: 2.26843
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.30308
Total Iteration Time: 4.78238

Cumulative Model Updates: 213,224
Cumulative Timesteps: 1,778,257,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1778257476...
Checkpoint 1778257476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.05842
Policy Entropy: 2.10559
Value Function Loss: 0.01744

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 21,553.17137
Overall Steps per Second: 10,202.97339

Timestep Collection Time: 2.32012
Timestep Consumption Time: 2.58100
PPO Batch Consumption Time: 0.30309
Total Iteration Time: 4.90112

Cumulative Model Updates: 213,230
Cumulative Timesteps: 1,778,307,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.97339
Policy Entropy: 2.10579
Value Function Loss: 0.01696

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.59650

Collected Steps per Second: 22,171.58604
Overall Steps per Second: 10,450.33032

Timestep Collection Time: 2.25640
Timestep Consumption Time: 2.53082
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.78722

Cumulative Model Updates: 213,236
Cumulative Timesteps: 1,778,357,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1778357510...
Checkpoint 1778357510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.08300
Policy Entropy: 2.10301
Value Function Loss: 0.01636

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.53742
Value Function Update Magnitude: 0.60409

Collected Steps per Second: 21,553.73959
Overall Steps per Second: 10,505.37129

Timestep Collection Time: 2.32043
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.76080

Cumulative Model Updates: 213,242
Cumulative Timesteps: 1,778,407,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.75186
Policy Entropy: 2.10460
Value Function Loss: 0.01669

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.62443

Collected Steps per Second: 22,070.30610
Overall Steps per Second: 10,315.35019

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.58228
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.84831

Cumulative Model Updates: 213,248
Cumulative Timesteps: 1,778,457,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1778457536...
Checkpoint 1778457536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.75319
Policy Entropy: 2.13137
Value Function Loss: 0.01683

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.53958
Value Function Update Magnitude: 0.63177

Collected Steps per Second: 21,958.96029
Overall Steps per Second: 10,425.83119

Timestep Collection Time: 2.27843
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.79885

Cumulative Model Updates: 213,254
Cumulative Timesteps: 1,778,507,568

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.61942
Policy Entropy: 2.13982
Value Function Loss: 0.01744

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.62172

Collected Steps per Second: 21,805.87039
Overall Steps per Second: 10,401.80339

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.80974

Cumulative Model Updates: 213,260
Cumulative Timesteps: 1,778,557,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1778557598...
Checkpoint 1778557598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.98321
Policy Entropy: 2.12850
Value Function Loss: 0.01710

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.62428

Collected Steps per Second: 21,926.77167
Overall Steps per Second: 10,300.82469

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.57490
PPO Batch Consumption Time: 0.30488
Total Iteration Time: 4.85631

Cumulative Model Updates: 213,266
Cumulative Timesteps: 1,778,607,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.09610
Policy Entropy: 2.09995
Value Function Loss: 0.01791

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.64863

Collected Steps per Second: 22,808.85108
Overall Steps per Second: 10,480.89335

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.57887
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 4.77135

Cumulative Model Updates: 213,272
Cumulative Timesteps: 1,778,657,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1778657630...
Checkpoint 1778657630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.11295
Policy Entropy: 2.11264
Value Function Loss: 0.01785

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.67071

Collected Steps per Second: 21,714.17844
Overall Steps per Second: 10,208.39028

Timestep Collection Time: 2.30338
Timestep Consumption Time: 2.59612
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.89950

Cumulative Model Updates: 213,278
Cumulative Timesteps: 1,778,707,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.64302
Policy Entropy: 2.13525
Value Function Loss: 0.01720

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.65291

Collected Steps per Second: 21,874.57811
Overall Steps per Second: 10,347.10222

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.54661
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.83246

Cumulative Model Updates: 213,284
Cumulative Timesteps: 1,778,757,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1778757648...
Checkpoint 1778757648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.24174
Policy Entropy: 2.14349
Value Function Loss: 0.01721

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 21,737.29229
Overall Steps per Second: 10,460.17271

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.47994
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 4.78023

Cumulative Model Updates: 213,290
Cumulative Timesteps: 1,778,807,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.39826
Policy Entropy: 2.11555
Value Function Loss: 0.01754

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.54705
Value Function Update Magnitude: 0.62394

Collected Steps per Second: 21,428.93754
Overall Steps per Second: 10,304.51488

Timestep Collection Time: 2.33339
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.30527
Total Iteration Time: 4.85244

Cumulative Model Updates: 213,296
Cumulative Timesteps: 1,778,857,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1778857652...
Checkpoint 1778857652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.96699
Policy Entropy: 2.08943
Value Function Loss: 0.01641

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.53635
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 21,735.58975
Overall Steps per Second: 10,198.01620

Timestep Collection Time: 2.30120
Timestep Consumption Time: 2.60348
PPO Batch Consumption Time: 0.30488
Total Iteration Time: 4.90468

Cumulative Model Updates: 213,302
Cumulative Timesteps: 1,778,907,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.73021
Policy Entropy: 2.09227
Value Function Loss: 0.01698

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.63486

Collected Steps per Second: 21,722.70971
Overall Steps per Second: 10,347.38082

Timestep Collection Time: 2.30303
Timestep Consumption Time: 2.53182
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.83485

Cumulative Model Updates: 213,308
Cumulative Timesteps: 1,778,957,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1778957698...
Checkpoint 1778957698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.13087
Policy Entropy: 2.09606
Value Function Loss: 0.01743

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.55011
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 21,955.24241
Overall Steps per Second: 10,330.82693

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.56283
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 4.84046

Cumulative Model Updates: 213,314
Cumulative Timesteps: 1,779,007,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.35907
Policy Entropy: 2.10899
Value Function Loss: 0.01802

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.61899

Collected Steps per Second: 22,079.35724
Overall Steps per Second: 10,437.89581

Timestep Collection Time: 2.26546
Timestep Consumption Time: 2.52669
PPO Batch Consumption Time: 0.30471
Total Iteration Time: 4.79215

Cumulative Model Updates: 213,320
Cumulative Timesteps: 1,779,057,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1779057724...
Checkpoint 1779057724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.23222
Policy Entropy: 2.09692
Value Function Loss: 0.01806

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.60032

Collected Steps per Second: 21,749.94340
Overall Steps per Second: 10,215.86749

Timestep Collection Time: 2.29978
Timestep Consumption Time: 2.59653
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 4.89630

Cumulative Model Updates: 213,326
Cumulative Timesteps: 1,779,107,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.06000
Policy Entropy: 2.10577
Value Function Loss: 0.01697

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 21,692.32968
Overall Steps per Second: 10,311.40637

Timestep Collection Time: 2.30515
Timestep Consumption Time: 2.54424
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.84939

Cumulative Model Updates: 213,332
Cumulative Timesteps: 1,779,157,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1779157748...
Checkpoint 1779157748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.62357
Policy Entropy: 2.11506
Value Function Loss: 0.01647

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 21,971.58728
Overall Steps per Second: 10,339.50651

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.56067
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.83679

Cumulative Model Updates: 213,338
Cumulative Timesteps: 1,779,207,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.96325
Policy Entropy: 2.13367
Value Function Loss: 0.01630

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.52870
Value Function Update Magnitude: 0.59256

Collected Steps per Second: 21,909.28527
Overall Steps per Second: 10,485.00737

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.48747
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.77043

Cumulative Model Updates: 213,344
Cumulative Timesteps: 1,779,257,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1779257776...
Checkpoint 1779257776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.10351
Policy Entropy: 2.12776
Value Function Loss: 0.01821

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.59340

Collected Steps per Second: 21,709.66805
Overall Steps per Second: 10,215.60183

Timestep Collection Time: 2.30331
Timestep Consumption Time: 2.59156
PPO Batch Consumption Time: 0.30582
Total Iteration Time: 4.89487

Cumulative Model Updates: 213,350
Cumulative Timesteps: 1,779,307,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.47467
Policy Entropy: 2.12450
Value Function Loss: 0.01921

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.62881

Collected Steps per Second: 21,894.44552
Overall Steps per Second: 10,316.03349

Timestep Collection Time: 2.28478
Timestep Consumption Time: 2.56437
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.84915

Cumulative Model Updates: 213,356
Cumulative Timesteps: 1,779,357,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1779357804...
Checkpoint 1779357804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.04223
Policy Entropy: 2.13450
Value Function Loss: 0.01879

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.65412

Collected Steps per Second: 21,976.70541
Overall Steps per Second: 10,311.49993

Timestep Collection Time: 2.27532
Timestep Consumption Time: 2.57402
PPO Batch Consumption Time: 0.30476
Total Iteration Time: 4.84934

Cumulative Model Updates: 213,362
Cumulative Timesteps: 1,779,407,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.73876
Policy Entropy: 2.11880
Value Function Loss: 0.01835

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.15308
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.64497

Collected Steps per Second: 21,795.66538
Overall Steps per Second: 10,484.90682

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.77181

Cumulative Model Updates: 213,368
Cumulative Timesteps: 1,779,457,840

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1779457840...
Checkpoint 1779457840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.21266
Policy Entropy: 2.12028
Value Function Loss: 0.01698

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16016
Policy Update Magnitude: 0.53392
Value Function Update Magnitude: 0.62963

Collected Steps per Second: 22,036.13869
Overall Steps per Second: 10,359.16787

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.55856
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.82838

Cumulative Model Updates: 213,374
Cumulative Timesteps: 1,779,507,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.99177
Policy Entropy: 2.10948
Value Function Loss: 0.01711

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.18995
Policy Update Magnitude: 0.51735
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 21,892.73680
Overall Steps per Second: 10,271.30587

Timestep Collection Time: 2.28441
Timestep Consumption Time: 2.58469
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.86910

Cumulative Model Updates: 213,380
Cumulative Timesteps: 1,779,557,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1779557870...
Checkpoint 1779557870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.12028
Policy Entropy: 2.14794
Value Function Loss: 0.01610

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.16855
Policy Update Magnitude: 0.52738
Value Function Update Magnitude: 0.59091

Collected Steps per Second: 21,520.57438
Overall Steps per Second: 10,214.59536

Timestep Collection Time: 2.32373
Timestep Consumption Time: 2.57201
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.89574

Cumulative Model Updates: 213,386
Cumulative Timesteps: 1,779,607,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.81315
Policy Entropy: 2.12876
Value Function Loss: 0.01751

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 22,135.69773
Overall Steps per Second: 10,474.76898

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.30488
Total Iteration Time: 4.77357

Cumulative Model Updates: 213,392
Cumulative Timesteps: 1,779,657,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1779657880...
Checkpoint 1779657880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.10144
Policy Entropy: 2.13015
Value Function Loss: 0.01806

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.59065

Collected Steps per Second: 20,668.38777
Overall Steps per Second: 10,201.90547

Timestep Collection Time: 2.42051
Timestep Consumption Time: 2.48328
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.90379

Cumulative Model Updates: 213,398
Cumulative Timesteps: 1,779,707,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.76094
Policy Entropy: 2.10505
Value Function Loss: 0.01732

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.54673
Value Function Update Magnitude: 0.61158

Collected Steps per Second: 21,963.26331
Overall Steps per Second: 10,376.90693

Timestep Collection Time: 2.27708
Timestep Consumption Time: 2.54247
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.81955

Cumulative Model Updates: 213,404
Cumulative Timesteps: 1,779,757,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1779757920...
Checkpoint 1779757920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.31006
Policy Entropy: 2.12049
Value Function Loss: 0.01603

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.53922
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 21,970.33083
Overall Steps per Second: 10,298.85544

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.57973
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.85607

Cumulative Model Updates: 213,410
Cumulative Timesteps: 1,779,807,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.03049
Policy Entropy: 2.10311
Value Function Loss: 0.01543

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.60323

Collected Steps per Second: 21,701.20358
Overall Steps per Second: 10,393.22935

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.81217

Cumulative Model Updates: 213,416
Cumulative Timesteps: 1,779,857,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1779857946...
Checkpoint 1779857946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.28091
Policy Entropy: 2.11001
Value Function Loss: 0.01558

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 21,742.78525
Overall Steps per Second: 10,508.23305

Timestep Collection Time: 2.30072
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.76046

Cumulative Model Updates: 213,422
Cumulative Timesteps: 1,779,907,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.90662
Policy Entropy: 2.12039
Value Function Loss: 0.01705

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 22,016.57358
Overall Steps per Second: 10,275.85938

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.59548
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.86714

Cumulative Model Updates: 213,428
Cumulative Timesteps: 1,779,957,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1779957984...
Checkpoint 1779957984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.72823
Policy Entropy: 2.14613
Value Function Loss: 0.01666

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.52218
Value Function Update Magnitude: 0.61162

Collected Steps per Second: 21,343.55370
Overall Steps per Second: 10,145.11726

Timestep Collection Time: 2.34272
Timestep Consumption Time: 2.58596
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.92868

Cumulative Model Updates: 213,434
Cumulative Timesteps: 1,780,007,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.99928
Policy Entropy: 2.14097
Value Function Loss: 0.01690

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.51719
Value Function Update Magnitude: 0.59799

Collected Steps per Second: 21,945.74325
Overall Steps per Second: 10,408.23742

Timestep Collection Time: 2.27844
Timestep Consumption Time: 2.52564
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80408

Cumulative Model Updates: 213,440
Cumulative Timesteps: 1,780,057,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1780057988...
Checkpoint 1780057988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.28658
Policy Entropy: 2.13006
Value Function Loss: 0.01640

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.57317

Collected Steps per Second: 21,500.21815
Overall Steps per Second: 10,277.25895

Timestep Collection Time: 2.32640
Timestep Consumption Time: 2.54047
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.86686

Cumulative Model Updates: 213,446
Cumulative Timesteps: 1,780,108,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.43460
Policy Entropy: 2.09919
Value Function Loss: 0.01706

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.58197

Collected Steps per Second: 21,726.39565
Overall Steps per Second: 10,449.36643

Timestep Collection Time: 2.30181
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.78594

Cumulative Model Updates: 213,452
Cumulative Timesteps: 1,780,158,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1780158016...
Checkpoint 1780158016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.95437
Policy Entropy: 2.10277
Value Function Loss: 0.01656

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 21,653.46458
Overall Steps per Second: 10,200.24162

Timestep Collection Time: 2.31039
Timestep Consumption Time: 2.59420
PPO Batch Consumption Time: 0.30416
Total Iteration Time: 4.90459

Cumulative Model Updates: 213,458
Cumulative Timesteps: 1,780,208,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.01377
Policy Entropy: 2.12821
Value Function Loss: 0.01709

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,039.85201
Overall Steps per Second: 10,415.82107

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.53319
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.80308

Cumulative Model Updates: 213,464
Cumulative Timesteps: 1,780,258,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1780258072...
Checkpoint 1780258072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.25695
Policy Entropy: 2.13683
Value Function Loss: 0.01814

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.60577

Collected Steps per Second: 21,450.75323
Overall Steps per Second: 10,274.26380

Timestep Collection Time: 2.33148
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.86770

Cumulative Model Updates: 213,470
Cumulative Timesteps: 1,780,308,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.71875
Policy Entropy: 2.12857
Value Function Loss: 0.01888

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.54454
Value Function Update Magnitude: 0.61203

Collected Steps per Second: 22,092.69552
Overall Steps per Second: 10,451.32906

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.52210
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.78638

Cumulative Model Updates: 213,476
Cumulative Timesteps: 1,780,358,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1780358108...
Checkpoint 1780358108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.47468
Policy Entropy: 2.11286
Value Function Loss: 0.01830

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.59586

Collected Steps per Second: 21,692.57686
Overall Steps per Second: 10,211.05598

Timestep Collection Time: 2.30632
Timestep Consumption Time: 2.59327
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.89959

Cumulative Model Updates: 213,482
Cumulative Timesteps: 1,780,408,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.20352
Policy Entropy: 2.12246
Value Function Loss: 0.01908

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.60731

Collected Steps per Second: 22,168.72418
Overall Steps per Second: 10,453.45384

Timestep Collection Time: 2.25570
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.78368

Cumulative Model Updates: 213,488
Cumulative Timesteps: 1,780,458,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1780458144...
Checkpoint 1780458144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.72730
Policy Entropy: 2.14564
Value Function Loss: 0.01838

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.64169

Collected Steps per Second: 21,632.49760
Overall Steps per Second: 10,295.18108

Timestep Collection Time: 2.31226
Timestep Consumption Time: 2.54632
PPO Batch Consumption Time: 0.30329
Total Iteration Time: 4.85858

Cumulative Model Updates: 213,494
Cumulative Timesteps: 1,780,508,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.04758
Policy Entropy: 2.12423
Value Function Loss: 0.01897

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.54582
Value Function Update Magnitude: 0.65049

Collected Steps per Second: 22,030.41258
Overall Steps per Second: 10,478.15557

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.77317

Cumulative Model Updates: 213,500
Cumulative Timesteps: 1,780,558,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1780558178...
Checkpoint 1780558178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.82347
Policy Entropy: 2.13963
Value Function Loss: 0.01891

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.63367

Collected Steps per Second: 21,726.70733
Overall Steps per Second: 10,272.77539

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.56725
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.86976

Cumulative Model Updates: 213,506
Cumulative Timesteps: 1,780,608,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.96023
Policy Entropy: 2.13993
Value Function Loss: 0.01912

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,326.30214
Overall Steps per Second: 10,380.74727

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.57833
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.81892

Cumulative Model Updates: 213,512
Cumulative Timesteps: 1,780,658,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1780658228...
Checkpoint 1780658228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.61817
Policy Entropy: 2.17760
Value Function Loss: 0.01817

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.59558

Collected Steps per Second: 21,615.53083
Overall Steps per Second: 10,279.27163

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.55213
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.86630

Cumulative Model Updates: 213,518
Cumulative Timesteps: 1,780,708,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.34440
Policy Entropy: 2.15180
Value Function Loss: 0.01821

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.53662
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 22,012.60451
Overall Steps per Second: 10,333.41059

Timestep Collection Time: 2.27143
Timestep Consumption Time: 2.56725
PPO Batch Consumption Time: 0.30431
Total Iteration Time: 4.83867

Cumulative Model Updates: 213,524
Cumulative Timesteps: 1,780,758,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1780758250...
Checkpoint 1780758250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.71274
Policy Entropy: 2.15203
Value Function Loss: 0.01810

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.59336

Collected Steps per Second: 21,597.33619
Overall Steps per Second: 10,493.13388

Timestep Collection Time: 2.31686
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.76864

Cumulative Model Updates: 213,530
Cumulative Timesteps: 1,780,808,288

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.98366
Policy Entropy: 2.15309
Value Function Loss: 0.01732

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.60567

Collected Steps per Second: 22,069.51540
Overall Steps per Second: 10,363.92218

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.55999
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.82655

Cumulative Model Updates: 213,536
Cumulative Timesteps: 1,780,858,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1780858310...
Checkpoint 1780858310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.49646
Policy Entropy: 2.15671
Value Function Loss: 0.01690

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.52737
Value Function Update Magnitude: 0.58835

Collected Steps per Second: 21,559.18884
Overall Steps per Second: 10,329.78946

Timestep Collection Time: 2.32040
Timestep Consumption Time: 2.52248
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.84289

Cumulative Model Updates: 213,542
Cumulative Timesteps: 1,780,908,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.66699
Policy Entropy: 2.15647
Value Function Loss: 0.01734

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.53503
Value Function Update Magnitude: 0.55908

Collected Steps per Second: 22,046.25003
Overall Steps per Second: 10,464.59122

Timestep Collection Time: 2.26796
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.77802

Cumulative Model Updates: 213,548
Cumulative Timesteps: 1,780,958,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1780958336...
Checkpoint 1780958336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.19783
Policy Entropy: 2.13503
Value Function Loss: 0.01753

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.55671

Collected Steps per Second: 22,006.77691
Overall Steps per Second: 10,606.64967

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.44248
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.71497

Cumulative Model Updates: 213,554
Cumulative Timesteps: 1,781,008,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.55595
Policy Entropy: 2.14417
Value Function Loss: 0.01744

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.53531
Value Function Update Magnitude: 0.56070

Collected Steps per Second: 22,256.45486
Overall Steps per Second: 10,235.98129

Timestep Collection Time: 2.24672
Timestep Consumption Time: 2.63840
PPO Batch Consumption Time: 0.31088
Total Iteration Time: 4.88512

Cumulative Model Updates: 213,560
Cumulative Timesteps: 1,781,058,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1781058350...
Checkpoint 1781058350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.32115
Policy Entropy: 2.11799
Value Function Loss: 0.01688

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.57121

Collected Steps per Second: 19,844.37370
Overall Steps per Second: 9,873.56638

Timestep Collection Time: 2.51991
Timestep Consumption Time: 2.54473
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 5.06463

Cumulative Model Updates: 213,566
Cumulative Timesteps: 1,781,108,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.38709
Policy Entropy: 2.10706
Value Function Loss: 0.01778

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.58678

Collected Steps per Second: 21,002.66878
Overall Steps per Second: 10,255.20849

Timestep Collection Time: 2.38198
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.87830

Cumulative Model Updates: 213,572
Cumulative Timesteps: 1,781,158,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1781158384...
Checkpoint 1781158384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.40119
Policy Entropy: 2.09638
Value Function Loss: 0.01735

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.58678

Collected Steps per Second: 22,088.61045
Overall Steps per Second: 10,620.67626

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.44546
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71025

Cumulative Model Updates: 213,578
Cumulative Timesteps: 1,781,208,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.14763
Policy Entropy: 2.11499
Value Function Loss: 0.01770

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 21,313.10490
Overall Steps per Second: 10,174.32320

Timestep Collection Time: 2.34701
Timestep Consumption Time: 2.56949
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.91649

Cumulative Model Updates: 213,584
Cumulative Timesteps: 1,781,258,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1781258432...
Checkpoint 1781258432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.57530
Policy Entropy: 2.12066
Value Function Loss: 0.01785

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.57915

Collected Steps per Second: 21,474.37421
Overall Steps per Second: 10,187.77586

Timestep Collection Time: 2.32929
Timestep Consumption Time: 2.58052
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.90981

Cumulative Model Updates: 213,590
Cumulative Timesteps: 1,781,308,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.89277
Policy Entropy: 2.13119
Value Function Loss: 0.01805

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.60307

Collected Steps per Second: 21,664.79573
Overall Steps per Second: 10,383.49610

Timestep Collection Time: 2.30909
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.81784

Cumulative Model Updates: 213,596
Cumulative Timesteps: 1,781,358,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1781358478...
Checkpoint 1781358478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.59409
Policy Entropy: 2.09825
Value Function Loss: 0.01864

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 21,882.27563
Overall Steps per Second: 10,519.64191

Timestep Collection Time: 2.28541
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.75396

Cumulative Model Updates: 213,602
Cumulative Timesteps: 1,781,408,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.37656
Policy Entropy: 2.10395
Value Function Loss: 0.01834

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.55549
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 21,934.87591
Overall Steps per Second: 10,225.14395

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.61064
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.89030

Cumulative Model Updates: 213,608
Cumulative Timesteps: 1,781,458,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1781458492...
Checkpoint 1781458492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.45897
Policy Entropy: 2.08649
Value Function Loss: 0.01848

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.63354

Collected Steps per Second: 21,828.55876
Overall Steps per Second: 10,261.96127

Timestep Collection Time: 2.29159
Timestep Consumption Time: 2.58292
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.87451

Cumulative Model Updates: 213,614
Cumulative Timesteps: 1,781,508,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.69958
Policy Entropy: 2.13033
Value Function Loss: 0.01759

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.63022

Collected Steps per Second: 21,873.49918
Overall Steps per Second: 10,419.67706

Timestep Collection Time: 2.28688
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.80072

Cumulative Model Updates: 213,620
Cumulative Timesteps: 1,781,558,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1781558536...
Checkpoint 1781558536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.37222
Policy Entropy: 2.17112
Value Function Loss: 0.01670

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 21,697.88440
Overall Steps per Second: 10,543.48572

Timestep Collection Time: 2.30520
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.74397

Cumulative Model Updates: 213,626
Cumulative Timesteps: 1,781,608,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.96405
Policy Entropy: 2.15158
Value Function Loss: 0.01708

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.53307
Value Function Update Magnitude: 0.61277

Collected Steps per Second: 21,897.43461
Overall Steps per Second: 10,298.14086

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.57187
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.85525

Cumulative Model Updates: 213,632
Cumulative Timesteps: 1,781,658,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1781658554...
Checkpoint 1781658554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.37272
Policy Entropy: 2.14366
Value Function Loss: 0.01758

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.60420

Collected Steps per Second: 21,768.73852
Overall Steps per Second: 10,348.87176

Timestep Collection Time: 2.29696
Timestep Consumption Time: 2.53467
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.83164

Cumulative Model Updates: 213,638
Cumulative Timesteps: 1,781,708,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.71879
Policy Entropy: 2.10309
Value Function Loss: 0.01860

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.61691

Collected Steps per Second: 20,181.01080
Overall Steps per Second: 10,026.74802

Timestep Collection Time: 2.47777
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.98706

Cumulative Model Updates: 213,644
Cumulative Timesteps: 1,781,758,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1781758560...
Checkpoint 1781758560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.31982
Policy Entropy: 2.14037
Value Function Loss: 0.01813

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 20,741.66312
Overall Steps per Second: 10,574.62555

Timestep Collection Time: 2.41147
Timestep Consumption Time: 2.31853
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.73000

Cumulative Model Updates: 213,650
Cumulative Timesteps: 1,781,808,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.05943
Policy Entropy: 2.12246
Value Function Loss: 0.01879

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.62410

Collected Steps per Second: 21,893.90602
Overall Steps per Second: 10,442.58239

Timestep Collection Time: 2.28502
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.79077

Cumulative Model Updates: 213,656
Cumulative Timesteps: 1,781,858,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1781858606...
Checkpoint 1781858606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.38535
Policy Entropy: 2.13201
Value Function Loss: 0.01772

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 23,048.14055
Overall Steps per Second: 10,731.44970

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.49063
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.66069

Cumulative Model Updates: 213,662
Cumulative Timesteps: 1,781,908,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.15526
Policy Entropy: 2.10782
Value Function Loss: 0.01859

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.59430

Collected Steps per Second: 23,052.49287
Overall Steps per Second: 10,708.27960

Timestep Collection Time: 2.17026
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67209

Cumulative Model Updates: 213,668
Cumulative Timesteps: 1,781,958,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1781958652...
Checkpoint 1781958652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.63956
Policy Entropy: 2.09900
Value Function Loss: 0.01871

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.62050

Collected Steps per Second: 22,739.90697
Overall Steps per Second: 10,669.26453

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.68898

Cumulative Model Updates: 213,674
Cumulative Timesteps: 1,782,008,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.10648
Policy Entropy: 2.08070
Value Function Loss: 0.02020

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.63167

Collected Steps per Second: 23,477.49104
Overall Steps per Second: 10,878.09359

Timestep Collection Time: 2.13013
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.59731

Cumulative Model Updates: 213,680
Cumulative Timesteps: 1,782,058,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1782058690...
Checkpoint 1782058690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.03165
Policy Entropy: 2.08508
Value Function Loss: 0.01986

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.63379

Collected Steps per Second: 23,135.87480
Overall Steps per Second: 10,744.98013

Timestep Collection Time: 2.16236
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.65594

Cumulative Model Updates: 213,686
Cumulative Timesteps: 1,782,108,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.14096
Policy Entropy: 2.09714
Value Function Loss: 0.02007

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 22,909.17696
Overall Steps per Second: 10,815.21967

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62533

Cumulative Model Updates: 213,692
Cumulative Timesteps: 1,782,158,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1782158742...
Checkpoint 1782158742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.61135
Policy Entropy: 2.09208
Value Function Loss: 0.01835

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.59636

Collected Steps per Second: 22,527.18727
Overall Steps per Second: 10,475.02675

Timestep Collection Time: 2.21954
Timestep Consumption Time: 2.55372
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.77326

Cumulative Model Updates: 213,698
Cumulative Timesteps: 1,782,208,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.57042
Policy Entropy: 2.09173
Value Function Loss: 0.01892

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.60538

Collected Steps per Second: 22,554.15936
Overall Steps per Second: 10,828.15399

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.61981

Cumulative Model Updates: 213,704
Cumulative Timesteps: 1,782,258,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1782258766...
Checkpoint 1782258766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.33761
Policy Entropy: 2.09586
Value Function Loss: 0.01773

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.63169

Collected Steps per Second: 22,717.68725
Overall Steps per Second: 10,799.66024

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.63144

Cumulative Model Updates: 213,710
Cumulative Timesteps: 1,782,308,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.65115
Policy Entropy: 2.12511
Value Function Loss: 0.01895

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.15166
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.64678

Collected Steps per Second: 23,004.86804
Overall Steps per Second: 10,559.07988

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.56201
PPO Batch Consumption Time: 0.30181
Total Iteration Time: 4.73564

Cumulative Model Updates: 213,716
Cumulative Timesteps: 1,782,358,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1782358788...
Checkpoint 1782358788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.97985
Policy Entropy: 2.12634
Value Function Loss: 0.01862

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.63640

Collected Steps per Second: 22,561.71961
Overall Steps per Second: 10,592.18300

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.72197

Cumulative Model Updates: 213,722
Cumulative Timesteps: 1,782,408,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.28797
Policy Entropy: 2.12364
Value Function Loss: 0.01908

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.61150

Collected Steps per Second: 19,998.72315
Overall Steps per Second: 9,925.47166

Timestep Collection Time: 2.50146
Timestep Consumption Time: 2.53870
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 5.04016

Cumulative Model Updates: 213,728
Cumulative Timesteps: 1,782,458,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1782458830...
Checkpoint 1782458830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.11357
Policy Entropy: 2.12496
Value Function Loss: 0.01793

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 21,647.03312
Overall Steps per Second: 10,258.34362

Timestep Collection Time: 2.31034
Timestep Consumption Time: 2.56491
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 4.87525

Cumulative Model Updates: 213,734
Cumulative Timesteps: 1,782,508,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.33925
Policy Entropy: 2.13190
Value Function Loss: 0.01798

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,091.76540
Overall Steps per Second: 10,505.47105

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76152

Cumulative Model Updates: 213,740
Cumulative Timesteps: 1,782,558,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1782558864...
Checkpoint 1782558864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.26328
Policy Entropy: 2.12883
Value Function Loss: 0.01813

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 22,045.60066
Overall Steps per Second: 10,633.73991

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70465

Cumulative Model Updates: 213,746
Cumulative Timesteps: 1,782,608,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.34403
Policy Entropy: 2.12004
Value Function Loss: 0.01863

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 22,550.44078
Overall Steps per Second: 10,475.68122

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.55632
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.77410

Cumulative Model Updates: 213,752
Cumulative Timesteps: 1,782,658,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1782658904...
Checkpoint 1782658904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.73538
Policy Entropy: 2.13841
Value Function Loss: 0.01844

Mean KL Divergence: 0.02805
SB3 Clip Fraction: 0.17537
Policy Update Magnitude: 0.52251
Value Function Update Magnitude: 0.61152

Collected Steps per Second: 22,180.85444
Overall Steps per Second: 10,540.92996

Timestep Collection Time: 2.25420
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.74341

Cumulative Model Updates: 213,758
Cumulative Timesteps: 1,782,708,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.39620
Policy Entropy: 2.14157
Value Function Loss: 0.01769

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.16463
Policy Update Magnitude: 0.50949
Value Function Update Magnitude: 0.59758

Collected Steps per Second: 21,963.32353
Overall Steps per Second: 10,486.00143

Timestep Collection Time: 2.27743
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.77017

Cumulative Model Updates: 213,764
Cumulative Timesteps: 1,782,758,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1782758924...
Checkpoint 1782758924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.47197
Policy Entropy: 2.15132
Value Function Loss: 0.01796

Mean KL Divergence: 0.02291
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.53369
Value Function Update Magnitude: 0.58822

Collected Steps per Second: 22,184.68254
Overall Steps per Second: 10,600.80534

Timestep Collection Time: 2.25480
Timestep Consumption Time: 2.46390
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.71870

Cumulative Model Updates: 213,770
Cumulative Timesteps: 1,782,808,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.03591
Policy Entropy: 2.11790
Value Function Loss: 0.01784

Mean KL Divergence: 0.02534
SB3 Clip Fraction: 0.17217
Policy Update Magnitude: 0.54138
Value Function Update Magnitude: 0.60631

Collected Steps per Second: 22,196.26547
Overall Steps per Second: 10,589.23361

Timestep Collection Time: 2.25272
Timestep Consumption Time: 2.46924
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.72197

Cumulative Model Updates: 213,776
Cumulative Timesteps: 1,782,858,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1782858948...
Checkpoint 1782858948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.69929
Policy Entropy: 2.09106
Value Function Loss: 0.01792

Mean KL Divergence: 0.02899
SB3 Clip Fraction: 0.18662
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.61387

Collected Steps per Second: 22,192.14510
Overall Steps per Second: 10,520.41965

Timestep Collection Time: 2.25413
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.75494

Cumulative Model Updates: 213,782
Cumulative Timesteps: 1,782,908,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.22864
Policy Entropy: 2.07730
Value Function Loss: 0.01819

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.18589
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.60180

Collected Steps per Second: 19,220.48455
Overall Steps per Second: 9,723.64168

Timestep Collection Time: 2.60264
Timestep Consumption Time: 2.54193
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 5.14457

Cumulative Model Updates: 213,788
Cumulative Timesteps: 1,782,958,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1782958996...
Checkpoint 1782958996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.39210
Policy Entropy: 2.10894
Value Function Loss: 0.01795

Mean KL Divergence: 0.03297
SB3 Clip Fraction: 0.19702
Policy Update Magnitude: 0.51397
Value Function Update Magnitude: 0.57981

Collected Steps per Second: 18,296.67654
Overall Steps per Second: 8,731.24395

Timestep Collection Time: 2.73470
Timestep Consumption Time: 2.99598
PPO Batch Consumption Time: 0.36249
Total Iteration Time: 5.73068

Cumulative Model Updates: 213,794
Cumulative Timesteps: 1,783,009,032

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.00515
Policy Entropy: 2.14169
Value Function Loss: 0.01808

Mean KL Divergence: 0.02496
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.57177

Collected Steps per Second: 19,466.63294
Overall Steps per Second: 9,954.03592

Timestep Collection Time: 2.56953
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 5.02510

Cumulative Model Updates: 213,800
Cumulative Timesteps: 1,783,059,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1783059052...
Checkpoint 1783059052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.63836
Policy Entropy: 2.14654
Value Function Loss: 0.01719

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.57824

Collected Steps per Second: 19,911.19800
Overall Steps per Second: 9,856.30614

Timestep Collection Time: 2.51256
Timestep Consumption Time: 2.56318
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 5.07574

Cumulative Model Updates: 213,806
Cumulative Timesteps: 1,783,109,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.63067
Policy Entropy: 2.14537
Value Function Loss: 0.01730

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.59296

Collected Steps per Second: 21,890.92255
Overall Steps per Second: 10,387.60183

Timestep Collection Time: 2.28442
Timestep Consumption Time: 2.52978
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.81420

Cumulative Model Updates: 213,812
Cumulative Timesteps: 1,783,159,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1783159088...
Checkpoint 1783159088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.84505
Policy Entropy: 2.13812
Value Function Loss: 0.01697

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.54936
Value Function Update Magnitude: 0.61465

Collected Steps per Second: 21,553.73890
Overall Steps per Second: 10,313.20120

Timestep Collection Time: 2.32015
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.84893

Cumulative Model Updates: 213,818
Cumulative Timesteps: 1,783,209,096

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.45724
Policy Entropy: 2.14159
Value Function Loss: 0.01696

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.60988

Collected Steps per Second: 21,801.26632
Overall Steps per Second: 10,413.15653

Timestep Collection Time: 2.29427
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.80335

Cumulative Model Updates: 213,824
Cumulative Timesteps: 1,783,259,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1783259114...
Checkpoint 1783259114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.25407
Policy Entropy: 2.11347
Value Function Loss: 0.01686

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.59523

Collected Steps per Second: 21,047.96959
Overall Steps per Second: 10,251.64800

Timestep Collection Time: 2.37667
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.87961

Cumulative Model Updates: 213,830
Cumulative Timesteps: 1,783,309,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.63254
Policy Entropy: 2.13030
Value Function Loss: 0.01649

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.59525

Collected Steps per Second: 21,962.85402
Overall Steps per Second: 10,384.02697

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.54004
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.81798

Cumulative Model Updates: 213,836
Cumulative Timesteps: 1,783,359,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1783359168...
Checkpoint 1783359168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.83403
Policy Entropy: 2.11511
Value Function Loss: 0.01747

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.61147

Collected Steps per Second: 21,680.67955
Overall Steps per Second: 10,306.27961

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.54653
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.85393

Cumulative Model Updates: 213,842
Cumulative Timesteps: 1,783,409,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.64457
Policy Entropy: 2.15126
Value Function Loss: 0.01761

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 21,833.43102
Overall Steps per Second: 10,408.65545

Timestep Collection Time: 2.29043
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.80446

Cumulative Model Updates: 213,848
Cumulative Timesteps: 1,783,459,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1783459202...
Checkpoint 1783459202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.70599
Policy Entropy: 2.14479
Value Function Loss: 0.01705

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.55501
Value Function Update Magnitude: 0.64253

Collected Steps per Second: 21,555.85324
Overall Steps per Second: 10,436.58112

Timestep Collection Time: 2.32058
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.79295

Cumulative Model Updates: 213,854
Cumulative Timesteps: 1,783,509,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.85628
Policy Entropy: 2.16405
Value Function Loss: 0.01680

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.54364
Value Function Update Magnitude: 0.64014

Collected Steps per Second: 22,064.50975
Overall Steps per Second: 10,299.16958

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.58909
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.85554

Cumulative Model Updates: 213,860
Cumulative Timesteps: 1,783,559,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1783559232...
Checkpoint 1783559232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.57405
Policy Entropy: 2.15218
Value Function Loss: 0.01745

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.63278

Collected Steps per Second: 21,366.35827
Overall Steps per Second: 10,185.18822

Timestep Collection Time: 2.34050
Timestep Consumption Time: 2.56937
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.90987

Cumulative Model Updates: 213,866
Cumulative Timesteps: 1,783,609,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.81242
Policy Entropy: 2.14108
Value Function Loss: 0.01718

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.62014

Collected Steps per Second: 22,052.75237
Overall Steps per Second: 10,472.81011

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.77618

Cumulative Model Updates: 213,872
Cumulative Timesteps: 1,783,659,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1783659260...
Checkpoint 1783659260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.29710
Policy Entropy: 2.12018
Value Function Loss: 0.01813

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.60392

Collected Steps per Second: 21,543.01384
Overall Steps per Second: 10,507.91682

Timestep Collection Time: 2.32187
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.76022

Cumulative Model Updates: 213,878
Cumulative Timesteps: 1,783,709,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.83291
Policy Entropy: 2.12205
Value Function Loss: 0.01703

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.59528

Collected Steps per Second: 21,791.45902
Overall Steps per Second: 10,284.63639

Timestep Collection Time: 2.29549
Timestep Consumption Time: 2.56827
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.86376

Cumulative Model Updates: 213,884
Cumulative Timesteps: 1,783,759,302

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1783759302...
Checkpoint 1783759302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.56242
Policy Entropy: 2.11677
Value Function Loss: 0.01667

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 21,274.71670
Overall Steps per Second: 10,119.37278

Timestep Collection Time: 2.35068
Timestep Consumption Time: 2.59133
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.94201

Cumulative Model Updates: 213,890
Cumulative Timesteps: 1,783,809,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.15095
Policy Entropy: 2.09323
Value Function Loss: 0.01764

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.55116
Value Function Update Magnitude: 0.57698

Collected Steps per Second: 21,904.46236
Overall Steps per Second: 10,434.06346

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.79506

Cumulative Model Updates: 213,896
Cumulative Timesteps: 1,783,859,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1783859344...
Checkpoint 1783859344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.05883
Policy Entropy: 2.07740
Value Function Loss: 0.01831

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.60363

Collected Steps per Second: 21,412.69516
Overall Steps per Second: 10,398.39349

Timestep Collection Time: 2.33637
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.81113

Cumulative Model Updates: 213,902
Cumulative Timesteps: 1,783,909,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.54385
Policy Entropy: 2.08176
Value Function Loss: 0.01955

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 21,983.34867
Overall Steps per Second: 10,273.91252

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.59297
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 4.86806

Cumulative Model Updates: 213,908
Cumulative Timesteps: 1,783,959,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1783959386...
Checkpoint 1783959386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.16133
Policy Entropy: 2.12262
Value Function Loss: 0.01825

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.55270
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 21,135.20728
Overall Steps per Second: 10,037.24330

Timestep Collection Time: 2.36695
Timestep Consumption Time: 2.61709
PPO Batch Consumption Time: 0.30604
Total Iteration Time: 4.98404

Cumulative Model Updates: 213,914
Cumulative Timesteps: 1,784,009,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.50352
Policy Entropy: 2.14484
Value Function Loss: 0.01755

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.57725

Collected Steps per Second: 19,347.40083
Overall Steps per Second: 9,623.94570

Timestep Collection Time: 2.58650
Timestep Consumption Time: 2.61324
PPO Batch Consumption Time: 0.30934
Total Iteration Time: 5.19974

Cumulative Model Updates: 213,920
Cumulative Timesteps: 1,784,059,454

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1784059454...
Checkpoint 1784059454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.84246
Policy Entropy: 2.13927
Value Function Loss: 0.01687

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.51843
Value Function Update Magnitude: 0.57577

Collected Steps per Second: 19,779.67428
Overall Steps per Second: 9,822.56555

Timestep Collection Time: 2.52936
Timestep Consumption Time: 2.56401
PPO Batch Consumption Time: 0.30863
Total Iteration Time: 5.09337

Cumulative Model Updates: 213,926
Cumulative Timesteps: 1,784,109,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.55549
Policy Entropy: 2.13350
Value Function Loss: 0.01585

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.50049
Value Function Update Magnitude: 0.59322

Collected Steps per Second: 21,643.78964
Overall Steps per Second: 10,216.70743

Timestep Collection Time: 2.31207
Timestep Consumption Time: 2.58598
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.89806

Cumulative Model Updates: 213,932
Cumulative Timesteps: 1,784,159,526

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1784159526...
Checkpoint 1784159526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.19429
Policy Entropy: 2.10487
Value Function Loss: 0.01750

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16226
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.57950

Collected Steps per Second: 21,810.69596
Overall Steps per Second: 10,234.23657

Timestep Collection Time: 2.29300
Timestep Consumption Time: 2.59373
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 4.88673

Cumulative Model Updates: 213,938
Cumulative Timesteps: 1,784,209,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.14146
Policy Entropy: 2.11365
Value Function Loss: 0.01769

Mean KL Divergence: 0.02811
SB3 Clip Fraction: 0.18676
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.57478

Collected Steps per Second: 21,536.35040
Overall Steps per Second: 10,220.44662

Timestep Collection Time: 2.32175
Timestep Consumption Time: 2.57060
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.89235

Cumulative Model Updates: 213,944
Cumulative Timesteps: 1,784,259,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1784259540...
Checkpoint 1784259540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.80445
Policy Entropy: 2.10676
Value Function Loss: 0.01845

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.16514
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.59026

Collected Steps per Second: 21,979.63581
Overall Steps per Second: 10,460.15917

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.78176

Cumulative Model Updates: 213,950
Cumulative Timesteps: 1,784,309,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.69967
Policy Entropy: 2.11329
Value Function Loss: 0.01740

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 21,432.43919
Overall Steps per Second: 10,191.80455

Timestep Collection Time: 2.33431
Timestep Consumption Time: 2.57453
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.90885

Cumulative Model Updates: 213,956
Cumulative Timesteps: 1,784,359,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1784359588...
Checkpoint 1784359588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.90512
Policy Entropy: 2.13083
Value Function Loss: 0.01738

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.58963

Collected Steps per Second: 22,004.09409
Overall Steps per Second: 10,391.92880

Timestep Collection Time: 2.27240
Timestep Consumption Time: 2.53922
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.81162

Cumulative Model Updates: 213,962
Cumulative Timesteps: 1,784,409,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.92265
Policy Entropy: 2.13039
Value Function Loss: 0.01681

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.58938

Collected Steps per Second: 21,535.47609
Overall Steps per Second: 10,210.95337

Timestep Collection Time: 2.32296
Timestep Consumption Time: 2.57629
PPO Batch Consumption Time: 0.30224
Total Iteration Time: 4.89925

Cumulative Model Updates: 213,968
Cumulative Timesteps: 1,784,459,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1784459616...
Checkpoint 1784459616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.04182
Policy Entropy: 2.13720
Value Function Loss: 0.01699

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.58226

Collected Steps per Second: 21,794.36589
Overall Steps per Second: 10,408.51648

Timestep Collection Time: 2.29445
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.80434

Cumulative Model Updates: 213,974
Cumulative Timesteps: 1,784,509,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.98077
Policy Entropy: 2.10937
Value Function Loss: 0.01820

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.60604

Collected Steps per Second: 22,729.13163
Overall Steps per Second: 10,567.13515

Timestep Collection Time: 2.20193
Timestep Consumption Time: 2.53426
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.73619

Cumulative Model Updates: 213,980
Cumulative Timesteps: 1,784,559,670

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1784559670...
Checkpoint 1784559670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.72767
Policy Entropy: 2.11234
Value Function Loss: 0.01833

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.62737

Collected Steps per Second: 21,548.22539
Overall Steps per Second: 10,189.95898

Timestep Collection Time: 2.32103
Timestep Consumption Time: 2.58714
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.90817

Cumulative Model Updates: 213,986
Cumulative Timesteps: 1,784,609,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.89021
Policy Entropy: 2.13638
Value Function Loss: 0.01771

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.54646
Value Function Update Magnitude: 0.63592

Collected Steps per Second: 22,098.34035
Overall Steps per Second: 10,449.38934

Timestep Collection Time: 2.26352
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.78688

Cumulative Model Updates: 213,992
Cumulative Timesteps: 1,784,659,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1784659704...
Checkpoint 1784659704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.48686
Policy Entropy: 2.13803
Value Function Loss: 0.01735

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.65458

Collected Steps per Second: 21,002.43298
Overall Steps per Second: 10,266.98619

Timestep Collection Time: 2.38115
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.87095

Cumulative Model Updates: 213,998
Cumulative Timesteps: 1,784,709,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.29393
Policy Entropy: 2.13986
Value Function Loss: 0.01757

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 21,777.42746
Overall Steps per Second: 10,435.66436

Timestep Collection Time: 2.29596
Timestep Consumption Time: 2.49531
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.79126

Cumulative Model Updates: 214,004
Cumulative Timesteps: 1,784,759,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1784759714...
Checkpoint 1784759714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.08585
Policy Entropy: 2.11767
Value Function Loss: 0.01751

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.63892

Collected Steps per Second: 21,734.05081
Overall Steps per Second: 10,217.03571

Timestep Collection Time: 2.30118
Timestep Consumption Time: 2.59398
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 4.89516

Cumulative Model Updates: 214,010
Cumulative Timesteps: 1,784,809,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.04949
Policy Entropy: 2.10408
Value Function Loss: 0.01788

Mean KL Divergence: 0.02917
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.50290
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 21,901.71738
Overall Steps per Second: 10,384.02906

Timestep Collection Time: 2.28347
Timestep Consumption Time: 2.53277
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.81624

Cumulative Model Updates: 214,016
Cumulative Timesteps: 1,784,859,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1784859740...
Checkpoint 1784859740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.34371
Policy Entropy: 2.08326
Value Function Loss: 0.01823

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.15525
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.57913

Collected Steps per Second: 21,658.56993
Overall Steps per Second: 10,288.43769

Timestep Collection Time: 2.30920
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.86119

Cumulative Model Updates: 214,022
Cumulative Timesteps: 1,784,909,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.90958
Policy Entropy: 2.08314
Value Function Loss: 0.01975

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.59360

Collected Steps per Second: 22,017.39609
Overall Steps per Second: 10,438.53232

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.79110

Cumulative Model Updates: 214,028
Cumulative Timesteps: 1,784,959,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1784959766...
Checkpoint 1784959766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.99751
Policy Entropy: 2.10006
Value Function Loss: 0.01961

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.59516

Collected Steps per Second: 22,355.60285
Overall Steps per Second: 10,502.31848

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.52478
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.76181

Cumulative Model Updates: 214,034
Cumulative Timesteps: 1,785,009,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.07186
Policy Entropy: 2.16362
Value Function Loss: 0.01766

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 22,185.94650
Overall Steps per Second: 10,470.71688

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.52235
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.77675

Cumulative Model Updates: 214,040
Cumulative Timesteps: 1,785,059,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1785059792...
Checkpoint 1785059792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.69802
Policy Entropy: 2.15624
Value Function Loss: 0.01800

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 21,650.76404
Overall Steps per Second: 10,334.00278

Timestep Collection Time: 2.30985
Timestep Consumption Time: 2.52951
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.83936

Cumulative Model Updates: 214,046
Cumulative Timesteps: 1,785,109,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.73955
Policy Entropy: 2.14687
Value Function Loss: 0.01780

Mean KL Divergence: 0.02717
SB3 Clip Fraction: 0.17274
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.63234

Collected Steps per Second: 21,518.33244
Overall Steps per Second: 10,354.72841

Timestep Collection Time: 2.32481
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.83122

Cumulative Model Updates: 214,052
Cumulative Timesteps: 1,785,159,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1785159828...
Checkpoint 1785159828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.04328
Policy Entropy: 2.08818
Value Function Loss: 0.01809

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.65782

Collected Steps per Second: 21,822.60612
Overall Steps per Second: 10,471.27655

Timestep Collection Time: 2.29148
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.77554

Cumulative Model Updates: 214,058
Cumulative Timesteps: 1,785,209,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.59655
Policy Entropy: 2.07959
Value Function Loss: 0.01751

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.63746

Collected Steps per Second: 21,863.27061
Overall Steps per Second: 10,297.50913

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.85593

Cumulative Model Updates: 214,064
Cumulative Timesteps: 1,785,259,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1785259838...
Checkpoint 1785259838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.66792
Policy Entropy: 2.10258
Value Function Loss: 0.01728

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 21,157.07436
Overall Steps per Second: 10,212.34978

Timestep Collection Time: 2.36384
Timestep Consumption Time: 2.53336
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.89721

Cumulative Model Updates: 214,070
Cumulative Timesteps: 1,785,309,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.75103
Policy Entropy: 2.11331
Value Function Loss: 0.01708

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.61436

Collected Steps per Second: 21,651.59012
Overall Steps per Second: 10,376.72913

Timestep Collection Time: 2.30967
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.81925

Cumulative Model Updates: 214,076
Cumulative Timesteps: 1,785,359,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1785359858...
Checkpoint 1785359858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.87723
Policy Entropy: 2.12863
Value Function Loss: 0.01633

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 21,634.81395
Overall Steps per Second: 10,448.04192

Timestep Collection Time: 2.31109
Timestep Consumption Time: 2.47450
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.78559

Cumulative Model Updates: 214,082
Cumulative Timesteps: 1,785,409,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.45163
Policy Entropy: 2.12643
Value Function Loss: 0.01605

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.52479
Value Function Update Magnitude: 0.58073

Collected Steps per Second: 21,798.55423
Overall Steps per Second: 10,276.77371

Timestep Collection Time: 2.29391
Timestep Consumption Time: 2.57182
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.86573

Cumulative Model Updates: 214,088
Cumulative Timesteps: 1,785,459,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1785459862...
Checkpoint 1785459862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.85591
Policy Entropy: 2.11683
Value Function Loss: 0.01751

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.57611

Collected Steps per Second: 21,419.39805
Overall Steps per Second: 10,188.86931

Timestep Collection Time: 2.33517
Timestep Consumption Time: 2.57391
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.90908

Cumulative Model Updates: 214,094
Cumulative Timesteps: 1,785,509,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.29017
Policy Entropy: 2.13178
Value Function Loss: 0.01707

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.54006
Value Function Update Magnitude: 0.59115

Collected Steps per Second: 21,919.38760
Overall Steps per Second: 10,466.76677

Timestep Collection Time: 2.28145
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.77779

Cumulative Model Updates: 214,100
Cumulative Timesteps: 1,785,559,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1785559888...
Checkpoint 1785559888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.53979
Policy Entropy: 2.11265
Value Function Loss: 0.01823

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.59669

Collected Steps per Second: 21,280.25823
Overall Steps per Second: 10,342.20120

Timestep Collection Time: 2.34988
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.83514

Cumulative Model Updates: 214,106
Cumulative Timesteps: 1,785,609,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.44183
Policy Entropy: 2.13590
Value Function Loss: 0.01719

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.59487

Collected Steps per Second: 21,953.74076
Overall Steps per Second: 10,332.39406

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.56327
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.84225

Cumulative Model Updates: 214,112
Cumulative Timesteps: 1,785,659,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1785659926...
Checkpoint 1785659926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.63577
Policy Entropy: 2.11518
Value Function Loss: 0.01756

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.60253

Collected Steps per Second: 21,178.21593
Overall Steps per Second: 10,224.93194

Timestep Collection Time: 2.36111
Timestep Consumption Time: 2.52929
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.89040

Cumulative Model Updates: 214,118
Cumulative Timesteps: 1,785,709,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.58438
Policy Entropy: 2.13841
Value Function Loss: 0.01739

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 21,857.73150
Overall Steps per Second: 10,369.82130

Timestep Collection Time: 2.28825
Timestep Consumption Time: 2.53497
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.82323

Cumulative Model Updates: 214,124
Cumulative Timesteps: 1,785,759,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1785759946...
Checkpoint 1785759946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.99225
Policy Entropy: 2.12547
Value Function Loss: 0.01771

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 21,462.38242
Overall Steps per Second: 10,262.34225

Timestep Collection Time: 2.33096
Timestep Consumption Time: 2.54395
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.87491

Cumulative Model Updates: 214,130
Cumulative Timesteps: 1,785,809,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.06250
Policy Entropy: 2.13527
Value Function Loss: 0.01755

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.60500

Collected Steps per Second: 21,896.17284
Overall Steps per Second: 10,503.41380

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.76093

Cumulative Model Updates: 214,136
Cumulative Timesteps: 1,785,859,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1785859980...
Checkpoint 1785859980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.27239
Policy Entropy: 2.13242
Value Function Loss: 0.01795

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.58526

Collected Steps per Second: 21,555.84996
Overall Steps per Second: 10,188.56005

Timestep Collection Time: 2.32085
Timestep Consumption Time: 2.58936
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.91021

Cumulative Model Updates: 214,142
Cumulative Timesteps: 1,785,910,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.70068
Policy Entropy: 2.12940
Value Function Loss: 0.01752

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.54126
Value Function Update Magnitude: 0.56784

Collected Steps per Second: 22,108.77048
Overall Steps per Second: 10,446.10341

Timestep Collection Time: 2.26281
Timestep Consumption Time: 2.52634
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.78915

Cumulative Model Updates: 214,148
Cumulative Timesteps: 1,785,960,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1785960036...
Checkpoint 1785960036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.09871
Policy Entropy: 2.13032
Value Function Loss: 0.01792

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.57927

Collected Steps per Second: 21,333.07443
Overall Steps per Second: 10,207.50609

Timestep Collection Time: 2.34425
Timestep Consumption Time: 2.55509
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.89934

Cumulative Model Updates: 214,154
Cumulative Timesteps: 1,786,010,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.76516
Policy Entropy: 2.10931
Value Function Loss: 0.01833

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.59478

Collected Steps per Second: 21,861.94847
Overall Steps per Second: 10,484.96605

Timestep Collection Time: 2.28790
Timestep Consumption Time: 2.48255
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.77045

Cumulative Model Updates: 214,160
Cumulative Timesteps: 1,786,060,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1786060064...
Checkpoint 1786060064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.31764
Policy Entropy: 2.11397
Value Function Loss: 0.01896

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.55553
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 21,570.56982
Overall Steps per Second: 10,195.28192

Timestep Collection Time: 2.31909
Timestep Consumption Time: 2.58750
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.90658

Cumulative Model Updates: 214,166
Cumulative Timesteps: 1,786,110,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.30765
Policy Entropy: 2.09744
Value Function Loss: 0.01860

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.55500
Value Function Update Magnitude: 0.62884

Collected Steps per Second: 21,742.68791
Overall Steps per Second: 10,340.64064

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.83761

Cumulative Model Updates: 214,172
Cumulative Timesteps: 1,786,160,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1786160112...
Checkpoint 1786160112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.40534
Policy Entropy: 2.13133
Value Function Loss: 0.01809

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 21,801.39887
Overall Steps per Second: 10,337.87616

Timestep Collection Time: 2.29462
Timestep Consumption Time: 2.54448
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.83910

Cumulative Model Updates: 214,178
Cumulative Timesteps: 1,786,210,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.60025
Policy Entropy: 2.11438
Value Function Loss: 0.01748

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.60927

Collected Steps per Second: 21,510.81481
Overall Steps per Second: 10,458.37097

Timestep Collection Time: 2.32553
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.78315

Cumulative Model Updates: 214,184
Cumulative Timesteps: 1,786,260,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1786260162...
Checkpoint 1786260162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.79964
Policy Entropy: 2.11389
Value Function Loss: 0.01802

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.59563

Collected Steps per Second: 21,568.42738
Overall Steps per Second: 10,196.21072

Timestep Collection Time: 2.31978
Timestep Consumption Time: 2.58734
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.90712

Cumulative Model Updates: 214,190
Cumulative Timesteps: 1,786,310,196

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.29744
Policy Entropy: 2.10624
Value Function Loss: 0.01711

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.60594

Collected Steps per Second: 21,687.20826
Overall Steps per Second: 10,326.16929

Timestep Collection Time: 2.30634
Timestep Consumption Time: 2.53747
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.84381

Cumulative Model Updates: 214,196
Cumulative Timesteps: 1,786,360,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1786360214...
Checkpoint 1786360214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.57132
Policy Entropy: 2.12342
Value Function Loss: 0.01688

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.61636

Collected Steps per Second: 21,685.91890
Overall Steps per Second: 10,345.32764

Timestep Collection Time: 2.30638
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.83465

Cumulative Model Updates: 214,202
Cumulative Timesteps: 1,786,410,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.88325
Policy Entropy: 2.13813
Value Function Loss: 0.01647

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.60090

Collected Steps per Second: 21,996.33544
Overall Steps per Second: 10,473.90833

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 4.77529

Cumulative Model Updates: 214,208
Cumulative Timesteps: 1,786,460,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1786460246...
Checkpoint 1786460246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.49317
Policy Entropy: 2.10972
Value Function Loss: 0.01723

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.59432

Collected Steps per Second: 21,745.94852
Overall Steps per Second: 10,236.28101

Timestep Collection Time: 2.29983
Timestep Consumption Time: 2.58593
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.88576

Cumulative Model Updates: 214,214
Cumulative Timesteps: 1,786,510,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.16717
Policy Entropy: 2.09786
Value Function Loss: 0.01749

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 21,869.79918
Overall Steps per Second: 10,371.10899

Timestep Collection Time: 2.28690
Timestep Consumption Time: 2.53554
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82244

Cumulative Model Updates: 214,220
Cumulative Timesteps: 1,786,560,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1786560272...
Checkpoint 1786560272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.10675
Policy Entropy: 2.08012
Value Function Loss: 0.01751

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 21,651.75389
Overall Steps per Second: 10,247.94731

Timestep Collection Time: 2.31039
Timestep Consumption Time: 2.57098
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.88137

Cumulative Model Updates: 214,226
Cumulative Timesteps: 1,786,610,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.81026
Policy Entropy: 2.10076
Value Function Loss: 0.01798

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.61395

Collected Steps per Second: 21,726.17703
Overall Steps per Second: 10,389.07421

Timestep Collection Time: 2.30257
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.81525

Cumulative Model Updates: 214,232
Cumulative Timesteps: 1,786,660,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1786660322...
Checkpoint 1786660322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.53146
Policy Entropy: 2.11502
Value Function Loss: 0.01829

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.62289

Collected Steps per Second: 21,641.18571
Overall Steps per Second: 10,457.36905

Timestep Collection Time: 2.31069
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.78189

Cumulative Model Updates: 214,238
Cumulative Timesteps: 1,786,710,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.28610
Policy Entropy: 2.15348
Value Function Loss: 0.01843

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.61906

Collected Steps per Second: 21,888.15717
Overall Steps per Second: 10,264.40927

Timestep Collection Time: 2.28580
Timestep Consumption Time: 2.58852
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.87432

Cumulative Model Updates: 214,244
Cumulative Timesteps: 1,786,760,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1786760360...
Checkpoint 1786760360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.29001
Policy Entropy: 2.16489
Value Function Loss: 0.01807

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.61275

Collected Steps per Second: 21,513.66944
Overall Steps per Second: 10,209.07708

Timestep Collection Time: 2.32503
Timestep Consumption Time: 2.57453
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.89956

Cumulative Model Updates: 214,250
Cumulative Timesteps: 1,786,810,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.60282
Policy Entropy: 2.16084
Value Function Loss: 0.01698

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.59604

Collected Steps per Second: 21,478.07337
Overall Steps per Second: 10,352.90731

Timestep Collection Time: 2.32823
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.83014

Cumulative Model Updates: 214,256
Cumulative Timesteps: 1,786,860,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1786860386...
Checkpoint 1786860386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.54853
Policy Entropy: 2.14036
Value Function Loss: 0.01711

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.57079

Collected Steps per Second: 21,743.06436
Overall Steps per Second: 10,450.39554

Timestep Collection Time: 2.30050
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.78642

Cumulative Model Updates: 214,262
Cumulative Timesteps: 1,786,910,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.91098
Policy Entropy: 2.13030
Value Function Loss: 0.01702

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.54895

Collected Steps per Second: 21,838.06111
Overall Steps per Second: 10,346.55113

Timestep Collection Time: 2.29040
Timestep Consumption Time: 2.54386
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.83427

Cumulative Model Updates: 214,268
Cumulative Timesteps: 1,786,960,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1786960424...
Checkpoint 1786960424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.98296
Policy Entropy: 2.11549
Value Function Loss: 0.01767

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.55854

Collected Steps per Second: 21,609.16477
Overall Steps per Second: 10,153.44531

Timestep Collection Time: 2.31476
Timestep Consumption Time: 2.61165
PPO Batch Consumption Time: 0.30470
Total Iteration Time: 4.92641

Cumulative Model Updates: 214,274
Cumulative Timesteps: 1,787,010,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.37506
Policy Entropy: 2.10704
Value Function Loss: 0.01646

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 21,572.77073
Overall Steps per Second: 10,212.29484

Timestep Collection Time: 2.31885
Timestep Consumption Time: 2.57956
PPO Batch Consumption Time: 0.30102
Total Iteration Time: 4.89841

Cumulative Model Updates: 214,280
Cumulative Timesteps: 1,787,060,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1787060468...
Checkpoint 1787060468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.16200
Policy Entropy: 2.09149
Value Function Loss: 0.01680

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.55723

Collected Steps per Second: 21,127.47304
Overall Steps per Second: 10,161.48046

Timestep Collection Time: 2.36725
Timestep Consumption Time: 2.55467
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.92192

Cumulative Model Updates: 214,286
Cumulative Timesteps: 1,787,110,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.08719
Policy Entropy: 2.06521
Value Function Loss: 0.01806

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.57146

Collected Steps per Second: 21,515.55978
Overall Steps per Second: 10,369.15300

Timestep Collection Time: 2.32446
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.82315

Cumulative Model Updates: 214,292
Cumulative Timesteps: 1,787,160,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1787160494...
Checkpoint 1787160494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.74072
Policy Entropy: 2.05264
Value Function Loss: 0.01907

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.60776

Collected Steps per Second: 21,794.35419
Overall Steps per Second: 10,246.99666

Timestep Collection Time: 2.29509
Timestep Consumption Time: 2.58634
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.88143

Cumulative Model Updates: 214,298
Cumulative Timesteps: 1,787,210,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.59627
Policy Entropy: 2.06687
Value Function Loss: 0.01818

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.63377

Collected Steps per Second: 21,547.49485
Overall Steps per Second: 10,300.99722

Timestep Collection Time: 2.32064
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.85429

Cumulative Model Updates: 214,304
Cumulative Timesteps: 1,787,260,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1787260518...
Checkpoint 1787260518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.24258
Policy Entropy: 2.10313
Value Function Loss: 0.01809

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.60263

Collected Steps per Second: 21,825.13820
Overall Steps per Second: 10,311.18656

Timestep Collection Time: 2.29158
Timestep Consumption Time: 2.55888
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.85046

Cumulative Model Updates: 214,310
Cumulative Timesteps: 1,787,310,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.69672
Policy Entropy: 2.13743
Value Function Loss: 0.01854

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.57828

Collected Steps per Second: 21,603.73773
Overall Steps per Second: 10,483.03568

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.77304

Cumulative Model Updates: 214,316
Cumulative Timesteps: 1,787,360,568

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1787360568...
Checkpoint 1787360568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.40807
Policy Entropy: 2.13508
Value Function Loss: 0.01800

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.56918

Collected Steps per Second: 21,786.86356
Overall Steps per Second: 10,246.51118

Timestep Collection Time: 2.29496
Timestep Consumption Time: 2.58475
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.87971

Cumulative Model Updates: 214,322
Cumulative Timesteps: 1,787,410,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.41055
Policy Entropy: 2.12200
Value Function Loss: 0.01645

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.52318
Value Function Update Magnitude: 0.56543

Collected Steps per Second: 21,603.74980
Overall Steps per Second: 10,275.76043

Timestep Collection Time: 2.31571
Timestep Consumption Time: 2.55284
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.86854

Cumulative Model Updates: 214,328
Cumulative Timesteps: 1,787,460,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1787460596...
Checkpoint 1787460596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.45568
Policy Entropy: 2.11374
Value Function Loss: 0.01567

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.57945

Collected Steps per Second: 21,680.17686
Overall Steps per Second: 10,339.36543

Timestep Collection Time: 2.30672
Timestep Consumption Time: 2.53014
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.83685

Cumulative Model Updates: 214,334
Cumulative Timesteps: 1,787,510,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.60326
Policy Entropy: 2.10581
Value Function Loss: 0.01535

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.52274
Value Function Update Magnitude: 0.57327

Collected Steps per Second: 21,851.30712
Overall Steps per Second: 10,453.19334

Timestep Collection Time: 2.28874
Timestep Consumption Time: 2.49563
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.78438

Cumulative Model Updates: 214,340
Cumulative Timesteps: 1,787,560,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1787560618...
Checkpoint 1787560618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.63759
Policy Entropy: 2.09850
Value Function Loss: 0.01541

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.51843
Value Function Update Magnitude: 0.52430

Collected Steps per Second: 20,623.70422
Overall Steps per Second: 10,050.35120

Timestep Collection Time: 2.42575
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.97774

Cumulative Model Updates: 214,346
Cumulative Timesteps: 1,787,610,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.32205
Policy Entropy: 2.06967
Value Function Loss: 0.01678

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.52960
Value Function Update Magnitude: 0.51668

Collected Steps per Second: 21,602.95069
Overall Steps per Second: 10,172.74565

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.60080
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.91549

Cumulative Model Updates: 214,352
Cumulative Timesteps: 1,787,660,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1787660650...
Checkpoint 1787660650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.68410
Policy Entropy: 2.05832
Value Function Loss: 0.01729

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.54084

Collected Steps per Second: 21,621.61695
Overall Steps per Second: 10,204.57395

Timestep Collection Time: 2.31250
Timestep Consumption Time: 2.58726
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.89976

Cumulative Model Updates: 214,358
Cumulative Timesteps: 1,787,710,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.72669
Policy Entropy: 2.07142
Value Function Loss: 0.01837

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.55006

Collected Steps per Second: 20,807.31916
Overall Steps per Second: 10,173.82039

Timestep Collection Time: 2.40454
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 4.91772

Cumulative Model Updates: 214,364
Cumulative Timesteps: 1,787,760,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1787760682...
Checkpoint 1787760682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.59191
Policy Entropy: 2.09407
Value Function Loss: 0.01739

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.51981
Value Function Update Magnitude: 0.53268

Collected Steps per Second: 21,877.71421
Overall Steps per Second: 10,404.25059

Timestep Collection Time: 2.28589
Timestep Consumption Time: 2.52080
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.80669

Cumulative Model Updates: 214,370
Cumulative Timesteps: 1,787,810,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.86208
Policy Entropy: 2.12239
Value Function Loss: 0.01700

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.51203
Value Function Update Magnitude: 0.53320

Collected Steps per Second: 21,796.84885
Overall Steps per Second: 10,290.00947

Timestep Collection Time: 2.29446
Timestep Consumption Time: 2.56579
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.86025

Cumulative Model Updates: 214,376
Cumulative Timesteps: 1,787,860,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1787860704...
Checkpoint 1787860704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.63105
Policy Entropy: 2.12686
Value Function Loss: 0.01626

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.52420
Value Function Update Magnitude: 0.54532

Collected Steps per Second: 21,577.23820
Overall Steps per Second: 10,380.88109

Timestep Collection Time: 2.31735
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.81674

Cumulative Model Updates: 214,382
Cumulative Timesteps: 1,787,910,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.26646
Policy Entropy: 2.11149
Value Function Loss: 0.01674

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.56735

Collected Steps per Second: 21,942.99075
Overall Steps per Second: 10,567.98607

Timestep Collection Time: 2.28073
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.73562

Cumulative Model Updates: 214,388
Cumulative Timesteps: 1,787,960,752

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1787960752...
Checkpoint 1787960752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.93679
Policy Entropy: 2.10934
Value Function Loss: 0.01649

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 21,799.37633
Overall Steps per Second: 10,236.67961

Timestep Collection Time: 2.29364
Timestep Consumption Time: 2.59075
PPO Batch Consumption Time: 0.30508
Total Iteration Time: 4.88440

Cumulative Model Updates: 214,394
Cumulative Timesteps: 1,788,010,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.14676
Policy Entropy: 2.11226
Value Function Loss: 0.01720

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.59378

Collected Steps per Second: 21,764.15526
Overall Steps per Second: 10,362.99903

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.82544

Cumulative Model Updates: 214,400
Cumulative Timesteps: 1,788,060,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1788060758...
Checkpoint 1788060758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.05298
Policy Entropy: 2.11522
Value Function Loss: 0.01747

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 21,655.94781
Overall Steps per Second: 10,292.49525

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.85927

Cumulative Model Updates: 214,406
Cumulative Timesteps: 1,788,110,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.65223
Policy Entropy: 2.11187
Value Function Loss: 0.01771

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 21,678.05637
Overall Steps per Second: 10,371.27428

Timestep Collection Time: 2.30657
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.82120

Cumulative Model Updates: 214,412
Cumulative Timesteps: 1,788,160,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1788160774...
Checkpoint 1788160774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.37056
Policy Entropy: 2.10366
Value Function Loss: 0.01677

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.58496

Collected Steps per Second: 22,037.89204
Overall Steps per Second: 10,261.56969

Timestep Collection Time: 2.26927
Timestep Consumption Time: 2.60425
PPO Batch Consumption Time: 0.30492
Total Iteration Time: 4.87352

Cumulative Model Updates: 214,418
Cumulative Timesteps: 1,788,210,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.71860
Policy Entropy: 2.10423
Value Function Loss: 0.01738

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.17686
Policy Update Magnitude: 0.50298
Value Function Update Magnitude: 0.58074

Collected Steps per Second: 22,027.14188
Overall Steps per Second: 10,416.56209

Timestep Collection Time: 2.27038
Timestep Consumption Time: 2.53063
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.80101

Cumulative Model Updates: 214,424
Cumulative Timesteps: 1,788,260,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1788260794...
Checkpoint 1788260794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.59444
Policy Entropy: 2.10541
Value Function Loss: 0.01741

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.51087
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 21,469.45909
Overall Steps per Second: 10,264.36129

Timestep Collection Time: 2.32889
Timestep Consumption Time: 2.54233
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.87122

Cumulative Model Updates: 214,430
Cumulative Timesteps: 1,788,310,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.04319
Policy Entropy: 2.09913
Value Function Loss: 0.01664

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.17990
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.59692

Collected Steps per Second: 21,843.27667
Overall Steps per Second: 10,393.06905

Timestep Collection Time: 2.29013
Timestep Consumption Time: 2.52308
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.81321

Cumulative Model Updates: 214,436
Cumulative Timesteps: 1,788,360,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1788360818...
Checkpoint 1788360818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.19214
Policy Entropy: 2.11303
Value Function Loss: 0.01740

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.58658

Collected Steps per Second: 21,191.71046
Overall Steps per Second: 10,268.96771

Timestep Collection Time: 2.36036
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.87099

Cumulative Model Updates: 214,442
Cumulative Timesteps: 1,788,410,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.08174
Policy Entropy: 2.11961
Value Function Loss: 0.01763

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.15374
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.59154

Collected Steps per Second: 22,018.32795
Overall Steps per Second: 10,400.26338

Timestep Collection Time: 2.27229
Timestep Consumption Time: 2.53836
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.81065

Cumulative Model Updates: 214,448
Cumulative Timesteps: 1,788,460,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1788460870...
Checkpoint 1788460870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.34657
Policy Entropy: 2.11148
Value Function Loss: 0.01810

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 21,716.34770
Overall Steps per Second: 10,279.54510

Timestep Collection Time: 2.30352
Timestep Consumption Time: 2.56285
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.86636

Cumulative Model Updates: 214,454
Cumulative Timesteps: 1,788,510,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.89855
Policy Entropy: 2.08717
Value Function Loss: 0.01823

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.60155

Collected Steps per Second: 21,764.41341
Overall Steps per Second: 10,389.56939

Timestep Collection Time: 2.29825
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.81444

Cumulative Model Updates: 214,460
Cumulative Timesteps: 1,788,560,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1788560914...
Checkpoint 1788560914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.05104
Policy Entropy: 2.07614
Value Function Loss: 0.01767

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 21,367.69390
Overall Steps per Second: 10,320.50602

Timestep Collection Time: 2.34073
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 4.84627

Cumulative Model Updates: 214,466
Cumulative Timesteps: 1,788,610,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.43331
Policy Entropy: 2.10513
Value Function Loss: 0.01795

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.60153

Collected Steps per Second: 22,042.20180
Overall Steps per Second: 10,417.32954

Timestep Collection Time: 2.27037
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.80392

Cumulative Model Updates: 214,472
Cumulative Timesteps: 1,788,660,974

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1788660974...
Checkpoint 1788660974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.08528
Policy Entropy: 2.12682
Value Function Loss: 0.01812

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.59793

Collected Steps per Second: 21,492.67195
Overall Steps per Second: 10,208.16271

Timestep Collection Time: 2.32703
Timestep Consumption Time: 2.57239
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.89941

Cumulative Model Updates: 214,478
Cumulative Timesteps: 1,788,710,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.72999
Policy Entropy: 2.14145
Value Function Loss: 0.01774

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.59707

Collected Steps per Second: 22,057.06928
Overall Steps per Second: 10,382.42097

Timestep Collection Time: 2.26803
Timestep Consumption Time: 2.55031
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.81834

Cumulative Model Updates: 214,484
Cumulative Timesteps: 1,788,761,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1788761014...
Checkpoint 1788761014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.30037
Policy Entropy: 2.14219
Value Function Loss: 0.01766

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 21,677.85168
Overall Steps per Second: 10,384.42965

Timestep Collection Time: 2.30724
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.30450
Total Iteration Time: 4.81644

Cumulative Model Updates: 214,490
Cumulative Timesteps: 1,788,811,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.79218
Policy Entropy: 2.13447
Value Function Loss: 0.01658

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 22,127.79053
Overall Steps per Second: 10,361.51074

Timestep Collection Time: 2.26023
Timestep Consumption Time: 2.56667
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.82690

Cumulative Model Updates: 214,496
Cumulative Timesteps: 1,788,861,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1788861044...
Checkpoint 1788861044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.34987
Policy Entropy: 2.15034
Value Function Loss: 0.01702

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 21,418.23662
Overall Steps per Second: 10,209.95692

Timestep Collection Time: 2.33455
Timestep Consumption Time: 2.56282
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.89738

Cumulative Model Updates: 214,502
Cumulative Timesteps: 1,788,911,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.00377
Policy Entropy: 2.14014
Value Function Loss: 0.01694

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.58069

Collected Steps per Second: 22,035.42105
Overall Steps per Second: 10,437.19431

Timestep Collection Time: 2.27044
Timestep Consumption Time: 2.52300
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.79343

Cumulative Model Updates: 214,508
Cumulative Timesteps: 1,788,961,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1788961076...
Checkpoint 1788961076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.72846
Policy Entropy: 2.14143
Value Function Loss: 0.01758

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.56384

Collected Steps per Second: 21,476.40749
Overall Steps per Second: 10,197.82251

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.57600
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.90516

Cumulative Model Updates: 214,514
Cumulative Timesteps: 1,789,011,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.29179
Policy Entropy: 2.14053
Value Function Loss: 0.01784

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.55592

Collected Steps per Second: 21,867.61713
Overall Steps per Second: 10,485.19108

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.76901

Cumulative Model Updates: 214,520
Cumulative Timesteps: 1,789,061,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1789061102...
Checkpoint 1789061102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.89440
Policy Entropy: 2.13568
Value Function Loss: 0.01902

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.55912

Collected Steps per Second: 21,600.99660
Overall Steps per Second: 10,200.99342

Timestep Collection Time: 2.31563
Timestep Consumption Time: 2.58781
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.90344

Cumulative Model Updates: 214,526
Cumulative Timesteps: 1,789,111,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.46932
Policy Entropy: 2.11419
Value Function Loss: 0.01899

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.58412

Collected Steps per Second: 21,748.65198
Overall Steps per Second: 10,327.46583

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.54287
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.84223

Cumulative Model Updates: 214,532
Cumulative Timesteps: 1,789,161,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1789161130...
Checkpoint 1789161130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.71019
Policy Entropy: 2.10304
Value Function Loss: 0.01872

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16136
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.58548

Collected Steps per Second: 21,568.22986
Overall Steps per Second: 10,272.54358

Timestep Collection Time: 2.31934
Timestep Consumption Time: 2.55034
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.86968

Cumulative Model Updates: 214,538
Cumulative Timesteps: 1,789,211,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.65290
Policy Entropy: 2.10353
Value Function Loss: 0.01755

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 22,113.01255
Overall Steps per Second: 10,538.53996

Timestep Collection Time: 2.26175
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.74582

Cumulative Model Updates: 214,544
Cumulative Timesteps: 1,789,261,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1789261168...
Checkpoint 1789261168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.02347
Policy Entropy: 2.10706
Value Function Loss: 0.01751

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.52933

Collected Steps per Second: 21,669.20465
Overall Steps per Second: 10,197.19879

Timestep Collection Time: 2.30807
Timestep Consumption Time: 2.59661
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 4.90468

Cumulative Model Updates: 214,550
Cumulative Timesteps: 1,789,311,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.04252
Policy Entropy: 2.10441
Value Function Loss: 0.01714

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.53742

Collected Steps per Second: 21,791.45083
Overall Steps per Second: 10,365.28900

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82649

Cumulative Model Updates: 214,556
Cumulative Timesteps: 1,789,361,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1789361210...
Checkpoint 1789361210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.93273
Policy Entropy: 2.10632
Value Function Loss: 0.01732

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.56090

Collected Steps per Second: 21,513.55508
Overall Steps per Second: 10,308.51804

Timestep Collection Time: 2.32467
Timestep Consumption Time: 2.52685
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.85152

Cumulative Model Updates: 214,562
Cumulative Timesteps: 1,789,411,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.88087
Policy Entropy: 2.10360
Value Function Loss: 0.01829

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.57908

Collected Steps per Second: 22,001.55756
Overall Steps per Second: 10,468.53036

Timestep Collection Time: 2.27329
Timestep Consumption Time: 2.50445
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.77775

Cumulative Model Updates: 214,568
Cumulative Timesteps: 1,789,461,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1789461238...
Checkpoint 1789461238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.41522
Policy Entropy: 2.10566
Value Function Loss: 0.01781

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.58421

Collected Steps per Second: 21,589.85347
Overall Steps per Second: 10,210.94766

Timestep Collection Time: 2.31692
Timestep Consumption Time: 2.58194
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.89886

Cumulative Model Updates: 214,574
Cumulative Timesteps: 1,789,511,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.96017
Policy Entropy: 2.09709
Value Function Loss: 0.01793

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.58948

Collected Steps per Second: 21,832.49065
Overall Steps per Second: 10,363.00924

Timestep Collection Time: 2.29117
Timestep Consumption Time: 2.53580
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.82698

Cumulative Model Updates: 214,580
Cumulative Timesteps: 1,789,561,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1789561282...
Checkpoint 1789561282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.89389
Policy Entropy: 2.10860
Value Function Loss: 0.01607

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.58983

Collected Steps per Second: 21,652.09259
Overall Steps per Second: 10,300.49545

Timestep Collection Time: 2.30962
Timestep Consumption Time: 2.54530
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.85491

Cumulative Model Updates: 214,586
Cumulative Timesteps: 1,789,611,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.27444
Policy Entropy: 2.09404
Value Function Loss: 0.01745

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.60480

Collected Steps per Second: 21,800.12936
Overall Steps per Second: 10,426.27289

Timestep Collection Time: 2.29384
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79615

Cumulative Model Updates: 214,592
Cumulative Timesteps: 1,789,661,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1789661296...
Checkpoint 1789661296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.16101
Policy Entropy: 2.09209
Value Function Loss: 0.01687

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.63464

Collected Steps per Second: 21,619.04167
Overall Steps per Second: 10,448.00256

Timestep Collection Time: 2.31305
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.78618

Cumulative Model Updates: 214,598
Cumulative Timesteps: 1,789,711,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.79709
Policy Entropy: 2.09395
Value Function Loss: 0.01651

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.63986

Collected Steps per Second: 21,956.11867
Overall Steps per Second: 10,255.24792

Timestep Collection Time: 2.27754
Timestep Consumption Time: 2.59859
PPO Batch Consumption Time: 0.30454
Total Iteration Time: 4.87614

Cumulative Model Updates: 214,604
Cumulative Timesteps: 1,789,761,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1789761308...
Checkpoint 1789761308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.12384
Policy Entropy: 2.11120
Value Function Loss: 0.01684

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 21,501.45769
Overall Steps per Second: 10,179.56651

Timestep Collection Time: 2.32580
Timestep Consumption Time: 2.58679
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.91259

Cumulative Model Updates: 214,610
Cumulative Timesteps: 1,789,811,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.15796
Policy Entropy: 2.13568
Value Function Loss: 0.01750

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.60272

Collected Steps per Second: 21,935.97451
Overall Steps per Second: 10,493.25383

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.76706

Cumulative Model Updates: 214,616
Cumulative Timesteps: 1,789,861,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1789861338...
Checkpoint 1789861338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.09763
Policy Entropy: 2.11950
Value Function Loss: 0.01867

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.61660

Collected Steps per Second: 21,672.31768
Overall Steps per Second: 10,199.67209

Timestep Collection Time: 2.30755
Timestep Consumption Time: 2.59555
PPO Batch Consumption Time: 0.30574
Total Iteration Time: 4.90310

Cumulative Model Updates: 214,622
Cumulative Timesteps: 1,789,911,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.48725
Policy Entropy: 2.12043
Value Function Loss: 0.01815

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 21,486.33095
Overall Steps per Second: 10,211.55154

Timestep Collection Time: 2.32743
Timestep Consumption Time: 2.56977
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.89720

Cumulative Model Updates: 214,628
Cumulative Timesteps: 1,789,961,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1789961356...
Checkpoint 1789961356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.96605
Policy Entropy: 2.11651
Value Function Loss: 0.01768

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.62760

Collected Steps per Second: 21,786.99437
Overall Steps per Second: 10,355.15211

Timestep Collection Time: 2.29587
Timestep Consumption Time: 2.53458
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.83045

Cumulative Model Updates: 214,634
Cumulative Timesteps: 1,790,011,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.24862
Policy Entropy: 2.11987
Value Function Loss: 0.01709

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.61212

Collected Steps per Second: 21,629.68704
Overall Steps per Second: 10,295.14683

Timestep Collection Time: 2.31164
Timestep Consumption Time: 2.54502
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.85666

Cumulative Model Updates: 214,640
Cumulative Timesteps: 1,790,061,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1790061376...
Checkpoint 1790061376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.48088
Policy Entropy: 2.11973
Value Function Loss: 0.01779

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.54930
Value Function Update Magnitude: 0.62187

Collected Steps per Second: 21,885.32231
Overall Steps per Second: 10,454.71599

Timestep Collection Time: 2.28601
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.78540

Cumulative Model Updates: 214,646
Cumulative Timesteps: 1,790,111,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.85105
Policy Entropy: 2.12499
Value Function Loss: 0.01823

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 21,813.86716
Overall Steps per Second: 10,356.45285

Timestep Collection Time: 2.29240
Timestep Consumption Time: 2.53609
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.82849

Cumulative Model Updates: 214,652
Cumulative Timesteps: 1,790,161,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1790161412...
Checkpoint 1790161412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.37829
Policy Entropy: 2.11149
Value Function Loss: 0.01864

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 20,598.27565
Overall Steps per Second: 9,872.26972

Timestep Collection Time: 2.42855
Timestep Consumption Time: 2.63857
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 5.06712

Cumulative Model Updates: 214,658
Cumulative Timesteps: 1,790,211,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.62598
Policy Entropy: 2.09690
Value Function Loss: 0.01891

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 21,552.53114
Overall Steps per Second: 10,386.00243

Timestep Collection Time: 2.32075
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.81590

Cumulative Model Updates: 214,664
Cumulative Timesteps: 1,790,261,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1790261454...
Checkpoint 1790261454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.40305
Policy Entropy: 2.08278
Value Function Loss: 0.01818

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.65947

Collected Steps per Second: 21,477.86950
Overall Steps per Second: 10,322.78297

Timestep Collection Time: 2.32826
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.84424

Cumulative Model Updates: 214,670
Cumulative Timesteps: 1,790,311,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.03430
Policy Entropy: 2.06604
Value Function Loss: 0.01817

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.56030
Value Function Update Magnitude: 0.66362

Collected Steps per Second: 21,717.72052
Overall Steps per Second: 10,341.79485

Timestep Collection Time: 2.30328
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.83688

Cumulative Model Updates: 214,676
Cumulative Timesteps: 1,790,361,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1790361482...
Checkpoint 1790361482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.32157
Policy Entropy: 2.08148
Value Function Loss: 0.01720

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.65061

Collected Steps per Second: 21,682.94716
Overall Steps per Second: 10,322.55828

Timestep Collection Time: 2.30670
Timestep Consumption Time: 2.53861
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.84531

Cumulative Model Updates: 214,682
Cumulative Timesteps: 1,790,411,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.25798
Policy Entropy: 2.07667
Value Function Loss: 0.01700

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 21,634.29296
Overall Steps per Second: 10,358.81693

Timestep Collection Time: 2.31124
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.82700

Cumulative Model Updates: 214,688
Cumulative Timesteps: 1,790,461,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1790461500...
Checkpoint 1790461500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.39446
Policy Entropy: 2.11211
Value Function Loss: 0.01668

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.62860

Collected Steps per Second: 21,710.29120
Overall Steps per Second: 10,442.68865

Timestep Collection Time: 2.30370
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.30102
Total Iteration Time: 4.78938

Cumulative Model Updates: 214,694
Cumulative Timesteps: 1,790,511,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.29300
Policy Entropy: 2.10173
Value Function Loss: 0.01762

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 21,809.98261
Overall Steps per Second: 10,298.12128

Timestep Collection Time: 2.29317
Timestep Consumption Time: 2.56344
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.85661

Cumulative Model Updates: 214,700
Cumulative Timesteps: 1,790,561,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1790561528...
Checkpoint 1790561528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.84107
Policy Entropy: 2.10791
Value Function Loss: 0.01842

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.64578

Collected Steps per Second: 21,772.36963
Overall Steps per Second: 10,230.31862

Timestep Collection Time: 2.29686
Timestep Consumption Time: 2.59136
PPO Batch Consumption Time: 0.30530
Total Iteration Time: 4.88822

Cumulative Model Updates: 214,706
Cumulative Timesteps: 1,790,611,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.52618
Policy Entropy: 2.10982
Value Function Loss: 0.01779

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.65209

Collected Steps per Second: 21,779.26048
Overall Steps per Second: 10,407.12796

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.80651

Cumulative Model Updates: 214,712
Cumulative Timesteps: 1,790,661,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1790661558...
Checkpoint 1790661558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.98894
Policy Entropy: 2.09686
Value Function Loss: 0.01822

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.65464

Collected Steps per Second: 21,316.43431
Overall Steps per Second: 10,233.58361

Timestep Collection Time: 2.34617
Timestep Consumption Time: 2.54088
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.88705

Cumulative Model Updates: 214,718
Cumulative Timesteps: 1,790,711,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.80496
Policy Entropy: 2.10163
Value Function Loss: 0.01825

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.68705

Collected Steps per Second: 22,693.20801
Overall Steps per Second: 10,490.97045

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.56393
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.76829

Cumulative Model Updates: 214,724
Cumulative Timesteps: 1,790,761,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1790761594...
Checkpoint 1790761594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.64174
Policy Entropy: 2.09910
Value Function Loss: 0.01881

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.53334
Value Function Update Magnitude: 0.69216

Collected Steps per Second: 21,616.19639
Overall Steps per Second: 10,183.05579

Timestep Collection Time: 2.31391
Timestep Consumption Time: 2.59797
PPO Batch Consumption Time: 0.30332
Total Iteration Time: 4.91189

Cumulative Model Updates: 214,730
Cumulative Timesteps: 1,790,811,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.28132
Policy Entropy: 2.10559
Value Function Loss: 0.01919

Mean KL Divergence: 0.02908
SB3 Clip Fraction: 0.18096
Policy Update Magnitude: 0.53612
Value Function Update Magnitude: 0.68412

Collected Steps per Second: 21,801.22343
Overall Steps per Second: 10,450.66519

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.78553

Cumulative Model Updates: 214,736
Cumulative Timesteps: 1,790,861,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1790861624...
Checkpoint 1790861624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.39138
Policy Entropy: 2.09061
Value Function Loss: 0.01904

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.18194
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.66364

Collected Steps per Second: 21,601.83115
Overall Steps per Second: 10,267.78950

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.30390
Total Iteration Time: 4.87077

Cumulative Model Updates: 214,742
Cumulative Timesteps: 1,790,911,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.56069
Policy Entropy: 2.09160
Value Function Loss: 0.01848

Mean KL Divergence: 0.03304
SB3 Clip Fraction: 0.19620
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.65608

Collected Steps per Second: 21,698.01287
Overall Steps per Second: 10,409.13312

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.80559

Cumulative Model Updates: 214,748
Cumulative Timesteps: 1,790,961,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1790961658...
Checkpoint 1790961658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.31548
Policy Entropy: 2.10075
Value Function Loss: 0.01788

Mean KL Divergence: 0.03366
SB3 Clip Fraction: 0.19735
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 20,415.87081
Overall Steps per Second: 9,957.45157

Timestep Collection Time: 2.44976
Timestep Consumption Time: 2.57301
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 5.02277

Cumulative Model Updates: 214,754
Cumulative Timesteps: 1,791,011,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.01161
Policy Entropy: 2.08672
Value Function Loss: 0.01754

Mean KL Divergence: 0.03628
SB3 Clip Fraction: 0.20513
Policy Update Magnitude: 0.52479
Value Function Update Magnitude: 0.62784

Collected Steps per Second: 22,430.91223
Overall Steps per Second: 10,426.96100

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.56763
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.79795

Cumulative Model Updates: 214,760
Cumulative Timesteps: 1,791,061,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1791061700...
Checkpoint 1791061700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.65813
Policy Entropy: 2.07619
Value Function Loss: 0.01745

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.17369
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 21,765.71810
Overall Steps per Second: 10,471.05120

Timestep Collection Time: 2.29839
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.77755

Cumulative Model Updates: 214,766
Cumulative Timesteps: 1,791,111,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.22992
Policy Entropy: 2.08288
Value Function Loss: 0.01776

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 21,916.85488
Overall Steps per Second: 10,514.53213

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.75627

Cumulative Model Updates: 214,772
Cumulative Timesteps: 1,791,161,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1791161736...
Checkpoint 1791161736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.07435
Policy Entropy: 2.10470
Value Function Loss: 0.01719

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.61787

Collected Steps per Second: 21,789.60459
Overall Steps per Second: 10,248.54273

Timestep Collection Time: 2.29541
Timestep Consumption Time: 2.58490
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.88030

Cumulative Model Updates: 214,778
Cumulative Timesteps: 1,791,211,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.26660
Policy Entropy: 2.11491
Value Function Loss: 0.01647

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.60725

Collected Steps per Second: 21,857.28545
Overall Steps per Second: 10,425.98219

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.79744

Cumulative Model Updates: 214,784
Cumulative Timesteps: 1,791,261,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1791261770...
Checkpoint 1791261770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.65961
Policy Entropy: 2.12038
Value Function Loss: 0.01583

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 21,499.77827
Overall Steps per Second: 10,270.97865

Timestep Collection Time: 2.32607
Timestep Consumption Time: 2.54299
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 4.86906

Cumulative Model Updates: 214,790
Cumulative Timesteps: 1,791,311,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.69148
Policy Entropy: 2.13731
Value Function Loss: 0.01665

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.52590
Value Function Update Magnitude: 0.60669

Collected Steps per Second: 21,961.70564
Overall Steps per Second: 10,370.09393

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.54487
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.82156

Cumulative Model Updates: 214,796
Cumulative Timesteps: 1,791,361,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1791361780...
Checkpoint 1791361780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.16152
Policy Entropy: 2.12195
Value Function Loss: 0.01767

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.63945

Collected Steps per Second: 22,502.72522
Overall Steps per Second: 10,564.71862

Timestep Collection Time: 2.22275
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73444

Cumulative Model Updates: 214,802
Cumulative Timesteps: 1,791,411,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.84174
Policy Entropy: 2.12396
Value Function Loss: 0.01736

Mean KL Divergence: 0.02620
SB3 Clip Fraction: 0.17086
Policy Update Magnitude: 0.50757
Value Function Update Magnitude: 0.64415

Collected Steps per Second: 22,303.03298
Overall Steps per Second: 10,500.04832

Timestep Collection Time: 2.24239
Timestep Consumption Time: 2.52064
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.76303

Cumulative Model Updates: 214,808
Cumulative Timesteps: 1,791,461,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1791461810...
Checkpoint 1791461810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.52801
Policy Entropy: 2.09674
Value Function Loss: 0.01740

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.16763
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 21,421.88007
Overall Steps per Second: 10,262.72662

Timestep Collection Time: 2.33500
Timestep Consumption Time: 2.53895
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.87395

Cumulative Model Updates: 214,814
Cumulative Timesteps: 1,791,511,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.05440
Policy Entropy: 2.10362
Value Function Loss: 0.01682

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.60857

Collected Steps per Second: 21,991.81530
Overall Steps per Second: 10,443.74470

Timestep Collection Time: 2.27376
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78794

Cumulative Model Updates: 214,820
Cumulative Timesteps: 1,791,561,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1791561834...
Checkpoint 1791561834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.78906
Policy Entropy: 2.08358
Value Function Loss: 0.01747

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.59102

Collected Steps per Second: 22,410.65847
Overall Steps per Second: 10,504.95135

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.76118

Cumulative Model Updates: 214,826
Cumulative Timesteps: 1,791,611,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.97463
Policy Entropy: 2.11160
Value Function Loss: 0.01766

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.61212

Collected Steps per Second: 22,359.07363
Overall Steps per Second: 10,493.08982

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.52922
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.76580

Cumulative Model Updates: 214,832
Cumulative Timesteps: 1,791,661,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1791661858...
Checkpoint 1791661858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.94204
Policy Entropy: 2.10656
Value Function Loss: 0.01816

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 21,806.57197
Overall Steps per Second: 10,292.13562

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.56550
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.85866

Cumulative Model Updates: 214,838
Cumulative Timesteps: 1,791,711,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.00677
Policy Entropy: 2.14367
Value Function Loss: 0.01703

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.61732

Collected Steps per Second: 22,080.67333
Overall Steps per Second: 10,506.34443

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.76150

Cumulative Model Updates: 214,844
Cumulative Timesteps: 1,791,761,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1791761890...
Checkpoint 1791761890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.61847
Policy Entropy: 2.13690
Value Function Loss: 0.01771

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.62749

Collected Steps per Second: 21,888.70806
Overall Steps per Second: 10,290.91404

Timestep Collection Time: 2.28565
Timestep Consumption Time: 2.57592
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.86157

Cumulative Model Updates: 214,850
Cumulative Timesteps: 1,791,811,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.45486
Policy Entropy: 2.13883
Value Function Loss: 0.01760

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.66598

Collected Steps per Second: 22,110.26872
Overall Steps per Second: 10,324.75143

Timestep Collection Time: 2.26239
Timestep Consumption Time: 2.58247
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.84486

Cumulative Model Updates: 214,856
Cumulative Timesteps: 1,791,861,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1791861942...
Checkpoint 1791861942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.54029
Policy Entropy: 2.10927
Value Function Loss: 0.01782

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.67872

Collected Steps per Second: 21,508.28713
Overall Steps per Second: 10,284.24351

Timestep Collection Time: 2.32506
Timestep Consumption Time: 2.53753
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.86258

Cumulative Model Updates: 214,862
Cumulative Timesteps: 1,791,911,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.27402
Policy Entropy: 2.10079
Value Function Loss: 0.01664

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 21,953.88526
Overall Steps per Second: 10,514.66012

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.75793

Cumulative Model Updates: 214,868
Cumulative Timesteps: 1,791,961,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1791961978...
Checkpoint 1791961978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.06604
Policy Entropy: 2.10277
Value Function Loss: 0.01643

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.54337
Value Function Update Magnitude: 0.62584

Collected Steps per Second: 21,886.84451
Overall Steps per Second: 10,414.15919

Timestep Collection Time: 2.28503
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.80231

Cumulative Model Updates: 214,874
Cumulative Timesteps: 1,792,011,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.56484
Policy Entropy: 2.08996
Value Function Loss: 0.01769

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.61021

Collected Steps per Second: 22,136.90998
Overall Steps per Second: 10,474.80058

Timestep Collection Time: 2.25876
Timestep Consumption Time: 2.51479
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77355

Cumulative Model Updates: 214,880
Cumulative Timesteps: 1,792,061,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1792061992...
Checkpoint 1792061992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.15661
Policy Entropy: 2.08143
Value Function Loss: 0.01954

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 21,182.84347
Overall Steps per Second: 10,218.44177

Timestep Collection Time: 2.36059
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.89351

Cumulative Model Updates: 214,886
Cumulative Timesteps: 1,792,111,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.38370
Policy Entropy: 2.06618
Value Function Loss: 0.01984

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.63196

Collected Steps per Second: 22,087.03346
Overall Steps per Second: 10,526.62261

Timestep Collection Time: 2.26459
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.75157

Cumulative Model Updates: 214,892
Cumulative Timesteps: 1,792,162,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1792162014...
Checkpoint 1792162014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.98418
Policy Entropy: 2.07790
Value Function Loss: 0.01766

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.63645

Collected Steps per Second: 22,695.04190
Overall Steps per Second: 10,628.66954

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.70520

Cumulative Model Updates: 214,898
Cumulative Timesteps: 1,792,212,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.16974
Policy Entropy: 2.06003
Value Function Loss: 0.01659

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.59326

Collected Steps per Second: 22,079.45489
Overall Steps per Second: 10,486.10977

Timestep Collection Time: 2.26636
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.77203

Cumulative Model Updates: 214,904
Cumulative Timesteps: 1,792,262,064

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1792262064...
Checkpoint 1792262064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.21748
Policy Entropy: 2.07369
Value Function Loss: 0.01740

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.57006

Collected Steps per Second: 21,817.20587
Overall Steps per Second: 10,321.23711

Timestep Collection Time: 2.29296
Timestep Consumption Time: 2.55394
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.84690

Cumulative Model Updates: 214,910
Cumulative Timesteps: 1,792,312,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.69996
Policy Entropy: 2.07881
Value Function Loss: 0.01807

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.59484

Collected Steps per Second: 21,826.61155
Overall Steps per Second: 10,316.41168

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.55719
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.84917

Cumulative Model Updates: 214,916
Cumulative Timesteps: 1,792,362,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1792362116...
Checkpoint 1792362116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.16229
Policy Entropy: 2.11785
Value Function Loss: 0.01828

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,624.59605
Overall Steps per Second: 10,592.39428

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.72301

Cumulative Model Updates: 214,922
Cumulative Timesteps: 1,792,412,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.61868
Policy Entropy: 2.11840
Value Function Loss: 0.01759

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.61975

Collected Steps per Second: 21,516.38732
Overall Steps per Second: 10,235.77066

Timestep Collection Time: 2.32437
Timestep Consumption Time: 2.56163
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.88600

Cumulative Model Updates: 214,928
Cumulative Timesteps: 1,792,462,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1792462156...
Checkpoint 1792462156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.68691
Policy Entropy: 2.09689
Value Function Loss: 0.01855

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.63057

Collected Steps per Second: 21,872.82404
Overall Steps per Second: 10,422.33375

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.79854

Cumulative Model Updates: 214,934
Cumulative Timesteps: 1,792,512,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.63376
Policy Entropy: 2.08096
Value Function Loss: 0.01731

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.61731

Collected Steps per Second: 22,163.86801
Overall Steps per Second: 10,518.99616

Timestep Collection Time: 2.25710
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.75578

Cumulative Model Updates: 214,940
Cumulative Timesteps: 1,792,562,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1792562194...
Checkpoint 1792562194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.54419
Policy Entropy: 2.06822
Value Function Loss: 0.01772

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 21,969.26358
Overall Steps per Second: 10,341.90131

Timestep Collection Time: 2.27700
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.83702

Cumulative Model Updates: 214,946
Cumulative Timesteps: 1,792,612,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.67364
Policy Entropy: 2.08398
Value Function Loss: 0.01816

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.59221

Collected Steps per Second: 21,955.93550
Overall Steps per Second: 10,351.73983

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.55435
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.83300

Cumulative Model Updates: 214,952
Cumulative Timesteps: 1,792,662,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1792662248...
Checkpoint 1792662248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.18609
Policy Entropy: 2.08168
Value Function Loss: 0.01776

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 21,887.33914
Overall Steps per Second: 10,323.07110

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.56042
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.84604

Cumulative Model Updates: 214,958
Cumulative Timesteps: 1,792,712,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.65202
Policy Entropy: 2.07250
Value Function Loss: 0.01712

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.59505

Collected Steps per Second: 21,908.08710
Overall Steps per Second: 10,322.68895

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.56297
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.84661

Cumulative Model Updates: 214,964
Cumulative Timesteps: 1,792,762,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1792762304...
Checkpoint 1792762304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.64851
Policy Entropy: 2.07476
Value Function Loss: 0.01682

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.57012

Collected Steps per Second: 21,863.87358
Overall Steps per Second: 10,619.22036

Timestep Collection Time: 2.28715
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.70901

Cumulative Model Updates: 214,970
Cumulative Timesteps: 1,792,812,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.32668
Policy Entropy: 2.08063
Value Function Loss: 0.01714

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.56225

Collected Steps per Second: 21,994.11200
Overall Steps per Second: 10,443.97156

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.78745

Cumulative Model Updates: 214,976
Cumulative Timesteps: 1,792,862,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1792862310...
Checkpoint 1792862310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.62882
Policy Entropy: 2.10995
Value Function Loss: 0.01709

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 21,578.34468
Overall Steps per Second: 10,255.64111

Timestep Collection Time: 2.31769
Timestep Consumption Time: 2.55884
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.87654

Cumulative Model Updates: 214,982
Cumulative Timesteps: 1,792,912,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.87483
Policy Entropy: 2.07170
Value Function Loss: 0.01853

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.57557

Collected Steps per Second: 22,008.49625
Overall Steps per Second: 10,463.66531

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.77844

Cumulative Model Updates: 214,988
Cumulative Timesteps: 1,792,962,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1792962322...
Checkpoint 1792962322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.77950
Policy Entropy: 2.08458
Value Function Loss: 0.01792

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 22,515.77934
Overall Steps per Second: 10,557.13486

Timestep Collection Time: 2.22146
Timestep Consumption Time: 2.51637
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73784

Cumulative Model Updates: 214,994
Cumulative Timesteps: 1,793,012,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.48352
Policy Entropy: 2.09450
Value Function Loss: 0.01705

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 21,778.43708
Overall Steps per Second: 10,324.60045

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.54767
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.84416

Cumulative Model Updates: 215,000
Cumulative Timesteps: 1,793,062,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1793062354...
Checkpoint 1793062354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.28258
Policy Entropy: 2.13993
Value Function Loss: 0.01628

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.57031

Collected Steps per Second: 21,942.04945
Overall Steps per Second: 10,426.71087

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.79806

Cumulative Model Updates: 215,006
Cumulative Timesteps: 1,793,112,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.92431
Policy Entropy: 2.14410
Value Function Loss: 0.01706

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 21,964.40299
Overall Steps per Second: 10,452.94486

Timestep Collection Time: 2.27769
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.78602

Cumulative Model Updates: 215,012
Cumulative Timesteps: 1,793,162,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1793162410...
Checkpoint 1793162410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.75139
Policy Entropy: 2.11175
Value Function Loss: 0.01803

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.60234

Collected Steps per Second: 22,001.31339
Overall Steps per Second: 10,645.26350

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.42433
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.69692

Cumulative Model Updates: 215,018
Cumulative Timesteps: 1,793,212,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.92343
Policy Entropy: 2.10556
Value Function Loss: 0.01751

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.63335

Collected Steps per Second: 21,293.48696
Overall Steps per Second: 10,081.58648

Timestep Collection Time: 2.34908
Timestep Consumption Time: 2.61245
PPO Batch Consumption Time: 0.30341
Total Iteration Time: 4.96152

Cumulative Model Updates: 215,024
Cumulative Timesteps: 1,793,262,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1793262430...
Checkpoint 1793262430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.18293
Policy Entropy: 2.12608
Value Function Loss: 0.01706

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.61177

Collected Steps per Second: 21,874.88900
Overall Steps per Second: 10,355.42177

Timestep Collection Time: 2.28609
Timestep Consumption Time: 2.54307
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.82916

Cumulative Model Updates: 215,030
Cumulative Timesteps: 1,793,312,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.26949
Policy Entropy: 2.14702
Value Function Loss: 0.01840

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.55367
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 21,983.56578
Overall Steps per Second: 10,376.27268

Timestep Collection Time: 2.27479
Timestep Consumption Time: 2.54467
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.81946

Cumulative Model Updates: 215,036
Cumulative Timesteps: 1,793,362,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1793362446...
Checkpoint 1793362446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.84385
Policy Entropy: 2.14641
Value Function Loss: 0.01769

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 21,656.91091
Overall Steps per Second: 10,405.46650

Timestep Collection Time: 2.30882
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.80536

Cumulative Model Updates: 215,042
Cumulative Timesteps: 1,793,412,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.62250
Policy Entropy: 2.13324
Value Function Loss: 0.01808

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 23,060.62585
Overall Steps per Second: 10,565.54143

Timestep Collection Time: 2.16889
Timestep Consumption Time: 2.56499
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.73388

Cumulative Model Updates: 215,048
Cumulative Timesteps: 1,793,462,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1793462464...
Checkpoint 1793462464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.63276
Policy Entropy: 2.14185
Value Function Loss: 0.01712

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.64329

Collected Steps per Second: 21,759.88637
Overall Steps per Second: 10,258.03310

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.57797
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 4.87715

Cumulative Model Updates: 215,054
Cumulative Timesteps: 1,793,512,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.99654
Policy Entropy: 2.14425
Value Function Loss: 0.01725

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.63672

Collected Steps per Second: 21,808.40553
Overall Steps per Second: 10,376.68556

Timestep Collection Time: 2.29297
Timestep Consumption Time: 2.52610
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.81907

Cumulative Model Updates: 215,060
Cumulative Timesteps: 1,793,562,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1793562500...
Checkpoint 1793562500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.98069
Policy Entropy: 2.14631
Value Function Loss: 0.01688

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 21,596.47481
Overall Steps per Second: 10,276.43064

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.55082
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.86648

Cumulative Model Updates: 215,066
Cumulative Timesteps: 1,793,612,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.90464
Policy Entropy: 2.14308
Value Function Loss: 0.01646

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.62054

Collected Steps per Second: 22,110.36853
Overall Steps per Second: 10,508.78066

Timestep Collection Time: 2.26174
Timestep Consumption Time: 2.49694
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.75869

Cumulative Model Updates: 215,072
Cumulative Timesteps: 1,793,662,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1793662518...
Checkpoint 1793662518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.45767
Policy Entropy: 2.13829
Value Function Loss: 0.01628

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.52752
Value Function Update Magnitude: 0.62186

Collected Steps per Second: 21,850.07020
Overall Steps per Second: 10,441.40027

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.78882

Cumulative Model Updates: 215,078
Cumulative Timesteps: 1,793,712,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.23397
Policy Entropy: 2.11406
Value Function Loss: 0.01650

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.52630
Value Function Update Magnitude: 0.60686

Collected Steps per Second: 22,414.58921
Overall Steps per Second: 10,512.22962

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.52567
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.75636

Cumulative Model Updates: 215,084
Cumulative Timesteps: 1,793,762,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1793762520...
Checkpoint 1793762520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.23120
Policy Entropy: 2.10248
Value Function Loss: 0.01718

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.53247
Value Function Update Magnitude: 0.60506

Collected Steps per Second: 21,666.45284
Overall Steps per Second: 10,292.60948

Timestep Collection Time: 2.30790
Timestep Consumption Time: 2.55034
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.85824

Cumulative Model Updates: 215,090
Cumulative Timesteps: 1,793,812,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.04146
Policy Entropy: 2.10045
Value Function Loss: 0.01813

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.60519

Collected Steps per Second: 22,111.10970
Overall Steps per Second: 10,568.01496

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.73315

Cumulative Model Updates: 215,096
Cumulative Timesteps: 1,793,862,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1793862544...
Checkpoint 1793862544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.48814
Policy Entropy: 2.11156
Value Function Loss: 0.01707

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.59939

Collected Steps per Second: 21,382.75247
Overall Steps per Second: 10,248.62945

Timestep Collection Time: 2.33946
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.88104

Cumulative Model Updates: 215,102
Cumulative Timesteps: 1,793,912,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.79051
Policy Entropy: 2.11660
Value Function Loss: 0.01746

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.53951
Value Function Update Magnitude: 0.60332

Collected Steps per Second: 22,139.46989
Overall Steps per Second: 10,379.68246

Timestep Collection Time: 2.25868
Timestep Consumption Time: 2.55900
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.81768

Cumulative Model Updates: 215,108
Cumulative Timesteps: 1,793,962,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1793962574...
Checkpoint 1793962574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.91266
Policy Entropy: 2.11847
Value Function Loss: 0.01778

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 21,623.76007
Overall Steps per Second: 10,412.96327

Timestep Collection Time: 2.31236
Timestep Consumption Time: 2.48954
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.80190

Cumulative Model Updates: 215,114
Cumulative Timesteps: 1,794,012,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.07002
Policy Entropy: 2.12036
Value Function Loss: 0.01788

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 22,078.00016
Overall Steps per Second: 10,563.63516

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.46911
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.73436

Cumulative Model Updates: 215,120
Cumulative Timesteps: 1,794,062,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1794062588...
Checkpoint 1794062588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.34124
Policy Entropy: 2.12196
Value Function Loss: 0.01742

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 20,881.42224
Overall Steps per Second: 10,178.12906

Timestep Collection Time: 2.39591
Timestep Consumption Time: 2.51953
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.91544

Cumulative Model Updates: 215,126
Cumulative Timesteps: 1,794,112,618

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.51203
Policy Entropy: 2.11811
Value Function Loss: 0.01739

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.59346

Collected Steps per Second: 22,164.87856
Overall Steps per Second: 10,484.68465

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.76905

Cumulative Model Updates: 215,132
Cumulative Timesteps: 1,794,162,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1794162620...
Checkpoint 1794162620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.96321
Policy Entropy: 2.10084
Value Function Loss: 0.01849

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.55001
Value Function Update Magnitude: 0.61031

Collected Steps per Second: 21,659.23548
Overall Steps per Second: 10,315.30047

Timestep Collection Time: 2.30950
Timestep Consumption Time: 2.53980
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.84930

Cumulative Model Updates: 215,138
Cumulative Timesteps: 1,794,212,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.70257
Policy Entropy: 2.08012
Value Function Loss: 0.01784

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 21,984.80408
Overall Steps per Second: 10,345.67176

Timestep Collection Time: 2.27457
Timestep Consumption Time: 2.55895
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 4.83352

Cumulative Model Updates: 215,144
Cumulative Timesteps: 1,794,262,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1794262648...
Checkpoint 1794262648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.56425
Policy Entropy: 2.08656
Value Function Loss: 0.01807

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.60602

Collected Steps per Second: 21,579.21650
Overall Steps per Second: 10,529.78696

Timestep Collection Time: 2.31741
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.74919

Cumulative Model Updates: 215,150
Cumulative Timesteps: 1,794,312,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.83593
Policy Entropy: 2.07508
Value Function Loss: 0.01730

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.60382

Collected Steps per Second: 22,254.84296
Overall Steps per Second: 10,490.72301

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.76726

Cumulative Model Updates: 215,156
Cumulative Timesteps: 1,794,362,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1794362668...
Checkpoint 1794362668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.91083
Policy Entropy: 2.09897
Value Function Loss: 0.01694

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.60114

Collected Steps per Second: 21,280.93330
Overall Steps per Second: 10,276.30526

Timestep Collection Time: 2.35008
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.86673

Cumulative Model Updates: 215,162
Cumulative Timesteps: 1,794,412,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.75364
Policy Entropy: 2.11313
Value Function Loss: 0.01657

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 21,996.77153
Overall Steps per Second: 10,448.04863

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.51413
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78865

Cumulative Model Updates: 215,168
Cumulative Timesteps: 1,794,462,712

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1794462712...
Checkpoint 1794462712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.74033
Policy Entropy: 2.11232
Value Function Loss: 0.01663

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 21,546.45096
Overall Steps per Second: 10,508.88978

Timestep Collection Time: 2.32103
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.75883

Cumulative Model Updates: 215,174
Cumulative Timesteps: 1,794,512,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.21791
Policy Entropy: 2.09795
Value Function Loss: 0.01783

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54443
Value Function Update Magnitude: 0.59376

Collected Steps per Second: 22,278.12988
Overall Steps per Second: 10,492.14280

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.76661

Cumulative Model Updates: 215,180
Cumulative Timesteps: 1,794,562,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1794562734...
Checkpoint 1794562734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.50909
Policy Entropy: 2.08711
Value Function Loss: 0.01723

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 21,743.53061
Overall Steps per Second: 10,295.34713

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.55734
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.85715

Cumulative Model Updates: 215,186
Cumulative Timesteps: 1,794,612,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.83464
Policy Entropy: 2.08790
Value Function Loss: 0.01781

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.54382
Value Function Update Magnitude: 0.59412

Collected Steps per Second: 22,081.69113
Overall Steps per Second: 10,463.65444

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.77864

Cumulative Model Updates: 215,192
Cumulative Timesteps: 1,794,662,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1794662742...
Checkpoint 1794662742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.12833
Policy Entropy: 2.09775
Value Function Loss: 0.01710

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.59026

Collected Steps per Second: 21,667.51560
Overall Steps per Second: 10,548.38079

Timestep Collection Time: 2.30779
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.74044

Cumulative Model Updates: 215,198
Cumulative Timesteps: 1,794,712,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.21243
Policy Entropy: 2.09205
Value Function Loss: 0.01731

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.53078
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 22,270.45950
Overall Steps per Second: 10,458.98876

Timestep Collection Time: 2.24593
Timestep Consumption Time: 2.53636
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.78230

Cumulative Model Updates: 215,204
Cumulative Timesteps: 1,794,762,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1794762764...
Checkpoint 1794762764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.21042
Policy Entropy: 2.11348
Value Function Loss: 0.01755

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.53116
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 21,756.68417
Overall Steps per Second: 10,291.77713

Timestep Collection Time: 2.29952
Timestep Consumption Time: 2.56164
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.86116

Cumulative Model Updates: 215,210
Cumulative Timesteps: 1,794,812,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.74374
Policy Entropy: 2.13461
Value Function Loss: 0.01866

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 21,763.69098
Overall Steps per Second: 10,442.98519

Timestep Collection Time: 2.29805
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.78924

Cumulative Model Updates: 215,216
Cumulative Timesteps: 1,794,862,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1794862808...
Checkpoint 1794862808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.44825
Policy Entropy: 2.13987
Value Function Loss: 0.01809

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.59523

Collected Steps per Second: 21,806.77468
Overall Steps per Second: 10,579.40170

Timestep Collection Time: 2.29387
Timestep Consumption Time: 2.43437
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.72824

Cumulative Model Updates: 215,222
Cumulative Timesteps: 1,794,912,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.63392
Policy Entropy: 2.11604
Value Function Loss: 0.01840

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.60072

Collected Steps per Second: 21,575.65238
Overall Steps per Second: 10,249.53499

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.56187
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.88022

Cumulative Model Updates: 215,228
Cumulative Timesteps: 1,794,962,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1794962850...
Checkpoint 1794962850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.73566
Policy Entropy: 2.09998
Value Function Loss: 0.01774

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.62745

Collected Steps per Second: 21,849.13854
Overall Steps per Second: 10,497.63103

Timestep Collection Time: 2.28906
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.76431

Cumulative Model Updates: 215,234
Cumulative Timesteps: 1,795,012,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.25750
Policy Entropy: 2.10422
Value Function Loss: 0.01757

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.64549

Collected Steps per Second: 22,082.27491
Overall Steps per Second: 10,459.73503

Timestep Collection Time: 2.26507
Timestep Consumption Time: 2.51688
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.78196

Cumulative Model Updates: 215,240
Cumulative Timesteps: 1,795,062,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1795062882...
Checkpoint 1795062882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.95841
Policy Entropy: 2.13699
Value Function Loss: 0.01834

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.63121

Collected Steps per Second: 22,715.48368
Overall Steps per Second: 10,627.97000

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.70551

Cumulative Model Updates: 215,246
Cumulative Timesteps: 1,795,112,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.87056
Policy Entropy: 2.11813
Value Function Loss: 0.01879

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.55545
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 21,912.41258
Overall Steps per Second: 10,382.83663

Timestep Collection Time: 2.28190
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.81583

Cumulative Model Updates: 215,252
Cumulative Timesteps: 1,795,162,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1795162894...
Checkpoint 1795162894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.94393
Policy Entropy: 2.13240
Value Function Loss: 0.01814

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.65655

Collected Steps per Second: 21,689.81971
Overall Steps per Second: 10,294.00646

Timestep Collection Time: 2.30689
Timestep Consumption Time: 2.55380
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.86069

Cumulative Model Updates: 215,258
Cumulative Timesteps: 1,795,212,930

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.60328
Policy Entropy: 2.13103
Value Function Loss: 0.01737

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54720
Value Function Update Magnitude: 0.63635

Collected Steps per Second: 21,934.03669
Overall Steps per Second: 10,465.78519

Timestep Collection Time: 2.28038
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.77919

Cumulative Model Updates: 215,264
Cumulative Timesteps: 1,795,262,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1795262948...
Checkpoint 1795262948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.57379
Policy Entropy: 2.13986
Value Function Loss: 0.01734

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.60250

Collected Steps per Second: 21,818.84030
Overall Steps per Second: 10,599.98572

Timestep Collection Time: 2.29288
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71963

Cumulative Model Updates: 215,270
Cumulative Timesteps: 1,795,312,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.81414
Policy Entropy: 2.09750
Value Function Loss: 0.01791

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.58775

Collected Steps per Second: 21,600.85253
Overall Steps per Second: 10,288.20992

Timestep Collection Time: 2.31602
Timestep Consumption Time: 2.54663
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.86265

Cumulative Model Updates: 215,276
Cumulative Timesteps: 1,795,363,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1795363004...
Checkpoint 1795363004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.07598
Policy Entropy: 2.10160
Value Function Loss: 0.01862

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.59511

Collected Steps per Second: 21,992.80694
Overall Steps per Second: 10,409.90283

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.52965
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.80312

Cumulative Model Updates: 215,282
Cumulative Timesteps: 1,795,413,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.19491
Policy Entropy: 2.13304
Value Function Loss: 0.01795

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 21,925.97924
Overall Steps per Second: 10,468.81961

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.77895

Cumulative Model Updates: 215,288
Cumulative Timesteps: 1,795,463,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1795463034...
Checkpoint 1795463034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.00760
Policy Entropy: 2.17819
Value Function Loss: 0.01787

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.62778

Collected Steps per Second: 21,759.19261
Overall Steps per Second: 10,292.69142

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.56076
PPO Batch Consumption Time: 0.30242
Total Iteration Time: 4.85937

Cumulative Model Updates: 215,294
Cumulative Timesteps: 1,795,513,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.12974
Policy Entropy: 2.16107
Value Function Loss: 0.01816

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 21,771.97521
Overall Steps per Second: 10,387.00631

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.51838
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.81602

Cumulative Model Updates: 215,300
Cumulative Timesteps: 1,795,563,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1795563074...
Checkpoint 1795563074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.13204
Policy Entropy: 2.15353
Value Function Loss: 0.01808

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 21,664.89989
Overall Steps per Second: 10,380.56221

Timestep Collection Time: 2.30788
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.81669

Cumulative Model Updates: 215,306
Cumulative Timesteps: 1,795,613,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.16509
Policy Entropy: 2.14311
Value Function Loss: 0.01704

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.60507

Collected Steps per Second: 21,948.57336
Overall Steps per Second: 10,341.61320

Timestep Collection Time: 2.27851
Timestep Consumption Time: 2.55729
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 4.83580

Cumulative Model Updates: 215,312
Cumulative Timesteps: 1,795,663,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1795663084...
Checkpoint 1795663084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.35379
Policy Entropy: 2.14626
Value Function Loss: 0.01737

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 21,773.57218
Overall Steps per Second: 10,562.24001

Timestep Collection Time: 2.29682
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.73479

Cumulative Model Updates: 215,318
Cumulative Timesteps: 1,795,713,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.10021
Policy Entropy: 2.13292
Value Function Loss: 0.01712

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.58224

Collected Steps per Second: 21,733.45959
Overall Steps per Second: 10,370.89286

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.82254

Cumulative Model Updates: 215,324
Cumulative Timesteps: 1,795,763,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1795763108...
Checkpoint 1795763108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.53458
Policy Entropy: 2.11427
Value Function Loss: 0.01678

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.52623
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 21,702.02497
Overall Steps per Second: 10,273.92814

Timestep Collection Time: 2.30430
Timestep Consumption Time: 2.56317
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 4.86747

Cumulative Model Updates: 215,330
Cumulative Timesteps: 1,795,813,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.47913
Policy Entropy: 2.12705
Value Function Loss: 0.01583

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.53437
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 21,991.31077
Overall Steps per Second: 10,488.10742

Timestep Collection Time: 2.27408
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 4.76826

Cumulative Model Updates: 215,336
Cumulative Timesteps: 1,795,863,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1795863126...
Checkpoint 1795863126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.89192
Policy Entropy: 2.11411
Value Function Loss: 0.01603

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.52927
Value Function Update Magnitude: 0.60780

Collected Steps per Second: 21,919.65086
Overall Steps per Second: 10,357.12038

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.54695
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.82837

Cumulative Model Updates: 215,342
Cumulative Timesteps: 1,795,913,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.72284
Policy Entropy: 2.12585
Value Function Loss: 0.01696

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.59125

Collected Steps per Second: 21,869.84700
Overall Steps per Second: 10,268.22173

Timestep Collection Time: 2.28708
Timestep Consumption Time: 2.58407
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 4.87115

Cumulative Model Updates: 215,348
Cumulative Timesteps: 1,795,963,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1795963152...
Checkpoint 1795963152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.08022
Policy Entropy: 2.10019
Value Function Loss: 0.01669

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.52568
Value Function Update Magnitude: 0.58255

Collected Steps per Second: 21,772.15221
Overall Steps per Second: 10,237.26907

Timestep Collection Time: 2.29743
Timestep Consumption Time: 2.58864
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.88607

Cumulative Model Updates: 215,354
Cumulative Timesteps: 1,796,013,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.01657
Policy Entropy: 2.09853
Value Function Loss: 0.01684

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.52732
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 21,939.57516
Overall Steps per Second: 10,465.60734

Timestep Collection Time: 2.27899
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.30282
Total Iteration Time: 4.77755

Cumulative Model Updates: 215,360
Cumulative Timesteps: 1,796,063,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1796063172...
Checkpoint 1796063172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.64828
Policy Entropy: 2.10168
Value Function Loss: 0.01694

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 21,948.91617
Overall Steps per Second: 10,365.36739

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.54716
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.82646

Cumulative Model Updates: 215,366
Cumulative Timesteps: 1,796,113,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.53914
Policy Entropy: 2.10055
Value Function Loss: 0.01787

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 21,912.55308
Overall Steps per Second: 10,275.18044

Timestep Collection Time: 2.28244
Timestep Consumption Time: 2.58502
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.86746

Cumulative Model Updates: 215,372
Cumulative Timesteps: 1,796,163,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1796163214...
Checkpoint 1796163214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.59722
Policy Entropy: 2.09397
Value Function Loss: 0.01753

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 21,532.57769
Overall Steps per Second: 10,286.72519

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.53979
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 4.86297

Cumulative Model Updates: 215,378
Cumulative Timesteps: 1,796,213,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.23372
Policy Entropy: 2.07054
Value Function Loss: 0.01723

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.59997

Collected Steps per Second: 21,790.48919
Overall Steps per Second: 10,444.16198

Timestep Collection Time: 2.29485
Timestep Consumption Time: 2.49308
PPO Batch Consumption Time: 0.30356
Total Iteration Time: 4.78794

Cumulative Model Updates: 215,384
Cumulative Timesteps: 1,796,263,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1796263244...
Checkpoint 1796263244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.13090
Policy Entropy: 2.10240
Value Function Loss: 0.01725

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.60173

Collected Steps per Second: 21,695.20309
Overall Steps per Second: 10,304.85226

Timestep Collection Time: 2.30549
Timestep Consumption Time: 2.54834
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.85383

Cumulative Model Updates: 215,390
Cumulative Timesteps: 1,796,313,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.98833
Policy Entropy: 2.10294
Value Function Loss: 0.01730

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.62029

Collected Steps per Second: 21,834.78668
Overall Steps per Second: 10,294.50850

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.56724
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.85735

Cumulative Model Updates: 215,396
Cumulative Timesteps: 1,796,363,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1796363266...
Checkpoint 1796363266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.03084
Policy Entropy: 2.11822
Value Function Loss: 0.01639

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.63477

Collected Steps per Second: 21,673.46831
Overall Steps per Second: 10,335.42613

Timestep Collection Time: 2.30697
Timestep Consumption Time: 2.53076
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.83773

Cumulative Model Updates: 215,402
Cumulative Timesteps: 1,796,413,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.19267
Policy Entropy: 2.11592
Value Function Loss: 0.01699

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.54120
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 22,180.42641
Overall Steps per Second: 10,636.47813

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70080

Cumulative Model Updates: 215,408
Cumulative Timesteps: 1,796,463,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1796463266...
Checkpoint 1796463266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.41863
Policy Entropy: 2.11718
Value Function Loss: 0.01718

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 21,807.25310
Overall Steps per Second: 10,306.29076

Timestep Collection Time: 2.29327
Timestep Consumption Time: 2.55910
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.85238

Cumulative Model Updates: 215,414
Cumulative Timesteps: 1,796,513,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.82643
Policy Entropy: 2.11149
Value Function Loss: 0.01813

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.62623

Collected Steps per Second: 21,905.60554
Overall Steps per Second: 10,372.71922

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.53944
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.82342

Cumulative Model Updates: 215,420
Cumulative Timesteps: 1,796,563,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1796563308...
Checkpoint 1796563308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.73502
Policy Entropy: 2.10222
Value Function Loss: 0.01795

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.16176
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 22,007.32703
Overall Steps per Second: 10,373.04004

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.54822
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 4.82019

Cumulative Model Updates: 215,426
Cumulative Timesteps: 1,796,613,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.45070
Policy Entropy: 2.12330
Value Function Loss: 0.01965

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.16167
Policy Update Magnitude: 0.56531
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 22,945.76391
Overall Steps per Second: 10,590.10085

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.54407
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.72460

Cumulative Model Updates: 215,432
Cumulative Timesteps: 1,796,663,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1796663342...
Checkpoint 1796663342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.95220
Policy Entropy: 2.12308
Value Function Loss: 0.01817

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.62839

Collected Steps per Second: 21,684.91616
Overall Steps per Second: 10,346.87781

Timestep Collection Time: 2.30603
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.83296

Cumulative Model Updates: 215,438
Cumulative Timesteps: 1,796,713,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.50893
Policy Entropy: 2.12027
Value Function Loss: 0.01729

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.60047

Collected Steps per Second: 21,891.56222
Overall Steps per Second: 10,424.05054

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.80044

Cumulative Model Updates: 215,444
Cumulative Timesteps: 1,796,763,388

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1796763388...
Checkpoint 1796763388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.20132
Policy Entropy: 2.11675
Value Function Loss: 0.01700

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.58311

Collected Steps per Second: 21,651.01315
Overall Steps per Second: 10,459.51259

Timestep Collection Time: 2.30955
Timestep Consumption Time: 2.47117
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.78072

Cumulative Model Updates: 215,450
Cumulative Timesteps: 1,796,813,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.25527
Policy Entropy: 2.11683
Value Function Loss: 0.01702

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.60323

Collected Steps per Second: 22,051.62050
Overall Steps per Second: 10,338.08740

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.57072
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 4.83958

Cumulative Model Updates: 215,456
Cumulative Timesteps: 1,796,863,424

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1796863424...
Checkpoint 1796863424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.98216
Policy Entropy: 2.11699
Value Function Loss: 0.01720

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.59685

Collected Steps per Second: 21,516.05350
Overall Steps per Second: 10,196.51319

Timestep Collection Time: 2.32413
Timestep Consumption Time: 2.58010
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.90423

Cumulative Model Updates: 215,462
Cumulative Timesteps: 1,796,913,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.16686
Policy Entropy: 2.11918
Value Function Loss: 0.01751

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.60072

Collected Steps per Second: 21,907.09559
Overall Steps per Second: 10,398.43422

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.80976

Cumulative Model Updates: 215,468
Cumulative Timesteps: 1,796,963,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1796963444...
Checkpoint 1796963444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.40632
Policy Entropy: 2.14539
Value Function Loss: 0.01826

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.61692

Collected Steps per Second: 21,866.58558
Overall Steps per Second: 10,374.77785

Timestep Collection Time: 2.28696
Timestep Consumption Time: 2.53319
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.82015

Cumulative Model Updates: 215,474
Cumulative Timesteps: 1,797,013,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.25393
Policy Entropy: 2.15012
Value Function Loss: 0.01844

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.53949
Value Function Update Magnitude: 0.62059

Collected Steps per Second: 22,138.40662
Overall Steps per Second: 10,662.59218

Timestep Collection Time: 2.25861
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.68948

Cumulative Model Updates: 215,480
Cumulative Timesteps: 1,797,063,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1797063454...
Checkpoint 1797063454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.01384
Policy Entropy: 2.16443
Value Function Loss: 0.01865

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 21,834.14122
Overall Steps per Second: 10,322.31897

Timestep Collection Time: 2.29017
Timestep Consumption Time: 2.55409
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.84426

Cumulative Model Updates: 215,486
Cumulative Timesteps: 1,797,113,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.69385
Policy Entropy: 2.14903
Value Function Loss: 0.01829

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.61748

Collected Steps per Second: 22,024.97987
Overall Steps per Second: 10,464.59523

Timestep Collection Time: 2.27115
Timestep Consumption Time: 2.50897
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.78012

Cumulative Model Updates: 215,492
Cumulative Timesteps: 1,797,163,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1797163480...
Checkpoint 1797163480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.99917
Policy Entropy: 2.16846
Value Function Loss: 0.01727

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.52900
Value Function Update Magnitude: 0.60959

Collected Steps per Second: 21,662.94391
Overall Steps per Second: 10,300.79495

Timestep Collection Time: 2.30855
Timestep Consumption Time: 2.54641
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.85497

Cumulative Model Updates: 215,498
Cumulative Timesteps: 1,797,213,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.55072
Policy Entropy: 2.17327
Value Function Loss: 0.01718

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.52484
Value Function Update Magnitude: 0.59735

Collected Steps per Second: 22,092.98895
Overall Steps per Second: 10,558.53315

Timestep Collection Time: 2.26416
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.73759

Cumulative Model Updates: 215,504
Cumulative Timesteps: 1,797,263,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1797263512...
Checkpoint 1797263512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.08482
Policy Entropy: 2.17351
Value Function Loss: 0.01649

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.60663

Collected Steps per Second: 21,716.78446
Overall Steps per Second: 10,400.27803

Timestep Collection Time: 2.30301
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.80891

Cumulative Model Updates: 215,510
Cumulative Timesteps: 1,797,313,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.70127
Policy Entropy: 2.14871
Value Function Loss: 0.01582

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.59270

Collected Steps per Second: 22,192.78393
Overall Steps per Second: 10,473.32838

Timestep Collection Time: 2.25307
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.77422

Cumulative Model Updates: 215,516
Cumulative Timesteps: 1,797,363,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1797363528...
Checkpoint 1797363528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.34105
Policy Entropy: 2.12202
Value Function Loss: 0.01717

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.58381

Collected Steps per Second: 21,828.18440
Overall Steps per Second: 10,350.67328

Timestep Collection Time: 2.29199
Timestep Consumption Time: 2.54151
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.83350

Cumulative Model Updates: 215,522
Cumulative Timesteps: 1,797,413,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.08960
Policy Entropy: 2.12256
Value Function Loss: 0.01726

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.61698

Collected Steps per Second: 21,807.28103
Overall Steps per Second: 10,342.50530

Timestep Collection Time: 2.29281
Timestep Consumption Time: 2.54161
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.83442

Cumulative Model Updates: 215,528
Cumulative Timesteps: 1,797,463,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1797463558...
Checkpoint 1797463558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.18170
Policy Entropy: 2.12169
Value Function Loss: 0.01772

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 21,633.78028
Overall Steps per Second: 10,549.80437

Timestep Collection Time: 2.31231
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.74170

Cumulative Model Updates: 215,534
Cumulative Timesteps: 1,797,513,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.88932
Policy Entropy: 2.15047
Value Function Loss: 0.01723

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.53134
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 22,324.18577
Overall Steps per Second: 10,520.92396

Timestep Collection Time: 2.24008
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.75319

Cumulative Model Updates: 215,540
Cumulative Timesteps: 1,797,563,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1797563590...
Checkpoint 1797563590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.61716
Policy Entropy: 2.14006
Value Function Loss: 0.01796

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.15244
Policy Update Magnitude: 0.52731
Value Function Update Magnitude: 0.61158

Collected Steps per Second: 21,338.75502
Overall Steps per Second: 10,223.58404

Timestep Collection Time: 2.34456
Timestep Consumption Time: 2.54903
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.89359

Cumulative Model Updates: 215,546
Cumulative Timesteps: 1,797,613,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.48745
Policy Entropy: 2.14651
Value Function Loss: 0.01808

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.61110

Collected Steps per Second: 22,119.79887
Overall Steps per Second: 10,474.98597

Timestep Collection Time: 2.26105
Timestep Consumption Time: 2.51356
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.77461

Cumulative Model Updates: 215,552
Cumulative Timesteps: 1,797,663,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1797663634...
Checkpoint 1797663634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.32300
Policy Entropy: 2.14807
Value Function Loss: 0.01835

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.62549

Collected Steps per Second: 21,779.91691
Overall Steps per Second: 10,583.19540

Timestep Collection Time: 2.29578
Timestep Consumption Time: 2.42888
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.72466

Cumulative Model Updates: 215,558
Cumulative Timesteps: 1,797,713,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.55282
Policy Entropy: 2.16128
Value Function Loss: 0.01743

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 22,075.95169
Overall Steps per Second: 10,454.98698

Timestep Collection Time: 2.26536
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.78336

Cumulative Model Updates: 215,564
Cumulative Timesteps: 1,797,763,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1797763646...
Checkpoint 1797763646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.79095
Policy Entropy: 2.14196
Value Function Loss: 0.01726

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.64258

Collected Steps per Second: 21,742.03254
Overall Steps per Second: 10,255.06039

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.57677
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.87720

Cumulative Model Updates: 215,570
Cumulative Timesteps: 1,797,813,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.93307
Policy Entropy: 2.12098
Value Function Loss: 0.01803

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 22,015.45969
Overall Steps per Second: 10,475.03535

Timestep Collection Time: 2.27149
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77402

Cumulative Model Updates: 215,576
Cumulative Timesteps: 1,797,863,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1797863670...
Checkpoint 1797863670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.02896
Policy Entropy: 2.12971
Value Function Loss: 0.01827

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 22,182.21007
Overall Steps per Second: 10,498.02441

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.50884
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.76299

Cumulative Model Updates: 215,582
Cumulative Timesteps: 1,797,913,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.80394
Policy Entropy: 2.16199
Value Function Loss: 0.01682

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.64531

Collected Steps per Second: 22,269.07636
Overall Steps per Second: 10,468.75066

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.53085
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.77612

Cumulative Model Updates: 215,588
Cumulative Timesteps: 1,797,963,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1797963672...
Checkpoint 1797963672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.19197
Policy Entropy: 2.15176
Value Function Loss: 0.01628

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.63637

Collected Steps per Second: 22,078.40297
Overall Steps per Second: 10,311.79636

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.58457
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 4.84959

Cumulative Model Updates: 215,594
Cumulative Timesteps: 1,798,013,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.94731
Policy Entropy: 2.15182
Value Function Loss: 0.01775

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.64661

Collected Steps per Second: 21,824.01577
Overall Steps per Second: 10,450.10567

Timestep Collection Time: 2.29179
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.78617

Cumulative Model Updates: 215,600
Cumulative Timesteps: 1,798,063,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1798063696...
Checkpoint 1798063696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.70691
Policy Entropy: 2.15613
Value Function Loss: 0.01841

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.53438
Value Function Update Magnitude: 0.64754

Collected Steps per Second: 21,695.70605
Overall Steps per Second: 10,257.04026

Timestep Collection Time: 2.30516
Timestep Consumption Time: 2.57071
PPO Batch Consumption Time: 0.30308
Total Iteration Time: 4.87587

Cumulative Model Updates: 215,606
Cumulative Timesteps: 1,798,113,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.51827
Policy Entropy: 2.18555
Value Function Loss: 0.01858

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.63638

Collected Steps per Second: 22,143.49511
Overall Steps per Second: 10,447.44901

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.52907
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.78815

Cumulative Model Updates: 215,612
Cumulative Timesteps: 1,798,163,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1798163732...
Checkpoint 1798163732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.04440
Policy Entropy: 2.14759
Value Function Loss: 0.01726

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.64928

Collected Steps per Second: 21,831.04260
Overall Steps per Second: 10,412.02615

Timestep Collection Time: 2.29224
Timestep Consumption Time: 2.51393
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.80617

Cumulative Model Updates: 215,618
Cumulative Timesteps: 1,798,213,774

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.57807
Policy Entropy: 2.12643
Value Function Loss: 0.01766

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.65424

Collected Steps per Second: 21,842.00629
Overall Steps per Second: 10,341.62507

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.54688
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.83715

Cumulative Model Updates: 215,624
Cumulative Timesteps: 1,798,263,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1798263798...
Checkpoint 1798263798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.45911
Policy Entropy: 2.12041
Value Function Loss: 0.01759

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.66457

Collected Steps per Second: 21,610.70528
Overall Steps per Second: 10,559.35377

Timestep Collection Time: 2.31441
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.73665

Cumulative Model Updates: 215,630
Cumulative Timesteps: 1,798,313,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.61143
Policy Entropy: 2.13984
Value Function Loss: 0.01780

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.66842

Collected Steps per Second: 22,077.79235
Overall Steps per Second: 10,461.04741

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.78117

Cumulative Model Updates: 215,636
Cumulative Timesteps: 1,798,363,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1798363830...
Checkpoint 1798363830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.80000
Policy Entropy: 2.14924
Value Function Loss: 0.01778

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.66356

Collected Steps per Second: 21,859.98579
Overall Steps per Second: 10,294.25535

Timestep Collection Time: 2.28829
Timestep Consumption Time: 2.57092
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.85922

Cumulative Model Updates: 215,642
Cumulative Timesteps: 1,798,413,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.00886
Policy Entropy: 2.14048
Value Function Loss: 0.01791

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.64416

Collected Steps per Second: 21,759.93539
Overall Steps per Second: 10,350.85529

Timestep Collection Time: 2.29826
Timestep Consumption Time: 2.53322
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.83148

Cumulative Model Updates: 215,648
Cumulative Timesteps: 1,798,463,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1798463862...
Checkpoint 1798463862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.22173
Policy Entropy: 2.14670
Value Function Loss: 0.01753

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.62681

Collected Steps per Second: 21,806.81119
Overall Steps per Second: 10,595.57651

Timestep Collection Time: 2.29286
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.71895

Cumulative Model Updates: 215,654
Cumulative Timesteps: 1,798,513,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.22735
Policy Entropy: 2.15760
Value Function Loss: 0.01755

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 21,862.73435
Overall Steps per Second: 10,412.59979

Timestep Collection Time: 2.28718
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.80226

Cumulative Model Updates: 215,660
Cumulative Timesteps: 1,798,563,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1798563866...
Checkpoint 1798563866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.79407
Policy Entropy: 2.15883
Value Function Loss: 0.01787

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.60964

Collected Steps per Second: 21,810.00830
Overall Steps per Second: 10,284.89568

Timestep Collection Time: 2.29326
Timestep Consumption Time: 2.56979
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.86305

Cumulative Model Updates: 215,666
Cumulative Timesteps: 1,798,613,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.57528
Policy Entropy: 2.17001
Value Function Loss: 0.01737

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 21,781.10232
Overall Steps per Second: 10,471.64318

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.47953
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.77537

Cumulative Model Updates: 215,672
Cumulative Timesteps: 1,798,663,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1798663888...
Checkpoint 1798663888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.17089
Policy Entropy: 2.19144
Value Function Loss: 0.01684

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.52679
Value Function Update Magnitude: 0.58302

Collected Steps per Second: 21,507.57309
Overall Steps per Second: 10,543.37648

Timestep Collection Time: 2.32504
Timestep Consumption Time: 2.41784
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.74288

Cumulative Model Updates: 215,678
Cumulative Timesteps: 1,798,713,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.67087
Policy Entropy: 2.19321
Value Function Loss: 0.01596

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.57099

Collected Steps per Second: 22,167.55058
Overall Steps per Second: 10,461.97692

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.52386
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.77959

Cumulative Model Updates: 215,684
Cumulative Timesteps: 1,798,763,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1798763898...
Checkpoint 1798763898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.32782
Policy Entropy: 2.18835
Value Function Loss: 0.01670

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.52284
Value Function Update Magnitude: 0.57376

Collected Steps per Second: 21,984.47836
Overall Steps per Second: 10,222.28032

Timestep Collection Time: 2.27460
Timestep Consumption Time: 2.61726
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.89186

Cumulative Model Updates: 215,690
Cumulative Timesteps: 1,798,813,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.07798
Policy Entropy: 2.16470
Value Function Loss: 0.01697

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.52690
Value Function Update Magnitude: 0.58197

Collected Steps per Second: 21,629.01430
Overall Steps per Second: 10,288.43419

Timestep Collection Time: 2.31171
Timestep Consumption Time: 2.54812
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.85983

Cumulative Model Updates: 215,696
Cumulative Timesteps: 1,798,863,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1798863904...
Checkpoint 1798863904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.46081
Policy Entropy: 2.15788
Value Function Loss: 0.01669

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 22,052.97669
Overall Steps per Second: 10,531.41123

Timestep Collection Time: 2.26845
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.75017

Cumulative Model Updates: 215,702
Cumulative Timesteps: 1,798,913,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.20912
Policy Entropy: 2.15378
Value Function Loss: 0.01563

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.52204
Value Function Update Magnitude: 0.55909

Collected Steps per Second: 22,048.20994
Overall Steps per Second: 10,355.87803

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.56144
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.83011

Cumulative Model Updates: 215,708
Cumulative Timesteps: 1,798,963,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1798963950...
Checkpoint 1798963950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.48288
Policy Entropy: 2.17268
Value Function Loss: 0.01676

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.53743
Value Function Update Magnitude: 0.55323

Collected Steps per Second: 21,572.52263
Overall Steps per Second: 10,208.16849

Timestep Collection Time: 2.31915
Timestep Consumption Time: 2.58182
PPO Batch Consumption Time: 0.30331
Total Iteration Time: 4.90098

Cumulative Model Updates: 215,714
Cumulative Timesteps: 1,799,013,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.94755
Policy Entropy: 2.18885
Value Function Loss: 0.01676

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.56302

Collected Steps per Second: 20,556.51206
Overall Steps per Second: 10,043.64530

Timestep Collection Time: 2.43300
Timestep Consumption Time: 2.54667
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.97967

Cumulative Model Updates: 215,720
Cumulative Timesteps: 1,799,063,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1799063994...
Checkpoint 1799063994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.80136
Policy Entropy: 2.17880
Value Function Loss: 0.01698

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.56951

Collected Steps per Second: 19,686.88456
Overall Steps per Second: 9,818.00444

Timestep Collection Time: 2.54118
Timestep Consumption Time: 2.55435
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 5.09554

Cumulative Model Updates: 215,726
Cumulative Timesteps: 1,799,114,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.67378
Policy Entropy: 2.16321
Value Function Loss: 0.01800

Mean KL Divergence: 0.02784
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.56147

Collected Steps per Second: 21,801.31823
Overall Steps per Second: 10,457.33601

Timestep Collection Time: 2.29491
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.78439

Cumulative Model Updates: 215,732
Cumulative Timesteps: 1,799,164,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1799164054...
Checkpoint 1799164054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.27711
Policy Entropy: 2.16956
Value Function Loss: 0.01774

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.54149
Value Function Update Magnitude: 0.58879

Collected Steps per Second: 21,862.31174
Overall Steps per Second: 10,337.10942

Timestep Collection Time: 2.28878
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.84062

Cumulative Model Updates: 215,738
Cumulative Timesteps: 1,799,214,092

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.65976
Policy Entropy: 2.18061
Value Function Loss: 0.01676

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 21,733.20082
Overall Steps per Second: 10,330.88392

Timestep Collection Time: 2.30090
Timestep Consumption Time: 2.53953
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.84044

Cumulative Model Updates: 215,744
Cumulative Timesteps: 1,799,264,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1799264098...
Checkpoint 1799264098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.90611
Policy Entropy: 2.17119
Value Function Loss: 0.01629

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.60041

Collected Steps per Second: 21,835.50054
Overall Steps per Second: 10,361.17094

Timestep Collection Time: 2.29049
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.82706

Cumulative Model Updates: 215,750
Cumulative Timesteps: 1,799,314,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.59344
Policy Entropy: 2.14956
Value Function Loss: 0.01754

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.60896

Collected Steps per Second: 21,993.65616
Overall Steps per Second: 10,601.04576

Timestep Collection Time: 2.27411
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.71803

Cumulative Model Updates: 215,756
Cumulative Timesteps: 1,799,364,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1799364128...
Checkpoint 1799364128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.24294
Policy Entropy: 2.15126
Value Function Loss: 0.01688

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.53322
Value Function Update Magnitude: 0.62305

Collected Steps per Second: 21,854.34760
Overall Steps per Second: 10,328.74128

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.55442
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.84357

Cumulative Model Updates: 215,762
Cumulative Timesteps: 1,799,414,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.08146
Policy Entropy: 2.14705
Value Function Loss: 0.01646

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.61509

Collected Steps per Second: 21,700.37323
Overall Steps per Second: 10,371.94829

Timestep Collection Time: 2.30420
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.82089

Cumulative Model Updates: 215,768
Cumulative Timesteps: 1,799,464,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1799464158...
Checkpoint 1799464158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.69990
Policy Entropy: 2.15795
Value Function Loss: 0.01510

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.60525

Collected Steps per Second: 21,718.35421
Overall Steps per Second: 10,289.79262

Timestep Collection Time: 2.30395
Timestep Consumption Time: 2.55893
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.86288

Cumulative Model Updates: 215,774
Cumulative Timesteps: 1,799,514,196

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.87915
Policy Entropy: 2.16145
Value Function Loss: 0.01650

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.52194
Value Function Update Magnitude: 0.58971

Collected Steps per Second: 21,759.48891
Overall Steps per Second: 10,456.52311

Timestep Collection Time: 2.29858
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.78323

Cumulative Model Updates: 215,780
Cumulative Timesteps: 1,799,564,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1799564212...
Checkpoint 1799564212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.10479
Policy Entropy: 2.16571
Value Function Loss: 0.01588

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.59186

Collected Steps per Second: 21,686.22992
Overall Steps per Second: 10,263.98427

Timestep Collection Time: 2.30589
Timestep Consumption Time: 2.56610
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.87199

Cumulative Model Updates: 215,786
Cumulative Timesteps: 1,799,614,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.03679
Policy Entropy: 2.16943
Value Function Loss: 0.01642

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.58897

Collected Steps per Second: 21,997.55982
Overall Steps per Second: 10,417.62269

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.80071

Cumulative Model Updates: 215,792
Cumulative Timesteps: 1,799,664,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1799664230...
Checkpoint 1799664230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.44832
Policy Entropy: 2.15973
Value Function Loss: 0.01691

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.58178

Collected Steps per Second: 21,655.95775
Overall Steps per Second: 10,304.28564

Timestep Collection Time: 2.30976
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.85429

Cumulative Model Updates: 215,798
Cumulative Timesteps: 1,799,714,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.90072
Policy Entropy: 2.18078
Value Function Loss: 0.01676

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.60760

Collected Steps per Second: 22,295.18791
Overall Steps per Second: 10,689.96759

Timestep Collection Time: 2.24425
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68065

Cumulative Model Updates: 215,804
Cumulative Timesteps: 1,799,764,286

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1799764286...
Checkpoint 1799764286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.98943
Policy Entropy: 2.17799
Value Function Loss: 0.01581

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.53651
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 21,744.75886
Overall Steps per Second: 10,308.07424

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.55188
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.85192

Cumulative Model Updates: 215,810
Cumulative Timesteps: 1,799,814,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.97197
Policy Entropy: 2.18689
Value Function Loss: 0.01626

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.59924

Collected Steps per Second: 21,981.05041
Overall Steps per Second: 10,464.92912

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.50368
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.77882

Cumulative Model Updates: 215,816
Cumulative Timesteps: 1,799,864,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1799864310...
Checkpoint 1799864310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.10668
Policy Entropy: 2.18581
Value Function Loss: 0.01598

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 21,753.71698
Overall Steps per Second: 10,344.25940

Timestep Collection Time: 2.29947
Timestep Consumption Time: 2.53626
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.83573

Cumulative Model Updates: 215,822
Cumulative Timesteps: 1,799,914,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.02131
Policy Entropy: 2.19294
Value Function Loss: 0.01629

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.63796

Collected Steps per Second: 21,823.69461
Overall Steps per Second: 10,524.15439

Timestep Collection Time: 2.29219
Timestep Consumption Time: 2.46107
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.75326

Cumulative Model Updates: 215,828
Cumulative Timesteps: 1,799,964,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1799964356...
Checkpoint 1799964356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.76346
Policy Entropy: 2.17839
Value Function Loss: 0.01551

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 21,946.27429
Overall Steps per Second: 10,433.59948

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.79259

Cumulative Model Updates: 215,834
Cumulative Timesteps: 1,800,014,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.94763
Policy Entropy: 2.17557
Value Function Loss: 0.01629

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.58750

Collected Steps per Second: 22,008.94177
Overall Steps per Second: 10,410.28553

Timestep Collection Time: 2.27217
Timestep Consumption Time: 2.53154
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.80371

Cumulative Model Updates: 215,840
Cumulative Timesteps: 1,800,064,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1800064368...
Checkpoint 1800064368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.59376
Policy Entropy: 2.14014
Value Function Loss: 0.01606

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.53842
Value Function Update Magnitude: 0.57064

Collected Steps per Second: 21,736.01771
Overall Steps per Second: 10,308.33559

Timestep Collection Time: 2.30051
Timestep Consumption Time: 2.55032
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.85083

Cumulative Model Updates: 215,846
Cumulative Timesteps: 1,800,114,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.26112
Policy Entropy: 2.15081
Value Function Loss: 0.01739

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.54574

Collected Steps per Second: 22,955.78159
Overall Steps per Second: 10,522.47876

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.57394
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.75230

Cumulative Model Updates: 215,852
Cumulative Timesteps: 1,800,164,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1800164378...
Checkpoint 1800164378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.09908
Policy Entropy: 2.15210
Value Function Loss: 0.01744

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.53911

Collected Steps per Second: 21,700.54857
Overall Steps per Second: 10,319.95279

Timestep Collection Time: 2.30464
Timestep Consumption Time: 2.54150
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.84615

Cumulative Model Updates: 215,858
Cumulative Timesteps: 1,800,214,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.57135
Policy Entropy: 2.16882
Value Function Loss: 0.01790

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 21,860.55909
Overall Steps per Second: 10,296.48483

Timestep Collection Time: 2.28814
Timestep Consumption Time: 2.56983
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.85797

Cumulative Model Updates: 215,864
Cumulative Timesteps: 1,800,264,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1800264410...
Checkpoint 1800264410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.40491
Policy Entropy: 2.18469
Value Function Loss: 0.01679

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.58520

Collected Steps per Second: 21,859.82985
Overall Steps per Second: 10,427.97599

Timestep Collection Time: 2.28858
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.79748

Cumulative Model Updates: 215,870
Cumulative Timesteps: 1,800,314,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.82714
Policy Entropy: 2.20059
Value Function Loss: 0.01674

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.54348
Value Function Update Magnitude: 0.59120

Collected Steps per Second: 23,048.99727
Overall Steps per Second: 10,677.12359

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.68666

Cumulative Model Updates: 215,876
Cumulative Timesteps: 1,800,364,478

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1800364478...
Checkpoint 1800364478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.90068
Policy Entropy: 2.21806
Value Function Loss: 0.01662

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.57965

Collected Steps per Second: 21,751.88016
Overall Steps per Second: 10,286.53396

Timestep Collection Time: 2.29911
Timestep Consumption Time: 2.56258
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 4.86170

Cumulative Model Updates: 215,882
Cumulative Timesteps: 1,800,414,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.57104
Policy Entropy: 2.20084
Value Function Loss: 0.01704

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.53151
Value Function Update Magnitude: 0.56885

Collected Steps per Second: 22,013.46511
Overall Steps per Second: 10,367.87673

Timestep Collection Time: 2.27134
Timestep Consumption Time: 2.55125
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.82259

Cumulative Model Updates: 215,888
Cumulative Timesteps: 1,800,464,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1800464488...
Checkpoint 1800464488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.26036
Policy Entropy: 2.19644
Value Function Loss: 0.01715

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.57291

Collected Steps per Second: 21,786.20954
Overall Steps per Second: 10,605.39861

Timestep Collection Time: 2.29549
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.71552

Cumulative Model Updates: 215,894
Cumulative Timesteps: 1,800,514,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.01701
Policy Entropy: 2.19433
Value Function Loss: 0.01827

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 22,092.44824
Overall Steps per Second: 10,490.19722

Timestep Collection Time: 2.26385
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.76769

Cumulative Model Updates: 215,900
Cumulative Timesteps: 1,800,564,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1800564512...
Checkpoint 1800564512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.94933
Policy Entropy: 2.21722
Value Function Loss: 0.01872

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 21,884.04248
Overall Steps per Second: 10,341.89548

Timestep Collection Time: 2.28605
Timestep Consumption Time: 2.55136
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.83741

Cumulative Model Updates: 215,906
Cumulative Timesteps: 1,800,614,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.74212
Policy Entropy: 2.18912
Value Function Loss: 0.01862

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.61607

Collected Steps per Second: 22,195.90413
Overall Steps per Second: 10,439.78094

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.53721
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 4.79033

Cumulative Model Updates: 215,912
Cumulative Timesteps: 1,800,664,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1800664550...
Checkpoint 1800664550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.66850
Policy Entropy: 2.16460
Value Function Loss: 0.01767

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.59830

Collected Steps per Second: 21,912.47062
Overall Steps per Second: 10,522.15815

Timestep Collection Time: 2.28208
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.75245

Cumulative Model Updates: 215,918
Cumulative Timesteps: 1,800,714,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.26510
Policy Entropy: 2.15397
Value Function Loss: 0.01773

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.58578

Collected Steps per Second: 22,116.75333
Overall Steps per Second: 10,467.87448

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.77881

Cumulative Model Updates: 215,924
Cumulative Timesteps: 1,800,764,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1800764580...
Checkpoint 1800764580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.23873
Policy Entropy: 2.16697
Value Function Loss: 0.01754

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.59690

Collected Steps per Second: 21,855.45967
Overall Steps per Second: 10,287.02304

Timestep Collection Time: 2.28886
Timestep Consumption Time: 2.57397
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.86283

Cumulative Model Updates: 215,930
Cumulative Timesteps: 1,800,814,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.74226
Policy Entropy: 2.19527
Value Function Loss: 0.01701

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.59276

Collected Steps per Second: 22,090.84808
Overall Steps per Second: 10,369.31224

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.56018
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.82501

Cumulative Model Updates: 215,936
Cumulative Timesteps: 1,800,864,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1800864636...
Checkpoint 1800864636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.11948
Policy Entropy: 2.22076
Value Function Loss: 0.01549

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.58310

Collected Steps per Second: 21,856.03891
Overall Steps per Second: 10,395.11842

Timestep Collection Time: 2.28834
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.81130

Cumulative Model Updates: 215,942
Cumulative Timesteps: 1,800,914,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.66293
Policy Entropy: 2.23134
Value Function Loss: 0.01564

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.52397
Value Function Update Magnitude: 0.56071

Collected Steps per Second: 21,964.42239
Overall Steps per Second: 10,606.42610

Timestep Collection Time: 2.27787
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.71714

Cumulative Model Updates: 215,948
Cumulative Timesteps: 1,800,964,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1800964682...
Checkpoint 1800964682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.89124
Policy Entropy: 2.21836
Value Function Loss: 0.01641

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.56146

Collected Steps per Second: 22,234.88711
Overall Steps per Second: 10,386.71857

Timestep Collection Time: 2.24944
Timestep Consumption Time: 2.56594
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.81538

Cumulative Model Updates: 215,954
Cumulative Timesteps: 1,801,014,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.12885
Policy Entropy: 2.20176
Value Function Loss: 0.01637

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 22,251.03354
Overall Steps per Second: 10,368.78838

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.57652
PPO Batch Consumption Time: 0.30205
Total Iteration Time: 4.82486

Cumulative Model Updates: 215,960
Cumulative Timesteps: 1,801,064,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1801064726...
Checkpoint 1801064726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.82789
Policy Entropy: 2.18785
Value Function Loss: 0.01618

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.54254

Collected Steps per Second: 21,856.60737
Overall Steps per Second: 10,381.83117

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.52948
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.81803

Cumulative Model Updates: 215,966
Cumulative Timesteps: 1,801,114,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.70323
Policy Entropy: 2.19565
Value Function Loss: 0.01540

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.51270
Value Function Update Magnitude: 0.51123

Collected Steps per Second: 22,299.06418
Overall Steps per Second: 10,672.73947

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68783

Cumulative Model Updates: 215,972
Cumulative Timesteps: 1,801,164,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1801164778...
Checkpoint 1801164778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.95287
Policy Entropy: 2.19858
Value Function Loss: 0.01669

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.51508
Value Function Update Magnitude: 0.51872

Collected Steps per Second: 21,724.99859
Overall Steps per Second: 10,259.37453

Timestep Collection Time: 2.30223
Timestep Consumption Time: 2.57292
PPO Batch Consumption Time: 0.30263
Total Iteration Time: 4.87515

Cumulative Model Updates: 215,978
Cumulative Timesteps: 1,801,214,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.03221
Policy Entropy: 2.21815
Value Function Loss: 0.01711

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.52891
Value Function Update Magnitude: 0.55448

Collected Steps per Second: 21,978.67020
Overall Steps per Second: 10,452.13063

Timestep Collection Time: 2.27502
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.78391

Cumulative Model Updates: 215,984
Cumulative Timesteps: 1,801,264,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1801264796...
Checkpoint 1801264796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.41497
Policy Entropy: 2.20198
Value Function Loss: 0.01773

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.58431

Collected Steps per Second: 21,739.35062
Overall Steps per Second: 10,363.44805

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.52518
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.82561

Cumulative Model Updates: 215,990
Cumulative Timesteps: 1,801,314,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.55791
Policy Entropy: 2.22607
Value Function Loss: 0.01782

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.54042
Value Function Update Magnitude: 0.58886

Collected Steps per Second: 21,962.36747
Overall Steps per Second: 10,524.76564

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.75336

Cumulative Model Updates: 215,996
Cumulative Timesteps: 1,801,364,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1801364834...
Checkpoint 1801364834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.94826
Policy Entropy: 2.18492
Value Function Loss: 0.01965

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.60527

Collected Steps per Second: 22,090.71591
Overall Steps per Second: 10,450.27026

Timestep Collection Time: 2.26421
Timestep Consumption Time: 2.52208
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.78629

Cumulative Model Updates: 216,002
Cumulative Timesteps: 1,801,414,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.34477
Policy Entropy: 2.20698
Value Function Loss: 0.01976

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 22,074.09959
Overall Steps per Second: 10,458.49495

Timestep Collection Time: 2.26619
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.78310

Cumulative Model Updates: 216,008
Cumulative Timesteps: 1,801,464,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1801464876...
Checkpoint 1801464876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.10911
Policy Entropy: 2.17985
Value Function Loss: 0.01870

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 21,565.56629
Overall Steps per Second: 10,303.28737

Timestep Collection Time: 2.31925
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.85437

Cumulative Model Updates: 216,014
Cumulative Timesteps: 1,801,514,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.14189
Policy Entropy: 2.21338
Value Function Loss: 0.01731

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.61459

Collected Steps per Second: 21,581.30914
Overall Steps per Second: 10,324.80109

Timestep Collection Time: 2.31784
Timestep Consumption Time: 2.52700
PPO Batch Consumption Time: 0.30717
Total Iteration Time: 4.84484

Cumulative Model Updates: 216,020
Cumulative Timesteps: 1,801,564,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1801564914...
Checkpoint 1801564914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.91077
Policy Entropy: 2.19158
Value Function Loss: 0.01699

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 21,348.61122
Overall Steps per Second: 10,233.85188

Timestep Collection Time: 2.34329
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.88829

Cumulative Model Updates: 216,026
Cumulative Timesteps: 1,801,614,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.74827
Policy Entropy: 2.18466
Value Function Loss: 0.01719

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.54229
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 21,607.16056
Overall Steps per Second: 10,290.22848

Timestep Collection Time: 2.31451
Timestep Consumption Time: 2.54544
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.85995

Cumulative Model Updates: 216,032
Cumulative Timesteps: 1,801,664,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1801664950...
Checkpoint 1801664950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.72160
Policy Entropy: 2.19646
Value Function Loss: 0.01673

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.59445

Collected Steps per Second: 22,033.98250
Overall Steps per Second: 10,381.02116

Timestep Collection Time: 2.27067
Timestep Consumption Time: 2.54889
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.81956

Cumulative Model Updates: 216,038
Cumulative Timesteps: 1,801,714,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.29296
Policy Entropy: 2.19266
Value Function Loss: 0.01555

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.58638

Collected Steps per Second: 21,698.20241
Overall Steps per Second: 10,392.33906

Timestep Collection Time: 2.30452
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.81162

Cumulative Model Updates: 216,044
Cumulative Timesteps: 1,801,764,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1801764986...
Checkpoint 1801764986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.30936
Policy Entropy: 2.19766
Value Function Loss: 0.01500

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.51536
Value Function Update Magnitude: 0.55925

Collected Steps per Second: 22,428.24710
Overall Steps per Second: 10,377.66352

Timestep Collection Time: 2.22933
Timestep Consumption Time: 2.58871
PPO Batch Consumption Time: 0.30364
Total Iteration Time: 4.81804

Cumulative Model Updates: 216,050
Cumulative Timesteps: 1,801,814,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.70131
Policy Entropy: 2.19112
Value Function Loss: 0.01490

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 21,812.12999
Overall Steps per Second: 10,305.13045

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.56088
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.85428

Cumulative Model Updates: 216,056
Cumulative Timesteps: 1,801,865,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1801865010...
Checkpoint 1801865010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.65573
Policy Entropy: 2.19442
Value Function Loss: 0.01599

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.51618
Value Function Update Magnitude: 0.55763

Collected Steps per Second: 21,636.89304
Overall Steps per Second: 10,261.12627

Timestep Collection Time: 2.31133
Timestep Consumption Time: 2.56240
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.87373

Cumulative Model Updates: 216,062
Cumulative Timesteps: 1,801,915,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.60282
Policy Entropy: 2.19795
Value Function Loss: 0.01668

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.56582

Collected Steps per Second: 21,711.20812
Overall Steps per Second: 10,411.09897

Timestep Collection Time: 2.30406
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.80487

Cumulative Model Updates: 216,068
Cumulative Timesteps: 1,801,965,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1801965044...
Checkpoint 1801965044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.52602
Policy Entropy: 2.19758
Value Function Loss: 0.01774

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.52321
Value Function Update Magnitude: 0.57187

Collected Steps per Second: 22,427.07403
Overall Steps per Second: 10,543.73111

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.51502
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.74652

Cumulative Model Updates: 216,074
Cumulative Timesteps: 1,802,015,090

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.39404
Policy Entropy: 2.19094
Value Function Loss: 0.01716

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.52050
Value Function Update Magnitude: 0.58779

Collected Steps per Second: 22,095.08155
Overall Steps per Second: 10,377.70868

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.55640
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.82052

Cumulative Model Updates: 216,080
Cumulative Timesteps: 1,802,065,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1802065116...
Checkpoint 1802065116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.54474
Policy Entropy: 2.16808
Value Function Loss: 0.01616

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 21,777.40367
Overall Steps per Second: 10,375.59531

Timestep Collection Time: 2.29642
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.81996

Cumulative Model Updates: 216,086
Cumulative Timesteps: 1,802,115,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.82808
Policy Entropy: 2.15405
Value Function Loss: 0.01672

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.60122

Collected Steps per Second: 21,975.64425
Overall Steps per Second: 10,477.92913

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.77289

Cumulative Model Updates: 216,092
Cumulative Timesteps: 1,802,165,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1802165136...
Checkpoint 1802165136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.37189
Policy Entropy: 2.15840
Value Function Loss: 0.01666

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.62707

Collected Steps per Second: 22,546.83507
Overall Steps per Second: 10,547.07118

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.74312

Cumulative Model Updates: 216,098
Cumulative Timesteps: 1,802,215,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.79594
Policy Entropy: 2.16705
Value Function Loss: 0.01769

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.62849

Collected Steps per Second: 22,208.06634
Overall Steps per Second: 10,473.89058

Timestep Collection Time: 2.25270
Timestep Consumption Time: 2.52375
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.77645

Cumulative Model Updates: 216,104
Cumulative Timesteps: 1,802,265,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1802265190...
Checkpoint 1802265190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.49961
Policy Entropy: 2.18373
Value Function Loss: 0.01694

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.54920
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 21,891.94108
Overall Steps per Second: 10,332.70070

Timestep Collection Time: 2.28586
Timestep Consumption Time: 2.55721
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.84307

Cumulative Model Updates: 216,110
Cumulative Timesteps: 1,802,315,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.65554
Policy Entropy: 2.17471
Value Function Loss: 0.01780

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.17617
Policy Update Magnitude: 0.52508
Value Function Update Magnitude: 0.60961

Collected Steps per Second: 21,886.38594
Overall Steps per Second: 10,453.52608

Timestep Collection Time: 2.28544
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.78499

Cumulative Model Updates: 216,116
Cumulative Timesteps: 1,802,365,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1802365252...
Checkpoint 1802365252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.11552
Policy Entropy: 2.20295
Value Function Loss: 0.01754

Mean KL Divergence: 0.03460
SB3 Clip Fraction: 0.20249
Policy Update Magnitude: 0.49879
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 21,645.39909
Overall Steps per Second: 10,501.76185

Timestep Collection Time: 2.31107
Timestep Consumption Time: 2.45232
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.76339

Cumulative Model Updates: 216,122
Cumulative Timesteps: 1,802,415,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.73750
Policy Entropy: 2.20807
Value Function Loss: 0.01771

Mean KL Divergence: 0.03172
SB3 Clip Fraction: 0.18566
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 22,183.69016
Overall Steps per Second: 10,411.27078

Timestep Collection Time: 2.25607
Timestep Consumption Time: 2.55103
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.80710

Cumulative Model Updates: 216,128
Cumulative Timesteps: 1,802,465,324

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1802465324...
Checkpoint 1802465324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.57680
Policy Entropy: 2.21485
Value Function Loss: 0.01716

Mean KL Divergence: 0.02666
SB3 Clip Fraction: 0.17180
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.60255

Collected Steps per Second: 21,643.54976
Overall Steps per Second: 10,383.12079

Timestep Collection Time: 2.31025
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.81570

Cumulative Model Updates: 216,134
Cumulative Timesteps: 1,802,515,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.33647
Policy Entropy: 2.21292
Value Function Loss: 0.01709

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 22,038.34264
Overall Steps per Second: 10,400.06604

Timestep Collection Time: 2.26905
Timestep Consumption Time: 2.53919
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.80824

Cumulative Model Updates: 216,140
Cumulative Timesteps: 1,802,565,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1802565332...
Checkpoint 1802565332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.64161
Policy Entropy: 2.20893
Value Function Loss: 0.01653

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.17618
Policy Update Magnitude: 0.49540
Value Function Update Magnitude: 0.56697

Collected Steps per Second: 21,895.10994
Overall Steps per Second: 10,441.51368

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.78973

Cumulative Model Updates: 216,146
Cumulative Timesteps: 1,802,615,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.86214
Policy Entropy: 2.20203
Value Function Loss: 0.01711

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 0.55701

Collected Steps per Second: 21,913.87546
Overall Steps per Second: 10,313.38408

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.56764
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.85040

Cumulative Model Updates: 216,152
Cumulative Timesteps: 1,802,665,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1802665368...
Checkpoint 1802665368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.70310
Policy Entropy: 2.17175
Value Function Loss: 0.01640

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.57095

Collected Steps per Second: 21,696.90875
Overall Steps per Second: 10,260.96611

Timestep Collection Time: 2.30512
Timestep Consumption Time: 2.56908
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.87420

Cumulative Model Updates: 216,158
Cumulative Timesteps: 1,802,715,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.89198
Policy Entropy: 2.16059
Value Function Loss: 0.01619

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.53806
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 22,126.35648
Overall Steps per Second: 10,383.98637

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.55597
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.81626

Cumulative Model Updates: 216,164
Cumulative Timesteps: 1,802,765,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1802765394...
Checkpoint 1802765394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.92264
Policy Entropy: 2.17543
Value Function Loss: 0.01529

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.52966
Value Function Update Magnitude: 0.55718

Collected Steps per Second: 21,754.51759
Overall Steps per Second: 10,331.52114

Timestep Collection Time: 2.29892
Timestep Consumption Time: 2.54180
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.84072

Cumulative Model Updates: 216,170
Cumulative Timesteps: 1,802,815,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.84170
Policy Entropy: 2.17225
Value Function Loss: 0.01613

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.53765

Collected Steps per Second: 22,339.40971
Overall Steps per Second: 10,682.43594

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.68320

Cumulative Model Updates: 216,176
Cumulative Timesteps: 1,802,865,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1802865434...
Checkpoint 1802865434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.61226
Policy Entropy: 2.16109
Value Function Loss: 0.01584

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.52144
Value Function Update Magnitude: 0.52104

Collected Steps per Second: 21,667.28324
Overall Steps per Second: 10,293.25763

Timestep Collection Time: 2.30873
Timestep Consumption Time: 2.55115
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.85988

Cumulative Model Updates: 216,182
Cumulative Timesteps: 1,802,915,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.20401
Policy Entropy: 2.16633
Value Function Loss: 0.01548

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.50679

Collected Steps per Second: 21,719.07509
Overall Steps per Second: 10,372.93375

Timestep Collection Time: 2.30222
Timestep Consumption Time: 2.51821
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.82043

Cumulative Model Updates: 216,188
Cumulative Timesteps: 1,802,965,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1802965460...
Checkpoint 1802965460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.76552
Policy Entropy: 2.18749
Value Function Loss: 0.01612

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.51708

Collected Steps per Second: 21,886.23594
Overall Steps per Second: 10,335.62299

Timestep Collection Time: 2.28527
Timestep Consumption Time: 2.55391
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.83919

Cumulative Model Updates: 216,194
Cumulative Timesteps: 1,803,015,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.79686
Policy Entropy: 2.20110
Value Function Loss: 0.01570

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.53407

Collected Steps per Second: 21,974.25499
Overall Steps per Second: 10,497.66125

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.76544

Cumulative Model Updates: 216,200
Cumulative Timesteps: 1,803,065,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1803065502...
Checkpoint 1803065502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.65985
Policy Entropy: 2.21487
Value Function Loss: 0.01682

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.53195

Collected Steps per Second: 21,975.17785
Overall Steps per Second: 10,434.00517

Timestep Collection Time: 2.27575
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.79298

Cumulative Model Updates: 216,206
Cumulative Timesteps: 1,803,115,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.77079
Policy Entropy: 2.20591
Value Function Loss: 0.01673

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.53396
Value Function Update Magnitude: 0.52892

Collected Steps per Second: 21,818.24845
Overall Steps per Second: 10,316.97583

Timestep Collection Time: 2.29212
Timestep Consumption Time: 2.55523
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.84735

Cumulative Model Updates: 216,212
Cumulative Timesteps: 1,803,165,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1803165522...
Checkpoint 1803165522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.22743
Policy Entropy: 2.19359
Value Function Loss: 0.01783

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.54314

Collected Steps per Second: 21,503.44057
Overall Steps per Second: 10,405.97474

Timestep Collection Time: 2.32521
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.80493

Cumulative Model Updates: 216,218
Cumulative Timesteps: 1,803,215,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.21527
Policy Entropy: 2.18069
Value Function Loss: 0.01730

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.55281

Collected Steps per Second: 21,901.94098
Overall Steps per Second: 10,536.75350

Timestep Collection Time: 2.28409
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.74776

Cumulative Model Updates: 216,224
Cumulative Timesteps: 1,803,265,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1803265548...
Checkpoint 1803265548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.83695
Policy Entropy: 2.16084
Value Function Loss: 0.01786

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.57071

Collected Steps per Second: 21,527.74780
Overall Steps per Second: 10,217.24454

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.57172
PPO Batch Consumption Time: 0.30307
Total Iteration Time: 4.89486

Cumulative Model Updates: 216,230
Cumulative Timesteps: 1,803,315,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.16135
Policy Entropy: 2.16899
Value Function Loss: 0.01663

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 22,153.53869
Overall Steps per Second: 10,437.48605

Timestep Collection Time: 2.25770
Timestep Consumption Time: 2.53426
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.79196

Cumulative Model Updates: 216,236
Cumulative Timesteps: 1,803,365,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1803365576...
Checkpoint 1803365576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.99858
Policy Entropy: 2.16155
Value Function Loss: 0.01667

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 21,681.49672
Overall Steps per Second: 10,221.37614

Timestep Collection Time: 2.30621
Timestep Consumption Time: 2.58570
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.89190

Cumulative Model Updates: 216,242
Cumulative Timesteps: 1,803,415,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.43474
Policy Entropy: 2.18695
Value Function Loss: 0.01633

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 21,731.80583
Overall Steps per Second: 10,441.94981

Timestep Collection Time: 2.30225
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.79144

Cumulative Model Updates: 216,248
Cumulative Timesteps: 1,803,465,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1803465610...
Checkpoint 1803465610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.81845
Policy Entropy: 2.19740
Value Function Loss: 0.01671

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 21,698.57956
Overall Steps per Second: 10,563.08310

Timestep Collection Time: 2.30430
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.73347

Cumulative Model Updates: 216,254
Cumulative Timesteps: 1,803,515,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.87322
Policy Entropy: 2.17785
Value Function Loss: 0.01706

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 22,019.75624
Overall Steps per Second: 10,469.32478

Timestep Collection Time: 2.27178
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.77815

Cumulative Model Updates: 216,260
Cumulative Timesteps: 1,803,565,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1803565634...
Checkpoint 1803565634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.45370
Policy Entropy: 2.17701
Value Function Loss: 0.01756

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.59209

Collected Steps per Second: 21,876.54408
Overall Steps per Second: 10,264.73229

Timestep Collection Time: 2.28656
Timestep Consumption Time: 2.58663
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 4.87319

Cumulative Model Updates: 216,266
Cumulative Timesteps: 1,803,615,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.00573
Policy Entropy: 2.15250
Value Function Loss: 0.01729

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.61672

Collected Steps per Second: 21,760.72304
Overall Steps per Second: 10,469.40541

Timestep Collection Time: 2.29910
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.77869

Cumulative Model Updates: 216,272
Cumulative Timesteps: 1,803,665,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1803665686...
Checkpoint 1803665686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.61488
Policy Entropy: 2.15518
Value Function Loss: 0.01747

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.61210

Collected Steps per Second: 21,622.76588
Overall Steps per Second: 10,539.04641

Timestep Collection Time: 2.31284
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.74521

Cumulative Model Updates: 216,278
Cumulative Timesteps: 1,803,715,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.79424
Policy Entropy: 2.14463
Value Function Loss: 0.01808

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.59737

Collected Steps per Second: 22,053.24690
Overall Steps per Second: 10,472.38129

Timestep Collection Time: 2.26760
Timestep Consumption Time: 2.50762
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.77523

Cumulative Model Updates: 216,284
Cumulative Timesteps: 1,803,765,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1803765704...
Checkpoint 1803765704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.69826
Policy Entropy: 2.14549
Value Function Loss: 0.01792

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.60191

Collected Steps per Second: 21,905.47504
Overall Steps per Second: 10,287.16093

Timestep Collection Time: 2.28354
Timestep Consumption Time: 2.57903
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.86257

Cumulative Model Updates: 216,290
Cumulative Timesteps: 1,803,815,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.45454
Policy Entropy: 2.16064
Value Function Loss: 0.01801

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.55777
Value Function Update Magnitude: 0.59652

Collected Steps per Second: 21,872.24627
Overall Steps per Second: 10,449.21822

Timestep Collection Time: 2.28747
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.78811

Cumulative Model Updates: 216,296
Cumulative Timesteps: 1,803,865,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1803865758...
Checkpoint 1803865758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.25342
Policy Entropy: 2.15310
Value Function Loss: 0.01770

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.55400
Value Function Update Magnitude: 0.60061

Collected Steps per Second: 21,710.91357
Overall Steps per Second: 10,586.56665

Timestep Collection Time: 2.30382
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.72467

Cumulative Model Updates: 216,302
Cumulative Timesteps: 1,803,915,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.67972
Policy Entropy: 2.17336
Value Function Loss: 0.01769

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.60578

Collected Steps per Second: 21,956.51963
Overall Steps per Second: 10,383.44825

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.53945
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.81786

Cumulative Model Updates: 216,308
Cumulative Timesteps: 1,803,965,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1803965802...
Checkpoint 1803965802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.54740
Policy Entropy: 2.16961
Value Function Loss: 0.01827

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.55089
Value Function Update Magnitude: 0.60900

Collected Steps per Second: 21,659.86203
Overall Steps per Second: 10,320.16642

Timestep Collection Time: 2.30869
Timestep Consumption Time: 2.53677
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.84546

Cumulative Model Updates: 216,314
Cumulative Timesteps: 1,804,015,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.88809
Policy Entropy: 2.16814
Value Function Loss: 0.01874

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.55982
Value Function Update Magnitude: 0.62009

Collected Steps per Second: 21,625.35631
Overall Steps per Second: 10,363.46189

Timestep Collection Time: 2.31229
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.82503

Cumulative Model Updates: 216,320
Cumulative Timesteps: 1,804,065,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1804065812...
Checkpoint 1804065812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.05390
Policy Entropy: 2.16378
Value Function Loss: 0.01841

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.64359

Collected Steps per Second: 21,689.33006
Overall Steps per Second: 10,305.25813

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.54681
PPO Batch Consumption Time: 0.30273
Total Iteration Time: 4.85228

Cumulative Model Updates: 216,326
Cumulative Timesteps: 1,804,115,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.49458
Policy Entropy: 2.17394
Value Function Loss: 0.01707

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.64460

Collected Steps per Second: 21,452.95078
Overall Steps per Second: 10,360.71161

Timestep Collection Time: 2.33133
Timestep Consumption Time: 2.49594
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82727

Cumulative Model Updates: 216,332
Cumulative Timesteps: 1,804,165,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1804165830...
Checkpoint 1804165830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.19230
Policy Entropy: 2.18282
Value Function Loss: 0.01699

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 20,843.25051
Overall Steps per Second: 10,084.20665

Timestep Collection Time: 2.40030
Timestep Consumption Time: 2.56093
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.96122

Cumulative Model Updates: 216,338
Cumulative Timesteps: 1,804,215,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.29479
Policy Entropy: 2.16686
Value Function Loss: 0.01794

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.61801

Collected Steps per Second: 21,921.81220
Overall Steps per Second: 10,355.49583

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.54803
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 4.82932

Cumulative Model Updates: 216,344
Cumulative Timesteps: 1,804,265,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1804265870...
Checkpoint 1804265870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.41639
Policy Entropy: 2.15253
Value Function Loss: 0.01729

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.63092

Collected Steps per Second: 21,685.71543
Overall Steps per Second: 10,564.18442

Timestep Collection Time: 2.30696
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.73562

Cumulative Model Updates: 216,350
Cumulative Timesteps: 1,804,315,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.84349
Policy Entropy: 2.15864
Value Function Loss: 0.01692

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 22,015.54104
Overall Steps per Second: 10,465.74927

Timestep Collection Time: 2.27249
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.78036

Cumulative Model Updates: 216,356
Cumulative Timesteps: 1,804,365,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1804365928...
Checkpoint 1804365928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.79167
Policy Entropy: 2.17140
Value Function Loss: 0.01685

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.67422

Collected Steps per Second: 21,378.17507
Overall Steps per Second: 10,205.24716

Timestep Collection Time: 2.33958
Timestep Consumption Time: 2.56143
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.90101

Cumulative Model Updates: 216,362
Cumulative Timesteps: 1,804,415,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.38275
Policy Entropy: 2.18726
Value Function Loss: 0.01724

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.68699

Collected Steps per Second: 21,620.70391
Overall Steps per Second: 10,384.03599

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.81720

Cumulative Model Updates: 216,368
Cumulative Timesteps: 1,804,465,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1804465966...
Checkpoint 1804465966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.43240
Policy Entropy: 2.14551
Value Function Loss: 0.01775

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.56088
Value Function Update Magnitude: 0.68859

Collected Steps per Second: 21,845.41771
Overall Steps per Second: 10,629.55610

Timestep Collection Time: 2.29000
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70631

Cumulative Model Updates: 216,374
Cumulative Timesteps: 1,804,515,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.06087
Policy Entropy: 2.15851
Value Function Loss: 0.01753

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.67967

Collected Steps per Second: 21,991.42671
Overall Steps per Second: 10,423.38809

Timestep Collection Time: 2.27425
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.79825

Cumulative Model Updates: 216,380
Cumulative Timesteps: 1,804,566,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1804566006...
Checkpoint 1804566006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.27744
Policy Entropy: 2.15439
Value Function Loss: 0.01734

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 21,879.88394
Overall Steps per Second: 10,327.28898

Timestep Collection Time: 2.28658
Timestep Consumption Time: 2.55787
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.84445

Cumulative Model Updates: 216,386
Cumulative Timesteps: 1,804,616,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.16057
Policy Entropy: 2.18893
Value Function Loss: 0.01770

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.63141

Collected Steps per Second: 21,444.52513
Overall Steps per Second: 10,330.41803

Timestep Collection Time: 2.33197
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.84085

Cumulative Model Updates: 216,392
Cumulative Timesteps: 1,804,666,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1804666044...
Checkpoint 1804666044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.31470
Policy Entropy: 2.19527
Value Function Loss: 0.01855

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 21,950.37733
Overall Steps per Second: 10,456.22179

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.78222

Cumulative Model Updates: 216,398
Cumulative Timesteps: 1,804,716,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.51733
Policy Entropy: 2.20115
Value Function Loss: 0.01820

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.60429

Collected Steps per Second: 21,915.23908
Overall Steps per Second: 10,336.49441

Timestep Collection Time: 2.28252
Timestep Consumption Time: 2.55684
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.83936

Cumulative Model Updates: 216,404
Cumulative Timesteps: 1,804,766,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1804766070...
Checkpoint 1804766070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.14219
Policy Entropy: 2.18995
Value Function Loss: 0.01748

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.52908
Value Function Update Magnitude: 0.57533

Collected Steps per Second: 21,566.78233
Overall Steps per Second: 10,191.59693

Timestep Collection Time: 2.31931
Timestep Consumption Time: 2.58866
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 4.90796

Cumulative Model Updates: 216,410
Cumulative Timesteps: 1,804,816,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.01267
Policy Entropy: 2.19939
Value Function Loss: 0.01605

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.51033
Value Function Update Magnitude: 0.54076

Collected Steps per Second: 21,641.42346
Overall Steps per Second: 10,377.14524

Timestep Collection Time: 2.31177
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.82117

Cumulative Model Updates: 216,416
Cumulative Timesteps: 1,804,866,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1804866120...
Checkpoint 1804866120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.33394
Policy Entropy: 2.17872
Value Function Loss: 0.01712

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.51896
Value Function Update Magnitude: 0.57176

Collected Steps per Second: 21,901.60030
Overall Steps per Second: 10,516.56305

Timestep Collection Time: 2.28449
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.75764

Cumulative Model Updates: 216,422
Cumulative Timesteps: 1,804,916,154

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.40031
Policy Entropy: 2.18071
Value Function Loss: 0.01718

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.53014
Value Function Update Magnitude: 0.60011

Collected Steps per Second: 21,813.28313
Overall Steps per Second: 10,242.69335

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.59028
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.88329

Cumulative Model Updates: 216,428
Cumulative Timesteps: 1,804,966,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1804966172...
Checkpoint 1804966172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.65084
Policy Entropy: 2.15705
Value Function Loss: 0.01733

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.53198
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 21,457.17683
Overall Steps per Second: 10,234.53404

Timestep Collection Time: 2.33153
Timestep Consumption Time: 2.55663
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.88816

Cumulative Model Updates: 216,434
Cumulative Timesteps: 1,805,016,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.59505
Policy Entropy: 2.19247
Value Function Loss: 0.01697

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.62405

Collected Steps per Second: 21,632.77525
Overall Steps per Second: 10,371.50266

Timestep Collection Time: 2.31131
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82090

Cumulative Model Updates: 216,440
Cumulative Timesteps: 1,805,066,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1805066200...
Checkpoint 1805066200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.96213
Policy Entropy: 2.22370
Value Function Loss: 0.01705

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.63383

Collected Steps per Second: 21,781.60535
Overall Steps per Second: 10,518.33443

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.45848
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.75436

Cumulative Model Updates: 216,446
Cumulative Timesteps: 1,805,116,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.31323
Policy Entropy: 2.24527
Value Function Loss: 0.01759

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.63587

Collected Steps per Second: 22,001.95628
Overall Steps per Second: 10,289.49704

Timestep Collection Time: 2.27289
Timestep Consumption Time: 2.58721
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 4.86010

Cumulative Model Updates: 216,452
Cumulative Timesteps: 1,805,166,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1805166216...
Checkpoint 1805166216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.27167
Policy Entropy: 2.23027
Value Function Loss: 0.01899

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 21,508.85976
Overall Steps per Second: 10,156.02521

Timestep Collection Time: 2.32500
Timestep Consumption Time: 2.59898
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.92397

Cumulative Model Updates: 216,458
Cumulative Timesteps: 1,805,216,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.93141
Policy Entropy: 2.22105
Value Function Loss: 0.01903

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.62491

Collected Steps per Second: 21,509.91185
Overall Steps per Second: 10,366.45048

Timestep Collection Time: 2.32479
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.82383

Cumulative Model Updates: 216,464
Cumulative Timesteps: 1,805,266,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1805266230...
Checkpoint 1805266230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.94431
Policy Entropy: 2.19478
Value Function Loss: 0.01870

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.64073

Collected Steps per Second: 21,488.43883
Overall Steps per Second: 10,376.28239

Timestep Collection Time: 2.32683
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 4.81868

Cumulative Model Updates: 216,470
Cumulative Timesteps: 1,805,316,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.32022
Policy Entropy: 2.16950
Value Function Loss: 0.01742

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.63603

Collected Steps per Second: 22,177.33944
Overall Steps per Second: 10,370.85833

Timestep Collection Time: 2.25546
Timestep Consumption Time: 2.56767
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.82313

Cumulative Model Updates: 216,476
Cumulative Timesteps: 1,805,366,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1805366250...
Checkpoint 1805366250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.54890
Policy Entropy: 2.15008
Value Function Loss: 0.01733

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.54128
Value Function Update Magnitude: 0.62056

Collected Steps per Second: 21,443.98198
Overall Steps per Second: 10,203.49594

Timestep Collection Time: 2.33194
Timestep Consumption Time: 2.56893
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.90087

Cumulative Model Updates: 216,482
Cumulative Timesteps: 1,805,416,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.74460
Policy Entropy: 2.15557
Value Function Loss: 0.01730

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.60805

Collected Steps per Second: 21,998.63085
Overall Steps per Second: 10,502.79066

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.76292

Cumulative Model Updates: 216,488
Cumulative Timesteps: 1,805,466,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1805466280...
Checkpoint 1805466280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.34489
Policy Entropy: 2.14976
Value Function Loss: 0.01672

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.53731
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 21,535.41758
Overall Steps per Second: 10,505.77317

Timestep Collection Time: 2.32269
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.76119

Cumulative Model Updates: 216,494
Cumulative Timesteps: 1,805,516,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.94757
Policy Entropy: 2.17483
Value Function Loss: 0.01634

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.52631
Value Function Update Magnitude: 0.59898

Collected Steps per Second: 22,267.71512
Overall Steps per Second: 10,466.35240

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.53272
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.77893

Cumulative Model Updates: 216,500
Cumulative Timesteps: 1,805,566,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1805566318...
Checkpoint 1805566318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.81179
Policy Entropy: 2.17642
Value Function Loss: 0.01629

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.58519

Collected Steps per Second: 21,479.26635
Overall Steps per Second: 10,296.16844

Timestep Collection Time: 2.32820
Timestep Consumption Time: 2.52875
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.85695

Cumulative Model Updates: 216,506
Cumulative Timesteps: 1,805,616,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.37846
Policy Entropy: 2.17785
Value Function Loss: 0.01647

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.53366
Value Function Update Magnitude: 0.59216

Collected Steps per Second: 21,758.25393
Overall Steps per Second: 10,431.57487

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.79602

Cumulative Model Updates: 216,512
Cumulative Timesteps: 1,805,666,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1805666356...
Checkpoint 1805666356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.91231
Policy Entropy: 2.17374
Value Function Loss: 0.01724

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.53755
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 21,626.45989
Overall Steps per Second: 10,224.11692

Timestep Collection Time: 2.31309
Timestep Consumption Time: 2.57965
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.89275

Cumulative Model Updates: 216,518
Cumulative Timesteps: 1,805,716,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.90216
Policy Entropy: 2.15288
Value Function Loss: 0.01737

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.59216

Collected Steps per Second: 21,734.33473
Overall Steps per Second: 10,354.77376

Timestep Collection Time: 2.30143
Timestep Consumption Time: 2.52919
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.83062

Cumulative Model Updates: 216,524
Cumulative Timesteps: 1,805,766,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1805766400...
Checkpoint 1805766400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.94040
Policy Entropy: 2.14961
Value Function Loss: 0.01801

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 21,607.64545
Overall Steps per Second: 10,353.67995

Timestep Collection Time: 2.31529
Timestep Consumption Time: 2.51661
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.83191

Cumulative Model Updates: 216,530
Cumulative Timesteps: 1,805,816,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.58915
Policy Entropy: 2.13352
Value Function Loss: 0.01806

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.58861

Collected Steps per Second: 21,748.07204
Overall Steps per Second: 10,432.22852

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.79572

Cumulative Model Updates: 216,536
Cumulative Timesteps: 1,805,866,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1805866458...
Checkpoint 1805866458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.51963
Policy Entropy: 2.14668
Value Function Loss: 0.01833

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.59554

Collected Steps per Second: 21,519.15014
Overall Steps per Second: 10,401.53743

Timestep Collection Time: 2.32481
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.80967

Cumulative Model Updates: 216,542
Cumulative Timesteps: 1,805,916,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.06773
Policy Entropy: 2.14553
Value Function Loss: 0.01814

Mean KL Divergence: 0.02993
SB3 Clip Fraction: 0.18844
Policy Update Magnitude: 0.51450
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 22,082.39327
Overall Steps per Second: 10,247.92720

Timestep Collection Time: 2.26434
Timestep Consumption Time: 2.61489
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 4.87923

Cumulative Model Updates: 216,548
Cumulative Timesteps: 1,805,966,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1805966488...
Checkpoint 1805966488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.86039
Policy Entropy: 2.13142
Value Function Loss: 0.01810

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.17498
Policy Update Magnitude: 0.51831
Value Function Update Magnitude: 0.60922

Collected Steps per Second: 21,390.46945
Overall Steps per Second: 10,230.21229

Timestep Collection Time: 2.33871
Timestep Consumption Time: 2.55132
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.89003

Cumulative Model Updates: 216,554
Cumulative Timesteps: 1,806,016,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.11887
Policy Entropy: 2.16217
Value Function Loss: 0.01848

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.16741
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.63045

Collected Steps per Second: 21,933.38015
Overall Steps per Second: 10,351.56395

Timestep Collection Time: 2.28082
Timestep Consumption Time: 2.55188
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.83270

Cumulative Model Updates: 216,560
Cumulative Timesteps: 1,806,066,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1806066540...
Checkpoint 1806066540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.41415
Policy Entropy: 2.15157
Value Function Loss: 0.01760

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.16965
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.63263

Collected Steps per Second: 21,864.64974
Overall Steps per Second: 10,429.75933

Timestep Collection Time: 2.28808
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 4.79666

Cumulative Model Updates: 216,566
Cumulative Timesteps: 1,806,116,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.19530
Policy Entropy: 2.16281
Value Function Loss: 0.01728

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.60850

Collected Steps per Second: 22,128.35232
Overall Steps per Second: 10,351.31878

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.57158
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.83185

Cumulative Model Updates: 216,572
Cumulative Timesteps: 1,806,166,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1806166584...
Checkpoint 1806166584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.14455
Policy Entropy: 2.14391
Value Function Loss: 0.01681

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.54846
Value Function Update Magnitude: 0.57594

Collected Steps per Second: 21,289.03172
Overall Steps per Second: 10,183.78681

Timestep Collection Time: 2.34957
Timestep Consumption Time: 2.56216
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.91173

Cumulative Model Updates: 216,578
Cumulative Timesteps: 1,806,216,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.66831
Policy Entropy: 2.16258
Value Function Loss: 0.01774

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.54942
Value Function Update Magnitude: 0.56550

Collected Steps per Second: 21,850.11372
Overall Steps per Second: 10,421.14377

Timestep Collection Time: 2.28969
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.80082

Cumulative Model Updates: 216,584
Cumulative Timesteps: 1,806,266,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1806266634...
Checkpoint 1806266634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.40078
Policy Entropy: 2.15891
Value Function Loss: 0.01803

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.57776

Collected Steps per Second: 21,624.66438
Overall Steps per Second: 10,452.21847

Timestep Collection Time: 2.31227
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.78386

Cumulative Model Updates: 216,590
Cumulative Timesteps: 1,806,316,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.30337
Policy Entropy: 2.19228
Value Function Loss: 0.01809

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.61467

Collected Steps per Second: 21,889.21688
Overall Steps per Second: 10,282.51576

Timestep Collection Time: 2.28551
Timestep Consumption Time: 2.57984
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.86535

Cumulative Model Updates: 216,596
Cumulative Timesteps: 1,806,366,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1806366664...
Checkpoint 1806366664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.67922
Policy Entropy: 2.18629
Value Function Loss: 0.01730

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.60543

Collected Steps per Second: 21,643.21740
Overall Steps per Second: 10,157.31943

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.61278
PPO Batch Consumption Time: 0.30660
Total Iteration Time: 4.92335

Cumulative Model Updates: 216,602
Cumulative Timesteps: 1,806,416,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.69640
Policy Entropy: 2.22357
Value Function Loss: 0.01648

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.52633
Value Function Update Magnitude: 0.58302

Collected Steps per Second: 21,510.35445
Overall Steps per Second: 10,274.10381

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.54275
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.86777

Cumulative Model Updates: 216,608
Cumulative Timesteps: 1,806,466,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1806466684...
Checkpoint 1806466684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.51771
Policy Entropy: 2.18117
Value Function Loss: 0.01643

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.57487

Collected Steps per Second: 21,770.65973
Overall Steps per Second: 10,445.94579

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.78903

Cumulative Model Updates: 216,614
Cumulative Timesteps: 1,806,516,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.79538
Policy Entropy: 2.18717
Value Function Loss: 0.01614

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.56413

Collected Steps per Second: 21,766.53106
Overall Steps per Second: 10,373.01375

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.52542
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.82463

Cumulative Model Updates: 216,620
Cumulative Timesteps: 1,806,566,756

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1806566756...
Checkpoint 1806566756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.02421
Policy Entropy: 2.13779
Value Function Loss: 0.01808

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.57392

Collected Steps per Second: 21,775.11257
Overall Steps per Second: 10,318.08429

Timestep Collection Time: 2.29758
Timestep Consumption Time: 2.55119
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.84877

Cumulative Model Updates: 216,626
Cumulative Timesteps: 1,806,616,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.59641
Policy Entropy: 2.16251
Value Function Loss: 0.01897

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.59686

Collected Steps per Second: 21,456.76254
Overall Steps per Second: 10,327.31087

Timestep Collection Time: 2.33055
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.84211

Cumulative Model Updates: 216,632
Cumulative Timesteps: 1,806,666,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1806666792...
Checkpoint 1806666792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.35126
Policy Entropy: 2.16580
Value Function Loss: 0.01888

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.61301

Collected Steps per Second: 21,941.41231
Overall Steps per Second: 10,500.74708

Timestep Collection Time: 2.27971
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.76347

Cumulative Model Updates: 216,638
Cumulative Timesteps: 1,806,716,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.49927
Policy Entropy: 2.16963
Value Function Loss: 0.01740

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.62588

Collected Steps per Second: 21,854.78792
Overall Steps per Second: 10,282.74802

Timestep Collection Time: 2.28856
Timestep Consumption Time: 2.57551
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.86407

Cumulative Model Updates: 216,644
Cumulative Timesteps: 1,806,766,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1806766828...
Checkpoint 1806766828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.56299
Policy Entropy: 2.15035
Value Function Loss: 0.01643

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.62443

Collected Steps per Second: 21,693.42147
Overall Steps per Second: 10,207.49375

Timestep Collection Time: 2.30632
Timestep Consumption Time: 2.59518
PPO Batch Consumption Time: 0.30303
Total Iteration Time: 4.90150

Cumulative Model Updates: 216,650
Cumulative Timesteps: 1,806,816,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.99157
Policy Entropy: 2.12842
Value Function Loss: 0.01698

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 21,960.66199
Overall Steps per Second: 10,379.84130

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.54094
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.81838

Cumulative Model Updates: 216,656
Cumulative Timesteps: 1,806,866,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1806866874...
Checkpoint 1806866874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.58141
Policy Entropy: 2.12354
Value Function Loss: 0.01742

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.63525

Collected Steps per Second: 21,870.42690
Overall Steps per Second: 10,280.39265

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.57867
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.86596

Cumulative Model Updates: 216,662
Cumulative Timesteps: 1,806,916,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.49947
Policy Entropy: 2.13109
Value Function Loss: 0.01912

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.63532

Collected Steps per Second: 21,610.07128
Overall Steps per Second: 10,466.45268

Timestep Collection Time: 2.31466
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.77908

Cumulative Model Updates: 216,668
Cumulative Timesteps: 1,806,966,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1806966918...
Checkpoint 1806966918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.29643
Policy Entropy: 2.15739
Value Function Loss: 0.01934

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.64618

Collected Steps per Second: 21,723.83430
Overall Steps per Second: 10,206.35726

Timestep Collection Time: 2.30180
Timestep Consumption Time: 2.59750
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.89930

Cumulative Model Updates: 216,674
Cumulative Timesteps: 1,807,016,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.22126
Policy Entropy: 2.16721
Value Function Loss: 0.01936

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.66510

Collected Steps per Second: 21,682.60313
Overall Steps per Second: 10,224.07398

Timestep Collection Time: 2.30627
Timestep Consumption Time: 2.58473
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.89101

Cumulative Model Updates: 216,680
Cumulative Timesteps: 1,807,066,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1807066928...
Checkpoint 1807066928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.41359
Policy Entropy: 2.15033
Value Function Loss: 0.01818

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.66412

Collected Steps per Second: 21,719.04293
Overall Steps per Second: 10,431.10726

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.79623

Cumulative Model Updates: 216,686
Cumulative Timesteps: 1,807,116,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.71235
Policy Entropy: 2.13643
Value Function Loss: 0.01822

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.65135

Collected Steps per Second: 21,862.19620
Overall Steps per Second: 10,395.88457

Timestep Collection Time: 2.28724
Timestep Consumption Time: 2.52274
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.80998

Cumulative Model Updates: 216,692
Cumulative Timesteps: 1,807,166,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1807166962...
Checkpoint 1807166962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.66570
Policy Entropy: 2.11717
Value Function Loss: 0.01796

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.65772

Collected Steps per Second: 21,761.65429
Overall Steps per Second: 10,290.69400

Timestep Collection Time: 2.29872
Timestep Consumption Time: 2.56237
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 4.86109

Cumulative Model Updates: 216,698
Cumulative Timesteps: 1,807,216,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.75475
Policy Entropy: 2.14997
Value Function Loss: 0.01899

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.65846

Collected Steps per Second: 21,543.08250
Overall Steps per Second: 10,302.85258

Timestep Collection Time: 2.32186
Timestep Consumption Time: 2.53311
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.85497

Cumulative Model Updates: 216,704
Cumulative Timesteps: 1,807,267,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1807267006...
Checkpoint 1807267006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.29834
Policy Entropy: 2.15858
Value Function Loss: 0.01864

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.16128
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 21,856.80584
Overall Steps per Second: 10,460.62124

Timestep Collection Time: 2.28817
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 4.78098

Cumulative Model Updates: 216,710
Cumulative Timesteps: 1,807,317,018

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.95344
Policy Entropy: 2.16948
Value Function Loss: 0.01839

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.49229
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 21,809.33117
Overall Steps per Second: 10,386.17396

Timestep Collection Time: 2.29333
Timestep Consumption Time: 2.52230
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.81563

Cumulative Model Updates: 216,716
Cumulative Timesteps: 1,807,367,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1807367034...
Checkpoint 1807367034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.54789
Policy Entropy: 2.17368
Value Function Loss: 0.01763

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.50228
Value Function Update Magnitude: 0.58026

Collected Steps per Second: 21,710.36953
Overall Steps per Second: 10,237.52990

Timestep Collection Time: 2.30332
Timestep Consumption Time: 2.58125
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 4.88458

Cumulative Model Updates: 216,722
Cumulative Timesteps: 1,807,417,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.74420
Policy Entropy: 2.16590
Value Function Loss: 0.01762

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.57369

Collected Steps per Second: 21,780.08964
Overall Steps per Second: 10,396.71503

Timestep Collection Time: 2.29613
Timestep Consumption Time: 2.51404
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.81017

Cumulative Model Updates: 216,728
Cumulative Timesteps: 1,807,467,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1807467050...
Checkpoint 1807467050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.50708
Policy Entropy: 2.15289
Value Function Loss: 0.01879

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.57674

Collected Steps per Second: 21,684.27795
Overall Steps per Second: 10,534.58734

Timestep Collection Time: 2.30674
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74817

Cumulative Model Updates: 216,734
Cumulative Timesteps: 1,807,517,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.35110
Policy Entropy: 2.16497
Value Function Loss: 0.01852

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.57674

Collected Steps per Second: 22,036.12937
Overall Steps per Second: 10,369.34033

Timestep Collection Time: 2.27018
Timestep Consumption Time: 2.55423
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.82441

Cumulative Model Updates: 216,740
Cumulative Timesteps: 1,807,567,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1807567096...
Checkpoint 1807567096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.35128
Policy Entropy: 2.18273
Value Function Loss: 0.01770

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.57507

Collected Steps per Second: 21,962.48730
Overall Steps per Second: 10,352.93971

Timestep Collection Time: 2.27679
Timestep Consumption Time: 2.55314
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.82993

Cumulative Model Updates: 216,746
Cumulative Timesteps: 1,807,617,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.47185
Policy Entropy: 2.15840
Value Function Loss: 0.01636

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.55486

Collected Steps per Second: 20,523.22237
Overall Steps per Second: 10,067.13631

Timestep Collection Time: 2.43743
Timestep Consumption Time: 2.53161
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.96904

Cumulative Model Updates: 216,752
Cumulative Timesteps: 1,807,667,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1807667124...
Checkpoint 1807667124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.64910
Policy Entropy: 2.13765
Value Function Loss: 0.01563

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.53475

Collected Steps per Second: 21,508.78994
Overall Steps per Second: 10,218.80056

Timestep Collection Time: 2.32593
Timestep Consumption Time: 2.56975
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 4.89568

Cumulative Model Updates: 216,758
Cumulative Timesteps: 1,807,717,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.14814
Policy Entropy: 2.11606
Value Function Loss: 0.01755

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.17957
Policy Update Magnitude: 0.51064
Value Function Update Magnitude: 0.54918

Collected Steps per Second: 21,475.66117
Overall Steps per Second: 10,504.02793

Timestep Collection Time: 2.33008
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.76389

Cumulative Model Updates: 216,764
Cumulative Timesteps: 1,807,767,192

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1807767192...
Checkpoint 1807767192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.53334
Policy Entropy: 2.16187
Value Function Loss: 0.01766

Mean KL Divergence: 0.02599
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.50726
Value Function Update Magnitude: 0.56278

Collected Steps per Second: 21,482.10470
Overall Steps per Second: 10,188.05127

Timestep Collection Time: 2.32985
Timestep Consumption Time: 2.58277
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.91262

Cumulative Model Updates: 216,770
Cumulative Timesteps: 1,807,817,242

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.61431
Policy Entropy: 2.15498
Value Function Loss: 0.01841

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.16129
Policy Update Magnitude: 0.53309
Value Function Update Magnitude: 0.55439

Collected Steps per Second: 21,232.65048
Overall Steps per Second: 10,110.33101

Timestep Collection Time: 2.35486
Timestep Consumption Time: 2.59057
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 4.94544

Cumulative Model Updates: 216,776
Cumulative Timesteps: 1,807,867,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1807867242...
Checkpoint 1807867242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.98833
Policy Entropy: 2.17098
Value Function Loss: 0.01811

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.54995

Collected Steps per Second: 21,422.84503
Overall Steps per Second: 10,189.66467

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.57308
PPO Batch Consumption Time: 0.30499
Total Iteration Time: 4.90713

Cumulative Model Updates: 216,782
Cumulative Timesteps: 1,807,917,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.07206
Policy Entropy: 2.16788
Value Function Loss: 0.01806

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.55592

Collected Steps per Second: 21,668.19914
Overall Steps per Second: 10,438.59422

Timestep Collection Time: 2.30771
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.79030

Cumulative Model Updates: 216,788
Cumulative Timesteps: 1,807,967,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1807967248...
Checkpoint 1807967248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.58362
Policy Entropy: 2.18315
Value Function Loss: 0.01832

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.54353
Value Function Update Magnitude: 0.58460

Collected Steps per Second: 21,481.63959
Overall Steps per Second: 10,201.64348

Timestep Collection Time: 2.32841
Timestep Consumption Time: 2.57453
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 4.90294

Cumulative Model Updates: 216,794
Cumulative Timesteps: 1,808,017,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.00734
Policy Entropy: 2.17761
Value Function Loss: 0.01819

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 21,626.81175
Overall Steps per Second: 10,320.05203

Timestep Collection Time: 2.31250
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.84610

Cumulative Model Updates: 216,800
Cumulative Timesteps: 1,808,067,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1808067278...
Checkpoint 1808067278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.72503
Policy Entropy: 2.15044
Value Function Loss: 0.01813

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.63387

Collected Steps per Second: 21,691.24436
Overall Steps per Second: 10,321.33817

Timestep Collection Time: 2.30711
Timestep Consumption Time: 2.54149
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.84860

Cumulative Model Updates: 216,806
Cumulative Timesteps: 1,808,117,322

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.32871
Policy Entropy: 2.13597
Value Function Loss: 0.01856

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.60240

Collected Steps per Second: 22,400.44566
Overall Steps per Second: 10,491.34868

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.53404
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.76640

Cumulative Model Updates: 216,812
Cumulative Timesteps: 1,808,167,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1808167328...
Checkpoint 1808167328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.01367
Policy Entropy: 2.11109
Value Function Loss: 0.01898

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.59854

Collected Steps per Second: 21,578.42406
Overall Steps per Second: 10,200.98751

Timestep Collection Time: 2.31815
Timestep Consumption Time: 2.58549
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.90364

Cumulative Model Updates: 216,818
Cumulative Timesteps: 1,808,217,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.99319
Policy Entropy: 2.14567
Value Function Loss: 0.01782

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.61370

Collected Steps per Second: 21,824.73224
Overall Steps per Second: 10,375.40302

Timestep Collection Time: 2.29226
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.82179

Cumulative Model Updates: 216,824
Cumulative Timesteps: 1,808,267,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1808267378...
Checkpoint 1808267378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.67380
Policy Entropy: 2.13281
Value Function Loss: 0.01702

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 21,487.07056
Overall Steps per Second: 10,369.73518

Timestep Collection Time: 2.32819
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.30243
Total Iteration Time: 4.82423

Cumulative Model Updates: 216,830
Cumulative Timesteps: 1,808,317,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.70984
Policy Entropy: 2.13715
Value Function Loss: 0.01785

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.55489
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 21,974.50704
Overall Steps per Second: 10,411.14315

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.80389

Cumulative Model Updates: 216,836
Cumulative Timesteps: 1,808,367,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1808367418...
Checkpoint 1808367418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.96774
Policy Entropy: 2.09484
Value Function Loss: 0.01828

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 21,607.99636
Overall Steps per Second: 10,192.99931

Timestep Collection Time: 2.31525
Timestep Consumption Time: 2.59282
PPO Batch Consumption Time: 0.30485
Total Iteration Time: 4.90807

Cumulative Model Updates: 216,842
Cumulative Timesteps: 1,808,417,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.72023
Policy Entropy: 2.10357
Value Function Loss: 0.01790

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.61138

Collected Steps per Second: 22,019.55934
Overall Steps per Second: 10,384.93744

Timestep Collection Time: 2.27207
Timestep Consumption Time: 2.54548
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.81755

Cumulative Model Updates: 216,848
Cumulative Timesteps: 1,808,467,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1808467476...
Checkpoint 1808467476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.12540
Policy Entropy: 2.12870
Value Function Loss: 0.01761

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.58148

Collected Steps per Second: 21,557.75972
Overall Steps per Second: 10,261.88798

Timestep Collection Time: 2.32065
Timestep Consumption Time: 2.55448
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.87513

Cumulative Model Updates: 216,854
Cumulative Timesteps: 1,808,517,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.53849
Policy Entropy: 2.15245
Value Function Loss: 0.01719

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.56992

Collected Steps per Second: 21,970.11690
Overall Steps per Second: 10,462.16107

Timestep Collection Time: 2.27618
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.77989

Cumulative Model Updates: 216,860
Cumulative Timesteps: 1,808,567,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1808567512...
Checkpoint 1808567512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.56356
Policy Entropy: 2.15998
Value Function Loss: 0.01802

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.58376

Collected Steps per Second: 21,626.89769
Overall Steps per Second: 10,208.48614

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.58616
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 4.89828

Cumulative Model Updates: 216,866
Cumulative Timesteps: 1,808,617,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.70714
Policy Entropy: 2.16841
Value Function Loss: 0.01830

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.16254
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.59038

Collected Steps per Second: 21,949.22513
Overall Steps per Second: 10,378.82698

Timestep Collection Time: 2.27871
Timestep Consumption Time: 2.54033
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.81904

Cumulative Model Updates: 216,872
Cumulative Timesteps: 1,808,667,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1808667532...
Checkpoint 1808667532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.75172
Policy Entropy: 2.14036
Value Function Loss: 0.01878

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.55473
Value Function Update Magnitude: 0.59641

Collected Steps per Second: 21,302.04876
Overall Steps per Second: 10,286.83764

Timestep Collection Time: 2.34776
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.30533
Total Iteration Time: 4.86175

Cumulative Model Updates: 216,878
Cumulative Timesteps: 1,808,717,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.78009
Policy Entropy: 2.14425
Value Function Loss: 0.01931

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.59493

Collected Steps per Second: 22,114.47694
Overall Steps per Second: 10,457.55044

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.78391

Cumulative Model Updates: 216,884
Cumulative Timesteps: 1,808,767,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1808767572...
Checkpoint 1808767572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.76116
Policy Entropy: 2.12600
Value Function Loss: 0.01913

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 21,444.22335
Overall Steps per Second: 10,207.01604

Timestep Collection Time: 2.33312
Timestep Consumption Time: 2.56860
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.90173

Cumulative Model Updates: 216,890
Cumulative Timesteps: 1,808,817,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.17152
Policy Entropy: 2.15457
Value Function Loss: 0.01900

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 21,768.99885
Overall Steps per Second: 10,428.24141

Timestep Collection Time: 2.29740
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.79582

Cumulative Model Updates: 216,896
Cumulative Timesteps: 1,808,867,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1808867616...
Checkpoint 1808867616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.89180
Policy Entropy: 2.16878
Value Function Loss: 0.01898

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.60432

Collected Steps per Second: 21,706.31172
Overall Steps per Second: 10,549.52230

Timestep Collection Time: 2.30449
Timestep Consumption Time: 2.43715
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74164

Cumulative Model Updates: 216,902
Cumulative Timesteps: 1,808,917,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.12981
Policy Entropy: 2.18105
Value Function Loss: 0.01870

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 22,259.31465
Overall Steps per Second: 10,460.48432

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.78008

Cumulative Model Updates: 216,908
Cumulative Timesteps: 1,808,967,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1808967640...
Checkpoint 1808967640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.17185
Policy Entropy: 2.14373
Value Function Loss: 0.01880

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.58480

Collected Steps per Second: 21,741.26092
Overall Steps per Second: 10,334.97628

Timestep Collection Time: 2.30097
Timestep Consumption Time: 2.53949
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.84046

Cumulative Model Updates: 216,914
Cumulative Timesteps: 1,809,017,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.95276
Policy Entropy: 2.14999
Value Function Loss: 0.01831

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 21,615.28451
Overall Steps per Second: 10,365.83207

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.82373

Cumulative Model Updates: 216,920
Cumulative Timesteps: 1,809,067,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1809067668...
Checkpoint 1809067668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.34150
Policy Entropy: 2.13959
Value Function Loss: 0.01869

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.59828

Collected Steps per Second: 21,600.53567
Overall Steps per Second: 10,409.59038

Timestep Collection Time: 2.31485
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.80346

Cumulative Model Updates: 216,926
Cumulative Timesteps: 1,809,117,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.28643
Policy Entropy: 2.15987
Value Function Loss: 0.01922

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.56088
Value Function Update Magnitude: 0.61528

Collected Steps per Second: 22,006.80573
Overall Steps per Second: 10,343.13188

Timestep Collection Time: 2.27212
Timestep Consumption Time: 2.56220
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.83432

Cumulative Model Updates: 216,932
Cumulative Timesteps: 1,809,167,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1809167672...
Checkpoint 1809167672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.90416
Policy Entropy: 2.12903
Value Function Loss: 0.01899

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 21,460.86368
Overall Steps per Second: 10,205.15304

Timestep Collection Time: 2.33057
Timestep Consumption Time: 2.57049
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.90105

Cumulative Model Updates: 216,938
Cumulative Timesteps: 1,809,217,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.61198
Policy Entropy: 2.13940
Value Function Loss: 0.01928

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.62899

Collected Steps per Second: 21,762.19287
Overall Steps per Second: 10,388.11217

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.51644
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.81473

Cumulative Model Updates: 216,944
Cumulative Timesteps: 1,809,267,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1809267704...
Checkpoint 1809267704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.63600
Policy Entropy: 2.11685
Value Function Loss: 0.01997

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.64390

Collected Steps per Second: 21,265.77821
Overall Steps per Second: 10,291.88709

Timestep Collection Time: 2.35138
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.85858

Cumulative Model Updates: 216,950
Cumulative Timesteps: 1,809,317,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.39876
Policy Entropy: 2.10473
Value Function Loss: 0.01861

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.63098

Collected Steps per Second: 21,755.14881
Overall Steps per Second: 10,345.10544

Timestep Collection Time: 2.29858
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.83378

Cumulative Model Updates: 216,956
Cumulative Timesteps: 1,809,367,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1809367714...
Checkpoint 1809367714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.12661
Policy Entropy: 2.10392
Value Function Loss: 0.01776

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.55406
Value Function Update Magnitude: 0.59815

Collected Steps per Second: 21,765.13675
Overall Steps per Second: 10,297.94374

Timestep Collection Time: 2.29835
Timestep Consumption Time: 2.55931
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.85767

Cumulative Model Updates: 216,962
Cumulative Timesteps: 1,809,417,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.82360
Policy Entropy: 2.11501
Value Function Loss: 0.01746

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.57351

Collected Steps per Second: 21,811.53769
Overall Steps per Second: 10,456.20920

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.78338

Cumulative Model Updates: 216,968
Cumulative Timesteps: 1,809,467,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1809467754...
Checkpoint 1809467754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.15997
Policy Entropy: 2.13831
Value Function Loss: 0.01686

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 21,721.02539
Overall Steps per Second: 10,210.39980

Timestep Collection Time: 2.30275
Timestep Consumption Time: 2.59598
PPO Batch Consumption Time: 0.30430
Total Iteration Time: 4.89873

Cumulative Model Updates: 216,974
Cumulative Timesteps: 1,809,517,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.69017
Policy Entropy: 2.13383
Value Function Loss: 0.01761

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.53642

Collected Steps per Second: 21,636.93675
Overall Steps per Second: 10,341.07561

Timestep Collection Time: 2.31151
Timestep Consumption Time: 2.52493
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.83644

Cumulative Model Updates: 216,980
Cumulative Timesteps: 1,809,567,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1809567786...
Checkpoint 1809567786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.37088
Policy Entropy: 2.13509
Value Function Loss: 0.01659

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.55900

Collected Steps per Second: 21,582.27148
Overall Steps per Second: 10,333.27594

Timestep Collection Time: 2.31699
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.83932

Cumulative Model Updates: 216,986
Cumulative Timesteps: 1,809,617,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.52302
Policy Entropy: 2.11434
Value Function Loss: 0.01722

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 21,672.51083
Overall Steps per Second: 10,365.95034

Timestep Collection Time: 2.30772
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.82483

Cumulative Model Updates: 216,992
Cumulative Timesteps: 1,809,667,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1809667806...
Checkpoint 1809667806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.32328
Policy Entropy: 2.11168
Value Function Loss: 0.01732

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 21,787.69378
Overall Steps per Second: 10,468.43527

Timestep Collection Time: 2.29579
Timestep Consumption Time: 2.48238
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.77817

Cumulative Model Updates: 216,998
Cumulative Timesteps: 1,809,717,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.11966
Policy Entropy: 2.09488
Value Function Loss: 0.01785

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.63052

Collected Steps per Second: 21,911.02887
Overall Steps per Second: 10,296.42805

Timestep Collection Time: 2.28333
Timestep Consumption Time: 2.57564
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.85897

Cumulative Model Updates: 217,004
Cumulative Timesteps: 1,809,767,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1809767856...
Checkpoint 1809767856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.91144
Policy Entropy: 2.12089
Value Function Loss: 0.01685

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 21,553.69430
Overall Steps per Second: 10,197.60073

Timestep Collection Time: 2.32127
Timestep Consumption Time: 2.58498
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.90625

Cumulative Model Updates: 217,010
Cumulative Timesteps: 1,809,817,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.93659
Policy Entropy: 2.11055
Value Function Loss: 0.01736

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.55494
Value Function Update Magnitude: 0.61607

Collected Steps per Second: 21,428.84810
Overall Steps per Second: 10,315.62785

Timestep Collection Time: 2.33386
Timestep Consumption Time: 2.51431
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.84818

Cumulative Model Updates: 217,016
Cumulative Timesteps: 1,809,867,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1809867900...
Checkpoint 1809867900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.10376
Policy Entropy: 2.12688
Value Function Loss: 0.01716

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.60599

Collected Steps per Second: 20,706.04715
Overall Steps per Second: 10,229.11755

Timestep Collection Time: 2.41582
Timestep Consumption Time: 2.47434
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.89016

Cumulative Model Updates: 217,022
Cumulative Timesteps: 1,809,917,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.91575
Policy Entropy: 2.12785
Value Function Loss: 0.01803

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,081.64638
Overall Steps per Second: 10,372.12336

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.55711
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.82216

Cumulative Model Updates: 217,028
Cumulative Timesteps: 1,809,967,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1809967938...
Checkpoint 1809967938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.54129
Policy Entropy: 2.14685
Value Function Loss: 0.01829

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 21,730.53614
Overall Steps per Second: 10,340.01000

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.53569
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.83752

Cumulative Model Updates: 217,034
Cumulative Timesteps: 1,810,017,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.23624
Policy Entropy: 2.14800
Value Function Loss: 0.01759

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.62893

Collected Steps per Second: 21,812.21107
Overall Steps per Second: 10,393.83206

Timestep Collection Time: 2.29312
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.81228

Cumulative Model Updates: 217,040
Cumulative Timesteps: 1,810,067,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1810067976...
Checkpoint 1810067976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.31908
Policy Entropy: 2.14491
Value Function Loss: 0.01719

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 20,880.13919
Overall Steps per Second: 10,346.12761

Timestep Collection Time: 2.39558
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.83466

Cumulative Model Updates: 217,046
Cumulative Timesteps: 1,810,117,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.83941
Policy Entropy: 2.13560
Value Function Loss: 0.01811

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.62455

Collected Steps per Second: 21,762.88978
Overall Steps per Second: 10,375.32850

Timestep Collection Time: 2.29859
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82144

Cumulative Model Updates: 217,052
Cumulative Timesteps: 1,810,168,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1810168020...
Checkpoint 1810168020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.08898
Policy Entropy: 2.13955
Value Function Loss: 0.01859

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.65021

Collected Steps per Second: 21,523.98621
Overall Steps per Second: 10,285.16601

Timestep Collection Time: 2.32308
Timestep Consumption Time: 2.53848
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.86156

Cumulative Model Updates: 217,058
Cumulative Timesteps: 1,810,218,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.02815
Policy Entropy: 2.14034
Value Function Loss: 0.01829

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.64088

Collected Steps per Second: 21,772.56573
Overall Steps per Second: 10,409.65254

Timestep Collection Time: 2.29775
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.80592

Cumulative Model Updates: 217,064
Cumulative Timesteps: 1,810,268,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1810268050...
Checkpoint 1810268050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.02917
Policy Entropy: 2.13550
Value Function Loss: 0.01809

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.62048

Collected Steps per Second: 21,600.35570
Overall Steps per Second: 10,391.20357

Timestep Collection Time: 2.31681
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.81600

Cumulative Model Updates: 217,070
Cumulative Timesteps: 1,810,318,094

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.72359
Policy Entropy: 2.10515
Value Function Loss: 0.01850

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.62583

Collected Steps per Second: 21,935.53119
Overall Steps per Second: 10,327.36811

Timestep Collection Time: 2.27959
Timestep Consumption Time: 2.56230
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.84189

Cumulative Model Updates: 217,076
Cumulative Timesteps: 1,810,368,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1810368098...
Checkpoint 1810368098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.11547
Policy Entropy: 2.10675
Value Function Loss: 0.01813

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.63489

Collected Steps per Second: 21,347.26801
Overall Steps per Second: 10,206.10617

Timestep Collection Time: 2.34297
Timestep Consumption Time: 2.55763
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.90060

Cumulative Model Updates: 217,082
Cumulative Timesteps: 1,810,418,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.29565
Policy Entropy: 2.10845
Value Function Loss: 0.01747

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.53829
Value Function Update Magnitude: 0.61614

Collected Steps per Second: 21,676.20478
Overall Steps per Second: 10,386.78331

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.81651

Cumulative Model Updates: 217,088
Cumulative Timesteps: 1,810,468,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1810468142...
Checkpoint 1810468142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.42670
Policy Entropy: 2.13284
Value Function Loss: 0.01658

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.51519
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 21,655.50513
Overall Steps per Second: 10,411.12992

Timestep Collection Time: 2.30934
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.80351

Cumulative Model Updates: 217,094
Cumulative Timesteps: 1,810,518,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.05242
Policy Entropy: 2.11047
Value Function Loss: 0.01721

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.55935

Collected Steps per Second: 21,675.38391
Overall Steps per Second: 10,327.31313

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.53517
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.84231

Cumulative Model Updates: 217,100
Cumulative Timesteps: 1,810,568,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1810568160...
Checkpoint 1810568160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.20344
Policy Entropy: 2.09502
Value Function Loss: 0.01851

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.54871
Value Function Update Magnitude: 0.59173

Collected Steps per Second: 21,409.15775
Overall Steps per Second: 10,210.00268

Timestep Collection Time: 2.33657
Timestep Consumption Time: 2.56294
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.89951

Cumulative Model Updates: 217,106
Cumulative Timesteps: 1,810,618,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.35020
Policy Entropy: 2.11581
Value Function Loss: 0.01823

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 21,800.26015
Overall Steps per Second: 10,386.00574

Timestep Collection Time: 2.29483
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.81687

Cumulative Model Updates: 217,112
Cumulative Timesteps: 1,810,668,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1810668212...
Checkpoint 1810668212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.07405
Policy Entropy: 2.13379
Value Function Loss: 0.01775

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 21,551.79101
Overall Steps per Second: 10,404.57836

Timestep Collection Time: 2.32055
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.30153
Total Iteration Time: 4.80673

Cumulative Model Updates: 217,118
Cumulative Timesteps: 1,810,718,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.11827
Policy Entropy: 2.16200
Value Function Loss: 0.01798

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.15368
Policy Update Magnitude: 0.52914
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 21,965.98461
Overall Steps per Second: 10,335.53991

Timestep Collection Time: 2.27698
Timestep Consumption Time: 2.56225
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.83922

Cumulative Model Updates: 217,124
Cumulative Timesteps: 1,810,768,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1810768240...
Checkpoint 1810768240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.35100
Policy Entropy: 2.12958
Value Function Loss: 0.01814

Mean KL Divergence: 0.02687
SB3 Clip Fraction: 0.17567
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 21,115.78582
Overall Steps per Second: 10,201.92196

Timestep Collection Time: 2.36837
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.90202

Cumulative Model Updates: 217,130
Cumulative Timesteps: 1,810,818,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.44592
Policy Entropy: 2.12927
Value Function Loss: 0.01840

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.17668
Policy Update Magnitude: 0.54934
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 21,482.18025
Overall Steps per Second: 10,336.15545

Timestep Collection Time: 2.32853
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.83952

Cumulative Model Updates: 217,136
Cumulative Timesteps: 1,810,868,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1810868272...
Checkpoint 1810868272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.37949
Policy Entropy: 2.13569
Value Function Loss: 0.01789

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.16810
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.61652

Collected Steps per Second: 21,767.39913
Overall Steps per Second: 10,324.13482

Timestep Collection Time: 2.29775
Timestep Consumption Time: 2.54682
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.84457

Cumulative Model Updates: 217,142
Cumulative Timesteps: 1,810,918,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.32538
Policy Entropy: 2.13536
Value Function Loss: 0.01766

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.61590

Collected Steps per Second: 22,010.46492
Overall Steps per Second: 10,456.74913

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.78160

Cumulative Model Updates: 217,148
Cumulative Timesteps: 1,810,968,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1810968288...
Checkpoint 1810968288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.76778
Policy Entropy: 2.11745
Value Function Loss: 0.01843

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 21,319.70709
Overall Steps per Second: 10,208.23522

Timestep Collection Time: 2.34544
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.89840

Cumulative Model Updates: 217,154
Cumulative Timesteps: 1,811,018,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.93265
Policy Entropy: 2.10865
Value Function Loss: 0.01730

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.64054

Collected Steps per Second: 21,961.83045
Overall Steps per Second: 10,374.85392

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.54409
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.82204

Cumulative Model Updates: 217,160
Cumulative Timesteps: 1,811,068,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1811068320...
Checkpoint 1811068320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.91882
Policy Entropy: 2.10210
Value Function Loss: 0.01745

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 21,685.32858
Overall Steps per Second: 10,295.13248

Timestep Collection Time: 2.30617
Timestep Consumption Time: 2.55147
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.85764

Cumulative Model Updates: 217,166
Cumulative Timesteps: 1,811,118,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.09042
Policy Entropy: 2.14464
Value Function Loss: 0.01635

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.53372
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 21,740.09720
Overall Steps per Second: 10,378.93532

Timestep Collection Time: 2.30036
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.81841

Cumulative Model Updates: 217,172
Cumulative Timesteps: 1,811,168,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1811168340...
Checkpoint 1811168340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.55230
Policy Entropy: 2.14997
Value Function Loss: 0.01734

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.53768
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 22,321.75526
Overall Steps per Second: 10,411.77199

Timestep Collection Time: 2.24113
Timestep Consumption Time: 2.56362
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.80475

Cumulative Model Updates: 217,178
Cumulative Timesteps: 1,811,218,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.33277
Policy Entropy: 2.18488
Value Function Loss: 0.01732

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.59875

Collected Steps per Second: 22,064.71107
Overall Steps per Second: 10,322.36004

Timestep Collection Time: 2.26787
Timestep Consumption Time: 2.57985
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.84773

Cumulative Model Updates: 217,184
Cumulative Timesteps: 1,811,268,406

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1811268406...
Checkpoint 1811268406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.74139
Policy Entropy: 2.16569
Value Function Loss: 0.01844

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.54099
Value Function Update Magnitude: 0.58958

Collected Steps per Second: 21,613.68838
Overall Steps per Second: 10,253.63329

Timestep Collection Time: 2.31390
Timestep Consumption Time: 2.56359
PPO Batch Consumption Time: 0.30370
Total Iteration Time: 4.87749

Cumulative Model Updates: 217,190
Cumulative Timesteps: 1,811,318,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.11617
Policy Entropy: 2.17089
Value Function Loss: 0.01734

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.53009
Value Function Update Magnitude: 0.59726

Collected Steps per Second: 21,981.78573
Overall Steps per Second: 10,474.45499

Timestep Collection Time: 2.27561
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 4.77562

Cumulative Model Updates: 217,196
Cumulative Timesteps: 1,811,368,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1811368440...
Checkpoint 1811368440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.76829
Policy Entropy: 2.17411
Value Function Loss: 0.01664

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.52197
Value Function Update Magnitude: 0.60768

Collected Steps per Second: 21,770.00112
Overall Steps per Second: 10,293.09217

Timestep Collection Time: 2.29738
Timestep Consumption Time: 2.56161
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.85899

Cumulative Model Updates: 217,202
Cumulative Timesteps: 1,811,418,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.88555
Policy Entropy: 2.18590
Value Function Loss: 0.01531

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.52025
Value Function Update Magnitude: 0.59798

Collected Steps per Second: 21,916.17829
Overall Steps per Second: 10,293.09406

Timestep Collection Time: 2.28197
Timestep Consumption Time: 2.57682
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 4.85879

Cumulative Model Updates: 217,208
Cumulative Timesteps: 1,811,468,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1811468466...
Checkpoint 1811468466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.76650
Policy Entropy: 2.18506
Value Function Loss: 0.01542

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.51136
Value Function Update Magnitude: 0.59205

Collected Steps per Second: 21,597.65662
Overall Steps per Second: 10,233.62340

Timestep Collection Time: 2.31590
Timestep Consumption Time: 2.57171
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.88761

Cumulative Model Updates: 217,214
Cumulative Timesteps: 1,811,518,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.59561
Policy Entropy: 2.18396
Value Function Loss: 0.01500

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.50748
Value Function Update Magnitude: 0.59492

Collected Steps per Second: 21,707.10147
Overall Steps per Second: 10,471.68685

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.77497

Cumulative Model Updates: 217,220
Cumulative Timesteps: 1,811,568,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1811568486...
Checkpoint 1811568486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.38870
Policy Entropy: 2.18055
Value Function Loss: 0.01560

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.51188
Value Function Update Magnitude: 0.60209

Collected Steps per Second: 21,773.52082
Overall Steps per Second: 10,235.09286

Timestep Collection Time: 2.29747
Timestep Consumption Time: 2.59003
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.88750

Cumulative Model Updates: 217,226
Cumulative Timesteps: 1,811,618,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.51531
Policy Entropy: 2.16755
Value Function Loss: 0.01594

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.51864
Value Function Update Magnitude: 0.60489

Collected Steps per Second: 21,745.88976
Overall Steps per Second: 10,353.63029

Timestep Collection Time: 2.30020
Timestep Consumption Time: 2.53095
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.83116

Cumulative Model Updates: 217,232
Cumulative Timesteps: 1,811,668,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1811668530...
Checkpoint 1811668530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.20307
Policy Entropy: 2.13834
Value Function Loss: 0.01725

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 21,693.65212
Overall Steps per Second: 10,277.50897

Timestep Collection Time: 2.30602
Timestep Consumption Time: 2.56150
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 4.86752

Cumulative Model Updates: 217,238
Cumulative Timesteps: 1,811,718,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.48691
Policy Entropy: 2.12680
Value Function Loss: 0.01691

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 21,756.92687
Overall Steps per Second: 10,462.52440

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.48174
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.78068

Cumulative Model Updates: 217,244
Cumulative Timesteps: 1,811,768,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1811768574...
Checkpoint 1811768574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.85214
Policy Entropy: 2.13357
Value Function Loss: 0.01733

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 21,723.91649
Overall Steps per Second: 10,224.65400

Timestep Collection Time: 2.30281
Timestep Consumption Time: 2.58988
PPO Batch Consumption Time: 0.30475
Total Iteration Time: 4.89268

Cumulative Model Updates: 217,250
Cumulative Timesteps: 1,811,818,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.03380
Policy Entropy: 2.13173
Value Function Loss: 0.01691

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.53026
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 21,920.32510
Overall Steps per Second: 10,368.16046

Timestep Collection Time: 2.28245
Timestep Consumption Time: 2.54309
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.82554

Cumulative Model Updates: 217,256
Cumulative Timesteps: 1,811,868,632

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1811868632...
Checkpoint 1811868632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.81280
Policy Entropy: 2.16212
Value Function Loss: 0.01660

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 21,883.27511
Overall Steps per Second: 10,324.95449

Timestep Collection Time: 2.28558
Timestep Consumption Time: 2.55860
PPO Batch Consumption Time: 0.30515
Total Iteration Time: 4.84419

Cumulative Model Updates: 217,262
Cumulative Timesteps: 1,811,918,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.76567
Policy Entropy: 2.15783
Value Function Loss: 0.01611

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.51746
Value Function Update Magnitude: 0.59477

Collected Steps per Second: 21,782.48705
Overall Steps per Second: 10,436.21805

Timestep Collection Time: 2.29542
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.79101

Cumulative Model Updates: 217,268
Cumulative Timesteps: 1,811,968,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1811968648...
Checkpoint 1811968648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.96922
Policy Entropy: 2.15840
Value Function Loss: 0.01653

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.51800
Value Function Update Magnitude: 0.58701

Collected Steps per Second: 21,781.18392
Overall Steps per Second: 10,252.15981

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.58270
PPO Batch Consumption Time: 0.30348
Total Iteration Time: 4.87936

Cumulative Model Updates: 217,274
Cumulative Timesteps: 1,812,018,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.91692
Policy Entropy: 2.14097
Value Function Loss: 0.01647

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.52600
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 21,863.59395
Overall Steps per Second: 10,406.38124

Timestep Collection Time: 2.28700
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.80494

Cumulative Model Updates: 217,280
Cumulative Timesteps: 1,812,068,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1812068674...
Checkpoint 1812068674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.59163
Policy Entropy: 2.15214
Value Function Loss: 0.01657

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.53461
Value Function Update Magnitude: 0.58932

Collected Steps per Second: 21,277.45499
Overall Steps per Second: 10,216.09889

Timestep Collection Time: 2.34991
Timestep Consumption Time: 2.54433
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.89424

Cumulative Model Updates: 217,286
Cumulative Timesteps: 1,812,118,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.53230
Policy Entropy: 2.14281
Value Function Loss: 0.01699

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.58979

Collected Steps per Second: 21,380.44080
Overall Steps per Second: 10,464.24409

Timestep Collection Time: 2.33961
Timestep Consumption Time: 2.44066
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.78028

Cumulative Model Updates: 217,292
Cumulative Timesteps: 1,812,168,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1812168696...
Checkpoint 1812168696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.31860
Policy Entropy: 2.13096
Value Function Loss: 0.01668

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.60059

Collected Steps per Second: 21,674.22325
Overall Steps per Second: 10,235.17766

Timestep Collection Time: 2.30781
Timestep Consumption Time: 2.57926
PPO Batch Consumption Time: 0.30355
Total Iteration Time: 4.88707

Cumulative Model Updates: 217,298
Cumulative Timesteps: 1,812,218,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.01032
Policy Entropy: 2.12451
Value Function Loss: 0.01725

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 21,655.68815
Overall Steps per Second: 10,317.13372

Timestep Collection Time: 2.31071
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.85018

Cumulative Model Updates: 217,304
Cumulative Timesteps: 1,812,268,756

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1812268756...
Checkpoint 1812268756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.00155
Policy Entropy: 2.13700
Value Function Loss: 0.01646

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.58616

Collected Steps per Second: 21,708.75181
Overall Steps per Second: 10,318.20958

Timestep Collection Time: 2.30368
Timestep Consumption Time: 2.54309
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.84677

Cumulative Model Updates: 217,310
Cumulative Timesteps: 1,812,318,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.42750
Policy Entropy: 2.13728
Value Function Loss: 0.01659

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.52537
Value Function Update Magnitude: 0.56985

Collected Steps per Second: 21,020.41616
Overall Steps per Second: 10,376.90061

Timestep Collection Time: 2.37912
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.81936

Cumulative Model Updates: 217,316
Cumulative Timesteps: 1,812,368,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1812368776...
Checkpoint 1812368776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.20796
Policy Entropy: 2.13390
Value Function Loss: 0.01643

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 21,775.29794
Overall Steps per Second: 10,297.55114

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.56057
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.85785

Cumulative Model Updates: 217,322
Cumulative Timesteps: 1,812,418,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.91068
Policy Entropy: 2.13697
Value Function Loss: 0.01583

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.57267

Collected Steps per Second: 21,717.58765
Overall Steps per Second: 10,338.30138

Timestep Collection Time: 2.30320
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.83832

Cumulative Model Updates: 217,328
Cumulative Timesteps: 1,812,468,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1812468820...
Checkpoint 1812468820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.21605
Policy Entropy: 2.13064
Value Function Loss: 0.01689

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.51259
Value Function Update Magnitude: 0.57464

Collected Steps per Second: 21,738.87820
Overall Steps per Second: 10,306.43875

Timestep Collection Time: 2.30113
Timestep Consumption Time: 2.55253
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.85366

Cumulative Model Updates: 217,334
Cumulative Timesteps: 1,812,518,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.17965
Policy Entropy: 2.14065
Value Function Loss: 0.01817

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.51977
Value Function Update Magnitude: 0.57505

Collected Steps per Second: 21,409.20841
Overall Steps per Second: 10,346.76174

Timestep Collection Time: 2.33619
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.83398

Cumulative Model Updates: 217,340
Cumulative Timesteps: 1,812,568,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1812568860...
Checkpoint 1812568860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.44836
Policy Entropy: 2.13127
Value Function Loss: 0.01871

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.16346
Policy Update Magnitude: 0.50388
Value Function Update Magnitude: 0.58275

Collected Steps per Second: 21,712.82582
Overall Steps per Second: 10,432.67648

Timestep Collection Time: 2.30279
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.79263

Cumulative Model Updates: 217,346
Cumulative Timesteps: 1,812,618,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.18195
Policy Entropy: 2.13870
Value Function Loss: 0.01879

Mean KL Divergence: 0.03151
SB3 Clip Fraction: 0.18914
Policy Update Magnitude: 0.51888
Value Function Update Magnitude: 0.60706

Collected Steps per Second: 21,999.25713
Overall Steps per Second: 10,355.45262

Timestep Collection Time: 2.27417
Timestep Consumption Time: 2.55710
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.83127

Cumulative Model Updates: 217,352
Cumulative Timesteps: 1,812,668,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1812668890...
Checkpoint 1812668890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.51634
Policy Entropy: 2.15099
Value Function Loss: 0.01736

Mean KL Divergence: 0.02965
SB3 Clip Fraction: 0.18242
Policy Update Magnitude: 0.53344
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 21,911.70035
Overall Steps per Second: 10,199.35190

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.62122
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.90384

Cumulative Model Updates: 217,358
Cumulative Timesteps: 1,812,718,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.94163
Policy Entropy: 2.15505
Value Function Loss: 0.01730

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.57337

Collected Steps per Second: 21,708.79179
Overall Steps per Second: 10,418.98657

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.79951

Cumulative Model Updates: 217,364
Cumulative Timesteps: 1,812,768,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1812768912...
Checkpoint 1812768912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.91335
Policy Entropy: 2.14871
Value Function Loss: 0.01679

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.55016

Collected Steps per Second: 21,888.33578
Overall Steps per Second: 10,596.80037

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.71897

Cumulative Model Updates: 217,370
Cumulative Timesteps: 1,812,818,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.78724
Policy Entropy: 2.13622
Value Function Loss: 0.01709

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.16092
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.54395

Collected Steps per Second: 21,887.39145
Overall Steps per Second: 10,310.67984

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.56554
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.85050

Cumulative Model Updates: 217,376
Cumulative Timesteps: 1,812,868,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1812868930...
Checkpoint 1812868930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.15552
Policy Entropy: 2.14355
Value Function Loss: 0.01704

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.52071
Value Function Update Magnitude: 0.57088

Collected Steps per Second: 21,801.87372
Overall Steps per Second: 10,358.49225

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.53368
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.82715

Cumulative Model Updates: 217,382
Cumulative Timesteps: 1,812,918,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.70176
Policy Entropy: 2.13636
Value Function Loss: 0.01661

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 21,746.15654
Overall Steps per Second: 10,419.01060

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.80007

Cumulative Model Updates: 217,388
Cumulative Timesteps: 1,812,968,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1812968944...
Checkpoint 1812968944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.83942
Policy Entropy: 2.13474
Value Function Loss: 0.01560

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.59794

Collected Steps per Second: 21,837.75527
Overall Steps per Second: 10,491.55300

Timestep Collection Time: 2.29089
Timestep Consumption Time: 2.47751
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.76841

Cumulative Model Updates: 217,394
Cumulative Timesteps: 1,813,018,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.73013
Policy Entropy: 2.11771
Value Function Loss: 0.01677

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.59153

Collected Steps per Second: 22,130.88798
Overall Steps per Second: 10,286.18284

Timestep Collection Time: 2.26010
Timestep Consumption Time: 2.60254
PPO Batch Consumption Time: 0.30488
Total Iteration Time: 4.86264

Cumulative Model Updates: 217,400
Cumulative Timesteps: 1,813,068,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1813068990...
Checkpoint 1813068990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.71286
Policy Entropy: 2.12967
Value Function Loss: 0.01753

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.58819

Collected Steps per Second: 21,482.07504
Overall Steps per Second: 10,211.70148

Timestep Collection Time: 2.32808
Timestep Consumption Time: 2.56944
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.89752

Cumulative Model Updates: 217,406
Cumulative Timesteps: 1,813,119,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.10108
Policy Entropy: 2.12202
Value Function Loss: 0.01771

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 21,331.97326
Overall Steps per Second: 10,445.60950

Timestep Collection Time: 2.34418
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.78727

Cumulative Model Updates: 217,412
Cumulative Timesteps: 1,813,169,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1813169008...
Checkpoint 1813169008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.21654
Policy Entropy: 2.12297
Value Function Loss: 0.01742

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.54070
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 21,776.49322
Overall Steps per Second: 10,260.27380

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.57711
PPO Batch Consumption Time: 0.30431
Total Iteration Time: 4.87316

Cumulative Model Updates: 217,418
Cumulative Timesteps: 1,813,219,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.49103
Policy Entropy: 2.10197
Value Function Loss: 0.01771

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.58385

Collected Steps per Second: 21,826.98214
Overall Steps per Second: 10,360.16985

Timestep Collection Time: 2.29074
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.82618

Cumulative Model Updates: 217,424
Cumulative Timesteps: 1,813,269,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1813269008...
Checkpoint 1813269008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.57843
Policy Entropy: 2.11181
Value Function Loss: 0.01783

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.57638

Collected Steps per Second: 21,500.93890
Overall Steps per Second: 10,253.54487

Timestep Collection Time: 2.32576
Timestep Consumption Time: 2.55119
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.87695

Cumulative Model Updates: 217,430
Cumulative Timesteps: 1,813,319,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.60545
Policy Entropy: 2.10230
Value Function Loss: 0.01747

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.52056
Value Function Update Magnitude: 0.57108

Collected Steps per Second: 21,661.59179
Overall Steps per Second: 10,367.46926

Timestep Collection Time: 2.30869
Timestep Consumption Time: 2.51505
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.82374

Cumulative Model Updates: 217,436
Cumulative Timesteps: 1,813,369,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1813369024...
Checkpoint 1813369024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.63699
Policy Entropy: 2.08459
Value Function Loss: 0.01778

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.55571

Collected Steps per Second: 21,592.66614
Overall Steps per Second: 10,430.19475

Timestep Collection Time: 2.31625
Timestep Consumption Time: 2.47887
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 4.79512

Cumulative Model Updates: 217,442
Cumulative Timesteps: 1,813,419,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.89087
Policy Entropy: 2.07088
Value Function Loss: 0.01870

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14467
Policy Update Magnitude: 0.55129
Value Function Update Magnitude: 0.58472

Collected Steps per Second: 22,079.63202
Overall Steps per Second: 10,315.04469

Timestep Collection Time: 2.26498
Timestep Consumption Time: 2.58327
PPO Batch Consumption Time: 0.30030
Total Iteration Time: 4.84826

Cumulative Model Updates: 217,448
Cumulative Timesteps: 1,813,469,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1813469048...
Checkpoint 1813469048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.45511
Policy Entropy: 2.09634
Value Function Loss: 0.01844

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.15024
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 21,429.47361
Overall Steps per Second: 10,225.75209

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.55638
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.88962

Cumulative Model Updates: 217,454
Cumulative Timesteps: 1,813,519,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.71590
Policy Entropy: 2.13025
Value Function Loss: 0.01767

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.57116

Collected Steps per Second: 21,777.15461
Overall Steps per Second: 10,423.29297

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.50206
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.79906

Cumulative Model Updates: 217,460
Cumulative Timesteps: 1,813,569,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1813569070...
Checkpoint 1813569070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.22582
Policy Entropy: 2.13344
Value Function Loss: 0.01731

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 21,385.16276
Overall Steps per Second: 10,383.42254

Timestep Collection Time: 2.33910
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.81749

Cumulative Model Updates: 217,466
Cumulative Timesteps: 1,813,619,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.30423
Policy Entropy: 2.11483
Value Function Loss: 0.01641

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.52838

Collected Steps per Second: 21,885.91736
Overall Steps per Second: 10,323.89838

Timestep Collection Time: 2.28512
Timestep Consumption Time: 2.55917
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.84429

Cumulative Model Updates: 217,472
Cumulative Timesteps: 1,813,669,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1813669104...
Checkpoint 1813669104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.83087
Policy Entropy: 2.11827
Value Function Loss: 0.01699

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.53889
Value Function Update Magnitude: 0.53134

Collected Steps per Second: 21,560.16927
Overall Steps per Second: 10,173.27292

Timestep Collection Time: 2.31974
Timestep Consumption Time: 2.59647
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 4.91622

Cumulative Model Updates: 217,478
Cumulative Timesteps: 1,813,719,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.54782
Policy Entropy: 2.13020
Value Function Loss: 0.01766

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.53972
Value Function Update Magnitude: 0.54309

Collected Steps per Second: 21,884.24754
Overall Steps per Second: 10,460.26570

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.78229

Cumulative Model Updates: 217,484
Cumulative Timesteps: 1,813,769,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1813769142...
Checkpoint 1813769142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.90749
Policy Entropy: 2.13991
Value Function Loss: 0.01768

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.56194

Collected Steps per Second: 21,765.57800
Overall Steps per Second: 10,455.14656

Timestep Collection Time: 2.29757
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 4.78310

Cumulative Model Updates: 217,490
Cumulative Timesteps: 1,813,819,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.35242
Policy Entropy: 2.12427
Value Function Loss: 0.01680

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 21,958.86417
Overall Steps per Second: 10,274.22293

Timestep Collection Time: 2.27744
Timestep Consumption Time: 2.59008
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 4.86752

Cumulative Model Updates: 217,496
Cumulative Timesteps: 1,813,869,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1813869160...
Checkpoint 1813869160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.85728
Policy Entropy: 2.12164
Value Function Loss: 0.01623

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.52152
Value Function Update Magnitude: 0.53503

Collected Steps per Second: 21,429.46275
Overall Steps per Second: 10,168.43576

Timestep Collection Time: 2.33361
Timestep Consumption Time: 2.58435
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 4.91796

Cumulative Model Updates: 217,502
Cumulative Timesteps: 1,813,919,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.46508
Policy Entropy: 2.12314
Value Function Loss: 0.01709

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.52789
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 21,914.41711
Overall Steps per Second: 10,473.90142

Timestep Collection Time: 2.28188
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.77434

Cumulative Model Updates: 217,508
Cumulative Timesteps: 1,813,969,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1813969174...
Checkpoint 1813969174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.61605
Policy Entropy: 2.12301
Value Function Loss: 0.01729

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.52443
Value Function Update Magnitude: 0.53356

Collected Steps per Second: 21,502.51708
Overall Steps per Second: 10,184.27310

Timestep Collection Time: 2.32559
Timestep Consumption Time: 2.58453
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 4.91012

Cumulative Model Updates: 217,514
Cumulative Timesteps: 1,814,019,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.18391
Policy Entropy: 2.13152
Value Function Loss: 0.01725

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.52030
Value Function Update Magnitude: 0.52843

Collected Steps per Second: 22,041.03977
Overall Steps per Second: 10,398.94403

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.54040
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.80953

Cumulative Model Updates: 217,520
Cumulative Timesteps: 1,814,069,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1814069194...
Checkpoint 1814069194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.33197
Policy Entropy: 2.11827
Value Function Loss: 0.01744

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.53412
Value Function Update Magnitude: 0.55264

Collected Steps per Second: 21,575.72125
Overall Steps per Second: 10,282.68144

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.54614
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.86449

Cumulative Model Updates: 217,526
Cumulative Timesteps: 1,814,119,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.45469
Policy Entropy: 2.15018
Value Function Loss: 0.01763

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.58611

Collected Steps per Second: 21,668.12036
Overall Steps per Second: 10,466.06791

Timestep Collection Time: 2.30837
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.77906

Cumulative Model Updates: 217,532
Cumulative Timesteps: 1,814,169,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1814169232...
Checkpoint 1814169232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.67038
Policy Entropy: 2.15592
Value Function Loss: 0.01809

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 21,675.00253
Overall Steps per Second: 10,224.02118

Timestep Collection Time: 2.30782
Timestep Consumption Time: 2.58478
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 4.89260

Cumulative Model Updates: 217,538
Cumulative Timesteps: 1,814,219,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.39490
Policy Entropy: 2.18031
Value Function Loss: 0.01767

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.59946

Collected Steps per Second: 21,934.58149
Overall Steps per Second: 10,358.49454

Timestep Collection Time: 2.28014
Timestep Consumption Time: 2.54816
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.82831

Cumulative Model Updates: 217,544
Cumulative Timesteps: 1,814,269,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1814269268...
Checkpoint 1814269268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.58572
Policy Entropy: 2.17240
Value Function Loss: 0.01791

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.52464
Value Function Update Magnitude: 0.58840

Collected Steps per Second: 21,361.66996
Overall Steps per Second: 10,276.25116

Timestep Collection Time: 2.34073
Timestep Consumption Time: 2.52505
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.86578

Cumulative Model Updates: 217,550
Cumulative Timesteps: 1,814,319,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.88300
Policy Entropy: 2.15311
Value Function Loss: 0.01704

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.55583

Collected Steps per Second: 21,580.90812
Overall Steps per Second: 10,344.88965

Timestep Collection Time: 2.31705
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.83369

Cumulative Model Updates: 217,556
Cumulative Timesteps: 1,814,369,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1814369274...
Checkpoint 1814369274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.03439
Policy Entropy: 2.12242
Value Function Loss: 0.01748

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.56127

Collected Steps per Second: 22,588.83344
Overall Steps per Second: 10,499.73343

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.55048
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.76564

Cumulative Model Updates: 217,562
Cumulative Timesteps: 1,814,419,312

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.52698
Policy Entropy: 2.11172
Value Function Loss: 0.01734

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.58344

Collected Steps per Second: 21,888.53909
Overall Steps per Second: 10,261.31230

Timestep Collection Time: 2.28549
Timestep Consumption Time: 2.58972
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.87520

Cumulative Model Updates: 217,568
Cumulative Timesteps: 1,814,469,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1814469338...
Checkpoint 1814469338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.49358
Policy Entropy: 2.11961
Value Function Loss: 0.01688

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.53811
Value Function Update Magnitude: 0.59039

Collected Steps per Second: 21,533.42546
Overall Steps per Second: 10,224.40502

Timestep Collection Time: 2.32281
Timestep Consumption Time: 2.56921
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.89202

Cumulative Model Updates: 217,574
Cumulative Timesteps: 1,814,519,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.47202
Policy Entropy: 2.12102
Value Function Loss: 0.01756

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.60142

Collected Steps per Second: 21,703.31392
Overall Steps per Second: 10,399.66229

Timestep Collection Time: 2.30426
Timestep Consumption Time: 2.50455
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.80881

Cumulative Model Updates: 217,580
Cumulative Timesteps: 1,814,569,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1814569366...
Checkpoint 1814569366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.83017
Policy Entropy: 2.12903
Value Function Loss: 0.01750

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.61529

Collected Steps per Second: 21,521.58334
Overall Steps per Second: 10,408.81893

Timestep Collection Time: 2.32436
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.80592

Cumulative Model Updates: 217,586
Cumulative Timesteps: 1,814,619,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.79795
Policy Entropy: 2.13017
Value Function Loss: 0.01813

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.54117
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 21,725.09638
Overall Steps per Second: 10,324.74874

Timestep Collection Time: 2.30185
Timestep Consumption Time: 2.54165
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.84351

Cumulative Model Updates: 217,592
Cumulative Timesteps: 1,814,669,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1814669398...
Checkpoint 1814669398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.77082
Policy Entropy: 2.12525
Value Function Loss: 0.01842

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 21,446.28319
Overall Steps per Second: 10,204.83741

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.56967
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.90238

Cumulative Model Updates: 217,598
Cumulative Timesteps: 1,814,719,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.77233
Policy Entropy: 2.10693
Value Function Loss: 0.01701

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 21,843.21651
Overall Steps per Second: 10,442.20419

Timestep Collection Time: 2.28968
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.78960

Cumulative Model Updates: 217,604
Cumulative Timesteps: 1,814,769,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1814769440...
Checkpoint 1814769440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.04964
Policy Entropy: 2.08112
Value Function Loss: 0.01758

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.59026

Collected Steps per Second: 21,810.62561
Overall Steps per Second: 10,545.06569

Timestep Collection Time: 2.29283
Timestep Consumption Time: 2.44949
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.74231

Cumulative Model Updates: 217,610
Cumulative Timesteps: 1,814,819,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.40799
Policy Entropy: 2.09687
Value Function Loss: 0.01742

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.60049

Collected Steps per Second: 20,924.59985
Overall Steps per Second: 10,034.53412

Timestep Collection Time: 2.38982
Timestep Consumption Time: 2.59357
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.98339

Cumulative Model Updates: 217,616
Cumulative Timesteps: 1,814,869,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1814869454...
Checkpoint 1814869454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.69853
Policy Entropy: 2.11004
Value Function Loss: 0.01823

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.60973

Collected Steps per Second: 21,233.82321
Overall Steps per Second: 10,246.36517

Timestep Collection Time: 2.35511
Timestep Consumption Time: 2.52545
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.88056

Cumulative Model Updates: 217,622
Cumulative Timesteps: 1,814,919,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.84227
Policy Entropy: 2.12423
Value Function Loss: 0.01759

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 22,178.50722
Overall Steps per Second: 10,553.49878

Timestep Collection Time: 2.25471
Timestep Consumption Time: 2.48363
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.73833

Cumulative Model Updates: 217,628
Cumulative Timesteps: 1,814,969,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1814969468...
Checkpoint 1814969468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.19039
Policy Entropy: 2.10851
Value Function Loss: 0.01783

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 21,744.85294
Overall Steps per Second: 10,560.94433

Timestep Collection Time: 2.30022
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.73613

Cumulative Model Updates: 217,634
Cumulative Timesteps: 1,815,019,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.77492
Policy Entropy: 2.06905
Value Function Loss: 0.01682

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.54786
Value Function Update Magnitude: 0.60121

Collected Steps per Second: 21,851.26152
Overall Steps per Second: 10,433.91623

Timestep Collection Time: 2.28948
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.79475

Cumulative Model Updates: 217,640
Cumulative Timesteps: 1,815,069,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1815069514...
Checkpoint 1815069514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.67921
Policy Entropy: 2.07770
Value Function Loss: 0.01619

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.18121
Policy Update Magnitude: 0.51350
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 22,079.35850
Overall Steps per Second: 10,291.93268

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.59507
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.86089

Cumulative Model Updates: 217,646
Cumulative Timesteps: 1,815,119,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.88006
Policy Entropy: 2.08665
Value Function Loss: 0.01755

Mean KL Divergence: 0.03068
SB3 Clip Fraction: 0.19002
Policy Update Magnitude: 0.50944
Value Function Update Magnitude: 0.59355

Collected Steps per Second: 21,814.77160
Overall Steps per Second: 10,348.32698

Timestep Collection Time: 2.29257
Timestep Consumption Time: 2.54028
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.83286

Cumulative Model Updates: 217,652
Cumulative Timesteps: 1,815,169,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1815169554...
Checkpoint 1815169554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.90872
Policy Entropy: 2.08453
Value Function Loss: 0.01761

Mean KL Divergence: 0.03424
SB3 Clip Fraction: 0.20111
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 21,891.88890
Overall Steps per Second: 10,320.84012

Timestep Collection Time: 2.28532
Timestep Consumption Time: 2.56215
PPO Batch Consumption Time: 0.30355
Total Iteration Time: 4.84747

Cumulative Model Updates: 217,658
Cumulative Timesteps: 1,815,219,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.67177
Policy Entropy: 2.10562
Value Function Loss: 0.01799

Mean KL Divergence: 0.03477
SB3 Clip Fraction: 0.20210
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.61964

Collected Steps per Second: 21,851.78256
Overall Steps per Second: 10,463.64577

Timestep Collection Time: 2.28833
Timestep Consumption Time: 2.49051
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.77883

Cumulative Model Updates: 217,664
Cumulative Timesteps: 1,815,269,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1815269588...
Checkpoint 1815269588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.01247
Policy Entropy: 2.10752
Value Function Loss: 0.01731

Mean KL Divergence: 0.03358
SB3 Clip Fraction: 0.19383
Policy Update Magnitude: 0.52393
Value Function Update Magnitude: 0.61817

Collected Steps per Second: 21,887.29483
Overall Steps per Second: 10,312.25029

Timestep Collection Time: 2.28452
Timestep Consumption Time: 2.56427
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 4.84880

Cumulative Model Updates: 217,670
Cumulative Timesteps: 1,815,319,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.46228
Policy Entropy: 2.13754
Value Function Loss: 0.01810

Mean KL Divergence: 0.02738
SB3 Clip Fraction: 0.18562
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.62834

Collected Steps per Second: 22,032.23756
Overall Steps per Second: 10,351.90473

Timestep Collection Time: 2.26986
Timestep Consumption Time: 2.56114
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.83100

Cumulative Model Updates: 217,676
Cumulative Timesteps: 1,815,369,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1815369600...
Checkpoint 1815369600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.91424
Policy Entropy: 2.14508
Value Function Loss: 0.01622

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.17279
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.64157

Collected Steps per Second: 21,706.38498
Overall Steps per Second: 10,293.61897

Timestep Collection Time: 2.30467
Timestep Consumption Time: 2.55524
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.85990

Cumulative Model Updates: 217,682
Cumulative Timesteps: 1,815,419,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.05087
Policy Entropy: 2.15793
Value Function Loss: 0.01643

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.53802
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 20,658.60212
Overall Steps per Second: 10,248.16833

Timestep Collection Time: 2.42040
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.87912

Cumulative Model Updates: 217,688
Cumulative Timesteps: 1,815,469,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1815469628...
Checkpoint 1815469628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.37427
Policy Entropy: 2.15612
Value Function Loss: 0.01604

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 22,189.37864
Overall Steps per Second: 10,338.36210

Timestep Collection Time: 2.25459
Timestep Consumption Time: 2.58447
PPO Batch Consumption Time: 0.30174
Total Iteration Time: 4.83906

Cumulative Model Updates: 217,694
Cumulative Timesteps: 1,815,519,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.70993
Policy Entropy: 2.13915
Value Function Loss: 0.01678

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.63331

Collected Steps per Second: 21,905.74077
Overall Steps per Second: 10,422.80297

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.51587
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.79948

Cumulative Model Updates: 217,700
Cumulative Timesteps: 1,815,569,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1815569680...
Checkpoint 1815569680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.36109
Policy Entropy: 2.13650
Value Function Loss: 0.01619

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.52559
Value Function Update Magnitude: 0.61834

Collected Steps per Second: 21,823.81307
Overall Steps per Second: 10,362.47229

Timestep Collection Time: 2.29163
Timestep Consumption Time: 2.53464
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.82626

Cumulative Model Updates: 217,706
Cumulative Timesteps: 1,815,619,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.73339
Policy Entropy: 2.12285
Value Function Loss: 0.01635

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 21,651.48613
Overall Steps per Second: 10,409.19658

Timestep Collection Time: 2.31033
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 4.80556

Cumulative Model Updates: 217,712
Cumulative Timesteps: 1,815,669,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1815669714...
Checkpoint 1815669714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.56540
Policy Entropy: 2.12001
Value Function Loss: 0.01635

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.54091
Value Function Update Magnitude: 0.64101

Collected Steps per Second: 21,336.61024
Overall Steps per Second: 10,157.21138

Timestep Collection Time: 2.34433
Timestep Consumption Time: 2.58025
PPO Batch Consumption Time: 0.30339
Total Iteration Time: 4.92458

Cumulative Model Updates: 217,718
Cumulative Timesteps: 1,815,719,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.35278
Policy Entropy: 2.12938
Value Function Loss: 0.01677

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.64887

Collected Steps per Second: 21,948.45519
Overall Steps per Second: 10,450.79252

Timestep Collection Time: 2.27825
Timestep Consumption Time: 2.50646
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.78471

Cumulative Model Updates: 217,724
Cumulative Timesteps: 1,815,769,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1815769738...
Checkpoint 1815769738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.10116
Policy Entropy: 2.13601
Value Function Loss: 0.01760

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 21,726.06098
Overall Steps per Second: 10,354.61096

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.52870
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.83128

Cumulative Model Updates: 217,730
Cumulative Timesteps: 1,815,819,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.96705
Policy Entropy: 2.13012
Value Function Loss: 0.01812

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 21,855.79598
Overall Steps per Second: 10,510.57947

Timestep Collection Time: 2.28800
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.75768

Cumulative Model Updates: 217,736
Cumulative Timesteps: 1,815,869,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1815869770...
Checkpoint 1815869770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.24043
Policy Entropy: 2.14658
Value Function Loss: 0.01812

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.61384

Collected Steps per Second: 22,070.21298
Overall Steps per Second: 10,411.17871

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.53835
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.80503

Cumulative Model Updates: 217,742
Cumulative Timesteps: 1,815,919,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.25792
Policy Entropy: 2.13422
Value Function Loss: 0.01733

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.60267

Collected Steps per Second: 21,920.86753
Overall Steps per Second: 10,408.45982

Timestep Collection Time: 2.28111
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.80417

Cumulative Model Updates: 217,748
Cumulative Timesteps: 1,815,969,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1815969800...
Checkpoint 1815969800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.13367
Policy Entropy: 2.12895
Value Function Loss: 0.01830

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 21,491.59781
Overall Steps per Second: 10,278.11046

Timestep Collection Time: 2.32807
Timestep Consumption Time: 2.53994
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.86802

Cumulative Model Updates: 217,754
Cumulative Timesteps: 1,816,019,834

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.61818
Policy Entropy: 2.12451
Value Function Loss: 0.01739

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.62187

Collected Steps per Second: 21,874.69008
Overall Steps per Second: 10,434.21566

Timestep Collection Time: 2.28584
Timestep Consumption Time: 2.50628
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.79212

Cumulative Model Updates: 217,760
Cumulative Timesteps: 1,816,069,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1816069836...
Checkpoint 1816069836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.48586
Policy Entropy: 2.12252
Value Function Loss: 0.01833

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.61952

Collected Steps per Second: 21,673.88573
Overall Steps per Second: 10,215.64602

Timestep Collection Time: 2.30720
Timestep Consumption Time: 2.58784
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 4.89504

Cumulative Model Updates: 217,766
Cumulative Timesteps: 1,816,119,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.26813
Policy Entropy: 2.11734
Value Function Loss: 0.01856

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.64325

Collected Steps per Second: 21,868.40693
Overall Steps per Second: 10,407.83931

Timestep Collection Time: 2.28787
Timestep Consumption Time: 2.51928
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.80715

Cumulative Model Updates: 217,772
Cumulative Timesteps: 1,816,169,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1816169874...
Checkpoint 1816169874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.30890
Policy Entropy: 2.10622
Value Function Loss: 0.01899

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.65612

Collected Steps per Second: 21,009.82373
Overall Steps per Second: 10,157.78659

Timestep Collection Time: 2.37984
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.92233

Cumulative Model Updates: 217,778
Cumulative Timesteps: 1,816,219,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.19206
Policy Entropy: 2.09634
Value Function Loss: 0.01810

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.53794
Value Function Update Magnitude: 0.63274

Collected Steps per Second: 22,847.87029
Overall Steps per Second: 10,559.73030

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.54780
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.73724

Cumulative Model Updates: 217,784
Cumulative Timesteps: 1,816,269,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1816269898...
Checkpoint 1816269898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.12866
Policy Entropy: 2.11685
Value Function Loss: 0.01689

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.16258
Policy Update Magnitude: 0.52529
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 21,555.85679
Overall Steps per Second: 10,209.41193

Timestep Collection Time: 2.32067
Timestep Consumption Time: 2.57912
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.89979

Cumulative Model Updates: 217,790
Cumulative Timesteps: 1,816,319,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.01794
Policy Entropy: 2.12451
Value Function Loss: 0.01601

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 21,974.40764
Overall Steps per Second: 10,408.82389

Timestep Collection Time: 2.27665
Timestep Consumption Time: 2.52966
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.80631

Cumulative Model Updates: 217,796
Cumulative Timesteps: 1,816,369,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1816369950...
Checkpoint 1816369950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.70228
Policy Entropy: 2.12421
Value Function Loss: 0.01636

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.59604

Collected Steps per Second: 21,486.01263
Overall Steps per Second: 10,268.90939

Timestep Collection Time: 2.32793
Timestep Consumption Time: 2.54289
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.87082

Cumulative Model Updates: 217,802
Cumulative Timesteps: 1,816,419,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.41909
Policy Entropy: 2.11443
Value Function Loss: 0.01606

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 21,532.98858
Overall Steps per Second: 10,430.25468

Timestep Collection Time: 2.32202
Timestep Consumption Time: 2.47173
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.79375

Cumulative Model Updates: 217,808
Cumulative Timesteps: 1,816,469,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1816469968...
Checkpoint 1816469968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.02511
Policy Entropy: 2.11921
Value Function Loss: 0.01581

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.53059
Value Function Update Magnitude: 0.58766

Collected Steps per Second: 21,579.77308
Overall Steps per Second: 10,230.28674

Timestep Collection Time: 2.31884
Timestep Consumption Time: 2.57252
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.89136

Cumulative Model Updates: 217,814
Cumulative Timesteps: 1,816,520,008

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.34234
Policy Entropy: 2.16010
Value Function Loss: 0.01484

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.52292
Value Function Update Magnitude: 0.61023

Collected Steps per Second: 21,913.40922
Overall Steps per Second: 10,381.28745

Timestep Collection Time: 2.28271
Timestep Consumption Time: 2.53577
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.81848

Cumulative Model Updates: 217,820
Cumulative Timesteps: 1,816,570,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1816570030...
Checkpoint 1816570030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.38971
Policy Entropy: 2.14980
Value Function Loss: 0.01606

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.51936
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 21,472.24564
Overall Steps per Second: 10,332.54808

Timestep Collection Time: 2.32887
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.83966

Cumulative Model Updates: 217,826
Cumulative Timesteps: 1,816,620,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.54740
Policy Entropy: 2.13588
Value Function Loss: 0.01595

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 22,126.02587
Overall Steps per Second: 10,419.40686

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.53926
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.79931

Cumulative Model Updates: 217,832
Cumulative Timesteps: 1,816,670,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1816670042...
Checkpoint 1816670042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.68125
Policy Entropy: 2.13341
Value Function Loss: 0.01639

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.52171
Value Function Update Magnitude: 0.62860

Collected Steps per Second: 21,765.02866
Overall Steps per Second: 10,215.69528

Timestep Collection Time: 2.29754
Timestep Consumption Time: 2.59748
PPO Batch Consumption Time: 0.30436
Total Iteration Time: 4.89502

Cumulative Model Updates: 217,838
Cumulative Timesteps: 1,816,720,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.45882
Policy Entropy: 2.12994
Value Function Loss: 0.01633

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.16315
Policy Update Magnitude: 0.52299
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 21,694.62437
Overall Steps per Second: 10,270.34784

Timestep Collection Time: 2.30555
Timestep Consumption Time: 2.56459
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.87014

Cumulative Model Updates: 217,844
Cumulative Timesteps: 1,816,770,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1816770066...
Checkpoint 1816770066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.71938
Policy Entropy: 2.11820
Value Function Loss: 0.01732

Mean KL Divergence: 0.02432
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.64019

Collected Steps per Second: 20,516.31762
Overall Steps per Second: 9,988.38675

Timestep Collection Time: 2.43835
Timestep Consumption Time: 2.57006
PPO Batch Consumption Time: 0.30476
Total Iteration Time: 5.00842

Cumulative Model Updates: 217,850
Cumulative Timesteps: 1,816,820,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.74848
Policy Entropy: 2.10781
Value Function Loss: 0.01759

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 21,766.60484
Overall Steps per Second: 10,432.43031

Timestep Collection Time: 2.29811
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.79486

Cumulative Model Updates: 217,856
Cumulative Timesteps: 1,816,870,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1816870114...
Checkpoint 1816870114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.09295
Policy Entropy: 2.12955
Value Function Loss: 0.01737

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.62583

Collected Steps per Second: 21,713.28623
Overall Steps per Second: 10,163.08783

Timestep Collection Time: 2.30301
Timestep Consumption Time: 2.61734
PPO Batch Consumption Time: 0.30631
Total Iteration Time: 4.92036

Cumulative Model Updates: 217,862
Cumulative Timesteps: 1,816,920,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.84934
Policy Entropy: 2.11783
Value Function Loss: 0.01664

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.52793
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 21,837.78974
Overall Steps per Second: 10,356.89424

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.53941
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.83021

Cumulative Model Updates: 217,868
Cumulative Timesteps: 1,816,970,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1816970146...
Checkpoint 1816970146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.40092
Policy Entropy: 2.10354
Value Function Loss: 0.01729

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.60421

Collected Steps per Second: 21,499.18649
Overall Steps per Second: 10,390.06867

Timestep Collection Time: 2.32604
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.81306

Cumulative Model Updates: 217,874
Cumulative Timesteps: 1,817,020,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.62156
Policy Entropy: 2.10690
Value Function Loss: 0.01769

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.62400

Collected Steps per Second: 21,797.95947
Overall Steps per Second: 10,396.61087

Timestep Collection Time: 2.29453
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.81080

Cumulative Model Updates: 217,880
Cumulative Timesteps: 1,817,070,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1817070170...
Checkpoint 1817070170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.16708
Policy Entropy: 2.12082
Value Function Loss: 0.01884

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.63860

Collected Steps per Second: 21,555.70942
Overall Steps per Second: 10,208.04410

Timestep Collection Time: 2.32050
Timestep Consumption Time: 2.57956
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.90006

Cumulative Model Updates: 217,886
Cumulative Timesteps: 1,817,120,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.17322
Policy Entropy: 2.11328
Value Function Loss: 0.01800

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.55533
Value Function Update Magnitude: 0.65310

Collected Steps per Second: 21,779.33074
Overall Steps per Second: 10,355.00208

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.83013

Cumulative Model Updates: 217,892
Cumulative Timesteps: 1,817,170,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1817170206...
Checkpoint 1817170206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.64442
Policy Entropy: 2.10069
Value Function Loss: 0.01789

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 21,880.20642
Overall Steps per Second: 10,347.19525

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.54859
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 4.83513

Cumulative Model Updates: 217,898
Cumulative Timesteps: 1,817,220,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.86371
Policy Entropy: 2.09981
Value Function Loss: 0.01829

Mean KL Divergence: 0.02745
SB3 Clip Fraction: 0.17849
Policy Update Magnitude: 0.52263
Value Function Update Magnitude: 0.63178

Collected Steps per Second: 21,453.00911
Overall Steps per Second: 10,453.22864

Timestep Collection Time: 2.33077
Timestep Consumption Time: 2.45263
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.78340

Cumulative Model Updates: 217,904
Cumulative Timesteps: 1,817,270,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1817270238...
Checkpoint 1817270238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.70910
Policy Entropy: 2.12476
Value Function Loss: 0.01899

Mean KL Divergence: 0.03619
SB3 Clip Fraction: 0.20298
Policy Update Magnitude: 0.63197
Value Function Update Magnitude: 0.62566

Collected Steps per Second: 21,750.42380
Overall Steps per Second: 10,227.87888

Timestep Collection Time: 2.29954
Timestep Consumption Time: 2.59062
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.89016

Cumulative Model Updates: 217,910
Cumulative Timesteps: 1,817,320,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.74519
Policy Entropy: 2.13651
Value Function Loss: 0.01951

Mean KL Divergence: 0.04159
SB3 Clip Fraction: 0.21797
Policy Update Magnitude: 0.63541
Value Function Update Magnitude: 0.62627

Collected Steps per Second: 21,728.53867
Overall Steps per Second: 10,309.73281

Timestep Collection Time: 2.30121
Timestep Consumption Time: 2.54877
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.84998

Cumulative Model Updates: 217,916
Cumulative Timesteps: 1,817,370,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1817370256...
Checkpoint 1817370256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.15495
Policy Entropy: 2.12480
Value Function Loss: 0.01997

Mean KL Divergence: 0.03222
SB3 Clip Fraction: 0.19050
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.64714

Collected Steps per Second: 21,880.12706
Overall Steps per Second: 10,333.90495

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.55347
PPO Batch Consumption Time: 0.30199
Total Iteration Time: 4.83883

Cumulative Model Updates: 217,922
Cumulative Timesteps: 1,817,420,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.12794
Policy Entropy: 2.11054
Value Function Loss: 0.01962

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.16530
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.66872

Collected Steps per Second: 21,738.72118
Overall Steps per Second: 10,458.84326

Timestep Collection Time: 2.30004
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.78064

Cumulative Model Updates: 217,928
Cumulative Timesteps: 1,817,470,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1817470260...
Checkpoint 1817470260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.59214
Policy Entropy: 2.09369
Value Function Loss: 0.01867

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.15146
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.67102

Collected Steps per Second: 21,716.51780
Overall Steps per Second: 10,224.06307

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.58824
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 4.89081

Cumulative Model Updates: 217,934
Cumulative Timesteps: 1,817,520,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.05299
Policy Entropy: 2.11335
Value Function Loss: 0.01808

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.66963

Collected Steps per Second: 21,818.81708
Overall Steps per Second: 10,363.40577

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.82544

Cumulative Model Updates: 217,940
Cumulative Timesteps: 1,817,570,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1817570272...
Checkpoint 1817570272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.35050
Policy Entropy: 2.11580
Value Function Loss: 0.01781

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.66208

Collected Steps per Second: 21,717.66900
Overall Steps per Second: 10,286.37943

Timestep Collection Time: 2.30292
Timestep Consumption Time: 2.55924
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.86216

Cumulative Model Updates: 217,946
Cumulative Timesteps: 1,817,620,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.30488
Policy Entropy: 2.13950
Value Function Loss: 0.01799

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.55588
Value Function Update Magnitude: 0.66095

Collected Steps per Second: 21,868.44352
Overall Steps per Second: 10,440.15696

Timestep Collection Time: 2.28677
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.78997

Cumulative Model Updates: 217,952
Cumulative Timesteps: 1,817,670,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1817670294...
Checkpoint 1817670294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.99782
Policy Entropy: 2.13678
Value Function Loss: 0.01825

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.65605

Collected Steps per Second: 21,151.32575
Overall Steps per Second: 10,254.20988

Timestep Collection Time: 2.36439
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.87702

Cumulative Model Updates: 217,958
Cumulative Timesteps: 1,817,720,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.98199
Policy Entropy: 2.15633
Value Function Loss: 0.01748

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.54606
Value Function Update Magnitude: 0.64919

Collected Steps per Second: 21,684.15575
Overall Steps per Second: 10,336.30438

Timestep Collection Time: 2.30648
Timestep Consumption Time: 2.53220
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.83867

Cumulative Model Updates: 217,964
Cumulative Timesteps: 1,817,770,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1817770318...
Checkpoint 1817770318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.12103
Policy Entropy: 2.13135
Value Function Loss: 0.01730

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.60753

Collected Steps per Second: 21,987.96822
Overall Steps per Second: 10,260.11305

Timestep Collection Time: 2.27443
Timestep Consumption Time: 2.59979
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.87422

Cumulative Model Updates: 217,970
Cumulative Timesteps: 1,817,820,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.92387
Policy Entropy: 2.11792
Value Function Loss: 0.01653

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.53528
Value Function Update Magnitude: 0.58086

Collected Steps per Second: 21,635.37729
Overall Steps per Second: 10,370.42147

Timestep Collection Time: 2.31232
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82410

Cumulative Model Updates: 217,976
Cumulative Timesteps: 1,817,870,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1817870356...
Checkpoint 1817870356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.85600
Policy Entropy: 2.09595
Value Function Loss: 0.01590

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 21,913.82522
Overall Steps per Second: 10,462.96956

Timestep Collection Time: 2.28230
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.78010

Cumulative Model Updates: 217,982
Cumulative Timesteps: 1,817,920,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.50342
Policy Entropy: 2.10520
Value Function Loss: 0.01658

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.52979
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 21,545.82043
Overall Steps per Second: 10,323.74080

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.52338
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.84476

Cumulative Model Updates: 217,988
Cumulative Timesteps: 1,817,970,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1817970386...
Checkpoint 1817970386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.47092
Policy Entropy: 2.13632
Value Function Loss: 0.01728

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.55036

Collected Steps per Second: 21,582.61369
Overall Steps per Second: 10,170.67777

Timestep Collection Time: 2.31770
Timestep Consumption Time: 2.60056
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 4.91826

Cumulative Model Updates: 217,994
Cumulative Timesteps: 1,818,020,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.12881
Policy Entropy: 2.13228
Value Function Loss: 0.01796

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.53532

Collected Steps per Second: 21,740.98785
Overall Steps per Second: 10,376.56480

Timestep Collection Time: 2.30100
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.82106

Cumulative Model Updates: 218,000
Cumulative Timesteps: 1,818,070,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1818070434...
Checkpoint 1818070434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.82505
Policy Entropy: 2.13038
Value Function Loss: 0.01794

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.56565

Collected Steps per Second: 21,898.38629
Overall Steps per Second: 10,455.84784

Timestep Collection Time: 2.28455
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.78469

Cumulative Model Updates: 218,006
Cumulative Timesteps: 1,818,120,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.41711
Policy Entropy: 2.11314
Value Function Loss: 0.01745

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.61528

Collected Steps per Second: 21,762.67578
Overall Steps per Second: 10,298.05444

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.55829
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.85626

Cumulative Model Updates: 218,012
Cumulative Timesteps: 1,818,170,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1818170472...
Checkpoint 1818170472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.14421
Policy Entropy: 2.08640
Value Function Loss: 0.01741

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 21,824.77037
Overall Steps per Second: 10,227.71480

Timestep Collection Time: 2.29180
Timestep Consumption Time: 2.59864
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 4.89044

Cumulative Model Updates: 218,018
Cumulative Timesteps: 1,818,220,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.51731
Policy Entropy: 2.08735
Value Function Loss: 0.01770

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.59064

Collected Steps per Second: 21,632.69525
Overall Steps per Second: 10,385.16252

Timestep Collection Time: 2.31317
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.81841

Cumulative Model Updates: 218,024
Cumulative Timesteps: 1,818,270,530

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1818270530...
Checkpoint 1818270530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.32787
Policy Entropy: 2.09229
Value Function Loss: 0.01716

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 21,754.93302
Overall Steps per Second: 10,438.76048

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.79042

Cumulative Model Updates: 218,030
Cumulative Timesteps: 1,818,320,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.67833
Policy Entropy: 2.09138
Value Function Loss: 0.01719

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.55765

Collected Steps per Second: 22,226.53983
Overall Steps per Second: 10,323.89620

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.59492
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.84565

Cumulative Model Updates: 218,036
Cumulative Timesteps: 1,818,370,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1818370562...
Checkpoint 1818370562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.49829
Policy Entropy: 2.09861
Value Function Loss: 0.01794

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.56738

Collected Steps per Second: 21,781.02168
Overall Steps per Second: 10,213.03468

Timestep Collection Time: 2.29585
Timestep Consumption Time: 2.60044
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 4.89629

Cumulative Model Updates: 218,042
Cumulative Timesteps: 1,818,420,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.36569
Policy Entropy: 2.09412
Value Function Loss: 0.01852

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.57703

Collected Steps per Second: 21,951.63723
Overall Steps per Second: 10,353.70637

Timestep Collection Time: 2.27837
Timestep Consumption Time: 2.55217
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.83054

Cumulative Model Updates: 218,048
Cumulative Timesteps: 1,818,470,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1818470582...
Checkpoint 1818470582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.12639
Policy Entropy: 2.09028
Value Function Loss: 0.01866

Mean KL Divergence: 0.02687
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.52715
Value Function Update Magnitude: 0.60294

Collected Steps per Second: 21,968.48077
Overall Steps per Second: 10,314.19715

Timestep Collection Time: 2.27653
Timestep Consumption Time: 2.57232
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 4.84885

Cumulative Model Updates: 218,054
Cumulative Timesteps: 1,818,520,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.21559
Policy Entropy: 2.08749
Value Function Loss: 0.01765

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.52875
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 21,945.27769
Overall Steps per Second: 10,432.94293

Timestep Collection Time: 2.27839
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 4.79251

Cumulative Model Updates: 218,060
Cumulative Timesteps: 1,818,570,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1818570594...
Checkpoint 1818570594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.86290
Policy Entropy: 2.09493
Value Function Loss: 0.01754

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.60576

Collected Steps per Second: 21,603.19099
Overall Steps per Second: 10,217.90143

Timestep Collection Time: 2.31577
Timestep Consumption Time: 2.58034
PPO Batch Consumption Time: 0.30218
Total Iteration Time: 4.89611

Cumulative Model Updates: 218,066
Cumulative Timesteps: 1,818,620,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.27186
Policy Entropy: 2.10725
Value Function Loss: 0.01779

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.17218
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 22,040.24634
Overall Steps per Second: 10,406.48596

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.53663
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.80566

Cumulative Model Updates: 218,072
Cumulative Timesteps: 1,818,670,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1818670632...
Checkpoint 1818670632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.71565
Policy Entropy: 2.10846
Value Function Loss: 0.01888

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.58399

Collected Steps per Second: 21,458.89972
Overall Steps per Second: 10,243.21838

Timestep Collection Time: 2.33087
Timestep Consumption Time: 2.55216
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.88304

Cumulative Model Updates: 218,078
Cumulative Timesteps: 1,818,720,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.40036
Policy Entropy: 2.12710
Value Function Loss: 0.01840

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.59459

Collected Steps per Second: 21,788.70264
Overall Steps per Second: 10,490.87456

Timestep Collection Time: 2.29569
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.76795

Cumulative Model Updates: 218,084
Cumulative Timesteps: 1,818,770,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1818770670...
Checkpoint 1818770670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.60716
Policy Entropy: 2.11028
Value Function Loss: 0.01765

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.58980

Collected Steps per Second: 21,571.34749
Overall Steps per Second: 10,190.70922

Timestep Collection Time: 2.31845
Timestep Consumption Time: 2.58916
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.90761

Cumulative Model Updates: 218,090
Cumulative Timesteps: 1,818,820,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.29857
Policy Entropy: 2.11809
Value Function Loss: 0.01681

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.58975

Collected Steps per Second: 22,086.33110
Overall Steps per Second: 10,431.40525

Timestep Collection Time: 2.26430
Timestep Consumption Time: 2.52988
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.79418

Cumulative Model Updates: 218,096
Cumulative Timesteps: 1,818,870,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1818870692...
Checkpoint 1818870692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.53432
Policy Entropy: 2.11207
Value Function Loss: 0.01683

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.58153

Collected Steps per Second: 21,159.25832
Overall Steps per Second: 10,213.86260

Timestep Collection Time: 2.36398
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.89727

Cumulative Model Updates: 218,102
Cumulative Timesteps: 1,818,920,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.78042
Policy Entropy: 2.14013
Value Function Loss: 0.01788

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.58107

Collected Steps per Second: 22,042.61961
Overall Steps per Second: 10,501.10889

Timestep Collection Time: 2.26960
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.76407

Cumulative Model Updates: 218,108
Cumulative Timesteps: 1,818,970,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1818970740...
Checkpoint 1818970740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.92063
Policy Entropy: 2.13200
Value Function Loss: 0.01873

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.59794

Collected Steps per Second: 21,488.48899
Overall Steps per Second: 10,507.66209

Timestep Collection Time: 2.32776
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76034

Cumulative Model Updates: 218,114
Cumulative Timesteps: 1,819,020,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.66574
Policy Entropy: 2.11743
Value Function Loss: 0.01823

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 22,345.00987
Overall Steps per Second: 10,489.16392

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.52980
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.76797

Cumulative Model Updates: 218,120
Cumulative Timesteps: 1,819,070,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1819070772...
Checkpoint 1819070772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.35202
Policy Entropy: 2.09564
Value Function Loss: 0.01806

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.61669

Collected Steps per Second: 21,633.59315
Overall Steps per Second: 10,309.78017

Timestep Collection Time: 2.31251
Timestep Consumption Time: 2.53997
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.85248

Cumulative Model Updates: 218,126
Cumulative Timesteps: 1,819,120,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.72351
Policy Entropy: 2.09329
Value Function Loss: 0.01847

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.62848

Collected Steps per Second: 21,817.20167
Overall Steps per Second: 10,452.41780

Timestep Collection Time: 2.29278
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.78569

Cumulative Model Updates: 218,132
Cumulative Timesteps: 1,819,170,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1819170822...
Checkpoint 1819170822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.09197
Policy Entropy: 2.11266
Value Function Loss: 0.01923

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.65724

Collected Steps per Second: 21,649.79224
Overall Steps per Second: 10,281.98870

Timestep Collection Time: 2.31078
Timestep Consumption Time: 2.55481
PPO Batch Consumption Time: 0.30430
Total Iteration Time: 4.86560

Cumulative Model Updates: 218,138
Cumulative Timesteps: 1,819,220,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.32453
Policy Entropy: 2.14491
Value Function Loss: 0.01921

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.67189

Collected Steps per Second: 21,538.41730
Overall Steps per Second: 10,380.95684

Timestep Collection Time: 2.32283
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.81940

Cumulative Model Updates: 218,144
Cumulative Timesteps: 1,819,270,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1819270880...
Checkpoint 1819270880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.08925
Policy Entropy: 2.14883
Value Function Loss: 0.01753

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 21,313.63134
Overall Steps per Second: 10,202.72436

Timestep Collection Time: 2.34610
Timestep Consumption Time: 2.55494
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.90104

Cumulative Model Updates: 218,150
Cumulative Timesteps: 1,819,320,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.36579
Policy Entropy: 2.14647
Value Function Loss: 0.01626

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.61394

Collected Steps per Second: 21,747.85854
Overall Steps per Second: 10,328.82716

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.54185
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.84101

Cumulative Model Updates: 218,156
Cumulative Timesteps: 1,819,370,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1819370886...
Checkpoint 1819370886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.35555
Policy Entropy: 2.11828
Value Function Loss: 0.01701

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 21,640.43551
Overall Steps per Second: 10,340.72723

Timestep Collection Time: 2.31169
Timestep Consumption Time: 2.52607
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.83776

Cumulative Model Updates: 218,162
Cumulative Timesteps: 1,819,420,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.96238
Policy Entropy: 2.12066
Value Function Loss: 0.01715

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.58507

Collected Steps per Second: 22,048.88450
Overall Steps per Second: 10,430.63844

Timestep Collection Time: 2.26869
Timestep Consumption Time: 2.52699
PPO Batch Consumption Time: 0.30341
Total Iteration Time: 4.79568

Cumulative Model Updates: 218,168
Cumulative Timesteps: 1,819,470,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1819470934...
Checkpoint 1819470934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.54657
Policy Entropy: 2.10226
Value Function Loss: 0.01791

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.58045

Collected Steps per Second: 21,442.26919
Overall Steps per Second: 10,203.29771

Timestep Collection Time: 2.33203
Timestep Consumption Time: 2.56874
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.90077

Cumulative Model Updates: 218,174
Cumulative Timesteps: 1,819,520,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.25080
Policy Entropy: 2.12199
Value Function Loss: 0.01719

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.59121

Collected Steps per Second: 21,663.68545
Overall Steps per Second: 10,249.51562

Timestep Collection Time: 2.30856
Timestep Consumption Time: 2.57089
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.87945

Cumulative Model Updates: 218,180
Cumulative Timesteps: 1,819,570,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1819570950...
Checkpoint 1819570950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.30436
Policy Entropy: 2.11637
Value Function Loss: 0.01761

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 21,421.73102
Overall Steps per Second: 10,241.36063

Timestep Collection Time: 2.33539
Timestep Consumption Time: 2.54951
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.88490

Cumulative Model Updates: 218,186
Cumulative Timesteps: 1,819,620,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.86054
Policy Entropy: 2.13992
Value Function Loss: 0.01685

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.62258

Collected Steps per Second: 21,860.27143
Overall Steps per Second: 10,314.98290

Timestep Collection Time: 2.28826
Timestep Consumption Time: 2.56119
PPO Batch Consumption Time: 0.30285
Total Iteration Time: 4.84945

Cumulative Model Updates: 218,192
Cumulative Timesteps: 1,819,671,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1819671000...
Checkpoint 1819671000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.34774
Policy Entropy: 2.14403
Value Function Loss: 0.01729

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.54051
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 21,628.39584
Overall Steps per Second: 10,482.48216

Timestep Collection Time: 2.31242
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.77120

Cumulative Model Updates: 218,198
Cumulative Timesteps: 1,819,721,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.06398
Policy Entropy: 2.16411
Value Function Loss: 0.01708

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 21,932.28491
Overall Steps per Second: 10,414.96164

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.80136

Cumulative Model Updates: 218,204
Cumulative Timesteps: 1,819,771,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1819771020...
Checkpoint 1819771020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.25424
Policy Entropy: 2.16955
Value Function Loss: 0.01724

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.62183

Collected Steps per Second: 21,788.58632
Overall Steps per Second: 10,335.79726

Timestep Collection Time: 2.29524
Timestep Consumption Time: 2.54329
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.83852

Cumulative Model Updates: 218,210
Cumulative Timesteps: 1,819,821,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.11004
Policy Entropy: 2.15156
Value Function Loss: 0.01687

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.53938
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 21,765.34939
Overall Steps per Second: 10,418.49004

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.80050

Cumulative Model Updates: 218,216
Cumulative Timesteps: 1,819,871,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1819871044...
Checkpoint 1819871044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.21168
Policy Entropy: 2.13593
Value Function Loss: 0.01681

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.53398
Value Function Update Magnitude: 0.60164

Collected Steps per Second: 21,608.08639
Overall Steps per Second: 10,233.65404

Timestep Collection Time: 2.31404
Timestep Consumption Time: 2.57199
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.88604

Cumulative Model Updates: 218,222
Cumulative Timesteps: 1,819,921,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.34620
Policy Entropy: 2.11973
Value Function Loss: 0.01723

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.59585

Collected Steps per Second: 21,886.19163
Overall Steps per Second: 10,366.36491

Timestep Collection Time: 2.28592
Timestep Consumption Time: 2.54027
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.82619

Cumulative Model Updates: 218,228
Cumulative Timesteps: 1,819,971,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1819971076...
Checkpoint 1819971076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.03648
Policy Entropy: 2.12832
Value Function Loss: 0.01721

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.59737

Collected Steps per Second: 21,704.61445
Overall Steps per Second: 10,317.97773

Timestep Collection Time: 2.30486
Timestep Consumption Time: 2.54358
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.84843

Cumulative Model Updates: 218,234
Cumulative Timesteps: 1,820,021,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.61473
Policy Entropy: 2.12820
Value Function Loss: 0.01731

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.59530

Collected Steps per Second: 21,530.00249
Overall Steps per Second: 10,328.98742

Timestep Collection Time: 2.32308
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.84229

Cumulative Model Updates: 218,240
Cumulative Timesteps: 1,820,071,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1820071118...
Checkpoint 1820071118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.53085
Policy Entropy: 2.12995
Value Function Loss: 0.01724

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.59096

Collected Steps per Second: 22,567.80133
Overall Steps per Second: 10,455.66878

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.56696
PPO Batch Consumption Time: 0.30145
Total Iteration Time: 4.78286

Cumulative Model Updates: 218,246
Cumulative Timesteps: 1,820,121,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.26481
Policy Entropy: 2.13726
Value Function Loss: 0.01741

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.58736

Collected Steps per Second: 21,412.85198
Overall Steps per Second: 10,277.11066

Timestep Collection Time: 2.33691
Timestep Consumption Time: 2.53216
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.86907

Cumulative Model Updates: 218,252
Cumulative Timesteps: 1,820,171,166

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1820171166...
Checkpoint 1820171166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.71463
Policy Entropy: 2.15048
Value Function Loss: 0.01719

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.60200

Collected Steps per Second: 21,393.79245
Overall Steps per Second: 10,297.55419

Timestep Collection Time: 2.33797
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.85727

Cumulative Model Updates: 218,258
Cumulative Timesteps: 1,820,221,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.54659
Policy Entropy: 2.14617
Value Function Loss: 0.01720

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.60697

Collected Steps per Second: 21,570.64308
Overall Steps per Second: 10,436.52367

Timestep Collection Time: 2.31797
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.79087

Cumulative Model Updates: 218,264
Cumulative Timesteps: 1,820,271,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1820271184...
Checkpoint 1820271184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.49003
Policy Entropy: 2.13133
Value Function Loss: 0.01655

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 21,858.92765
Overall Steps per Second: 10,245.03515

Timestep Collection Time: 2.28776
Timestep Consumption Time: 2.59343
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 4.88119

Cumulative Model Updates: 218,270
Cumulative Timesteps: 1,820,321,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.99688
Policy Entropy: 2.11884
Value Function Loss: 0.01656

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.60538

Collected Steps per Second: 21,871.31384
Overall Steps per Second: 10,373.05162

Timestep Collection Time: 2.28711
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.82230

Cumulative Model Updates: 218,276
Cumulative Timesteps: 1,820,371,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1820371214...
Checkpoint 1820371214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.19984
Policy Entropy: 2.10313
Value Function Loss: 0.01655

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 21,746.39060
Overall Steps per Second: 10,252.39863

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.57778
PPO Batch Consumption Time: 0.30258
Total Iteration Time: 4.87710

Cumulative Model Updates: 218,282
Cumulative Timesteps: 1,820,421,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.61475
Policy Entropy: 2.10654
Value Function Loss: 0.01668

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.57969

Collected Steps per Second: 21,663.29947
Overall Steps per Second: 10,379.49553

Timestep Collection Time: 2.30805
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.81719

Cumulative Model Updates: 218,288
Cumulative Timesteps: 1,820,471,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1820471216...
Checkpoint 1820471216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.64222
Policy Entropy: 2.09633
Value Function Loss: 0.01695

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.17450
Policy Update Magnitude: 0.53352
Value Function Update Magnitude: 0.57980

Collected Steps per Second: 21,607.90490
Overall Steps per Second: 10,385.20133

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.81724

Cumulative Model Updates: 218,294
Cumulative Timesteps: 1,820,521,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.47862
Policy Entropy: 2.11212
Value Function Loss: 0.01698

Mean KL Divergence: 0.02940
SB3 Clip Fraction: 0.17931
Policy Update Magnitude: 0.52654
Value Function Update Magnitude: 0.59734

Collected Steps per Second: 21,964.64334
Overall Steps per Second: 10,418.13107

Timestep Collection Time: 2.27639
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.79933

Cumulative Model Updates: 218,300
Cumulative Timesteps: 1,820,571,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1820571244...
Checkpoint 1820571244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.58110
Policy Entropy: 2.11009
Value Function Loss: 0.01714

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.16847
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.62254

Collected Steps per Second: 21,610.62333
Overall Steps per Second: 10,204.99904

Timestep Collection Time: 2.31368
Timestep Consumption Time: 2.58588
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 4.89956

Cumulative Model Updates: 218,306
Cumulative Timesteps: 1,820,621,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.34513
Policy Entropy: 2.13428
Value Function Loss: 0.01681

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.16039
Policy Update Magnitude: 0.56107
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 21,689.06828
Overall Steps per Second: 10,319.37534

Timestep Collection Time: 2.30605
Timestep Consumption Time: 2.54076
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.84681

Cumulative Model Updates: 218,312
Cumulative Timesteps: 1,820,671,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1820671260...
Checkpoint 1820671260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.86022
Policy Entropy: 2.13505
Value Function Loss: 0.01771

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.56551
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 21,650.06890
Overall Steps per Second: 10,324.01505

Timestep Collection Time: 2.31020
Timestep Consumption Time: 2.53443
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.84463

Cumulative Model Updates: 218,318
Cumulative Timesteps: 1,820,721,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.31365
Policy Entropy: 2.17021
Value Function Loss: 0.01674

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 21,377.24031
Overall Steps per Second: 10,469.41974

Timestep Collection Time: 2.33903
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.77600

Cumulative Model Updates: 218,324
Cumulative Timesteps: 1,820,771,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1820771278...
Checkpoint 1820771278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.28340
Policy Entropy: 2.13915
Value Function Loss: 0.01695

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 21,650.28550
Overall Steps per Second: 10,194.19320

Timestep Collection Time: 2.30972
Timestep Consumption Time: 2.59563
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.90534

Cumulative Model Updates: 218,330
Cumulative Timesteps: 1,820,821,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.89521
Policy Entropy: 2.13874
Value Function Loss: 0.01776

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.58917

Collected Steps per Second: 21,653.73132
Overall Steps per Second: 10,336.32894

Timestep Collection Time: 2.30972
Timestep Consumption Time: 2.52894
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.83866

Cumulative Model Updates: 218,336
Cumulative Timesteps: 1,820,871,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1820871298...
Checkpoint 1820871298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.01043
Policy Entropy: 2.13157
Value Function Loss: 0.01787

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.60507

Collected Steps per Second: 21,898.34705
Overall Steps per Second: 10,331.45481

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.55744
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.84172

Cumulative Model Updates: 218,342
Cumulative Timesteps: 1,820,921,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.34515
Policy Entropy: 2.12356
Value Function Loss: 0.01816

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.55955
Value Function Update Magnitude: 0.63078

Collected Steps per Second: 20,975.35396
Overall Steps per Second: 10,281.31203

Timestep Collection Time: 2.38394
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.86358

Cumulative Model Updates: 218,348
Cumulative Timesteps: 1,820,971,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1820971324...
Checkpoint 1820971324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.70402
Policy Entropy: 2.11794
Value Function Loss: 0.01746

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.63427

Collected Steps per Second: 20,961.99397
Overall Steps per Second: 10,328.45930

Timestep Collection Time: 2.38556
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.84157

Cumulative Model Updates: 218,354
Cumulative Timesteps: 1,821,021,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.18968
Policy Entropy: 2.11265
Value Function Loss: 0.01817

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.55659
Value Function Update Magnitude: 0.61771

Collected Steps per Second: 21,781.63325
Overall Steps per Second: 10,361.39047

Timestep Collection Time: 2.29606
Timestep Consumption Time: 2.53070
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.82677

Cumulative Model Updates: 218,360
Cumulative Timesteps: 1,821,071,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1821071342...
Checkpoint 1821071342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.41231
Policy Entropy: 2.15437
Value Function Loss: 0.01786

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 21,214.47393
Overall Steps per Second: 10,224.26283

Timestep Collection Time: 2.35820
Timestep Consumption Time: 2.53487
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.89307

Cumulative Model Updates: 218,366
Cumulative Timesteps: 1,821,121,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.23155
Policy Entropy: 2.17085
Value Function Loss: 0.01693

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.54365
Value Function Update Magnitude: 0.62778

Collected Steps per Second: 22,244.58050
Overall Steps per Second: 10,496.03220

Timestep Collection Time: 2.24774
Timestep Consumption Time: 2.51597
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.76370

Cumulative Model Updates: 218,372
Cumulative Timesteps: 1,821,171,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1821171370...
Checkpoint 1821171370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.45659
Policy Entropy: 2.15065
Value Function Loss: 0.01701

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 21,697.45432
Overall Steps per Second: 10,445.86596

Timestep Collection Time: 2.30562
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 4.78907

Cumulative Model Updates: 218,378
Cumulative Timesteps: 1,821,221,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.41109
Policy Entropy: 2.16528
Value Function Loss: 0.01773

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 21,450.76224
Overall Steps per Second: 10,307.08390

Timestep Collection Time: 2.33092
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.85103

Cumulative Model Updates: 218,384
Cumulative Timesteps: 1,821,271,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1821271396...
Checkpoint 1821271396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.49967
Policy Entropy: 2.16992
Value Function Loss: 0.01710

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.64765

Collected Steps per Second: 21,248.97629
Overall Steps per Second: 10,189.00498

Timestep Collection Time: 2.35418
Timestep Consumption Time: 2.55542
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.90961

Cumulative Model Updates: 218,390
Cumulative Timesteps: 1,821,321,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.17602
Policy Entropy: 2.17059
Value Function Loss: 0.01730

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.53926
Value Function Update Magnitude: 0.61190

Collected Steps per Second: 21,836.89612
Overall Steps per Second: 10,415.66134

Timestep Collection Time: 2.28970
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.80046

Cumulative Model Updates: 218,396
Cumulative Timesteps: 1,821,371,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1821371420...
Checkpoint 1821371420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.42803
Policy Entropy: 2.15126
Value Function Loss: 0.01827

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 21,619.08454
Overall Steps per Second: 10,462.25572

Timestep Collection Time: 2.31379
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.78119

Cumulative Model Updates: 218,402
Cumulative Timesteps: 1,821,421,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.85023
Policy Entropy: 2.14731
Value Function Loss: 0.01856

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.63934

Collected Steps per Second: 22,209.53137
Overall Steps per Second: 10,337.64786

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.58665
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 4.83901

Cumulative Model Updates: 218,408
Cumulative Timesteps: 1,821,471,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1821471466...
Checkpoint 1821471466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.99069
Policy Entropy: 2.15772
Value Function Loss: 0.01781

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 21,623.25945
Overall Steps per Second: 10,220.99770

Timestep Collection Time: 2.31288
Timestep Consumption Time: 2.58018
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.89306

Cumulative Model Updates: 218,414
Cumulative Timesteps: 1,821,521,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.87774
Policy Entropy: 2.15126
Value Function Loss: 0.01739

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.64377

Collected Steps per Second: 21,460.67405
Overall Steps per Second: 10,278.20555

Timestep Collection Time: 2.33050
Timestep Consumption Time: 2.53553
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.86602

Cumulative Model Updates: 218,420
Cumulative Timesteps: 1,821,571,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1821571492...
Checkpoint 1821571492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.69908
Policy Entropy: 2.15309
Value Function Loss: 0.01708

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 21,722.49926
Overall Steps per Second: 10,475.97540

Timestep Collection Time: 2.30277
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.77493

Cumulative Model Updates: 218,426
Cumulative Timesteps: 1,821,621,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.42771
Policy Entropy: 2.15231
Value Function Loss: 0.01631

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.61497

Collected Steps per Second: 21,965.07724
Overall Steps per Second: 10,271.01409

Timestep Collection Time: 2.27680
Timestep Consumption Time: 2.59225
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.86904

Cumulative Model Updates: 218,432
Cumulative Timesteps: 1,821,671,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1821671524...
Checkpoint 1821671524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.60519
Policy Entropy: 2.15767
Value Function Loss: 0.01667

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.61293

Collected Steps per Second: 21,534.59803
Overall Steps per Second: 10,198.45822

Timestep Collection Time: 2.32240
Timestep Consumption Time: 2.58148
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.90388

Cumulative Model Updates: 218,438
Cumulative Timesteps: 1,821,721,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.84531
Policy Entropy: 2.15514
Value Function Loss: 0.01681

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.53589
Value Function Update Magnitude: 0.59271

Collected Steps per Second: 21,318.44886
Overall Steps per Second: 10,231.60119

Timestep Collection Time: 2.34661
Timestep Consumption Time: 2.54276
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.88936

Cumulative Model Updates: 218,444
Cumulative Timesteps: 1,821,771,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1821771562...
Checkpoint 1821771562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.19922
Policy Entropy: 2.13935
Value Function Loss: 0.01724

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.57407

Collected Steps per Second: 21,742.06988
Overall Steps per Second: 10,398.90217

Timestep Collection Time: 2.30079
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.81051

Cumulative Model Updates: 218,450
Cumulative Timesteps: 1,821,821,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.10740
Policy Entropy: 2.16018
Value Function Loss: 0.01721

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.57499

Collected Steps per Second: 21,719.12008
Overall Steps per Second: 10,507.93309

Timestep Collection Time: 2.30240
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.75888

Cumulative Model Updates: 218,456
Cumulative Timesteps: 1,821,871,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1821871592...
Checkpoint 1821871592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.78036
Policy Entropy: 2.13945
Value Function Loss: 0.01725

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.58902

Collected Steps per Second: 21,520.72317
Overall Steps per Second: 10,193.50618

Timestep Collection Time: 2.32334
Timestep Consumption Time: 2.58174
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.90508

Cumulative Model Updates: 218,462
Cumulative Timesteps: 1,821,921,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.05284
Policy Entropy: 2.15327
Value Function Loss: 0.01747

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.60215

Collected Steps per Second: 21,830.42731
Overall Steps per Second: 10,232.32981

Timestep Collection Time: 2.29166
Timestep Consumption Time: 2.59755
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.88921

Cumulative Model Updates: 218,468
Cumulative Timesteps: 1,821,971,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1821971620...
Checkpoint 1821971620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.25153
Policy Entropy: 2.12967
Value Function Loss: 0.01758

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 21,617.75924
Overall Steps per Second: 10,362.19901

Timestep Collection Time: 2.31365
Timestep Consumption Time: 2.51312
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82677

Cumulative Model Updates: 218,474
Cumulative Timesteps: 1,822,021,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.34522
Policy Entropy: 2.17566
Value Function Loss: 0.01670

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.54796
Value Function Update Magnitude: 0.62129

Collected Steps per Second: 22,714.17498
Overall Steps per Second: 10,547.00229

Timestep Collection Time: 2.20215
Timestep Consumption Time: 2.54043
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.74258

Cumulative Model Updates: 218,480
Cumulative Timesteps: 1,822,071,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1822071656...
Checkpoint 1822071656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.75994
Policy Entropy: 2.16057
Value Function Loss: 0.01719

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.60041

Collected Steps per Second: 21,766.64495
Overall Steps per Second: 10,249.73291

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.58263
PPO Batch Consumption Time: 0.30478
Total Iteration Time: 4.88110

Cumulative Model Updates: 218,486
Cumulative Timesteps: 1,822,121,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.87141
Policy Entropy: 2.14888
Value Function Loss: 0.01782

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.60278

Collected Steps per Second: 21,835.75787
Overall Steps per Second: 10,345.15860

Timestep Collection Time: 2.29055
Timestep Consumption Time: 2.54417
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.83473

Cumulative Model Updates: 218,492
Cumulative Timesteps: 1,822,171,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1822171702...
Checkpoint 1822171702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.31904
Policy Entropy: 2.12189
Value Function Loss: 0.01891

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.60697

Collected Steps per Second: 21,434.91898
Overall Steps per Second: 10,281.90245

Timestep Collection Time: 2.33330
Timestep Consumption Time: 2.53098
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.86427

Cumulative Model Updates: 218,498
Cumulative Timesteps: 1,822,221,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.87223
Policy Entropy: 2.12908
Value Function Loss: 0.01885

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.59754

Collected Steps per Second: 22,013.41478
Overall Steps per Second: 10,441.63126

Timestep Collection Time: 2.27152
Timestep Consumption Time: 2.51738
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 4.78891

Cumulative Model Updates: 218,504
Cumulative Timesteps: 1,822,271,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1822271720...
Checkpoint 1822271720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.01565
Policy Entropy: 2.13536
Value Function Loss: 0.01830

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 21,595.07579
Overall Steps per Second: 10,220.71781

Timestep Collection Time: 2.31636
Timestep Consumption Time: 2.57782
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.89418

Cumulative Model Updates: 218,510
Cumulative Timesteps: 1,822,321,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.17873
Policy Entropy: 2.13148
Value Function Loss: 0.01821

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.59568

Collected Steps per Second: 21,627.16064
Overall Steps per Second: 10,302.33884

Timestep Collection Time: 2.31283
Timestep Consumption Time: 2.54238
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.85521

Cumulative Model Updates: 218,516
Cumulative Timesteps: 1,822,371,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1822371762...
Checkpoint 1822371762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.85468
Policy Entropy: 2.13672
Value Function Loss: 0.01813

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 21,910.49705
Overall Steps per Second: 10,343.53429

Timestep Collection Time: 2.28302
Timestep Consumption Time: 2.55305
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.83606

Cumulative Model Updates: 218,522
Cumulative Timesteps: 1,822,421,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.12392
Policy Entropy: 2.13499
Value Function Loss: 0.01843

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 21,954.93684
Overall Steps per Second: 10,497.15289

Timestep Collection Time: 2.27767
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.76377

Cumulative Model Updates: 218,528
Cumulative Timesteps: 1,822,471,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1822471790...
Checkpoint 1822471790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.60014
Policy Entropy: 2.14542
Value Function Loss: 0.01748

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.61617

Collected Steps per Second: 21,792.03040
Overall Steps per Second: 10,252.94087

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.58254
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.87723

Cumulative Model Updates: 218,534
Cumulative Timesteps: 1,822,521,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.23779
Policy Entropy: 2.12384
Value Function Loss: 0.01878

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 21,806.22521
Overall Steps per Second: 10,341.28857

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.54318
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.83711

Cumulative Model Updates: 218,540
Cumulative Timesteps: 1,822,571,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1822571818...
Checkpoint 1822571818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.78610
Policy Entropy: 2.15400
Value Function Loss: 0.01739

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.55348
Value Function Update Magnitude: 0.61727

Collected Steps per Second: 21,656.36237
Overall Steps per Second: 10,246.63763

Timestep Collection Time: 2.30999
Timestep Consumption Time: 2.57220
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.88219

Cumulative Model Updates: 218,546
Cumulative Timesteps: 1,822,621,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.63242
Policy Entropy: 2.14334
Value Function Loss: 0.01788

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 21,663.73557
Overall Steps per Second: 10,462.11356

Timestep Collection Time: 2.30920
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.78163

Cumulative Model Updates: 218,552
Cumulative Timesteps: 1,822,671,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1822671870...
Checkpoint 1822671870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.30844
Policy Entropy: 2.12012
Value Function Loss: 0.01732

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.60450

Collected Steps per Second: 21,909.85886
Overall Steps per Second: 10,254.76286

Timestep Collection Time: 2.28308
Timestep Consumption Time: 2.59485
PPO Batch Consumption Time: 0.30441
Total Iteration Time: 4.87793

Cumulative Model Updates: 218,558
Cumulative Timesteps: 1,822,721,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.23073
Policy Entropy: 2.09322
Value Function Loss: 0.01771

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.61058

Collected Steps per Second: 21,734.03889
Overall Steps per Second: 10,327.78093

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.54260
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.84480

Cumulative Model Updates: 218,564
Cumulative Timesteps: 1,822,771,928

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1822771928...
Checkpoint 1822771928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.33103
Policy Entropy: 2.09413
Value Function Loss: 0.01711

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 21,817.73600
Overall Steps per Second: 10,301.97629

Timestep Collection Time: 2.29199
Timestep Consumption Time: 2.56203
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.85402

Cumulative Model Updates: 218,570
Cumulative Timesteps: 1,822,821,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.32017
Policy Entropy: 2.13371
Value Function Loss: 0.01711

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 21,873.64320
Overall Steps per Second: 10,455.89059

Timestep Collection Time: 2.28595
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.78218

Cumulative Model Updates: 218,576
Cumulative Timesteps: 1,822,871,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1822871936...
Checkpoint 1822871936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.73714
Policy Entropy: 2.13100
Value Function Loss: 0.01769

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 21,668.70040
Overall Steps per Second: 10,213.14897

Timestep Collection Time: 2.30914
Timestep Consumption Time: 2.59004
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 4.89917

Cumulative Model Updates: 218,582
Cumulative Timesteps: 1,822,921,972

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.26587
Policy Entropy: 2.12081
Value Function Loss: 0.01679

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.53615
Value Function Update Magnitude: 0.62705

Collected Steps per Second: 21,677.70474
Overall Steps per Second: 10,327.61103

Timestep Collection Time: 2.30735
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.84313

Cumulative Model Updates: 218,588
Cumulative Timesteps: 1,822,971,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1822971990...
Checkpoint 1822971990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.90900
Policy Entropy: 2.09731
Value Function Loss: 0.01681

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.60679

Collected Steps per Second: 21,686.36339
Overall Steps per Second: 10,346.93529

Timestep Collection Time: 2.30661
Timestep Consumption Time: 2.52786
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.83448

Cumulative Model Updates: 218,594
Cumulative Timesteps: 1,823,022,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.66537
Policy Entropy: 2.08624
Value Function Loss: 0.01629

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.58533

Collected Steps per Second: 21,543.58313
Overall Steps per Second: 10,451.39553

Timestep Collection Time: 2.32116
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.78462

Cumulative Model Updates: 218,600
Cumulative Timesteps: 1,823,072,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1823072018...
Checkpoint 1823072018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.05968
Policy Entropy: 2.08363
Value Function Loss: 0.01750

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.57405

Collected Steps per Second: 21,982.23617
Overall Steps per Second: 10,329.55983

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.56745
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.84338

Cumulative Model Updates: 218,606
Cumulative Timesteps: 1,823,122,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.75176
Policy Entropy: 2.09239
Value Function Loss: 0.01649

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 21,742.07980
Overall Steps per Second: 10,348.17911

Timestep Collection Time: 2.30042
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.83331

Cumulative Model Updates: 218,612
Cumulative Timesteps: 1,823,172,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1823172064...
Checkpoint 1823172064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.72501
Policy Entropy: 2.09947
Value Function Loss: 0.01652

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.58070

Collected Steps per Second: 21,353.03779
Overall Steps per Second: 10,195.19990

Timestep Collection Time: 2.34262
Timestep Consumption Time: 2.56381
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.90643

Cumulative Model Updates: 218,618
Cumulative Timesteps: 1,823,222,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.14269
Policy Entropy: 2.11514
Value Function Loss: 0.01628

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.53329
Value Function Update Magnitude: 0.57779

Collected Steps per Second: 21,831.58274
Overall Steps per Second: 10,461.03268

Timestep Collection Time: 2.29053
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.78022

Cumulative Model Updates: 218,624
Cumulative Timesteps: 1,823,272,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1823272092...
Checkpoint 1823272092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.71942
Policy Entropy: 2.10635
Value Function Loss: 0.01716

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.57398

Collected Steps per Second: 21,900.13163
Overall Steps per Second: 10,296.08599

Timestep Collection Time: 2.28309
Timestep Consumption Time: 2.57312
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 4.85621

Cumulative Model Updates: 218,630
Cumulative Timesteps: 1,823,322,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.29427
Policy Entropy: 2.10021
Value Function Loss: 0.01693

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.58209

Collected Steps per Second: 21,529.03038
Overall Steps per Second: 10,277.62915

Timestep Collection Time: 2.32300
Timestep Consumption Time: 2.54310
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.86610

Cumulative Model Updates: 218,636
Cumulative Timesteps: 1,823,372,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1823372104...
Checkpoint 1823372104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.35910
Policy Entropy: 2.08832
Value Function Loss: 0.01806

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.57911

Collected Steps per Second: 21,648.78789
Overall Steps per Second: 10,291.29767

Timestep Collection Time: 2.31034
Timestep Consumption Time: 2.54969
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.86003

Cumulative Model Updates: 218,642
Cumulative Timesteps: 1,823,422,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.96696
Policy Entropy: 2.08075
Value Function Loss: 0.01774

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.58864

Collected Steps per Second: 21,890.55144
Overall Steps per Second: 10,441.04972

Timestep Collection Time: 2.28528
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.79128

Cumulative Model Updates: 218,648
Cumulative Timesteps: 1,823,472,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1823472146...
Checkpoint 1823472146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.45820
Policy Entropy: 2.10841
Value Function Loss: 0.01722

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.52880
Value Function Update Magnitude: 0.58948

Collected Steps per Second: 22,348.33929
Overall Steps per Second: 10,443.09556

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.55065
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.78804

Cumulative Model Updates: 218,654
Cumulative Timesteps: 1,823,522,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.26684
Policy Entropy: 2.11252
Value Function Loss: 0.01701

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.58396

Collected Steps per Second: 21,913.60340
Overall Steps per Second: 10,242.06610

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.60056
PPO Batch Consumption Time: 0.30412
Total Iteration Time: 4.88261

Cumulative Model Updates: 218,660
Cumulative Timesteps: 1,823,572,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1823572156...
Checkpoint 1823572156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.85251
Policy Entropy: 2.12713
Value Function Loss: 0.01737

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.59345

Collected Steps per Second: 21,448.35682
Overall Steps per Second: 10,213.91377

Timestep Collection Time: 2.33155
Timestep Consumption Time: 2.56451
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.89607

Cumulative Model Updates: 218,666
Cumulative Timesteps: 1,823,622,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.02081
Policy Entropy: 2.08574
Value Function Loss: 0.01815

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.58578

Collected Steps per Second: 21,913.82522
Overall Steps per Second: 10,470.51418

Timestep Collection Time: 2.28258
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.77722

Cumulative Model Updates: 218,672
Cumulative Timesteps: 1,823,672,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1823672184...
Checkpoint 1823672184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.75874
Policy Entropy: 2.07450
Value Function Loss: 0.01760

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.58362

Collected Steps per Second: 21,682.05513
Overall Steps per Second: 10,211.46800

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.59123
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 4.89802

Cumulative Model Updates: 218,678
Cumulative Timesteps: 1,823,722,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.39904
Policy Entropy: 2.07395
Value Function Loss: 0.01736

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.59155

Collected Steps per Second: 21,947.32572
Overall Steps per Second: 10,373.71060

Timestep Collection Time: 2.27855
Timestep Consumption Time: 2.54210
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.82065

Cumulative Model Updates: 218,684
Cumulative Timesteps: 1,823,772,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1823772208...
Checkpoint 1823772208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.52832
Policy Entropy: 2.10252
Value Function Loss: 0.01782

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 21,681.30630
Overall Steps per Second: 10,283.11003

Timestep Collection Time: 2.30632
Timestep Consumption Time: 2.55641
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.86273

Cumulative Model Updates: 218,690
Cumulative Timesteps: 1,823,822,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.60296
Policy Entropy: 2.08997
Value Function Loss: 0.01825

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 21,765.56731
Overall Steps per Second: 10,401.40158

Timestep Collection Time: 2.29858
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.80993

Cumulative Model Updates: 218,696
Cumulative Timesteps: 1,823,872,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1823872242...
Checkpoint 1823872242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.03691
Policy Entropy: 2.08597
Value Function Loss: 0.01682

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.58585

Collected Steps per Second: 21,390.27094
Overall Steps per Second: 10,312.39445

Timestep Collection Time: 2.33779
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 4.84912

Cumulative Model Updates: 218,702
Cumulative Timesteps: 1,823,922,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.10619
Policy Entropy: 2.05819
Value Function Loss: 0.01669

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 22,129.87362
Overall Steps per Second: 10,373.73842

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.56221
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.82314

Cumulative Model Updates: 218,708
Cumulative Timesteps: 1,823,972,282

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1823972282...
Checkpoint 1823972282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.10722
Policy Entropy: 2.07700
Value Function Loss: 0.01606

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.57671

Collected Steps per Second: 21,749.70161
Overall Steps per Second: 10,204.63503

Timestep Collection Time: 2.29953
Timestep Consumption Time: 2.60158
PPO Batch Consumption Time: 0.30529
Total Iteration Time: 4.90111

Cumulative Model Updates: 218,714
Cumulative Timesteps: 1,824,022,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.70338
Policy Entropy: 2.06509
Value Function Loss: 0.01695

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.57652

Collected Steps per Second: 22,123.23418
Overall Steps per Second: 10,505.02864

Timestep Collection Time: 2.26061
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76077

Cumulative Model Updates: 218,720
Cumulative Timesteps: 1,824,072,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1824072308...
Checkpoint 1824072308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.71851
Policy Entropy: 2.08378
Value Function Loss: 0.01648

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.53502
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 21,255.98279
Overall Steps per Second: 10,337.12716

Timestep Collection Time: 2.35237
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.83713

Cumulative Model Updates: 218,726
Cumulative Timesteps: 1,824,122,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.55131
Policy Entropy: 2.06159
Value Function Loss: 0.01810

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.57659

Collected Steps per Second: 22,081.37077
Overall Steps per Second: 10,304.22691

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.58834
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.85296

Cumulative Model Updates: 218,732
Cumulative Timesteps: 1,824,172,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1824172316...
Checkpoint 1824172316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.30527
Policy Entropy: 2.05232
Value Function Loss: 0.01800

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.61733

Collected Steps per Second: 21,664.68641
Overall Steps per Second: 10,219.74411

Timestep Collection Time: 2.30938
Timestep Consumption Time: 2.58624
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.89562

Cumulative Model Updates: 218,738
Cumulative Timesteps: 1,824,222,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.17114
Policy Entropy: 2.07321
Value Function Loss: 0.01764

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.55747
Value Function Update Magnitude: 0.62904

Collected Steps per Second: 21,951.00301
Overall Steps per Second: 10,478.38874

Timestep Collection Time: 2.27898
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.77421

Cumulative Model Updates: 218,744
Cumulative Timesteps: 1,824,272,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1824272374...
Checkpoint 1824272374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.42587
Policy Entropy: 2.09655
Value Function Loss: 0.01810

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.62785

Collected Steps per Second: 21,321.60249
Overall Steps per Second: 10,355.67247

Timestep Collection Time: 2.34513
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.82846

Cumulative Model Updates: 218,750
Cumulative Timesteps: 1,824,322,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.22966
Policy Entropy: 2.13246
Value Function Loss: 0.01786

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 21,931.54377
Overall Steps per Second: 10,315.29625

Timestep Collection Time: 2.28073
Timestep Consumption Time: 2.56838
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.84911

Cumulative Model Updates: 218,756
Cumulative Timesteps: 1,824,372,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1824372396...
Checkpoint 1824372396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.14249
Policy Entropy: 2.11827
Value Function Loss: 0.01844

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.64479

Collected Steps per Second: 21,531.33633
Overall Steps per Second: 10,213.38801

Timestep Collection Time: 2.32285
Timestep Consumption Time: 2.57406
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.89691

Cumulative Model Updates: 218,762
Cumulative Timesteps: 1,824,422,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.21584
Policy Entropy: 2.11664
Value Function Loss: 0.01679

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.63061

Collected Steps per Second: 21,573.20041
Overall Steps per Second: 10,345.98851

Timestep Collection Time: 2.31862
Timestep Consumption Time: 2.51611
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.83472

Cumulative Model Updates: 218,768
Cumulative Timesteps: 1,824,472,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1824472430...
Checkpoint 1824472430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.07822
Policy Entropy: 2.08900
Value Function Loss: 0.01658

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 21,482.71359
Overall Steps per Second: 10,330.70676

Timestep Collection Time: 2.32801
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 4.84110

Cumulative Model Updates: 218,774
Cumulative Timesteps: 1,824,522,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.72431
Policy Entropy: 2.07759
Value Function Loss: 0.01745

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.62078

Collected Steps per Second: 22,003.41851
Overall Steps per Second: 10,435.27899

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.52058
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.79431

Cumulative Model Updates: 218,780
Cumulative Timesteps: 1,824,572,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1824572472...
Checkpoint 1824572472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.61387
Policy Entropy: 2.08760
Value Function Loss: 0.01737

Mean KL Divergence: 0.02683
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.62514

Collected Steps per Second: 20,844.38334
Overall Steps per Second: 10,143.26079

Timestep Collection Time: 2.40026
Timestep Consumption Time: 2.53227
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.93254

Cumulative Model Updates: 218,786
Cumulative Timesteps: 1,824,622,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.40632
Policy Entropy: 2.10431
Value Function Loss: 0.01766

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 22,151.56568
Overall Steps per Second: 10,460.89429

Timestep Collection Time: 2.25853
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.78257

Cumulative Model Updates: 218,792
Cumulative Timesteps: 1,824,672,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1824672534...
Checkpoint 1824672534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.64511
Policy Entropy: 2.11528
Value Function Loss: 0.01656

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.60530

Collected Steps per Second: 21,498.80147
Overall Steps per Second: 10,279.38553

Timestep Collection Time: 2.32590
Timestep Consumption Time: 2.53860
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.86449

Cumulative Model Updates: 218,798
Cumulative Timesteps: 1,824,722,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.45520
Policy Entropy: 2.12336
Value Function Loss: 0.01699

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.57923

Collected Steps per Second: 21,851.63897
Overall Steps per Second: 10,461.11947

Timestep Collection Time: 2.28926
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.78190

Cumulative Model Updates: 218,804
Cumulative Timesteps: 1,824,772,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1824772562...
Checkpoint 1824772562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.47095
Policy Entropy: 2.13714
Value Function Loss: 0.01727

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.53491
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 21,588.00383
Overall Steps per Second: 10,217.30930

Timestep Collection Time: 2.31731
Timestep Consumption Time: 2.57890
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.89620

Cumulative Model Updates: 218,810
Cumulative Timesteps: 1,824,822,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.28252
Policy Entropy: 2.16598
Value Function Loss: 0.01651

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.59296

Collected Steps per Second: 21,803.66659
Overall Steps per Second: 10,360.50756

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.53435
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.82891

Cumulative Model Updates: 218,816
Cumulative Timesteps: 1,824,872,618

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1824872618...
Checkpoint 1824872618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.22745
Policy Entropy: 2.15284
Value Function Loss: 0.01655

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.60501

Collected Steps per Second: 21,451.21119
Overall Steps per Second: 10,307.25052

Timestep Collection Time: 2.33190
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.85309

Cumulative Model Updates: 218,822
Cumulative Timesteps: 1,824,922,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.46802
Policy Entropy: 2.11116
Value Function Loss: 0.01657

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.59063

Collected Steps per Second: 22,176.14179
Overall Steps per Second: 10,504.04811

Timestep Collection Time: 2.25495
Timestep Consumption Time: 2.50569
PPO Batch Consumption Time: 0.30367
Total Iteration Time: 4.76064

Cumulative Model Updates: 218,828
Cumulative Timesteps: 1,824,972,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1824972646...
Checkpoint 1824972646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.25379
Policy Entropy: 2.10609
Value Function Loss: 0.01679

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.57344

Collected Steps per Second: 21,720.29890
Overall Steps per Second: 10,225.72736

Timestep Collection Time: 2.30338
Timestep Consumption Time: 2.58919
PPO Batch Consumption Time: 0.30186
Total Iteration Time: 4.89256

Cumulative Model Updates: 218,834
Cumulative Timesteps: 1,825,022,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.42269
Policy Entropy: 2.08566
Value Function Loss: 0.01633

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.57770

Collected Steps per Second: 21,871.60743
Overall Steps per Second: 10,389.71829

Timestep Collection Time: 2.28707
Timestep Consumption Time: 2.52749
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.81457

Cumulative Model Updates: 218,840
Cumulative Timesteps: 1,825,072,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1825072698...
Checkpoint 1825072698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.46461
Policy Entropy: 2.11100
Value Function Loss: 0.01606

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 21,414.43431
Overall Steps per Second: 10,183.83357

Timestep Collection Time: 2.33534
Timestep Consumption Time: 2.57538
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 4.91072

Cumulative Model Updates: 218,846
Cumulative Timesteps: 1,825,122,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.74804
Policy Entropy: 2.08713
Value Function Loss: 0.01670

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.54308
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 21,734.82239
Overall Steps per Second: 10,487.31266

Timestep Collection Time: 2.30156
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.76995

Cumulative Model Updates: 218,852
Cumulative Timesteps: 1,825,172,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1825172732...
Checkpoint 1825172732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.34989
Policy Entropy: 2.10556
Value Function Loss: 0.01680

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 21,799.17623
Overall Steps per Second: 10,215.49647

Timestep Collection Time: 2.29376
Timestep Consumption Time: 2.60096
PPO Batch Consumption Time: 0.30500
Total Iteration Time: 4.89472

Cumulative Model Updates: 218,858
Cumulative Timesteps: 1,825,222,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.72450
Policy Entropy: 2.10062
Value Function Loss: 0.01715

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.60353

Collected Steps per Second: 21,737.79813
Overall Steps per Second: 10,362.12361

Timestep Collection Time: 2.30069
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.82642

Cumulative Model Updates: 218,864
Cumulative Timesteps: 1,825,272,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1825272746...
Checkpoint 1825272746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.24566
Policy Entropy: 2.11354
Value Function Loss: 0.01714

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.60137

Collected Steps per Second: 21,841.98055
Overall Steps per Second: 10,280.54985

Timestep Collection Time: 2.29137
Timestep Consumption Time: 2.57685
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.86822

Cumulative Model Updates: 218,870
Cumulative Timesteps: 1,825,322,794

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.47238
Policy Entropy: 2.09555
Value Function Loss: 0.01806

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.60414

Collected Steps per Second: 21,585.78219
Overall Steps per Second: 10,357.55061

Timestep Collection Time: 2.31754
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.82991

Cumulative Model Updates: 218,876
Cumulative Timesteps: 1,825,372,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1825372820...
Checkpoint 1825372820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.55645
Policy Entropy: 2.08403
Value Function Loss: 0.01729

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.62008

Collected Steps per Second: 21,660.45621
Overall Steps per Second: 10,407.70361

Timestep Collection Time: 2.30845
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.80433

Cumulative Model Updates: 218,882
Cumulative Timesteps: 1,825,422,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.08360
Policy Entropy: 2.12682
Value Function Loss: 0.01725

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.62402

Collected Steps per Second: 21,106.76939
Overall Steps per Second: 10,380.12296

Timestep Collection Time: 2.36900
Timestep Consumption Time: 2.44809
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.81709

Cumulative Model Updates: 218,888
Cumulative Timesteps: 1,825,472,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1825472824...
Checkpoint 1825472824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.21533
Policy Entropy: 2.13323
Value Function Loss: 0.01625

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.61916

Collected Steps per Second: 21,790.83111
Overall Steps per Second: 10,246.06389

Timestep Collection Time: 2.29528
Timestep Consumption Time: 2.58621
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.88148

Cumulative Model Updates: 218,894
Cumulative Timesteps: 1,825,522,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.68784
Policy Entropy: 2.14935
Value Function Loss: 0.01616

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.53593
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,040.29408
Overall Steps per Second: 10,415.54865

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.53225
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.80109

Cumulative Model Updates: 218,900
Cumulative Timesteps: 1,825,572,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1825572846...
Checkpoint 1825572846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.39563
Policy Entropy: 2.14598
Value Function Loss: 0.01714

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.61700

Collected Steps per Second: 21,570.84136
Overall Steps per Second: 10,246.91727

Timestep Collection Time: 2.31850
Timestep Consumption Time: 2.56219
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.88069

Cumulative Model Updates: 218,906
Cumulative Timesteps: 1,825,622,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.59657
Policy Entropy: 2.14597
Value Function Loss: 0.01886

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 21,519.02552
Overall Steps per Second: 10,413.87513

Timestep Collection Time: 2.32445
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.80321

Cumulative Model Updates: 218,912
Cumulative Timesteps: 1,825,672,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1825672878...
Checkpoint 1825672878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.87355
Policy Entropy: 2.11035
Value Function Loss: 0.01931

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.62153

Collected Steps per Second: 21,852.66547
Overall Steps per Second: 10,289.48088

Timestep Collection Time: 2.28887
Timestep Consumption Time: 2.57221
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.86108

Cumulative Model Updates: 218,918
Cumulative Timesteps: 1,825,722,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.48394
Policy Entropy: 2.10479
Value Function Loss: 0.01802

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 21,851.22108
Overall Steps per Second: 10,372.78960

Timestep Collection Time: 2.28838
Timestep Consumption Time: 2.53230
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.82069

Cumulative Model Updates: 218,924
Cumulative Timesteps: 1,825,772,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1825772900...
Checkpoint 1825772900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.06213
Policy Entropy: 2.06809
Value Function Loss: 0.01776

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 21,743.77474
Overall Steps per Second: 10,313.19839

Timestep Collection Time: 2.30015
Timestep Consumption Time: 2.54936
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 4.84951

Cumulative Model Updates: 218,930
Cumulative Timesteps: 1,825,822,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.22819
Policy Entropy: 2.09548
Value Function Loss: 0.01774

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 21,722.94204
Overall Steps per Second: 10,391.35178

Timestep Collection Time: 2.30291
Timestep Consumption Time: 2.51128
PPO Batch Consumption Time: 0.30355
Total Iteration Time: 4.81420

Cumulative Model Updates: 218,936
Cumulative Timesteps: 1,825,872,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1825872940...
Checkpoint 1825872940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.26290
Policy Entropy: 2.10902
Value Function Loss: 0.01816

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.58575

Collected Steps per Second: 21,919.21145
Overall Steps per Second: 10,316.39403

Timestep Collection Time: 2.28202
Timestep Consumption Time: 2.56658
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.84859

Cumulative Model Updates: 218,942
Cumulative Timesteps: 1,825,922,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.36774
Policy Entropy: 2.14370
Value Function Loss: 0.01734

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.57073

Collected Steps per Second: 22,342.81241
Overall Steps per Second: 10,355.22316

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.59176
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 4.83061

Cumulative Model Updates: 218,948
Cumulative Timesteps: 1,825,972,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1825972982...
Checkpoint 1825972982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.49799
Policy Entropy: 2.13189
Value Function Loss: 0.01765

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.53998
Value Function Update Magnitude: 0.57281

Collected Steps per Second: 21,776.39807
Overall Steps per Second: 10,338.02972

Timestep Collection Time: 2.29707
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.83864

Cumulative Model Updates: 218,954
Cumulative Timesteps: 1,826,023,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.39473
Policy Entropy: 2.14304
Value Function Loss: 0.01818

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.60509

Collected Steps per Second: 22,579.12272
Overall Steps per Second: 10,486.07950

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.55522
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.77090

Cumulative Model Updates: 218,960
Cumulative Timesteps: 1,826,073,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1826073032...
Checkpoint 1826073032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.54429
Policy Entropy: 2.12187
Value Function Loss: 0.01774

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.62305

Collected Steps per Second: 21,996.85760
Overall Steps per Second: 10,432.42084

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.52131
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.79582

Cumulative Model Updates: 218,966
Cumulative Timesteps: 1,826,123,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.31092
Policy Entropy: 2.12001
Value Function Loss: 0.01762

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 21,671.47278
Overall Steps per Second: 10,330.69287

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.53378
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.84188

Cumulative Model Updates: 218,972
Cumulative Timesteps: 1,826,173,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1826173084...
Checkpoint 1826173084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.85355
Policy Entropy: 2.12936
Value Function Loss: 0.01811

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.57845

Collected Steps per Second: 21,928.75473
Overall Steps per Second: 10,327.97546

Timestep Collection Time: 2.28148
Timestep Consumption Time: 2.56265
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.84412

Cumulative Model Updates: 218,978
Cumulative Timesteps: 1,826,223,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.50912
Policy Entropy: 2.13928
Value Function Loss: 0.01777

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.59959

Collected Steps per Second: 20,943.38196
Overall Steps per Second: 10,335.65925

Timestep Collection Time: 2.38768
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.83820

Cumulative Model Updates: 218,984
Cumulative Timesteps: 1,826,273,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1826273120...
Checkpoint 1826273120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.84575
Policy Entropy: 2.12563
Value Function Loss: 0.01805

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.61288

Collected Steps per Second: 21,831.18133
Overall Steps per Second: 10,341.19985

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.54574
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.83696

Cumulative Model Updates: 218,990
Cumulative Timesteps: 1,826,323,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.01642
Policy Entropy: 2.10305
Value Function Loss: 0.01781

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 21,823.06032
Overall Steps per Second: 10,331.14597

Timestep Collection Time: 2.29161
Timestep Consumption Time: 2.54909
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.84070

Cumulative Model Updates: 218,996
Cumulative Timesteps: 1,826,373,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1826373150...
Checkpoint 1826373150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.87388
Policy Entropy: 2.10247
Value Function Loss: 0.01876

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.62475

Collected Steps per Second: 21,450.09910
Overall Steps per Second: 10,310.05301

Timestep Collection Time: 2.33155
Timestep Consumption Time: 2.51925
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.85080

Cumulative Model Updates: 219,002
Cumulative Timesteps: 1,826,423,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.73487
Policy Entropy: 2.10084
Value Function Loss: 0.01869

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.62351

Collected Steps per Second: 21,707.10827
Overall Steps per Second: 10,452.62914

Timestep Collection Time: 2.30431
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.78540

Cumulative Model Updates: 219,008
Cumulative Timesteps: 1,826,473,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1826473182...
Checkpoint 1826473182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.23033
Policy Entropy: 2.08926
Value Function Loss: 0.01926

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 20,958.15574
Overall Steps per Second: 10,201.51127

Timestep Collection Time: 2.38571
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.90123

Cumulative Model Updates: 219,014
Cumulative Timesteps: 1,826,523,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.80419
Policy Entropy: 2.08494
Value Function Loss: 0.01748

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 21,691.19202
Overall Steps per Second: 10,325.76270

Timestep Collection Time: 2.30527
Timestep Consumption Time: 2.53738
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.84264

Cumulative Model Updates: 219,020
Cumulative Timesteps: 1,826,573,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1826573186...
Checkpoint 1826573186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.07703
Policy Entropy: 2.10830
Value Function Loss: 0.01636

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.60034

Collected Steps per Second: 21,575.76210
Overall Steps per Second: 10,360.74899

Timestep Collection Time: 2.31862
Timestep Consumption Time: 2.50980
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 4.82842

Cumulative Model Updates: 219,026
Cumulative Timesteps: 1,826,623,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.27221
Policy Entropy: 2.13052
Value Function Loss: 0.01623

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54103
Value Function Update Magnitude: 0.57260

Collected Steps per Second: 21,835.66941
Overall Steps per Second: 10,383.91543

Timestep Collection Time: 2.29029
Timestep Consumption Time: 2.52581
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.81610

Cumulative Model Updates: 219,032
Cumulative Timesteps: 1,826,673,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1826673222...
Checkpoint 1826673222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.81202
Policy Entropy: 2.14099
Value Function Loss: 0.01735

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.58991

Collected Steps per Second: 21,563.51385
Overall Steps per Second: 10,293.36015

Timestep Collection Time: 2.31938
Timestep Consumption Time: 2.53948
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.85886

Cumulative Model Updates: 219,038
Cumulative Timesteps: 1,826,723,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.16889
Policy Entropy: 2.12978
Value Function Loss: 0.01755

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 21,834.30028
Overall Steps per Second: 10,351.74992

Timestep Collection Time: 2.29162
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.83358

Cumulative Model Updates: 219,044
Cumulative Timesteps: 1,826,773,272

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1826773272...
Checkpoint 1826773272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.94348
Policy Entropy: 2.11882
Value Function Loss: 0.01796

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 21,567.81941
Overall Steps per Second: 10,311.63803

Timestep Collection Time: 2.31836
Timestep Consumption Time: 2.53072
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.84908

Cumulative Model Updates: 219,050
Cumulative Timesteps: 1,826,823,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.84875
Policy Entropy: 2.11370
Value Function Loss: 0.01744

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.60367

Collected Steps per Second: 21,950.21107
Overall Steps per Second: 10,450.59055

Timestep Collection Time: 2.27834
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.78538

Cumulative Model Updates: 219,056
Cumulative Timesteps: 1,826,873,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1826873284...
Checkpoint 1826873284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.73446
Policy Entropy: 2.12831
Value Function Loss: 0.01736

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 21,715.19188
Overall Steps per Second: 10,218.24886

Timestep Collection Time: 2.30309
Timestep Consumption Time: 2.59129
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.89438

Cumulative Model Updates: 219,062
Cumulative Timesteps: 1,826,923,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.87948
Policy Entropy: 2.12652
Value Function Loss: 0.01683

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.53309
Value Function Update Magnitude: 0.57657

Collected Steps per Second: 21,842.74429
Overall Steps per Second: 10,373.34329

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.53167
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.82140

Cumulative Model Updates: 219,068
Cumulative Timesteps: 1,826,973,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1826973310...
Checkpoint 1826973310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.95873
Policy Entropy: 2.13364
Value Function Loss: 0.01708

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 21,370.54509
Overall Steps per Second: 10,277.27345

Timestep Collection Time: 2.33976
Timestep Consumption Time: 2.52554
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.86530

Cumulative Model Updates: 219,074
Cumulative Timesteps: 1,827,023,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.08235
Policy Entropy: 2.12412
Value Function Loss: 0.01706

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.57793

Collected Steps per Second: 21,873.05353
Overall Steps per Second: 10,417.81119

Timestep Collection Time: 2.28619
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.80005

Cumulative Model Updates: 219,080
Cumulative Timesteps: 1,827,073,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1827073318...
Checkpoint 1827073318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.19535
Policy Entropy: 2.10665
Value Function Loss: 0.01731

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.53812
Value Function Update Magnitude: 0.59681

Collected Steps per Second: 21,509.55614
Overall Steps per Second: 10,381.56551

Timestep Collection Time: 2.32455
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.30153
Total Iteration Time: 4.81623

Cumulative Model Updates: 219,086
Cumulative Timesteps: 1,827,123,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.50290
Policy Entropy: 2.13002
Value Function Loss: 0.01615

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.52516
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 22,166.76983
Overall Steps per Second: 10,302.39868

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.59761
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.85324

Cumulative Model Updates: 219,092
Cumulative Timesteps: 1,827,173,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1827173318...
Checkpoint 1827173318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.03976
Policy Entropy: 2.09144
Value Function Loss: 0.01553

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.16914
Policy Update Magnitude: 0.50579
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 21,275.10238
Overall Steps per Second: 10,217.90906

Timestep Collection Time: 2.35082
Timestep Consumption Time: 2.54392
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.89474

Cumulative Model Updates: 219,098
Cumulative Timesteps: 1,827,223,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.11421
Policy Entropy: 2.10182
Value Function Loss: 0.01592

Mean KL Divergence: 0.02688
SB3 Clip Fraction: 0.17636
Policy Update Magnitude: 0.51780
Value Function Update Magnitude: 0.54756

Collected Steps per Second: 21,859.53184
Overall Steps per Second: 10,427.06054

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.79790

Cumulative Model Updates: 219,104
Cumulative Timesteps: 1,827,273,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1827273360...
Checkpoint 1827273360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.51896
Policy Entropy: 2.09069
Value Function Loss: 0.01703

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.55270

Collected Steps per Second: 22,444.52200
Overall Steps per Second: 10,465.72672

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.55009
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.77807

Cumulative Model Updates: 219,110
Cumulative Timesteps: 1,827,323,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.72320
Policy Entropy: 2.11740
Value Function Loss: 0.01728

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.54096
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 22,069.02224
Overall Steps per Second: 10,265.10372

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.60619
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.87262

Cumulative Model Updates: 219,116
Cumulative Timesteps: 1,827,373,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1827373384...
Checkpoint 1827373384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.57525
Policy Entropy: 2.10994
Value Function Loss: 0.01746

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.57113

Collected Steps per Second: 21,368.07544
Overall Steps per Second: 10,188.99838

Timestep Collection Time: 2.34088
Timestep Consumption Time: 2.56834
PPO Batch Consumption Time: 0.30376
Total Iteration Time: 4.90922

Cumulative Model Updates: 219,122
Cumulative Timesteps: 1,827,423,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.91437
Policy Entropy: 2.10518
Value Function Loss: 0.01814

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.57314

Collected Steps per Second: 21,943.63184
Overall Steps per Second: 10,437.43742

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.79275

Cumulative Model Updates: 219,128
Cumulative Timesteps: 1,827,473,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1827473428...
Checkpoint 1827473428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.17408
Policy Entropy: 2.12937
Value Function Loss: 0.01850

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.57746

Collected Steps per Second: 21,690.63919
Overall Steps per Second: 10,227.44178

Timestep Collection Time: 2.30606
Timestep Consumption Time: 2.58470
PPO Batch Consumption Time: 0.30463
Total Iteration Time: 4.89076

Cumulative Model Updates: 219,134
Cumulative Timesteps: 1,827,523,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.14477
Policy Entropy: 2.17099
Value Function Loss: 0.01783

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.57278

Collected Steps per Second: 21,928.72725
Overall Steps per Second: 10,381.15945

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.53651
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.81680

Cumulative Model Updates: 219,140
Cumulative Timesteps: 1,827,573,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1827573452...
Checkpoint 1827573452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.62832
Policy Entropy: 2.14081
Value Function Loss: 0.01703

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.54446

Collected Steps per Second: 21,683.89075
Overall Steps per Second: 10,262.82601

Timestep Collection Time: 2.30761
Timestep Consumption Time: 2.56804
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.87566

Cumulative Model Updates: 219,146
Cumulative Timesteps: 1,827,623,490

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.03596
Policy Entropy: 2.12761
Value Function Loss: 0.01617

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.54638

Collected Steps per Second: 21,557.31027
Overall Steps per Second: 10,488.87908

Timestep Collection Time: 2.31986
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.76791

Cumulative Model Updates: 219,152
Cumulative Timesteps: 1,827,673,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1827673500...
Checkpoint 1827673500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.18005
Policy Entropy: 2.09564
Value Function Loss: 0.01558

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.55603

Collected Steps per Second: 21,930.04668
Overall Steps per Second: 10,310.71969

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.57017
PPO Batch Consumption Time: 0.30218
Total Iteration Time: 4.85087

Cumulative Model Updates: 219,158
Cumulative Timesteps: 1,827,723,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.53149
Policy Entropy: 2.11429
Value Function Loss: 0.01649

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.55542

Collected Steps per Second: 22,028.45956
Overall Steps per Second: 10,342.89855

Timestep Collection Time: 2.27124
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.83733

Cumulative Model Updates: 219,164
Cumulative Timesteps: 1,827,773,548

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1827773548...
Checkpoint 1827773548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.87936
Policy Entropy: 2.11596
Value Function Loss: 0.01706

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.16791
Policy Update Magnitude: 0.52568
Value Function Update Magnitude: 0.58648

Collected Steps per Second: 20,783.26472
Overall Steps per Second: 10,127.76356

Timestep Collection Time: 2.40578
Timestep Consumption Time: 2.53114
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.93692

Cumulative Model Updates: 219,170
Cumulative Timesteps: 1,827,823,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.24057
Policy Entropy: 2.11173
Value Function Loss: 0.01722

Mean KL Divergence: 0.02743
SB3 Clip Fraction: 0.17464
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.63021

Collected Steps per Second: 22,379.67535
Overall Steps per Second: 10,603.48454

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.48225
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.71732

Cumulative Model Updates: 219,176
Cumulative Timesteps: 1,827,873,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1827873568...
Checkpoint 1827873568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.47563
Policy Entropy: 2.11988
Value Function Loss: 0.01798

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.18198
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.62116

Collected Steps per Second: 22,392.06597
Overall Steps per Second: 10,552.76064

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74075

Cumulative Model Updates: 219,182
Cumulative Timesteps: 1,827,923,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.01288
Policy Entropy: 2.13912
Value Function Loss: 0.01707

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.17570
Policy Update Magnitude: 0.55743
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 21,228.92501
Overall Steps per Second: 10,083.26517

Timestep Collection Time: 2.35565
Timestep Consumption Time: 2.60385
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 4.95950

Cumulative Model Updates: 219,188
Cumulative Timesteps: 1,827,973,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1827973604...
Checkpoint 1827973604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.10254
Policy Entropy: 2.13010
Value Function Loss: 0.01681

Mean KL Divergence: 0.02184
SB3 Clip Fraction: 0.15472
Policy Update Magnitude: 0.54375
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 21,680.89688
Overall Steps per Second: 10,258.84873

Timestep Collection Time: 2.30645
Timestep Consumption Time: 2.56797
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.87443

Cumulative Model Updates: 219,194
Cumulative Timesteps: 1,828,023,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.06234
Policy Entropy: 2.14380
Value Function Loss: 0.01618

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.57476

Collected Steps per Second: 21,567.44562
Overall Steps per Second: 10,454.64848

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.78524

Cumulative Model Updates: 219,200
Cumulative Timesteps: 1,828,073,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1828073638...
Checkpoint 1828073638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.81997
Policy Entropy: 2.11997
Value Function Loss: 0.01763

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 21,680.48363
Overall Steps per Second: 10,220.03598

Timestep Collection Time: 2.30751
Timestep Consumption Time: 2.58758
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.89509

Cumulative Model Updates: 219,206
Cumulative Timesteps: 1,828,123,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.53832
Policy Entropy: 2.08936
Value Function Loss: 0.01800

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.61950

Collected Steps per Second: 21,699.66168
Overall Steps per Second: 10,318.29836

Timestep Collection Time: 2.30557
Timestep Consumption Time: 2.54310
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.84867

Cumulative Model Updates: 219,212
Cumulative Timesteps: 1,828,173,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1828173696...
Checkpoint 1828173696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.56062
Policy Entropy: 2.07963
Value Function Loss: 0.01788

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 21,822.38926
Overall Steps per Second: 10,297.84068

Timestep Collection Time: 2.29342
Timestep Consumption Time: 2.56662
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 4.86005

Cumulative Model Updates: 219,218
Cumulative Timesteps: 1,828,223,744

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.57944
Policy Entropy: 2.06405
Value Function Loss: 0.01735

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 21,638.65794
Overall Steps per Second: 10,384.42314

Timestep Collection Time: 2.31188
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.81741

Cumulative Model Updates: 219,224
Cumulative Timesteps: 1,828,273,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1828273770...
Checkpoint 1828273770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.23975
Policy Entropy: 2.10251
Value Function Loss: 0.01771

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.62666

Collected Steps per Second: 22,647.79170
Overall Steps per Second: 10,525.66286

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.54298
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.75105

Cumulative Model Updates: 219,230
Cumulative Timesteps: 1,828,323,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.41648
Policy Entropy: 2.07940
Value Function Loss: 0.01786

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 21,854.33542
Overall Steps per Second: 10,249.84935

Timestep Collection Time: 2.28870
Timestep Consumption Time: 2.59118
PPO Batch Consumption Time: 0.30221
Total Iteration Time: 4.87988

Cumulative Model Updates: 219,236
Cumulative Timesteps: 1,828,373,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1828373796...
Checkpoint 1828373796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.92845
Policy Entropy: 2.10706
Value Function Loss: 0.01846

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.62892

Collected Steps per Second: 21,636.02536
Overall Steps per Second: 10,169.36797

Timestep Collection Time: 2.31216
Timestep Consumption Time: 2.60712
PPO Batch Consumption Time: 0.30285
Total Iteration Time: 4.91928

Cumulative Model Updates: 219,242
Cumulative Timesteps: 1,828,423,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.72949
Policy Entropy: 2.10222
Value Function Loss: 0.01760

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.62943

Collected Steps per Second: 21,369.35055
Overall Steps per Second: 10,251.74429

Timestep Collection Time: 2.33980
Timestep Consumption Time: 2.53742
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.87722

Cumulative Model Updates: 219,248
Cumulative Timesteps: 1,828,473,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1828473822...
Checkpoint 1828473822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.63322
Policy Entropy: 2.14110
Value Function Loss: 0.01717

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.62779

Collected Steps per Second: 21,730.02665
Overall Steps per Second: 10,466.94931

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.77751

Cumulative Model Updates: 219,254
Cumulative Timesteps: 1,828,523,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.96399
Policy Entropy: 2.12366
Value Function Loss: 0.01662

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 20,874.83528
Overall Steps per Second: 10,290.06523

Timestep Collection Time: 2.39647
Timestep Consumption Time: 2.46511
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.86158

Cumulative Model Updates: 219,260
Cumulative Timesteps: 1,828,573,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1828573854...
Checkpoint 1828573854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.05254
Policy Entropy: 2.14527
Value Function Loss: 0.01725

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.64100

Collected Steps per Second: 21,873.94427
Overall Steps per Second: 10,356.05330

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.54349
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.83041

Cumulative Model Updates: 219,266
Cumulative Timesteps: 1,828,623,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.68830
Policy Entropy: 2.13542
Value Function Loss: 0.01688

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.53891
Value Function Update Magnitude: 0.62400

Collected Steps per Second: 21,885.17483
Overall Steps per Second: 10,384.91498

Timestep Collection Time: 2.28474
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.81487

Cumulative Model Updates: 219,272
Cumulative Timesteps: 1,828,673,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1828673880...
Checkpoint 1828673880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.05130
Policy Entropy: 2.14956
Value Function Loss: 0.01610

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.59628

Collected Steps per Second: 21,741.03540
Overall Steps per Second: 10,466.76284

Timestep Collection Time: 2.30063
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.77875

Cumulative Model Updates: 219,278
Cumulative Timesteps: 1,828,723,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.62320
Policy Entropy: 2.14207
Value Function Loss: 0.01524

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.51879
Value Function Update Magnitude: 0.55907

Collected Steps per Second: 21,961.99019
Overall Steps per Second: 10,254.72952

Timestep Collection Time: 2.27721
Timestep Consumption Time: 2.59976
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.87697

Cumulative Model Updates: 219,284
Cumulative Timesteps: 1,828,773,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1828773910...
Checkpoint 1828773910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.08555
Policy Entropy: 2.15064
Value Function Loss: 0.01510

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.54423

Collected Steps per Second: 21,551.24972
Overall Steps per Second: 10,238.15519

Timestep Collection Time: 2.32135
Timestep Consumption Time: 2.56508
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.88643

Cumulative Model Updates: 219,290
Cumulative Timesteps: 1,828,823,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.84799
Policy Entropy: 2.16021
Value Function Loss: 0.01567

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.51545
Value Function Update Magnitude: 0.54501

Collected Steps per Second: 21,788.30569
Overall Steps per Second: 10,430.93271

Timestep Collection Time: 2.29481
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.79344

Cumulative Model Updates: 219,296
Cumulative Timesteps: 1,828,873,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1828873938...
Checkpoint 1828873938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.59345
Policy Entropy: 2.13153
Value Function Loss: 0.01639

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.55368

Collected Steps per Second: 21,612.21545
Overall Steps per Second: 10,452.20267

Timestep Collection Time: 2.31452
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.78579

Cumulative Model Updates: 219,302
Cumulative Timesteps: 1,828,923,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.15594
Policy Entropy: 2.11725
Value Function Loss: 0.01725

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.58709

Collected Steps per Second: 21,320.16519
Overall Steps per Second: 10,281.18469

Timestep Collection Time: 2.34651
Timestep Consumption Time: 2.51947
PPO Batch Consumption Time: 0.30357
Total Iteration Time: 4.86598

Cumulative Model Updates: 219,308
Cumulative Timesteps: 1,828,973,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1828973988...
Checkpoint 1828973988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.06620
Policy Entropy: 2.10548
Value Function Loss: 0.01692

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.59692

Collected Steps per Second: 21,871.51684
Overall Steps per Second: 10,251.48945

Timestep Collection Time: 2.28672
Timestep Consumption Time: 2.59199
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.87871

Cumulative Model Updates: 219,314
Cumulative Timesteps: 1,829,024,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.60872
Policy Entropy: 2.11606
Value Function Loss: 0.01638

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.52984
Value Function Update Magnitude: 0.58590

Collected Steps per Second: 21,911.24941
Overall Steps per Second: 10,377.58740

Timestep Collection Time: 2.28257
Timestep Consumption Time: 2.53685
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.81942

Cumulative Model Updates: 219,320
Cumulative Timesteps: 1,829,074,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1829074016...
Checkpoint 1829074016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.26771
Policy Entropy: 2.11413
Value Function Loss: 0.01580

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.52386
Value Function Update Magnitude: 0.58098

Collected Steps per Second: 21,480.12775
Overall Steps per Second: 10,209.84766

Timestep Collection Time: 2.32876
Timestep Consumption Time: 2.57063
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 4.89939

Cumulative Model Updates: 219,326
Cumulative Timesteps: 1,829,124,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.11132
Policy Entropy: 2.11461
Value Function Loss: 0.01661

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.52270
Value Function Update Magnitude: 0.57662

Collected Steps per Second: 22,598.12577
Overall Steps per Second: 10,445.56080

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.57518
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.78864

Cumulative Model Updates: 219,332
Cumulative Timesteps: 1,829,174,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1829174058...
Checkpoint 1829174058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.38441
Policy Entropy: 2.10875
Value Function Loss: 0.01665

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 21,653.46492
Overall Steps per Second: 10,216.42520

Timestep Collection Time: 2.31030
Timestep Consumption Time: 2.58632
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.89662

Cumulative Model Updates: 219,338
Cumulative Timesteps: 1,829,224,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.72391
Policy Entropy: 2.09754
Value Function Loss: 0.01704

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.57309

Collected Steps per Second: 21,990.77209
Overall Steps per Second: 10,400.22462

Timestep Collection Time: 2.27432
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.80893

Cumulative Model Updates: 219,344
Cumulative Timesteps: 1,829,274,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1829274098...
Checkpoint 1829274098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.11601
Policy Entropy: 2.10215
Value Function Loss: 0.01662

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.53385
Value Function Update Magnitude: 0.56767

Collected Steps per Second: 21,504.61704
Overall Steps per Second: 10,294.91523

Timestep Collection Time: 2.32527
Timestep Consumption Time: 2.53189
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.85716

Cumulative Model Updates: 219,350
Cumulative Timesteps: 1,829,324,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.50990
Policy Entropy: 2.13189
Value Function Loss: 0.01598

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.52921
Value Function Update Magnitude: 0.56824

Collected Steps per Second: 21,751.93409
Overall Steps per Second: 10,448.98938

Timestep Collection Time: 2.29911
Timestep Consumption Time: 2.48700
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.78611

Cumulative Model Updates: 219,356
Cumulative Timesteps: 1,829,374,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1829374112...
Checkpoint 1829374112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.63345
Policy Entropy: 2.15018
Value Function Loss: 0.01612

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.52576
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 21,300.12464
Overall Steps per Second: 10,196.40613

Timestep Collection Time: 2.34750
Timestep Consumption Time: 2.55639
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.90388

Cumulative Model Updates: 219,362
Cumulative Timesteps: 1,829,424,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.25929
Policy Entropy: 2.17003
Value Function Loss: 0.01581

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.52114
Value Function Update Magnitude: 0.55867

Collected Steps per Second: 22,085.67289
Overall Steps per Second: 10,455.55370

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.51824
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.78215

Cumulative Model Updates: 219,368
Cumulative Timesteps: 1,829,474,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1829474114...
Checkpoint 1829474114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.25013
Policy Entropy: 2.14444
Value Function Loss: 0.01647

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.51775
Value Function Update Magnitude: 0.55131

Collected Steps per Second: 21,223.81257
Overall Steps per Second: 10,200.94557

Timestep Collection Time: 2.35584
Timestep Consumption Time: 2.54566
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.90151

Cumulative Model Updates: 219,374
Cumulative Timesteps: 1,829,524,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.10176
Policy Entropy: 2.14361
Value Function Loss: 0.01551

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.51805
Value Function Update Magnitude: 0.55641

Collected Steps per Second: 21,785.21015
Overall Steps per Second: 10,446.90147

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.78687

Cumulative Model Updates: 219,380
Cumulative Timesteps: 1,829,574,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1829574122...
Checkpoint 1829574122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.85962
Policy Entropy: 2.12655
Value Function Loss: 0.01571

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.52202
Value Function Update Magnitude: 0.56781

Collected Steps per Second: 21,612.55296
Overall Steps per Second: 10,203.90592

Timestep Collection Time: 2.31412
Timestep Consumption Time: 2.58734
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.90146

Cumulative Model Updates: 219,386
Cumulative Timesteps: 1,829,624,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.73512
Policy Entropy: 2.11543
Value Function Loss: 0.01516

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.52376
Value Function Update Magnitude: 0.58156

Collected Steps per Second: 22,100.47402
Overall Steps per Second: 10,425.94877

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.79630

Cumulative Model Updates: 219,392
Cumulative Timesteps: 1,829,674,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1829674142...
Checkpoint 1829674142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.22018
Policy Entropy: 2.08477
Value Function Loss: 0.01681

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.57440

Collected Steps per Second: 21,535.39997
Overall Steps per Second: 10,248.40352

Timestep Collection Time: 2.32269
Timestep Consumption Time: 2.55807
PPO Batch Consumption Time: 0.30015
Total Iteration Time: 4.88076

Cumulative Model Updates: 219,398
Cumulative Timesteps: 1,829,724,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.07906
Policy Entropy: 2.07434
Value Function Loss: 0.01733

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.57220

Collected Steps per Second: 22,032.24272
Overall Steps per Second: 10,449.47970

Timestep Collection Time: 2.27049
Timestep Consumption Time: 2.51673
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 4.78722

Cumulative Model Updates: 219,404
Cumulative Timesteps: 1,829,774,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1829774186...
Checkpoint 1829774186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.90613
Policy Entropy: 2.08802
Value Function Loss: 0.01642

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.53356
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 21,650.50871
Overall Steps per Second: 10,237.51036

Timestep Collection Time: 2.31043
Timestep Consumption Time: 2.57572
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.88615

Cumulative Model Updates: 219,410
Cumulative Timesteps: 1,829,824,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.13564
Policy Entropy: 2.11314
Value Function Loss: 0.01683

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.53842
Value Function Update Magnitude: 0.57970

Collected Steps per Second: 21,861.64183
Overall Steps per Second: 10,357.75324

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.54039
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82769

Cumulative Model Updates: 219,416
Cumulative Timesteps: 1,829,874,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1829874212...
Checkpoint 1829874212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.66644
Policy Entropy: 2.11597
Value Function Loss: 0.01590

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.56954

Collected Steps per Second: 21,660.24243
Overall Steps per Second: 10,429.30214

Timestep Collection Time: 2.30930
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.30154
Total Iteration Time: 4.79610

Cumulative Model Updates: 219,422
Cumulative Timesteps: 1,829,924,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.30677
Policy Entropy: 2.12499
Value Function Loss: 0.01688

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.55471

Collected Steps per Second: 21,847.19177
Overall Steps per Second: 10,328.42232

Timestep Collection Time: 2.28972
Timestep Consumption Time: 2.55361
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.84333

Cumulative Model Updates: 219,428
Cumulative Timesteps: 1,829,974,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1829974256...
Checkpoint 1829974256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.01436
Policy Entropy: 2.13176
Value Function Loss: 0.01654

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.53427
Value Function Update Magnitude: 0.55812

Collected Steps per Second: 21,736.78890
Overall Steps per Second: 10,202.40480

Timestep Collection Time: 2.30154
Timestep Consumption Time: 2.60201
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 4.90355

Cumulative Model Updates: 219,434
Cumulative Timesteps: 1,830,024,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.07955
Policy Entropy: 2.12729
Value Function Loss: 0.01781

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.58938

Collected Steps per Second: 21,838.83478
Overall Steps per Second: 10,451.71801

Timestep Collection Time: 2.29014
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78524

Cumulative Model Updates: 219,440
Cumulative Timesteps: 1,830,074,298

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1830074298...
Checkpoint 1830074298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.35900
Policy Entropy: 2.10116
Value Function Loss: 0.01783

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 21,420.67242
Overall Steps per Second: 10,237.61256

Timestep Collection Time: 2.33438
Timestep Consumption Time: 2.54996
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.88434

Cumulative Model Updates: 219,446
Cumulative Timesteps: 1,830,124,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.57781
Policy Entropy: 2.10399
Value Function Loss: 0.01620

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.61831

Collected Steps per Second: 22,380.96579
Overall Steps per Second: 10,441.06560

Timestep Collection Time: 2.23431
Timestep Consumption Time: 2.55505
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.78936

Cumulative Model Updates: 219,452
Cumulative Timesteps: 1,830,174,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1830174308...
Checkpoint 1830174308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.63453
Policy Entropy: 2.11607
Value Function Loss: 0.01476

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.51939
Value Function Update Magnitude: 0.57838

Collected Steps per Second: 21,639.19709
Overall Steps per Second: 10,204.83822

Timestep Collection Time: 2.31071
Timestep Consumption Time: 2.58912
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 4.89983

Cumulative Model Updates: 219,458
Cumulative Timesteps: 1,830,224,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.27730
Policy Entropy: 2.14272
Value Function Loss: 0.01409

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.51173
Value Function Update Magnitude: 0.54498

Collected Steps per Second: 21,651.59867
Overall Steps per Second: 10,411.13814

Timestep Collection Time: 2.30930
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.80255

Cumulative Model Updates: 219,464
Cumulative Timesteps: 1,830,274,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1830274310...
Checkpoint 1830274310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.01171
Policy Entropy: 2.13132
Value Function Loss: 0.01560

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.51750
Value Function Update Magnitude: 0.55676

Collected Steps per Second: 21,466.81794
Overall Steps per Second: 10,418.98154

Timestep Collection Time: 2.32927
Timestep Consumption Time: 2.46986
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.79913

Cumulative Model Updates: 219,470
Cumulative Timesteps: 1,830,324,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.03031
Policy Entropy: 2.09026
Value Function Loss: 0.01641

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.57171

Collected Steps per Second: 22,109.94287
Overall Steps per Second: 10,284.67089

Timestep Collection Time: 2.26188
Timestep Consumption Time: 2.60070
PPO Batch Consumption Time: 0.30329
Total Iteration Time: 4.86258

Cumulative Model Updates: 219,476
Cumulative Timesteps: 1,830,374,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1830374322...
Checkpoint 1830374322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.20220
Policy Entropy: 2.09175
Value Function Loss: 0.01667

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.57562

Collected Steps per Second: 21,630.13354
Overall Steps per Second: 10,198.67147

Timestep Collection Time: 2.31307
Timestep Consumption Time: 2.59267
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.90574

Cumulative Model Updates: 219,482
Cumulative Timesteps: 1,830,424,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.53596
Policy Entropy: 2.09267
Value Function Loss: 0.01683

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.56010

Collected Steps per Second: 21,728.08748
Overall Steps per Second: 10,354.90236

Timestep Collection Time: 2.30227
Timestep Consumption Time: 2.52867
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.83095

Cumulative Model Updates: 219,488
Cumulative Timesteps: 1,830,474,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1830474378...
Checkpoint 1830474378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.91981
Policy Entropy: 2.09782
Value Function Loss: 0.01676

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.55356

Collected Steps per Second: 21,479.82564
Overall Steps per Second: 10,334.34601

Timestep Collection Time: 2.32832
Timestep Consumption Time: 2.51107
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 4.83940

Cumulative Model Updates: 219,494
Cumulative Timesteps: 1,830,524,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.63674
Policy Entropy: 2.09663
Value Function Loss: 0.01729

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.55345

Collected Steps per Second: 21,686.28726
Overall Steps per Second: 10,329.88080

Timestep Collection Time: 2.30625
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.84168

Cumulative Model Updates: 219,500
Cumulative Timesteps: 1,830,574,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1830574404...
Checkpoint 1830574404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.07569
Policy Entropy: 2.08819
Value Function Loss: 0.01796

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.54563

Collected Steps per Second: 21,801.05129
Overall Steps per Second: 10,321.45647

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.84738

Cumulative Model Updates: 219,506
Cumulative Timesteps: 1,830,624,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.61215
Policy Entropy: 2.09293
Value Function Loss: 0.01836

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 21,629.30320
Overall Steps per Second: 10,354.36535

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.51942
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.83313

Cumulative Model Updates: 219,512
Cumulative Timesteps: 1,830,674,480

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1830674480...
Checkpoint 1830674480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.13813
Policy Entropy: 2.09220
Value Function Loss: 0.01771

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.58843

Collected Steps per Second: 22,045.34647
Overall Steps per Second: 10,528.58734

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.74936

Cumulative Model Updates: 219,518
Cumulative Timesteps: 1,830,724,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.66325
Policy Entropy: 2.09596
Value Function Loss: 0.01716

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.58537

Collected Steps per Second: 21,901.69359
Overall Steps per Second: 10,263.21391

Timestep Collection Time: 2.28412
Timestep Consumption Time: 2.59019
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.87430

Cumulative Model Updates: 219,524
Cumulative Timesteps: 1,830,774,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1830774510...
Checkpoint 1830774510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.22421
Policy Entropy: 2.10936
Value Function Loss: 0.01841

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.56935

Collected Steps per Second: 21,817.37876
Overall Steps per Second: 10,243.63699

Timestep Collection Time: 2.29395
Timestep Consumption Time: 2.59181
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.88576

Cumulative Model Updates: 219,530
Cumulative Timesteps: 1,830,824,558

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.88318
Policy Entropy: 2.09412
Value Function Loss: 0.01925

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.58572

Collected Steps per Second: 21,480.49756
Overall Steps per Second: 10,322.86100

Timestep Collection Time: 2.32862
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.84556

Cumulative Model Updates: 219,536
Cumulative Timesteps: 1,830,874,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1830874578...
Checkpoint 1830874578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.54056
Policy Entropy: 2.12430
Value Function Loss: 0.01837

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.58948

Collected Steps per Second: 21,790.94889
Overall Steps per Second: 10,479.56616

Timestep Collection Time: 2.29572
Timestep Consumption Time: 2.47795
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.77367

Cumulative Model Updates: 219,542
Cumulative Timesteps: 1,830,924,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.17807
Policy Entropy: 2.13439
Value Function Loss: 0.01666

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.56791

Collected Steps per Second: 21,871.12345
Overall Steps per Second: 10,298.75785

Timestep Collection Time: 2.28731
Timestep Consumption Time: 2.57017
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.85748

Cumulative Model Updates: 219,548
Cumulative Timesteps: 1,830,974,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1830974630...
Checkpoint 1830974630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.51945
Policy Entropy: 2.12653
Value Function Loss: 0.01690

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.52810
Value Function Update Magnitude: 0.55486

Collected Steps per Second: 21,636.88254
Overall Steps per Second: 10,219.82261

Timestep Collection Time: 2.31207
Timestep Consumption Time: 2.58293
PPO Batch Consumption Time: 0.30155
Total Iteration Time: 4.89500

Cumulative Model Updates: 219,554
Cumulative Timesteps: 1,831,024,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.16307
Policy Entropy: 2.11353
Value Function Loss: 0.01676

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.56877

Collected Steps per Second: 21,565.65091
Overall Steps per Second: 10,358.61910

Timestep Collection Time: 2.31971
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.82941

Cumulative Model Updates: 219,560
Cumulative Timesteps: 1,831,074,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1831074682...
Checkpoint 1831074682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.10174
Policy Entropy: 2.12311
Value Function Loss: 0.01683

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.52777
Value Function Update Magnitude: 0.55574

Collected Steps per Second: 22,072.71534
Overall Steps per Second: 10,614.32203

Timestep Collection Time: 2.26615
Timestep Consumption Time: 2.44635
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.71250

Cumulative Model Updates: 219,566
Cumulative Timesteps: 1,831,124,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.91397
Policy Entropy: 2.15245
Value Function Loss: 0.01684

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.51885
Value Function Update Magnitude: 0.55724

Collected Steps per Second: 21,872.09325
Overall Steps per Second: 10,227.65163

Timestep Collection Time: 2.28702
Timestep Consumption Time: 2.60383
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.89086

Cumulative Model Updates: 219,572
Cumulative Timesteps: 1,831,174,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1831174724...
Checkpoint 1831174724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.42479
Policy Entropy: 2.12698
Value Function Loss: 0.01729

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.56465

Collected Steps per Second: 21,547.41225
Overall Steps per Second: 10,189.52857

Timestep Collection Time: 2.32167
Timestep Consumption Time: 2.58788
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.90955

Cumulative Model Updates: 219,578
Cumulative Timesteps: 1,831,224,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.45329
Policy Entropy: 2.12321
Value Function Loss: 0.01765

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.52437
Value Function Update Magnitude: 0.58150

Collected Steps per Second: 21,723.19953
Overall Steps per Second: 10,414.28015

Timestep Collection Time: 2.30261
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.80302

Cumulative Model Updates: 219,584
Cumulative Timesteps: 1,831,274,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1831274770...
Checkpoint 1831274770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.84632
Policy Entropy: 2.10843
Value Function Loss: 0.01771

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.52371
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 21,731.22437
Overall Steps per Second: 10,536.31260

Timestep Collection Time: 2.30120
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.74625

Cumulative Model Updates: 219,590
Cumulative Timesteps: 1,831,324,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.36101
Policy Entropy: 2.12561
Value Function Loss: 0.01722

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 22,004.58699
Overall Steps per Second: 10,401.09311

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.53605
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.80930

Cumulative Model Updates: 219,596
Cumulative Timesteps: 1,831,374,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1831374800...
Checkpoint 1831374800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.51358
Policy Entropy: 2.10271
Value Function Loss: 0.01723

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.58418

Collected Steps per Second: 21,763.47197
Overall Steps per Second: 10,357.23583

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.83063

Cumulative Model Updates: 219,602
Cumulative Timesteps: 1,831,424,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.37831
Policy Entropy: 2.11769
Value Function Loss: 0.01667

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.58789

Collected Steps per Second: 21,539.72937
Overall Steps per Second: 10,340.92942

Timestep Collection Time: 2.32231
Timestep Consumption Time: 2.51497
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.83728

Cumulative Model Updates: 219,608
Cumulative Timesteps: 1,831,474,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1831474854...
Checkpoint 1831474854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.31889
Policy Entropy: 2.09800
Value Function Loss: 0.01704

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 22,042.92729
Overall Steps per Second: 10,551.30661

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.73951

Cumulative Model Updates: 219,614
Cumulative Timesteps: 1,831,524,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.49054
Policy Entropy: 2.10618
Value Function Loss: 0.01820

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 22,023.36931
Overall Steps per Second: 10,264.95481

Timestep Collection Time: 2.27068
Timestep Consumption Time: 2.60104
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.87172

Cumulative Model Updates: 219,620
Cumulative Timesteps: 1,831,574,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1831574870...
Checkpoint 1831574870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.84160
Policy Entropy: 2.10874
Value Function Loss: 0.01828

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.55483
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 21,588.71428
Overall Steps per Second: 10,175.66198

Timestep Collection Time: 2.31714
Timestep Consumption Time: 2.59891
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 4.91604

Cumulative Model Updates: 219,626
Cumulative Timesteps: 1,831,624,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.89140
Policy Entropy: 2.13514
Value Function Loss: 0.01805

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 21,669.87236
Overall Steps per Second: 10,378.79337

Timestep Collection Time: 2.30772
Timestep Consumption Time: 2.51057
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.81829

Cumulative Model Updates: 219,632
Cumulative Timesteps: 1,831,674,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1831674902...
Checkpoint 1831674902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.25997
Policy Entropy: 2.16844
Value Function Loss: 0.01712

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.61035

Collected Steps per Second: 21,716.85806
Overall Steps per Second: 10,420.70698

Timestep Collection Time: 2.30291
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.79929

Cumulative Model Updates: 219,638
Cumulative Timesteps: 1,831,724,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.56846
Policy Entropy: 2.16262
Value Function Loss: 0.01622

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.57807

Collected Steps per Second: 21,709.97887
Overall Steps per Second: 10,241.70586

Timestep Collection Time: 2.30318
Timestep Consumption Time: 2.57901
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.88219

Cumulative Model Updates: 219,644
Cumulative Timesteps: 1,831,774,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1831774916...
Checkpoint 1831774916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.47090
Policy Entropy: 2.15951
Value Function Loss: 0.01560

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.51669
Value Function Update Magnitude: 0.55809

Collected Steps per Second: 21,377.60366
Overall Steps per Second: 10,283.05738

Timestep Collection Time: 2.33908
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.86276

Cumulative Model Updates: 219,650
Cumulative Timesteps: 1,831,824,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.26684
Policy Entropy: 2.12257
Value Function Loss: 0.01701

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.55093

Collected Steps per Second: 21,623.35135
Overall Steps per Second: 10,461.79896

Timestep Collection Time: 2.31250
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.77968

Cumulative Model Updates: 219,656
Cumulative Timesteps: 1,831,874,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1831874924...
Checkpoint 1831874924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.56941
Policy Entropy: 2.12491
Value Function Loss: 0.01801

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.57265

Collected Steps per Second: 21,652.36939
Overall Steps per Second: 10,198.43503

Timestep Collection Time: 2.30922
Timestep Consumption Time: 2.59350
PPO Batch Consumption Time: 0.30419
Total Iteration Time: 4.90271

Cumulative Model Updates: 219,662
Cumulative Timesteps: 1,831,924,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.08906
Policy Entropy: 2.11411
Value Function Loss: 0.01844

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.59503

Collected Steps per Second: 21,951.34134
Overall Steps per Second: 10,375.14342

Timestep Collection Time: 2.27831
Timestep Consumption Time: 2.54206
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.82037

Cumulative Model Updates: 219,668
Cumulative Timesteps: 1,831,974,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1831974936...
Checkpoint 1831974936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.98856
Policy Entropy: 2.12271
Value Function Loss: 0.01744

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54095
Value Function Update Magnitude: 0.60270

Collected Steps per Second: 20,473.61862
Overall Steps per Second: 9,909.48540

Timestep Collection Time: 2.44295
Timestep Consumption Time: 2.60434
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 5.04729

Cumulative Model Updates: 219,674
Cumulative Timesteps: 1,832,024,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.63979
Policy Entropy: 2.10658
Value Function Loss: 0.01686

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.60298

Collected Steps per Second: 21,937.29684
Overall Steps per Second: 10,435.57443

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.30333
Total Iteration Time: 4.79245

Cumulative Model Updates: 219,680
Cumulative Timesteps: 1,832,074,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1832074964...
Checkpoint 1832074964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.33318
Policy Entropy: 2.09839
Value Function Loss: 0.01700

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.58850

Collected Steps per Second: 21,736.47512
Overall Steps per Second: 10,224.78538

Timestep Collection Time: 2.30056
Timestep Consumption Time: 2.59011
PPO Batch Consumption Time: 0.30510
Total Iteration Time: 4.89067

Cumulative Model Updates: 219,686
Cumulative Timesteps: 1,832,124,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.99198
Policy Entropy: 2.09571
Value Function Loss: 0.01723

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.52691
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 21,952.30982
Overall Steps per Second: 10,409.29404

Timestep Collection Time: 2.27839
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.80494

Cumulative Model Updates: 219,692
Cumulative Timesteps: 1,832,174,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1832174986...
Checkpoint 1832174986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.76898
Policy Entropy: 2.12072
Value Function Loss: 0.01629

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.51062
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 21,100.69603
Overall Steps per Second: 10,236.93191

Timestep Collection Time: 2.37063
Timestep Consumption Time: 2.51579
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.88642

Cumulative Model Updates: 219,698
Cumulative Timesteps: 1,832,225,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.03735
Policy Entropy: 2.13540
Value Function Loss: 0.01606

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.51300
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 21,835.01341
Overall Steps per Second: 10,356.02710

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.53892
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82946

Cumulative Model Updates: 219,704
Cumulative Timesteps: 1,832,275,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1832275022...
Checkpoint 1832275022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.74257
Policy Entropy: 2.11979
Value Function Loss: 0.01612

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.52682
Value Function Update Magnitude: 0.58267

Collected Steps per Second: 21,574.00422
Overall Steps per Second: 10,321.50836

Timestep Collection Time: 2.31825
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.84561

Cumulative Model Updates: 219,710
Cumulative Timesteps: 1,832,325,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.35249
Policy Entropy: 2.09560
Value Function Loss: 0.01720

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.53561
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 22,029.11015
Overall Steps per Second: 10,382.70355

Timestep Collection Time: 2.26972
Timestep Consumption Time: 2.54598
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.81570

Cumulative Model Updates: 219,716
Cumulative Timesteps: 1,832,375,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1832375036...
Checkpoint 1832375036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.66450
Policy Entropy: 2.09389
Value Function Loss: 0.01762

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.53123
Value Function Update Magnitude: 0.61034

Collected Steps per Second: 21,694.83784
Overall Steps per Second: 10,458.79109

Timestep Collection Time: 2.30488
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.78105

Cumulative Model Updates: 219,722
Cumulative Timesteps: 1,832,425,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.25512
Policy Entropy: 2.09076
Value Function Loss: 0.01710

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 22,188.83237
Overall Steps per Second: 10,318.05760

Timestep Collection Time: 2.25438
Timestep Consumption Time: 2.59363
PPO Batch Consumption Time: 0.30534
Total Iteration Time: 4.84801

Cumulative Model Updates: 219,728
Cumulative Timesteps: 1,832,475,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1832475062...
Checkpoint 1832475062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.42820
Policy Entropy: 2.10532
Value Function Loss: 0.01585

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.60543

Collected Steps per Second: 21,830.37505
Overall Steps per Second: 10,261.51450

Timestep Collection Time: 2.29057
Timestep Consumption Time: 2.58239
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.87296

Cumulative Model Updates: 219,734
Cumulative Timesteps: 1,832,525,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.38197
Policy Entropy: 2.10161
Value Function Loss: 0.01616

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.52627
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 21,720.13987
Overall Steps per Second: 10,351.99773

Timestep Collection Time: 2.30229
Timestep Consumption Time: 2.52828
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.83057

Cumulative Model Updates: 219,740
Cumulative Timesteps: 1,832,575,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1832575072...
Checkpoint 1832575072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.17746
Policy Entropy: 2.13678
Value Function Loss: 0.01740

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.60173

Collected Steps per Second: 21,493.54944
Overall Steps per Second: 10,203.56394

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.57490
PPO Batch Consumption Time: 0.30454
Total Iteration Time: 4.90201

Cumulative Model Updates: 219,746
Cumulative Timesteps: 1,832,625,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.14335
Policy Entropy: 2.13003
Value Function Loss: 0.01810

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,776.16833
Overall Steps per Second: 10,484.54837

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.57395
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.76949

Cumulative Model Updates: 219,752
Cumulative Timesteps: 1,832,675,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1832675096...
Checkpoint 1832675096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.37958
Policy Entropy: 2.13264
Value Function Loss: 0.01781

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.60214

Collected Steps per Second: 21,730.56996
Overall Steps per Second: 10,223.44968

Timestep Collection Time: 2.30127
Timestep Consumption Time: 2.59023
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.89150

Cumulative Model Updates: 219,758
Cumulative Timesteps: 1,832,725,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.38284
Policy Entropy: 2.11146
Value Function Loss: 0.01842

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.59720

Collected Steps per Second: 21,919.44073
Overall Steps per Second: 10,347.80300

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.55158
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.83330

Cumulative Model Updates: 219,764
Cumulative Timesteps: 1,832,775,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1832775118...
Checkpoint 1832775118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.35323
Policy Entropy: 2.11299
Value Function Loss: 0.01916

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 21,678.09426
Overall Steps per Second: 10,279.26388

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.55871
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.86611

Cumulative Model Updates: 219,770
Cumulative Timesteps: 1,832,825,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.98169
Policy Entropy: 2.09950
Value Function Loss: 0.01861

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.65628

Collected Steps per Second: 21,443.69023
Overall Steps per Second: 10,482.51266

Timestep Collection Time: 2.33262
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.77176

Cumulative Model Updates: 219,776
Cumulative Timesteps: 1,832,875,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1832875158...
Checkpoint 1832875158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.74281
Policy Entropy: 2.11332
Value Function Loss: 0.01804

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.63388

Collected Steps per Second: 21,582.64997
Overall Steps per Second: 10,182.47781

Timestep Collection Time: 2.31686
Timestep Consumption Time: 2.59393
PPO Batch Consumption Time: 0.30280
Total Iteration Time: 4.91079

Cumulative Model Updates: 219,782
Cumulative Timesteps: 1,832,925,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.55154
Policy Entropy: 2.09701
Value Function Loss: 0.01740

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.60703

Collected Steps per Second: 21,737.18401
Overall Steps per Second: 10,344.42839

Timestep Collection Time: 2.30076
Timestep Consumption Time: 2.53392
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.83468

Cumulative Model Updates: 219,788
Cumulative Timesteps: 1,832,975,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1832975174...
Checkpoint 1832975174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.31614
Policy Entropy: 2.09709
Value Function Loss: 0.01712

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.60554

Collected Steps per Second: 21,760.72876
Overall Steps per Second: 10,326.65437

Timestep Collection Time: 2.29808
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.84261

Cumulative Model Updates: 219,794
Cumulative Timesteps: 1,833,025,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.00440
Policy Entropy: 2.09487
Value Function Loss: 0.01759

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.61447

Collected Steps per Second: 22,759.74672
Overall Steps per Second: 10,472.28831

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.57806
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.77527

Cumulative Model Updates: 219,800
Cumulative Timesteps: 1,833,075,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1833075190...
Checkpoint 1833075190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.37660
Policy Entropy: 2.11664
Value Function Loss: 0.01778

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 21,605.22314
Overall Steps per Second: 10,195.42073

Timestep Collection Time: 2.31426
Timestep Consumption Time: 2.58991
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.90416

Cumulative Model Updates: 219,806
Cumulative Timesteps: 1,833,125,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.36588
Policy Entropy: 2.12222
Value Function Loss: 0.01874

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 21,412.83057
Overall Steps per Second: 10,159.09130

Timestep Collection Time: 2.33514
Timestep Consumption Time: 2.58675
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.92190

Cumulative Model Updates: 219,812
Cumulative Timesteps: 1,833,175,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1833175192...
Checkpoint 1833175192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.71651
Policy Entropy: 2.13285
Value Function Loss: 0.01826

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.63782

Collected Steps per Second: 21,788.99707
Overall Steps per Second: 10,395.70567

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.51575
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.81122

Cumulative Model Updates: 219,818
Cumulative Timesteps: 1,833,225,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.64550
Policy Entropy: 2.13732
Value Function Loss: 0.01754

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 22,747.27689
Overall Steps per Second: 10,565.94654

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.53412
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.73218

Cumulative Model Updates: 219,824
Cumulative Timesteps: 1,833,275,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1833275208...
Checkpoint 1833275208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.19596
Policy Entropy: 2.12207
Value Function Loss: 0.01765

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 21,681.98032
Overall Steps per Second: 10,203.01766

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.59611
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 4.90365

Cumulative Model Updates: 219,830
Cumulative Timesteps: 1,833,325,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.20298
Policy Entropy: 2.11048
Value Function Loss: 0.01757

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.60753

Collected Steps per Second: 21,648.52192
Overall Steps per Second: 10,362.56032

Timestep Collection Time: 2.31027
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.82641

Cumulative Model Updates: 219,836
Cumulative Timesteps: 1,833,375,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1833375254...
Checkpoint 1833375254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.75401
Policy Entropy: 2.08330
Value Function Loss: 0.01729

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 21,893.77283
Overall Steps per Second: 10,500.47146

Timestep Collection Time: 2.28449
Timestep Consumption Time: 2.47873
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.76321

Cumulative Model Updates: 219,842
Cumulative Timesteps: 1,833,425,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.18415
Policy Entropy: 2.09874
Value Function Loss: 0.01694

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.65067

Collected Steps per Second: 22,040.42578
Overall Steps per Second: 10,289.53124

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.59096
PPO Batch Consumption Time: 0.30465
Total Iteration Time: 4.85970

Cumulative Model Updates: 219,848
Cumulative Timesteps: 1,833,475,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1833475274...
Checkpoint 1833475274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.95678
Policy Entropy: 2.10814
Value Function Loss: 0.01716

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.65313

Collected Steps per Second: 21,752.71167
Overall Steps per Second: 10,209.89860

Timestep Collection Time: 2.29921
Timestep Consumption Time: 2.59937
PPO Batch Consumption Time: 0.30539
Total Iteration Time: 4.89858

Cumulative Model Updates: 219,854
Cumulative Timesteps: 1,833,525,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.95505
Policy Entropy: 2.13571
Value Function Loss: 0.01714

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.17303
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.63621

Collected Steps per Second: 21,195.32749
Overall Steps per Second: 10,067.30280

Timestep Collection Time: 2.35995
Timestep Consumption Time: 2.60861
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.96856

Cumulative Model Updates: 219,860
Cumulative Timesteps: 1,833,575,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1833575308...
Checkpoint 1833575308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.73345
Policy Entropy: 2.13945
Value Function Loss: 0.01680

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.17233
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.62961

Collected Steps per Second: 21,693.95042
Overall Steps per Second: 10,306.20411

Timestep Collection Time: 2.30590
Timestep Consumption Time: 2.54788
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.85378

Cumulative Model Updates: 219,866
Cumulative Timesteps: 1,833,625,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.78163
Policy Entropy: 2.11209
Value Function Loss: 0.01794

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.64140

Collected Steps per Second: 21,738.57770
Overall Steps per Second: 10,444.78875

Timestep Collection Time: 2.30079
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.78861

Cumulative Model Updates: 219,872
Cumulative Timesteps: 1,833,675,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1833675348...
Checkpoint 1833675348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.17762
Policy Entropy: 2.11526
Value Function Loss: 0.01803

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.66330

Collected Steps per Second: 21,928.65133
Overall Steps per Second: 10,395.36976

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.53002
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.81041

Cumulative Model Updates: 219,878
Cumulative Timesteps: 1,833,725,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.26466
Policy Entropy: 2.12659
Value Function Loss: 0.01811

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.55673
Value Function Update Magnitude: 0.64605

Collected Steps per Second: 21,930.89580
Overall Steps per Second: 10,287.49786

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.58110
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.86163

Cumulative Model Updates: 219,884
Cumulative Timesteps: 1,833,775,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1833775368...
Checkpoint 1833775368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.08283
Policy Entropy: 2.14423
Value Function Loss: 0.01681

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.54112
Value Function Update Magnitude: 0.61523

Collected Steps per Second: 21,705.15839
Overall Steps per Second: 10,495.21480

Timestep Collection Time: 2.30388
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.76465

Cumulative Model Updates: 219,890
Cumulative Timesteps: 1,833,825,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.63125
Policy Entropy: 2.13493
Value Function Loss: 0.01612

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.58289

Collected Steps per Second: 21,688.86130
Overall Steps per Second: 10,352.01400

Timestep Collection Time: 2.30671
Timestep Consumption Time: 2.52616
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.83288

Cumulative Model Updates: 219,896
Cumulative Timesteps: 1,833,875,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1833875404...
Checkpoint 1833875404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.35537
Policy Entropy: 2.11783
Value Function Loss: 0.01649

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.52764
Value Function Update Magnitude: 0.56576

Collected Steps per Second: 21,967.47777
Overall Steps per Second: 10,333.46768

Timestep Collection Time: 2.27655
Timestep Consumption Time: 2.56307
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.83961

Cumulative Model Updates: 219,902
Cumulative Timesteps: 1,833,925,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.90777
Policy Entropy: 2.13346
Value Function Loss: 0.01608

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 21,491.98102
Overall Steps per Second: 10,329.73610

Timestep Collection Time: 2.32757
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.84272

Cumulative Model Updates: 219,908
Cumulative Timesteps: 1,833,975,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1833975438...
Checkpoint 1833975438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.57680
Policy Entropy: 2.12717
Value Function Loss: 0.01633

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.53270
Value Function Update Magnitude: 0.57507

Collected Steps per Second: 21,776.94013
Overall Steps per Second: 10,321.91107

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.54836
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 4.84465

Cumulative Model Updates: 219,914
Cumulative Timesteps: 1,834,025,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.11262
Policy Entropy: 2.12403
Value Function Loss: 0.01646

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.56438

Collected Steps per Second: 22,375.24517
Overall Steps per Second: 10,466.30590

Timestep Collection Time: 2.23568
Timestep Consumption Time: 2.54384
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.77953

Cumulative Model Updates: 219,920
Cumulative Timesteps: 1,834,075,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1834075468...
Checkpoint 1834075468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.96353
Policy Entropy: 2.13096
Value Function Loss: 0.01696

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.57354

Collected Steps per Second: 21,758.72310
Overall Steps per Second: 10,213.02350

Timestep Collection Time: 2.29866
Timestep Consumption Time: 2.59861
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 4.89728

Cumulative Model Updates: 219,926
Cumulative Timesteps: 1,834,125,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.45779
Policy Entropy: 2.14020
Value Function Loss: 0.01709

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 21,541.36984
Overall Steps per Second: 10,178.13259

Timestep Collection Time: 2.32121
Timestep Consumption Time: 2.59148
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.91269

Cumulative Model Updates: 219,932
Cumulative Timesteps: 1,834,175,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1834175486...
Checkpoint 1834175486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.34782
Policy Entropy: 2.15438
Value Function Loss: 0.01693

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.61051

Collected Steps per Second: 21,538.15921
Overall Steps per Second: 10,360.52202

Timestep Collection Time: 2.32248
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.82814

Cumulative Model Updates: 219,938
Cumulative Timesteps: 1,834,225,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.08510
Policy Entropy: 2.13984
Value Function Loss: 0.01737

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 22,047.50115
Overall Steps per Second: 10,593.07589

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.45370
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.72290

Cumulative Model Updates: 219,944
Cumulative Timesteps: 1,834,275,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1834275538...
Checkpoint 1834275538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.87246
Policy Entropy: 2.14436
Value Function Loss: 0.01727

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.62234

Collected Steps per Second: 21,541.47097
Overall Steps per Second: 10,192.86128

Timestep Collection Time: 2.32203
Timestep Consumption Time: 2.58532
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 4.90736

Cumulative Model Updates: 219,950
Cumulative Timesteps: 1,834,325,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.83982
Policy Entropy: 2.12211
Value Function Loss: 0.01773

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.54301
Value Function Update Magnitude: 0.62837

Collected Steps per Second: 21,934.34930
Overall Steps per Second: 10,380.98579

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.53788
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.81823

Cumulative Model Updates: 219,956
Cumulative Timesteps: 1,834,375,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1834375576...
Checkpoint 1834375576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.36595
Policy Entropy: 2.10661
Value Function Loss: 0.01686

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.63729

Collected Steps per Second: 21,623.69378
Overall Steps per Second: 10,260.59874

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.56186
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.87515

Cumulative Model Updates: 219,962
Cumulative Timesteps: 1,834,425,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.20527
Policy Entropy: 2.11341
Value Function Loss: 0.01681

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.64306

Collected Steps per Second: 21,795.56769
Overall Steps per Second: 10,408.19700

Timestep Collection Time: 2.29404
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.80391

Cumulative Model Updates: 219,968
Cumulative Timesteps: 1,834,475,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1834475598...
Checkpoint 1834475598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.64213
Policy Entropy: 2.14897
Value Function Loss: 0.01676

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.65237

Collected Steps per Second: 22,416.74907
Overall Steps per Second: 10,369.80941

Timestep Collection Time: 2.23155
Timestep Consumption Time: 2.59246
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 4.82400

Cumulative Model Updates: 219,974
Cumulative Timesteps: 1,834,525,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.02824
Policy Entropy: 2.14939
Value Function Loss: 0.01712

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.62801

Collected Steps per Second: 21,983.08356
Overall Steps per Second: 10,406.64754

Timestep Collection Time: 2.27484
Timestep Consumption Time: 2.53055
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.80539

Cumulative Model Updates: 219,980
Cumulative Timesteps: 1,834,575,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1834575630...
Checkpoint 1834575630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.51149
Policy Entropy: 2.14857
Value Function Loss: 0.01840

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.54582
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 21,509.72078
Overall Steps per Second: 10,173.64034

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.59127
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.91682

Cumulative Model Updates: 219,986
Cumulative Timesteps: 1,834,625,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.50483
Policy Entropy: 2.13595
Value Function Loss: 0.01775

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.53500
Value Function Update Magnitude: 0.61114

Collected Steps per Second: 21,941.58452
Overall Steps per Second: 10,418.46443

Timestep Collection Time: 2.27914
Timestep Consumption Time: 2.52080
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.79994

Cumulative Model Updates: 219,992
Cumulative Timesteps: 1,834,675,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1834675660...
Checkpoint 1834675660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.31956
Policy Entropy: 2.14815
Value Function Loss: 0.01702

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.60363

Collected Steps per Second: 21,531.98794
Overall Steps per Second: 10,385.50230

Timestep Collection Time: 2.32343
Timestep Consumption Time: 2.49367
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 4.81710

Cumulative Model Updates: 219,998
Cumulative Timesteps: 1,834,725,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.96201
Policy Entropy: 2.14636
Value Function Loss: 0.01617

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.51926
Value Function Update Magnitude: 0.58467

Collected Steps per Second: 22,061.74793
Overall Steps per Second: 10,358.76690

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.56138
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.82857

Cumulative Model Updates: 220,004
Cumulative Timesteps: 1,834,775,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1834775706...
Checkpoint 1834775706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.17651
Policy Entropy: 2.13664
Value Function Loss: 0.01751

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 21,421.74242
Overall Steps per Second: 10,171.50387

Timestep Collection Time: 2.33426
Timestep Consumption Time: 2.58182
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.91609

Cumulative Model Updates: 220,010
Cumulative Timesteps: 1,834,825,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.95025
Policy Entropy: 2.13016
Value Function Loss: 0.01786

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.54292
Value Function Update Magnitude: 0.61586

Collected Steps per Second: 21,939.92518
Overall Steps per Second: 10,446.46860

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.50746
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.78650

Cumulative Model Updates: 220,016
Cumulative Timesteps: 1,834,875,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1834875712...
Checkpoint 1834875712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.05132
Policy Entropy: 2.12102
Value Function Loss: 0.01772

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.61154

Collected Steps per Second: 22,329.50489
Overall Steps per Second: 10,407.75228

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.56656
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.80719

Cumulative Model Updates: 220,022
Cumulative Timesteps: 1,834,925,744

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.96946
Policy Entropy: 2.10840
Value Function Loss: 0.01728

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.59081

Collected Steps per Second: 21,804.43018
Overall Steps per Second: 10,314.35072

Timestep Collection Time: 2.29357
Timestep Consumption Time: 2.55501
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.84858

Cumulative Model Updates: 220,028
Cumulative Timesteps: 1,834,975,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1834975754...
Checkpoint 1834975754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.80780
Policy Entropy: 2.11983
Value Function Loss: 0.01618

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.52936
Value Function Update Magnitude: 0.58346

Collected Steps per Second: 21,029.98937
Overall Steps per Second: 10,154.57046

Timestep Collection Time: 2.37860
Timestep Consumption Time: 2.54745
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.92606

Cumulative Model Updates: 220,034
Cumulative Timesteps: 1,835,025,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.11536
Policy Entropy: 2.12326
Value Function Loss: 0.01540

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.52582
Value Function Update Magnitude: 0.56731

Collected Steps per Second: 22,162.65143
Overall Steps per Second: 10,523.33691

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.75382

Cumulative Model Updates: 220,040
Cumulative Timesteps: 1,835,075,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1835075802...
Checkpoint 1835075802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.18521
Policy Entropy: 2.14395
Value Function Loss: 0.01579

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.52347
Value Function Update Magnitude: 0.56109

Collected Steps per Second: 21,340.89875
Overall Steps per Second: 10,390.34952

Timestep Collection Time: 2.34329
Timestep Consumption Time: 2.46963
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.81293

Cumulative Model Updates: 220,046
Cumulative Timesteps: 1,835,125,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.87667
Policy Entropy: 2.13864
Value Function Loss: 0.01620

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.52091
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 22,093.12961
Overall Steps per Second: 10,281.29965

Timestep Collection Time: 2.26315
Timestep Consumption Time: 2.60005
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.86320

Cumulative Model Updates: 220,052
Cumulative Timesteps: 1,835,175,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1835175810...
Checkpoint 1835175810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.82612
Policy Entropy: 2.17094
Value Function Loss: 0.01623

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.51122
Value Function Update Magnitude: 0.56912

Collected Steps per Second: 21,630.64637
Overall Steps per Second: 10,199.61393

Timestep Collection Time: 2.31172
Timestep Consumption Time: 2.59082
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 4.90254

Cumulative Model Updates: 220,058
Cumulative Timesteps: 1,835,225,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.21076
Policy Entropy: 2.16309
Value Function Loss: 0.01649

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.51693
Value Function Update Magnitude: 0.56126

Collected Steps per Second: 21,816.93089
Overall Steps per Second: 10,432.24847

Timestep Collection Time: 2.29299
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.79532

Cumulative Model Updates: 220,064
Cumulative Timesteps: 1,835,275,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1835275840...
Checkpoint 1835275840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.62618
Policy Entropy: 2.14147
Value Function Loss: 0.01545

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.52321
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 21,288.11978
Overall Steps per Second: 10,313.44719

Timestep Collection Time: 2.34976
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.85017

Cumulative Model Updates: 220,070
Cumulative Timesteps: 1,835,325,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.22975
Policy Entropy: 2.12683
Value Function Loss: 0.01505

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.52080
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 21,959.60639
Overall Steps per Second: 10,411.84259

Timestep Collection Time: 2.27745
Timestep Consumption Time: 2.52592
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.80338

Cumulative Model Updates: 220,076
Cumulative Timesteps: 1,835,375,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1835375874...
Checkpoint 1835375874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.60382
Policy Entropy: 2.12975
Value Function Loss: 0.01538

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.58562

Collected Steps per Second: 21,526.57632
Overall Steps per Second: 10,177.44588

Timestep Collection Time: 2.32299
Timestep Consumption Time: 2.59042
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.91341

Cumulative Model Updates: 220,082
Cumulative Timesteps: 1,835,425,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.68086
Policy Entropy: 2.13474
Value Function Loss: 0.01566

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.52118
Value Function Update Magnitude: 0.60173

Collected Steps per Second: 21,541.17858
Overall Steps per Second: 10,477.62958

Timestep Collection Time: 2.32244
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.77474

Cumulative Model Updates: 220,088
Cumulative Timesteps: 1,835,475,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1835475908...
Checkpoint 1835475908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.82779
Policy Entropy: 2.12252
Value Function Loss: 0.01680

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.58628

Collected Steps per Second: 21,556.71835
Overall Steps per Second: 10,219.27027

Timestep Collection Time: 2.31993
Timestep Consumption Time: 2.57377
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.89370

Cumulative Model Updates: 220,094
Cumulative Timesteps: 1,835,525,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.27286
Policy Entropy: 2.10138
Value Function Loss: 0.01654

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.57552

Collected Steps per Second: 21,874.16105
Overall Steps per Second: 10,373.38096

Timestep Collection Time: 2.28708
Timestep Consumption Time: 2.53565
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.82273

Cumulative Model Updates: 220,100
Cumulative Timesteps: 1,835,575,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1835575946...
Checkpoint 1835575946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.22501
Policy Entropy: 2.12110
Value Function Loss: 0.01653

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.54006
Value Function Update Magnitude: 0.61874

Collected Steps per Second: 22,056.79406
Overall Steps per Second: 10,374.50817

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.55355
PPO Batch Consumption Time: 0.30260
Total Iteration Time: 4.82124

Cumulative Model Updates: 220,106
Cumulative Timesteps: 1,835,625,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.46210
Policy Entropy: 2.13580
Value Function Loss: 0.01666

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.54433
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 21,946.55664
Overall Steps per Second: 10,427.99456

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 4.79651

Cumulative Model Updates: 220,112
Cumulative Timesteps: 1,835,675,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1835675982...
Checkpoint 1835675982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.92492
Policy Entropy: 2.14964
Value Function Loss: 0.01737

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.63340

Collected Steps per Second: 21,760.89042
Overall Steps per Second: 10,251.51332

Timestep Collection Time: 2.29889
Timestep Consumption Time: 2.58097
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.87986

Cumulative Model Updates: 220,118
Cumulative Timesteps: 1,835,726,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.77724
Policy Entropy: 2.15049
Value Function Loss: 0.01705

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.63674

Collected Steps per Second: 22,013.62866
Overall Steps per Second: 10,350.83148

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.56013
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.83227

Cumulative Model Updates: 220,124
Cumulative Timesteps: 1,835,776,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1835776026...
Checkpoint 1835776026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.66492
Policy Entropy: 2.15646
Value Function Loss: 0.01634

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 21,694.29880
Overall Steps per Second: 10,210.75185

Timestep Collection Time: 2.30558
Timestep Consumption Time: 2.59298
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.89856

Cumulative Model Updates: 220,130
Cumulative Timesteps: 1,835,826,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.96713
Policy Entropy: 2.15862
Value Function Loss: 0.01581

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.53386
Value Function Update Magnitude: 0.62201

Collected Steps per Second: 21,674.26104
Overall Steps per Second: 10,400.35394

Timestep Collection Time: 2.30735
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.80849

Cumulative Model Updates: 220,136
Cumulative Timesteps: 1,835,876,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1835876054...
Checkpoint 1835876054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.22870
Policy Entropy: 2.15634
Value Function Loss: 0.01653

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.54054
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 21,762.63228
Overall Steps per Second: 10,439.40545

Timestep Collection Time: 2.29899
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.30061
Total Iteration Time: 4.79261

Cumulative Model Updates: 220,142
Cumulative Timesteps: 1,835,926,086

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.51180
Policy Entropy: 2.13157
Value Function Loss: 0.01781

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 22,189.34911
Overall Steps per Second: 10,311.15842

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.59661
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.85067

Cumulative Model Updates: 220,148
Cumulative Timesteps: 1,835,976,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1835976102...
Checkpoint 1835976102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.18394
Policy Entropy: 2.11072
Value Function Loss: 0.01866

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.64335

Collected Steps per Second: 21,728.90603
Overall Steps per Second: 10,237.89529

Timestep Collection Time: 2.30246
Timestep Consumption Time: 2.58428
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.88675

Cumulative Model Updates: 220,154
Cumulative Timesteps: 1,836,026,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.70116
Policy Entropy: 2.08622
Value Function Loss: 0.01931

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.55693
Value Function Update Magnitude: 0.64581

Collected Steps per Second: 21,495.24711
Overall Steps per Second: 10,331.51126

Timestep Collection Time: 2.32628
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.83995

Cumulative Model Updates: 220,160
Cumulative Timesteps: 1,836,076,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1836076136...
Checkpoint 1836076136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.44811
Policy Entropy: 2.12179
Value Function Loss: 0.01858

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.64272

Collected Steps per Second: 21,687.28424
Overall Steps per Second: 10,503.32524

Timestep Collection Time: 2.30670
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.76287

Cumulative Model Updates: 220,166
Cumulative Timesteps: 1,836,126,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.14664
Policy Entropy: 2.13507
Value Function Loss: 0.01813

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.53071
Value Function Update Magnitude: 0.61552

Collected Steps per Second: 22,128.53595
Overall Steps per Second: 10,301.79649

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.59452
PPO Batch Consumption Time: 0.30299
Total Iteration Time: 4.85449

Cumulative Model Updates: 220,172
Cumulative Timesteps: 1,836,176,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1836176172...
Checkpoint 1836176172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.55016
Policy Entropy: 2.14665
Value Function Loss: 0.01753

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 21,887.37921
Overall Steps per Second: 10,291.87371

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.57430
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 4.85917

Cumulative Model Updates: 220,178
Cumulative Timesteps: 1,836,226,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.48775
Policy Entropy: 2.12051
Value Function Loss: 0.01692

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.53624
Value Function Update Magnitude: 0.58674

Collected Steps per Second: 21,566.45281
Overall Steps per Second: 10,314.17274

Timestep Collection Time: 2.31925
Timestep Consumption Time: 2.53019
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.84944

Cumulative Model Updates: 220,184
Cumulative Timesteps: 1,836,276,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1836276200...
Checkpoint 1836276200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.85963
Policy Entropy: 2.14106
Value Function Loss: 0.01659

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.58634

Collected Steps per Second: 21,756.95908
Overall Steps per Second: 10,557.14208

Timestep Collection Time: 2.29821
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.73632

Cumulative Model Updates: 220,190
Cumulative Timesteps: 1,836,326,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.18839
Policy Entropy: 2.13339
Value Function Loss: 0.01693

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 21,597.74409
Overall Steps per Second: 10,270.71573

Timestep Collection Time: 2.31506
Timestep Consumption Time: 2.55315
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.86821

Cumulative Model Updates: 220,196
Cumulative Timesteps: 1,836,376,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1836376202...
Checkpoint 1836376202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.25686
Policy Entropy: 2.13697
Value Function Loss: 0.01811

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 21,846.29592
Overall Steps per Second: 10,392.28659

Timestep Collection Time: 2.28945
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.81280

Cumulative Model Updates: 220,202
Cumulative Timesteps: 1,836,426,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.46274
Policy Entropy: 2.12533
Value Function Loss: 0.01954

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.54570
Value Function Update Magnitude: 0.63007

Collected Steps per Second: 21,517.77154
Overall Steps per Second: 10,282.21479

Timestep Collection Time: 2.32487
Timestep Consumption Time: 2.54043
PPO Batch Consumption Time: 0.29878
Total Iteration Time: 4.86529

Cumulative Model Updates: 220,208
Cumulative Timesteps: 1,836,476,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1836476244...
Checkpoint 1836476244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.65839
Policy Entropy: 2.13205
Value Function Loss: 0.01876

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.63978

Collected Steps per Second: 21,765.31181
Overall Steps per Second: 10,456.89138

Timestep Collection Time: 2.29760
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.78230

Cumulative Model Updates: 220,214
Cumulative Timesteps: 1,836,526,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.43672
Policy Entropy: 2.15074
Value Function Loss: 0.01792

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 22,052.54618
Overall Steps per Second: 10,390.79501

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.54576
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.81407

Cumulative Model Updates: 220,220
Cumulative Timesteps: 1,836,576,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1836576274...
Checkpoint 1836576274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.29569
Policy Entropy: 2.16174
Value Function Loss: 0.01694

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 21,823.36940
Overall Steps per Second: 10,276.46502

Timestep Collection Time: 2.29149
Timestep Consumption Time: 2.57478
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.86626

Cumulative Model Updates: 220,226
Cumulative Timesteps: 1,836,626,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.61350
Policy Entropy: 2.16701
Value Function Loss: 0.01610

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.52853
Value Function Update Magnitude: 0.60203

Collected Steps per Second: 21,290.29199
Overall Steps per Second: 10,397.20206

Timestep Collection Time: 2.34915
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.81033

Cumulative Model Updates: 220,232
Cumulative Timesteps: 1,836,676,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1836676296...
Checkpoint 1836676296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.88956
Policy Entropy: 2.16341
Value Function Loss: 0.01593

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.52044
Value Function Update Magnitude: 0.57604

Collected Steps per Second: 21,797.08962
Overall Steps per Second: 10,266.93603

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.57663
PPO Batch Consumption Time: 0.30265
Total Iteration Time: 4.87098

Cumulative Model Updates: 220,238
Cumulative Timesteps: 1,836,726,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.83800
Policy Entropy: 2.16427
Value Function Loss: 0.01648

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.57878

Collected Steps per Second: 21,824.77121
Overall Steps per Second: 10,361.05270

Timestep Collection Time: 2.29107
Timestep Consumption Time: 2.53489
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.82596

Cumulative Model Updates: 220,244
Cumulative Timesteps: 1,836,776,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1836776308...
Checkpoint 1836776308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.30397
Policy Entropy: 2.15217
Value Function Loss: 0.01688

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.53093
Value Function Update Magnitude: 0.59570

Collected Steps per Second: 21,707.01229
Overall Steps per Second: 10,291.86506

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.55501
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.85859

Cumulative Model Updates: 220,250
Cumulative Timesteps: 1,836,826,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.06164
Policy Entropy: 2.11688
Value Function Loss: 0.01809

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.61274

Collected Steps per Second: 21,331.87435
Overall Steps per Second: 10,471.23621

Timestep Collection Time: 2.34391
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.77499

Cumulative Model Updates: 220,256
Cumulative Timesteps: 1,836,876,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1836876312...
Checkpoint 1836876312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.89933
Policy Entropy: 2.10774
Value Function Loss: 0.01813

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 21,811.79464
Overall Steps per Second: 10,272.49069

Timestep Collection Time: 2.29289
Timestep Consumption Time: 2.57565
PPO Batch Consumption Time: 0.30463
Total Iteration Time: 4.86854

Cumulative Model Updates: 220,262
Cumulative Timesteps: 1,836,926,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.76975
Policy Entropy: 2.11582
Value Function Loss: 0.01735

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.62269

Collected Steps per Second: 21,776.00183
Overall Steps per Second: 10,352.68422

Timestep Collection Time: 2.29629
Timestep Consumption Time: 2.53376
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.83005

Cumulative Model Updates: 220,268
Cumulative Timesteps: 1,836,976,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1836976328...
Checkpoint 1836976328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.97480
Policy Entropy: 2.12941
Value Function Loss: 0.01667

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.54340
Value Function Update Magnitude: 0.59003

Collected Steps per Second: 21,644.75741
Overall Steps per Second: 10,240.16903

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.57270
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 4.88273

Cumulative Model Updates: 220,274
Cumulative Timesteps: 1,837,026,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.88437
Policy Entropy: 2.13160
Value Function Loss: 0.01623

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.53496
Value Function Update Magnitude: 0.56779

Collected Steps per Second: 21,901.74297
Overall Steps per Second: 10,468.41402

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.77818

Cumulative Model Updates: 220,280
Cumulative Timesteps: 1,837,076,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1837076348...
Checkpoint 1837076348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.70632
Policy Entropy: 2.11787
Value Function Loss: 0.01688

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.52735
Value Function Update Magnitude: 0.55925

Collected Steps per Second: 22,366.12229
Overall Steps per Second: 10,499.22994

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.76263

Cumulative Model Updates: 220,286
Cumulative Timesteps: 1,837,126,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.05430
Policy Entropy: 2.11330
Value Function Loss: 0.01806

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 22,080.39883
Overall Steps per Second: 10,352.30445

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.56703
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.83293

Cumulative Model Updates: 220,292
Cumulative Timesteps: 1,837,176,384

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1837176384...
Checkpoint 1837176384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.96932
Policy Entropy: 2.11492
Value Function Loss: 0.01809

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.56983

Collected Steps per Second: 21,449.72321
Overall Steps per Second: 10,346.72771

Timestep Collection Time: 2.33169
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.83380

Cumulative Model Updates: 220,298
Cumulative Timesteps: 1,837,226,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.39824
Policy Entropy: 2.13092
Value Function Loss: 0.01750

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.52864
Value Function Update Magnitude: 0.58048

Collected Steps per Second: 22,097.33228
Overall Steps per Second: 10,471.55788

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.77541

Cumulative Model Updates: 220,304
Cumulative Timesteps: 1,837,276,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1837276404...
Checkpoint 1837276404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.27221
Policy Entropy: 2.12913
Value Function Loss: 0.01667

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.51997
Value Function Update Magnitude: 0.55849

Collected Steps per Second: 22,499.00917
Overall Steps per Second: 10,474.71937

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.55230
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.77569

Cumulative Model Updates: 220,310
Cumulative Timesteps: 1,837,326,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.88035
Policy Entropy: 2.13181
Value Function Loss: 0.01713

Mean KL Divergence: 0.02994
SB3 Clip Fraction: 0.18374
Policy Update Magnitude: 0.51420
Value Function Update Magnitude: 0.55752

Collected Steps per Second: 21,943.83967
Overall Steps per Second: 10,267.13119

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.59209
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.87127

Cumulative Model Updates: 220,316
Cumulative Timesteps: 1,837,376,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1837376442...
Checkpoint 1837376442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.75838
Policy Entropy: 2.11879
Value Function Loss: 0.01743

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.18112
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.57993

Collected Steps per Second: 21,500.79318
Overall Steps per Second: 10,216.77075

Timestep Collection Time: 2.32689
Timestep Consumption Time: 2.56996
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.89685

Cumulative Model Updates: 220,322
Cumulative Timesteps: 1,837,426,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.78861
Policy Entropy: 2.10917
Value Function Loss: 0.01797

Mean KL Divergence: 0.03123
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.60155

Collected Steps per Second: 22,085.72154
Overall Steps per Second: 10,479.40513

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.50876
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.77394

Cumulative Model Updates: 220,328
Cumulative Timesteps: 1,837,476,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1837476500...
Checkpoint 1837476500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.30800
Policy Entropy: 2.12680
Value Function Loss: 0.01859

Mean KL Divergence: 0.02978
SB3 Clip Fraction: 0.17963
Policy Update Magnitude: 0.52730
Value Function Update Magnitude: 0.59828

Collected Steps per Second: 21,727.35562
Overall Steps per Second: 10,203.63592

Timestep Collection Time: 2.30189
Timestep Consumption Time: 2.59970
PPO Batch Consumption Time: 0.30492
Total Iteration Time: 4.90159

Cumulative Model Updates: 220,334
Cumulative Timesteps: 1,837,526,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.61014
Policy Entropy: 2.12787
Value Function Loss: 0.01804

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.18249
Policy Update Magnitude: 0.51822
Value Function Update Magnitude: 0.60350

Collected Steps per Second: 21,597.99974
Overall Steps per Second: 10,324.60714

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.52797
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.84319

Cumulative Model Updates: 220,340
Cumulative Timesteps: 1,837,576,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1837576518...
Checkpoint 1837576518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.91577
Policy Entropy: 2.14668
Value Function Loss: 0.01760

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.16930
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 21,524.98362
Overall Steps per Second: 10,312.70991

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.84916

Cumulative Model Updates: 220,346
Cumulative Timesteps: 1,837,626,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.36106
Policy Entropy: 2.13454
Value Function Loss: 0.01754

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.17265
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.59931

Collected Steps per Second: 21,729.45641
Overall Steps per Second: 10,355.86706

Timestep Collection Time: 2.30222
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.83069

Cumulative Model Updates: 220,352
Cumulative Timesteps: 1,837,676,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1837676552...
Checkpoint 1837676552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.88426
Policy Entropy: 2.15030
Value Function Loss: 0.01723

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.59997

Collected Steps per Second: 21,845.48822
Overall Steps per Second: 10,497.75538

Timestep Collection Time: 2.28963
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.76464

Cumulative Model Updates: 220,358
Cumulative Timesteps: 1,837,726,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.67285
Policy Entropy: 2.14030
Value Function Loss: 0.01785

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.55594
Value Function Update Magnitude: 0.57584

Collected Steps per Second: 22,023.97668
Overall Steps per Second: 10,277.22661

Timestep Collection Time: 2.27080
Timestep Consumption Time: 2.59550
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 4.86629

Cumulative Model Updates: 220,364
Cumulative Timesteps: 1,837,776,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1837776582...
Checkpoint 1837776582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.43751
Policy Entropy: 2.15326
Value Function Loss: 0.01696

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.57164

Collected Steps per Second: 21,600.49901
Overall Steps per Second: 10,196.63699

Timestep Collection Time: 2.31513
Timestep Consumption Time: 2.58923
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.90436

Cumulative Model Updates: 220,370
Cumulative Timesteps: 1,837,826,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.06389
Policy Entropy: 2.13105
Value Function Loss: 0.01730

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.53694
Value Function Update Magnitude: 0.57941

Collected Steps per Second: 21,824.37178
Overall Steps per Second: 10,408.98727

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.80642

Cumulative Model Updates: 220,376
Cumulative Timesteps: 1,837,876,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1837876620...
Checkpoint 1837876620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.19891
Policy Entropy: 2.11892
Value Function Loss: 0.01640

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.51629
Value Function Update Magnitude: 0.57580

Collected Steps per Second: 21,489.73962
Overall Steps per Second: 10,389.60025

Timestep Collection Time: 2.32772
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 4.81462

Cumulative Model Updates: 220,382
Cumulative Timesteps: 1,837,926,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.18318
Policy Entropy: 2.10807
Value Function Loss: 0.01657

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.57191

Collected Steps per Second: 21,925.77567
Overall Steps per Second: 10,323.62632

Timestep Collection Time: 2.28079
Timestep Consumption Time: 2.56325
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.84403

Cumulative Model Updates: 220,388
Cumulative Timesteps: 1,837,976,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1837976650...
Checkpoint 1837976650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.37631
Policy Entropy: 2.14095
Value Function Loss: 0.01624

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.57048

Collected Steps per Second: 21,160.14682
Overall Steps per Second: 10,238.13471

Timestep Collection Time: 2.36312
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.88409

Cumulative Model Updates: 220,394
Cumulative Timesteps: 1,838,026,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.76075
Policy Entropy: 2.13266
Value Function Loss: 0.01691

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.56464

Collected Steps per Second: 21,869.88955
Overall Steps per Second: 10,424.07265

Timestep Collection Time: 2.28661
Timestep Consumption Time: 2.51074
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.79736

Cumulative Model Updates: 220,400
Cumulative Timesteps: 1,838,076,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1838076662...
Checkpoint 1838076662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.67435
Policy Entropy: 2.14322
Value Function Loss: 0.01651

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.16356
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.58164

Collected Steps per Second: 21,436.88986
Overall Steps per Second: 10,363.74743

Timestep Collection Time: 2.33243
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.30137
Total Iteration Time: 4.82451

Cumulative Model Updates: 220,406
Cumulative Timesteps: 1,838,126,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.33576
Policy Entropy: 2.13336
Value Function Loss: 0.01585

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.17008
Policy Update Magnitude: 0.52843
Value Function Update Magnitude: 0.57975

Collected Steps per Second: 22,000.67518
Overall Steps per Second: 10,354.69830

Timestep Collection Time: 2.27375
Timestep Consumption Time: 2.55730
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.83104

Cumulative Model Updates: 220,412
Cumulative Timesteps: 1,838,176,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1838176686...
Checkpoint 1838176686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.37657
Policy Entropy: 2.14299
Value Function Loss: 0.01532

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.16331
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.56678

Collected Steps per Second: 21,345.69455
Overall Steps per Second: 10,222.44903

Timestep Collection Time: 2.34333
Timestep Consumption Time: 2.54982
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.89315

Cumulative Model Updates: 220,418
Cumulative Timesteps: 1,838,226,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.21889
Policy Entropy: 2.14021
Value Function Loss: 0.01536

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.56197

Collected Steps per Second: 21,797.23620
Overall Steps per Second: 10,436.72201

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.79288

Cumulative Model Updates: 220,424
Cumulative Timesteps: 1,838,276,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1838276728...
Checkpoint 1838276728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.37934
Policy Entropy: 2.13755
Value Function Loss: 0.01566

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 21,666.44801
Overall Steps per Second: 10,546.05808

Timestep Collection Time: 2.30882
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.74338

Cumulative Model Updates: 220,430
Cumulative Timesteps: 1,838,326,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.04221
Policy Entropy: 2.13010
Value Function Loss: 0.01623

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.56272

Collected Steps per Second: 22,041.29458
Overall Steps per Second: 10,335.76185

Timestep Collection Time: 2.26965
Timestep Consumption Time: 2.57044
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.84009

Cumulative Model Updates: 220,436
Cumulative Timesteps: 1,838,376,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1838376778...
Checkpoint 1838376778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.77743
Policy Entropy: 2.14363
Value Function Loss: 0.01663

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.55193
Value Function Update Magnitude: 0.57732

Collected Steps per Second: 21,644.06054
Overall Steps per Second: 10,331.68271

Timestep Collection Time: 2.31066
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.84064

Cumulative Model Updates: 220,442
Cumulative Timesteps: 1,838,426,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.20350
Policy Entropy: 2.12566
Value Function Loss: 0.01642

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.58239

Collected Steps per Second: 21,971.10905
Overall Steps per Second: 10,470.43431

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.77669

Cumulative Model Updates: 220,448
Cumulative Timesteps: 1,838,476,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1838476804...
Checkpoint 1838476804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.54026
Policy Entropy: 2.14584
Value Function Loss: 0.01674

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.55947

Collected Steps per Second: 21,779.29421
Overall Steps per Second: 10,454.13065

Timestep Collection Time: 2.29603
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 4.78337

Cumulative Model Updates: 220,454
Cumulative Timesteps: 1,838,526,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.20899
Policy Entropy: 2.13912
Value Function Loss: 0.01626

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.54086

Collected Steps per Second: 21,143.39092
Overall Steps per Second: 10,285.70047

Timestep Collection Time: 2.36556
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.86267

Cumulative Model Updates: 220,460
Cumulative Timesteps: 1,838,576,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1838576826...
Checkpoint 1838576826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.84599
Policy Entropy: 2.13818
Value Function Loss: 0.01644

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.55172

Collected Steps per Second: 21,555.64703
Overall Steps per Second: 10,236.27455

Timestep Collection Time: 2.32060
Timestep Consumption Time: 2.56614
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.88674

Cumulative Model Updates: 220,466
Cumulative Timesteps: 1,838,626,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.93193
Policy Entropy: 2.14405
Value Function Loss: 0.01624

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.55706

Collected Steps per Second: 21,716.42257
Overall Steps per Second: 10,334.20922

Timestep Collection Time: 2.30250
Timestep Consumption Time: 2.53600
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.83849

Cumulative Model Updates: 220,472
Cumulative Timesteps: 1,838,676,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1838676850...
Checkpoint 1838676850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.22408
Policy Entropy: 2.12821
Value Function Loss: 0.01673

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.55731

Collected Steps per Second: 21,872.75407
Overall Steps per Second: 10,345.40144

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.54742
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.83365

Cumulative Model Updates: 220,478
Cumulative Timesteps: 1,838,726,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.60010
Policy Entropy: 2.13928
Value Function Loss: 0.01718

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.57021

Collected Steps per Second: 22,380.63916
Overall Steps per Second: 10,427.66300

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.56230
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.79762

Cumulative Model Updates: 220,484
Cumulative Timesteps: 1,838,776,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1838776884...
Checkpoint 1838776884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.74477
Policy Entropy: 2.11877
Value Function Loss: 0.01688

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.52786
Value Function Update Magnitude: 0.57781

Collected Steps per Second: 21,742.22724
Overall Steps per Second: 10,231.54643

Timestep Collection Time: 2.30041
Timestep Consumption Time: 2.58800
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.88841

Cumulative Model Updates: 220,490
Cumulative Timesteps: 1,838,826,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.44328
Policy Entropy: 2.12029
Value Function Loss: 0.01720

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.56968

Collected Steps per Second: 21,934.86336
Overall Steps per Second: 10,396.50050

Timestep Collection Time: 2.28011
Timestep Consumption Time: 2.53054
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.81066

Cumulative Model Updates: 220,496
Cumulative Timesteps: 1,838,876,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1838876914...
Checkpoint 1838876914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.10894
Policy Entropy: 2.14375
Value Function Loss: 0.01665

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.57526

Collected Steps per Second: 21,479.10592
Overall Steps per Second: 10,425.06676

Timestep Collection Time: 2.32896
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.79843

Cumulative Model Updates: 220,502
Cumulative Timesteps: 1,838,926,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.11919
Policy Entropy: 2.14648
Value Function Loss: 0.01733

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 21,960.26222
Overall Steps per Second: 10,275.66643

Timestep Collection Time: 2.27802
Timestep Consumption Time: 2.59037
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.86839

Cumulative Model Updates: 220,508
Cumulative Timesteps: 1,838,976,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1838976964...
Checkpoint 1838976964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.93788
Policy Entropy: 2.15569
Value Function Loss: 0.01668

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.54104
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 21,800.59187
Overall Steps per Second: 10,237.70094

Timestep Collection Time: 2.29462
Timestep Consumption Time: 2.59164
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.88625

Cumulative Model Updates: 220,514
Cumulative Timesteps: 1,839,026,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.67256
Policy Entropy: 2.12157
Value Function Loss: 0.01735

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 21,681.47262
Overall Steps per Second: 10,385.21776

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.81704

Cumulative Model Updates: 220,520
Cumulative Timesteps: 1,839,077,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1839077014...
Checkpoint 1839077014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.81457
Policy Entropy: 2.12233
Value Function Loss: 0.01694

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.61719

Collected Steps per Second: 20,458.29226
Overall Steps per Second: 10,209.22397

Timestep Collection Time: 2.44439
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.89832

Cumulative Model Updates: 220,526
Cumulative Timesteps: 1,839,127,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.64411
Policy Entropy: 2.10335
Value Function Loss: 0.01682

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,083.08182
Overall Steps per Second: 10,387.98244

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.81460

Cumulative Model Updates: 220,532
Cumulative Timesteps: 1,839,177,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1839177036...
Checkpoint 1839177036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.96891
Policy Entropy: 2.09772
Value Function Loss: 0.01735

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.55232
Value Function Update Magnitude: 0.60438

Collected Steps per Second: 21,945.57191
Overall Steps per Second: 10,344.87309

Timestep Collection Time: 2.27928
Timestep Consumption Time: 2.55597
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.83525

Cumulative Model Updates: 220,538
Cumulative Timesteps: 1,839,227,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.97293
Policy Entropy: 2.10436
Value Function Loss: 0.01699

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.58893

Collected Steps per Second: 21,537.62542
Overall Steps per Second: 10,237.49641

Timestep Collection Time: 2.32245
Timestep Consumption Time: 2.56351
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 4.88596

Cumulative Model Updates: 220,544
Cumulative Timesteps: 1,839,277,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1839277076...
Checkpoint 1839277076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.98318
Policy Entropy: 2.11007
Value Function Loss: 0.01714

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.56702

Collected Steps per Second: 21,727.08844
Overall Steps per Second: 10,465.35894

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.77786

Cumulative Model Updates: 220,550
Cumulative Timesteps: 1,839,327,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.29235
Policy Entropy: 2.15234
Value Function Loss: 0.01610

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.52748
Value Function Update Magnitude: 0.55250

Collected Steps per Second: 21,796.11778
Overall Steps per Second: 10,337.49684

Timestep Collection Time: 2.29445
Timestep Consumption Time: 2.54328
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.83773

Cumulative Model Updates: 220,556
Cumulative Timesteps: 1,839,377,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1839377088...
Checkpoint 1839377088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.14545
Policy Entropy: 2.17769
Value Function Loss: 0.01645

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.54993

Collected Steps per Second: 21,973.95753
Overall Steps per Second: 10,326.56278

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.56708
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.84304

Cumulative Model Updates: 220,562
Cumulative Timesteps: 1,839,427,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.02955
Policy Entropy: 2.19088
Value Function Loss: 0.01628

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.55388

Collected Steps per Second: 21,528.60311
Overall Steps per Second: 10,476.80235

Timestep Collection Time: 2.32398
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.77550

Cumulative Model Updates: 220,568
Cumulative Timesteps: 1,839,477,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1839477132...
Checkpoint 1839477132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.11598
Policy Entropy: 2.15041
Value Function Loss: 0.01740

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.58014

Collected Steps per Second: 21,955.41026
Overall Steps per Second: 10,322.85396

Timestep Collection Time: 2.27743
Timestep Consumption Time: 2.56638
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.84382

Cumulative Model Updates: 220,574
Cumulative Timesteps: 1,839,527,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.88007
Policy Entropy: 2.13358
Value Function Loss: 0.01780

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.58561

Collected Steps per Second: 21,888.38412
Overall Steps per Second: 10,315.01107

Timestep Collection Time: 2.28477
Timestep Consumption Time: 2.56350
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.84827

Cumulative Model Updates: 220,580
Cumulative Timesteps: 1,839,577,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1839577144...
Checkpoint 1839577144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.41461
Policy Entropy: 2.11298
Value Function Loss: 0.01854

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.55748
Value Function Update Magnitude: 0.61759

Collected Steps per Second: 21,589.11738
Overall Steps per Second: 10,207.58449

Timestep Collection Time: 2.31654
Timestep Consumption Time: 2.58296
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.89949

Cumulative Model Updates: 220,586
Cumulative Timesteps: 1,839,627,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.85320
Policy Entropy: 2.13714
Value Function Loss: 0.01796

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.63353

Collected Steps per Second: 21,616.21055
Overall Steps per Second: 10,366.16250

Timestep Collection Time: 2.31437
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82609

Cumulative Model Updates: 220,592
Cumulative Timesteps: 1,839,677,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1839677184...
Checkpoint 1839677184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.06610
Policy Entropy: 2.14682
Value Function Loss: 0.01728

Mean KL Divergence: 0.03375
SB3 Clip Fraction: 0.19108
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.61341

Collected Steps per Second: 22,571.05241
Overall Steps per Second: 10,478.49284

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.55768
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.77397

Cumulative Model Updates: 220,598
Cumulative Timesteps: 1,839,727,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.14647
Policy Entropy: 2.15004
Value Function Loss: 0.01738

Mean KL Divergence: 0.02787
SB3 Clip Fraction: 0.17229
Policy Update Magnitude: 0.51490
Value Function Update Magnitude: 0.59082

Collected Steps per Second: 21,833.13281
Overall Steps per Second: 10,297.00125

Timestep Collection Time: 2.29083
Timestep Consumption Time: 2.56651
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.85734

Cumulative Model Updates: 220,604
Cumulative Timesteps: 1,839,777,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1839777224...
Checkpoint 1839777224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.38640
Policy Entropy: 2.14319
Value Function Loss: 0.01639

Mean KL Divergence: 0.02303
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.53104
Value Function Update Magnitude: 0.56751

Collected Steps per Second: 21,556.53453
Overall Steps per Second: 10,191.30446

Timestep Collection Time: 2.32032
Timestep Consumption Time: 2.58759
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.90791

Cumulative Model Updates: 220,610
Cumulative Timesteps: 1,839,827,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.53000
Policy Entropy: 2.12171
Value Function Loss: 0.01754

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.57044

Collected Steps per Second: 21,846.90289
Overall Steps per Second: 10,374.42179

Timestep Collection Time: 2.28920
Timestep Consumption Time: 2.53150
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.82070

Cumulative Model Updates: 220,616
Cumulative Timesteps: 1,839,877,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1839877254...
Checkpoint 1839877254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.32975
Policy Entropy: 2.13390
Value Function Loss: 0.01719

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.54990
Value Function Update Magnitude: 0.60484

Collected Steps per Second: 20,615.86188
Overall Steps per Second: 10,178.28026

Timestep Collection Time: 2.42619
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.91419

Cumulative Model Updates: 220,622
Cumulative Timesteps: 1,839,927,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.46659
Policy Entropy: 2.13688
Value Function Loss: 0.01696

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,023.74144
Overall Steps per Second: 10,310.72456

Timestep Collection Time: 2.27037
Timestep Consumption Time: 2.57915
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.84951

Cumulative Model Updates: 220,628
Cumulative Timesteps: 1,839,977,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1839977274...
Checkpoint 1839977274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.10656
Policy Entropy: 2.14202
Value Function Loss: 0.01664

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 21,441.84440
Overall Steps per Second: 10,156.67180

Timestep Collection Time: 2.33208
Timestep Consumption Time: 2.59119
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 4.92327

Cumulative Model Updates: 220,634
Cumulative Timesteps: 1,840,027,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.69553
Policy Entropy: 2.13355
Value Function Loss: 0.01706

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 21,991.28616
Overall Steps per Second: 10,361.34164

Timestep Collection Time: 2.27399
Timestep Consumption Time: 2.55241
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.82640

Cumulative Model Updates: 220,640
Cumulative Timesteps: 1,840,077,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1840077286...
Checkpoint 1840077286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.08831
Policy Entropy: 2.15038
Value Function Loss: 0.01778

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.53653
Value Function Update Magnitude: 0.58810

Collected Steps per Second: 22,200.73052
Overall Steps per Second: 10,391.69299

Timestep Collection Time: 2.25317
Timestep Consumption Time: 2.56048
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.81365

Cumulative Model Updates: 220,646
Cumulative Timesteps: 1,840,127,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.72665
Policy Entropy: 2.15180
Value Function Loss: 0.01813

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 22,202.63723
Overall Steps per Second: 10,304.27325

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.60204
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.85546

Cumulative Model Updates: 220,652
Cumulative Timesteps: 1,840,177,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1840177340...
Checkpoint 1840177340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.76251
Policy Entropy: 2.17374
Value Function Loss: 0.01711

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 21,629.11717
Overall Steps per Second: 10,203.75415

Timestep Collection Time: 2.31373
Timestep Consumption Time: 2.59074
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.90447

Cumulative Model Updates: 220,658
Cumulative Timesteps: 1,840,227,384

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.26325
Policy Entropy: 2.17726
Value Function Loss: 0.01835

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 21,853.86516
Overall Steps per Second: 10,374.56829

Timestep Collection Time: 2.28902
Timestep Consumption Time: 2.53277
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.82179

Cumulative Model Updates: 220,664
Cumulative Timesteps: 1,840,277,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1840277408...
Checkpoint 1840277408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.52439
Policy Entropy: 2.19908
Value Function Loss: 0.01838

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.62717

Collected Steps per Second: 21,574.54204
Overall Steps per Second: 10,387.19169

Timestep Collection Time: 2.31773
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.30216
Total Iteration Time: 4.81401

Cumulative Model Updates: 220,670
Cumulative Timesteps: 1,840,327,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.45599
Policy Entropy: 2.18164
Value Function Loss: 0.01833

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 22,064.46027
Overall Steps per Second: 10,381.04051

Timestep Collection Time: 2.26690
Timestep Consumption Time: 2.55130
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.81821

Cumulative Model Updates: 220,676
Cumulative Timesteps: 1,840,377,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1840377430...
Checkpoint 1840377430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.33790
Policy Entropy: 2.15123
Value Function Loss: 0.01771

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.63805

Collected Steps per Second: 21,581.71567
Overall Steps per Second: 10,241.85748

Timestep Collection Time: 2.31696
Timestep Consumption Time: 2.56536
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 4.88232

Cumulative Model Updates: 220,682
Cumulative Timesteps: 1,840,427,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.94453
Policy Entropy: 2.11689
Value Function Loss: 0.01691

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.62951

Collected Steps per Second: 22,035.44090
Overall Steps per Second: 10,380.30062

Timestep Collection Time: 2.26934
Timestep Consumption Time: 2.54805
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.81739

Cumulative Model Updates: 220,688
Cumulative Timesteps: 1,840,477,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1840477440...
Checkpoint 1840477440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.81641
Policy Entropy: 2.10240
Value Function Loss: 0.01669

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.54573
Value Function Update Magnitude: 0.62375

Collected Steps per Second: 21,527.08641
Overall Steps per Second: 10,423.51761

Timestep Collection Time: 2.32358
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.79876

Cumulative Model Updates: 220,694
Cumulative Timesteps: 1,840,527,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.76531
Policy Entropy: 2.12967
Value Function Loss: 0.01655

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.63423

Collected Steps per Second: 22,182.39955
Overall Steps per Second: 10,289.81124

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.60618
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 4.86112

Cumulative Model Updates: 220,700
Cumulative Timesteps: 1,840,577,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1840577480...
Checkpoint 1840577480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.39433
Policy Entropy: 2.14332
Value Function Loss: 0.01785

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.63620

Collected Steps per Second: 21,513.61234
Overall Steps per Second: 10,239.40148

Timestep Collection Time: 2.32523
Timestep Consumption Time: 2.56022
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 4.88544

Cumulative Model Updates: 220,706
Cumulative Timesteps: 1,840,627,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.61133
Policy Entropy: 2.15275
Value Function Loss: 0.01832

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.65334

Collected Steps per Second: 21,880.14129
Overall Steps per Second: 10,404.78549

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.30349
Total Iteration Time: 4.80548

Cumulative Model Updates: 220,712
Cumulative Timesteps: 1,840,677,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1840677504...
Checkpoint 1840677504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.70249
Policy Entropy: 2.15347
Value Function Loss: 0.01894

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.63484

Collected Steps per Second: 21,155.86142
Overall Steps per Second: 10,200.42501

Timestep Collection Time: 2.36417
Timestep Consumption Time: 2.53916
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.90333

Cumulative Model Updates: 220,718
Cumulative Timesteps: 1,840,727,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.87341
Policy Entropy: 2.15737
Value Function Loss: 0.01881

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.61283

Collected Steps per Second: 21,769.91763
Overall Steps per Second: 10,360.61883

Timestep Collection Time: 2.29803
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.82867

Cumulative Model Updates: 220,724
Cumulative Timesteps: 1,840,777,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1840777548...
Checkpoint 1840777548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.12995
Policy Entropy: 2.15111
Value Function Loss: 0.01851

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.61543

Collected Steps per Second: 21,648.48658
Overall Steps per Second: 10,324.15152

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.53389
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.84398

Cumulative Model Updates: 220,730
Cumulative Timesteps: 1,840,827,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.35450
Policy Entropy: 2.12045
Value Function Loss: 0.01787

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.62255

Collected Steps per Second: 21,763.75352
Overall Steps per Second: 10,444.76570

Timestep Collection Time: 2.29795
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.78824

Cumulative Model Updates: 220,736
Cumulative Timesteps: 1,840,877,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1840877570...
Checkpoint 1840877570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.74735
Policy Entropy: 2.09405
Value Function Loss: 0.01843

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.62878

Collected Steps per Second: 21,537.54700
Overall Steps per Second: 10,218.30422

Timestep Collection Time: 2.32283
Timestep Consumption Time: 2.57309
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.89592

Cumulative Model Updates: 220,742
Cumulative Timesteps: 1,840,927,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.52422
Policy Entropy: 2.08185
Value Function Loss: 0.01856

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.64348

Collected Steps per Second: 21,831.28278
Overall Steps per Second: 10,353.81923

Timestep Collection Time: 2.29157
Timestep Consumption Time: 2.54027
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.83184

Cumulative Model Updates: 220,748
Cumulative Timesteps: 1,840,977,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1840977626...
Checkpoint 1840977626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.75507
Policy Entropy: 2.10082
Value Function Loss: 0.01760

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 21,484.83048
Overall Steps per Second: 10,329.68520

Timestep Collection Time: 2.32797
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.84197

Cumulative Model Updates: 220,754
Cumulative Timesteps: 1,841,027,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.79695
Policy Entropy: 2.10693
Value Function Loss: 0.01735

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.53682
Value Function Update Magnitude: 0.61380

Collected Steps per Second: 21,815.67881
Overall Steps per Second: 10,367.01342

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.53106
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.82299

Cumulative Model Updates: 220,760
Cumulative Timesteps: 1,841,077,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1841077642...
Checkpoint 1841077642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.82262
Policy Entropy: 2.10282
Value Function Loss: 0.01770

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.60424

Collected Steps per Second: 21,714.36096
Overall Steps per Second: 10,465.60799

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.47493
PPO Batch Consumption Time: 0.29854
Total Iteration Time: 4.77755

Cumulative Model Updates: 220,766
Cumulative Timesteps: 1,841,127,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.15145
Policy Entropy: 2.10594
Value Function Loss: 0.01800

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 21,941.78044
Overall Steps per Second: 10,292.86017

Timestep Collection Time: 2.27921
Timestep Consumption Time: 2.57949
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.85871

Cumulative Model Updates: 220,772
Cumulative Timesteps: 1,841,177,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1841177652...
Checkpoint 1841177652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.63599
Policy Entropy: 2.09048
Value Function Loss: 0.01772

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.61371

Collected Steps per Second: 21,604.26179
Overall Steps per Second: 10,204.07539

Timestep Collection Time: 2.31501
Timestep Consumption Time: 2.58637
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 4.90138

Cumulative Model Updates: 220,778
Cumulative Timesteps: 1,841,227,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.51096
Policy Entropy: 2.08996
Value Function Loss: 0.01709

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.53329
Value Function Update Magnitude: 0.60847

Collected Steps per Second: 21,921.87241
Overall Steps per Second: 10,443.03980

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.50805
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 4.78979

Cumulative Model Updates: 220,784
Cumulative Timesteps: 1,841,277,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1841277686...
Checkpoint 1841277686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.59588
Policy Entropy: 2.08315
Value Function Loss: 0.01694

Mean KL Divergence: 0.03689
SB3 Clip Fraction: 0.20082
Policy Update Magnitude: 0.48461
Value Function Update Magnitude: 0.58731

Collected Steps per Second: 21,557.52261
Overall Steps per Second: 10,202.65807

Timestep Collection Time: 2.32077
Timestep Consumption Time: 2.58286
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.90362

Cumulative Model Updates: 220,790
Cumulative Timesteps: 1,841,327,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.87833
Policy Entropy: 2.12035
Value Function Loss: 0.01689

Mean KL Divergence: 0.03061
SB3 Clip Fraction: 0.18507
Policy Update Magnitude: 0.51483
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 21,810.86710
Overall Steps per Second: 10,360.16433

Timestep Collection Time: 2.29326
Timestep Consumption Time: 2.53466
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.82792

Cumulative Model Updates: 220,796
Cumulative Timesteps: 1,841,377,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1841377734...
Checkpoint 1841377734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.43197
Policy Entropy: 2.12662
Value Function Loss: 0.01732

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.58289

Collected Steps per Second: 21,975.48756
Overall Steps per Second: 10,346.20383

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.55866
PPO Batch Consumption Time: 0.30290
Total Iteration Time: 4.83501

Cumulative Model Updates: 220,802
Cumulative Timesteps: 1,841,427,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.22564
Policy Entropy: 2.13721
Value Function Loss: 0.01637

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.15474
Policy Update Magnitude: 0.54744
Value Function Update Magnitude: 0.60203

Collected Steps per Second: 21,629.29438
Overall Steps per Second: 10,442.49934

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.78851

Cumulative Model Updates: 220,808
Cumulative Timesteps: 1,841,477,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1841477762...
Checkpoint 1841477762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.86211
Policy Entropy: 2.10547
Value Function Loss: 0.01701

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 21,829.70300
Overall Steps per Second: 10,250.76930

Timestep Collection Time: 2.29055
Timestep Consumption Time: 2.58733
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.87788

Cumulative Model Updates: 220,814
Cumulative Timesteps: 1,841,527,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.44965
Policy Entropy: 2.10931
Value Function Loss: 0.01762

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14506
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 22,014.85968
Overall Steps per Second: 10,421.34544

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.52746
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.79938

Cumulative Model Updates: 220,820
Cumulative Timesteps: 1,841,577,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1841577780...
Checkpoint 1841577780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.41145
Policy Entropy: 2.09784
Value Function Loss: 0.01799

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 21,551.59969
Overall Steps per Second: 10,260.29798

Timestep Collection Time: 2.32066
Timestep Consumption Time: 2.55385
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.87452

Cumulative Model Updates: 220,826
Cumulative Timesteps: 1,841,627,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.85041
Policy Entropy: 2.11214
Value Function Loss: 0.01723

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.57571

Collected Steps per Second: 21,602.20872
Overall Steps per Second: 10,413.39891

Timestep Collection Time: 2.31587
Timestep Consumption Time: 2.48832
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.80420

Cumulative Model Updates: 220,832
Cumulative Timesteps: 1,841,677,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1841677822...
Checkpoint 1841677822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.80257
Policy Entropy: 2.12404
Value Function Loss: 0.01715

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.53533
Value Function Update Magnitude: 0.57973

Collected Steps per Second: 21,700.34130
Overall Steps per Second: 10,175.80522

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.61076
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 4.91597

Cumulative Model Updates: 220,838
Cumulative Timesteps: 1,841,727,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.55910
Policy Entropy: 2.14576
Value Function Loss: 0.01678

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.57086

Collected Steps per Second: 21,240.32436
Overall Steps per Second: 10,102.46643

Timestep Collection Time: 2.35477
Timestep Consumption Time: 2.59610
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 4.95087

Cumulative Model Updates: 220,844
Cumulative Timesteps: 1,841,777,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1841777862...
Checkpoint 1841777862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.90780
Policy Entropy: 2.13134
Value Function Loss: 0.01807

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 21,672.85327
Overall Steps per Second: 10,348.72972

Timestep Collection Time: 2.30786
Timestep Consumption Time: 2.52539
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.83325

Cumulative Model Updates: 220,850
Cumulative Timesteps: 1,841,827,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.94306
Policy Entropy: 2.13089
Value Function Loss: 0.01815

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 21,861.08832
Overall Steps per Second: 10,554.11867

Timestep Collection Time: 2.28744
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.73806

Cumulative Model Updates: 220,856
Cumulative Timesteps: 1,841,877,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1841877886...
Checkpoint 1841877886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.80509
Policy Entropy: 2.11645
Value Function Loss: 0.01864

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 21,947.77434
Overall Steps per Second: 10,335.11688

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.56005
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.83846

Cumulative Model Updates: 220,862
Cumulative Timesteps: 1,841,927,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.62382
Policy Entropy: 2.11099
Value Function Loss: 0.01927

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.59867

Collected Steps per Second: 21,925.61167
Overall Steps per Second: 10,335.77380

Timestep Collection Time: 2.28153
Timestep Consumption Time: 2.55836
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.83989

Cumulative Model Updates: 220,868
Cumulative Timesteps: 1,841,977,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1841977916...
Checkpoint 1841977916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.06448
Policy Entropy: 2.10830
Value Function Loss: 0.01894

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.58759

Collected Steps per Second: 21,459.84062
Overall Steps per Second: 10,223.57395

Timestep Collection Time: 2.33087
Timestep Consumption Time: 2.56175
PPO Batch Consumption Time: 0.30458
Total Iteration Time: 4.89261

Cumulative Model Updates: 220,874
Cumulative Timesteps: 1,842,027,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.62737
Policy Entropy: 2.11504
Value Function Loss: 0.01906

Mean KL Divergence: 0.03678
SB3 Clip Fraction: 0.19546
Policy Update Magnitude: 0.51114
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 21,653.67058
Overall Steps per Second: 10,395.36655

Timestep Collection Time: 2.30917
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.81003

Cumulative Model Updates: 220,880
Cumulative Timesteps: 1,842,077,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1842077938...
Checkpoint 1842077938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.22340
Policy Entropy: 2.12332
Value Function Loss: 0.01851

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.17109
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 21,947.62896
Overall Steps per Second: 10,290.64161

Timestep Collection Time: 2.27915
Timestep Consumption Time: 2.58177
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.86092

Cumulative Model Updates: 220,886
Cumulative Timesteps: 1,842,127,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.08949
Policy Entropy: 2.10595
Value Function Loss: 0.01847

Mean KL Divergence: 0.02945
SB3 Clip Fraction: 0.18421
Policy Update Magnitude: 0.53464
Value Function Update Magnitude: 0.60808

Collected Steps per Second: 21,786.01990
Overall Steps per Second: 10,366.21298

Timestep Collection Time: 2.29634
Timestep Consumption Time: 2.52973
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.82606

Cumulative Model Updates: 220,892
Cumulative Timesteps: 1,842,177,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1842177988...
Checkpoint 1842177988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.62305
Policy Entropy: 2.07900
Value Function Loss: 0.01838

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16816
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 21,480.81477
Overall Steps per Second: 10,263.51370

Timestep Collection Time: 2.32840
Timestep Consumption Time: 2.54478
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.87318

Cumulative Model Updates: 220,898
Cumulative Timesteps: 1,842,228,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.95179
Policy Entropy: 2.08619
Value Function Loss: 0.01840

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.61053

Collected Steps per Second: 21,525.61865
Overall Steps per Second: 10,338.28125

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.83930

Cumulative Model Updates: 220,904
Cumulative Timesteps: 1,842,278,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1842278034...
Checkpoint 1842278034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.06027
Policy Entropy: 2.09491
Value Function Loss: 0.01726

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.17885
Policy Update Magnitude: 0.54045
Value Function Update Magnitude: 0.60582

Collected Steps per Second: 21,776.18432
Overall Steps per Second: 10,471.27764

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.77554

Cumulative Model Updates: 220,910
Cumulative Timesteps: 1,842,328,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.61836
Policy Entropy: 2.12853
Value Function Loss: 0.01648

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.16320
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.57680

Collected Steps per Second: 22,059.03040
Overall Steps per Second: 10,314.00628

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.58237
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.85010

Cumulative Model Updates: 220,916
Cumulative Timesteps: 1,842,378,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1842378064...
Checkpoint 1842378064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.72726
Policy Entropy: 2.12045
Value Function Loss: 0.01569

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.53162
Value Function Update Magnitude: 0.56061

Collected Steps per Second: 21,599.51208
Overall Steps per Second: 10,204.87487

Timestep Collection Time: 2.31496
Timestep Consumption Time: 2.58486
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.89982

Cumulative Model Updates: 220,922
Cumulative Timesteps: 1,842,428,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.79056
Policy Entropy: 2.12626
Value Function Loss: 0.01632

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.57425

Collected Steps per Second: 21,982.37665
Overall Steps per Second: 10,455.47852

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.78352

Cumulative Model Updates: 220,928
Cumulative Timesteps: 1,842,478,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1842478080...
Checkpoint 1842478080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.37107
Policy Entropy: 2.10463
Value Function Loss: 0.01740

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.60191

Collected Steps per Second: 21,681.59406
Overall Steps per Second: 10,217.52201

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.58838
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 4.89532

Cumulative Model Updates: 220,934
Cumulative Timesteps: 1,842,528,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.51457
Policy Entropy: 2.11223
Value Function Loss: 0.01773

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.16170
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 21,692.04076
Overall Steps per Second: 10,331.71177

Timestep Collection Time: 2.30591
Timestep Consumption Time: 2.53549
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.84140

Cumulative Model Updates: 220,940
Cumulative Timesteps: 1,842,578,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1842578118...
Checkpoint 1842578118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.23858
Policy Entropy: 2.11814
Value Function Loss: 0.01780

Mean KL Divergence: 0.02933
SB3 Clip Fraction: 0.18282
Policy Update Magnitude: 0.50835
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 21,461.28869
Overall Steps per Second: 10,313.61674

Timestep Collection Time: 2.32996
Timestep Consumption Time: 2.51839
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.84835

Cumulative Model Updates: 220,946
Cumulative Timesteps: 1,842,628,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.76647
Policy Entropy: 2.11366
Value Function Loss: 0.01843

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.16778
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 22,055.20425
Overall Steps per Second: 10,424.64819

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.30599
Total Iteration Time: 4.79767

Cumulative Model Updates: 220,952
Cumulative Timesteps: 1,842,678,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1842678136...
Checkpoint 1842678136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.67364
Policy Entropy: 2.11669
Value Function Loss: 0.01968

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.17340
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.64714

Collected Steps per Second: 21,780.52054
Overall Steps per Second: 10,217.66277

Timestep Collection Time: 2.29655
Timestep Consumption Time: 2.59890
PPO Batch Consumption Time: 0.30214
Total Iteration Time: 4.89544

Cumulative Model Updates: 220,958
Cumulative Timesteps: 1,842,728,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.03099
Policy Entropy: 2.11626
Value Function Loss: 0.01972

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.55616
Value Function Update Magnitude: 0.63479

Collected Steps per Second: 21,838.66430
Overall Steps per Second: 10,358.80840

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.53841
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.82893

Cumulative Model Updates: 220,964
Cumulative Timesteps: 1,842,778,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1842778178...
Checkpoint 1842778178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.39213
Policy Entropy: 2.15150
Value Function Loss: 0.01878

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.61519

Collected Steps per Second: 21,402.21011
Overall Steps per Second: 10,367.19770

Timestep Collection Time: 2.33752
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.82560

Cumulative Model Updates: 220,970
Cumulative Timesteps: 1,842,828,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.97057
Policy Entropy: 2.16737
Value Function Loss: 0.01815

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.58534

Collected Steps per Second: 21,939.45098
Overall Steps per Second: 10,418.45235

Timestep Collection Time: 2.27900
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.30364
Total Iteration Time: 4.79918

Cumulative Model Updates: 220,976
Cumulative Timesteps: 1,842,878,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1842878206...
Checkpoint 1842878206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.22138
Policy Entropy: 2.17320
Value Function Loss: 0.01692

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.59064

Collected Steps per Second: 21,878.72617
Overall Steps per Second: 10,240.85203

Timestep Collection Time: 2.28670
Timestep Consumption Time: 2.59864
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.88534

Cumulative Model Updates: 220,982
Cumulative Timesteps: 1,842,928,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.34948
Policy Entropy: 2.14541
Value Function Loss: 0.01727

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 21,852.04015
Overall Steps per Second: 10,381.35506

Timestep Collection Time: 2.28857
Timestep Consumption Time: 2.52872
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.81729

Cumulative Model Updates: 220,988
Cumulative Timesteps: 1,842,978,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1842978246...
Checkpoint 1842978246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.49805
Policy Entropy: 2.14618
Value Function Loss: 0.01787

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.54503
Value Function Update Magnitude: 0.59473

Collected Steps per Second: 21,555.38367
Overall Steps per Second: 10,253.26146

Timestep Collection Time: 2.32035
Timestep Consumption Time: 2.55771
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 4.87806

Cumulative Model Updates: 220,994
Cumulative Timesteps: 1,843,028,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.99009
Policy Entropy: 2.14069
Value Function Loss: 0.01750

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.61070

Collected Steps per Second: 20,523.80692
Overall Steps per Second: 10,065.89392

Timestep Collection Time: 2.43639
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.96767

Cumulative Model Updates: 221,000
Cumulative Timesteps: 1,843,078,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1843078266...
Checkpoint 1843078266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.84775
Policy Entropy: 2.14752
Value Function Loss: 0.01766

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.59837

Collected Steps per Second: 21,800.74560
Overall Steps per Second: 10,282.68906

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.57048
PPO Batch Consumption Time: 0.30254
Total Iteration Time: 4.86526

Cumulative Model Updates: 221,006
Cumulative Timesteps: 1,843,128,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.57259
Policy Entropy: 2.15375
Value Function Loss: 0.01782

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.59441

Collected Steps per Second: 22,028.82628
Overall Steps per Second: 10,383.78602

Timestep Collection Time: 2.27112
Timestep Consumption Time: 2.54697
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.81809

Cumulative Model Updates: 221,012
Cumulative Timesteps: 1,843,178,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1843178324...
Checkpoint 1843178324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.90284
Policy Entropy: 2.15010
Value Function Loss: 0.01810

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.60324

Collected Steps per Second: 21,125.88122
Overall Steps per Second: 10,201.91206

Timestep Collection Time: 2.36733
Timestep Consumption Time: 2.53489
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.90222

Cumulative Model Updates: 221,018
Cumulative Timesteps: 1,843,228,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.84516
Policy Entropy: 2.14876
Value Function Loss: 0.01782

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 21,209.52931
Overall Steps per Second: 10,385.70469

Timestep Collection Time: 2.35781
Timestep Consumption Time: 2.45727
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.81508

Cumulative Model Updates: 221,024
Cumulative Timesteps: 1,843,278,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1843278344...
Checkpoint 1843278344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.52207
Policy Entropy: 2.15076
Value Function Loss: 0.01798

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 21,931.44338
Overall Steps per Second: 10,260.55830

Timestep Collection Time: 2.27992
Timestep Consumption Time: 2.59330
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.87322

Cumulative Model Updates: 221,030
Cumulative Timesteps: 1,843,328,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.26659
Policy Entropy: 2.15162
Value Function Loss: 0.01811

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 22,327.83378
Overall Steps per Second: 10,482.43443

Timestep Collection Time: 2.24043
Timestep Consumption Time: 2.53174
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.77217

Cumulative Model Updates: 221,036
Cumulative Timesteps: 1,843,378,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1843378370...
Checkpoint 1843378370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.68001
Policy Entropy: 2.13996
Value Function Loss: 0.01784

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.61820

Collected Steps per Second: 21,435.64396
Overall Steps per Second: 10,210.92773

Timestep Collection Time: 2.33378
Timestep Consumption Time: 2.56548
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.89926

Cumulative Model Updates: 221,042
Cumulative Timesteps: 1,843,428,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.44286
Policy Entropy: 2.12787
Value Function Loss: 0.01764

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.61712

Collected Steps per Second: 22,021.16975
Overall Steps per Second: 10,467.31807

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.77926

Cumulative Model Updates: 221,048
Cumulative Timesteps: 1,843,478,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1843478422...
Checkpoint 1843478422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.27719
Policy Entropy: 2.11823
Value Function Loss: 0.01685

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.59458

Collected Steps per Second: 22,573.53762
Overall Steps per Second: 10,553.53061

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.74003

Cumulative Model Updates: 221,054
Cumulative Timesteps: 1,843,528,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.72761
Policy Entropy: 2.13739
Value Function Loss: 0.01634

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.58422

Collected Steps per Second: 21,611.75860
Overall Steps per Second: 10,251.46968

Timestep Collection Time: 2.31430
Timestep Consumption Time: 2.56461
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.87891

Cumulative Model Updates: 221,060
Cumulative Timesteps: 1,843,578,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1843578462...
Checkpoint 1843578462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.37110
Policy Entropy: 2.13843
Value Function Loss: 0.01644

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.53503
Value Function Update Magnitude: 0.57048

Collected Steps per Second: 21,480.72738
Overall Steps per Second: 10,357.19936

Timestep Collection Time: 2.32879
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.82988

Cumulative Model Updates: 221,066
Cumulative Timesteps: 1,843,628,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.40199
Policy Entropy: 2.11204
Value Function Loss: 0.01826

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.60629

Collected Steps per Second: 22,107.17539
Overall Steps per Second: 10,506.49647

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.76144

Cumulative Model Updates: 221,072
Cumulative Timesteps: 1,843,678,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1843678512...
Checkpoint 1843678512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.32111
Policy Entropy: 2.11513
Value Function Loss: 0.01775

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.66797

Collected Steps per Second: 22,727.08167
Overall Steps per Second: 10,600.32275

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.51762
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.71835

Cumulative Model Updates: 221,078
Cumulative Timesteps: 1,843,728,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.65659
Policy Entropy: 2.11439
Value Function Loss: 0.01734

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.67022

Collected Steps per Second: 22,075.22374
Overall Steps per Second: 10,370.02598

Timestep Collection Time: 2.26571
Timestep Consumption Time: 2.55742
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.82313

Cumulative Model Updates: 221,084
Cumulative Timesteps: 1,843,778,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1843778544...
Checkpoint 1843778544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.86077
Policy Entropy: 2.14007
Value Function Loss: 0.01645

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.61888

Collected Steps per Second: 21,366.21375
Overall Steps per Second: 10,337.65058

Timestep Collection Time: 2.34164
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.83978

Cumulative Model Updates: 221,090
Cumulative Timesteps: 1,843,828,576

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.73283
Policy Entropy: 2.13090
Value Function Loss: 0.01720

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.52426
Value Function Update Magnitude: 0.58525

Collected Steps per Second: 22,045.67817
Overall Steps per Second: 10,454.99850

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.78489

Cumulative Model Updates: 221,096
Cumulative Timesteps: 1,843,878,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1843878602...
Checkpoint 1843878602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.43067
Policy Entropy: 2.14448
Value Function Loss: 0.01779

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,591.40745
Overall Steps per Second: 10,491.55285

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.55302
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.76669

Cumulative Model Updates: 221,102
Cumulative Timesteps: 1,843,928,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.99859
Policy Entropy: 2.14508
Value Function Loss: 0.01859

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 21,855.81124
Overall Steps per Second: 10,276.17666

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.57935
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.86835

Cumulative Model Updates: 221,108
Cumulative Timesteps: 1,843,978,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1843978640...
Checkpoint 1843978640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.02255
Policy Entropy: 2.14106
Value Function Loss: 0.01829

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.64737

Collected Steps per Second: 21,432.29505
Overall Steps per Second: 10,215.33093

Timestep Collection Time: 2.33433
Timestep Consumption Time: 2.56321
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.89754

Cumulative Model Updates: 221,114
Cumulative Timesteps: 1,844,028,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.27272
Policy Entropy: 2.12144
Value Function Loss: 0.01722

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.64266

Collected Steps per Second: 21,841.14091
Overall Steps per Second: 10,388.82375

Timestep Collection Time: 2.28926
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.81286

Cumulative Model Updates: 221,120
Cumulative Timesteps: 1,844,078,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1844078670...
Checkpoint 1844078670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.74988
Policy Entropy: 2.10746
Value Function Loss: 0.01733

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 21,448.73233
Overall Steps per Second: 10,393.81768

Timestep Collection Time: 2.33217
Timestep Consumption Time: 2.48050
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.81267

Cumulative Model Updates: 221,126
Cumulative Timesteps: 1,844,128,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.01488
Policy Entropy: 2.11867
Value Function Loss: 0.01781

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 21,657.08444
Overall Steps per Second: 10,339.79509

Timestep Collection Time: 2.30881
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.83588

Cumulative Model Updates: 221,132
Cumulative Timesteps: 1,844,178,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1844178694...
Checkpoint 1844178694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.59287
Policy Entropy: 2.12156
Value Function Loss: 0.01772

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.63485

Collected Steps per Second: 21,478.74405
Overall Steps per Second: 10,192.09820

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.57819
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.90635

Cumulative Model Updates: 221,138
Cumulative Timesteps: 1,844,228,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.14315
Policy Entropy: 2.13619
Value Function Loss: 0.01855

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.61733

Collected Steps per Second: 21,568.25868
Overall Steps per Second: 10,370.74028

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.50424
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.82357

Cumulative Model Updates: 221,144
Cumulative Timesteps: 1,844,278,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1844278724...
Checkpoint 1844278724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.60994
Policy Entropy: 2.14771
Value Function Loss: 0.01752

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 21,808.53108
Overall Steps per Second: 10,473.58333

Timestep Collection Time: 2.29296
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.77449

Cumulative Model Updates: 221,150
Cumulative Timesteps: 1,844,328,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.54346
Policy Entropy: 2.16986
Value Function Loss: 0.01711

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.53738
Value Function Update Magnitude: 0.62157

Collected Steps per Second: 22,039.69755
Overall Steps per Second: 10,277.82855

Timestep Collection Time: 2.26909
Timestep Consumption Time: 2.59673
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 4.86581

Cumulative Model Updates: 221,156
Cumulative Timesteps: 1,844,378,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1844378740...
Checkpoint 1844378740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.75097
Policy Entropy: 2.17833
Value Function Loss: 0.01701

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.61745

Collected Steps per Second: 21,683.43819
Overall Steps per Second: 10,187.34362

Timestep Collection Time: 2.30674
Timestep Consumption Time: 2.60308
PPO Batch Consumption Time: 0.30529
Total Iteration Time: 4.90982

Cumulative Model Updates: 221,162
Cumulative Timesteps: 1,844,428,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.47819
Policy Entropy: 2.16709
Value Function Loss: 0.01790

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 21,587.01470
Overall Steps per Second: 10,484.55714

Timestep Collection Time: 2.31630
Timestep Consumption Time: 2.45281
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.76911

Cumulative Model Updates: 221,168
Cumulative Timesteps: 1,844,478,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1844478760...
Checkpoint 1844478760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.84037
Policy Entropy: 2.16944
Value Function Loss: 0.01776

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 21,591.68749
Overall Steps per Second: 10,178.29230

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.59712
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 4.91320

Cumulative Model Updates: 221,174
Cumulative Timesteps: 1,844,528,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.83832
Policy Entropy: 2.16239
Value Function Loss: 0.01778

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 21,357.55553
Overall Steps per Second: 10,112.51476

Timestep Collection Time: 2.34240
Timestep Consumption Time: 2.60473
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 4.94714

Cumulative Model Updates: 221,180
Cumulative Timesteps: 1,844,578,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1844578796...
Checkpoint 1844578796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.42474
Policy Entropy: 2.17244
Value Function Loss: 0.01640

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.52704
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 21,705.19331
Overall Steps per Second: 10,315.49536

Timestep Collection Time: 2.30452
Timestep Consumption Time: 2.54450
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.84902

Cumulative Model Updates: 221,186
Cumulative Timesteps: 1,844,628,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.86187
Policy Entropy: 2.13555
Value Function Loss: 0.01686

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.59508

Collected Steps per Second: 21,859.41710
Overall Steps per Second: 10,464.94626

Timestep Collection Time: 2.28734
Timestep Consumption Time: 2.49051
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.77786

Cumulative Model Updates: 221,192
Cumulative Timesteps: 1,844,678,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1844678816...
Checkpoint 1844678816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.48460
Policy Entropy: 2.12589
Value Function Loss: 0.01707

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 21,836.39671
Overall Steps per Second: 10,392.72080

Timestep Collection Time: 2.29131
Timestep Consumption Time: 2.52302
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.81433

Cumulative Model Updates: 221,198
Cumulative Timesteps: 1,844,728,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.61827
Policy Entropy: 2.11069
Value Function Loss: 0.01650

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.61621

Collected Steps per Second: 21,739.01420
Overall Steps per Second: 10,300.85521

Timestep Collection Time: 2.30047
Timestep Consumption Time: 2.55446
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.85494

Cumulative Model Updates: 221,204
Cumulative Timesteps: 1,844,778,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1844778860...
Checkpoint 1844778860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.35086
Policy Entropy: 2.12326
Value Function Loss: 0.01786

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.62995

Collected Steps per Second: 21,932.95168
Overall Steps per Second: 10,448.24352

Timestep Collection Time: 2.27986
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.78588

Cumulative Model Updates: 221,210
Cumulative Timesteps: 1,844,828,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.10020
Policy Entropy: 2.15533
Value Function Loss: 0.01786

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.62930

Collected Steps per Second: 21,673.49757
Overall Steps per Second: 10,466.27038

Timestep Collection Time: 2.30733
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.77802

Cumulative Model Updates: 221,216
Cumulative Timesteps: 1,844,878,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1844878872...
Checkpoint 1844878872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.11952
Policy Entropy: 2.16422
Value Function Loss: 0.01869

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.55007
Value Function Update Magnitude: 0.62073

Collected Steps per Second: 21,782.11380
Overall Steps per Second: 10,224.46083

Timestep Collection Time: 2.29629
Timestep Consumption Time: 2.59571
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 4.89199

Cumulative Model Updates: 221,222
Cumulative Timesteps: 1,844,928,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.45860
Policy Entropy: 2.16808
Value Function Loss: 0.01726

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.62855

Collected Steps per Second: 21,600.86041
Overall Steps per Second: 10,308.26372

Timestep Collection Time: 2.31482
Timestep Consumption Time: 2.53586
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.85067

Cumulative Model Updates: 221,228
Cumulative Timesteps: 1,844,978,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1844978892...
Checkpoint 1844978892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.99860
Policy Entropy: 2.13385
Value Function Loss: 0.01694

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 21,709.44066
Overall Steps per Second: 10,327.40104

Timestep Collection Time: 2.30324
Timestep Consumption Time: 2.53845
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.84168

Cumulative Model Updates: 221,234
Cumulative Timesteps: 1,845,028,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.78075
Policy Entropy: 2.13950
Value Function Loss: 0.01693

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.61104

Collected Steps per Second: 21,515.66345
Overall Steps per Second: 10,452.07818

Timestep Collection Time: 2.32528
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.78661

Cumulative Model Updates: 221,240
Cumulative Timesteps: 1,845,078,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1845078924...
Checkpoint 1845078924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.48769
Policy Entropy: 2.13545
Value Function Loss: 0.01716

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 21,745.21358
Overall Steps per Second: 10,211.95617

Timestep Collection Time: 2.30037
Timestep Consumption Time: 2.59801
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.89838

Cumulative Model Updates: 221,246
Cumulative Timesteps: 1,845,128,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.01107
Policy Entropy: 2.13627
Value Function Loss: 0.01721

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 21,578.80835
Overall Steps per Second: 10,235.84828

Timestep Collection Time: 2.31820
Timestep Consumption Time: 2.56894
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.88714

Cumulative Model Updates: 221,252
Cumulative Timesteps: 1,845,178,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1845178970...
Checkpoint 1845178970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.83931
Policy Entropy: 2.12542
Value Function Loss: 0.01756

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.52469
Value Function Update Magnitude: 0.61318

Collected Steps per Second: 21,745.62978
Overall Steps per Second: 10,438.15763

Timestep Collection Time: 2.30023
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.79203

Cumulative Model Updates: 221,258
Cumulative Timesteps: 1,845,228,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.84513
Policy Entropy: 2.12765
Value Function Loss: 0.01722

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 22,693.32103
Overall Steps per Second: 10,452.43187

Timestep Collection Time: 2.20373
Timestep Consumption Time: 2.58080
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.78453

Cumulative Model Updates: 221,264
Cumulative Timesteps: 1,845,279,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1845279000...
Checkpoint 1845279000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.48097
Policy Entropy: 2.15904
Value Function Loss: 0.01757

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.57793

Collected Steps per Second: 21,373.33709
Overall Steps per Second: 10,234.32995

Timestep Collection Time: 2.34077
Timestep Consumption Time: 2.54768
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.88845

Cumulative Model Updates: 221,270
Cumulative Timesteps: 1,845,329,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.24991
Policy Entropy: 2.17656
Value Function Loss: 0.01775

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.56206

Collected Steps per Second: 21,643.23130
Overall Steps per Second: 10,322.69891

Timestep Collection Time: 2.31038
Timestep Consumption Time: 2.53371
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.84408

Cumulative Model Updates: 221,276
Cumulative Timesteps: 1,845,379,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1845379034...
Checkpoint 1845379034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.40944
Policy Entropy: 2.18171
Value Function Loss: 0.01772

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.55204

Collected Steps per Second: 21,781.36499
Overall Steps per Second: 10,335.86947

Timestep Collection Time: 2.29618
Timestep Consumption Time: 2.54269
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.83888

Cumulative Model Updates: 221,282
Cumulative Timesteps: 1,845,429,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.46031
Policy Entropy: 2.16384
Value Function Loss: 0.01664

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 21,967.39625
Overall Steps per Second: 10,431.12081

Timestep Collection Time: 2.27728
Timestep Consumption Time: 2.51856
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.79584

Cumulative Model Updates: 221,288
Cumulative Timesteps: 1,845,479,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1845479074...
Checkpoint 1845479074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.89408
Policy Entropy: 2.16939
Value Function Loss: 0.01644

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.53733
Value Function Update Magnitude: 0.54941

Collected Steps per Second: 21,518.59980
Overall Steps per Second: 10,234.16134

Timestep Collection Time: 2.32366
Timestep Consumption Time: 2.56213
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.88579

Cumulative Model Updates: 221,294
Cumulative Timesteps: 1,845,529,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.02423
Policy Entropy: 2.13296
Value Function Loss: 0.01647

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.58278

Collected Steps per Second: 21,876.63293
Overall Steps per Second: 10,397.93368

Timestep Collection Time: 2.28692
Timestep Consumption Time: 2.52462
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.81153

Cumulative Model Updates: 221,300
Cumulative Timesteps: 1,845,579,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1845579106...
Checkpoint 1845579106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.27086
Policy Entropy: 2.13980
Value Function Loss: 0.01719

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 21,517.54205
Overall Steps per Second: 10,277.18042

Timestep Collection Time: 2.32471
Timestep Consumption Time: 2.54258
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.86729

Cumulative Model Updates: 221,306
Cumulative Timesteps: 1,845,629,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.36874
Policy Entropy: 2.13594
Value Function Loss: 0.01695

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.54033
Value Function Update Magnitude: 0.59843

Collected Steps per Second: 22,014.18821
Overall Steps per Second: 10,436.06014

Timestep Collection Time: 2.27253
Timestep Consumption Time: 2.52123
PPO Batch Consumption Time: 0.30338
Total Iteration Time: 4.79376

Cumulative Model Updates: 221,312
Cumulative Timesteps: 1,845,679,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1845679156...
Checkpoint 1845679156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.79399
Policy Entropy: 2.15553
Value Function Loss: 0.01744

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.53858
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 21,438.93231
Overall Steps per Second: 10,234.86557

Timestep Collection Time: 2.33295
Timestep Consumption Time: 2.55387
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.88683

Cumulative Model Updates: 221,318
Cumulative Timesteps: 1,845,729,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.04871
Policy Entropy: 2.15017
Value Function Loss: 0.01777

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.60588

Collected Steps per Second: 21,856.92413
Overall Steps per Second: 10,380.60517

Timestep Collection Time: 2.28779
Timestep Consumption Time: 2.52927
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.81706

Cumulative Model Updates: 221,324
Cumulative Timesteps: 1,845,779,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1845779176...
Checkpoint 1845779176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.61672
Policy Entropy: 2.12482
Value Function Loss: 0.01784

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 21,688.10379
Overall Steps per Second: 10,277.41566

Timestep Collection Time: 2.30698
Timestep Consumption Time: 2.56137
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.86834

Cumulative Model Updates: 221,330
Cumulative Timesteps: 1,845,829,210

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.76661
Policy Entropy: 2.12670
Value Function Loss: 0.01662

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.53557
Value Function Update Magnitude: 0.60856

Collected Steps per Second: 21,898.39328
Overall Steps per Second: 10,449.24721

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.50196
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.78542

Cumulative Model Updates: 221,336
Cumulative Timesteps: 1,845,879,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1845879214...
Checkpoint 1845879214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.96854
Policy Entropy: 2.13141
Value Function Loss: 0.01590

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.52737
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 21,587.81137
Overall Steps per Second: 10,193.00156

Timestep Collection Time: 2.31659
Timestep Consumption Time: 2.58972
PPO Batch Consumption Time: 0.30238
Total Iteration Time: 4.90631

Cumulative Model Updates: 221,342
Cumulative Timesteps: 1,845,929,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.48768
Policy Entropy: 2.14218
Value Function Loss: 0.01621

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.52778
Value Function Update Magnitude: 0.56128

Collected Steps per Second: 21,992.65988
Overall Steps per Second: 10,384.80251

Timestep Collection Time: 2.27394
Timestep Consumption Time: 2.54175
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.81569

Cumulative Model Updates: 221,348
Cumulative Timesteps: 1,845,979,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1845979234...
Checkpoint 1845979234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.28582
Policy Entropy: 2.16181
Value Function Loss: 0.01744

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.56026

Collected Steps per Second: 21,876.69244
Overall Steps per Second: 10,519.21555

Timestep Collection Time: 2.28572
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.75359

Cumulative Model Updates: 221,354
Cumulative Timesteps: 1,846,029,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.02804
Policy Entropy: 2.14918
Value Function Loss: 0.01762

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 21,823.97373
Overall Steps per Second: 10,228.07921

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.59848
PPO Batch Consumption Time: 0.30418
Total Iteration Time: 4.89046

Cumulative Model Updates: 221,360
Cumulative Timesteps: 1,846,079,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1846079258...
Checkpoint 1846079258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.08495
Policy Entropy: 2.14014
Value Function Loss: 0.01694

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.51911
Value Function Update Magnitude: 0.59919

Collected Steps per Second: 21,324.35581
Overall Steps per Second: 10,220.23104

Timestep Collection Time: 2.34577
Timestep Consumption Time: 2.54864
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.89441

Cumulative Model Updates: 221,366
Cumulative Timesteps: 1,846,129,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.43787
Policy Entropy: 2.12914
Value Function Loss: 0.01627

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.52482
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 21,915.95208
Overall Steps per Second: 10,459.40398

Timestep Collection Time: 2.28254
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.78268

Cumulative Model Updates: 221,372
Cumulative Timesteps: 1,846,179,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1846179304...
Checkpoint 1846179304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.79091
Policy Entropy: 2.14470
Value Function Loss: 0.01626

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.53583
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 21,630.15199
Overall Steps per Second: 10,531.79901

Timestep Collection Time: 2.31288
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.75019

Cumulative Model Updates: 221,378
Cumulative Timesteps: 1,846,229,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.74978
Policy Entropy: 2.17985
Value Function Loss: 0.01612

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.51472
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 22,225.61074
Overall Steps per Second: 10,458.36966

Timestep Collection Time: 2.25074
Timestep Consumption Time: 2.53242
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.78315

Cumulative Model Updates: 221,384
Cumulative Timesteps: 1,846,279,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1846279356...
Checkpoint 1846279356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.59321
Policy Entropy: 2.16398
Value Function Loss: 0.01629

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.57085

Collected Steps per Second: 21,775.99844
Overall Steps per Second: 10,314.70298

Timestep Collection Time: 2.29721
Timestep Consumption Time: 2.55257
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.84978

Cumulative Model Updates: 221,390
Cumulative Timesteps: 1,846,329,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.61397
Policy Entropy: 2.15861
Value Function Loss: 0.01724

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.52660
Value Function Update Magnitude: 0.56970

Collected Steps per Second: 21,779.43844
Overall Steps per Second: 10,421.84045

Timestep Collection Time: 2.29758
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.80146

Cumulative Model Updates: 221,396
Cumulative Timesteps: 1,846,379,420

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1846379420...
Checkpoint 1846379420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.39546
Policy Entropy: 2.13303
Value Function Loss: 0.01747

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.57974

Collected Steps per Second: 21,605.31741
Overall Steps per Second: 10,470.33753

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.77731

Cumulative Model Updates: 221,402
Cumulative Timesteps: 1,846,429,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.48802
Policy Entropy: 2.14118
Value Function Loss: 0.01741

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.52899
Value Function Update Magnitude: 0.59660

Collected Steps per Second: 22,028.51690
Overall Steps per Second: 10,286.87093

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.59109
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.86115

Cumulative Model Updates: 221,408
Cumulative Timesteps: 1,846,479,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1846479446...
Checkpoint 1846479446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.31424
Policy Entropy: 2.13714
Value Function Loss: 0.01754

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.60006

Collected Steps per Second: 21,631.91693
Overall Steps per Second: 10,202.18040

Timestep Collection Time: 2.31205
Timestep Consumption Time: 2.59024
PPO Batch Consumption Time: 0.30391
Total Iteration Time: 4.90229

Cumulative Model Updates: 221,414
Cumulative Timesteps: 1,846,529,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.97516
Policy Entropy: 2.13348
Value Function Loss: 0.01781

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.60757

Collected Steps per Second: 21,688.44078
Overall Steps per Second: 10,421.89368

Timestep Collection Time: 2.30538
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79759

Cumulative Model Updates: 221,420
Cumulative Timesteps: 1,846,579,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1846579460...
Checkpoint 1846579460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.51173
Policy Entropy: 2.10603
Value Function Loss: 0.01898

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 21,345.73993
Overall Steps per Second: 10,353.77466

Timestep Collection Time: 2.34370
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.83186

Cumulative Model Updates: 221,426
Cumulative Timesteps: 1,846,629,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.69563
Policy Entropy: 2.11054
Value Function Loss: 0.01847

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 21,618.06169
Overall Steps per Second: 10,302.54359

Timestep Collection Time: 2.31344
Timestep Consumption Time: 2.54090
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.85434

Cumulative Model Updates: 221,432
Cumulative Timesteps: 1,846,679,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1846679500...
Checkpoint 1846679500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.01232
Policy Entropy: 2.09949
Value Function Loss: 0.01768

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.54463
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 21,484.58721
Overall Steps per Second: 10,221.51383

Timestep Collection Time: 2.32762
Timestep Consumption Time: 2.56480
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.89243

Cumulative Model Updates: 221,438
Cumulative Timesteps: 1,846,729,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.08744
Policy Entropy: 2.11854
Value Function Loss: 0.01620

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.59063

Collected Steps per Second: 21,793.06137
Overall Steps per Second: 10,405.44311

Timestep Collection Time: 2.29440
Timestep Consumption Time: 2.51097
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.80537

Cumulative Model Updates: 221,444
Cumulative Timesteps: 1,846,779,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1846779510...
Checkpoint 1846779510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.18545
Policy Entropy: 2.09478
Value Function Loss: 0.01638

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.53202
Value Function Update Magnitude: 0.58268

Collected Steps per Second: 21,880.79243
Overall Steps per Second: 10,610.56725

Timestep Collection Time: 2.28520
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71247

Cumulative Model Updates: 221,450
Cumulative Timesteps: 1,846,829,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.33118
Policy Entropy: 2.13658
Value Function Loss: 0.01632

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.59017

Collected Steps per Second: 21,626.69001
Overall Steps per Second: 10,206.79782

Timestep Collection Time: 2.31344
Timestep Consumption Time: 2.58839
PPO Batch Consumption Time: 0.30342
Total Iteration Time: 4.90183

Cumulative Model Updates: 221,456
Cumulative Timesteps: 1,846,879,544

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1846879544...
Checkpoint 1846879544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.86579
Policy Entropy: 2.15260
Value Function Loss: 0.01649

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.60042

Collected Steps per Second: 21,652.45421
Overall Steps per Second: 10,242.44844

Timestep Collection Time: 2.30995
Timestep Consumption Time: 2.57326
PPO Batch Consumption Time: 0.30144
Total Iteration Time: 4.88321

Cumulative Model Updates: 221,462
Cumulative Timesteps: 1,846,929,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.80358
Policy Entropy: 2.17514
Value Function Loss: 0.01577

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 21,578.65168
Overall Steps per Second: 10,337.05178

Timestep Collection Time: 2.31840
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.83968

Cumulative Model Updates: 221,468
Cumulative Timesteps: 1,846,979,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1846979588...
Checkpoint 1846979588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.00774
Policy Entropy: 2.15653
Value Function Loss: 0.01634

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.52627
Value Function Update Magnitude: 0.60162

Collected Steps per Second: 21,635.59696
Overall Steps per Second: 10,543.87897

Timestep Collection Time: 2.31110
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74228

Cumulative Model Updates: 221,474
Cumulative Timesteps: 1,847,029,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.35719
Policy Entropy: 2.16281
Value Function Loss: 0.01621

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 22,027.71768
Overall Steps per Second: 10,403.49529

Timestep Collection Time: 2.27123
Timestep Consumption Time: 2.53773
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.80896

Cumulative Model Updates: 221,480
Cumulative Timesteps: 1,847,079,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1847079620...
Checkpoint 1847079620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.12103
Policy Entropy: 2.13319
Value Function Loss: 0.01763

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.53073
Value Function Update Magnitude: 0.59986

Collected Steps per Second: 21,958.05185
Overall Steps per Second: 10,341.14404

Timestep Collection Time: 2.27780
Timestep Consumption Time: 2.55880
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.83660

Cumulative Model Updates: 221,486
Cumulative Timesteps: 1,847,129,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.49595
Policy Entropy: 2.12132
Value Function Loss: 0.01820

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 21,826.00874
Overall Steps per Second: 10,418.56275

Timestep Collection Time: 2.29149
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.80047

Cumulative Model Updates: 221,492
Cumulative Timesteps: 1,847,179,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1847179650...
Checkpoint 1847179650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.26829
Policy Entropy: 2.10687
Value Function Loss: 0.01841

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14270
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.63211

Collected Steps per Second: 21,770.66856
Overall Steps per Second: 10,546.11235

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.44471
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.74165

Cumulative Model Updates: 221,498
Cumulative Timesteps: 1,847,229,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.97126
Policy Entropy: 2.12256
Value Function Loss: 0.01822

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.64079

Collected Steps per Second: 21,799.30598
Overall Steps per Second: 10,239.03478

Timestep Collection Time: 2.29484
Timestep Consumption Time: 2.59097
PPO Batch Consumption Time: 0.30260
Total Iteration Time: 4.88581

Cumulative Model Updates: 221,504
Cumulative Timesteps: 1,847,279,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1847279682...
Checkpoint 1847279682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.65712
Policy Entropy: 2.13397
Value Function Loss: 0.01688

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.54494
Value Function Update Magnitude: 0.63337

Collected Steps per Second: 21,774.54437
Overall Steps per Second: 10,265.23576

Timestep Collection Time: 2.29644
Timestep Consumption Time: 2.57476
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.87120

Cumulative Model Updates: 221,510
Cumulative Timesteps: 1,847,329,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.18485
Policy Entropy: 2.15145
Value Function Loss: 0.01678

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.53164
Value Function Update Magnitude: 0.59192

Collected Steps per Second: 21,901.26312
Overall Steps per Second: 10,326.29170

Timestep Collection Time: 2.28370
Timestep Consumption Time: 2.55985
PPO Batch Consumption Time: 0.30134
Total Iteration Time: 4.84356

Cumulative Model Updates: 221,516
Cumulative Timesteps: 1,847,379,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1847379702...
Checkpoint 1847379702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.19300
Policy Entropy: 2.16030
Value Function Loss: 0.01664

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.57558

Collected Steps per Second: 21,759.90854
Overall Steps per Second: 10,563.25911

Timestep Collection Time: 2.29799
Timestep Consumption Time: 2.43578
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.73377

Cumulative Model Updates: 221,522
Cumulative Timesteps: 1,847,429,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.96718
Policy Entropy: 2.16799
Value Function Loss: 0.01591

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.52468
Value Function Update Magnitude: 0.56732

Collected Steps per Second: 21,788.28817
Overall Steps per Second: 10,287.43838

Timestep Collection Time: 2.29536
Timestep Consumption Time: 2.56610
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 4.86146

Cumulative Model Updates: 221,528
Cumulative Timesteps: 1,847,479,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1847479718...
Checkpoint 1847479718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.72831
Policy Entropy: 2.15580
Value Function Loss: 0.01608

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.51851
Value Function Update Magnitude: 0.55775

Collected Steps per Second: 21,462.78544
Overall Steps per Second: 10,325.09386

Timestep Collection Time: 2.32989
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.84315

Cumulative Model Updates: 221,534
Cumulative Timesteps: 1,847,529,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.58918
Policy Entropy: 2.14250
Value Function Loss: 0.01652

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.52294
Value Function Update Magnitude: 0.55108

Collected Steps per Second: 21,985.48856
Overall Steps per Second: 10,462.66469

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.78062

Cumulative Model Updates: 221,540
Cumulative Timesteps: 1,847,579,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1847579742...
Checkpoint 1847579742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.55738
Policy Entropy: 2.12854
Value Function Loss: 0.01691

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.18000
Policy Update Magnitude: 0.51555
Value Function Update Magnitude: 0.55984

Collected Steps per Second: 21,930.12846
Overall Steps per Second: 10,512.94856

Timestep Collection Time: 2.28033
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.75680

Cumulative Model Updates: 221,546
Cumulative Timesteps: 1,847,629,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.33888
Policy Entropy: 2.14228
Value Function Loss: 0.01643

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.16724
Policy Update Magnitude: 0.51816
Value Function Update Magnitude: 0.56112

Collected Steps per Second: 21,869.00379
Overall Steps per Second: 10,238.90037

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.59700
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 4.88334

Cumulative Model Updates: 221,552
Cumulative Timesteps: 1,847,679,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1847679750...
Checkpoint 1847679750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.17196
Policy Entropy: 2.13153
Value Function Loss: 0.01796

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.15379
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.59041

Collected Steps per Second: 21,748.48518
Overall Steps per Second: 10,235.23215

Timestep Collection Time: 2.30039
Timestep Consumption Time: 2.58763
PPO Batch Consumption Time: 0.30348
Total Iteration Time: 4.88802

Cumulative Model Updates: 221,558
Cumulative Timesteps: 1,847,729,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.60589
Policy Entropy: 2.14447
Value Function Loss: 0.01845

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.55451
Value Function Update Magnitude: 0.64676

Collected Steps per Second: 21,998.28826
Overall Steps per Second: 10,471.49558

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.77582

Cumulative Model Updates: 221,564
Cumulative Timesteps: 1,847,779,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1847779790...
Checkpoint 1847779790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.88720
Policy Entropy: 2.11652
Value Function Loss: 0.01778

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.64563

Collected Steps per Second: 21,725.91378
Overall Steps per Second: 10,324.11331

Timestep Collection Time: 2.30260
Timestep Consumption Time: 2.54295
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.84555

Cumulative Model Updates: 221,570
Cumulative Timesteps: 1,847,829,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.45457
Policy Entropy: 2.11740
Value Function Loss: 0.01738

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.61972

Collected Steps per Second: 22,331.75738
Overall Steps per Second: 10,379.42857

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.57991
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.82030

Cumulative Model Updates: 221,576
Cumulative Timesteps: 1,847,879,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1847879848...
Checkpoint 1847879848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.58964
Policy Entropy: 2.09550
Value Function Loss: 0.01651

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.53055
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 21,651.72364
Overall Steps per Second: 10,220.00726

Timestep Collection Time: 2.30984
Timestep Consumption Time: 2.58370
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 4.89354

Cumulative Model Updates: 221,582
Cumulative Timesteps: 1,847,929,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.97144
Policy Entropy: 2.10088
Value Function Loss: 0.01734

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.60066

Collected Steps per Second: 21,899.66403
Overall Steps per Second: 10,413.83281

Timestep Collection Time: 2.28332
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.80169

Cumulative Model Updates: 221,588
Cumulative Timesteps: 1,847,979,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1847979864...
Checkpoint 1847979864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.70039
Policy Entropy: 2.10602
Value Function Loss: 0.01771

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.59098

Collected Steps per Second: 21,609.86075
Overall Steps per Second: 10,279.24649

Timestep Collection Time: 2.31478
Timestep Consumption Time: 2.55153
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.86631

Cumulative Model Updates: 221,594
Cumulative Timesteps: 1,848,029,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.37506
Policy Entropy: 2.11193
Value Function Loss: 0.01680

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.59628

Collected Steps per Second: 22,313.37914
Overall Steps per Second: 10,335.28216

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.59709
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.83799

Cumulative Model Updates: 221,600
Cumulative Timesteps: 1,848,079,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1848079888...
Checkpoint 1848079888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.91378
Policy Entropy: 2.13117
Value Function Loss: 0.01645

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.52446
Value Function Update Magnitude: 0.58793

Collected Steps per Second: 21,733.93140
Overall Steps per Second: 10,208.67066

Timestep Collection Time: 2.30101
Timestep Consumption Time: 2.59777
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.89878

Cumulative Model Updates: 221,606
Cumulative Timesteps: 1,848,129,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.20430
Policy Entropy: 2.12795
Value Function Loss: 0.01561

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.52121
Value Function Update Magnitude: 0.57804

Collected Steps per Second: 21,765.57171
Overall Steps per Second: 10,362.46773

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.52800
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.82530

Cumulative Model Updates: 221,612
Cumulative Timesteps: 1,848,179,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1848179900...
Checkpoint 1848179900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.32261
Policy Entropy: 2.14006
Value Function Loss: 0.01664

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.51767
Value Function Update Magnitude: 0.58517

Collected Steps per Second: 21,724.04393
Overall Steps per Second: 10,407.94461

Timestep Collection Time: 2.30252
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.80594

Cumulative Model Updates: 221,618
Cumulative Timesteps: 1,848,229,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.18415
Policy Entropy: 2.14211
Value Function Loss: 0.01685

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.51696
Value Function Update Magnitude: 0.57844

Collected Steps per Second: 21,953.95077
Overall Steps per Second: 10,377.13378

Timestep Collection Time: 2.27850
Timestep Consumption Time: 2.54191
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.82041

Cumulative Model Updates: 221,624
Cumulative Timesteps: 1,848,279,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1848279942...
Checkpoint 1848279942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.63934
Policy Entropy: 2.17608
Value Function Loss: 0.01583

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.50804
Value Function Update Magnitude: 0.55426

Collected Steps per Second: 21,451.78065
Overall Steps per Second: 10,193.35167

Timestep Collection Time: 2.33155
Timestep Consumption Time: 2.57517
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.90673

Cumulative Model Updates: 221,630
Cumulative Timesteps: 1,848,329,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.29492
Policy Entropy: 2.15492
Value Function Loss: 0.01598

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.50743
Value Function Update Magnitude: 0.53394

Collected Steps per Second: 22,028.19743
Overall Steps per Second: 10,484.38566

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.77014

Cumulative Model Updates: 221,636
Cumulative Timesteps: 1,848,379,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1848379970...
Checkpoint 1848379970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.98660
Policy Entropy: 2.12025
Value Function Loss: 0.01615

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.51872
Value Function Update Magnitude: 0.53461

Collected Steps per Second: 21,366.04892
Overall Steps per Second: 10,391.28943

Timestep Collection Time: 2.34072
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.81288

Cumulative Model Updates: 221,642
Cumulative Timesteps: 1,848,429,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.10799
Policy Entropy: 2.08661
Value Function Loss: 0.01722

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.56383

Collected Steps per Second: 22,057.41862
Overall Steps per Second: 10,281.17968

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.59696
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.86423

Cumulative Model Updates: 221,648
Cumulative Timesteps: 1,848,479,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1848479992...
Checkpoint 1848479992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.46415
Policy Entropy: 2.10682
Value Function Loss: 0.01722

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.58270

Collected Steps per Second: 21,767.93134
Overall Steps per Second: 10,255.77326

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.57927
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.87706

Cumulative Model Updates: 221,654
Cumulative Timesteps: 1,848,530,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.39478
Policy Entropy: 2.13115
Value Function Loss: 0.01655

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.52618
Value Function Update Magnitude: 0.57231

Collected Steps per Second: 21,829.40029
Overall Steps per Second: 10,358.86993

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.53710
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.82833

Cumulative Model Updates: 221,660
Cumulative Timesteps: 1,848,580,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1848580026...
Checkpoint 1848580026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.91718
Policy Entropy: 2.12943
Value Function Loss: 0.01658

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.57851

Collected Steps per Second: 20,970.46322
Overall Steps per Second: 10,240.55517

Timestep Collection Time: 2.38478
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.88352

Cumulative Model Updates: 221,666
Cumulative Timesteps: 1,848,630,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.37838
Policy Entropy: 2.11786
Value Function Loss: 0.01609

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.59368

Collected Steps per Second: 21,953.92284
Overall Steps per Second: 10,418.36706

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.80037

Cumulative Model Updates: 221,672
Cumulative Timesteps: 1,848,680,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1848680048...
Checkpoint 1848680048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.31168
Policy Entropy: 2.12110
Value Function Loss: 0.01683

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.51992
Value Function Update Magnitude: 0.57837

Collected Steps per Second: 21,690.02061
Overall Steps per Second: 10,253.81723

Timestep Collection Time: 2.30650
Timestep Consumption Time: 2.57246
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.87896

Cumulative Model Updates: 221,678
Cumulative Timesteps: 1,848,730,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.34353
Policy Entropy: 2.11267
Value Function Loss: 0.01625

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.52044
Value Function Update Magnitude: 0.56856

Collected Steps per Second: 21,868.15923
Overall Steps per Second: 10,485.32457

Timestep Collection Time: 2.28771
Timestep Consumption Time: 2.48353
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.77124

Cumulative Model Updates: 221,684
Cumulative Timesteps: 1,848,780,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1848780104...
Checkpoint 1848780104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.70817
Policy Entropy: 2.10377
Value Function Loss: 0.01624

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.52015
Value Function Update Magnitude: 0.57499

Collected Steps per Second: 21,324.49065
Overall Steps per Second: 10,322.06255

Timestep Collection Time: 2.34547
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.84554

Cumulative Model Updates: 221,690
Cumulative Timesteps: 1,848,830,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.71621
Policy Entropy: 2.10283
Value Function Loss: 0.01664

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.52602
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 21,946.38217
Overall Steps per Second: 10,316.75219

Timestep Collection Time: 2.27846
Timestep Consumption Time: 2.56841
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.84687

Cumulative Model Updates: 221,696
Cumulative Timesteps: 1,848,880,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1848880124...
Checkpoint 1848880124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.26914
Policy Entropy: 2.09363
Value Function Loss: 0.01718

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.54429
Value Function Update Magnitude: 0.60062

Collected Steps per Second: 21,296.07136
Overall Steps per Second: 10,187.28472

Timestep Collection Time: 2.34794
Timestep Consumption Time: 2.56033
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.90828

Cumulative Model Updates: 221,702
Cumulative Timesteps: 1,848,930,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.50442
Policy Entropy: 2.11016
Value Function Loss: 0.01770

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.62423

Collected Steps per Second: 21,946.74431
Overall Steps per Second: 10,461.08359

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.78191

Cumulative Model Updates: 221,708
Cumulative Timesteps: 1,848,980,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1848980150...
Checkpoint 1848980150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.72713
Policy Entropy: 2.10484
Value Function Loss: 0.01808

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.61521

Collected Steps per Second: 21,566.62663
Overall Steps per Second: 10,451.04802

Timestep Collection Time: 2.31895
Timestep Consumption Time: 2.46640
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.78536

Cumulative Model Updates: 221,714
Cumulative Timesteps: 1,849,030,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.40909
Policy Entropy: 2.12180
Value Function Loss: 0.01755

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.53676
Value Function Update Magnitude: 0.60053

Collected Steps per Second: 22,016.20116
Overall Steps per Second: 10,289.19388

Timestep Collection Time: 2.27142
Timestep Consumption Time: 2.58883
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 4.86024

Cumulative Model Updates: 221,720
Cumulative Timesteps: 1,849,080,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1849080170...
Checkpoint 1849080170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.50626
Policy Entropy: 2.09683
Value Function Loss: 0.01647

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.58976

Collected Steps per Second: 21,417.04036
Overall Steps per Second: 10,143.01666

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.59564
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.93088

Cumulative Model Updates: 221,726
Cumulative Timesteps: 1,849,130,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.91703
Policy Entropy: 2.07855
Value Function Loss: 0.01581

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.57056

Collected Steps per Second: 21,752.74464
Overall Steps per Second: 10,350.03299

Timestep Collection Time: 2.29939
Timestep Consumption Time: 2.53325
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.83264

Cumulative Model Updates: 221,732
Cumulative Timesteps: 1,849,180,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1849180202...
Checkpoint 1849180202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.46037
Policy Entropy: 2.09248
Value Function Loss: 0.01698

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.56900

Collected Steps per Second: 21,712.34546
Overall Steps per Second: 10,331.58675

Timestep Collection Time: 2.30321
Timestep Consumption Time: 2.53710
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.84030

Cumulative Model Updates: 221,738
Cumulative Timesteps: 1,849,230,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.67037
Policy Entropy: 2.11111
Value Function Loss: 0.01710

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.53220
Value Function Update Magnitude: 0.57509

Collected Steps per Second: 22,853.81339
Overall Steps per Second: 10,454.10087

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.59510
PPO Batch Consumption Time: 0.30282
Total Iteration Time: 4.78300

Cumulative Model Updates: 221,744
Cumulative Timesteps: 1,849,280,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1849280212...
Checkpoint 1849280212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.71463
Policy Entropy: 2.14229
Value Function Loss: 0.01732

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.57954

Collected Steps per Second: 21,605.77129
Overall Steps per Second: 10,189.18160

Timestep Collection Time: 2.31531
Timestep Consumption Time: 2.59421
PPO Batch Consumption Time: 0.30430
Total Iteration Time: 4.90952

Cumulative Model Updates: 221,750
Cumulative Timesteps: 1,849,330,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.04362
Policy Entropy: 2.14520
Value Function Loss: 0.01643

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 21,697.69030
Overall Steps per Second: 10,365.36310

Timestep Collection Time: 2.30568
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.82646

Cumulative Model Updates: 221,756
Cumulative Timesteps: 1,849,380,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1849380264...
Checkpoint 1849380264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.88930
Policy Entropy: 2.15731
Value Function Loss: 0.01565

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.52094
Value Function Update Magnitude: 0.59818

Collected Steps per Second: 21,670.97797
Overall Steps per Second: 10,331.36948

Timestep Collection Time: 2.30816
Timestep Consumption Time: 2.53341
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.84157

Cumulative Model Updates: 221,762
Cumulative Timesteps: 1,849,430,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.26214
Policy Entropy: 2.15452
Value Function Loss: 0.01652

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.52437
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 22,618.44023
Overall Steps per Second: 10,450.92146

Timestep Collection Time: 2.21067
Timestep Consumption Time: 2.57378
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.78446

Cumulative Model Updates: 221,768
Cumulative Timesteps: 1,849,480,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1849480286...
Checkpoint 1849480286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.59541
Policy Entropy: 2.13267
Value Function Loss: 0.01687

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.52885
Value Function Update Magnitude: 0.61539

Collected Steps per Second: 21,738.43881
Overall Steps per Second: 10,235.34143

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.58579
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.88660

Cumulative Model Updates: 221,774
Cumulative Timesteps: 1,849,530,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.65800
Policy Entropy: 2.12694
Value Function Loss: 0.01658

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.52671
Value Function Update Magnitude: 0.60866

Collected Steps per Second: 21,545.36151
Overall Steps per Second: 10,309.94366

Timestep Collection Time: 2.32161
Timestep Consumption Time: 2.53001
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.85163

Cumulative Model Updates: 221,780
Cumulative Timesteps: 1,849,580,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1849580322...
Checkpoint 1849580322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.80455
Policy Entropy: 2.11493
Value Function Loss: 0.01685

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14990
Policy Update Magnitude: 0.50488
Value Function Update Magnitude: 0.58868

Collected Steps per Second: 21,844.99957
Overall Steps per Second: 10,466.22677

Timestep Collection Time: 2.28931
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.77823

Cumulative Model Updates: 221,786
Cumulative Timesteps: 1,849,630,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.00587
Policy Entropy: 2.11901
Value Function Loss: 0.01727

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.51712
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 22,268.98411
Overall Steps per Second: 10,326.10448

Timestep Collection Time: 2.24608
Timestep Consumption Time: 2.59776
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.84384

Cumulative Model Updates: 221,792
Cumulative Timesteps: 1,849,680,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1849680350...
Checkpoint 1849680350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.44670
Policy Entropy: 2.12582
Value Function Loss: 0.01694

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.52597
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 21,781.30395
Overall Steps per Second: 10,247.23493

Timestep Collection Time: 2.29646
Timestep Consumption Time: 2.58485
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 4.88132

Cumulative Model Updates: 221,798
Cumulative Timesteps: 1,849,730,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.04627
Policy Entropy: 2.13494
Value Function Loss: 0.01695

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.57694

Collected Steps per Second: 21,728.01436
Overall Steps per Second: 10,418.54617

Timestep Collection Time: 2.30219
Timestep Consumption Time: 2.49906
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.80125

Cumulative Model Updates: 221,804
Cumulative Timesteps: 1,849,780,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1849780392...
Checkpoint 1849780392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.69345
Policy Entropy: 2.12940
Value Function Loss: 0.01660

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.56433

Collected Steps per Second: 21,695.17152
Overall Steps per Second: 10,549.24926

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.74214

Cumulative Model Updates: 221,810
Cumulative Timesteps: 1,849,830,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.65974
Policy Entropy: 2.12313
Value Function Loss: 0.01678

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.52503
Value Function Update Magnitude: 0.56720

Collected Steps per Second: 22,184.23812
Overall Steps per Second: 10,470.04739

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.52228
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.77667

Cumulative Model Updates: 221,816
Cumulative Timesteps: 1,849,880,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1849880430...
Checkpoint 1849880430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.22280
Policy Entropy: 2.12176
Value Function Loss: 0.01606

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.52390
Value Function Update Magnitude: 0.55699

Collected Steps per Second: 22,007.98065
Overall Steps per Second: 10,372.06447

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.54884
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 4.82083

Cumulative Model Updates: 221,822
Cumulative Timesteps: 1,849,930,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.88030
Policy Entropy: 2.13209
Value Function Loss: 0.01620

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.51847
Value Function Update Magnitude: 0.55866

Collected Steps per Second: 21,623.25232
Overall Steps per Second: 10,384.66777

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.81768

Cumulative Model Updates: 221,828
Cumulative Timesteps: 1,849,980,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1849980462...
Checkpoint 1849980462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.80893
Policy Entropy: 2.13989
Value Function Loss: 0.01645

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.52245
Value Function Update Magnitude: 0.56703

Collected Steps per Second: 22,609.31294
Overall Steps per Second: 10,566.39213

Timestep Collection Time: 2.21165
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.73236

Cumulative Model Updates: 221,834
Cumulative Timesteps: 1,850,030,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.25530
Policy Entropy: 2.13047
Value Function Loss: 0.01733

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.53322
Value Function Update Magnitude: 0.56980

Collected Steps per Second: 21,646.29570
Overall Steps per Second: 10,238.55208

Timestep Collection Time: 2.31051
Timestep Consumption Time: 2.57436
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.88487

Cumulative Model Updates: 221,840
Cumulative Timesteps: 1,850,080,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1850080480...
Checkpoint 1850080480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.10021
Policy Entropy: 2.13901
Value Function Loss: 0.01761

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.53927
Value Function Update Magnitude: 0.57726

Collected Steps per Second: 21,563.84006
Overall Steps per Second: 10,387.42094

Timestep Collection Time: 2.31990
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.81602

Cumulative Model Updates: 221,846
Cumulative Timesteps: 1,850,130,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.34751
Policy Entropy: 2.11954
Value Function Loss: 0.01778

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.58328

Collected Steps per Second: 21,758.83953
Overall Steps per Second: 10,436.73984

Timestep Collection Time: 2.29920
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.79345

Cumulative Model Updates: 221,852
Cumulative Timesteps: 1,850,180,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1850180534...
Checkpoint 1850180534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.66552
Policy Entropy: 2.11537
Value Function Loss: 0.01786

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 21,597.90272
Overall Steps per Second: 10,417.79864

Timestep Collection Time: 2.31522
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.79986

Cumulative Model Updates: 221,858
Cumulative Timesteps: 1,850,230,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.37473
Policy Entropy: 2.10520
Value Function Loss: 0.01846

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.61718

Collected Steps per Second: 21,986.34177
Overall Steps per Second: 10,368.56861

Timestep Collection Time: 2.27605
Timestep Consumption Time: 2.55027
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.82632

Cumulative Model Updates: 221,864
Cumulative Timesteps: 1,850,280,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1850280580...
Checkpoint 1850280580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.06122
Policy Entropy: 2.12525
Value Function Loss: 0.01837

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 21,713.22888
Overall Steps per Second: 10,211.18936

Timestep Collection Time: 2.30413
Timestep Consumption Time: 2.59540
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.89953

Cumulative Model Updates: 221,870
Cumulative Timesteps: 1,850,330,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.38755
Policy Entropy: 2.13562
Value Function Loss: 0.01936

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 21,557.00907
Overall Steps per Second: 10,466.05826

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.77926

Cumulative Model Updates: 221,876
Cumulative Timesteps: 1,850,380,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1850380630...
Checkpoint 1850380630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.89494
Policy Entropy: 2.12422
Value Function Loss: 0.01788

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 21,989.55006
Overall Steps per Second: 10,379.15065

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.54466
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.81947

Cumulative Model Updates: 221,882
Cumulative Timesteps: 1,850,430,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.15512
Policy Entropy: 2.13167
Value Function Loss: 0.01737

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 22,106.56807
Overall Steps per Second: 10,310.44819

Timestep Collection Time: 2.26222
Timestep Consumption Time: 2.58820
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 4.85042

Cumulative Model Updates: 221,888
Cumulative Timesteps: 1,850,480,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1850480662...
Checkpoint 1850480662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.60864
Policy Entropy: 2.15507
Value Function Loss: 0.01678

Mean KL Divergence: 0.02918
SB3 Clip Fraction: 0.17893
Policy Update Magnitude: 0.47724
Value Function Update Magnitude: 0.58314

Collected Steps per Second: 21,682.57097
Overall Steps per Second: 10,275.79363

Timestep Collection Time: 2.30738
Timestep Consumption Time: 2.56134
PPO Batch Consumption Time: 0.30269
Total Iteration Time: 4.86872

Cumulative Model Updates: 221,894
Cumulative Timesteps: 1,850,530,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.27610
Policy Entropy: 2.17119
Value Function Loss: 0.01838

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.16590
Policy Update Magnitude: 0.50832
Value Function Update Magnitude: 0.58369

Collected Steps per Second: 21,847.93070
Overall Steps per Second: 10,450.64997

Timestep Collection Time: 2.28974
Timestep Consumption Time: 2.49714
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 4.78688

Cumulative Model Updates: 221,900
Cumulative Timesteps: 1,850,580,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1850580718...
Checkpoint 1850580718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.91841
Policy Entropy: 2.16846
Value Function Loss: 0.01927

Mean KL Divergence: 0.03089
SB3 Clip Fraction: 0.18151
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.59681

Collected Steps per Second: 22,013.34524
Overall Steps per Second: 10,428.88258

Timestep Collection Time: 2.27208
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.79591

Cumulative Model Updates: 221,906
Cumulative Timesteps: 1,850,630,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.40565
Policy Entropy: 2.14388
Value Function Loss: 0.01922

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.16065
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.61031

Collected Steps per Second: 21,798.34280
Overall Steps per Second: 10,249.18156

Timestep Collection Time: 2.29495
Timestep Consumption Time: 2.58603
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 4.88098

Cumulative Model Updates: 221,912
Cumulative Timesteps: 1,850,680,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1850680760...
Checkpoint 1850680760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.58331
Policy Entropy: 2.16108
Value Function Loss: 0.01808

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.54544
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 21,442.95887
Overall Steps per Second: 10,226.84296

Timestep Collection Time: 2.33289
Timestep Consumption Time: 2.55855
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 4.89144

Cumulative Model Updates: 221,918
Cumulative Timesteps: 1,850,730,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.28855
Policy Entropy: 2.17211
Value Function Loss: 0.01797

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 22,033.20608
Overall Steps per Second: 10,515.41730

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.75740

Cumulative Model Updates: 221,924
Cumulative Timesteps: 1,850,780,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1850780810...
Checkpoint 1850780810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.53463
Policy Entropy: 2.20426
Value Function Loss: 0.01695

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 21,881.58159
Overall Steps per Second: 10,400.56563

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.81032

Cumulative Model Updates: 221,930
Cumulative Timesteps: 1,850,830,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.72847
Policy Entropy: 2.19119
Value Function Loss: 0.01739

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.57954

Collected Steps per Second: 22,310.90142
Overall Steps per Second: 10,457.02847

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.54133
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.78319

Cumulative Model Updates: 221,936
Cumulative Timesteps: 1,850,880,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1850880858...
Checkpoint 1850880858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.19109
Policy Entropy: 2.16937
Value Function Loss: 0.01775

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.15614
Policy Update Magnitude: 0.51787
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 21,514.76156
Overall Steps per Second: 10,283.52459

Timestep Collection Time: 2.32464
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.86351

Cumulative Model Updates: 221,942
Cumulative Timesteps: 1,850,930,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.71952
Policy Entropy: 2.14801
Value Function Loss: 0.01767

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.58426

Collected Steps per Second: 21,701.66875
Overall Steps per Second: 10,466.87398

Timestep Collection Time: 2.30462
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.77831

Cumulative Model Updates: 221,948
Cumulative Timesteps: 1,850,980,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1850980886...
Checkpoint 1850980886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.79264
Policy Entropy: 2.15367
Value Function Loss: 0.01748

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 21,790.32131
Overall Steps per Second: 10,241.94842

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.58811
PPO Batch Consumption Time: 0.30390
Total Iteration Time: 4.88345

Cumulative Model Updates: 221,954
Cumulative Timesteps: 1,851,030,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.93124
Policy Entropy: 2.18353
Value Function Loss: 0.01668

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.52772
Value Function Update Magnitude: 0.62043

Collected Steps per Second: 21,976.62586
Overall Steps per Second: 10,422.06292

Timestep Collection Time: 2.27633
Timestep Consumption Time: 2.52368
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.80001

Cumulative Model Updates: 221,960
Cumulative Timesteps: 1,851,080,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1851080928...
Checkpoint 1851080928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.83158
Policy Entropy: 2.21192
Value Function Loss: 0.01754

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.53043
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 21,482.80302
Overall Steps per Second: 10,211.35629

Timestep Collection Time: 2.32837
Timestep Consumption Time: 2.57009
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.89847

Cumulative Model Updates: 221,966
Cumulative Timesteps: 1,851,130,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.25032
Policy Entropy: 2.23105
Value Function Loss: 0.01703

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.53196
Value Function Update Magnitude: 0.61763

Collected Steps per Second: 22,027.33340
Overall Steps per Second: 10,461.54802

Timestep Collection Time: 2.27181
Timestep Consumption Time: 2.51161
PPO Batch Consumption Time: 0.30470
Total Iteration Time: 4.78342

Cumulative Model Updates: 221,972
Cumulative Timesteps: 1,851,180,990

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1851180990...
Checkpoint 1851180990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.87548
Policy Entropy: 2.21776
Value Function Loss: 0.01837

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.58711

Collected Steps per Second: 21,702.95156
Overall Steps per Second: 10,229.28392

Timestep Collection Time: 2.30503
Timestep Consumption Time: 2.58544
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.89047

Cumulative Model Updates: 221,978
Cumulative Timesteps: 1,851,231,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.96341
Policy Entropy: 2.20799
Value Function Loss: 0.01735

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 21,944.01275
Overall Steps per Second: 10,358.07137

Timestep Collection Time: 2.27889
Timestep Consumption Time: 2.54904
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.82793

Cumulative Model Updates: 221,984
Cumulative Timesteps: 1,851,281,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1851281024...
Checkpoint 1851281024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.40250
Policy Entropy: 2.19889
Value Function Loss: 0.01722

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.52087
Value Function Update Magnitude: 0.58593

Collected Steps per Second: 21,736.56047
Overall Steps per Second: 10,283.85344

Timestep Collection Time: 2.30082
Timestep Consumption Time: 2.56233
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.86316

Cumulative Model Updates: 221,990
Cumulative Timesteps: 1,851,331,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.53914
Policy Entropy: 2.18958
Value Function Loss: 0.01657

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.52738
Value Function Update Magnitude: 0.57343

Collected Steps per Second: 21,973.83122
Overall Steps per Second: 10,468.64113

Timestep Collection Time: 2.27607
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.77751

Cumulative Model Updates: 221,996
Cumulative Timesteps: 1,851,381,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1851381050...
Checkpoint 1851381050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.53989
Policy Entropy: 2.17030
Value Function Loss: 0.01737

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.56816

Collected Steps per Second: 21,595.68542
Overall Steps per Second: 10,202.64884

Timestep Collection Time: 2.31620
Timestep Consumption Time: 2.58644
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 4.90265

Cumulative Model Updates: 222,002
Cumulative Timesteps: 1,851,431,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.61909
Policy Entropy: 2.16426
Value Function Loss: 0.01718

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.53278
Value Function Update Magnitude: 0.56939

Collected Steps per Second: 21,733.60003
Overall Steps per Second: 10,318.08307

Timestep Collection Time: 2.30151
Timestep Consumption Time: 2.54629
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.84780

Cumulative Model Updates: 222,008
Cumulative Timesteps: 1,851,481,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1851481090...
Checkpoint 1851481090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.12856
Policy Entropy: 2.16609
Value Function Loss: 0.01654

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 21,498.02456
Overall Steps per Second: 10,336.49002

Timestep Collection Time: 2.32728
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.84033

Cumulative Model Updates: 222,014
Cumulative Timesteps: 1,851,531,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.50727
Policy Entropy: 2.17093
Value Function Loss: 0.01644

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.56281

Collected Steps per Second: 21,853.76770
Overall Steps per Second: 10,441.95120

Timestep Collection Time: 2.28794
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.78838

Cumulative Model Updates: 222,020
Cumulative Timesteps: 1,851,581,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1851581122...
Checkpoint 1851581122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.18794
Policy Entropy: 2.16030
Value Function Loss: 0.01673

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.54454
Value Function Update Magnitude: 0.56885

Collected Steps per Second: 21,412.95724
Overall Steps per Second: 10,368.38764

Timestep Collection Time: 2.33606
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.82447

Cumulative Model Updates: 222,026
Cumulative Timesteps: 1,851,631,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.27984
Policy Entropy: 2.16504
Value Function Loss: 0.01602

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.57180

Collected Steps per Second: 21,996.53159
Overall Steps per Second: 10,371.35158

Timestep Collection Time: 2.27372
Timestep Consumption Time: 2.54860
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.82232

Cumulative Model Updates: 222,032
Cumulative Timesteps: 1,851,681,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1851681158...
Checkpoint 1851681158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.55144
Policy Entropy: 2.19285
Value Function Loss: 0.01555

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.56158

Collected Steps per Second: 21,355.43896
Overall Steps per Second: 10,193.88661

Timestep Collection Time: 2.34235
Timestep Consumption Time: 2.56470
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.90706

Cumulative Model Updates: 222,038
Cumulative Timesteps: 1,851,731,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.25651
Policy Entropy: 2.19481
Value Function Loss: 0.01500

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.51753
Value Function Update Magnitude: 0.55645

Collected Steps per Second: 21,637.24690
Overall Steps per Second: 10,466.85948

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.46694
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.77851

Cumulative Model Updates: 222,044
Cumulative Timesteps: 1,851,781,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1851781196...
Checkpoint 1851781196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.59545
Policy Entropy: 2.19121
Value Function Loss: 0.01613

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.51776
Value Function Update Magnitude: 0.54481

Collected Steps per Second: 21,750.42857
Overall Steps per Second: 10,247.88805

Timestep Collection Time: 2.29972
Timestep Consumption Time: 2.58128
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 4.88101

Cumulative Model Updates: 222,050
Cumulative Timesteps: 1,851,831,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.65606
Policy Entropy: 2.17656
Value Function Loss: 0.01724

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.54186

Collected Steps per Second: 21,787.49373
Overall Steps per Second: 10,340.20323

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.54111
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.83646

Cumulative Model Updates: 222,056
Cumulative Timesteps: 1,851,881,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1851881226...
Checkpoint 1851881226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.97832
Policy Entropy: 2.17252
Value Function Loss: 0.01713

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.54695

Collected Steps per Second: 21,245.91252
Overall Steps per Second: 10,285.94465

Timestep Collection Time: 2.35377
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.86178

Cumulative Model Updates: 222,062
Cumulative Timesteps: 1,851,931,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.65752
Policy Entropy: 2.15655
Value Function Loss: 0.01703

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.54759

Collected Steps per Second: 21,767.47018
Overall Steps per Second: 10,457.06703

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.78299

Cumulative Model Updates: 222,068
Cumulative Timesteps: 1,851,981,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1851981250...
Checkpoint 1851981250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.46982
Policy Entropy: 2.14871
Value Function Loss: 0.01636

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.53190
Value Function Update Magnitude: 0.55631

Collected Steps per Second: 21,559.84770
Overall Steps per Second: 10,208.87846

Timestep Collection Time: 2.31978
Timestep Consumption Time: 2.57929
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.89907

Cumulative Model Updates: 222,074
Cumulative Timesteps: 1,852,031,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.95443
Policy Entropy: 2.12999
Value Function Loss: 0.01682

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.57175

Collected Steps per Second: 21,806.70657
Overall Steps per Second: 10,344.25580

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.54073
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.83360

Cumulative Model Updates: 222,080
Cumulative Timesteps: 1,852,081,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1852081264...
Checkpoint 1852081264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.21002
Policy Entropy: 2.13887
Value Function Loss: 0.01656

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.54139
Value Function Update Magnitude: 0.57706

Collected Steps per Second: 21,772.11163
Overall Steps per Second: 10,285.02182

Timestep Collection Time: 2.29716
Timestep Consumption Time: 2.56564
PPO Batch Consumption Time: 0.30224
Total Iteration Time: 4.86280

Cumulative Model Updates: 222,086
Cumulative Timesteps: 1,852,131,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.18724
Policy Entropy: 2.14417
Value Function Loss: 0.01826

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.57477

Collected Steps per Second: 21,954.21974
Overall Steps per Second: 10,481.16975

Timestep Collection Time: 2.27747
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.77046

Cumulative Model Updates: 222,092
Cumulative Timesteps: 1,852,181,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1852181278...
Checkpoint 1852181278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.28290
Policy Entropy: 2.16423
Value Function Loss: 0.01768

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.57961

Collected Steps per Second: 21,364.71564
Overall Steps per Second: 10,219.60275

Timestep Collection Time: 2.34106
Timestep Consumption Time: 2.55307
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.89412

Cumulative Model Updates: 222,098
Cumulative Timesteps: 1,852,231,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.62183
Policy Entropy: 2.16335
Value Function Loss: 0.01748

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.52808
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 20,123.13858
Overall Steps per Second: 9,788.03929

Timestep Collection Time: 2.48609
Timestep Consumption Time: 2.62504
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 5.11114

Cumulative Model Updates: 222,104
Cumulative Timesteps: 1,852,281,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1852281322...
Checkpoint 1852281322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.57240
Policy Entropy: 2.15074
Value Function Loss: 0.01664

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.54501

Collected Steps per Second: 21,420.37822
Overall Steps per Second: 10,349.25700

Timestep Collection Time: 2.33460
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.83204

Cumulative Model Updates: 222,110
Cumulative Timesteps: 1,852,331,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.25173
Policy Entropy: 2.15057
Value Function Loss: 0.01713

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.54314

Collected Steps per Second: 22,054.55718
Overall Steps per Second: 10,498.08390

Timestep Collection Time: 2.26792
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.76449

Cumulative Model Updates: 222,116
Cumulative Timesteps: 1,852,381,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1852381348...
Checkpoint 1852381348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.56636
Policy Entropy: 2.15274
Value Function Loss: 0.01811

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.55614

Collected Steps per Second: 22,021.59763
Overall Steps per Second: 10,601.74315

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71715

Cumulative Model Updates: 222,122
Cumulative Timesteps: 1,852,431,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.53646
Policy Entropy: 2.16023
Value Function Loss: 0.01688

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.58884

Collected Steps per Second: 22,150.27269
Overall Steps per Second: 10,367.78609

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.56604
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.82398

Cumulative Model Updates: 222,128
Cumulative Timesteps: 1,852,481,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1852481372...
Checkpoint 1852481372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.61975
Policy Entropy: 2.14314
Value Function Loss: 0.01791

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.19139
Policy Update Magnitude: 0.50736
Value Function Update Magnitude: 0.59751

Collected Steps per Second: 21,774.87146
Overall Steps per Second: 10,344.65562

Timestep Collection Time: 2.29678
Timestep Consumption Time: 2.53780
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.83457

Cumulative Model Updates: 222,134
Cumulative Timesteps: 1,852,531,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.64925
Policy Entropy: 2.13550
Value Function Loss: 0.01699

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 22,001.28367
Overall Steps per Second: 10,478.40071

Timestep Collection Time: 2.27332
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.77325

Cumulative Model Updates: 222,140
Cumulative Timesteps: 1,852,581,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1852581400...
Checkpoint 1852581400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.53466
Policy Entropy: 2.10332
Value Function Loss: 0.01850

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.16268
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.57029

Collected Steps per Second: 21,648.46487
Overall Steps per Second: 10,486.80395

Timestep Collection Time: 2.31083
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.77038

Cumulative Model Updates: 222,146
Cumulative Timesteps: 1,852,631,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.79537
Policy Entropy: 2.10086
Value Function Loss: 0.01870

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.16264
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.58037

Collected Steps per Second: 22,121.59615
Overall Steps per Second: 10,335.63921

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.57812
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.83898

Cumulative Model Updates: 222,152
Cumulative Timesteps: 1,852,681,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1852681440...
Checkpoint 1852681440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.77952
Policy Entropy: 2.10298
Value Function Loss: 0.01859

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.57135
Value Function Update Magnitude: 0.59447

Collected Steps per Second: 21,932.11177
Overall Steps per Second: 10,403.18965

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.80680

Cumulative Model Updates: 222,158
Cumulative Timesteps: 1,852,731,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.79879
Policy Entropy: 2.10317
Value Function Loss: 0.01785

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.15792
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.60293

Collected Steps per Second: 21,863.77129
Overall Steps per Second: 10,477.07503

Timestep Collection Time: 2.28716
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.77290

Cumulative Model Updates: 222,164
Cumulative Timesteps: 1,852,781,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1852781452...
Checkpoint 1852781452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.04796
Policy Entropy: 2.13520
Value Function Loss: 0.01658

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.59126

Collected Steps per Second: 21,989.88497
Overall Steps per Second: 10,326.34594

Timestep Collection Time: 2.27432
Timestep Consumption Time: 2.56883
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 4.84315

Cumulative Model Updates: 222,170
Cumulative Timesteps: 1,852,831,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.96047
Policy Entropy: 2.13318
Value Function Loss: 0.01630

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.57943

Collected Steps per Second: 21,624.15733
Overall Steps per Second: 10,468.55752

Timestep Collection Time: 2.31334
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.77850

Cumulative Model Updates: 222,176
Cumulative Timesteps: 1,852,881,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1852881488...
Checkpoint 1852881488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.10110
Policy Entropy: 2.14425
Value Function Loss: 0.01611

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.17258
Policy Update Magnitude: 0.50661
Value Function Update Magnitude: 0.57859

Collected Steps per Second: 21,771.38677
Overall Steps per Second: 10,261.80091

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.57595
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.87263

Cumulative Model Updates: 222,182
Cumulative Timesteps: 1,852,931,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.76261
Policy Entropy: 2.14514
Value Function Loss: 0.01593

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.18324
Policy Update Magnitude: 0.48097
Value Function Update Magnitude: 0.56970

Collected Steps per Second: 21,900.24579
Overall Steps per Second: 10,406.94730

Timestep Collection Time: 2.28427
Timestep Consumption Time: 2.52271
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.80698

Cumulative Model Updates: 222,188
Cumulative Timesteps: 1,852,981,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1852981516...
Checkpoint 1852981516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.55514
Policy Entropy: 2.15248
Value Function Loss: 0.01594

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.18211
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.56001

Collected Steps per Second: 21,345.55238
Overall Steps per Second: 10,161.64540

Timestep Collection Time: 2.34353
Timestep Consumption Time: 2.57929
PPO Batch Consumption Time: 0.30654
Total Iteration Time: 4.92282

Cumulative Model Updates: 222,194
Cumulative Timesteps: 1,853,031,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.85877
Policy Entropy: 2.16458
Value Function Loss: 0.01604

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.50888
Value Function Update Magnitude: 0.54734

Collected Steps per Second: 21,774.25814
Overall Steps per Second: 10,486.78890

Timestep Collection Time: 2.29721
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.76981

Cumulative Model Updates: 222,200
Cumulative Timesteps: 1,853,081,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1853081560...
Checkpoint 1853081560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.52926
Policy Entropy: 2.15531
Value Function Loss: 0.01593

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.55656

Collected Steps per Second: 21,643.34399
Overall Steps per Second: 10,209.67853

Timestep Collection Time: 2.31073
Timestep Consumption Time: 2.58776
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.89849

Cumulative Model Updates: 222,206
Cumulative Timesteps: 1,853,131,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.34036
Policy Entropy: 2.15324
Value Function Loss: 0.01556

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.56082

Collected Steps per Second: 21,597.39657
Overall Steps per Second: 10,259.96961

Timestep Collection Time: 2.31630
Timestep Consumption Time: 2.55955
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.87584

Cumulative Model Updates: 222,212
Cumulative Timesteps: 1,853,181,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1853181598...
Checkpoint 1853181598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.64453
Policy Entropy: 2.12173
Value Function Loss: 0.01669

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.54948
Value Function Update Magnitude: 0.56822

Collected Steps per Second: 21,737.61596
Overall Steps per Second: 10,438.55496

Timestep Collection Time: 2.30099
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.79166

Cumulative Model Updates: 222,218
Cumulative Timesteps: 1,853,231,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.23021
Policy Entropy: 2.10004
Value Function Loss: 0.01729

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.58906

Collected Steps per Second: 21,724.60837
Overall Steps per Second: 10,395.32232

Timestep Collection Time: 2.30264
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.81216

Cumulative Model Updates: 222,224
Cumulative Timesteps: 1,853,281,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1853281640...
Checkpoint 1853281640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.72449
Policy Entropy: 2.10831
Value Function Loss: 0.01768

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.60580

Collected Steps per Second: 21,882.02282
Overall Steps per Second: 10,571.33300

Timestep Collection Time: 2.28589
Timestep Consumption Time: 2.44577
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.73166

Cumulative Model Updates: 222,230
Cumulative Timesteps: 1,853,331,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.29167
Policy Entropy: 2.14765
Value Function Loss: 0.01612

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 22,191.83475
Overall Steps per Second: 10,470.80724

Timestep Collection Time: 2.25407
Timestep Consumption Time: 2.52321
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.77728

Cumulative Model Updates: 222,236
Cumulative Timesteps: 1,853,381,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1853381682...
Checkpoint 1853381682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.09356
Policy Entropy: 2.17469
Value Function Loss: 0.01602

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.56880

Collected Steps per Second: 21,989.07368
Overall Steps per Second: 10,383.44616

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.54303
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.81825

Cumulative Model Updates: 222,242
Cumulative Timesteps: 1,853,431,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.34254
Policy Entropy: 2.17796
Value Function Loss: 0.01534

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 21,684.28423
Overall Steps per Second: 10,384.65926

Timestep Collection Time: 2.30665
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.81653

Cumulative Model Updates: 222,248
Cumulative Timesteps: 1,853,481,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1853481730...
Checkpoint 1853481730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.50574
Policy Entropy: 2.16761
Value Function Loss: 0.01754

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.57554

Collected Steps per Second: 21,785.85456
Overall Steps per Second: 10,545.45506

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74214

Cumulative Model Updates: 222,254
Cumulative Timesteps: 1,853,531,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.86151
Policy Entropy: 2.15622
Value Function Loss: 0.01777

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.58385

Collected Steps per Second: 22,374.72789
Overall Steps per Second: 10,486.74980

Timestep Collection Time: 2.23565
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77002

Cumulative Model Updates: 222,260
Cumulative Timesteps: 1,853,581,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1853581760...
Checkpoint 1853581760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.77052
Policy Entropy: 2.15456
Value Function Loss: 0.01734

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.55494
Value Function Update Magnitude: 0.59541

Collected Steps per Second: 21,839.82897
Overall Steps per Second: 10,283.94528

Timestep Collection Time: 2.29022
Timestep Consumption Time: 2.57348
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.86370

Cumulative Model Updates: 222,266
Cumulative Timesteps: 1,853,631,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.56139
Policy Entropy: 2.16289
Value Function Loss: 0.01664

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.56001

Collected Steps per Second: 21,889.83145
Overall Steps per Second: 10,458.80707

Timestep Collection Time: 2.28471
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.78181

Cumulative Model Updates: 222,272
Cumulative Timesteps: 1,853,681,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1853681790...
Checkpoint 1853681790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.56506
Policy Entropy: 2.15606
Value Function Loss: 0.01635

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.53642
Value Function Update Magnitude: 0.52460

Collected Steps per Second: 21,542.62347
Overall Steps per Second: 10,493.50246

Timestep Collection Time: 2.32126
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.76543

Cumulative Model Updates: 222,278
Cumulative Timesteps: 1,853,731,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.11619
Policy Entropy: 2.16488
Value Function Loss: 0.01675

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.53055

Collected Steps per Second: 22,250.85623
Overall Steps per Second: 10,428.73090

Timestep Collection Time: 2.24845
Timestep Consumption Time: 2.54887
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.79732

Cumulative Model Updates: 222,284
Cumulative Timesteps: 1,853,781,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1853781826...
Checkpoint 1853781826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.28378
Policy Entropy: 2.15945
Value Function Loss: 0.01666

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.53752
Value Function Update Magnitude: 0.54891

Collected Steps per Second: 21,668.66292
Overall Steps per Second: 10,311.37032

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.54265
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.85115

Cumulative Model Updates: 222,290
Cumulative Timesteps: 1,853,831,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.94788
Policy Entropy: 2.17136
Value Function Loss: 0.01635

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.53779
Value Function Update Magnitude: 0.57597

Collected Steps per Second: 22,031.00024
Overall Steps per Second: 10,467.68564

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.77737

Cumulative Model Updates: 222,296
Cumulative Timesteps: 1,853,881,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1853881856...
Checkpoint 1853881856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.45935
Policy Entropy: 2.15784
Value Function Loss: 0.01618

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 21,730.82898
Overall Steps per Second: 10,497.97375

Timestep Collection Time: 2.30106
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.76320

Cumulative Model Updates: 222,302
Cumulative Timesteps: 1,853,931,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.26009
Policy Entropy: 2.14102
Value Function Loss: 0.01654

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.56116

Collected Steps per Second: 22,067.16348
Overall Steps per Second: 10,338.40665

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.57207
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.83924

Cumulative Model Updates: 222,308
Cumulative Timesteps: 1,853,981,890

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1853981890...
Checkpoint 1853981890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.97944
Policy Entropy: 2.12871
Value Function Loss: 0.01628

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.55799

Collected Steps per Second: 21,239.31817
Overall Steps per Second: 10,085.28644

Timestep Collection Time: 2.35422
Timestep Consumption Time: 2.60370
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 4.95792

Cumulative Model Updates: 222,314
Cumulative Timesteps: 1,854,031,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.27757
Policy Entropy: 2.13372
Value Function Loss: 0.01683

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 21,928.21810
Overall Steps per Second: 10,432.54865

Timestep Collection Time: 2.28108
Timestep Consumption Time: 2.51353
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.79461

Cumulative Model Updates: 222,320
Cumulative Timesteps: 1,854,081,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854081912...
Checkpoint 1854081912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.65334
Policy Entropy: 2.14577
Value Function Loss: 0.01727

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.55348

Collected Steps per Second: 21,344.27269
Overall Steps per Second: 10,294.73574

Timestep Collection Time: 2.34339
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.85860

Cumulative Model Updates: 222,326
Cumulative Timesteps: 1,854,131,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.76522
Policy Entropy: 2.16572
Value Function Loss: 0.01709

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.57628

Collected Steps per Second: 22,205.38767
Overall Steps per Second: 10,392.67638

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.55999
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.81223

Cumulative Model Updates: 222,332
Cumulative Timesteps: 1,854,181,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1854181942...
Checkpoint 1854181942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.90596
Policy Entropy: 2.16086
Value Function Loss: 0.01568

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12324
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 21,705.56861
Overall Steps per Second: 10,215.14850

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.59155
PPO Batch Consumption Time: 0.30471
Total Iteration Time: 4.89547

Cumulative Model Updates: 222,338
Cumulative Timesteps: 1,854,231,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.44598
Policy Entropy: 2.16574
Value Function Loss: 0.01564

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.52602
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 21,960.51986
Overall Steps per Second: 10,455.77821

Timestep Collection Time: 2.27891
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78644

Cumulative Model Updates: 222,344
Cumulative Timesteps: 1,854,281,996

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1854281996...
Checkpoint 1854281996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.28600
Policy Entropy: 2.18814
Value Function Loss: 0.01704

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.57816

Collected Steps per Second: 21,692.85953
Overall Steps per Second: 10,548.36922

Timestep Collection Time: 2.30500
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.74026

Cumulative Model Updates: 222,350
Cumulative Timesteps: 1,854,331,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.71035
Policy Entropy: 2.16604
Value Function Loss: 0.01788

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.58520

Collected Steps per Second: 22,288.05195
Overall Steps per Second: 10,499.97260

Timestep Collection Time: 2.24407
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76344

Cumulative Model Updates: 222,356
Cumulative Timesteps: 1,854,382,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1854382014...
Checkpoint 1854382014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.58054
Policy Entropy: 2.14237
Value Function Loss: 0.01879

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 21,434.01077
Overall Steps per Second: 10,262.08187

Timestep Collection Time: 2.33274
Timestep Consumption Time: 2.53956
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.87231

Cumulative Model Updates: 222,362
Cumulative Timesteps: 1,854,432,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.15562
Policy Entropy: 2.13125
Value Function Loss: 0.01690

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 21,836.60695
Overall Steps per Second: 10,404.07181

Timestep Collection Time: 2.28992
Timestep Consumption Time: 2.51628
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.80620

Cumulative Model Updates: 222,368
Cumulative Timesteps: 1,854,482,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1854482018...
Checkpoint 1854482018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.08438
Policy Entropy: 2.11825
Value Function Loss: 0.01648

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.56292

Collected Steps per Second: 21,658.57822
Overall Steps per Second: 10,539.35882

Timestep Collection Time: 2.30939
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.74583

Cumulative Model Updates: 222,374
Cumulative Timesteps: 1,854,532,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.31305
Policy Entropy: 2.12393
Value Function Loss: 0.01573

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.55545
Value Function Update Magnitude: 0.56016

Collected Steps per Second: 22,480.00069
Overall Steps per Second: 10,526.83971

Timestep Collection Time: 2.22509
Timestep Consumption Time: 2.52657
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.75166

Cumulative Model Updates: 222,380
Cumulative Timesteps: 1,854,582,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854582056...
Checkpoint 1854582056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.42145
Policy Entropy: 2.11386
Value Function Loss: 0.01613

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 21,608.97585
Overall Steps per Second: 10,276.15086

Timestep Collection Time: 2.31506
Timestep Consumption Time: 2.55311
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.86817

Cumulative Model Updates: 222,386
Cumulative Timesteps: 1,854,632,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.23740
Policy Entropy: 2.12917
Value Function Loss: 0.01706

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.59438

Collected Steps per Second: 22,140.22304
Overall Steps per Second: 10,454.84906

Timestep Collection Time: 2.25924
Timestep Consumption Time: 2.52515
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.78438

Cumulative Model Updates: 222,392
Cumulative Timesteps: 1,854,682,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854682102...
Checkpoint 1854682102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.98474
Policy Entropy: 2.10045
Value Function Loss: 0.01686

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 21,337.36022
Overall Steps per Second: 10,202.03996

Timestep Collection Time: 2.34425
Timestep Consumption Time: 2.55870
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.90294

Cumulative Model Updates: 222,398
Cumulative Timesteps: 1,854,732,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.15046
Policy Entropy: 2.11173
Value Function Loss: 0.01675

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.15591
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.60240

Collected Steps per Second: 21,821.87340
Overall Steps per Second: 10,466.99080

Timestep Collection Time: 2.29220
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.77883

Cumulative Model Updates: 222,404
Cumulative Timesteps: 1,854,782,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1854782142...
Checkpoint 1854782142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.39798
Policy Entropy: 2.13216
Value Function Loss: 0.01640

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.18108
Policy Update Magnitude: 0.53214
Value Function Update Magnitude: 0.60100

Collected Steps per Second: 21,671.57636
Overall Steps per Second: 10,239.57639

Timestep Collection Time: 2.30717
Timestep Consumption Time: 2.57584
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.88301

Cumulative Model Updates: 222,410
Cumulative Timesteps: 1,854,832,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.73543
Policy Entropy: 2.14848
Value Function Loss: 0.01703

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.18407
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.61323

Collected Steps per Second: 22,097.27411
Overall Steps per Second: 10,437.86356

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.52945
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.79389

Cumulative Model Updates: 222,416
Cumulative Timesteps: 1,854,882,180

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1854882180...
Checkpoint 1854882180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.33538
Policy Entropy: 2.15471
Value Function Loss: 0.01698

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.63330

Collected Steps per Second: 21,672.96520
Overall Steps per Second: 10,528.75236

Timestep Collection Time: 2.30776
Timestep Consumption Time: 2.44266
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.75042

Cumulative Model Updates: 222,422
Cumulative Timesteps: 1,854,932,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.45894
Policy Entropy: 2.15248
Value Function Loss: 0.01696

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.61662

Collected Steps per Second: 22,288.65326
Overall Steps per Second: 10,489.65982

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.76717

Cumulative Model Updates: 222,428
Cumulative Timesteps: 1,854,982,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1854982202...
Checkpoint 1854982202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.68836
Policy Entropy: 2.16797
Value Function Loss: 0.01849

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.60740

Collected Steps per Second: 21,667.00099
Overall Steps per Second: 10,281.83243

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.55529
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.86295

Cumulative Model Updates: 222,434
Cumulative Timesteps: 1,855,032,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.43439
Policy Entropy: 2.15475
Value Function Loss: 0.02001

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 21,710.53722
Overall Steps per Second: 10,374.27934

Timestep Collection Time: 2.30413
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.82193

Cumulative Model Updates: 222,440
Cumulative Timesteps: 1,855,082,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1855082226...
Checkpoint 1855082226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.42189
Policy Entropy: 2.15469
Value Function Loss: 0.01943

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.66044

Collected Steps per Second: 21,603.58832
Overall Steps per Second: 10,271.34946

Timestep Collection Time: 2.31536
Timestep Consumption Time: 2.55450
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.86986

Cumulative Model Updates: 222,446
Cumulative Timesteps: 1,855,132,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.48949
Policy Entropy: 2.16697
Value Function Loss: 0.01705

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.65482

Collected Steps per Second: 21,791.12980
Overall Steps per Second: 10,482.14603

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.77192

Cumulative Model Updates: 222,452
Cumulative Timesteps: 1,855,182,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1855182266...
Checkpoint 1855182266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.82841
Policy Entropy: 2.19242
Value Function Loss: 0.01627

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.61801

Collected Steps per Second: 21,626.77911
Overall Steps per Second: 10,206.05840

Timestep Collection Time: 2.31204
Timestep Consumption Time: 2.58721
PPO Batch Consumption Time: 0.30496
Total Iteration Time: 4.89925

Cumulative Model Updates: 222,458
Cumulative Timesteps: 1,855,232,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.21295
Policy Entropy: 2.18647
Value Function Loss: 0.01626

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.53702
Value Function Update Magnitude: 0.59768

Collected Steps per Second: 21,247.01670
Overall Steps per Second: 10,112.26625

Timestep Collection Time: 2.35402
Timestep Consumption Time: 2.59205
PPO Batch Consumption Time: 0.30207
Total Iteration Time: 4.94607

Cumulative Model Updates: 222,464
Cumulative Timesteps: 1,855,282,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1855282284...
Checkpoint 1855282284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.63247
Policy Entropy: 2.20191
Value Function Loss: 0.01717

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.52527
Value Function Update Magnitude: 0.59811

Collected Steps per Second: 21,940.76669
Overall Steps per Second: 10,461.42814

Timestep Collection Time: 2.27914
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.78004

Cumulative Model Updates: 222,470
Cumulative Timesteps: 1,855,332,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.79016
Policy Entropy: 2.21125
Value Function Loss: 0.01662

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.51765
Value Function Update Magnitude: 0.58774

Collected Steps per Second: 21,942.19201
Overall Steps per Second: 10,535.21851

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.74675

Cumulative Model Updates: 222,476
Cumulative Timesteps: 1,855,382,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1855382298...
Checkpoint 1855382298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.93650
Policy Entropy: 2.21465
Value Function Loss: 0.01645

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.56086

Collected Steps per Second: 21,913.14958
Overall Steps per Second: 10,295.87379

Timestep Collection Time: 2.28228
Timestep Consumption Time: 2.57520
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 4.85748

Cumulative Model Updates: 222,482
Cumulative Timesteps: 1,855,432,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.11454
Policy Entropy: 2.17838
Value Function Loss: 0.01673

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.57260

Collected Steps per Second: 21,876.41005
Overall Steps per Second: 10,366.82093

Timestep Collection Time: 2.28694
Timestep Consumption Time: 2.53903
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.82597

Cumulative Model Updates: 222,488
Cumulative Timesteps: 1,855,482,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1855482340...
Checkpoint 1855482340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.92739
Policy Entropy: 2.14645
Value Function Loss: 0.01662

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 21,467.23128
Overall Steps per Second: 10,214.49959

Timestep Collection Time: 2.33044
Timestep Consumption Time: 2.56731
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 4.89774

Cumulative Model Updates: 222,494
Cumulative Timesteps: 1,855,532,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.01876
Policy Entropy: 2.14705
Value Function Loss: 0.01731

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.59458

Collected Steps per Second: 21,618.07627
Overall Steps per Second: 10,475.57849

Timestep Collection Time: 2.31380
Timestep Consumption Time: 2.46111
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.77492

Cumulative Model Updates: 222,500
Cumulative Timesteps: 1,855,582,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1855582388...
Checkpoint 1855582388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.91803
Policy Entropy: 2.13746
Value Function Loss: 0.01751

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 21,967.28510
Overall Steps per Second: 10,331.54462

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.56518
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.84284

Cumulative Model Updates: 222,506
Cumulative Timesteps: 1,855,632,422

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.81976
Policy Entropy: 2.16724
Value Function Loss: 0.01810

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.61537

Collected Steps per Second: 22,163.43640
Overall Steps per Second: 10,304.31940

Timestep Collection Time: 2.25678
Timestep Consumption Time: 2.59730
PPO Batch Consumption Time: 0.30136
Total Iteration Time: 4.85408

Cumulative Model Updates: 222,512
Cumulative Timesteps: 1,855,682,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1855682440...
Checkpoint 1855682440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.35980
Policy Entropy: 2.16877
Value Function Loss: 0.01772

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.54292
Value Function Update Magnitude: 0.60282

Collected Steps per Second: 21,789.08493
Overall Steps per Second: 10,235.51904

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.59147
PPO Batch Consumption Time: 0.30487
Total Iteration Time: 4.88729

Cumulative Model Updates: 222,518
Cumulative Timesteps: 1,855,732,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.27272
Policy Entropy: 2.18186
Value Function Loss: 0.01823

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.57776

Collected Steps per Second: 21,799.79616
Overall Steps per Second: 10,414.60066

Timestep Collection Time: 2.29479
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.80345

Cumulative Model Updates: 222,524
Cumulative Timesteps: 1,855,782,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1855782490...
Checkpoint 1855782490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.82916
Policy Entropy: 2.14815
Value Function Loss: 0.01784

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.57266

Collected Steps per Second: 21,794.24334
Overall Steps per Second: 10,551.18616

Timestep Collection Time: 2.29418
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.73880

Cumulative Model Updates: 222,530
Cumulative Timesteps: 1,855,832,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.60779
Policy Entropy: 2.14280
Value Function Loss: 0.01792

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.55084
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,047.21440
Overall Steps per Second: 10,348.87895

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.56573
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.83550

Cumulative Model Updates: 222,536
Cumulative Timesteps: 1,855,882,532

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1855882532...
Checkpoint 1855882532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.40150
Policy Entropy: 2.14695
Value Function Loss: 0.01722

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 21,913.83642
Overall Steps per Second: 10,345.59256

Timestep Collection Time: 2.28239
Timestep Consumption Time: 2.55213
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.83452

Cumulative Model Updates: 222,542
Cumulative Timesteps: 1,855,932,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.25307
Policy Entropy: 2.15273
Value Function Loss: 0.01735

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 21,806.93196
Overall Steps per Second: 10,563.73340

Timestep Collection Time: 2.29349
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.73450

Cumulative Model Updates: 222,548
Cumulative Timesteps: 1,855,982,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1855982562...
Checkpoint 1855982562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.40697
Policy Entropy: 2.17112
Value Function Loss: 0.01688

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.61366

Collected Steps per Second: 22,020.03606
Overall Steps per Second: 10,375.91371

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.54891
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.82020

Cumulative Model Updates: 222,554
Cumulative Timesteps: 1,856,032,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.81487
Policy Entropy: 2.15553
Value Function Loss: 0.01722

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.54680
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 22,193.15922
Overall Steps per Second: 10,329.47155

Timestep Collection Time: 2.25304
Timestep Consumption Time: 2.58768
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.84071

Cumulative Model Updates: 222,560
Cumulative Timesteps: 1,856,082,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1856082578...
Checkpoint 1856082578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.56876
Policy Entropy: 2.15409
Value Function Loss: 0.01761

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.62566

Collected Steps per Second: 21,615.27542
Overall Steps per Second: 10,241.96216

Timestep Collection Time: 2.31336
Timestep Consumption Time: 2.56890
PPO Batch Consumption Time: 0.30238
Total Iteration Time: 4.88227

Cumulative Model Updates: 222,566
Cumulative Timesteps: 1,856,132,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.97869
Policy Entropy: 2.14429
Value Function Loss: 0.01733

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.63201

Collected Steps per Second: 21,760.82526
Overall Steps per Second: 10,389.49776

Timestep Collection Time: 2.29909
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.81544

Cumulative Model Updates: 222,572
Cumulative Timesteps: 1,856,182,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1856182612...
Checkpoint 1856182612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.60347
Policy Entropy: 2.14769
Value Function Loss: 0.01663

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.53858
Value Function Update Magnitude: 0.62973

Collected Steps per Second: 21,989.02975
Overall Steps per Second: 10,323.95090

Timestep Collection Time: 2.27532
Timestep Consumption Time: 2.57089
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.84621

Cumulative Model Updates: 222,578
Cumulative Timesteps: 1,856,232,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.31069
Policy Entropy: 2.15183
Value Function Loss: 0.01640

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.53570
Value Function Update Magnitude: 0.60072

Collected Steps per Second: 21,734.43861
Overall Steps per Second: 10,303.84564

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.55359
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.85547

Cumulative Model Updates: 222,584
Cumulative Timesteps: 1,856,282,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1856282674...
Checkpoint 1856282674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.96450
Policy Entropy: 2.13995
Value Function Loss: 0.01671

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.58209

Collected Steps per Second: 21,403.24106
Overall Steps per Second: 10,225.80873

Timestep Collection Time: 2.33675
Timestep Consumption Time: 2.55421
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.89096

Cumulative Model Updates: 222,590
Cumulative Timesteps: 1,856,332,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.63882
Policy Entropy: 2.14924
Value Function Loss: 0.01725

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.52482
Value Function Update Magnitude: 0.58841

Collected Steps per Second: 21,884.09627
Overall Steps per Second: 10,500.39579

Timestep Collection Time: 2.28586
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.76401

Cumulative Model Updates: 222,596
Cumulative Timesteps: 1,856,382,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1856382712...
Checkpoint 1856382712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.38557
Policy Entropy: 2.14180
Value Function Loss: 0.01645

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.53106
Value Function Update Magnitude: 0.60388

Collected Steps per Second: 21,813.93984
Overall Steps per Second: 10,274.51658

Timestep Collection Time: 2.29275
Timestep Consumption Time: 2.57502
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 4.86777

Cumulative Model Updates: 222,602
Cumulative Timesteps: 1,856,432,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.42627
Policy Entropy: 2.12952
Value Function Loss: 0.01620

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 21,932.92617
Overall Steps per Second: 10,360.10822

Timestep Collection Time: 2.28022
Timestep Consumption Time: 2.54714
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.82736

Cumulative Model Updates: 222,608
Cumulative Timesteps: 1,856,482,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1856482738...
Checkpoint 1856482738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.00087
Policy Entropy: 2.12741
Value Function Loss: 0.01553

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.59142

Collected Steps per Second: 21,337.28071
Overall Steps per Second: 10,239.72887

Timestep Collection Time: 2.34444
Timestep Consumption Time: 2.54084
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.88529

Cumulative Model Updates: 222,614
Cumulative Timesteps: 1,856,532,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.62079
Policy Entropy: 2.12250
Value Function Loss: 0.01587

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.58274

Collected Steps per Second: 21,899.52222
Overall Steps per Second: 10,447.94357

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.78831

Cumulative Model Updates: 222,620
Cumulative Timesteps: 1,856,582,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1856582790...
Checkpoint 1856582790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.19609
Policy Entropy: 2.13850
Value Function Loss: 0.01579

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.52247
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 21,793.84691
Overall Steps per Second: 10,249.90356

Timestep Collection Time: 2.29432
Timestep Consumption Time: 2.58397
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.87829

Cumulative Model Updates: 222,626
Cumulative Timesteps: 1,856,632,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.72602
Policy Entropy: 2.12633
Value Function Loss: 0.01673

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.57820

Collected Steps per Second: 21,948.98819
Overall Steps per Second: 10,404.43741

Timestep Collection Time: 2.27919
Timestep Consumption Time: 2.52895
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.80814

Cumulative Model Updates: 222,632
Cumulative Timesteps: 1,856,682,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1856682818...
Checkpoint 1856682818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.74037
Policy Entropy: 2.13648
Value Function Loss: 0.01744

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.58016

Collected Steps per Second: 21,572.89482
Overall Steps per Second: 10,241.45799

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.56491
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 4.88309

Cumulative Model Updates: 222,638
Cumulative Timesteps: 1,856,732,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.12876
Policy Entropy: 2.14668
Value Function Loss: 0.01754

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.60449

Collected Steps per Second: 21,982.67554
Overall Steps per Second: 10,426.66627

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.52088
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 4.79540

Cumulative Model Updates: 222,644
Cumulative Timesteps: 1,856,782,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1856782828...
Checkpoint 1856782828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.30519
Policy Entropy: 2.15405
Value Function Loss: 0.01716

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.58615

Collected Steps per Second: 21,668.92668
Overall Steps per Second: 10,205.97557

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.59278
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.90125

Cumulative Model Updates: 222,650
Cumulative Timesteps: 1,856,832,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.66403
Policy Entropy: 2.14685
Value Function Loss: 0.01743

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.60135

Collected Steps per Second: 22,135.95944
Overall Steps per Second: 10,425.66903

Timestep Collection Time: 2.25958
Timestep Consumption Time: 2.53800
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.79758

Cumulative Model Updates: 222,656
Cumulative Timesteps: 1,856,882,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1856882868...
Checkpoint 1856882868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.32512
Policy Entropy: 2.13268
Value Function Loss: 0.01703

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.61749

Collected Steps per Second: 21,087.95663
Overall Steps per Second: 10,202.36853

Timestep Collection Time: 2.37225
Timestep Consumption Time: 2.53112
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.90337

Cumulative Model Updates: 222,662
Cumulative Timesteps: 1,856,932,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.56827
Policy Entropy: 2.12100
Value Function Loss: 0.01774

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.54099
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 21,720.24836
Overall Steps per Second: 10,512.38781

Timestep Collection Time: 2.30320
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75877

Cumulative Model Updates: 222,668
Cumulative Timesteps: 1,856,982,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1856982920...
Checkpoint 1856982920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.69252
Policy Entropy: 2.12887
Value Function Loss: 0.01625

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.59962

Collected Steps per Second: 21,579.47423
Overall Steps per Second: 10,202.77901

Timestep Collection Time: 2.31702
Timestep Consumption Time: 2.58361
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 4.90063

Cumulative Model Updates: 222,674
Cumulative Timesteps: 1,857,032,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.20222
Policy Entropy: 2.13282
Value Function Loss: 0.01647

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 21,988.12256
Overall Steps per Second: 10,418.39349

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.52656
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.80170

Cumulative Model Updates: 222,680
Cumulative Timesteps: 1,857,082,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1857082946...
Checkpoint 1857082946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.01490
Policy Entropy: 2.14226
Value Function Loss: 0.01592

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.52948
Value Function Update Magnitude: 0.57741

Collected Steps per Second: 21,398.54593
Overall Steps per Second: 10,237.73458

Timestep Collection Time: 2.33782
Timestep Consumption Time: 2.54861
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.88643

Cumulative Model Updates: 222,686
Cumulative Timesteps: 1,857,132,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.56474
Policy Entropy: 2.14296
Value Function Loss: 0.01648

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 22,029.88649
Overall Steps per Second: 10,489.27775

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.76696

Cumulative Model Updates: 222,692
Cumulative Timesteps: 1,857,182,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1857182974...
Checkpoint 1857182974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.34223
Policy Entropy: 2.14858
Value Function Loss: 0.01692

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.57482

Collected Steps per Second: 21,758.34903
Overall Steps per Second: 10,210.48056

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.59969
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.89830

Cumulative Model Updates: 222,698
Cumulative Timesteps: 1,857,232,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.79870
Policy Entropy: 2.15030
Value Function Loss: 0.01622

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 22,112.14572
Overall Steps per Second: 10,463.88620

Timestep Collection Time: 2.26247
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.78102

Cumulative Model Updates: 222,704
Cumulative Timesteps: 1,857,283,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1857283016...
Checkpoint 1857283016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.11691
Policy Entropy: 2.16192
Value Function Loss: 0.01623

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.52930
Value Function Update Magnitude: 0.58009

Collected Steps per Second: 21,571.35151
Overall Steps per Second: 10,223.30615

Timestep Collection Time: 2.31863
Timestep Consumption Time: 2.57372
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 4.89235

Cumulative Model Updates: 222,710
Cumulative Timesteps: 1,857,333,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.10702
Policy Entropy: 2.16839
Value Function Loss: 0.01731

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.56264

Collected Steps per Second: 22,046.33237
Overall Steps per Second: 10,464.48224

Timestep Collection Time: 2.26931
Timestep Consumption Time: 2.51162
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.78093

Cumulative Model Updates: 222,716
Cumulative Timesteps: 1,857,383,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1857383062...
Checkpoint 1857383062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.49348
Policy Entropy: 2.15812
Value Function Loss: 0.01781

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.56460

Collected Steps per Second: 21,721.86501
Overall Steps per Second: 10,542.70720

Timestep Collection Time: 2.30229
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.74356

Cumulative Model Updates: 222,722
Cumulative Timesteps: 1,857,433,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.12228
Policy Entropy: 2.14434
Value Function Loss: 0.01805

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.57012

Collected Steps per Second: 22,121.32878
Overall Steps per Second: 10,414.92379

Timestep Collection Time: 2.26153
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.80349

Cumulative Model Updates: 222,728
Cumulative Timesteps: 1,857,483,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1857483100...
Checkpoint 1857483100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.89500
Policy Entropy: 2.14676
Value Function Loss: 0.01700

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.56693

Collected Steps per Second: 21,687.78000
Overall Steps per Second: 10,313.02775

Timestep Collection Time: 2.30628
Timestep Consumption Time: 2.54371
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.84998

Cumulative Model Updates: 222,734
Cumulative Timesteps: 1,857,533,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.36959
Policy Entropy: 2.16061
Value Function Loss: 0.01688

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.56190

Collected Steps per Second: 21,838.22623
Overall Steps per Second: 10,414.95309

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.80233

Cumulative Model Updates: 222,740
Cumulative Timesteps: 1,857,583,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1857583134...
Checkpoint 1857583134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.83258
Policy Entropy: 2.15955
Value Function Loss: 0.01622

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.58011

Collected Steps per Second: 21,566.74847
Overall Steps per Second: 10,449.52755

Timestep Collection Time: 2.31894
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.78605

Cumulative Model Updates: 222,746
Cumulative Timesteps: 1,857,633,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.99764
Policy Entropy: 2.15378
Value Function Loss: 0.01634

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.52186
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 22,196.45872
Overall Steps per Second: 10,315.37536

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.59494
PPO Batch Consumption Time: 0.30437
Total Iteration Time: 4.84791

Cumulative Model Updates: 222,752
Cumulative Timesteps: 1,857,683,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1857683154...
Checkpoint 1857683154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.81541
Policy Entropy: 2.12941
Value Function Loss: 0.01606

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.16577
Policy Update Magnitude: 0.50085
Value Function Update Magnitude: 0.58509

Collected Steps per Second: 21,565.55312
Overall Steps per Second: 10,166.44976

Timestep Collection Time: 2.31990
Timestep Consumption Time: 2.60119
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.92109

Cumulative Model Updates: 222,758
Cumulative Timesteps: 1,857,733,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.97847
Policy Entropy: 2.14935
Value Function Loss: 0.01543

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16168
Policy Update Magnitude: 0.51167
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 21,656.56767
Overall Steps per Second: 10,380.75101

Timestep Collection Time: 2.30978
Timestep Consumption Time: 2.50894
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.81873

Cumulative Model Updates: 222,764
Cumulative Timesteps: 1,857,783,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1857783206...
Checkpoint 1857783206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.48552
Policy Entropy: 2.12178
Value Function Loss: 0.01553

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.52695
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 21,410.81631
Overall Steps per Second: 10,294.20638

Timestep Collection Time: 2.33639
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.85943

Cumulative Model Updates: 222,770
Cumulative Timesteps: 1,857,833,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.85777
Policy Entropy: 2.11550
Value Function Loss: 0.01657

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.54344
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 22,421.50758
Overall Steps per Second: 10,444.63591

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.55847
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.78964

Cumulative Model Updates: 222,776
Cumulative Timesteps: 1,857,883,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1857883256...
Checkpoint 1857883256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.90570
Policy Entropy: 2.09428
Value Function Loss: 0.01736

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.16269
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.65196

Collected Steps per Second: 21,677.81954
Overall Steps per Second: 10,218.22130

Timestep Collection Time: 2.30706
Timestep Consumption Time: 2.58734
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 4.89439

Cumulative Model Updates: 222,782
Cumulative Timesteps: 1,857,933,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.37606
Policy Entropy: 2.10561
Value Function Loss: 0.01826

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.67914

Collected Steps per Second: 21,654.26346
Overall Steps per Second: 10,287.59586

Timestep Collection Time: 2.30975
Timestep Consumption Time: 2.55202
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.86178

Cumulative Model Updates: 222,788
Cumulative Timesteps: 1,857,983,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1857983284...
Checkpoint 1857983284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.54281
Policy Entropy: 2.13397
Value Function Loss: 0.01679

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.66465

Collected Steps per Second: 21,629.73611
Overall Steps per Second: 10,418.48657

Timestep Collection Time: 2.31311
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.80223

Cumulative Model Updates: 222,794
Cumulative Timesteps: 1,858,033,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.45973
Policy Entropy: 2.12934
Value Function Loss: 0.01829

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.63872

Collected Steps per Second: 22,314.81381
Overall Steps per Second: 10,428.35658

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.55549
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.79750

Cumulative Model Updates: 222,800
Cumulative Timesteps: 1,858,083,346

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1858083346...
Checkpoint 1858083346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.30420
Policy Entropy: 2.14988
Value Function Loss: 0.01729

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.63634

Collected Steps per Second: 21,659.41439
Overall Steps per Second: 10,221.97017

Timestep Collection Time: 2.30967
Timestep Consumption Time: 2.58430
PPO Batch Consumption Time: 0.30466
Total Iteration Time: 4.89397

Cumulative Model Updates: 222,806
Cumulative Timesteps: 1,858,133,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.93126
Policy Entropy: 2.15781
Value Function Loss: 0.01841

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.61810

Collected Steps per Second: 21,841.20073
Overall Steps per Second: 10,364.61699

Timestep Collection Time: 2.28934
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.82430

Cumulative Model Updates: 222,812
Cumulative Timesteps: 1,858,183,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1858183374...
Checkpoint 1858183374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.22519
Policy Entropy: 2.16205
Value Function Loss: 0.01767

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.59815

Collected Steps per Second: 21,635.63535
Overall Steps per Second: 10,282.05624

Timestep Collection Time: 2.31202
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.86498

Cumulative Model Updates: 222,818
Cumulative Timesteps: 1,858,233,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.31288
Policy Entropy: 2.15387
Value Function Loss: 0.01752

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.59835

Collected Steps per Second: 22,432.56584
Overall Steps per Second: 10,463.53038

Timestep Collection Time: 2.22953
Timestep Consumption Time: 2.55031
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77984

Cumulative Model Updates: 222,824
Cumulative Timesteps: 1,858,283,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1858283410...
Checkpoint 1858283410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.67180
Policy Entropy: 2.12961
Value Function Loss: 0.01727

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.60470

Collected Steps per Second: 21,715.86594
Overall Steps per Second: 10,171.24710

Timestep Collection Time: 2.30375
Timestep Consumption Time: 2.61482
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 4.91857

Cumulative Model Updates: 222,830
Cumulative Timesteps: 1,858,333,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.47975
Policy Entropy: 2.13324
Value Function Loss: 0.01662

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.54226
Value Function Update Magnitude: 0.62331

Collected Steps per Second: 21,418.39065
Overall Steps per Second: 10,160.62512

Timestep Collection Time: 2.33500
Timestep Consumption Time: 2.58714
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.92214

Cumulative Model Updates: 222,836
Cumulative Timesteps: 1,858,383,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1858383450...
Checkpoint 1858383450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.94351
Policy Entropy: 2.11310
Value Function Loss: 0.01724

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.61085

Collected Steps per Second: 21,715.30781
Overall Steps per Second: 10,436.84419

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.79091

Cumulative Model Updates: 222,842
Cumulative Timesteps: 1,858,433,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.32352
Policy Entropy: 2.12015
Value Function Loss: 0.01696

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.59438

Collected Steps per Second: 21,770.61707
Overall Steps per Second: 10,526.65636

Timestep Collection Time: 2.29704
Timestep Consumption Time: 2.45357
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.75061

Cumulative Model Updates: 222,848
Cumulative Timesteps: 1,858,483,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1858483460...
Checkpoint 1858483460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.29635
Policy Entropy: 2.12451
Value Function Loss: 0.01726

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.60738

Collected Steps per Second: 21,527.38209
Overall Steps per Second: 10,227.04673

Timestep Collection Time: 2.32383
Timestep Consumption Time: 2.56771
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.89154

Cumulative Model Updates: 222,854
Cumulative Timesteps: 1,858,533,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.41092
Policy Entropy: 2.14296
Value Function Loss: 0.01588

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.60588

Collected Steps per Second: 21,686.78231
Overall Steps per Second: 10,389.68617

Timestep Collection Time: 2.30555
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.81246

Cumulative Model Updates: 222,860
Cumulative Timesteps: 1,858,583,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1858583486...
Checkpoint 1858583486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.56562
Policy Entropy: 2.13525
Value Function Loss: 0.01636

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 21,876.06123
Overall Steps per Second: 10,589.85635

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.72225

Cumulative Model Updates: 222,866
Cumulative Timesteps: 1,858,633,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.58111
Policy Entropy: 2.10593
Value Function Loss: 0.01543

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.59439

Collected Steps per Second: 21,134.70007
Overall Steps per Second: 10,298.30779

Timestep Collection Time: 2.36578
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.85517

Cumulative Model Updates: 222,872
Cumulative Timesteps: 1,858,683,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1858683494...
Checkpoint 1858683494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.74241
Policy Entropy: 2.11382
Value Function Loss: 0.01574

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.53133
Value Function Update Magnitude: 0.59533

Collected Steps per Second: 21,894.61258
Overall Steps per Second: 10,391.10162

Timestep Collection Time: 2.28385
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.81219

Cumulative Model Updates: 222,878
Cumulative Timesteps: 1,858,733,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.22937
Policy Entropy: 2.10253
Value Function Loss: 0.01575

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.52970
Value Function Update Magnitude: 0.59618

Collected Steps per Second: 21,703.62145
Overall Steps per Second: 10,210.17439

Timestep Collection Time: 2.30432
Timestep Consumption Time: 2.59394
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.89825

Cumulative Model Updates: 222,884
Cumulative Timesteps: 1,858,783,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1858783510...
Checkpoint 1858783510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.24970
Policy Entropy: 2.11978
Value Function Loss: 0.01593

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.59202

Collected Steps per Second: 21,835.25683
Overall Steps per Second: 10,437.03606

Timestep Collection Time: 2.28987
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.79063

Cumulative Model Updates: 222,890
Cumulative Timesteps: 1,858,833,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.19567
Policy Entropy: 2.10987
Value Function Loss: 0.01630

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 22,083.60665
Overall Steps per Second: 10,543.48522

Timestep Collection Time: 2.26521
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.74454

Cumulative Model Updates: 222,896
Cumulative Timesteps: 1,858,883,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1858883534...
Checkpoint 1858883534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.63745
Policy Entropy: 2.09990
Value Function Loss: 0.01652

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.59837

Collected Steps per Second: 21,611.05807
Overall Steps per Second: 10,230.37276

Timestep Collection Time: 2.31474
Timestep Consumption Time: 2.57501
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.88975

Cumulative Model Updates: 222,902
Cumulative Timesteps: 1,858,933,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.63404
Policy Entropy: 2.12479
Value Function Loss: 0.01654

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.59458

Collected Steps per Second: 21,778.35523
Overall Steps per Second: 10,373.22175

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.52515
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.82184

Cumulative Model Updates: 222,908
Cumulative Timesteps: 1,858,983,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1858983576...
Checkpoint 1858983576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.04306
Policy Entropy: 2.12745
Value Function Loss: 0.01604

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.56462

Collected Steps per Second: 21,531.54558
Overall Steps per Second: 10,283.30360

Timestep Collection Time: 2.32301
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.86400

Cumulative Model Updates: 222,914
Cumulative Timesteps: 1,859,033,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.82497
Policy Entropy: 2.16390
Value Function Loss: 0.01570

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.51725
Value Function Update Magnitude: 0.54412

Collected Steps per Second: 21,721.64427
Overall Steps per Second: 10,458.50927

Timestep Collection Time: 2.30194
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.78099

Cumulative Model Updates: 222,920
Cumulative Timesteps: 1,859,083,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1859083596...
Checkpoint 1859083596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.99853
Policy Entropy: 2.15884
Value Function Loss: 0.01616

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.51814
Value Function Update Magnitude: 0.55485

Collected Steps per Second: 21,488.23307
Overall Steps per Second: 10,207.10209

Timestep Collection Time: 2.32751
Timestep Consumption Time: 2.57242
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.89992

Cumulative Model Updates: 222,926
Cumulative Timesteps: 1,859,133,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.07680
Policy Entropy: 2.16773
Value Function Loss: 0.01612

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.52684
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 21,915.02534
Overall Steps per Second: 10,359.31776

Timestep Collection Time: 2.28245
Timestep Consumption Time: 2.54605
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.82850

Cumulative Model Updates: 222,932
Cumulative Timesteps: 1,859,183,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1859183630...
Checkpoint 1859183630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.85650
Policy Entropy: 2.15946
Value Function Loss: 0.01610

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.52681
Value Function Update Magnitude: 0.57786

Collected Steps per Second: 21,637.28873
Overall Steps per Second: 10,311.90682

Timestep Collection Time: 2.31092
Timestep Consumption Time: 2.53804
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.84896

Cumulative Model Updates: 222,938
Cumulative Timesteps: 1,859,233,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.20137
Policy Entropy: 2.15998
Value Function Loss: 0.01537

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.59748

Collected Steps per Second: 22,635.44147
Overall Steps per Second: 10,442.09577

Timestep Collection Time: 2.20919
Timestep Consumption Time: 2.57969
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.78889

Cumulative Model Updates: 222,944
Cumulative Timesteps: 1,859,283,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1859283638...
Checkpoint 1859283638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.98530
Policy Entropy: 2.14040
Value Function Loss: 0.01483

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.52762
Value Function Update Magnitude: 0.60004

Collected Steps per Second: 21,527.69226
Overall Steps per Second: 10,223.81855

Timestep Collection Time: 2.32333
Timestep Consumption Time: 2.56877
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 4.89211

Cumulative Model Updates: 222,950
Cumulative Timesteps: 1,859,333,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.78804
Policy Entropy: 2.13074
Value Function Loss: 0.01569

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.58908

Collected Steps per Second: 21,894.12647
Overall Steps per Second: 10,393.28169

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.81234

Cumulative Model Updates: 222,956
Cumulative Timesteps: 1,859,383,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1859383670...
Checkpoint 1859383670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.46437
Policy Entropy: 2.11882
Value Function Loss: 0.01578

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.53288
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 21,528.78019
Overall Steps per Second: 10,380.86786

Timestep Collection Time: 2.32266
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.30308
Total Iteration Time: 4.81694

Cumulative Model Updates: 222,962
Cumulative Timesteps: 1,859,433,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.16946
Policy Entropy: 2.13086
Value Function Loss: 0.01689

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 21,714.11374
Overall Steps per Second: 10,322.38427

Timestep Collection Time: 2.30394
Timestep Consumption Time: 2.54262
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.84655

Cumulative Model Updates: 222,968
Cumulative Timesteps: 1,859,483,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1859483702...
Checkpoint 1859483702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.79136
Policy Entropy: 2.14251
Value Function Loss: 0.01606

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.60501

Collected Steps per Second: 21,742.67619
Overall Steps per Second: 10,270.46355

Timestep Collection Time: 2.30036
Timestep Consumption Time: 2.56953
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.86989

Cumulative Model Updates: 222,974
Cumulative Timesteps: 1,859,533,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.46082
Policy Entropy: 2.14046
Value Function Loss: 0.01644

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 21,911.81243
Overall Steps per Second: 10,366.57973

Timestep Collection Time: 2.28197
Timestep Consumption Time: 2.54142
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.82338

Cumulative Model Updates: 222,980
Cumulative Timesteps: 1,859,583,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1859583720...
Checkpoint 1859583720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.25612
Policy Entropy: 2.13615
Value Function Loss: 0.01611

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.60641

Collected Steps per Second: 21,615.34226
Overall Steps per Second: 10,422.44347

Timestep Collection Time: 2.31354
Timestep Consumption Time: 2.48457
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 4.79811

Cumulative Model Updates: 222,986
Cumulative Timesteps: 1,859,633,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.52636
Policy Entropy: 2.13679
Value Function Loss: 0.01620

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.53904
Value Function Update Magnitude: 0.62338

Collected Steps per Second: 20,482.46930
Overall Steps per Second: 9,901.61939

Timestep Collection Time: 2.44150
Timestep Consumption Time: 2.60898
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 5.05049

Cumulative Model Updates: 222,992
Cumulative Timesteps: 1,859,683,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1859683736...
Checkpoint 1859683736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.21168
Policy Entropy: 2.15176
Value Function Loss: 0.01559

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.53375
Value Function Update Magnitude: 0.60821

Collected Steps per Second: 21,604.84972
Overall Steps per Second: 10,214.64858

Timestep Collection Time: 2.31430
Timestep Consumption Time: 2.58064
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.89493

Cumulative Model Updates: 222,998
Cumulative Timesteps: 1,859,733,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.04485
Policy Entropy: 2.14549
Value Function Loss: 0.01669

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.53818
Value Function Update Magnitude: 0.59183

Collected Steps per Second: 21,836.69511
Overall Steps per Second: 10,468.53560

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.77927

Cumulative Model Updates: 223,004
Cumulative Timesteps: 1,859,783,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1859783768...
Checkpoint 1859783768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.04369
Policy Entropy: 2.16581
Value Function Loss: 0.01679

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.58108

Collected Steps per Second: 21,489.19152
Overall Steps per Second: 10,420.82240

Timestep Collection Time: 2.32675
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.79809

Cumulative Model Updates: 223,010
Cumulative Timesteps: 1,859,833,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.16528
Policy Entropy: 2.14776
Value Function Loss: 0.01756

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.55143

Collected Steps per Second: 22,157.25414
Overall Steps per Second: 10,351.51449

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.57506
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 4.83292

Cumulative Model Updates: 223,016
Cumulative Timesteps: 1,859,883,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1859883796...
Checkpoint 1859883796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.86978
Policy Entropy: 2.15916
Value Function Loss: 0.01649

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 21,819.06882
Overall Steps per Second: 10,309.13434

Timestep Collection Time: 2.29332
Timestep Consumption Time: 2.56044
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.85375

Cumulative Model Updates: 223,022
Cumulative Timesteps: 1,859,933,834

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.18200
Policy Entropy: 2.14916
Value Function Loss: 0.01528

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.51998
Value Function Update Magnitude: 0.54836

Collected Steps per Second: 22,205.54254
Overall Steps per Second: 10,419.94351

Timestep Collection Time: 2.25304
Timestep Consumption Time: 2.54833
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.80137

Cumulative Model Updates: 223,028
Cumulative Timesteps: 1,859,983,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1859983864...
Checkpoint 1859983864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.02290
Policy Entropy: 2.15649
Value Function Loss: 0.01629

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.55013

Collected Steps per Second: 21,480.84222
Overall Steps per Second: 10,478.74351

Timestep Collection Time: 2.32803
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77233

Cumulative Model Updates: 223,034
Cumulative Timesteps: 1,860,033,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.67410
Policy Entropy: 2.15396
Value Function Loss: 0.01635

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.53689
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 22,079.93324
Overall Steps per Second: 10,420.73037

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.53414
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.79909

Cumulative Model Updates: 223,040
Cumulative Timesteps: 1,860,083,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1860083882...
Checkpoint 1860083882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.08966
Policy Entropy: 2.14749
Value Function Loss: 0.01666

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.56080

Collected Steps per Second: 21,429.63867
Overall Steps per Second: 10,251.28563

Timestep Collection Time: 2.33378
Timestep Consumption Time: 2.54483
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.87861

Cumulative Model Updates: 223,046
Cumulative Timesteps: 1,860,133,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.12245
Policy Entropy: 2.14026
Value Function Loss: 0.01677

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.53305
Value Function Update Magnitude: 0.55587

Collected Steps per Second: 22,117.92803
Overall Steps per Second: 10,449.89866

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.52503
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.78646

Cumulative Model Updates: 223,052
Cumulative Timesteps: 1,860,183,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1860183912...
Checkpoint 1860183912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.82058
Policy Entropy: 2.12200
Value Function Loss: 0.01707

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.56899

Collected Steps per Second: 21,296.67497
Overall Steps per Second: 10,338.90564

Timestep Collection Time: 2.34910
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.83881

Cumulative Model Updates: 223,058
Cumulative Timesteps: 1,860,233,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.77674
Policy Entropy: 2.12570
Value Function Loss: 0.01715

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 22,295.62812
Overall Steps per Second: 10,360.44266

Timestep Collection Time: 2.24448
Timestep Consumption Time: 2.58563
PPO Batch Consumption Time: 0.30354
Total Iteration Time: 4.83010

Cumulative Model Updates: 223,064
Cumulative Timesteps: 1,860,283,982

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1860283982...
Checkpoint 1860283982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.94058
Policy Entropy: 2.13853
Value Function Loss: 0.01680

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.58233

Collected Steps per Second: 21,326.76359
Overall Steps per Second: 10,187.09657

Timestep Collection Time: 2.34578
Timestep Consumption Time: 2.56513
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.91092

Cumulative Model Updates: 223,070
Cumulative Timesteps: 1,860,334,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.89987
Policy Entropy: 2.17200
Value Function Loss: 0.01706

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 21,849.89039
Overall Steps per Second: 10,421.32922

Timestep Collection Time: 2.28862
Timestep Consumption Time: 2.50981
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.79843

Cumulative Model Updates: 223,076
Cumulative Timesteps: 1,860,384,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1860384016...
Checkpoint 1860384016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.27445
Policy Entropy: 2.16327
Value Function Loss: 0.01589

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.59501

Collected Steps per Second: 21,574.88276
Overall Steps per Second: 10,245.29323

Timestep Collection Time: 2.31834
Timestep Consumption Time: 2.56370
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 4.88205

Cumulative Model Updates: 223,082
Cumulative Timesteps: 1,860,434,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.88203
Policy Entropy: 2.15262
Value Function Loss: 0.01680

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 22,602.72472
Overall Steps per Second: 10,472.90843

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.56333
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.77651

Cumulative Model Updates: 223,088
Cumulative Timesteps: 1,860,484,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1860484058...
Checkpoint 1860484058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.25514
Policy Entropy: 2.13459
Value Function Loss: 0.01653

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.60151

Collected Steps per Second: 21,723.52628
Overall Steps per Second: 10,246.29833

Timestep Collection Time: 2.30248
Timestep Consumption Time: 2.57909
PPO Batch Consumption Time: 0.30461
Total Iteration Time: 4.88157

Cumulative Model Updates: 223,094
Cumulative Timesteps: 1,860,534,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.75004
Policy Entropy: 2.13980
Value Function Loss: 0.01717

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.60977

Collected Steps per Second: 21,697.72135
Overall Steps per Second: 10,356.47553

Timestep Collection Time: 2.30568
Timestep Consumption Time: 2.52492
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.83060

Cumulative Model Updates: 223,100
Cumulative Timesteps: 1,860,584,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1860584104...
Checkpoint 1860584104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.16992
Policy Entropy: 2.14234
Value Function Loss: 0.01670

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.53802
Value Function Update Magnitude: 0.61139

Collected Steps per Second: 21,406.14040
Overall Steps per Second: 10,269.69710

Timestep Collection Time: 2.33643
Timestep Consumption Time: 2.53362
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.87006

Cumulative Model Updates: 223,106
Cumulative Timesteps: 1,860,634,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.51382
Policy Entropy: 2.14770
Value Function Loss: 0.01715

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.61525

Collected Steps per Second: 21,874.26353
Overall Steps per Second: 10,452.30254

Timestep Collection Time: 2.28625
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.78459

Cumulative Model Updates: 223,112
Cumulative Timesteps: 1,860,684,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1860684128...
Checkpoint 1860684128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.84674
Policy Entropy: 2.12365
Value Function Loss: 0.01783

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.60761

Collected Steps per Second: 21,655.05409
Overall Steps per Second: 10,211.62461

Timestep Collection Time: 2.31004
Timestep Consumption Time: 2.58869
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.89873

Cumulative Model Updates: 223,118
Cumulative Timesteps: 1,860,734,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.31312
Policy Entropy: 2.12356
Value Function Loss: 0.01838

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 21,472.31035
Overall Steps per Second: 10,220.73812

Timestep Collection Time: 2.32998
Timestep Consumption Time: 2.56497
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.89495

Cumulative Model Updates: 223,124
Cumulative Timesteps: 1,860,784,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1860784182...
Checkpoint 1860784182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.75085
Policy Entropy: 2.09920
Value Function Loss: 0.01685

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.60712

Collected Steps per Second: 21,905.96235
Overall Steps per Second: 10,421.13827

Timestep Collection Time: 2.28367
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.80044

Cumulative Model Updates: 223,130
Cumulative Timesteps: 1,860,834,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.54571
Policy Entropy: 2.11148
Value Function Loss: 0.01635

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 21,936.98680
Overall Steps per Second: 10,400.57221

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.52817
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.80743

Cumulative Model Updates: 223,136
Cumulative Timesteps: 1,860,884,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1860884208...
Checkpoint 1860884208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.40166
Policy Entropy: 2.11256
Value Function Loss: 0.01677

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.54005
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 21,499.94340
Overall Steps per Second: 10,269.28418

Timestep Collection Time: 2.32670
Timestep Consumption Time: 2.54452
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.87123

Cumulative Model Updates: 223,142
Cumulative Timesteps: 1,860,934,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.53814
Policy Entropy: 2.11549
Value Function Loss: 0.01689

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.53003
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 21,817.91941
Overall Steps per Second: 10,346.64595

Timestep Collection Time: 2.29206
Timestep Consumption Time: 2.54120
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.83326

Cumulative Model Updates: 223,148
Cumulative Timesteps: 1,860,984,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1860984240...
Checkpoint 1860984240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.12973
Policy Entropy: 2.07870
Value Function Loss: 0.01767

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.60088

Collected Steps per Second: 21,832.51453
Overall Steps per Second: 10,309.54478

Timestep Collection Time: 2.29126
Timestep Consumption Time: 2.56094
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.85220

Cumulative Model Updates: 223,154
Cumulative Timesteps: 1,861,034,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.40567
Policy Entropy: 2.09645
Value Function Loss: 0.01659

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.55121
Value Function Update Magnitude: 0.60805

Collected Steps per Second: 22,626.18624
Overall Steps per Second: 10,485.43678

Timestep Collection Time: 2.21098
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.77100

Cumulative Model Updates: 223,160
Cumulative Timesteps: 1,861,084,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1861084290...
Checkpoint 1861084290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.68350
Policy Entropy: 2.08866
Value Function Loss: 0.01662

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.59844

Collected Steps per Second: 21,464.53118
Overall Steps per Second: 10,187.72675

Timestep Collection Time: 2.33054
Timestep Consumption Time: 2.57968
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.91022

Cumulative Model Updates: 223,166
Cumulative Timesteps: 1,861,134,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.89257
Policy Entropy: 2.12455
Value Function Loss: 0.01676

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.58471

Collected Steps per Second: 21,596.16137
Overall Steps per Second: 10,371.55134

Timestep Collection Time: 2.31662
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.82377

Cumulative Model Updates: 223,172
Cumulative Timesteps: 1,861,184,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1861184344...
Checkpoint 1861184344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.25029
Policy Entropy: 2.11525
Value Function Loss: 0.01719

Mean KL Divergence: 0.02899
SB3 Clip Fraction: 0.18291
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.59867

Collected Steps per Second: 21,492.81789
Overall Steps per Second: 10,324.21299

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.51733
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 4.84434

Cumulative Model Updates: 223,178
Cumulative Timesteps: 1,861,234,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.87459
Policy Entropy: 2.10953
Value Function Loss: 0.01757

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.17815
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.60426

Collected Steps per Second: 22,130.92700
Overall Steps per Second: 10,473.03750

Timestep Collection Time: 2.26046
Timestep Consumption Time: 2.51619
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.77665

Cumulative Model Updates: 223,184
Cumulative Timesteps: 1,861,284,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1861284384...
Checkpoint 1861284384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.36970
Policy Entropy: 2.11602
Value Function Loss: 0.01650

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.60941

Collected Steps per Second: 21,846.30064
Overall Steps per Second: 10,286.55512

Timestep Collection Time: 2.28982
Timestep Consumption Time: 2.57323
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 4.86305

Cumulative Model Updates: 223,190
Cumulative Timesteps: 1,861,334,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.66549
Policy Entropy: 2.10925
Value Function Loss: 0.01660

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.15089
Policy Update Magnitude: 0.54839
Value Function Update Magnitude: 0.59570

Collected Steps per Second: 21,691.21208
Overall Steps per Second: 10,341.50578

Timestep Collection Time: 2.30619
Timestep Consumption Time: 2.53102
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.83721

Cumulative Model Updates: 223,196
Cumulative Timesteps: 1,861,384,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1861384432...
Checkpoint 1861384432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.74549
Policy Entropy: 2.12746
Value Function Loss: 0.01577

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.57028

Collected Steps per Second: 21,794.94127
Overall Steps per Second: 10,288.87069

Timestep Collection Time: 2.29549
Timestep Consumption Time: 2.56705
PPO Batch Consumption Time: 0.30376
Total Iteration Time: 4.86254

Cumulative Model Updates: 223,202
Cumulative Timesteps: 1,861,434,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.12400
Policy Entropy: 2.12564
Value Function Loss: 0.01591

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.56490

Collected Steps per Second: 22,317.35812
Overall Steps per Second: 10,421.91417

Timestep Collection Time: 2.24122
Timestep Consumption Time: 2.55810
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.79931

Cumulative Model Updates: 223,208
Cumulative Timesteps: 1,861,484,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1861484480...
Checkpoint 1861484480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.74309
Policy Entropy: 2.14075
Value Function Loss: 0.01569

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 21,849.29161
Overall Steps per Second: 10,232.12643

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.59900
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.88813

Cumulative Model Updates: 223,214
Cumulative Timesteps: 1,861,534,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.46513
Policy Entropy: 2.13847
Value Function Loss: 0.01564

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.52634
Value Function Update Magnitude: 0.58022

Collected Steps per Second: 21,549.81956
Overall Steps per Second: 10,352.18136

Timestep Collection Time: 2.32085
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.83125

Cumulative Model Updates: 223,220
Cumulative Timesteps: 1,861,584,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1861584510...
Checkpoint 1861584510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.18439
Policy Entropy: 2.16219
Value Function Loss: 0.01627

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.58163

Collected Steps per Second: 21,661.92630
Overall Steps per Second: 10,459.88669

Timestep Collection Time: 2.30949
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.78284

Cumulative Model Updates: 223,226
Cumulative Timesteps: 1,861,634,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.67878
Policy Entropy: 2.14685
Value Function Loss: 0.01614

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.52266
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 22,100.00699
Overall Steps per Second: 10,308.73911

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.58885
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.85219

Cumulative Model Updates: 223,232
Cumulative Timesteps: 1,861,684,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1861684558...
Checkpoint 1861684558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.34281
Policy Entropy: 2.14178
Value Function Loss: 0.01710

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.53014
Value Function Update Magnitude: 0.60657

Collected Steps per Second: 21,809.15684
Overall Steps per Second: 10,243.38078

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.58869
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.88140

Cumulative Model Updates: 223,238
Cumulative Timesteps: 1,861,734,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.05424
Policy Entropy: 2.12903
Value Function Loss: 0.01740

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 21,743.15654
Overall Steps per Second: 10,319.02848

Timestep Collection Time: 2.29967
Timestep Consumption Time: 2.54595
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.84561

Cumulative Model Updates: 223,244
Cumulative Timesteps: 1,861,784,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1861784562...
Checkpoint 1861784562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.08097
Policy Entropy: 2.12027
Value Function Loss: 0.01727

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.61865

Collected Steps per Second: 21,606.23261
Overall Steps per Second: 10,276.70367

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.55235
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.86751

Cumulative Model Updates: 223,250
Cumulative Timesteps: 1,861,834,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.88221
Policy Entropy: 2.12403
Value Function Loss: 0.01636

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.52880
Value Function Update Magnitude: 0.59398

Collected Steps per Second: 20,946.80321
Overall Steps per Second: 10,269.99717

Timestep Collection Time: 2.38834
Timestep Consumption Time: 2.48294
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.87128

Cumulative Model Updates: 223,256
Cumulative Timesteps: 1,861,884,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1861884612...
Checkpoint 1861884612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.98514
Policy Entropy: 2.12674
Value Function Loss: 0.01658

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.57932

Collected Steps per Second: 21,127.90797
Overall Steps per Second: 10,099.38695

Timestep Collection Time: 2.36786
Timestep Consumption Time: 2.58570
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.95357

Cumulative Model Updates: 223,262
Cumulative Timesteps: 1,861,934,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.37697
Policy Entropy: 2.14008
Value Function Loss: 0.01572

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.57841

Collected Steps per Second: 21,329.54960
Overall Steps per Second: 10,208.44122

Timestep Collection Time: 2.34520
Timestep Consumption Time: 2.55487
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.90006

Cumulative Model Updates: 223,268
Cumulative Timesteps: 1,861,984,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1861984662...
Checkpoint 1861984662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.52834
Policy Entropy: 2.14823
Value Function Loss: 0.01671

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.56879

Collected Steps per Second: 21,121.21355
Overall Steps per Second: 10,224.01230

Timestep Collection Time: 2.36861
Timestep Consumption Time: 2.52457
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.89319

Cumulative Model Updates: 223,274
Cumulative Timesteps: 1,862,034,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.36126
Policy Entropy: 2.15621
Value Function Loss: 0.01631

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.56660

Collected Steps per Second: 22,244.61319
Overall Steps per Second: 10,367.78936

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.57603
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.82475

Cumulative Model Updates: 223,280
Cumulative Timesteps: 1,862,084,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1862084712...
Checkpoint 1862084712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.27619
Policy Entropy: 2.16179
Value Function Loss: 0.01623

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.55392

Collected Steps per Second: 20,973.37354
Overall Steps per Second: 10,007.93087

Timestep Collection Time: 2.38464
Timestep Consumption Time: 2.61279
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.99744

Cumulative Model Updates: 223,286
Cumulative Timesteps: 1,862,134,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.05614
Policy Entropy: 2.15421
Value Function Loss: 0.01555

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.51506
Value Function Update Magnitude: 0.53784

Collected Steps per Second: 18,837.63244
Overall Steps per Second: 9,296.22202

Timestep Collection Time: 2.65522
Timestep Consumption Time: 2.72525
PPO Batch Consumption Time: 0.30412
Total Iteration Time: 5.38047

Cumulative Model Updates: 223,292
Cumulative Timesteps: 1,862,184,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1862184744...
Checkpoint 1862184744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.52260
Policy Entropy: 2.15079
Value Function Loss: 0.01561

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.51216
Value Function Update Magnitude: 0.54965

Collected Steps per Second: 17,937.02162
Overall Steps per Second: 9,410.25648

Timestep Collection Time: 2.78865
Timestep Consumption Time: 2.52683
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 5.31548

Cumulative Model Updates: 223,298
Cumulative Timesteps: 1,862,234,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.83217
Policy Entropy: 2.14995
Value Function Loss: 0.01589

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.51337
Value Function Update Magnitude: 0.56473

Collected Steps per Second: 20,707.44963
Overall Steps per Second: 10,051.48706

Timestep Collection Time: 2.41671
Timestep Consumption Time: 2.56205
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.97877

Cumulative Model Updates: 223,304
Cumulative Timesteps: 1,862,284,808

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1862284808...
Checkpoint 1862284808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.80824
Policy Entropy: 2.16358
Value Function Loss: 0.01612

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.51873
Value Function Update Magnitude: 0.58713

Collected Steps per Second: 20,762.74737
Overall Steps per Second: 9,982.97002

Timestep Collection Time: 2.40835
Timestep Consumption Time: 2.60058
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 5.00893

Cumulative Model Updates: 223,310
Cumulative Timesteps: 1,862,334,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.93252
Policy Entropy: 2.14614
Value Function Loss: 0.01695

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.61214

Collected Steps per Second: 14,041.12860
Overall Steps per Second: 7,871.13978

Timestep Collection Time: 3.56239
Timestep Consumption Time: 2.79247
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 6.35486

Cumulative Model Updates: 223,316
Cumulative Timesteps: 1,862,384,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1862384832...
Checkpoint 1862384832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.58563
Policy Entropy: 2.12932
Value Function Loss: 0.01763

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.60313

Collected Steps per Second: 8,413.63540
Overall Steps per Second: 5,712.49563

Timestep Collection Time: 5.94939
Timestep Consumption Time: 2.81315
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 8.76255

Cumulative Model Updates: 223,322
Cumulative Timesteps: 1,862,434,888

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.90310
Policy Entropy: 2.11495
Value Function Loss: 0.01709

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.59564

Collected Steps per Second: 18,651.76673
Overall Steps per Second: 9,398.50878

Timestep Collection Time: 2.68146
Timestep Consumption Time: 2.64002
PPO Batch Consumption Time: 0.30199
Total Iteration Time: 5.32148

Cumulative Model Updates: 223,328
Cumulative Timesteps: 1,862,484,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1862484902...
Checkpoint 1862484902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.19638
Policy Entropy: 2.13475
Value Function Loss: 0.01638

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.52923
Value Function Update Magnitude: 0.59031

Collected Steps per Second: 20,604.07738
Overall Steps per Second: 9,976.56321

Timestep Collection Time: 2.42806
Timestep Consumption Time: 2.58649
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 5.01455

Cumulative Model Updates: 223,334
Cumulative Timesteps: 1,862,534,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.10340
Policy Entropy: 2.14081
Value Function Loss: 0.01571

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 21,627.98423
Overall Steps per Second: 10,244.61596

Timestep Collection Time: 2.31284
Timestep Consumption Time: 2.56992
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 4.88276

Cumulative Model Updates: 223,340
Cumulative Timesteps: 1,862,584,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1862584952...
Checkpoint 1862584952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.33946
Policy Entropy: 2.13215
Value Function Loss: 0.01609

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.55487

Collected Steps per Second: 21,617.13449
Overall Steps per Second: 10,510.90543

Timestep Collection Time: 2.31437
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.75982

Cumulative Model Updates: 223,346
Cumulative Timesteps: 1,862,634,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.11006
Policy Entropy: 2.13203
Value Function Loss: 0.01565

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.56679

Collected Steps per Second: 21,762.04051
Overall Steps per Second: 10,288.26686

Timestep Collection Time: 2.29859
Timestep Consumption Time: 2.56345
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.86204

Cumulative Model Updates: 223,352
Cumulative Timesteps: 1,862,685,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1862685004...
Checkpoint 1862685004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.82221
Policy Entropy: 2.12055
Value Function Loss: 0.01548

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.51455
Value Function Update Magnitude: 0.55500

Collected Steps per Second: 21,454.90075
Overall Steps per Second: 10,191.64624

Timestep Collection Time: 2.33056
Timestep Consumption Time: 2.57561
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.90618

Cumulative Model Updates: 223,358
Cumulative Timesteps: 1,862,735,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.53884
Policy Entropy: 2.10949
Value Function Loss: 0.01698

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.54853

Collected Steps per Second: 21,955.81027
Overall Steps per Second: 10,294.33769

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.57994
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.85743

Cumulative Model Updates: 223,364
Cumulative Timesteps: 1,862,785,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1862785010...
Checkpoint 1862785010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.18948
Policy Entropy: 2.10498
Value Function Loss: 0.01659

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.57668

Collected Steps per Second: 22,443.17176
Overall Steps per Second: 10,528.70525

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.74892

Cumulative Model Updates: 223,370
Cumulative Timesteps: 1,862,835,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.56001
Policy Entropy: 2.10288
Value Function Loss: 0.01712

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.57369

Collected Steps per Second: 21,989.85642
Overall Steps per Second: 10,360.52561

Timestep Collection Time: 2.27405
Timestep Consumption Time: 2.55254
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.82659

Cumulative Model Updates: 223,376
Cumulative Timesteps: 1,862,885,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1862885016...
Checkpoint 1862885016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.38616
Policy Entropy: 2.12225
Value Function Loss: 0.01626

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.55444

Collected Steps per Second: 21,497.89902
Overall Steps per Second: 10,387.24632

Timestep Collection Time: 2.32646
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.81494

Cumulative Model Updates: 223,382
Cumulative Timesteps: 1,862,935,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.09855
Policy Entropy: 2.10207
Value Function Loss: 0.01624

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 21,895.53390
Overall Steps per Second: 10,465.01619

Timestep Collection Time: 2.28375
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.77821

Cumulative Model Updates: 223,388
Cumulative Timesteps: 1,862,985,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1862985034...
Checkpoint 1862985034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.33050
Policy Entropy: 2.09264
Value Function Loss: 0.01566

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.58510

Collected Steps per Second: 21,746.74747
Overall Steps per Second: 10,197.47346

Timestep Collection Time: 2.29919
Timestep Consumption Time: 2.60398
PPO Batch Consumption Time: 0.30359
Total Iteration Time: 4.90318

Cumulative Model Updates: 223,394
Cumulative Timesteps: 1,863,035,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.46390
Policy Entropy: 2.09590
Value Function Loss: 0.01584

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.52504
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 21,678.92220
Overall Steps per Second: 10,343.46851

Timestep Collection Time: 2.30685
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.83494

Cumulative Model Updates: 223,400
Cumulative Timesteps: 1,863,085,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1863085044...
Checkpoint 1863085044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.44391
Policy Entropy: 2.08698
Value Function Loss: 0.01681

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.15904
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.59837

Collected Steps per Second: 21,861.94575
Overall Steps per Second: 10,324.79943

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.55706
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.84542

Cumulative Model Updates: 223,406
Cumulative Timesteps: 1,863,135,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.77845
Policy Entropy: 2.07647
Value Function Loss: 0.01706

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 21,888.69643
Overall Steps per Second: 10,435.60733

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.79359

Cumulative Model Updates: 223,412
Cumulative Timesteps: 1,863,185,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1863185096...
Checkpoint 1863185096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.64585
Policy Entropy: 2.06474
Value Function Loss: 0.01688

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.53581
Value Function Update Magnitude: 0.57980

Collected Steps per Second: 21,918.43553
Overall Steps per Second: 10,272.23729

Timestep Collection Time: 2.28155
Timestep Consumption Time: 2.58672
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.86827

Cumulative Model Updates: 223,418
Cumulative Timesteps: 1,863,235,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.60365
Policy Entropy: 2.09018
Value Function Loss: 0.01629

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.52497
Value Function Update Magnitude: 0.58081

Collected Steps per Second: 21,696.99703
Overall Steps per Second: 10,350.14986

Timestep Collection Time: 2.30520
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.83239

Cumulative Model Updates: 223,424
Cumulative Timesteps: 1,863,285,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1863285120...
Checkpoint 1863285120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.88989
Policy Entropy: 2.11548
Value Function Loss: 0.01671

Mean KL Divergence: 0.02875
SB3 Clip Fraction: 0.17690
Policy Update Magnitude: 0.50362
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 21,639.41949
Overall Steps per Second: 10,276.38811

Timestep Collection Time: 2.31088
Timestep Consumption Time: 2.55523
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.86611

Cumulative Model Updates: 223,430
Cumulative Timesteps: 1,863,335,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.36996
Policy Entropy: 2.12813
Value Function Loss: 0.01660

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.52567
Value Function Update Magnitude: 0.58749

Collected Steps per Second: 21,789.51784
Overall Steps per Second: 10,471.63931

Timestep Collection Time: 2.29569
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.77690

Cumulative Model Updates: 223,436
Cumulative Timesteps: 1,863,385,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1863385148...
Checkpoint 1863385148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.05840
Policy Entropy: 2.14570
Value Function Loss: 0.01700

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.59478

Collected Steps per Second: 21,768.40882
Overall Steps per Second: 10,257.83385

Timestep Collection Time: 2.29773
Timestep Consumption Time: 2.57834
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 4.87608

Cumulative Model Updates: 223,442
Cumulative Timesteps: 1,863,435,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.62920
Policy Entropy: 2.13290
Value Function Loss: 0.01679

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.62681

Collected Steps per Second: 21,731.88622
Overall Steps per Second: 10,324.60372

Timestep Collection Time: 2.30169
Timestep Consumption Time: 2.54305
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.84474

Cumulative Model Updates: 223,448
Cumulative Timesteps: 1,863,485,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1863485186...
Checkpoint 1863485186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.07027
Policy Entropy: 2.10557
Value Function Loss: 0.01723

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.62598

Collected Steps per Second: 21,654.06514
Overall Steps per Second: 10,284.49528

Timestep Collection Time: 2.31014
Timestep Consumption Time: 2.55388
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.86402

Cumulative Model Updates: 223,454
Cumulative Timesteps: 1,863,535,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.74165
Policy Entropy: 2.10657
Value Function Loss: 0.01671

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.14817
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 21,853.44993
Overall Steps per Second: 10,436.77204

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.79209

Cumulative Model Updates: 223,460
Cumulative Timesteps: 1,863,585,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1863585224...
Checkpoint 1863585224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.40830
Policy Entropy: 2.11889
Value Function Loss: 0.01650

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.59169

Collected Steps per Second: 21,483.80888
Overall Steps per Second: 10,224.02796

Timestep Collection Time: 2.32808
Timestep Consumption Time: 2.56393
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.89201

Cumulative Model Updates: 223,466
Cumulative Timesteps: 1,863,635,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.03706
Policy Entropy: 2.12765
Value Function Loss: 0.01679

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.53889
Value Function Update Magnitude: 0.57405

Collected Steps per Second: 21,485.43408
Overall Steps per Second: 10,236.57948

Timestep Collection Time: 2.32790
Timestep Consumption Time: 2.55810
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.88601

Cumulative Model Updates: 223,472
Cumulative Timesteps: 1,863,685,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1863685256...
Checkpoint 1863685256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.15715
Policy Entropy: 2.10817
Value Function Loss: 0.01626

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.57098

Collected Steps per Second: 21,675.42705
Overall Steps per Second: 10,430.40355

Timestep Collection Time: 2.30777
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.79579

Cumulative Model Updates: 223,478
Cumulative Timesteps: 1,863,735,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.12359
Policy Entropy: 2.09919
Value Function Loss: 0.01713

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.51919
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 21,643.55901
Overall Steps per Second: 10,483.78091

Timestep Collection Time: 2.31154
Timestep Consumption Time: 2.46059
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.77213

Cumulative Model Updates: 223,484
Cumulative Timesteps: 1,863,785,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1863785308...
Checkpoint 1863785308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.75195
Policy Entropy: 2.09568
Value Function Loss: 0.01684

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.52512
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 21,581.07706
Overall Steps per Second: 10,202.09484

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.58535
PPO Batch Consumption Time: 0.30369
Total Iteration Time: 4.90331

Cumulative Model Updates: 223,490
Cumulative Timesteps: 1,863,835,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.66880
Policy Entropy: 2.10044
Value Function Loss: 0.01737

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.54212
Value Function Update Magnitude: 0.55759

Collected Steps per Second: 21,670.16137
Overall Steps per Second: 10,336.98650

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.53039
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.83835

Cumulative Model Updates: 223,496
Cumulative Timesteps: 1,863,885,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1863885346...
Checkpoint 1863885346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.60333
Policy Entropy: 2.11319
Value Function Loss: 0.01768

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.55546

Collected Steps per Second: 21,838.20264
Overall Steps per Second: 10,314.65767

Timestep Collection Time: 2.29121
Timestep Consumption Time: 2.55975
PPO Batch Consumption Time: 0.30258
Total Iteration Time: 4.85096

Cumulative Model Updates: 223,502
Cumulative Timesteps: 1,863,935,382

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.20851
Policy Entropy: 2.14035
Value Function Loss: 0.01779

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.50741
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 21,622.76490
Overall Steps per Second: 10,466.82145

Timestep Collection Time: 2.31293
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.77815

Cumulative Model Updates: 223,508
Cumulative Timesteps: 1,863,985,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1863985394...
Checkpoint 1863985394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.87695
Policy Entropy: 2.14090
Value Function Loss: 0.01810

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.48466
Value Function Update Magnitude: 0.57861

Collected Steps per Second: 21,364.27850
Overall Steps per Second: 10,212.26071

Timestep Collection Time: 2.34176
Timestep Consumption Time: 2.55725
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.89901

Cumulative Model Updates: 223,514
Cumulative Timesteps: 1,864,035,424

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.57558
Policy Entropy: 2.16296
Value Function Loss: 0.01613

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.17520
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.58001

Collected Steps per Second: 21,855.08592
Overall Steps per Second: 10,386.24579

Timestep Collection Time: 2.28780
Timestep Consumption Time: 2.52626
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.81406

Cumulative Model Updates: 223,520
Cumulative Timesteps: 1,864,085,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1864085424...
Checkpoint 1864085424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.22966
Policy Entropy: 2.15140
Value Function Loss: 0.01530

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.57590

Collected Steps per Second: 21,612.96775
Overall Steps per Second: 10,290.38555

Timestep Collection Time: 2.31435
Timestep Consumption Time: 2.54650
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.86085

Cumulative Model Updates: 223,526
Cumulative Timesteps: 1,864,135,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.62195
Policy Entropy: 2.15542
Value Function Loss: 0.01473

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.55795

Collected Steps per Second: 21,938.74710
Overall Steps per Second: 10,460.16116

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.78272

Cumulative Model Updates: 223,532
Cumulative Timesteps: 1,864,185,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1864185472...
Checkpoint 1864185472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.18436
Policy Entropy: 2.15642
Value Function Loss: 0.01592

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.52929
Value Function Update Magnitude: 0.54651

Collected Steps per Second: 21,463.11568
Overall Steps per Second: 10,415.05571

Timestep Collection Time: 2.33070
Timestep Consumption Time: 2.47235
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.80305

Cumulative Model Updates: 223,538
Cumulative Timesteps: 1,864,235,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.44784
Policy Entropy: 2.17707
Value Function Loss: 0.01666

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.54632

Collected Steps per Second: 22,017.91302
Overall Steps per Second: 10,251.33167

Timestep Collection Time: 2.27124
Timestep Consumption Time: 2.60695
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 4.87820

Cumulative Model Updates: 223,544
Cumulative Timesteps: 1,864,285,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1864285504...
Checkpoint 1864285504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.28938
Policy Entropy: 2.16510
Value Function Loss: 0.01740

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.56923

Collected Steps per Second: 21,657.35479
Overall Steps per Second: 10,201.07958

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.59400
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.90379

Cumulative Model Updates: 223,550
Cumulative Timesteps: 1,864,335,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.74448
Policy Entropy: 2.14838
Value Function Loss: 0.01671

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.59163

Collected Steps per Second: 21,925.90594
Overall Steps per Second: 10,370.04330

Timestep Collection Time: 2.28050
Timestep Consumption Time: 2.54127
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.82177

Cumulative Model Updates: 223,556
Cumulative Timesteps: 1,864,385,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1864385530...
Checkpoint 1864385530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.72327
Policy Entropy: 2.11551
Value Function Loss: 0.01600

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 21,577.04182
Overall Steps per Second: 10,294.04253

Timestep Collection Time: 2.31728
Timestep Consumption Time: 2.53990
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.85718

Cumulative Model Updates: 223,562
Cumulative Timesteps: 1,864,435,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.78606
Policy Entropy: 2.11112
Value Function Loss: 0.01555

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 21,881.39472
Overall Steps per Second: 10,461.29692

Timestep Collection Time: 2.28514
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.77971

Cumulative Model Updates: 223,568
Cumulative Timesteps: 1,864,485,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1864485532...
Checkpoint 1864485532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.37966
Policy Entropy: 2.10895
Value Function Loss: 0.01579

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.53295
Value Function Update Magnitude: 0.59224

Collected Steps per Second: 21,559.67664
Overall Steps per Second: 10,198.15397

Timestep Collection Time: 2.32035
Timestep Consumption Time: 2.58505
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.90540

Cumulative Model Updates: 223,574
Cumulative Timesteps: 1,864,535,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.04047
Policy Entropy: 2.12165
Value Function Loss: 0.01631

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.59503

Collected Steps per Second: 22,062.32017
Overall Steps per Second: 10,406.14180

Timestep Collection Time: 2.26730
Timestep Consumption Time: 2.53966
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.80697

Cumulative Model Updates: 223,580
Cumulative Timesteps: 1,864,585,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1864585580...
Checkpoint 1864585580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.55491
Policy Entropy: 2.14739
Value Function Loss: 0.01594

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.61012

Collected Steps per Second: 21,304.37088
Overall Steps per Second: 10,275.12251

Timestep Collection Time: 2.34750
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.86729

Cumulative Model Updates: 223,586
Cumulative Timesteps: 1,864,635,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.94703
Policy Entropy: 2.14181
Value Function Loss: 0.01747

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 21,831.25885
Overall Steps per Second: 10,462.17920

Timestep Collection Time: 2.29148
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.78160

Cumulative Model Updates: 223,592
Cumulative Timesteps: 1,864,685,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1864685618...
Checkpoint 1864685618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.98413
Policy Entropy: 2.12925
Value Function Loss: 0.01816

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.62583

Collected Steps per Second: 21,446.54309
Overall Steps per Second: 10,219.62363

Timestep Collection Time: 2.33212
Timestep Consumption Time: 2.56199
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.89411

Cumulative Model Updates: 223,598
Cumulative Timesteps: 1,864,735,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.68258
Policy Entropy: 2.12960
Value Function Loss: 0.01818

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 22,094.08946
Overall Steps per Second: 10,398.50363

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.54635
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.81031

Cumulative Model Updates: 223,604
Cumulative Timesteps: 1,864,785,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1864785654...
Checkpoint 1864785654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.14332
Policy Entropy: 2.13110
Value Function Loss: 0.01691

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.53782
Value Function Update Magnitude: 0.64160

Collected Steps per Second: 21,537.71612
Overall Steps per Second: 10,264.68045

Timestep Collection Time: 2.32272
Timestep Consumption Time: 2.55089
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.87361

Cumulative Model Updates: 223,610
Cumulative Timesteps: 1,864,835,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.11125
Policy Entropy: 2.15335
Value Function Loss: 0.01697

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.62771

Collected Steps per Second: 22,141.14459
Overall Steps per Second: 10,509.67400

Timestep Collection Time: 2.25833
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 4.75771

Cumulative Model Updates: 223,616
Cumulative Timesteps: 1,864,885,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1864885682...
Checkpoint 1864885682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.27028
Policy Entropy: 2.11992
Value Function Loss: 0.01631

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 21,720.78989
Overall Steps per Second: 10,248.64604

Timestep Collection Time: 2.30305
Timestep Consumption Time: 2.57799
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.88103

Cumulative Model Updates: 223,622
Cumulative Timesteps: 1,864,935,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.25836
Policy Entropy: 2.11091
Value Function Loss: 0.01581

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.53015
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 21,813.05376
Overall Steps per Second: 10,364.16768

Timestep Collection Time: 2.29312
Timestep Consumption Time: 2.53312
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.82624

Cumulative Model Updates: 223,628
Cumulative Timesteps: 1,864,985,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1864985726...
Checkpoint 1864985726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.94755
Policy Entropy: 2.13223
Value Function Loss: 0.01574

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.61979

Collected Steps per Second: 21,673.27213
Overall Steps per Second: 10,525.89039

Timestep Collection Time: 2.30736
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.75095

Cumulative Model Updates: 223,634
Cumulative Timesteps: 1,865,035,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.42883
Policy Entropy: 2.15663
Value Function Loss: 0.01589

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.59612

Collected Steps per Second: 22,212.65766
Overall Steps per Second: 10,476.76837

Timestep Collection Time: 2.25160
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.77380

Cumulative Model Updates: 223,640
Cumulative Timesteps: 1,865,085,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1865085748...
Checkpoint 1865085748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.26673
Policy Entropy: 2.16554
Value Function Loss: 0.01719

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.53369
Value Function Update Magnitude: 0.58945

Collected Steps per Second: 20,852.60647
Overall Steps per Second: 10,064.71175

Timestep Collection Time: 2.39874
Timestep Consumption Time: 2.57110
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.96984

Cumulative Model Updates: 223,646
Cumulative Timesteps: 1,865,135,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.01247
Policy Entropy: 2.13980
Value Function Loss: 0.01694

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 21,740.85348
Overall Steps per Second: 10,285.94990

Timestep Collection Time: 2.30129
Timestep Consumption Time: 2.56282
PPO Batch Consumption Time: 0.30118
Total Iteration Time: 4.86411

Cumulative Model Updates: 223,652
Cumulative Timesteps: 1,865,185,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1865185800...
Checkpoint 1865185800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.52814
Policy Entropy: 2.13012
Value Function Loss: 0.01771

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 21,709.43950
Overall Steps per Second: 10,519.79102

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.75371

Cumulative Model Updates: 223,658
Cumulative Timesteps: 1,865,235,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.67712
Policy Entropy: 2.12918
Value Function Loss: 0.01735

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 22,275.06124
Overall Steps per Second: 10,523.41256

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.75188

Cumulative Model Updates: 223,664
Cumulative Timesteps: 1,865,285,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1865285814...
Checkpoint 1865285814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.54965
Policy Entropy: 2.10233
Value Function Loss: 0.01793

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.59475

Collected Steps per Second: 21,724.39350
Overall Steps per Second: 10,270.13460

Timestep Collection Time: 2.30211
Timestep Consumption Time: 2.56754
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.86965

Cumulative Model Updates: 223,670
Cumulative Timesteps: 1,865,335,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.01282
Policy Entropy: 2.12122
Value Function Loss: 0.01777

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 21,850.23751
Overall Steps per Second: 10,460.49079

Timestep Collection Time: 2.28931
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.78199

Cumulative Model Updates: 223,676
Cumulative Timesteps: 1,865,385,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1865385848...
Checkpoint 1865385848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.89686
Policy Entropy: 2.12841
Value Function Loss: 0.01738

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.59757

Collected Steps per Second: 21,758.67515
Overall Steps per Second: 10,340.69809

Timestep Collection Time: 2.29885
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.83720

Cumulative Model Updates: 223,682
Cumulative Timesteps: 1,865,435,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.83542
Policy Entropy: 2.14656
Value Function Loss: 0.01736

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.53265
Value Function Update Magnitude: 0.58247

Collected Steps per Second: 22,606.70800
Overall Steps per Second: 10,445.72484

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.57594
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.78856

Cumulative Model Updates: 223,688
Cumulative Timesteps: 1,865,485,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1865485888...
Checkpoint 1865485888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.06618
Policy Entropy: 2.13480
Value Function Loss: 0.01703

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.57228

Collected Steps per Second: 21,667.67282
Overall Steps per Second: 10,236.07419

Timestep Collection Time: 2.30897
Timestep Consumption Time: 2.57865
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.88762

Cumulative Model Updates: 223,694
Cumulative Timesteps: 1,865,535,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.13215
Policy Entropy: 2.16863
Value Function Loss: 0.01747

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.58922

Collected Steps per Second: 21,603.71055
Overall Steps per Second: 10,325.14377

Timestep Collection Time: 2.31534
Timestep Consumption Time: 2.52914
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.84448

Cumulative Model Updates: 223,700
Cumulative Timesteps: 1,865,585,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1865585938...
Checkpoint 1865585938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.72747
Policy Entropy: 2.15724
Value Function Loss: 0.01758

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.53221
Value Function Update Magnitude: 0.59721

Collected Steps per Second: 21,644.07471
Overall Steps per Second: 10,459.43144

Timestep Collection Time: 2.31093
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.78210

Cumulative Model Updates: 223,706
Cumulative Timesteps: 1,865,635,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.01743
Policy Entropy: 2.16272
Value Function Loss: 0.01741

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.59627

Collected Steps per Second: 21,999.80390
Overall Steps per Second: 10,333.83468

Timestep Collection Time: 2.27338
Timestep Consumption Time: 2.56645
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.83983

Cumulative Model Updates: 223,712
Cumulative Timesteps: 1,865,685,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1865685970...
Checkpoint 1865685970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.45917
Policy Entropy: 2.09887
Value Function Loss: 0.01783

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.52371
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 21,935.56977
Overall Steps per Second: 10,409.49956

Timestep Collection Time: 2.28031
Timestep Consumption Time: 2.52491
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.80523

Cumulative Model Updates: 223,718
Cumulative Timesteps: 1,865,735,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.41271
Policy Entropy: 2.11305
Value Function Loss: 0.01769

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 21,726.51534
Overall Steps per Second: 10,316.77158

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.54657
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.84919

Cumulative Model Updates: 223,724
Cumulative Timesteps: 1,865,786,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1865786018...
Checkpoint 1865786018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.22250
Policy Entropy: 2.10541
Value Function Loss: 0.01737

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 21,804.61814
Overall Steps per Second: 10,418.05465

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.80090

Cumulative Model Updates: 223,730
Cumulative Timesteps: 1,865,836,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.75739
Policy Entropy: 2.13747
Value Function Loss: 0.01759

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.59002

Collected Steps per Second: 22,145.61352
Overall Steps per Second: 10,436.45970

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.79320

Cumulative Model Updates: 223,736
Cumulative Timesteps: 1,865,886,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1865886058...
Checkpoint 1865886058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.39334
Policy Entropy: 2.14978
Value Function Loss: 0.01777

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 21,740.13748
Overall Steps per Second: 10,258.50497

Timestep Collection Time: 2.30118
Timestep Consumption Time: 2.57555
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.87673

Cumulative Model Updates: 223,742
Cumulative Timesteps: 1,865,936,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.49364
Policy Entropy: 2.19145
Value Function Loss: 0.01680

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.52317
Value Function Update Magnitude: 0.59058

Collected Steps per Second: 21,639.30497
Overall Steps per Second: 10,388.06030

Timestep Collection Time: 2.31153
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.81514

Cumulative Model Updates: 223,748
Cumulative Timesteps: 1,865,986,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1865986106...
Checkpoint 1865986106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.85365
Policy Entropy: 2.18689
Value Function Loss: 0.01682

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.51956
Value Function Update Magnitude: 0.56923

Collected Steps per Second: 21,879.00960
Overall Steps per Second: 10,573.08936

Timestep Collection Time: 2.28530
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.72899

Cumulative Model Updates: 223,754
Cumulative Timesteps: 1,866,036,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.22455
Policy Entropy: 2.17785
Value Function Loss: 0.01600

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.51252
Value Function Update Magnitude: 0.55167

Collected Steps per Second: 22,030.02640
Overall Steps per Second: 10,352.70871

Timestep Collection Time: 2.26963
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.82965

Cumulative Model Updates: 223,760
Cumulative Timesteps: 1,866,086,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1866086106...
Checkpoint 1866086106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.34287
Policy Entropy: 2.17079
Value Function Loss: 0.01620

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.51581
Value Function Update Magnitude: 0.55772

Collected Steps per Second: 21,809.78197
Overall Steps per Second: 10,393.36987

Timestep Collection Time: 2.29337
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.81249

Cumulative Model Updates: 223,766
Cumulative Timesteps: 1,866,136,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.59575
Policy Entropy: 2.15140
Value Function Loss: 0.01624

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.51813
Value Function Update Magnitude: 0.55923

Collected Steps per Second: 21,662.66193
Overall Steps per Second: 10,530.41020

Timestep Collection Time: 2.30877
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.74948

Cumulative Model Updates: 223,772
Cumulative Timesteps: 1,866,186,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1866186138...
Checkpoint 1866186138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.73059
Policy Entropy: 2.14822
Value Function Loss: 0.01683

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.57083

Collected Steps per Second: 21,753.39876
Overall Steps per Second: 10,250.73406

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.57972
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.87867

Cumulative Model Updates: 223,778
Cumulative Timesteps: 1,866,236,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.16827
Policy Entropy: 2.11381
Value Function Loss: 0.01714

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 21,886.29185
Overall Steps per Second: 10,405.87749

Timestep Collection Time: 2.28508
Timestep Consumption Time: 2.52105
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.80613

Cumulative Model Updates: 223,784
Cumulative Timesteps: 1,866,286,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1866286160...
Checkpoint 1866286160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.24278
Policy Entropy: 2.12107
Value Function Loss: 0.01739

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 21,338.77049
Overall Steps per Second: 10,188.46875

Timestep Collection Time: 2.34456
Timestep Consumption Time: 2.56589
PPO Batch Consumption Time: 0.30321
Total Iteration Time: 4.91045

Cumulative Model Updates: 223,790
Cumulative Timesteps: 1,866,336,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.05269
Policy Entropy: 2.11029
Value Function Loss: 0.01784

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.52031
Value Function Update Magnitude: 0.61402

Collected Steps per Second: 21,841.51038
Overall Steps per Second: 10,468.32464

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.77861

Cumulative Model Updates: 223,796
Cumulative Timesteps: 1,866,386,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1866386214...
Checkpoint 1866386214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.88323
Policy Entropy: 2.13488
Value Function Loss: 0.01746

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.60366

Collected Steps per Second: 21,877.69926
Overall Steps per Second: 10,283.95250

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.57785
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.86447

Cumulative Model Updates: 223,802
Cumulative Timesteps: 1,866,436,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.79384
Policy Entropy: 2.16313
Value Function Loss: 0.01709

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.60247

Collected Steps per Second: 21,661.50697
Overall Steps per Second: 10,344.24319

Timestep Collection Time: 2.30889
Timestep Consumption Time: 2.52607
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.83496

Cumulative Model Updates: 223,808
Cumulative Timesteps: 1,866,486,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1866486254...
Checkpoint 1866486254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.81770
Policy Entropy: 2.19067
Value Function Loss: 0.01743

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.61228

Collected Steps per Second: 21,630.50260
Overall Steps per Second: 10,269.67601

Timestep Collection Time: 2.31238
Timestep Consumption Time: 2.55807
PPO Batch Consumption Time: 0.30463
Total Iteration Time: 4.87046

Cumulative Model Updates: 223,814
Cumulative Timesteps: 1,866,536,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.78922
Policy Entropy: 2.18958
Value Function Loss: 0.01714

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.65723

Collected Steps per Second: 21,930.90415
Overall Steps per Second: 10,435.56816

Timestep Collection Time: 2.28116
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.30410
Total Iteration Time: 4.79399

Cumulative Model Updates: 223,820
Cumulative Timesteps: 1,866,586,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1866586300...
Checkpoint 1866586300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.11475
Policy Entropy: 2.18259
Value Function Loss: 0.01689

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.65326

Collected Steps per Second: 21,821.54365
Overall Steps per Second: 10,256.24436

Timestep Collection Time: 2.29269
Timestep Consumption Time: 2.58532
PPO Batch Consumption Time: 0.30436
Total Iteration Time: 4.87800

Cumulative Model Updates: 223,826
Cumulative Timesteps: 1,866,636,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.98576
Policy Entropy: 2.18575
Value Function Loss: 0.01638

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.53925
Value Function Update Magnitude: 0.60972

Collected Steps per Second: 21,998.87965
Overall Steps per Second: 10,418.91553

Timestep Collection Time: 2.27339
Timestep Consumption Time: 2.52673
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.80012

Cumulative Model Updates: 223,832
Cumulative Timesteps: 1,866,686,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1866686342...
Checkpoint 1866686342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.84075
Policy Entropy: 2.16886
Value Function Loss: 0.01564

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.60085

Collected Steps per Second: 21,417.67245
Overall Steps per Second: 10,196.75006

Timestep Collection Time: 2.33508
Timestep Consumption Time: 2.56962
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.90470

Cumulative Model Updates: 223,838
Cumulative Timesteps: 1,866,736,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.48460
Policy Entropy: 2.16474
Value Function Loss: 0.01613

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.53218
Value Function Update Magnitude: 0.59882

Collected Steps per Second: 21,615.17425
Overall Steps per Second: 10,446.72243

Timestep Collection Time: 2.31328
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.78638

Cumulative Model Updates: 223,844
Cumulative Timesteps: 1,866,786,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1866786356...
Checkpoint 1866786356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.36875
Policy Entropy: 2.14919
Value Function Loss: 0.01654

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.53495
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 21,704.75183
Overall Steps per Second: 10,198.90828

Timestep Collection Time: 2.30401
Timestep Consumption Time: 2.59926
PPO Batch Consumption Time: 0.30527
Total Iteration Time: 4.90327

Cumulative Model Updates: 223,850
Cumulative Timesteps: 1,866,836,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.11910
Policy Entropy: 2.15744
Value Function Loss: 0.01664

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.53621
Value Function Update Magnitude: 0.60042

Collected Steps per Second: 21,513.67447
Overall Steps per Second: 10,213.92341

Timestep Collection Time: 2.32466
Timestep Consumption Time: 2.57179
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.89645

Cumulative Model Updates: 223,856
Cumulative Timesteps: 1,866,886,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1866886376...
Checkpoint 1866886376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.37271
Policy Entropy: 2.14731
Value Function Loss: 0.01578

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.59182

Collected Steps per Second: 21,543.80192
Overall Steps per Second: 10,366.68753

Timestep Collection Time: 2.32187
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.82526

Cumulative Model Updates: 223,862
Cumulative Timesteps: 1,866,936,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.38898
Policy Entropy: 2.15190
Value Function Loss: 0.01531

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.51833
Value Function Update Magnitude: 0.57753

Collected Steps per Second: 22,053.09840
Overall Steps per Second: 10,574.30335

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.73052

Cumulative Model Updates: 223,868
Cumulative Timesteps: 1,866,986,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1866986420...
Checkpoint 1866986420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.76852
Policy Entropy: 2.14195
Value Function Loss: 0.01632

Mean KL Divergence: 0.02921
SB3 Clip Fraction: 0.17785
Policy Update Magnitude: 0.51656
Value Function Update Magnitude: 0.59027

Collected Steps per Second: 21,842.22923
Overall Steps per Second: 10,255.17485

Timestep Collection Time: 2.28924
Timestep Consumption Time: 2.58655
PPO Batch Consumption Time: 0.30418
Total Iteration Time: 4.87578

Cumulative Model Updates: 223,874
Cumulative Timesteps: 1,867,036,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.59787
Policy Entropy: 2.12363
Value Function Loss: 0.01687

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.17215
Policy Update Magnitude: 0.53303
Value Function Update Magnitude: 0.60106

Collected Steps per Second: 22,263.65796
Overall Steps per Second: 10,431.23901

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.54830
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.79483

Cumulative Model Updates: 223,880
Cumulative Timesteps: 1,867,086,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1867086438...
Checkpoint 1867086438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.55094
Policy Entropy: 2.11595
Value Function Loss: 0.01745

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.16546
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.58397

Collected Steps per Second: 21,362.97251
Overall Steps per Second: 10,188.40875

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.56724
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 4.90793

Cumulative Model Updates: 223,886
Cumulative Timesteps: 1,867,136,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.75575
Policy Entropy: 2.11508
Value Function Loss: 0.01702

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.58095

Collected Steps per Second: 21,554.74790
Overall Steps per Second: 10,448.70266

Timestep Collection Time: 2.32070
Timestep Consumption Time: 2.46669
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.78739

Cumulative Model Updates: 223,892
Cumulative Timesteps: 1,867,186,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1867186464...
Checkpoint 1867186464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.93277
Policy Entropy: 2.12262
Value Function Loss: 0.01745

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.58496

Collected Steps per Second: 21,541.81623
Overall Steps per Second: 10,222.41302

Timestep Collection Time: 2.32116
Timestep Consumption Time: 2.57025
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 4.89141

Cumulative Model Updates: 223,898
Cumulative Timesteps: 1,867,236,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.82826
Policy Entropy: 2.11582
Value Function Loss: 0.01655

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.59463

Collected Steps per Second: 21,358.35919
Overall Steps per Second: 10,171.71982

Timestep Collection Time: 2.34147
Timestep Consumption Time: 2.57510
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.91657

Cumulative Model Updates: 223,904
Cumulative Timesteps: 1,867,286,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1867286476...
Checkpoint 1867286476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.75338
Policy Entropy: 2.11989
Value Function Loss: 0.01638

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.57152

Collected Steps per Second: 21,256.78444
Overall Steps per Second: 10,217.67433

Timestep Collection Time: 2.35370
Timestep Consumption Time: 2.54292
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.89661

Cumulative Model Updates: 223,910
Cumulative Timesteps: 1,867,336,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.42744
Policy Entropy: 2.11546
Value Function Loss: 0.01531

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.52312
Value Function Update Magnitude: 0.54266

Collected Steps per Second: 21,984.55474
Overall Steps per Second: 10,314.06756

Timestep Collection Time: 2.27560
Timestep Consumption Time: 2.57487
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.85046

Cumulative Model Updates: 223,916
Cumulative Timesteps: 1,867,386,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1867386536...
Checkpoint 1867386536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.07300
Policy Entropy: 2.11409
Value Function Loss: 0.01574

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.52397

Collected Steps per Second: 21,658.68396
Overall Steps per Second: 10,522.94084

Timestep Collection Time: 2.30910
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.75266

Cumulative Model Updates: 223,922
Cumulative Timesteps: 1,867,436,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.34531
Policy Entropy: 2.12455
Value Function Loss: 0.01565

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.52926

Collected Steps per Second: 22,113.42585
Overall Steps per Second: 10,468.37851

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.51562
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.77705

Cumulative Model Updates: 223,928
Cumulative Timesteps: 1,867,486,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1867486556...
Checkpoint 1867486556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.70050
Policy Entropy: 2.14828
Value Function Loss: 0.01524

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.55977

Collected Steps per Second: 21,604.64349
Overall Steps per Second: 10,362.23033

Timestep Collection Time: 2.31497
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.82657

Cumulative Model Updates: 223,934
Cumulative Timesteps: 1,867,536,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.33205
Policy Entropy: 2.16155
Value Function Loss: 0.01448

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.51883
Value Function Update Magnitude: 0.56089

Collected Steps per Second: 21,868.63403
Overall Steps per Second: 10,387.47379

Timestep Collection Time: 2.28711
Timestep Consumption Time: 2.52792
PPO Batch Consumption Time: 0.30437
Total Iteration Time: 4.81503

Cumulative Model Updates: 223,940
Cumulative Timesteps: 1,867,586,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1867586586...
Checkpoint 1867586586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.06546
Policy Entropy: 2.16228
Value Function Loss: 0.01490

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.51547
Value Function Update Magnitude: 0.55294

Collected Steps per Second: 21,652.54233
Overall Steps per Second: 10,229.27621

Timestep Collection Time: 2.30994
Timestep Consumption Time: 2.57956
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.88950

Cumulative Model Updates: 223,946
Cumulative Timesteps: 1,867,636,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.05905
Policy Entropy: 2.16542
Value Function Loss: 0.01534

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.51397
Value Function Update Magnitude: 0.56554

Collected Steps per Second: 22,058.28025
Overall Steps per Second: 10,458.10039

Timestep Collection Time: 2.26699
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.78156

Cumulative Model Updates: 223,952
Cumulative Timesteps: 1,867,686,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1867686608...
Checkpoint 1867686608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.86119
Policy Entropy: 2.13628
Value Function Loss: 0.01659

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.57851

Collected Steps per Second: 21,286.27305
Overall Steps per Second: 10,228.46991

Timestep Collection Time: 2.34987
Timestep Consumption Time: 2.54040
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.89027

Cumulative Model Updates: 223,958
Cumulative Timesteps: 1,867,736,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.35589
Policy Entropy: 2.12434
Value Function Loss: 0.01655

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.59150

Collected Steps per Second: 21,868.41938
Overall Steps per Second: 10,450.60654

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.78441

Cumulative Model Updates: 223,964
Cumulative Timesteps: 1,867,786,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1867786628...
Checkpoint 1867786628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.96042
Policy Entropy: 2.12682
Value Function Loss: 0.01636

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.58311

Collected Steps per Second: 22,411.95060
Overall Steps per Second: 10,520.16763

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.75316

Cumulative Model Updates: 223,970
Cumulative Timesteps: 1,867,836,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.22115
Policy Entropy: 2.12016
Value Function Loss: 0.01679

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.57758

Collected Steps per Second: 22,145.70068
Overall Steps per Second: 10,433.60536

Timestep Collection Time: 2.25796
Timestep Consumption Time: 2.53464
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.79259

Cumulative Model Updates: 223,976
Cumulative Timesteps: 1,867,886,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1867886636...
Checkpoint 1867886636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.68204
Policy Entropy: 2.11855
Value Function Loss: 0.01690

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 21,731.67672
Overall Steps per Second: 10,334.47809

Timestep Collection Time: 2.30116
Timestep Consumption Time: 2.53779
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.83895

Cumulative Model Updates: 223,982
Cumulative Timesteps: 1,867,936,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.70360
Policy Entropy: 2.11031
Value Function Loss: 0.01694

Mean KL Divergence: 0.02447
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.61282

Collected Steps per Second: 21,821.80956
Overall Steps per Second: 10,424.38624

Timestep Collection Time: 2.29184
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.79760

Cumulative Model Updates: 223,988
Cumulative Timesteps: 1,867,986,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1867986656...
Checkpoint 1867986656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.86935
Policy Entropy: 2.13699
Value Function Loss: 0.01622

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.58631

Collected Steps per Second: 20,977.55683
Overall Steps per Second: 10,212.73545

Timestep Collection Time: 2.38474
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.89839

Cumulative Model Updates: 223,994
Cumulative Timesteps: 1,868,036,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.83784
Policy Entropy: 2.13321
Value Function Loss: 0.01701

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.14910
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.56979

Collected Steps per Second: 21,760.92579
Overall Steps per Second: 10,366.34725

Timestep Collection Time: 2.29816
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.82426

Cumulative Model Updates: 224,000
Cumulative Timesteps: 1,868,086,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1868086692...
Checkpoint 1868086692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.14520
Policy Entropy: 2.12553
Value Function Loss: 0.01646

Mean KL Divergence: 0.02056
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 21,872.97579
Overall Steps per Second: 10,324.54477

Timestep Collection Time: 2.28638
Timestep Consumption Time: 2.55741
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.84380

Cumulative Model Updates: 224,006
Cumulative Timesteps: 1,868,136,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.59952
Policy Entropy: 2.14252
Value Function Loss: 0.01676

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.58437

Collected Steps per Second: 21,877.65453
Overall Steps per Second: 10,444.43247

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.78781

Cumulative Model Updates: 224,012
Cumulative Timesteps: 1,868,186,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1868186708...
Checkpoint 1868186708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.74200
Policy Entropy: 2.16993
Value Function Loss: 0.01594

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.59231

Collected Steps per Second: 21,775.70674
Overall Steps per Second: 10,568.32113

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.73226

Cumulative Model Updates: 224,018
Cumulative Timesteps: 1,868,236,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.79272
Policy Entropy: 2.17841
Value Function Loss: 0.01566

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.53380
Value Function Update Magnitude: 0.59453

Collected Steps per Second: 22,080.62736
Overall Steps per Second: 10,437.95562

Timestep Collection Time: 2.26488
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79117

Cumulative Model Updates: 224,024
Cumulative Timesteps: 1,868,286,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1868286730...
Checkpoint 1868286730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.77890
Policy Entropy: 2.15121
Value Function Loss: 0.01566

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.60234

Collected Steps per Second: 21,589.80290
Overall Steps per Second: 10,300.69230

Timestep Collection Time: 2.31609
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.85443

Cumulative Model Updates: 224,030
Cumulative Timesteps: 1,868,336,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.92651
Policy Entropy: 2.13095
Value Function Loss: 0.01563

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.53031
Value Function Update Magnitude: 0.59668

Collected Steps per Second: 21,861.41666
Overall Steps per Second: 10,368.46509

Timestep Collection Time: 2.28768
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.82347

Cumulative Model Updates: 224,036
Cumulative Timesteps: 1,868,386,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1868386746...
Checkpoint 1868386746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.55271
Policy Entropy: 2.12025
Value Function Loss: 0.01701

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.58264

Collected Steps per Second: 21,926.96540
Overall Steps per Second: 10,596.89692

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.71836

Cumulative Model Updates: 224,042
Cumulative Timesteps: 1,868,436,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.71864
Policy Entropy: 2.11973
Value Function Loss: 0.01727

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.58788

Collected Steps per Second: 22,045.27715
Overall Steps per Second: 10,369.50694

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.55428
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.82279

Cumulative Model Updates: 224,048
Cumulative Timesteps: 1,868,486,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1868486756...
Checkpoint 1868486756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.38955
Policy Entropy: 2.11713
Value Function Loss: 0.01708

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 21,720.63973
Overall Steps per Second: 10,386.78967

Timestep Collection Time: 2.30315
Timestep Consumption Time: 2.51316
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.81631

Cumulative Model Updates: 224,054
Cumulative Timesteps: 1,868,536,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.79142
Policy Entropy: 2.10830
Value Function Loss: 0.01702

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.52658
Value Function Update Magnitude: 0.61722

Collected Steps per Second: 21,443.24903
Overall Steps per Second: 10,200.41510

Timestep Collection Time: 2.33174
Timestep Consumption Time: 2.57003
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.90176

Cumulative Model Updates: 224,060
Cumulative Timesteps: 1,868,586,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1868586782...
Checkpoint 1868586782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.68014
Policy Entropy: 2.13810
Value Function Loss: 0.01712

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 21,647.66828
Overall Steps per Second: 10,484.21188

Timestep Collection Time: 2.31120
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.77213

Cumulative Model Updates: 224,066
Cumulative Timesteps: 1,868,636,814

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.59384
Policy Entropy: 2.12802
Value Function Loss: 0.01689

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.61017

Collected Steps per Second: 21,778.35135
Overall Steps per Second: 10,364.87339

Timestep Collection Time: 2.29586
Timestep Consumption Time: 2.52813
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.82399

Cumulative Model Updates: 224,072
Cumulative Timesteps: 1,868,686,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1868686814...
Checkpoint 1868686814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.00258
Policy Entropy: 2.11035
Value Function Loss: 0.01782

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,053.76661
Overall Steps per Second: 10,296.35757

Timestep Collection Time: 2.26800
Timestep Consumption Time: 2.58983
PPO Batch Consumption Time: 0.30457
Total Iteration Time: 4.85783

Cumulative Model Updates: 224,078
Cumulative Timesteps: 1,868,736,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.72972
Policy Entropy: 2.09828
Value Function Loss: 0.01693

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.54030
Value Function Update Magnitude: 0.60806

Collected Steps per Second: 21,966.39690
Overall Steps per Second: 10,389.55516

Timestep Collection Time: 2.27757
Timestep Consumption Time: 2.53784
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.81541

Cumulative Model Updates: 224,084
Cumulative Timesteps: 1,868,786,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1868786862...
Checkpoint 1868786862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.67405
Policy Entropy: 2.11138
Value Function Loss: 0.01760

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.57566

Collected Steps per Second: 21,832.45297
Overall Steps per Second: 10,302.29911

Timestep Collection Time: 2.29044
Timestep Consumption Time: 2.56342
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.85387

Cumulative Model Updates: 224,090
Cumulative Timesteps: 1,868,836,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.99936
Policy Entropy: 2.12789
Value Function Loss: 0.01746

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.54781

Collected Steps per Second: 21,799.62294
Overall Steps per Second: 10,441.01756

Timestep Collection Time: 2.29454
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.79072

Cumulative Model Updates: 224,096
Cumulative Timesteps: 1,868,886,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1868886888...
Checkpoint 1868886888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.81961
Policy Entropy: 2.11344
Value Function Loss: 0.01849

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.56147

Collected Steps per Second: 21,589.21006
Overall Steps per Second: 10,193.47731

Timestep Collection Time: 2.31616
Timestep Consumption Time: 2.58933
PPO Batch Consumption Time: 0.30304
Total Iteration Time: 4.90549

Cumulative Model Updates: 224,102
Cumulative Timesteps: 1,868,936,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.74158
Policy Entropy: 2.11604
Value Function Loss: 0.01791

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.58876

Collected Steps per Second: 21,483.69993
Overall Steps per Second: 10,183.20630

Timestep Collection Time: 2.32818
Timestep Consumption Time: 2.58363
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.91181

Cumulative Model Updates: 224,108
Cumulative Timesteps: 1,868,986,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1868986910...
Checkpoint 1868986910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.62818
Policy Entropy: 2.11558
Value Function Loss: 0.01679

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.60324

Collected Steps per Second: 21,741.87405
Overall Steps per Second: 10,406.55347

Timestep Collection Time: 2.30100
Timestep Consumption Time: 2.50636
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.80736

Cumulative Model Updates: 224,114
Cumulative Timesteps: 1,869,036,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.39922
Policy Entropy: 2.12185
Value Function Loss: 0.01720

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.52479
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 21,930.00435
Overall Steps per Second: 10,557.85033

Timestep Collection Time: 2.28098
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.73790

Cumulative Model Updates: 224,120
Cumulative Timesteps: 1,869,086,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1869086960...
Checkpoint 1869086960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.83297
Policy Entropy: 2.11348
Value Function Loss: 0.01715

Mean KL Divergence: 0.03357
SB3 Clip Fraction: 0.19264
Policy Update Magnitude: 0.51688
Value Function Update Magnitude: 0.59621

Collected Steps per Second: 21,764.72797
Overall Steps per Second: 10,244.87286

Timestep Collection Time: 2.29803
Timestep Consumption Time: 2.58402
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 4.88205

Cumulative Model Updates: 224,126
Cumulative Timesteps: 1,869,136,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.68006
Policy Entropy: 2.10812
Value Function Loss: 0.01710

Mean KL Divergence: 0.03126
SB3 Clip Fraction: 0.18669
Policy Update Magnitude: 0.48759
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 21,662.63590
Overall Steps per Second: 10,328.16010

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.53342
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.84191

Cumulative Model Updates: 224,132
Cumulative Timesteps: 1,869,186,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1869186984...
Checkpoint 1869186984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.61281
Policy Entropy: 2.09385
Value Function Loss: 0.01623

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.17395
Policy Update Magnitude: 0.50695
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 21,609.97886
Overall Steps per Second: 10,271.58449

Timestep Collection Time: 2.31412
Timestep Consumption Time: 2.55446
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.86858

Cumulative Model Updates: 224,138
Cumulative Timesteps: 1,869,236,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.80304
Policy Entropy: 2.11056
Value Function Loss: 0.01615

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.17029
Policy Update Magnitude: 0.53197
Value Function Update Magnitude: 0.59418

Collected Steps per Second: 21,524.71461
Overall Steps per Second: 10,486.14720

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.77087

Cumulative Model Updates: 224,144
Cumulative Timesteps: 1,869,287,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1869287020...
Checkpoint 1869287020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.90126
Policy Entropy: 2.12996
Value Function Loss: 0.01565

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 21,022.09666
Overall Steps per Second: 10,235.27479

Timestep Collection Time: 2.37864
Timestep Consumption Time: 2.50682
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 4.88546

Cumulative Model Updates: 224,150
Cumulative Timesteps: 1,869,337,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.39438
Policy Entropy: 2.16971
Value Function Loss: 0.01559

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.57831

Collected Steps per Second: 22,178.81787
Overall Steps per Second: 10,394.99700

Timestep Collection Time: 2.25512
Timestep Consumption Time: 2.55642
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.81155

Cumulative Model Updates: 224,156
Cumulative Timesteps: 1,869,387,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1869387040...
Checkpoint 1869387040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.34630
Policy Entropy: 2.14879
Value Function Loss: 0.01587

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.56558

Collected Steps per Second: 21,497.43203
Overall Steps per Second: 10,219.87487

Timestep Collection Time: 2.32614
Timestep Consumption Time: 2.56688
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.89301

Cumulative Model Updates: 224,162
Cumulative Timesteps: 1,869,437,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.29713
Policy Entropy: 2.15743
Value Function Loss: 0.01588

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.53092
Value Function Update Magnitude: 0.57149

Collected Steps per Second: 21,852.71100
Overall Steps per Second: 10,440.84629

Timestep Collection Time: 2.28832
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.78946

Cumulative Model Updates: 224,168
Cumulative Timesteps: 1,869,487,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1869487052...
Checkpoint 1869487052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.79554
Policy Entropy: 2.15600
Value Function Loss: 0.01584

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.57742

Collected Steps per Second: 21,748.52980
Overall Steps per Second: 10,530.63571

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.75033

Cumulative Model Updates: 224,174
Cumulative Timesteps: 1,869,537,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.01481
Policy Entropy: 2.15048
Value Function Loss: 0.01619

Mean KL Divergence: 0.02327
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.59663

Collected Steps per Second: 22,022.95448
Overall Steps per Second: 10,390.15115

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.54321
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.81475

Cumulative Model Updates: 224,180
Cumulative Timesteps: 1,869,587,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1869587102...
Checkpoint 1869587102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.42710
Policy Entropy: 2.14264
Value Function Loss: 0.01646

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.59940

Collected Steps per Second: 21,689.98025
Overall Steps per Second: 10,330.23125

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.84307

Cumulative Model Updates: 224,186
Cumulative Timesteps: 1,869,637,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.85401
Policy Entropy: 2.14529
Value Function Loss: 0.01611

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 22,194.36882
Overall Steps per Second: 10,534.38765

Timestep Collection Time: 2.25354
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.74788

Cumulative Model Updates: 224,192
Cumulative Timesteps: 1,869,687,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1869687148...
Checkpoint 1869687148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.98181
Policy Entropy: 2.14527
Value Function Loss: 0.01738

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.55832
Value Function Update Magnitude: 0.60649

Collected Steps per Second: 21,693.16963
Overall Steps per Second: 10,243.29180

Timestep Collection Time: 2.30589
Timestep Consumption Time: 2.57750
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.88339

Cumulative Model Updates: 224,198
Cumulative Timesteps: 1,869,737,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.63078
Policy Entropy: 2.14746
Value Function Loss: 0.01704

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.61147

Collected Steps per Second: 22,172.70522
Overall Steps per Second: 10,430.96634

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.53911
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.79476

Cumulative Model Updates: 224,204
Cumulative Timesteps: 1,869,787,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1869787184...
Checkpoint 1869787184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.84191
Policy Entropy: 2.13885
Value Function Loss: 0.01831

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.60771

Collected Steps per Second: 21,308.37224
Overall Steps per Second: 10,187.44670

Timestep Collection Time: 2.34678
Timestep Consumption Time: 2.56181
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 4.90859

Cumulative Model Updates: 224,210
Cumulative Timesteps: 1,869,837,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.62846
Policy Entropy: 2.13626
Value Function Loss: 0.01758

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.61252

Collected Steps per Second: 22,023.50359
Overall Steps per Second: 10,484.46146

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.50026
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.77201

Cumulative Model Updates: 224,216
Cumulative Timesteps: 1,869,887,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1869887222...
Checkpoint 1869887222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.62683
Policy Entropy: 2.12968
Value Function Loss: 0.01712

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.61535

Collected Steps per Second: 21,699.81885
Overall Steps per Second: 10,238.26826

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.57947
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.88364

Cumulative Model Updates: 224,222
Cumulative Timesteps: 1,869,937,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.95364
Policy Entropy: 2.09549
Value Function Loss: 0.01671

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 21,883.86636
Overall Steps per Second: 10,400.72688

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.80774

Cumulative Model Updates: 224,228
Cumulative Timesteps: 1,869,987,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1869987226...
Checkpoint 1869987226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.27375
Policy Entropy: 2.11905
Value Function Loss: 0.01575

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.60387

Collected Steps per Second: 21,312.18074
Overall Steps per Second: 10,217.23998

Timestep Collection Time: 2.34608
Timestep Consumption Time: 2.54761
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.89369

Cumulative Model Updates: 224,234
Cumulative Timesteps: 1,870,037,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.49772
Policy Entropy: 2.11749
Value Function Loss: 0.01613

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.58558

Collected Steps per Second: 22,163.75717
Overall Steps per Second: 10,479.53727

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.51688
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.77426

Cumulative Model Updates: 224,240
Cumulative Timesteps: 1,870,087,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1870087258...
Checkpoint 1870087258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.12506
Policy Entropy: 2.11564
Value Function Loss: 0.01696

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.59239

Collected Steps per Second: 21,520.41847
Overall Steps per Second: 10,498.30437

Timestep Collection Time: 2.32365
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.76325

Cumulative Model Updates: 224,246
Cumulative Timesteps: 1,870,137,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.48986
Policy Entropy: 2.09762
Value Function Loss: 0.01706

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.60231

Collected Steps per Second: 22,151.42934
Overall Steps per Second: 10,457.78344

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.78247

Cumulative Model Updates: 224,252
Cumulative Timesteps: 1,870,187,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1870187278...
Checkpoint 1870187278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.74378
Policy Entropy: 2.09399
Value Function Loss: 0.01701

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 21,532.79628
Overall Steps per Second: 10,326.45082

Timestep Collection Time: 2.32223
Timestep Consumption Time: 2.52010
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.84232

Cumulative Model Updates: 224,258
Cumulative Timesteps: 1,870,237,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.05841
Policy Entropy: 2.10259
Value Function Loss: 0.01678

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 21,478.56224
Overall Steps per Second: 10,368.42756

Timestep Collection Time: 2.32930
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.82523

Cumulative Model Updates: 224,264
Cumulative Timesteps: 1,870,287,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1870287312...
Checkpoint 1870287312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.29689
Policy Entropy: 2.11358
Value Function Loss: 0.01672

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.61435

Collected Steps per Second: 21,719.99966
Overall Steps per Second: 10,473.91896

Timestep Collection Time: 2.30212
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.77395

Cumulative Model Updates: 224,270
Cumulative Timesteps: 1,870,337,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.43214
Policy Entropy: 2.10358
Value Function Loss: 0.01818

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 22,072.01979
Overall Steps per Second: 10,289.18053

Timestep Collection Time: 2.26613
Timestep Consumption Time: 2.59510
PPO Batch Consumption Time: 0.30392
Total Iteration Time: 4.86122

Cumulative Model Updates: 224,276
Cumulative Timesteps: 1,870,387,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1870387332...
Checkpoint 1870387332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.70945
Policy Entropy: 2.11452
Value Function Loss: 0.01874

Mean KL Divergence: 0.02640
SB3 Clip Fraction: 0.17024
Policy Update Magnitude: 0.51529
Value Function Update Magnitude: 0.61892

Collected Steps per Second: 21,224.93079
Overall Steps per Second: 10,189.25676

Timestep Collection Time: 2.35610
Timestep Consumption Time: 2.55182
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.90791

Cumulative Model Updates: 224,282
Cumulative Timesteps: 1,870,437,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.92765
Policy Entropy: 2.11583
Value Function Loss: 0.01830

Mean KL Divergence: 0.02905
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.50425
Value Function Update Magnitude: 0.61393

Collected Steps per Second: 21,789.95756
Overall Steps per Second: 10,418.01819

Timestep Collection Time: 2.29610
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.80245

Cumulative Model Updates: 224,288
Cumulative Timesteps: 1,870,487,372

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1870487372...
Checkpoint 1870487372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.12818
Policy Entropy: 2.12547
Value Function Loss: 0.01774

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.16695
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.60232

Collected Steps per Second: 20,860.71166
Overall Steps per Second: 10,225.16232

Timestep Collection Time: 2.39743
Timestep Consumption Time: 2.49365
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.89107

Cumulative Model Updates: 224,294
Cumulative Timesteps: 1,870,537,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.30771
Policy Entropy: 2.11526
Value Function Loss: 0.01777

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.16656
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 21,814.53001
Overall Steps per Second: 10,504.73816

Timestep Collection Time: 2.29306
Timestep Consumption Time: 2.46879
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.76185

Cumulative Model Updates: 224,300
Cumulative Timesteps: 1,870,587,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1870587406...
Checkpoint 1870587406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.77061
Policy Entropy: 2.10667
Value Function Loss: 0.01734

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.15643
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.63339

Collected Steps per Second: 21,674.26925
Overall Steps per Second: 10,205.15642

Timestep Collection Time: 2.30707
Timestep Consumption Time: 2.59281
PPO Batch Consumption Time: 0.30446
Total Iteration Time: 4.89988

Cumulative Model Updates: 224,306
Cumulative Timesteps: 1,870,637,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.52116
Policy Entropy: 2.12576
Value Function Loss: 0.01652

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 21,230.15601
Overall Steps per Second: 10,124.10389

Timestep Collection Time: 2.35533
Timestep Consumption Time: 2.58377
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.93910

Cumulative Model Updates: 224,312
Cumulative Timesteps: 1,870,687,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1870687414...
Checkpoint 1870687414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.31227
Policy Entropy: 2.14185
Value Function Loss: 0.01604

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.61704

Collected Steps per Second: 21,405.45760
Overall Steps per Second: 10,256.75808

Timestep Collection Time: 2.33697
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.87717

Cumulative Model Updates: 224,318
Cumulative Timesteps: 1,870,737,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.75033
Policy Entropy: 2.14713
Value Function Loss: 0.01655

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 21,765.69182
Overall Steps per Second: 10,446.16563

Timestep Collection Time: 2.29820
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.78855

Cumulative Model Updates: 224,324
Cumulative Timesteps: 1,870,787,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1870787460...
Checkpoint 1870787460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.30342
Policy Entropy: 2.13538
Value Function Loss: 0.01706

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.65061

Collected Steps per Second: 21,558.62878
Overall Steps per Second: 10,238.88549

Timestep Collection Time: 2.32009
Timestep Consumption Time: 2.56501
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.88510

Cumulative Model Updates: 224,330
Cumulative Timesteps: 1,870,837,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.89335
Policy Entropy: 2.12555
Value Function Loss: 0.01698

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.63801

Collected Steps per Second: 21,923.53292
Overall Steps per Second: 10,302.94477

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.57305
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.85434

Cumulative Model Updates: 224,336
Cumulative Timesteps: 1,870,887,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1870887492...
Checkpoint 1870887492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.55813
Policy Entropy: 2.12315
Value Function Loss: 0.01636

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.53227
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 21,413.24689
Overall Steps per Second: 10,203.17824

Timestep Collection Time: 2.33528
Timestep Consumption Time: 2.56574
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 4.90102

Cumulative Model Updates: 224,342
Cumulative Timesteps: 1,870,937,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.68415
Policy Entropy: 2.11043
Value Function Loss: 0.01622

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.52609
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 21,671.23523
Overall Steps per Second: 10,449.58428

Timestep Collection Time: 2.30813
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.78679

Cumulative Model Updates: 224,348
Cumulative Timesteps: 1,870,987,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1870987518...
Checkpoint 1870987518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.23607
Policy Entropy: 2.10827
Value Function Loss: 0.01746

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.53675
Value Function Update Magnitude: 0.58179

Collected Steps per Second: 21,855.19793
Overall Steps per Second: 10,307.27367

Timestep Collection Time: 2.28879
Timestep Consumption Time: 2.56429
PPO Batch Consumption Time: 0.30205
Total Iteration Time: 4.85308

Cumulative Model Updates: 224,354
Cumulative Timesteps: 1,871,037,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.51173
Policy Entropy: 2.10178
Value Function Loss: 0.01827

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.60476

Collected Steps per Second: 21,816.81829
Overall Steps per Second: 10,368.15985

Timestep Collection Time: 2.29245
Timestep Consumption Time: 2.53136
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.82381

Cumulative Model Updates: 224,360
Cumulative Timesteps: 1,871,087,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1871087554...
Checkpoint 1871087554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.87687
Policy Entropy: 2.12696
Value Function Loss: 0.01868

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.60588

Collected Steps per Second: 21,804.76774
Overall Steps per Second: 10,569.74502

Timestep Collection Time: 2.29317
Timestep Consumption Time: 2.43750
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.73067

Cumulative Model Updates: 224,366
Cumulative Timesteps: 1,871,137,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.10360
Policy Entropy: 2.11985
Value Function Loss: 0.01754

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.53465
Value Function Update Magnitude: 0.59378

Collected Steps per Second: 21,764.94633
Overall Steps per Second: 10,265.39613

Timestep Collection Time: 2.29746
Timestep Consumption Time: 2.57367
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 4.87112

Cumulative Model Updates: 224,372
Cumulative Timesteps: 1,871,187,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1871187560...
Checkpoint 1871187560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.90389
Policy Entropy: 2.15167
Value Function Loss: 0.01743

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.60088

Collected Steps per Second: 21,875.89112
Overall Steps per Second: 10,387.57257

Timestep Collection Time: 2.28681
Timestep Consumption Time: 2.52914
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.81595

Cumulative Model Updates: 224,378
Cumulative Timesteps: 1,871,237,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.56513
Policy Entropy: 2.14824
Value Function Loss: 0.01683

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.61150

Collected Steps per Second: 21,755.92472
Overall Steps per Second: 10,289.19439

Timestep Collection Time: 2.29970
Timestep Consumption Time: 2.56288
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.86258

Cumulative Model Updates: 224,384
Cumulative Timesteps: 1,871,287,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1871287618...
Checkpoint 1871287618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.43712
Policy Entropy: 2.13941
Value Function Loss: 0.01750

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.53832
Value Function Update Magnitude: 0.59965

Collected Steps per Second: 21,910.87382
Overall Steps per Second: 10,507.32753

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.47790
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.76106

Cumulative Model Updates: 224,390
Cumulative Timesteps: 1,871,337,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.68960
Policy Entropy: 2.10934
Value Function Loss: 0.01874

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.58836

Collected Steps per Second: 22,460.30886
Overall Steps per Second: 10,408.50651

Timestep Collection Time: 2.22642
Timestep Consumption Time: 2.57792
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.80434

Cumulative Model Updates: 224,396
Cumulative Timesteps: 1,871,387,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1871387650...
Checkpoint 1871387650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.25909
Policy Entropy: 2.09821
Value Function Loss: 0.01829

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.53931
Value Function Update Magnitude: 0.58845

Collected Steps per Second: 21,690.45335
Overall Steps per Second: 10,222.97021

Timestep Collection Time: 2.30525
Timestep Consumption Time: 2.58589
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 4.89114

Cumulative Model Updates: 224,402
Cumulative Timesteps: 1,871,437,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.80722
Policy Entropy: 2.09831
Value Function Loss: 0.01781

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.59836

Collected Steps per Second: 22,066.46648
Overall Steps per Second: 10,453.90269

Timestep Collection Time: 2.26670
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.78462

Cumulative Model Updates: 224,408
Cumulative Timesteps: 1,871,487,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1871487670...
Checkpoint 1871487670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.47058
Policy Entropy: 2.10139
Value Function Loss: 0.01718

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.54632
Value Function Update Magnitude: 0.61307

Collected Steps per Second: 21,602.04654
Overall Steps per Second: 10,288.17145

Timestep Collection Time: 2.31524
Timestep Consumption Time: 2.54607
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 4.86131

Cumulative Model Updates: 224,414
Cumulative Timesteps: 1,871,537,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.05002
Policy Entropy: 2.12661
Value Function Loss: 0.01739

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.61241

Collected Steps per Second: 21,675.57790
Overall Steps per Second: 10,370.28004

Timestep Collection Time: 2.30757
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.30325
Total Iteration Time: 4.82321

Cumulative Model Updates: 224,420
Cumulative Timesteps: 1,871,587,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1871587702...
Checkpoint 1871587702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.35104
Policy Entropy: 2.12037
Value Function Loss: 0.01703

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.54194
Value Function Update Magnitude: 0.60206

Collected Steps per Second: 21,617.13626
Overall Steps per Second: 10,201.89857

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.58848
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.90183

Cumulative Model Updates: 224,426
Cumulative Timesteps: 1,871,637,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.40568
Policy Entropy: 2.14172
Value Function Loss: 0.01700

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.59429

Collected Steps per Second: 22,107.27692
Overall Steps per Second: 10,457.75960

Timestep Collection Time: 2.26233
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.78248

Cumulative Model Updates: 224,432
Cumulative Timesteps: 1,871,687,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1871687724...
Checkpoint 1871687724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.10396
Policy Entropy: 2.12943
Value Function Loss: 0.01724

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.60644

Collected Steps per Second: 21,823.67320
Overall Steps per Second: 10,382.83572

Timestep Collection Time: 2.29146
Timestep Consumption Time: 2.52495
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.81641

Cumulative Model Updates: 224,438
Cumulative Timesteps: 1,871,737,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.14370
Policy Entropy: 2.14641
Value Function Loss: 0.01708

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 21,965.14670
Overall Steps per Second: 10,587.01427

Timestep Collection Time: 2.27679
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.72371

Cumulative Model Updates: 224,444
Cumulative Timesteps: 1,871,787,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1871787742...
Checkpoint 1871787742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.22082
Policy Entropy: 2.12260
Value Function Loss: 0.01743

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.62270

Collected Steps per Second: 22,103.60947
Overall Steps per Second: 10,318.06888

Timestep Collection Time: 2.26307
Timestep Consumption Time: 2.58493
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.84800

Cumulative Model Updates: 224,450
Cumulative Timesteps: 1,871,837,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.21318
Policy Entropy: 2.12931
Value Function Loss: 0.01729

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 21,865.71359
Overall Steps per Second: 10,373.32949

Timestep Collection Time: 2.28678
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.82025

Cumulative Model Updates: 224,456
Cumulative Timesteps: 1,871,887,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1871887766...
Checkpoint 1871887766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.86640
Policy Entropy: 2.11474
Value Function Loss: 0.01663

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 21,822.46126
Overall Steps per Second: 10,301.22188

Timestep Collection Time: 2.29223
Timestep Consumption Time: 2.56370
PPO Batch Consumption Time: 0.30409
Total Iteration Time: 4.85593

Cumulative Model Updates: 224,462
Cumulative Timesteps: 1,871,937,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.99754
Policy Entropy: 2.14421
Value Function Loss: 0.01707

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.61512

Collected Steps per Second: 21,703.67702
Overall Steps per Second: 10,454.62963

Timestep Collection Time: 2.30413
Timestep Consumption Time: 2.47921
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.78334

Cumulative Model Updates: 224,468
Cumulative Timesteps: 1,871,987,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1871987796...
Checkpoint 1871987796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.86392
Policy Entropy: 2.13397
Value Function Loss: 0.01691

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 21,733.00820
Overall Steps per Second: 10,224.82076

Timestep Collection Time: 2.30166
Timestep Consumption Time: 2.59055
PPO Batch Consumption Time: 0.30408
Total Iteration Time: 4.89221

Cumulative Model Updates: 224,474
Cumulative Timesteps: 1,872,037,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.22820
Policy Entropy: 2.11246
Value Function Loss: 0.01854

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.55206
Value Function Update Magnitude: 0.60225

Collected Steps per Second: 21,879.59556
Overall Steps per Second: 10,392.37910

Timestep Collection Time: 2.28624
Timestep Consumption Time: 2.52710
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.81333

Cumulative Model Updates: 224,480
Cumulative Timesteps: 1,872,087,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1872087840...
Checkpoint 1872087840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.71177
Policy Entropy: 2.08649
Value Function Loss: 0.01805

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 21,545.54700
Overall Steps per Second: 10,259.22958

Timestep Collection Time: 2.32085
Timestep Consumption Time: 2.55320
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.87405

Cumulative Model Updates: 224,486
Cumulative Timesteps: 1,872,137,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.23815
Policy Entropy: 2.09830
Value Function Loss: 0.01802

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.60570

Collected Steps per Second: 21,767.83661
Overall Steps per Second: 10,390.42773

Timestep Collection Time: 2.29779
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.81385

Cumulative Model Updates: 224,492
Cumulative Timesteps: 1,872,187,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1872187862...
Checkpoint 1872187862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.07619
Policy Entropy: 2.12403
Value Function Loss: 0.01675

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.60917

Collected Steps per Second: 21,735.72025
Overall Steps per Second: 10,518.15991

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.45499
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.75692

Cumulative Model Updates: 224,498
Cumulative Timesteps: 1,872,237,896

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.14917
Policy Entropy: 2.12534
Value Function Loss: 0.01708

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.52206
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 22,182.89163
Overall Steps per Second: 10,392.30073

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.55798
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.81260

Cumulative Model Updates: 224,504
Cumulative Timesteps: 1,872,287,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1872287910...
Checkpoint 1872287910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.98482
Policy Entropy: 2.12545
Value Function Loss: 0.01780

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.61008

Collected Steps per Second: 21,827.81599
Overall Steps per Second: 10,368.27312

Timestep Collection Time: 2.29139
Timestep Consumption Time: 2.53256
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.82395

Cumulative Model Updates: 224,510
Cumulative Timesteps: 1,872,337,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.46932
Policy Entropy: 2.11824
Value Function Loss: 0.01975

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 22,087.05100
Overall Steps per Second: 10,543.51822

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.74358

Cumulative Model Updates: 224,516
Cumulative Timesteps: 1,872,387,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1872387940...
Checkpoint 1872387940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.83621
Policy Entropy: 2.11764
Value Function Loss: 0.01876

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.66203

Collected Steps per Second: 21,716.82442
Overall Steps per Second: 10,243.34038

Timestep Collection Time: 2.30236
Timestep Consumption Time: 2.57886
PPO Batch Consumption Time: 0.30398
Total Iteration Time: 4.88122

Cumulative Model Updates: 224,522
Cumulative Timesteps: 1,872,437,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.96007
Policy Entropy: 2.12822
Value Function Loss: 0.01865

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.64249

Collected Steps per Second: 22,037.61288
Overall Steps per Second: 10,429.39965

Timestep Collection Time: 2.26939
Timestep Consumption Time: 2.52590
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.79529

Cumulative Model Updates: 224,528
Cumulative Timesteps: 1,872,487,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1872487952...
Checkpoint 1872487952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.50044
Policy Entropy: 2.13983
Value Function Loss: 0.01710

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.62927

Collected Steps per Second: 21,409.07145
Overall Steps per Second: 10,203.94425

Timestep Collection Time: 2.33649
Timestep Consumption Time: 2.56574
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 4.90222

Cumulative Model Updates: 224,534
Cumulative Timesteps: 1,872,537,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.61966
Policy Entropy: 2.14382
Value Function Loss: 0.01634

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 21,759.44561
Overall Steps per Second: 10,383.52421

Timestep Collection Time: 2.30006
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.81994

Cumulative Model Updates: 224,540
Cumulative Timesteps: 1,872,588,022

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1872588022...
Checkpoint 1872588022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.73597
Policy Entropy: 2.15174
Value Function Loss: 0.01643

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.52392
Value Function Update Magnitude: 0.62983

Collected Steps per Second: 22,609.50240
Overall Steps per Second: 10,502.10088

Timestep Collection Time: 2.21199
Timestep Consumption Time: 2.55010
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.76209

Cumulative Model Updates: 224,546
Cumulative Timesteps: 1,872,638,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.49211
Policy Entropy: 2.15218
Value Function Loss: 0.01782

Mean KL Divergence: 0.02948
SB3 Clip Fraction: 0.17918
Policy Update Magnitude: 0.51921
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 22,135.17800
Overall Steps per Second: 10,339.47096

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.57740
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.83661

Cumulative Model Updates: 224,552
Cumulative Timesteps: 1,872,688,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1872688042...
Checkpoint 1872688042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.60490
Policy Entropy: 2.13515
Value Function Loss: 0.01915

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.17890
Policy Update Magnitude: 0.54076
Value Function Update Magnitude: 0.63622

Collected Steps per Second: 21,560.10491
Overall Steps per Second: 10,317.05945

Timestep Collection Time: 2.32058
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.84944

Cumulative Model Updates: 224,558
Cumulative Timesteps: 1,872,738,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.62163
Policy Entropy: 2.13177
Value Function Loss: 0.01889

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.67410

Collected Steps per Second: 22,219.27221
Overall Steps per Second: 10,623.25376

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.70779

Cumulative Model Updates: 224,564
Cumulative Timesteps: 1,872,788,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1872788086...
Checkpoint 1872788086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.56237
Policy Entropy: 2.14341
Value Function Loss: 0.01733

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.67474

Collected Steps per Second: 21,644.16864
Overall Steps per Second: 10,281.18572

Timestep Collection Time: 2.31166
Timestep Consumption Time: 2.55490
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.86656

Cumulative Model Updates: 224,570
Cumulative Timesteps: 1,872,838,120

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.91559
Policy Entropy: 2.14779
Value Function Loss: 0.01656

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.66445

Collected Steps per Second: 21,980.69831
Overall Steps per Second: 10,398.87691

Timestep Collection Time: 2.27554
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.80994

Cumulative Model Updates: 224,576
Cumulative Timesteps: 1,872,888,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1872888138...
Checkpoint 1872888138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.07526
Policy Entropy: 2.13676
Value Function Loss: 0.01638

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.64861

Collected Steps per Second: 21,355.82862
Overall Steps per Second: 10,286.97056

Timestep Collection Time: 2.34147
Timestep Consumption Time: 2.51944
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.86091

Cumulative Model Updates: 224,582
Cumulative Timesteps: 1,872,938,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.60150
Policy Entropy: 2.12565
Value Function Loss: 0.01608

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.53139
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 21,915.67273
Overall Steps per Second: 10,431.69235

Timestep Collection Time: 2.28211
Timestep Consumption Time: 2.51232
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.79443

Cumulative Model Updates: 224,588
Cumulative Timesteps: 1,872,988,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1872988156...
Checkpoint 1872988156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.05460
Policy Entropy: 2.12871
Value Function Loss: 0.01655

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 21,524.76650
Overall Steps per Second: 10,498.50740

Timestep Collection Time: 2.32365
Timestep Consumption Time: 2.44046
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.76411

Cumulative Model Updates: 224,594
Cumulative Timesteps: 1,873,038,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.21976
Policy Entropy: 2.13061
Value Function Loss: 0.01768

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.60613

Collected Steps per Second: 22,214.96121
Overall Steps per Second: 10,500.72898

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.51214
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.76405

Cumulative Model Updates: 224,600
Cumulative Timesteps: 1,873,088,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1873088198...
Checkpoint 1873088198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.86864
Policy Entropy: 2.11178
Value Function Loss: 0.01727

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.61735

Collected Steps per Second: 21,468.68004
Overall Steps per Second: 10,309.20228

Timestep Collection Time: 2.32991
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.85198

Cumulative Model Updates: 224,606
Cumulative Timesteps: 1,873,138,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.22384
Policy Entropy: 2.09051
Value Function Loss: 0.01659

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.60948

Collected Steps per Second: 21,881.75575
Overall Steps per Second: 10,430.69695

Timestep Collection Time: 2.28601
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.79565

Cumulative Model Updates: 224,612
Cumulative Timesteps: 1,873,188,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1873188240...
Checkpoint 1873188240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.07625
Policy Entropy: 2.08555
Value Function Loss: 0.01663

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.61982

Collected Steps per Second: 21,515.06692
Overall Steps per Second: 10,226.88927

Timestep Collection Time: 2.32395
Timestep Consumption Time: 2.56512
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.88907

Cumulative Model Updates: 224,618
Cumulative Timesteps: 1,873,238,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.04216
Policy Entropy: 2.09557
Value Function Loss: 0.01622

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.62329

Collected Steps per Second: 21,788.41268
Overall Steps per Second: 10,349.41100

Timestep Collection Time: 2.29516
Timestep Consumption Time: 2.53680
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.83197

Cumulative Model Updates: 224,624
Cumulative Timesteps: 1,873,288,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1873288248...
Checkpoint 1873288248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.26964
Policy Entropy: 2.11485
Value Function Loss: 0.01762

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.53635
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 21,352.81565
Overall Steps per Second: 10,348.73110

Timestep Collection Time: 2.34283
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.83402

Cumulative Model Updates: 224,630
Cumulative Timesteps: 1,873,338,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.18565
Policy Entropy: 2.13649
Value Function Loss: 0.01640

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.60244

Collected Steps per Second: 21,993.20114
Overall Steps per Second: 10,392.31639

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.53822
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.81202

Cumulative Model Updates: 224,636
Cumulative Timesteps: 1,873,388,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1873388282...
Checkpoint 1873388282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.38779
Policy Entropy: 2.14221
Value Function Loss: 0.01649

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.62066

Collected Steps per Second: 22,029.71002
Overall Steps per Second: 10,313.00913

Timestep Collection Time: 2.27030
Timestep Consumption Time: 2.57931
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.84960

Cumulative Model Updates: 224,642
Cumulative Timesteps: 1,873,438,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.81433
Policy Entropy: 2.13003
Value Function Loss: 0.01673

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.63812

Collected Steps per Second: 22,154.04880
Overall Steps per Second: 10,353.48760

Timestep Collection Time: 2.25810
Timestep Consumption Time: 2.57370
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.83180

Cumulative Model Updates: 224,648
Cumulative Timesteps: 1,873,488,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1873488322...
Checkpoint 1873488322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.17353
Policy Entropy: 2.08814
Value Function Loss: 0.01746

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.65283

Collected Steps per Second: 21,663.95095
Overall Steps per Second: 10,245.93878

Timestep Collection Time: 2.30946
Timestep Consumption Time: 2.57365
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.88311

Cumulative Model Updates: 224,654
Cumulative Timesteps: 1,873,538,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.01900
Policy Entropy: 2.06688
Value Function Loss: 0.01706

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.51714
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 21,762.71745
Overall Steps per Second: 10,377.08191

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.52131
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.81927

Cumulative Model Updates: 224,660
Cumulative Timesteps: 1,873,588,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1873588364...
Checkpoint 1873588364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.52757
Policy Entropy: 2.10483
Value Function Loss: 0.01630

Mean KL Divergence: 0.02998
SB3 Clip Fraction: 0.18148
Policy Update Magnitude: 0.49811
Value Function Update Magnitude: 0.62817

Collected Steps per Second: 22,163.74773
Overall Steps per Second: 10,362.89167

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.56907
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.82510

Cumulative Model Updates: 224,666
Cumulative Timesteps: 1,873,638,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.81074
Policy Entropy: 2.12692
Value Function Loss: 0.01591

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.15814
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.60039

Collected Steps per Second: 21,901.44281
Overall Steps per Second: 10,380.92301

Timestep Collection Time: 2.28387
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.81845

Cumulative Model Updates: 224,672
Cumulative Timesteps: 1,873,688,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1873688386...
Checkpoint 1873688386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.17864
Policy Entropy: 2.14895
Value Function Loss: 0.01587

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.51676
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 21,674.66566
Overall Steps per Second: 10,200.12265

Timestep Collection Time: 2.30739
Timestep Consumption Time: 2.59568
PPO Batch Consumption Time: 0.30552
Total Iteration Time: 4.90308

Cumulative Model Updates: 224,678
Cumulative Timesteps: 1,873,738,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.28327
Policy Entropy: 2.11120
Value Function Loss: 0.01639

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.53625
Value Function Update Magnitude: 0.63482

Collected Steps per Second: 21,829.41781
Overall Steps per Second: 10,436.36721

Timestep Collection Time: 2.29140
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.79286

Cumulative Model Updates: 224,684
Cumulative Timesteps: 1,873,788,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1873788418...
Checkpoint 1873788418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.41094
Policy Entropy: 2.11578
Value Function Loss: 0.01659

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.62892

Collected Steps per Second: 21,730.43165
Overall Steps per Second: 10,533.99296

Timestep Collection Time: 2.30092
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.74654

Cumulative Model Updates: 224,690
Cumulative Timesteps: 1,873,838,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.58029
Policy Entropy: 2.11193
Value Function Loss: 0.01668

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 21,879.54383
Overall Steps per Second: 10,307.73517

Timestep Collection Time: 2.28524
Timestep Consumption Time: 2.56549
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.85073

Cumulative Model Updates: 224,696
Cumulative Timesteps: 1,873,888,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1873888418...
Checkpoint 1873888418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.88136
Policy Entropy: 2.12572
Value Function Loss: 0.01720

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.64554

Collected Steps per Second: 21,872.20780
Overall Steps per Second: 10,389.28013

Timestep Collection Time: 2.28628
Timestep Consumption Time: 2.52695
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.81323

Cumulative Model Updates: 224,702
Cumulative Timesteps: 1,873,938,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.17914
Policy Entropy: 2.11696
Value Function Loss: 0.01685

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.64140

Collected Steps per Second: 21,920.00543
Overall Steps per Second: 10,438.04021

Timestep Collection Time: 2.28184
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.79190

Cumulative Model Updates: 224,708
Cumulative Timesteps: 1,873,988,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1873988442...
Checkpoint 1873988442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.08253
Policy Entropy: 2.13040
Value Function Loss: 0.01613

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.61302

Collected Steps per Second: 21,818.97822
Overall Steps per Second: 10,481.07532

Timestep Collection Time: 2.29213
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.77165

Cumulative Model Updates: 224,714
Cumulative Timesteps: 1,874,038,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.59234
Policy Entropy: 2.11120
Value Function Loss: 0.01716

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.53072
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 21,793.40015
Overall Steps per Second: 10,293.15616

Timestep Collection Time: 2.29510
Timestep Consumption Time: 2.56425
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.85935

Cumulative Model Updates: 224,720
Cumulative Timesteps: 1,874,088,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1874088472...
Checkpoint 1874088472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.09591
Policy Entropy: 2.12580
Value Function Loss: 0.01803

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.62987

Collected Steps per Second: 21,634.15964
Overall Steps per Second: 10,211.25683

Timestep Collection Time: 2.31236
Timestep Consumption Time: 2.58674
PPO Batch Consumption Time: 0.30357
Total Iteration Time: 4.89910

Cumulative Model Updates: 224,726
Cumulative Timesteps: 1,874,138,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.98391
Policy Entropy: 2.09393
Value Function Loss: 0.01764

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.63944

Collected Steps per Second: 21,568.85077
Overall Steps per Second: 10,337.31938

Timestep Collection Time: 2.31881
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.83820

Cumulative Model Updates: 224,732
Cumulative Timesteps: 1,874,188,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1874188512...
Checkpoint 1874188512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.72066
Policy Entropy: 2.11093
Value Function Loss: 0.01669

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 21,994.91824
Overall Steps per Second: 10,529.30036

Timestep Collection Time: 2.27425
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.75074

Cumulative Model Updates: 224,738
Cumulative Timesteps: 1,874,238,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.99784
Policy Entropy: 2.10487
Value Function Loss: 0.01622

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.59685

Collected Steps per Second: 21,915.00105
Overall Steps per Second: 10,276.66900

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.58550
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 4.86850

Cumulative Model Updates: 224,744
Cumulative Timesteps: 1,874,288,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1874288566...
Checkpoint 1874288566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.70155
Policy Entropy: 2.14361
Value Function Loss: 0.01687

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 21,739.65288
Overall Steps per Second: 10,221.43702

Timestep Collection Time: 2.30105
Timestep Consumption Time: 2.59298
PPO Batch Consumption Time: 0.30394
Total Iteration Time: 4.89403

Cumulative Model Updates: 224,750
Cumulative Timesteps: 1,874,338,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.01516
Policy Entropy: 2.13057
Value Function Loss: 0.01753

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.64208

Collected Steps per Second: 21,855.81758
Overall Steps per Second: 10,444.20180

Timestep Collection Time: 2.28864
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.78926

Cumulative Model Updates: 224,756
Cumulative Timesteps: 1,874,388,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1874388610...
Checkpoint 1874388610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.27035
Policy Entropy: 2.13303
Value Function Loss: 0.01755

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.64182

Collected Steps per Second: 21,561.04724
Overall Steps per Second: 10,503.21657

Timestep Collection Time: 2.31928
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.76102

Cumulative Model Updates: 224,762
Cumulative Timesteps: 1,874,438,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.97092
Policy Entropy: 2.12073
Value Function Loss: 0.01786

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 21,863.29929
Overall Steps per Second: 10,311.29282

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.56232
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.84944

Cumulative Model Updates: 224,768
Cumulative Timesteps: 1,874,488,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1874488620...
Checkpoint 1874488620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.24378
Policy Entropy: 2.13979
Value Function Loss: 0.01814

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.62648

Collected Steps per Second: 21,745.16489
Overall Steps per Second: 10,350.28556

Timestep Collection Time: 2.30056
Timestep Consumption Time: 2.53274
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.83330

Cumulative Model Updates: 224,774
Cumulative Timesteps: 1,874,538,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.50192
Policy Entropy: 2.14283
Value Function Loss: 0.01772

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 21,686.49191
Overall Steps per Second: 10,542.89125

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.74519

Cumulative Model Updates: 224,780
Cumulative Timesteps: 1,874,588,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1874588674...
Checkpoint 1874588674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.18416
Policy Entropy: 2.10469
Value Function Loss: 0.01794

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 21,881.18523
Overall Steps per Second: 10,259.89295

Timestep Collection Time: 2.28589
Timestep Consumption Time: 2.58921
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.87510

Cumulative Model Updates: 224,786
Cumulative Timesteps: 1,874,638,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.17094
Policy Entropy: 2.08272
Value Function Loss: 0.01793

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.55979
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 21,845.72478
Overall Steps per Second: 10,381.27444

Timestep Collection Time: 2.28905
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.81694

Cumulative Model Updates: 224,792
Cumulative Timesteps: 1,874,688,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1874688698...
Checkpoint 1874688698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.62888
Policy Entropy: 2.07524
Value Function Loss: 0.01687

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 21,548.95316
Overall Steps per Second: 10,268.72703

Timestep Collection Time: 2.32086
Timestep Consumption Time: 2.54947
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.87032

Cumulative Model Updates: 224,798
Cumulative Timesteps: 1,874,738,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.00953
Policy Entropy: 2.11698
Value Function Loss: 0.01688

Mean KL Divergence: 0.03125
SB3 Clip Fraction: 0.18508
Policy Update Magnitude: 0.49147
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 21,863.77756
Overall Steps per Second: 10,426.27535

Timestep Collection Time: 2.28808
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.79807

Cumulative Model Updates: 224,804
Cumulative Timesteps: 1,874,788,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1874788736...
Checkpoint 1874788736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.08491
Policy Entropy: 2.14636
Value Function Loss: 0.01552

Mean KL Divergence: 0.02890
SB3 Clip Fraction: 0.17762
Policy Update Magnitude: 0.48485
Value Function Update Magnitude: 0.56812

Collected Steps per Second: 22,397.22298
Overall Steps per Second: 10,545.65032

Timestep Collection Time: 2.23296
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.74243

Cumulative Model Updates: 224,810
Cumulative Timesteps: 1,874,838,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.48667
Policy Entropy: 2.16898
Value Function Loss: 0.01620

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.49902
Value Function Update Magnitude: 0.57302

Collected Steps per Second: 21,758.28479
Overall Steps per Second: 10,259.75457

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.57677
PPO Batch Consumption Time: 0.30243
Total Iteration Time: 4.87595

Cumulative Model Updates: 224,816
Cumulative Timesteps: 1,874,888,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1874888774...
Checkpoint 1874888774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.06959
Policy Entropy: 2.14243
Value Function Loss: 0.01637

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.57344

Collected Steps per Second: 21,545.85220
Overall Steps per Second: 10,404.61016

Timestep Collection Time: 2.32073
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.80575

Cumulative Model Updates: 224,822
Cumulative Timesteps: 1,874,938,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.25174
Policy Entropy: 2.11899
Value Function Loss: 0.01739

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.57347

Collected Steps per Second: 21,893.32474
Overall Steps per Second: 10,570.94719

Timestep Collection Time: 2.28426
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.73089

Cumulative Model Updates: 224,828
Cumulative Timesteps: 1,874,988,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1874988786...
Checkpoint 1874988786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.92853
Policy Entropy: 2.09106
Value Function Loss: 0.01694

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.58057

Collected Steps per Second: 21,798.65971
Overall Steps per Second: 10,232.09382

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.59307
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 4.88698

Cumulative Model Updates: 224,834
Cumulative Timesteps: 1,875,038,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.86698
Policy Entropy: 2.08311
Value Function Loss: 0.01750

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.59044

Collected Steps per Second: 21,813.70022
Overall Steps per Second: 10,387.32152

Timestep Collection Time: 2.29269
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.81472

Cumulative Model Updates: 224,840
Cumulative Timesteps: 1,875,088,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1875088802...
Checkpoint 1875088802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.73867
Policy Entropy: 2.08128
Value Function Loss: 0.01789

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.61434

Collected Steps per Second: 21,370.66751
Overall Steps per Second: 10,287.92935

Timestep Collection Time: 2.34040
Timestep Consumption Time: 2.52122
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.86162

Cumulative Model Updates: 224,846
Cumulative Timesteps: 1,875,138,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.07597
Policy Entropy: 2.09977
Value Function Loss: 0.01873

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.63911

Collected Steps per Second: 21,938.50342
Overall Steps per Second: 10,449.38606

Timestep Collection Time: 2.28019
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.78727

Cumulative Model Updates: 224,852
Cumulative Timesteps: 1,875,188,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1875188842...
Checkpoint 1875188842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.29871
Policy Entropy: 2.13851
Value Function Loss: 0.01765

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.53843
Value Function Update Magnitude: 0.62505

Collected Steps per Second: 22,315.31921
Overall Steps per Second: 10,506.57553

Timestep Collection Time: 2.24151
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.76083

Cumulative Model Updates: 224,858
Cumulative Timesteps: 1,875,238,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.23783
Policy Entropy: 2.13695
Value Function Loss: 0.01688

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.52075
Value Function Update Magnitude: 0.60763

Collected Steps per Second: 22,093.85285
Overall Steps per Second: 10,459.66282

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.78180

Cumulative Model Updates: 224,864
Cumulative Timesteps: 1,875,288,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1875288878...
Checkpoint 1875288878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.67354
Policy Entropy: 2.11346
Value Function Loss: 0.01710

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 21,872.02677
Overall Steps per Second: 10,338.74185

Timestep Collection Time: 2.28603
Timestep Consumption Time: 2.55015
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.83618

Cumulative Model Updates: 224,870
Cumulative Timesteps: 1,875,338,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.39729
Policy Entropy: 2.07904
Value Function Loss: 0.01676

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.52565
Value Function Update Magnitude: 0.57061

Collected Steps per Second: 21,926.32446
Overall Steps per Second: 10,434.16309

Timestep Collection Time: 2.28064
Timestep Consumption Time: 2.51189
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.79253

Cumulative Model Updates: 224,876
Cumulative Timesteps: 1,875,388,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1875388884...
Checkpoint 1875388884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.95873
Policy Entropy: 2.10438
Value Function Loss: 0.01618

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.52252
Value Function Update Magnitude: 0.57707

Collected Steps per Second: 22,026.82945
Overall Steps per Second: 10,326.93246

Timestep Collection Time: 2.27059
Timestep Consumption Time: 2.57247
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.84306

Cumulative Model Updates: 224,882
Cumulative Timesteps: 1,875,438,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.55870
Policy Entropy: 2.12334
Value Function Loss: 0.01601

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.57815

Collected Steps per Second: 21,977.53316
Overall Steps per Second: 10,338.31024

Timestep Collection Time: 2.27505
Timestep Consumption Time: 2.56133
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.83638

Cumulative Model Updates: 224,888
Cumulative Timesteps: 1,875,488,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1875488898...
Checkpoint 1875488898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.88406
Policy Entropy: 2.12453
Value Function Loss: 0.01670

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.52341
Value Function Update Magnitude: 0.58158

Collected Steps per Second: 21,667.85546
Overall Steps per Second: 10,324.73439

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.84293

Cumulative Model Updates: 224,894
Cumulative Timesteps: 1,875,538,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.79830
Policy Entropy: 2.11912
Value Function Loss: 0.01693

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 22,123.70104
Overall Steps per Second: 10,553.85969

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.47867
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.73969

Cumulative Model Updates: 224,900
Cumulative Timesteps: 1,875,588,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1875588922...
Checkpoint 1875588922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.45050
Policy Entropy: 2.13410
Value Function Loss: 0.01653

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.54992

Collected Steps per Second: 21,664.57134
Overall Steps per Second: 10,341.66793

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.52750
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.83597

Cumulative Model Updates: 224,906
Cumulative Timesteps: 1,875,638,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.39491
Policy Entropy: 2.15133
Value Function Loss: 0.01692

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.53400
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 22,132.30656
Overall Steps per Second: 10,452.06814

Timestep Collection Time: 2.26032
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.78623

Cumulative Model Updates: 224,912
Cumulative Timesteps: 1,875,688,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1875688960...
Checkpoint 1875688960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.80475
Policy Entropy: 2.13853
Value Function Loss: 0.01834

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.54841
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 21,656.53997
Overall Steps per Second: 10,288.77848

Timestep Collection Time: 2.30933
Timestep Consumption Time: 2.55150
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.86083

Cumulative Model Updates: 224,918
Cumulative Timesteps: 1,875,738,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.54687
Policy Entropy: 2.13635
Value Function Loss: 0.01806

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 22,066.82344
Overall Steps per Second: 10,461.05878

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.30426
Total Iteration Time: 4.78116

Cumulative Model Updates: 224,924
Cumulative Timesteps: 1,875,788,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1875788988...
Checkpoint 1875788988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.62112
Policy Entropy: 2.12428
Value Function Loss: 0.01794

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 21,254.35374
Overall Steps per Second: 10,198.68715

Timestep Collection Time: 2.35246
Timestep Consumption Time: 2.55013
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.90259

Cumulative Model Updates: 224,930
Cumulative Timesteps: 1,875,838,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.16434
Policy Entropy: 2.11282
Value Function Loss: 0.01763

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,140.77191
Overall Steps per Second: 10,470.93717

Timestep Collection Time: 2.25891
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.77646

Cumulative Model Updates: 224,936
Cumulative Timesteps: 1,875,889,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1875889002...
Checkpoint 1875889002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.48943
Policy Entropy: 2.10816
Value Function Loss: 0.01728

Mean KL Divergence: 0.02986
SB3 Clip Fraction: 0.18248
Policy Update Magnitude: 0.52508
Value Function Update Magnitude: 0.58958

Collected Steps per Second: 21,548.31948
Overall Steps per Second: 10,262.38073

Timestep Collection Time: 2.32250
Timestep Consumption Time: 2.55414
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 4.87665

Cumulative Model Updates: 224,942
Cumulative Timesteps: 1,875,939,048

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.90736
Policy Entropy: 2.11755
Value Function Loss: 0.01624

Mean KL Divergence: 0.02787
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.58025

Collected Steps per Second: 22,142.17385
Overall Steps per Second: 10,536.61318

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.74612

Cumulative Model Updates: 224,948
Cumulative Timesteps: 1,875,989,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1875989056...
Checkpoint 1875989056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.51306
Policy Entropy: 2.14217
Value Function Loss: 0.01604

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 21,699.55368
Overall Steps per Second: 10,368.75072

Timestep Collection Time: 2.30493
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.82372

Cumulative Model Updates: 224,954
Cumulative Timesteps: 1,876,039,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.40917
Policy Entropy: 2.12527
Value Function Loss: 0.01720

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.57437

Collected Steps per Second: 22,221.65071
Overall Steps per Second: 10,459.78609

Timestep Collection Time: 2.25132
Timestep Consumption Time: 2.53157
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.78289

Cumulative Model Updates: 224,960
Cumulative Timesteps: 1,876,089,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1876089100...
Checkpoint 1876089100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.50480
Policy Entropy: 2.10231
Value Function Loss: 0.01721

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 21,645.52099
Overall Steps per Second: 10,281.32552

Timestep Collection Time: 2.31041
Timestep Consumption Time: 2.55375
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.86416

Cumulative Model Updates: 224,966
Cumulative Timesteps: 1,876,139,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.37085
Policy Entropy: 2.09701
Value Function Loss: 0.01667

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 18,054.10103
Overall Steps per Second: 9,404.65086

Timestep Collection Time: 2.77134
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 5.32013

Cumulative Model Updates: 224,972
Cumulative Timesteps: 1,876,189,144

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1876189144...
Checkpoint 1876189144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.99344
Policy Entropy: 2.11708
Value Function Loss: 0.01587

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.53208
Value Function Update Magnitude: 0.58368

Collected Steps per Second: 20,745.21743
Overall Steps per Second: 10,161.35169

Timestep Collection Time: 2.41058
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.92139

Cumulative Model Updates: 224,978
Cumulative Timesteps: 1,876,239,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.91086
Policy Entropy: 2.14203
Value Function Loss: 0.01655

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.59099

Collected Steps per Second: 22,097.86923
Overall Steps per Second: 10,462.03937

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.77937

Cumulative Model Updates: 224,984
Cumulative Timesteps: 1,876,289,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1876289154...
Checkpoint 1876289154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.40240
Policy Entropy: 2.12342
Value Function Loss: 0.01670

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.53413
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 21,231.31884
Overall Steps per Second: 10,167.47668

Timestep Collection Time: 2.35529
Timestep Consumption Time: 2.56294
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.91823

Cumulative Model Updates: 224,990
Cumulative Timesteps: 1,876,339,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.44009
Policy Entropy: 2.11301
Value Function Loss: 0.01698

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.60412

Collected Steps per Second: 21,861.26980
Overall Steps per Second: 10,481.05390

Timestep Collection Time: 2.28880
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.77395

Cumulative Model Updates: 224,996
Cumulative Timesteps: 1,876,389,196

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1876389196...
Checkpoint 1876389196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.00021
Policy Entropy: 2.14354
Value Function Loss: 0.01669

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.59708

Collected Steps per Second: 21,433.62916
Overall Steps per Second: 10,181.21056

Timestep Collection Time: 2.33334
Timestep Consumption Time: 2.57884
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.91219

Cumulative Model Updates: 225,002
Cumulative Timesteps: 1,876,439,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.77765
Policy Entropy: 2.16624
Value Function Loss: 0.01693

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.52774
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 21,821.33464
Overall Steps per Second: 10,365.44041

Timestep Collection Time: 2.29244
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.82604

Cumulative Model Updates: 225,008
Cumulative Timesteps: 1,876,489,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1876489232...
Checkpoint 1876489232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.04977
Policy Entropy: 2.15940
Value Function Loss: 0.01680

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.58690

Collected Steps per Second: 21,903.60348
Overall Steps per Second: 10,318.95745

Timestep Collection Time: 2.28355
Timestep Consumption Time: 2.56364
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.84720

Cumulative Model Updates: 225,014
Cumulative Timesteps: 1,876,539,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.17266
Policy Entropy: 2.13725
Value Function Loss: 0.01718

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.52805
Value Function Update Magnitude: 0.58309

Collected Steps per Second: 21,784.89792
Overall Steps per Second: 10,462.52398

Timestep Collection Time: 2.29554
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.77973

Cumulative Model Updates: 225,020
Cumulative Timesteps: 1,876,589,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1876589258...
Checkpoint 1876589258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.55747
Policy Entropy: 2.14460
Value Function Loss: 0.01702

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.59617

Collected Steps per Second: 21,587.90756
Overall Steps per Second: 10,194.56653

Timestep Collection Time: 2.31620
Timestep Consumption Time: 2.58857
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.90477

Cumulative Model Updates: 225,026
Cumulative Timesteps: 1,876,639,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.10548
Policy Entropy: 2.18185
Value Function Loss: 0.01643

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.52151
Value Function Update Magnitude: 0.58909

Collected Steps per Second: 21,344.83287
Overall Steps per Second: 10,171.79713

Timestep Collection Time: 2.34324
Timestep Consumption Time: 2.57389
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.91713

Cumulative Model Updates: 225,032
Cumulative Timesteps: 1,876,689,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1876689276...
Checkpoint 1876689276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.53641
Policy Entropy: 2.17272
Value Function Loss: 0.01580

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.51482
Value Function Update Magnitude: 0.56410

Collected Steps per Second: 21,648.51986
Overall Steps per Second: 10,392.20791

Timestep Collection Time: 2.31101
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.81418

Cumulative Model Updates: 225,038
Cumulative Timesteps: 1,876,739,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.62972
Policy Entropy: 2.15243
Value Function Loss: 0.01636

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.52187
Value Function Update Magnitude: 0.55906

Collected Steps per Second: 21,687.82597
Overall Steps per Second: 10,512.65257

Timestep Collection Time: 2.30673
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.75884

Cumulative Model Updates: 225,044
Cumulative Timesteps: 1,876,789,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1876789334...
Checkpoint 1876789334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.07564
Policy Entropy: 2.10264
Value Function Loss: 0.01613

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.53435
Value Function Update Magnitude: 0.57768

Collected Steps per Second: 21,746.30339
Overall Steps per Second: 10,292.80891

Timestep Collection Time: 2.29970
Timestep Consumption Time: 2.55903
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.85873

Cumulative Model Updates: 225,050
Cumulative Timesteps: 1,876,839,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.71765
Policy Entropy: 2.09612
Value Function Loss: 0.01580

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.56743

Collected Steps per Second: 21,853.23871
Overall Steps per Second: 10,373.46658

Timestep Collection Time: 2.28854
Timestep Consumption Time: 2.53261
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.82115

Cumulative Model Updates: 225,056
Cumulative Timesteps: 1,876,889,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1876889356...
Checkpoint 1876889356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.78469
Policy Entropy: 2.10348
Value Function Loss: 0.01580

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.54212

Collected Steps per Second: 21,570.65197
Overall Steps per Second: 10,259.54541

Timestep Collection Time: 2.31824
Timestep Consumption Time: 2.55585
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.87410

Cumulative Model Updates: 225,062
Cumulative Timesteps: 1,876,939,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.18146
Policy Entropy: 2.12426
Value Function Loss: 0.01641

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.54053

Collected Steps per Second: 21,619.33775
Overall Steps per Second: 10,482.37667

Timestep Collection Time: 2.31376
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77201

Cumulative Model Updates: 225,068
Cumulative Timesteps: 1,876,989,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1876989384...
Checkpoint 1876989384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.22778
Policy Entropy: 2.14325
Value Function Loss: 0.01722

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.53070
Value Function Update Magnitude: 0.53826

Collected Steps per Second: 21,731.50164
Overall Steps per Second: 10,277.27711

Timestep Collection Time: 2.30164
Timestep Consumption Time: 2.56522
PPO Batch Consumption Time: 0.30256
Total Iteration Time: 4.86685

Cumulative Model Updates: 225,074
Cumulative Timesteps: 1,877,039,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.45568
Policy Entropy: 2.15487
Value Function Loss: 0.01731

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.55540

Collected Steps per Second: 21,739.21735
Overall Steps per Second: 10,367.47351

Timestep Collection Time: 2.30109
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.82509

Cumulative Model Updates: 225,080
Cumulative Timesteps: 1,877,089,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1877089426...
Checkpoint 1877089426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.54050
Policy Entropy: 2.16624
Value Function Loss: 0.01626

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.57704

Collected Steps per Second: 21,743.70463
Overall Steps per Second: 10,559.25844

Timestep Collection Time: 2.30071
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.73764

Cumulative Model Updates: 225,086
Cumulative Timesteps: 1,877,139,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.94860
Policy Entropy: 2.17060
Value Function Loss: 0.01555

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.51052
Value Function Update Magnitude: 0.57916

Collected Steps per Second: 22,102.24325
Overall Steps per Second: 10,429.05273

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.53310
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.79622

Cumulative Model Updates: 225,092
Cumulative Timesteps: 1,877,189,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1877189472...
Checkpoint 1877189472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.40825
Policy Entropy: 2.17185
Value Function Loss: 0.01517

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.50676
Value Function Update Magnitude: 0.56482

Collected Steps per Second: 20,504.16148
Overall Steps per Second: 9,903.97583

Timestep Collection Time: 2.43931
Timestep Consumption Time: 2.61078
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 5.05009

Cumulative Model Updates: 225,098
Cumulative Timesteps: 1,877,239,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.92281
Policy Entropy: 2.17808
Value Function Loss: 0.01653

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.51660
Value Function Update Magnitude: 0.56520

Collected Steps per Second: 20,698.31441
Overall Steps per Second: 10,056.82694

Timestep Collection Time: 2.41624
Timestep Consumption Time: 2.55670
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.97294

Cumulative Model Updates: 225,104
Cumulative Timesteps: 1,877,289,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1877289500...
Checkpoint 1877289500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.77911
Policy Entropy: 2.17005
Value Function Loss: 0.01701

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.52635
Value Function Update Magnitude: 0.58468

Collected Steps per Second: 21,729.88435
Overall Steps per Second: 10,546.94450

Timestep Collection Time: 2.30227
Timestep Consumption Time: 2.44110
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.74336

Cumulative Model Updates: 225,110
Cumulative Timesteps: 1,877,339,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.70646
Policy Entropy: 2.15747
Value Function Loss: 0.01763

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.59018

Collected Steps per Second: 21,959.13649
Overall Steps per Second: 10,426.66594

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.79597

Cumulative Model Updates: 225,116
Cumulative Timesteps: 1,877,389,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1877389534...
Checkpoint 1877389534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.69782
Policy Entropy: 2.13416
Value Function Loss: 0.01682

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.58284

Collected Steps per Second: 22,044.14559
Overall Steps per Second: 10,321.42997

Timestep Collection Time: 2.26881
Timestep Consumption Time: 2.57684
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.84565

Cumulative Model Updates: 225,122
Cumulative Timesteps: 1,877,439,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.08994
Policy Entropy: 2.11686
Value Function Loss: 0.01752

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.57271

Collected Steps per Second: 21,794.45232
Overall Steps per Second: 10,402.21907

Timestep Collection Time: 2.29499
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.80840

Cumulative Model Updates: 225,128
Cumulative Timesteps: 1,877,489,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1877489566...
Checkpoint 1877489566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.45848
Policy Entropy: 2.14215
Value Function Loss: 0.01730

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.58415

Collected Steps per Second: 21,708.79112
Overall Steps per Second: 10,491.54222

Timestep Collection Time: 2.30358
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.76651

Cumulative Model Updates: 225,134
Cumulative Timesteps: 1,877,539,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.95931
Policy Entropy: 2.15367
Value Function Loss: 0.01696

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.52784
Value Function Update Magnitude: 0.60371

Collected Steps per Second: 21,982.22849
Overall Steps per Second: 10,298.02040

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.58167
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 4.85705

Cumulative Model Updates: 225,140
Cumulative Timesteps: 1,877,589,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1877589592...
Checkpoint 1877589592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.28736
Policy Entropy: 2.17450
Value Function Loss: 0.01650

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.52916
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 21,866.39766
Overall Steps per Second: 10,307.37542

Timestep Collection Time: 2.28789
Timestep Consumption Time: 2.56572
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.85361

Cumulative Model Updates: 225,146
Cumulative Timesteps: 1,877,639,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.55544
Policy Entropy: 2.16250
Value Function Loss: 0.01665

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.56175

Collected Steps per Second: 21,581.29729
Overall Steps per Second: 10,298.52356

Timestep Collection Time: 2.31775
Timestep Consumption Time: 2.53926
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.85701

Cumulative Model Updates: 225,152
Cumulative Timesteps: 1,877,689,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1877689640...
Checkpoint 1877689640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.33695
Policy Entropy: 2.15843
Value Function Loss: 0.01667

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.52710
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 21,747.36466
Overall Steps per Second: 10,536.14796

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.74747

Cumulative Model Updates: 225,158
Cumulative Timesteps: 1,877,739,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.44304
Policy Entropy: 2.13590
Value Function Loss: 0.01689

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.59542

Collected Steps per Second: 22,097.61537
Overall Steps per Second: 10,405.95106

Timestep Collection Time: 2.26405
Timestep Consumption Time: 2.54378
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.80783

Cumulative Model Updates: 225,164
Cumulative Timesteps: 1,877,789,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1877789690...
Checkpoint 1877789690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.53684
Policy Entropy: 2.13146
Value Function Loss: 0.01657

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.60308

Collected Steps per Second: 22,027.15070
Overall Steps per Second: 10,391.31518

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.54199
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.81210

Cumulative Model Updates: 225,170
Cumulative Timesteps: 1,877,839,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.92039
Policy Entropy: 2.11236
Value Function Loss: 0.01707

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.59552

Collected Steps per Second: 21,864.95385
Overall Steps per Second: 10,409.81479

Timestep Collection Time: 2.28704
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.80374

Cumulative Model Updates: 225,176
Cumulative Timesteps: 1,877,889,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1877889700...
Checkpoint 1877889700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.29872
Policy Entropy: 2.13448
Value Function Loss: 0.01683

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.53757
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 21,605.45625
Overall Steps per Second: 10,517.50624

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.43985
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.75417

Cumulative Model Updates: 225,182
Cumulative Timesteps: 1,877,939,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.89338
Policy Entropy: 2.11305
Value Function Loss: 0.01696

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 22,164.98987
Overall Steps per Second: 10,457.86175

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.52579
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.78205

Cumulative Model Updates: 225,188
Cumulative Timesteps: 1,877,989,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1877989712...
Checkpoint 1877989712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.33179
Policy Entropy: 2.12002
Value Function Loss: 0.01619

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.61372

Collected Steps per Second: 21,788.16023
Overall Steps per Second: 10,352.81729

Timestep Collection Time: 2.29510
Timestep Consumption Time: 2.53508
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.83018

Cumulative Model Updates: 225,194
Cumulative Timesteps: 1,878,039,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.30965
Policy Entropy: 2.12526
Value Function Loss: 0.01581

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 21,726.13703
Overall Steps per Second: 10,360.21522

Timestep Collection Time: 2.30184
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.82712

Cumulative Model Updates: 225,200
Cumulative Timesteps: 1,878,089,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1878089728...
Checkpoint 1878089728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.08901
Policy Entropy: 2.15541
Value Function Loss: 0.01583

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.53036
Value Function Update Magnitude: 0.60241

Collected Steps per Second: 21,832.68090
Overall Steps per Second: 10,488.39799

Timestep Collection Time: 2.29060
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.76813

Cumulative Model Updates: 225,206
Cumulative Timesteps: 1,878,139,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.67240
Policy Entropy: 2.14304
Value Function Loss: 0.01692

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.53459
Value Function Update Magnitude: 0.59004

Collected Steps per Second: 22,007.17803
Overall Steps per Second: 10,289.83982

Timestep Collection Time: 2.27235
Timestep Consumption Time: 2.58759
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 4.85994

Cumulative Model Updates: 225,212
Cumulative Timesteps: 1,878,189,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1878189746...
Checkpoint 1878189746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.82502
Policy Entropy: 2.11199
Value Function Loss: 0.01764

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.60725

Collected Steps per Second: 21,636.47120
Overall Steps per Second: 10,230.55216

Timestep Collection Time: 2.31147
Timestep Consumption Time: 2.57703
PPO Batch Consumption Time: 0.30322
Total Iteration Time: 4.88849

Cumulative Model Updates: 225,218
Cumulative Timesteps: 1,878,239,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.08121
Policy Entropy: 2.10326
Value Function Loss: 0.01771

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 21,824.28371
Overall Steps per Second: 10,398.32090

Timestep Collection Time: 2.29139
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.80924

Cumulative Model Updates: 225,224
Cumulative Timesteps: 1,878,289,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1878289766...
Checkpoint 1878289766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.50748
Policy Entropy: 2.11039
Value Function Loss: 0.01646

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.53607
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 21,465.90291
Overall Steps per Second: 10,411.75686

Timestep Collection Time: 2.33030
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.80438

Cumulative Model Updates: 225,230
Cumulative Timesteps: 1,878,339,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.91538
Policy Entropy: 2.10663
Value Function Loss: 0.01671

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.60329

Collected Steps per Second: 22,090.95686
Overall Steps per Second: 10,316.70460

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.58376
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 4.84767

Cumulative Model Updates: 225,236
Cumulative Timesteps: 1,878,389,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1878389800...
Checkpoint 1878389800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.79890
Policy Entropy: 2.09316
Value Function Loss: 0.01773

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 21,687.62362
Overall Steps per Second: 10,238.19445

Timestep Collection Time: 2.30565
Timestep Consumption Time: 2.57842
PPO Batch Consumption Time: 0.30308
Total Iteration Time: 4.88406

Cumulative Model Updates: 225,242
Cumulative Timesteps: 1,878,439,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.38387
Policy Entropy: 2.12092
Value Function Loss: 0.01763

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.60517

Collected Steps per Second: 22,018.92394
Overall Steps per Second: 10,380.59108

Timestep Collection Time: 2.27077
Timestep Consumption Time: 2.54591
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.81668

Cumulative Model Updates: 225,248
Cumulative Timesteps: 1,878,489,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1878489804...
Checkpoint 1878489804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.03054
Policy Entropy: 2.15156
Value Function Loss: 0.01758

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.59511

Collected Steps per Second: 20,963.35421
Overall Steps per Second: 10,230.31885

Timestep Collection Time: 2.38521
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.88763

Cumulative Model Updates: 225,254
Cumulative Timesteps: 1,878,539,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.77780
Policy Entropy: 2.16013
Value Function Loss: 0.01603

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.53007
Value Function Update Magnitude: 0.59394

Collected Steps per Second: 21,862.96411
Overall Steps per Second: 10,388.66788

Timestep Collection Time: 2.28743
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.81390

Cumulative Model Updates: 225,260
Cumulative Timesteps: 1,878,589,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1878589816...
Checkpoint 1878589816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.26792
Policy Entropy: 2.11520
Value Function Loss: 0.01676

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.58869

Collected Steps per Second: 21,377.17047
Overall Steps per Second: 10,257.14892

Timestep Collection Time: 2.33913
Timestep Consumption Time: 2.53591
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.87504

Cumulative Model Updates: 225,266
Cumulative Timesteps: 1,878,639,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.89273
Policy Entropy: 2.09225
Value Function Loss: 0.01723

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.57670

Collected Steps per Second: 21,948.77945
Overall Steps per Second: 10,429.27914

Timestep Collection Time: 2.27803
Timestep Consumption Time: 2.51616
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.79420

Cumulative Model Updates: 225,272
Cumulative Timesteps: 1,878,689,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1878689820...
Checkpoint 1878689820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.45450
Policy Entropy: 2.09575
Value Function Loss: 0.01814

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 21,561.22836
Overall Steps per Second: 10,522.53735

Timestep Collection Time: 2.31907
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.75190

Cumulative Model Updates: 225,278
Cumulative Timesteps: 1,878,739,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.34721
Policy Entropy: 2.10780
Value Function Loss: 0.01820

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.53195
Value Function Update Magnitude: 0.58119

Collected Steps per Second: 22,253.43670
Overall Steps per Second: 10,479.16872

Timestep Collection Time: 2.24810
Timestep Consumption Time: 2.52594
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.77404

Cumulative Model Updates: 225,284
Cumulative Timesteps: 1,878,789,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1878789850...
Checkpoint 1878789850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.42002
Policy Entropy: 2.10062
Value Function Loss: 0.01784

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.57774

Collected Steps per Second: 21,778.76713
Overall Steps per Second: 10,326.04644

Timestep Collection Time: 2.29618
Timestep Consumption Time: 2.54672
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.84290

Cumulative Model Updates: 225,290
Cumulative Timesteps: 1,878,839,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.22098
Policy Entropy: 2.08131
Value Function Loss: 0.01804

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.56384

Collected Steps per Second: 21,809.66975
Overall Steps per Second: 10,403.30129

Timestep Collection Time: 2.29339
Timestep Consumption Time: 2.51451
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.80790

Cumulative Model Updates: 225,296
Cumulative Timesteps: 1,878,889,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1878889876...
Checkpoint 1878889876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.76816
Policy Entropy: 2.07939
Value Function Loss: 0.01829

Mean KL Divergence: 0.03154
SB3 Clip Fraction: 0.18755
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.58440

Collected Steps per Second: 21,362.58823
Overall Steps per Second: 10,259.70833

Timestep Collection Time: 2.34157
Timestep Consumption Time: 2.53401
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.87558

Cumulative Model Updates: 225,302
Cumulative Timesteps: 1,878,939,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.22252
Policy Entropy: 2.09830
Value Function Loss: 0.01772

Mean KL Divergence: 0.02991
SB3 Clip Fraction: 0.17931
Policy Update Magnitude: 0.54789
Value Function Update Magnitude: 0.62299

Collected Steps per Second: 22,664.58811
Overall Steps per Second: 10,452.08769

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.57847
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.78526

Cumulative Model Updates: 225,308
Cumulative Timesteps: 1,878,989,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1878989914...
Checkpoint 1878989914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.09013
Policy Entropy: 2.11012
Value Function Loss: 0.01662

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.16146
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.61681

Collected Steps per Second: 21,386.83997
Overall Steps per Second: 10,206.96294

Timestep Collection Time: 2.33854
Timestep Consumption Time: 2.56145
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.89999

Cumulative Model Updates: 225,314
Cumulative Timesteps: 1,879,039,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.23978
Policy Entropy: 2.11850
Value Function Loss: 0.01641

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.59846

Collected Steps per Second: 21,875.71964
Overall Steps per Second: 10,450.19308

Timestep Collection Time: 2.28674
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.78690

Cumulative Model Updates: 225,320
Cumulative Timesteps: 1,879,089,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1879089952...
Checkpoint 1879089952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.88400
Policy Entropy: 2.10963
Value Function Loss: 0.01775

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.55409
Value Function Update Magnitude: 0.60705

Collected Steps per Second: 21,784.80397
Overall Steps per Second: 10,525.77518

Timestep Collection Time: 2.29555
Timestep Consumption Time: 2.45546
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.75100

Cumulative Model Updates: 225,326
Cumulative Timesteps: 1,879,139,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.96984
Policy Entropy: 2.10882
Value Function Loss: 0.01811

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.14686
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 22,226.24254
Overall Steps per Second: 10,483.44881

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.76961

Cumulative Model Updates: 225,332
Cumulative Timesteps: 1,879,189,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1879189962...
Checkpoint 1879189962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.84663
Policy Entropy: 2.10578
Value Function Loss: 0.01775

Mean KL Divergence: 0.02984
SB3 Clip Fraction: 0.17585
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.63209

Collected Steps per Second: 21,855.04645
Overall Steps per Second: 10,306.77998

Timestep Collection Time: 2.28908
Timestep Consumption Time: 2.56481
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.85389

Cumulative Model Updates: 225,338
Cumulative Timesteps: 1,879,239,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.42701
Policy Entropy: 2.13424
Value Function Loss: 0.01704

Mean KL Divergence: 0.02828
SB3 Clip Fraction: 0.17298
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.60710

Collected Steps per Second: 21,787.57683
Overall Steps per Second: 10,354.69433

Timestep Collection Time: 2.29626
Timestep Consumption Time: 2.53536
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.83162

Cumulative Model Updates: 225,344
Cumulative Timesteps: 1,879,290,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1879290020...
Checkpoint 1879290020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.42228
Policy Entropy: 2.13838
Value Function Loss: 0.01701

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.58933

Collected Steps per Second: 21,811.49699
Overall Steps per Second: 10,512.10282

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.46445
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.75718

Cumulative Model Updates: 225,350
Cumulative Timesteps: 1,879,340,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.59367
Policy Entropy: 2.15640
Value Function Loss: 0.01709

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.58858

Collected Steps per Second: 22,251.98545
Overall Steps per Second: 10,333.95043

Timestep Collection Time: 2.24789
Timestep Consumption Time: 2.59247
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.84036

Cumulative Model Updates: 225,356
Cumulative Timesteps: 1,879,390,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1879390048...
Checkpoint 1879390048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.12835
Policy Entropy: 2.13753
Value Function Loss: 0.01672

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 21,619.95446
Overall Steps per Second: 10,216.78572

Timestep Collection Time: 2.31370
Timestep Consumption Time: 2.58236
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.89606

Cumulative Model Updates: 225,362
Cumulative Timesteps: 1,879,440,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.89204
Policy Entropy: 2.12299
Value Function Loss: 0.01719

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.57313

Collected Steps per Second: 21,843.46726
Overall Steps per Second: 10,393.43374

Timestep Collection Time: 2.29039
Timestep Consumption Time: 2.52323
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.81362

Cumulative Model Updates: 225,368
Cumulative Timesteps: 1,879,490,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1879490100...
Checkpoint 1879490100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.96004
Policy Entropy: 2.12695
Value Function Loss: 0.01697

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.57190

Collected Steps per Second: 21,637.48864
Overall Steps per Second: 10,508.11493

Timestep Collection Time: 2.31219
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.76108

Cumulative Model Updates: 225,374
Cumulative Timesteps: 1,879,540,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.73273
Policy Entropy: 2.12332
Value Function Loss: 0.01694

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.53022
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 21,814.51537
Overall Steps per Second: 10,272.47765

Timestep Collection Time: 2.29224
Timestep Consumption Time: 2.57553
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.86776

Cumulative Model Updates: 225,380
Cumulative Timesteps: 1,879,590,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1879590134...
Checkpoint 1879590134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.95191
Policy Entropy: 2.15199
Value Function Loss: 0.01616

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.52290
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 21,820.41734
Overall Steps per Second: 10,392.14844

Timestep Collection Time: 2.29290
Timestep Consumption Time: 2.52151
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.81440

Cumulative Model Updates: 225,386
Cumulative Timesteps: 1,879,640,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.70953
Policy Entropy: 2.13673
Value Function Loss: 0.01580

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.52242
Value Function Update Magnitude: 0.54562

Collected Steps per Second: 21,858.83273
Overall Steps per Second: 10,440.11864

Timestep Collection Time: 2.28859
Timestep Consumption Time: 2.50311
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.79171

Cumulative Model Updates: 225,392
Cumulative Timesteps: 1,879,690,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1879690192...
Checkpoint 1879690192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.37268
Policy Entropy: 2.14929
Value Function Loss: 0.01653

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 21,723.70268
Overall Steps per Second: 10,333.77020

Timestep Collection Time: 2.30274
Timestep Consumption Time: 2.53809
PPO Batch Consumption Time: 0.30475
Total Iteration Time: 4.84083

Cumulative Model Updates: 225,398
Cumulative Timesteps: 1,879,740,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.72475
Policy Entropy: 2.15776
Value Function Loss: 0.01650

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.58687

Collected Steps per Second: 22,081.78394
Overall Steps per Second: 10,440.70472

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.52504
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.78971

Cumulative Model Updates: 225,404
Cumulative Timesteps: 1,879,790,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1879790224...
Checkpoint 1879790224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.94965
Policy Entropy: 2.16215
Value Function Loss: 0.01649

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 21,771.62130
Overall Steps per Second: 10,239.54607

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.58812
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.88615

Cumulative Model Updates: 225,410
Cumulative Timesteps: 1,879,840,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.83808
Policy Entropy: 2.16122
Value Function Loss: 0.01593

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.52495
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 21,371.27765
Overall Steps per Second: 10,333.35298

Timestep Collection Time: 2.34081
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.84122

Cumulative Model Updates: 225,416
Cumulative Timesteps: 1,879,890,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1879890282...
Checkpoint 1879890282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.78481
Policy Entropy: 2.16808
Value Function Loss: 0.01660

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.53372
Value Function Update Magnitude: 0.60930

Collected Steps per Second: 21,852.46410
Overall Steps per Second: 10,470.04625

Timestep Collection Time: 2.28853
Timestep Consumption Time: 2.48795
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.77648

Cumulative Model Updates: 225,422
Cumulative Timesteps: 1,879,940,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.42835
Policy Entropy: 2.16743
Value Function Loss: 0.01679

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.53930
Value Function Update Magnitude: 0.64006

Collected Steps per Second: 21,920.86751
Overall Steps per Second: 10,328.27968

Timestep Collection Time: 2.28184
Timestep Consumption Time: 2.56117
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.84301

Cumulative Model Updates: 225,428
Cumulative Timesteps: 1,879,990,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1879990312...
Checkpoint 1879990312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.78747
Policy Entropy: 2.18862
Value Function Loss: 0.01677

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.53903
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 21,714.45535
Overall Steps per Second: 10,213.45934

Timestep Collection Time: 2.30280
Timestep Consumption Time: 2.59309
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 4.89589

Cumulative Model Updates: 225,434
Cumulative Timesteps: 1,880,040,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.27998
Policy Entropy: 2.13735
Value Function Loss: 0.01736

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 21,511.37400
Overall Steps per Second: 10,358.93503

Timestep Collection Time: 2.32528
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.82868

Cumulative Model Updates: 225,440
Cumulative Timesteps: 1,880,090,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1880090336...
Checkpoint 1880090336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.63757
Policy Entropy: 2.10794
Value Function Loss: 0.01733

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.62330

Collected Steps per Second: 21,874.37518
Overall Steps per Second: 10,581.78935

Timestep Collection Time: 2.28615
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.72585

Cumulative Model Updates: 225,446
Cumulative Timesteps: 1,880,140,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.86666
Policy Entropy: 2.09972
Value Function Loss: 0.01746

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.63449

Collected Steps per Second: 21,724.15827
Overall Steps per Second: 10,241.61092

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.58087
PPO Batch Consumption Time: 0.30213
Total Iteration Time: 4.88283

Cumulative Model Updates: 225,452
Cumulative Timesteps: 1,880,190,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1880190352...
Checkpoint 1880190352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.56778
Policy Entropy: 2.12803
Value Function Loss: 0.01575

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.62010

Collected Steps per Second: 21,800.26211
Overall Steps per Second: 10,306.84768

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.55831
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.85250

Cumulative Model Updates: 225,458
Cumulative Timesteps: 1,880,240,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.52974
Policy Entropy: 2.14058
Value Function Loss: 0.01542

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.52249
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 21,756.05056
Overall Steps per Second: 10,260.51413

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.57504
PPO Batch Consumption Time: 0.30271
Total Iteration Time: 4.87344

Cumulative Model Updates: 225,464
Cumulative Timesteps: 1,880,290,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1880290370...
Checkpoint 1880290370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.36605
Policy Entropy: 2.10921
Value Function Loss: 0.01576

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.57681

Collected Steps per Second: 21,776.95495
Overall Steps per Second: 10,333.32492

Timestep Collection Time: 2.29711
Timestep Consumption Time: 2.54393
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.84104

Cumulative Model Updates: 225,470
Cumulative Timesteps: 1,880,340,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.58144
Policy Entropy: 2.10676
Value Function Loss: 0.01637

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.53461
Value Function Update Magnitude: 0.57597

Collected Steps per Second: 22,384.90059
Overall Steps per Second: 10,357.10493

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.59437
PPO Batch Consumption Time: 0.30377
Total Iteration Time: 4.82838

Cumulative Model Updates: 225,476
Cumulative Timesteps: 1,880,390,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1880390402...
Checkpoint 1880390402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.56445
Policy Entropy: 2.12634
Value Function Loss: 0.01662

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.58443

Collected Steps per Second: 21,901.79619
Overall Steps per Second: 10,314.91225

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.56577
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.84987

Cumulative Model Updates: 225,482
Cumulative Timesteps: 1,880,440,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.91250
Policy Entropy: 2.12562
Value Function Loss: 0.01672

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.54335
Value Function Update Magnitude: 0.59741

Collected Steps per Second: 21,563.61294
Overall Steps per Second: 10,263.77849

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.55278
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.87150

Cumulative Model Updates: 225,488
Cumulative Timesteps: 1,880,490,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1880490428...
Checkpoint 1880490428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.24252
Policy Entropy: 2.11561
Value Function Loss: 0.01762

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54753
Value Function Update Magnitude: 0.61318

Collected Steps per Second: 21,655.42219
Overall Steps per Second: 10,277.93710

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.55651
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.86596

Cumulative Model Updates: 225,494
Cumulative Timesteps: 1,880,540,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.73392
Policy Entropy: 2.09678
Value Function Loss: 0.01694

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.63777

Collected Steps per Second: 21,587.79618
Overall Steps per Second: 10,459.63556

Timestep Collection Time: 2.31714
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.78238

Cumulative Model Updates: 225,500
Cumulative Timesteps: 1,880,590,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1880590462...
Checkpoint 1880590462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.46511
Policy Entropy: 2.11238
Value Function Loss: 0.01724

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.62794

Collected Steps per Second: 21,858.73343
Overall Steps per Second: 10,256.81465

Timestep Collection Time: 2.28851
Timestep Consumption Time: 2.58863
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 4.87715

Cumulative Model Updates: 225,506
Cumulative Timesteps: 1,880,640,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.55285
Policy Entropy: 2.10453
Value Function Loss: 0.01803

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.61974

Collected Steps per Second: 21,774.51978
Overall Steps per Second: 10,328.81670

Timestep Collection Time: 2.29773
Timestep Consumption Time: 2.54619
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.84392

Cumulative Model Updates: 225,512
Cumulative Timesteps: 1,880,690,518

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1880690518...
Checkpoint 1880690518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.41706
Policy Entropy: 2.10083
Value Function Loss: 0.01870

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.64239

Collected Steps per Second: 21,743.76078
Overall Steps per Second: 10,288.92969

Timestep Collection Time: 2.30098
Timestep Consumption Time: 2.56172
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.86270

Cumulative Model Updates: 225,518
Cumulative Timesteps: 1,880,740,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.26908
Policy Entropy: 2.08760
Value Function Loss: 0.01795

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.65065

Collected Steps per Second: 21,671.57868
Overall Steps per Second: 10,484.63335

Timestep Collection Time: 2.30754
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.76965

Cumulative Model Updates: 225,524
Cumulative Timesteps: 1,880,790,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1880790558...
Checkpoint 1880790558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.55983
Policy Entropy: 2.08799
Value Function Loss: 0.01877

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.64379

Collected Steps per Second: 21,671.28120
Overall Steps per Second: 10,226.30558

Timestep Collection Time: 2.30739
Timestep Consumption Time: 2.58236
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 4.88974

Cumulative Model Updates: 225,530
Cumulative Timesteps: 1,880,840,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.19444
Policy Entropy: 2.09221
Value Function Loss: 0.01850

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.63421

Collected Steps per Second: 21,869.16044
Overall Steps per Second: 10,353.11023

Timestep Collection Time: 2.28715
Timestep Consumption Time: 2.54406
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.83121

Cumulative Model Updates: 225,536
Cumulative Timesteps: 1,880,890,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1880890580...
Checkpoint 1880890580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.61558
Policy Entropy: 2.11366
Value Function Loss: 0.01840

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.63399

Collected Steps per Second: 21,560.71515
Overall Steps per Second: 10,296.99718

Timestep Collection Time: 2.31913
Timestep Consumption Time: 2.53685
PPO Batch Consumption Time: 0.30936
Total Iteration Time: 4.85598

Cumulative Model Updates: 225,542
Cumulative Timesteps: 1,880,940,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.47311
Policy Entropy: 2.14441
Value Function Loss: 0.01735

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.63035

Collected Steps per Second: 21,299.76989
Overall Steps per Second: 10,589.53016

Timestep Collection Time: 2.34744
Timestep Consumption Time: 2.37420
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.72164

Cumulative Model Updates: 225,548
Cumulative Timesteps: 1,880,990,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1880990582...
Checkpoint 1880990582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.93601
Policy Entropy: 2.13461
Value Function Loss: 0.01750

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.60655

Collected Steps per Second: 20,458.52685
Overall Steps per Second: 10,175.03807

Timestep Collection Time: 2.44524
Timestep Consumption Time: 2.47130
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.91654

Cumulative Model Updates: 225,554
Cumulative Timesteps: 1,881,040,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.88839
Policy Entropy: 2.14441
Value Function Loss: 0.01672

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.52838
Value Function Update Magnitude: 0.58258

Collected Steps per Second: 20,189.86546
Overall Steps per Second: 9,648.06773

Timestep Collection Time: 2.47748
Timestep Consumption Time: 2.70698
PPO Batch Consumption Time: 0.32246
Total Iteration Time: 5.18446

Cumulative Model Updates: 225,560
Cumulative Timesteps: 1,881,090,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1881090628...
Checkpoint 1881090628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.35688
Policy Entropy: 2.15229
Value Function Loss: 0.01698

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.52889
Value Function Update Magnitude: 0.56420

Collected Steps per Second: 21,468.77349
Overall Steps per Second: 10,513.73063

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.75740

Cumulative Model Updates: 225,566
Cumulative Timesteps: 1,881,140,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.13581
Policy Entropy: 2.17119
Value Function Loss: 0.01678

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 19,933.26026
Overall Steps per Second: 10,129.32877

Timestep Collection Time: 2.51068
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.94070

Cumulative Model Updates: 225,572
Cumulative Timesteps: 1,881,190,692

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1881190692...
Checkpoint 1881190692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.10662
Policy Entropy: 2.14893
Value Function Loss: 0.01721

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.53735
Value Function Update Magnitude: 0.57734

Collected Steps per Second: 20,631.11256
Overall Steps per Second: 10,215.96671

Timestep Collection Time: 2.42430
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.89587

Cumulative Model Updates: 225,578
Cumulative Timesteps: 1,881,240,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.16982
Policy Entropy: 2.13765
Value Function Loss: 0.01680

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 20,638.39220
Overall Steps per Second: 10,063.23534

Timestep Collection Time: 2.42354
Timestep Consumption Time: 2.54683
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.97037

Cumulative Model Updates: 225,584
Cumulative Timesteps: 1,881,290,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1881290726...
Checkpoint 1881290726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.08153
Policy Entropy: 2.14098
Value Function Loss: 0.01754

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 20,556.95780
Overall Steps per Second: 10,180.99310

Timestep Collection Time: 2.43236
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.91131

Cumulative Model Updates: 225,590
Cumulative Timesteps: 1,881,340,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.37142
Policy Entropy: 2.16793
Value Function Loss: 0.01761

Mean KL Divergence: 0.03252
SB3 Clip Fraction: 0.18245
Policy Update Magnitude: 0.50810
Value Function Update Magnitude: 0.60114

Collected Steps per Second: 20,456.74403
Overall Steps per Second: 9,916.33373

Timestep Collection Time: 2.44487
Timestep Consumption Time: 2.59873
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 5.04360

Cumulative Model Updates: 225,596
Cumulative Timesteps: 1,881,390,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1881390742...
Checkpoint 1881390742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.71304
Policy Entropy: 2.17874
Value Function Loss: 0.01797

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.51745
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 21,383.77933
Overall Steps per Second: 10,379.16617

Timestep Collection Time: 2.33916
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.81927

Cumulative Model Updates: 225,602
Cumulative Timesteps: 1,881,440,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.96637
Policy Entropy: 2.16434
Value Function Loss: 0.01701

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.62000

Collected Steps per Second: 21,584.38035
Overall Steps per Second: 10,261.52611

Timestep Collection Time: 2.31705
Timestep Consumption Time: 2.55669
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.87374

Cumulative Model Updates: 225,608
Cumulative Timesteps: 1,881,490,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1881490774...
Checkpoint 1881490774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.83241
Policy Entropy: 2.14444
Value Function Loss: 0.01721

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.61322

Collected Steps per Second: 20,607.64878
Overall Steps per Second: 10,038.66532

Timestep Collection Time: 2.42725
Timestep Consumption Time: 2.55548
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.98273

Cumulative Model Updates: 225,614
Cumulative Timesteps: 1,881,540,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.98375
Policy Entropy: 2.13133
Value Function Loss: 0.01689

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 20,032.08836
Overall Steps per Second: 9,469.23737

Timestep Collection Time: 2.49629
Timestep Consumption Time: 2.78460
PPO Batch Consumption Time: 0.35215
Total Iteration Time: 5.28089

Cumulative Model Updates: 225,620
Cumulative Timesteps: 1,881,590,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1881590800...
Checkpoint 1881590800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.13974
Policy Entropy: 2.14997
Value Function Loss: 0.01733

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.54092
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 20,078.75190
Overall Steps per Second: 9,351.20404

Timestep Collection Time: 2.49119
Timestep Consumption Time: 2.85785
PPO Batch Consumption Time: 0.34541
Total Iteration Time: 5.34904

Cumulative Model Updates: 225,626
Cumulative Timesteps: 1,881,640,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.64667
Policy Entropy: 2.15586
Value Function Loss: 0.01698

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.60066

Collected Steps per Second: 18,769.78987
Overall Steps per Second: 9,506.58338

Timestep Collection Time: 2.66449
Timestep Consumption Time: 2.59628
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 5.26078

Cumulative Model Updates: 225,632
Cumulative Timesteps: 1,881,690,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1881690832...
Checkpoint 1881690832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.06691
Policy Entropy: 2.14494
Value Function Loss: 0.01686

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 20,963.10712
Overall Steps per Second: 9,782.88763

Timestep Collection Time: 2.38667
Timestep Consumption Time: 2.72757
PPO Batch Consumption Time: 0.32947
Total Iteration Time: 5.11424

Cumulative Model Updates: 225,638
Cumulative Timesteps: 1,881,740,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.94568
Policy Entropy: 2.14962
Value Function Loss: 0.01746

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.60821

Collected Steps per Second: 19,509.11463
Overall Steps per Second: 9,383.55310

Timestep Collection Time: 2.56342
Timestep Consumption Time: 2.76612
PPO Batch Consumption Time: 0.33359
Total Iteration Time: 5.32954

Cumulative Model Updates: 225,644
Cumulative Timesteps: 1,881,790,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1881790874...
Checkpoint 1881790874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.53352
Policy Entropy: 2.14414
Value Function Loss: 0.01691

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.60742

Collected Steps per Second: 20,141.58842
Overall Steps per Second: 9,170.69414

Timestep Collection Time: 2.48451
Timestep Consumption Time: 2.97222
PPO Batch Consumption Time: 0.36208
Total Iteration Time: 5.45673

Cumulative Model Updates: 225,650
Cumulative Timesteps: 1,881,840,916

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.53674
Policy Entropy: 2.17448
Value Function Loss: 0.01752

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.60503

Collected Steps per Second: 19,562.17083
Overall Steps per Second: 8,876.43909

Timestep Collection Time: 2.55769
Timestep Consumption Time: 3.07903
PPO Batch Consumption Time: 0.36254
Total Iteration Time: 5.63672

Cumulative Model Updates: 225,656
Cumulative Timesteps: 1,881,890,950

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1881890950...
Checkpoint 1881890950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.30681
Policy Entropy: 2.16039
Value Function Loss: 0.01751

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.59916

Collected Steps per Second: 19,493.51920
Overall Steps per Second: 9,098.84975

Timestep Collection Time: 2.56629
Timestep Consumption Time: 2.93177
PPO Batch Consumption Time: 0.34825
Total Iteration Time: 5.49806

Cumulative Model Updates: 225,662
Cumulative Timesteps: 1,881,940,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.30845
Policy Entropy: 2.14508
Value Function Loss: 0.01765

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 16,921.63062
Overall Steps per Second: 8,688.43520

Timestep Collection Time: 2.95598
Timestep Consumption Time: 2.80110
PPO Batch Consumption Time: 0.34061
Total Iteration Time: 5.75708

Cumulative Model Updates: 225,668
Cumulative Timesteps: 1,881,990,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1881990996...
Checkpoint 1881990996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.36059
Policy Entropy: 2.11323
Value Function Loss: 0.01774

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 17,327.60386
Overall Steps per Second: 8,707.99516

Timestep Collection Time: 2.88811
Timestep Consumption Time: 2.85879
PPO Batch Consumption Time: 0.34375
Total Iteration Time: 5.74690

Cumulative Model Updates: 225,674
Cumulative Timesteps: 1,882,041,040

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.92264
Policy Entropy: 2.10927
Value Function Loss: 0.01761

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 20,871.77621
Overall Steps per Second: 9,429.15012

Timestep Collection Time: 2.39625
Timestep Consumption Time: 2.90794
PPO Batch Consumption Time: 0.34203
Total Iteration Time: 5.30419

Cumulative Model Updates: 225,680
Cumulative Timesteps: 1,882,091,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1882091054...
Checkpoint 1882091054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.61083
Policy Entropy: 2.11586
Value Function Loss: 0.01803

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.63159

Collected Steps per Second: 20,587.61711
Overall Steps per Second: 9,492.37051

Timestep Collection Time: 2.42981
Timestep Consumption Time: 2.84011
PPO Batch Consumption Time: 0.34470
Total Iteration Time: 5.26992

Cumulative Model Updates: 225,686
Cumulative Timesteps: 1,882,141,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.99187
Policy Entropy: 2.11563
Value Function Loss: 0.01733

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.61282

Collected Steps per Second: 21,084.10362
Overall Steps per Second: 9,623.77545

Timestep Collection Time: 2.37250
Timestep Consumption Time: 2.82525
PPO Batch Consumption Time: 0.35097
Total Iteration Time: 5.19775

Cumulative Model Updates: 225,692
Cumulative Timesteps: 1,882,191,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1882191100...
Checkpoint 1882191100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.94150
Policy Entropy: 2.12109
Value Function Loss: 0.01711

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.61127

Collected Steps per Second: 19,097.32739
Overall Steps per Second: 9,189.21295

Timestep Collection Time: 2.61974
Timestep Consumption Time: 2.82469
PPO Batch Consumption Time: 0.34035
Total Iteration Time: 5.44443

Cumulative Model Updates: 225,698
Cumulative Timesteps: 1,882,241,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.56226
Policy Entropy: 2.10196
Value Function Loss: 0.01680

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.61232

Collected Steps per Second: 20,173.37681
Overall Steps per Second: 9,279.04861

Timestep Collection Time: 2.47911
Timestep Consumption Time: 2.91067
PPO Batch Consumption Time: 0.35725
Total Iteration Time: 5.38978

Cumulative Model Updates: 225,704
Cumulative Timesteps: 1,882,291,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1882291142...
Checkpoint 1882291142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.05612
Policy Entropy: 2.08483
Value Function Loss: 0.01829

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 17,726.93092
Overall Steps per Second: 9,327.15518

Timestep Collection Time: 2.82203
Timestep Consumption Time: 2.54144
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 5.36348

Cumulative Model Updates: 225,710
Cumulative Timesteps: 1,882,341,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.26428
Policy Entropy: 2.08548
Value Function Loss: 0.01848

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.17443
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 19,904.06941
Overall Steps per Second: 9,077.39521

Timestep Collection Time: 2.51215
Timestep Consumption Time: 2.99626
PPO Batch Consumption Time: 0.35488
Total Iteration Time: 5.50841

Cumulative Model Updates: 225,716
Cumulative Timesteps: 1,882,391,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1882391170...
Checkpoint 1882391170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.09871
Policy Entropy: 2.08799
Value Function Loss: 0.01803

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.18887
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.60945

Collected Steps per Second: 15,513.84396
Overall Steps per Second: 7,691.04516

Timestep Collection Time: 3.22319
Timestep Consumption Time: 3.27840
PPO Batch Consumption Time: 0.43081
Total Iteration Time: 6.50159

Cumulative Model Updates: 225,722
Cumulative Timesteps: 1,882,441,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.10271
Policy Entropy: 2.10776
Value Function Loss: 0.01655

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.18217
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.60835

Collected Steps per Second: 15,746.19035
Overall Steps per Second: 7,152.56223

Timestep Collection Time: 3.17588
Timestep Consumption Time: 3.81574
PPO Batch Consumption Time: 0.50589
Total Iteration Time: 6.99162

Cumulative Model Updates: 225,728
Cumulative Timesteps: 1,882,491,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1882491182...
Checkpoint 1882491182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.43856
Policy Entropy: 2.11829
Value Function Loss: 0.01664

Mean KL Divergence: 0.02456
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.54924
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 16,121.30494
Overall Steps per Second: 7,675.42525

Timestep Collection Time: 3.10211
Timestep Consumption Time: 3.41349
PPO Batch Consumption Time: 0.43950
Total Iteration Time: 6.51560

Cumulative Model Updates: 225,734
Cumulative Timesteps: 1,882,541,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.62981
Policy Entropy: 2.12111
Value Function Loss: 0.01756

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.58157

Collected Steps per Second: 16,437.71366
Overall Steps per Second: 7,502.23745

Timestep Collection Time: 3.04288
Timestep Consumption Time: 3.62420
PPO Batch Consumption Time: 0.48335
Total Iteration Time: 6.66708

Cumulative Model Updates: 225,740
Cumulative Timesteps: 1,882,591,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1882591210...
Checkpoint 1882591210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.88588
Policy Entropy: 2.10262
Value Function Loss: 0.01842

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 15,258.26294
Overall Steps per Second: 7,287.00704

Timestep Collection Time: 3.27796
Timestep Consumption Time: 3.58576
PPO Batch Consumption Time: 0.48565
Total Iteration Time: 6.86372

Cumulative Model Updates: 225,746
Cumulative Timesteps: 1,882,641,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.90484
Policy Entropy: 2.06486
Value Function Loss: 0.01758

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.60692

Collected Steps per Second: 15,891.51962
Overall Steps per Second: 7,612.50919

Timestep Collection Time: 3.14797
Timestep Consumption Time: 3.42358
PPO Batch Consumption Time: 0.44155
Total Iteration Time: 6.57155

Cumulative Model Updates: 225,752
Cumulative Timesteps: 1,882,691,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1882691252...
Checkpoint 1882691252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.52673
Policy Entropy: 2.07555
Value Function Loss: 0.01664

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.59422

Collected Steps per Second: 16,552.48365
Overall Steps per Second: 7,736.41678

Timestep Collection Time: 3.02190
Timestep Consumption Time: 3.44362
PPO Batch Consumption Time: 0.44137
Total Iteration Time: 6.46553

Cumulative Model Updates: 225,758
Cumulative Timesteps: 1,882,741,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.44014
Policy Entropy: 2.08980
Value Function Loss: 0.01640

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.53932
Value Function Update Magnitude: 0.57666

Collected Steps per Second: 16,459.09235
Overall Steps per Second: 7,864.44949

Timestep Collection Time: 3.03796
Timestep Consumption Time: 3.32002
PPO Batch Consumption Time: 0.42972
Total Iteration Time: 6.35798

Cumulative Model Updates: 225,764
Cumulative Timesteps: 1,882,791,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1882791274...
Checkpoint 1882791274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.95982
Policy Entropy: 2.11112
Value Function Loss: 0.01700

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.58948

Collected Steps per Second: 16,096.35453
Overall Steps per Second: 7,679.10952

Timestep Collection Time: 3.10915
Timestep Consumption Time: 3.40801
PPO Batch Consumption Time: 0.45609
Total Iteration Time: 6.51716

Cumulative Model Updates: 225,770
Cumulative Timesteps: 1,882,841,320

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.38083
Policy Entropy: 2.11116
Value Function Loss: 0.01773

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 16,392.93334
Overall Steps per Second: 7,739.86635

Timestep Collection Time: 3.05156
Timestep Consumption Time: 3.41160
PPO Batch Consumption Time: 0.44432
Total Iteration Time: 6.46316

Cumulative Model Updates: 225,776
Cumulative Timesteps: 1,882,891,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1882891344...
Checkpoint 1882891344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.46671
Policy Entropy: 2.10618
Value Function Loss: 0.01761

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 17,319.00465
Overall Steps per Second: 7,870.38399

Timestep Collection Time: 2.88781
Timestep Consumption Time: 3.46690
PPO Batch Consumption Time: 0.44950
Total Iteration Time: 6.35471

Cumulative Model Updates: 225,782
Cumulative Timesteps: 1,882,941,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.94455
Policy Entropy: 2.10853
Value Function Loss: 0.01743

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.59078

Collected Steps per Second: 16,527.02222
Overall Steps per Second: 7,665.75670

Timestep Collection Time: 3.02547
Timestep Consumption Time: 3.49730
PPO Batch Consumption Time: 0.45673
Total Iteration Time: 6.52277

Cumulative Model Updates: 225,788
Cumulative Timesteps: 1,882,991,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1882991360...
Checkpoint 1882991360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.03364
Policy Entropy: 2.12807
Value Function Loss: 0.01773

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.61599

Collected Steps per Second: 15,375.42613
Overall Steps per Second: 7,696.18411

Timestep Collection Time: 3.25480
Timestep Consumption Time: 3.24764
PPO Batch Consumption Time: 0.41686
Total Iteration Time: 6.50244

Cumulative Model Updates: 225,794
Cumulative Timesteps: 1,883,041,404

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.24017
Policy Entropy: 2.12184
Value Function Loss: 0.01725

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.63740

Collected Steps per Second: 16,671.09160
Overall Steps per Second: 8,103.41719

Timestep Collection Time: 3.00004
Timestep Consumption Time: 3.17192
PPO Batch Consumption Time: 0.41734
Total Iteration Time: 6.17196

Cumulative Model Updates: 225,800
Cumulative Timesteps: 1,883,091,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1883091418...
Checkpoint 1883091418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.90459
Policy Entropy: 2.09855
Value Function Loss: 0.01712

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.64338

Collected Steps per Second: 16,009.36576
Overall Steps per Second: 7,477.14094

Timestep Collection Time: 3.12355
Timestep Consumption Time: 3.56430
PPO Batch Consumption Time: 0.46617
Total Iteration Time: 6.68785

Cumulative Model Updates: 225,806
Cumulative Timesteps: 1,883,141,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.30926
Policy Entropy: 2.07415
Value Function Loss: 0.01649

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 15,659.04444
Overall Steps per Second: 7,276.75325

Timestep Collection Time: 3.19624
Timestep Consumption Time: 3.68183
PPO Batch Consumption Time: 0.48296
Total Iteration Time: 6.87807

Cumulative Model Updates: 225,812
Cumulative Timesteps: 1,883,191,474

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1883191474...
Checkpoint 1883191474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.59682
Policy Entropy: 2.06426
Value Function Loss: 0.01683

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.62084

Collected Steps per Second: 15,433.78764
Overall Steps per Second: 7,610.00760

Timestep Collection Time: 3.24107
Timestep Consumption Time: 3.33212
PPO Batch Consumption Time: 0.43573
Total Iteration Time: 6.57319

Cumulative Model Updates: 225,818
Cumulative Timesteps: 1,883,241,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.01740
Policy Entropy: 2.07926
Value Function Loss: 0.01687

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.62411

Collected Steps per Second: 16,381.18121
Overall Steps per Second: 7,788.81299

Timestep Collection Time: 3.05289
Timestep Consumption Time: 3.36785
PPO Batch Consumption Time: 0.43736
Total Iteration Time: 6.42075

Cumulative Model Updates: 225,824
Cumulative Timesteps: 1,883,291,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1883291506...
Checkpoint 1883291506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.22073
Policy Entropy: 2.09906
Value Function Loss: 0.01697

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.62561

Collected Steps per Second: 17,000.46554
Overall Steps per Second: 7,871.45062

Timestep Collection Time: 2.94263
Timestep Consumption Time: 3.41275
PPO Batch Consumption Time: 0.44131
Total Iteration Time: 6.35537

Cumulative Model Updates: 225,830
Cumulative Timesteps: 1,883,341,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.55886
Policy Entropy: 2.10574
Value Function Loss: 0.01611

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.59758

Collected Steps per Second: 16,202.27666
Overall Steps per Second: 7,759.60928

Timestep Collection Time: 3.08734
Timestep Consumption Time: 3.35911
PPO Batch Consumption Time: 0.43311
Total Iteration Time: 6.44646

Cumulative Model Updates: 225,836
Cumulative Timesteps: 1,883,391,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1883391554...
Checkpoint 1883391554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.80730
Policy Entropy: 2.09840
Value Function Loss: 0.01667

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.57018

Collected Steps per Second: 16,119.00610
Overall Steps per Second: 7,585.27248

Timestep Collection Time: 3.10478
Timestep Consumption Time: 3.49300
PPO Batch Consumption Time: 0.45663
Total Iteration Time: 6.59779

Cumulative Model Updates: 225,842
Cumulative Timesteps: 1,883,441,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.20776
Policy Entropy: 2.08452
Value Function Loss: 0.01614

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.53671
Value Function Update Magnitude: 0.56241

Collected Steps per Second: 15,453.79968
Overall Steps per Second: 7,458.13987

Timestep Collection Time: 3.23726
Timestep Consumption Time: 3.47058
PPO Batch Consumption Time: 0.45414
Total Iteration Time: 6.70784

Cumulative Model Updates: 225,848
Cumulative Timesteps: 1,883,491,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1883491628...
Checkpoint 1883491628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.41813
Policy Entropy: 2.10123
Value Function Loss: 0.01706

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 15,682.56153
Overall Steps per Second: 7,348.38167

Timestep Collection Time: 3.18966
Timestep Consumption Time: 3.61756
PPO Batch Consumption Time: 0.48867
Total Iteration Time: 6.80721

Cumulative Model Updates: 225,854
Cumulative Timesteps: 1,883,541,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.33606
Policy Entropy: 2.11708
Value Function Loss: 0.01633

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.59479

Collected Steps per Second: 16,032.65933
Overall Steps per Second: 7,688.06078

Timestep Collection Time: 3.11913
Timestep Consumption Time: 3.38550
PPO Batch Consumption Time: 0.43628
Total Iteration Time: 6.50463

Cumulative Model Updates: 225,860
Cumulative Timesteps: 1,883,591,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1883591658...
Checkpoint 1883591658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.12805
Policy Entropy: 2.12507
Value Function Loss: 0.01593

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.52093
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 16,001.02814
Overall Steps per Second: 7,334.69289

Timestep Collection Time: 3.12642
Timestep Consumption Time: 3.69404
PPO Batch Consumption Time: 0.48793
Total Iteration Time: 6.82046

Cumulative Model Updates: 225,866
Cumulative Timesteps: 1,883,641,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.77430
Policy Entropy: 2.14284
Value Function Loss: 0.01490

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.51496
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 15,604.40657
Overall Steps per Second: 7,213.96166

Timestep Collection Time: 3.20422
Timestep Consumption Time: 3.72678
PPO Batch Consumption Time: 0.49475
Total Iteration Time: 6.93100

Cumulative Model Updates: 225,872
Cumulative Timesteps: 1,883,691,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1883691684...
Checkpoint 1883691684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.73063
Policy Entropy: 2.14364
Value Function Loss: 0.01543

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.51501
Value Function Update Magnitude: 0.56065

Collected Steps per Second: 15,783.22677
Overall Steps per Second: 7,649.87240

Timestep Collection Time: 3.16931
Timestep Consumption Time: 3.36962
PPO Batch Consumption Time: 0.43971
Total Iteration Time: 6.53893

Cumulative Model Updates: 225,878
Cumulative Timesteps: 1,883,741,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.45549
Policy Entropy: 2.15188
Value Function Loss: 0.01569

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.55708

Collected Steps per Second: 16,871.93513
Overall Steps per Second: 8,011.66524

Timestep Collection Time: 2.96350
Timestep Consumption Time: 3.27740
PPO Batch Consumption Time: 0.43262
Total Iteration Time: 6.24090

Cumulative Model Updates: 225,884
Cumulative Timesteps: 1,883,791,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1883791706...
Checkpoint 1883791706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.89125
Policy Entropy: 2.11760
Value Function Loss: 0.01659

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.55309

Collected Steps per Second: 16,757.51753
Overall Steps per Second: 7,808.89328

Timestep Collection Time: 2.98445
Timestep Consumption Time: 3.42004
PPO Batch Consumption Time: 0.44357
Total Iteration Time: 6.40449

Cumulative Model Updates: 225,890
Cumulative Timesteps: 1,883,841,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.74684
Policy Entropy: 2.14932
Value Function Loss: 0.01663

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.56314

Collected Steps per Second: 16,834.27682
Overall Steps per Second: 7,819.89489

Timestep Collection Time: 2.97108
Timestep Consumption Time: 3.42491
PPO Batch Consumption Time: 0.43997
Total Iteration Time: 6.39599

Cumulative Model Updates: 225,896
Cumulative Timesteps: 1,883,891,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1883891734...
Checkpoint 1883891734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.72210
Policy Entropy: 2.16731
Value Function Loss: 0.01658

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.55243

Collected Steps per Second: 15,857.51234
Overall Steps per Second: 7,591.20616

Timestep Collection Time: 3.15371
Timestep Consumption Time: 3.43418
PPO Batch Consumption Time: 0.44993
Total Iteration Time: 6.58789

Cumulative Model Updates: 225,902
Cumulative Timesteps: 1,883,941,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.47139
Policy Entropy: 2.16743
Value Function Loss: 0.01723

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.54999

Collected Steps per Second: 16,209.07417
Overall Steps per Second: 7,503.17184

Timestep Collection Time: 3.08482
Timestep Consumption Time: 3.57930
PPO Batch Consumption Time: 0.46781
Total Iteration Time: 6.66411

Cumulative Model Updates: 225,908
Cumulative Timesteps: 1,883,991,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1883991746...
Checkpoint 1883991746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.46998
Policy Entropy: 2.14878
Value Function Loss: 0.01708

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.17991
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.56734

Collected Steps per Second: 16,476.96670
Overall Steps per Second: 7,459.91126

Timestep Collection Time: 3.03466
Timestep Consumption Time: 3.66810
PPO Batch Consumption Time: 0.48401
Total Iteration Time: 6.70276

Cumulative Model Updates: 225,914
Cumulative Timesteps: 1,884,041,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.97695
Policy Entropy: 2.13597
Value Function Loss: 0.01691

Mean KL Divergence: 0.02885
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.57465

Collected Steps per Second: 15,701.94340
Overall Steps per Second: 7,524.06741

Timestep Collection Time: 3.18483
Timestep Consumption Time: 3.46158
PPO Batch Consumption Time: 0.44865
Total Iteration Time: 6.64641

Cumulative Model Updates: 225,920
Cumulative Timesteps: 1,884,091,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1884091756...
Checkpoint 1884091756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.32388
Policy Entropy: 2.14719
Value Function Loss: 0.01639

Mean KL Divergence: 0.02594
SB3 Clip Fraction: 0.15507
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.55574

Collected Steps per Second: 15,130.65303
Overall Steps per Second: 7,127.93189

Timestep Collection Time: 3.30627
Timestep Consumption Time: 3.71204
PPO Batch Consumption Time: 0.49263
Total Iteration Time: 7.01830

Cumulative Model Updates: 225,926
Cumulative Timesteps: 1,884,141,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.43554
Policy Entropy: 2.13897
Value Function Loss: 0.01729

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.56222

Collected Steps per Second: 15,583.46517
Overall Steps per Second: 7,300.60059

Timestep Collection Time: 3.21007
Timestep Consumption Time: 3.64197
PPO Batch Consumption Time: 0.49313
Total Iteration Time: 6.85204

Cumulative Model Updates: 225,932
Cumulative Timesteps: 1,884,191,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1884191806...
Checkpoint 1884191806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.59832
Policy Entropy: 2.14505
Value Function Loss: 0.01723

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.60464

Collected Steps per Second: 16,321.13326
Overall Steps per Second: 7,734.60357

Timestep Collection Time: 3.06364
Timestep Consumption Time: 3.40108
PPO Batch Consumption Time: 0.44226
Total Iteration Time: 6.46471

Cumulative Model Updates: 225,938
Cumulative Timesteps: 1,884,241,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.23515
Policy Entropy: 2.16256
Value Function Loss: 0.01657

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.63707

Collected Steps per Second: 16,157.86444
Overall Steps per Second: 7,652.89256

Timestep Collection Time: 3.09472
Timestep Consumption Time: 3.43928
PPO Batch Consumption Time: 0.43944
Total Iteration Time: 6.53400

Cumulative Model Updates: 225,944
Cumulative Timesteps: 1,884,291,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1884291812...
Checkpoint 1884291812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.87562
Policy Entropy: 2.19901
Value Function Loss: 0.01563

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.64055

Collected Steps per Second: 15,566.16876
Overall Steps per Second: 7,412.72942

Timestep Collection Time: 3.21428
Timestep Consumption Time: 3.53546
PPO Batch Consumption Time: 0.46481
Total Iteration Time: 6.74974

Cumulative Model Updates: 225,950
Cumulative Timesteps: 1,884,341,846

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.74385
Policy Entropy: 2.20392
Value Function Loss: 0.01622

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 16,462.68808
Overall Steps per Second: 7,945.91769

Timestep Collection Time: 3.03875
Timestep Consumption Time: 3.25706
PPO Batch Consumption Time: 0.43121
Total Iteration Time: 6.29581

Cumulative Model Updates: 225,956
Cumulative Timesteps: 1,884,391,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1884391872...
Checkpoint 1884391872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.34241
Policy Entropy: 2.19036
Value Function Loss: 0.01698

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 16,612.98513
Overall Steps per Second: 7,823.02147

Timestep Collection Time: 3.00969
Timestep Consumption Time: 3.38170
PPO Batch Consumption Time: 0.43886
Total Iteration Time: 6.39139

Cumulative Model Updates: 225,962
Cumulative Timesteps: 1,884,441,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.95808
Policy Entropy: 2.16796
Value Function Loss: 0.01723

Mean KL Divergence: 0.02142
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.52224
Value Function Update Magnitude: 0.57171

Collected Steps per Second: 16,341.62984
Overall Steps per Second: 7,606.25429

Timestep Collection Time: 3.06089
Timestep Consumption Time: 3.51527
PPO Batch Consumption Time: 0.45900
Total Iteration Time: 6.57617

Cumulative Model Updates: 225,968
Cumulative Timesteps: 1,884,491,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1884491892...
Checkpoint 1884491892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.67447
Policy Entropy: 2.16110
Value Function Loss: 0.01716

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.51960
Value Function Update Magnitude: 0.56821

Collected Steps per Second: 16,568.40291
Overall Steps per Second: 7,876.59075

Timestep Collection Time: 3.01803
Timestep Consumption Time: 3.33040
PPO Batch Consumption Time: 0.43428
Total Iteration Time: 6.34843

Cumulative Model Updates: 225,974
Cumulative Timesteps: 1,884,541,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.61850
Policy Entropy: 2.15271
Value Function Loss: 0.01638

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.52645
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 15,849.88412
Overall Steps per Second: 7,240.29191

Timestep Collection Time: 3.15535
Timestep Consumption Time: 3.75210
PPO Batch Consumption Time: 0.50952
Total Iteration Time: 6.90746

Cumulative Model Updates: 225,980
Cumulative Timesteps: 1,884,591,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1884591908...
Checkpoint 1884591908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.94028
Policy Entropy: 2.13722
Value Function Loss: 0.01712

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 15,505.70348
Overall Steps per Second: 7,499.45888

Timestep Collection Time: 3.22462
Timestep Consumption Time: 3.44253
PPO Batch Consumption Time: 0.44546
Total Iteration Time: 6.66715

Cumulative Model Updates: 225,986
Cumulative Timesteps: 1,884,641,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.39237
Policy Entropy: 2.12139
Value Function Loss: 0.01743

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.58896

Collected Steps per Second: 16,629.89575
Overall Steps per Second: 7,843.50439

Timestep Collection Time: 3.00663
Timestep Consumption Time: 3.36807
PPO Batch Consumption Time: 0.43176
Total Iteration Time: 6.37470

Cumulative Model Updates: 225,992
Cumulative Timesteps: 1,884,691,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1884691908...
Checkpoint 1884691908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.18188
Policy Entropy: 2.11228
Value Function Loss: 0.01635

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.57850

Collected Steps per Second: 16,204.81171
Overall Steps per Second: 7,676.25395

Timestep Collection Time: 3.08612
Timestep Consumption Time: 3.42878
PPO Batch Consumption Time: 0.44794
Total Iteration Time: 6.51490

Cumulative Model Updates: 225,998
Cumulative Timesteps: 1,884,741,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.95124
Policy Entropy: 2.10094
Value Function Loss: 0.01613

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.15808
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 15,938.23055
Overall Steps per Second: 7,790.36387

Timestep Collection Time: 3.13874
Timestep Consumption Time: 3.28278
PPO Batch Consumption Time: 0.43058
Total Iteration Time: 6.42152

Cumulative Model Updates: 226,004
Cumulative Timesteps: 1,884,791,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1884791944...
Checkpoint 1884791944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.94874
Policy Entropy: 2.10314
Value Function Loss: 0.01543

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.17527
Policy Update Magnitude: 0.52846
Value Function Update Magnitude: 0.57650

Collected Steps per Second: 15,851.69244
Overall Steps per Second: 8,272.48372

Timestep Collection Time: 3.15600
Timestep Consumption Time: 2.89151
PPO Batch Consumption Time: 0.33317
Total Iteration Time: 6.04752

Cumulative Model Updates: 226,010
Cumulative Timesteps: 1,884,841,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.92859
Policy Entropy: 2.11052
Value Function Loss: 0.01632

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.16837
Policy Update Magnitude: 0.52514
Value Function Update Magnitude: 0.57163

Collected Steps per Second: 19,627.90012
Overall Steps per Second: 9,289.33522

Timestep Collection Time: 2.54872
Timestep Consumption Time: 2.83660
PPO Batch Consumption Time: 0.31778
Total Iteration Time: 5.38532

Cumulative Model Updates: 226,016
Cumulative Timesteps: 1,884,891,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1884891998...
Checkpoint 1884891998 saved!
