Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.45895
Policy Entropy: 1.00260
Value Function Loss: 2.48772

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 15,391.43044
Overall Steps per Second: 11,680.63397

Timestep Collection Time: 3.24869
Timestep Consumption Time: 1.03207
PPO Batch Consumption Time: 0.16631
Total Iteration Time: 4.28076

Cumulative Model Updates: 2,164
Cumulative Timesteps: 18,156,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.05423
Policy Entropy: 1.00717
Value Function Loss: 1.78715

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.08853

Collected Steps per Second: 17,000.17896
Overall Steps per Second: 12,928.27095

Timestep Collection Time: 2.94138
Timestep Consumption Time: 0.92642
PPO Batch Consumption Time: 0.13427
Total Iteration Time: 3.86780

Cumulative Model Updates: 2,166
Cumulative Timesteps: 18,206,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18206630...
Checkpoint 18206630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.56841
Policy Entropy: 1.01612
Value Function Loss: 1.96612

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05602
Policy Update Magnitude: 0.10024
Value Function Update Magnitude: 0.13754

Collected Steps per Second: 17,503.09413
Overall Steps per Second: 12,543.40724

Timestep Collection Time: 2.85824
Timestep Consumption Time: 1.13015
PPO Batch Consumption Time: 0.11498
Total Iteration Time: 3.98839

Cumulative Model Updates: 2,170
Cumulative Timesteps: 18,256,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.28028
Policy Entropy: 1.00513
Value Function Loss: 1.96906

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.11814
Value Function Update Magnitude: 0.17055

Collected Steps per Second: 16,902.97141
Overall Steps per Second: 11,524.61714

Timestep Collection Time: 2.95972
Timestep Consumption Time: 1.38125
PPO Batch Consumption Time: 0.11285
Total Iteration Time: 4.34097

Cumulative Model Updates: 2,176
Cumulative Timesteps: 18,306,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 18306686...
Checkpoint 18306686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.27881
Policy Entropy: 1.01103
Value Function Loss: 2.05329

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.11718
Value Function Update Magnitude: 0.17675

Collected Steps per Second: 16,997.22623
Overall Steps per Second: 11,844.67734

Timestep Collection Time: 2.94354
Timestep Consumption Time: 1.28047
PPO Batch Consumption Time: 0.11332
Total Iteration Time: 4.22401

Cumulative Model Updates: 2,182
Cumulative Timesteps: 18,356,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.46170
Policy Entropy: 1.00749
Value Function Loss: 2.00114

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.11548
Value Function Update Magnitude: 0.20998

Collected Steps per Second: 17,014.11211
Overall Steps per Second: 11,402.44253

Timestep Collection Time: 2.93979
Timestep Consumption Time: 1.44681
PPO Batch Consumption Time: 0.11700
Total Iteration Time: 4.38660

Cumulative Model Updates: 2,188
Cumulative Timesteps: 18,406,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 18406736...
Checkpoint 18406736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.52085
Policy Entropy: 0.96987
Value Function Loss: 2.08616

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.10329
Value Function Update Magnitude: 0.22413

Collected Steps per Second: 16,737.54212
Overall Steps per Second: 11,521.11262

Timestep Collection Time: 2.98789
Timestep Consumption Time: 1.35283
PPO Batch Consumption Time: 0.11472
Total Iteration Time: 4.34073

Cumulative Model Updates: 2,194
Cumulative Timesteps: 18,456,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.28391
Policy Entropy: 0.98710
Value Function Loss: 2.17827

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.09531
Value Function Update Magnitude: 0.25542

Collected Steps per Second: 17,830.63526
Overall Steps per Second: 11,958.58753

Timestep Collection Time: 2.80674
Timestep Consumption Time: 1.37820
PPO Batch Consumption Time: 0.11033
Total Iteration Time: 4.18494

Cumulative Model Updates: 2,200
Cumulative Timesteps: 18,506,792

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 18506792...
Checkpoint 18506792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.35411
Policy Entropy: 0.98407
Value Function Loss: 2.21081

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.10715
Value Function Update Magnitude: 0.25657

Collected Steps per Second: 17,247.58482
Overall Steps per Second: 11,810.11182

Timestep Collection Time: 2.89954
Timestep Consumption Time: 1.33497
PPO Batch Consumption Time: 0.10955
Total Iteration Time: 4.23451

Cumulative Model Updates: 2,206
Cumulative Timesteps: 18,556,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.19060
Policy Entropy: 0.98216
Value Function Loss: 2.21981

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.11500
Value Function Update Magnitude: 0.23571

Collected Steps per Second: 17,003.71437
Overall Steps per Second: 11,678.26497

Timestep Collection Time: 2.94171
Timestep Consumption Time: 1.34146
PPO Batch Consumption Time: 0.11565
Total Iteration Time: 4.28317

Cumulative Model Updates: 2,212
Cumulative Timesteps: 18,606,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18606822...
Checkpoint 18606822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.57360
Policy Entropy: 0.99590
Value Function Loss: 2.17379

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.10239
Value Function Update Magnitude: 0.25880

Collected Steps per Second: 14,524.59089
Overall Steps per Second: 10,407.61423

Timestep Collection Time: 3.44533
Timestep Consumption Time: 1.36288
PPO Batch Consumption Time: 0.11144
Total Iteration Time: 4.80821

Cumulative Model Updates: 2,218
Cumulative Timesteps: 18,656,864

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.12174
Policy Entropy: 1.00248
Value Function Loss: 2.30192

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.09919
Value Function Update Magnitude: 0.27196

Collected Steps per Second: 16,977.66582
Overall Steps per Second: 11,618.81899

Timestep Collection Time: 2.94516
Timestep Consumption Time: 1.35837
PPO Batch Consumption Time: 0.11462
Total Iteration Time: 4.30354

Cumulative Model Updates: 2,224
Cumulative Timesteps: 18,706,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 18706866...
Checkpoint 18706866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.19332
Policy Entropy: 1.00440
Value Function Loss: 2.41138

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.09454
Value Function Update Magnitude: 0.22047

Collected Steps per Second: 17,358.31403
Overall Steps per Second: 11,803.31418

Timestep Collection Time: 2.88185
Timestep Consumption Time: 1.35628
PPO Batch Consumption Time: 0.11317
Total Iteration Time: 4.23813

Cumulative Model Updates: 2,230
Cumulative Timesteps: 18,756,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.98512
Policy Entropy: 0.99621
Value Function Loss: 2.35019

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.10190
Value Function Update Magnitude: 0.24057

Collected Steps per Second: 17,175.43560
Overall Steps per Second: 11,599.54658

Timestep Collection Time: 2.91160
Timestep Consumption Time: 1.39960
PPO Batch Consumption Time: 0.11465
Total Iteration Time: 4.31120

Cumulative Model Updates: 2,236
Cumulative Timesteps: 18,806,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18806898...
Checkpoint 18806898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.23797
Policy Entropy: 0.98285
Value Function Loss: 2.30932

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.10428
Value Function Update Magnitude: 0.24297

Collected Steps per Second: 17,087.96603
Overall Steps per Second: 11,817.33736

Timestep Collection Time: 2.92779
Timestep Consumption Time: 1.30582
PPO Batch Consumption Time: 0.11658
Total Iteration Time: 4.23361

Cumulative Model Updates: 2,242
Cumulative Timesteps: 18,856,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.25463
Policy Entropy: 0.99540
Value Function Loss: 2.35240

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.25800

Collected Steps per Second: 17,181.93104
Overall Steps per Second: 11,752.71181

Timestep Collection Time: 2.91038
Timestep Consumption Time: 1.34446
PPO Batch Consumption Time: 0.10878
Total Iteration Time: 4.25485

Cumulative Model Updates: 2,248
Cumulative Timesteps: 18,906,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 18906934...
Checkpoint 18906934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.41024
Policy Entropy: 0.97815
Value Function Loss: 2.46042

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05693
Policy Update Magnitude: 0.11692
Value Function Update Magnitude: 0.24520

Collected Steps per Second: 16,939.41441
Overall Steps per Second: 11,585.16903

Timestep Collection Time: 2.95205
Timestep Consumption Time: 1.36433
PPO Batch Consumption Time: 0.11775
Total Iteration Time: 4.31638

Cumulative Model Updates: 2,254
Cumulative Timesteps: 18,956,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.94468
Policy Entropy: 0.98201
Value Function Loss: 2.48961

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05279
Policy Update Magnitude: 0.11179
Value Function Update Magnitude: 0.23893

Collected Steps per Second: 16,804.92704
Overall Steps per Second: 11,380.44129

Timestep Collection Time: 2.97639
Timestep Consumption Time: 1.41870
PPO Batch Consumption Time: 0.11536
Total Iteration Time: 4.39508

Cumulative Model Updates: 2,260
Cumulative Timesteps: 19,006,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 19006958...
Checkpoint 19006958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.66238
Policy Entropy: 0.98517
Value Function Loss: 2.43906

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05449
Policy Update Magnitude: 0.10756
Value Function Update Magnitude: 0.20060

Collected Steps per Second: 17,051.98128
Overall Steps per Second: 11,586.92519

Timestep Collection Time: 2.93409
Timestep Consumption Time: 1.38388
PPO Batch Consumption Time: 0.11591
Total Iteration Time: 4.31797

Cumulative Model Updates: 2,266
Cumulative Timesteps: 19,056,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.54824
Policy Entropy: 0.98536
Value Function Loss: 2.35829

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.11283
Value Function Update Magnitude: 0.18681

Collected Steps per Second: 16,773.33815
Overall Steps per Second: 11,641.33326

Timestep Collection Time: 2.98176
Timestep Consumption Time: 1.31449
PPO Batch Consumption Time: 0.11152
Total Iteration Time: 4.29624

Cumulative Model Updates: 2,272
Cumulative Timesteps: 19,107,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19107004...
Checkpoint 19107004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.09142
Policy Entropy: 0.98588
Value Function Loss: 2.39193

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.10588
Value Function Update Magnitude: 0.15765

Collected Steps per Second: 17,254.81346
Overall Steps per Second: 11,688.29794

Timestep Collection Time: 2.89971
Timestep Consumption Time: 1.38098
PPO Batch Consumption Time: 0.11504
Total Iteration Time: 4.28069

Cumulative Model Updates: 2,278
Cumulative Timesteps: 19,157,038

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.23296
Policy Entropy: 1.00295
Value Function Loss: 2.42943

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.07750
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 17,158.45454
Overall Steps per Second: 11,747.15532

Timestep Collection Time: 2.91506
Timestep Consumption Time: 1.34282
PPO Batch Consumption Time: 0.11122
Total Iteration Time: 4.25788

Cumulative Model Updates: 2,284
Cumulative Timesteps: 19,207,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 19207056...
Checkpoint 19207056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.79682
Policy Entropy: 0.98733
Value Function Loss: 2.51776

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04622
Policy Update Magnitude: 0.10218
Value Function Update Magnitude: 0.10842

Collected Steps per Second: 17,402.45948
Overall Steps per Second: 11,728.59313

Timestep Collection Time: 2.87316
Timestep Consumption Time: 1.38993
PPO Batch Consumption Time: 0.11503
Total Iteration Time: 4.26309

Cumulative Model Updates: 2,290
Cumulative Timesteps: 19,257,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.73973
Policy Entropy: 0.99060
Value Function Loss: 2.52697

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04793
Policy Update Magnitude: 0.11411
Value Function Update Magnitude: 0.10566

Collected Steps per Second: 17,149.93925
Overall Steps per Second: 11,727.68819

Timestep Collection Time: 2.91721
Timestep Consumption Time: 1.34876
PPO Batch Consumption Time: 0.11099
Total Iteration Time: 4.26597

Cumulative Model Updates: 2,296
Cumulative Timesteps: 19,307,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 19307086...
Checkpoint 19307086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.71248
Policy Entropy: 0.98339
Value Function Loss: 2.60503

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.11417
Value Function Update Magnitude: 0.10061

Collected Steps per Second: 16,612.27602
Overall Steps per Second: 11,586.37091

Timestep Collection Time: 3.01271
Timestep Consumption Time: 1.30685
PPO Batch Consumption Time: 0.11465
Total Iteration Time: 4.31956

Cumulative Model Updates: 2,302
Cumulative Timesteps: 19,357,134

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.50209
Policy Entropy: 0.98706
Value Function Loss: 2.48812

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06298
Policy Update Magnitude: 0.10318
Value Function Update Magnitude: 0.09394

Collected Steps per Second: 17,258.57272
Overall Steps per Second: 11,759.78127

Timestep Collection Time: 2.89897
Timestep Consumption Time: 1.35554
PPO Batch Consumption Time: 0.11118
Total Iteration Time: 4.25450

Cumulative Model Updates: 2,308
Cumulative Timesteps: 19,407,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 19407166...
Checkpoint 19407166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.41076
Policy Entropy: 0.99269
Value Function Loss: 2.58875

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05502
Policy Update Magnitude: 0.10644
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 16,923.21528
Overall Steps per Second: 11,590.38862

Timestep Collection Time: 2.95452
Timestep Consumption Time: 1.35940
PPO Batch Consumption Time: 0.11333
Total Iteration Time: 4.31392

Cumulative Model Updates: 2,314
Cumulative Timesteps: 19,457,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.81709
Policy Entropy: 0.98947
Value Function Loss: 2.56965

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.11509
Value Function Update Magnitude: 0.08125

Collected Steps per Second: 17,513.58675
Overall Steps per Second: 11,861.22298

Timestep Collection Time: 2.85618
Timestep Consumption Time: 1.36109
PPO Batch Consumption Time: 0.11099
Total Iteration Time: 4.21727

Cumulative Model Updates: 2,320
Cumulative Timesteps: 19,507,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 19507188...
Checkpoint 19507188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.55764
Policy Entropy: 0.98197
Value Function Loss: 2.63832

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.10373
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 16,809.76818
Overall Steps per Second: 11,502.18198

Timestep Collection Time: 2.97506
Timestep Consumption Time: 1.37281
PPO Batch Consumption Time: 0.11272
Total Iteration Time: 4.34787

Cumulative Model Updates: 2,326
Cumulative Timesteps: 19,557,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.30340
Policy Entropy: 0.97870
Value Function Loss: 2.61105

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04816
Policy Update Magnitude: 0.09412
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 16,613.28162
Overall Steps per Second: 11,676.83435

Timestep Collection Time: 3.01121
Timestep Consumption Time: 1.27300
PPO Batch Consumption Time: 0.11260
Total Iteration Time: 4.28421

Cumulative Model Updates: 2,332
Cumulative Timesteps: 19,607,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19607224...
Checkpoint 19607224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.85592
Policy Entropy: 1.00576
Value Function Loss: 2.49387

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05130
Policy Update Magnitude: 0.13095
Value Function Update Magnitude: 0.09346

Collected Steps per Second: 17,114.62049
Overall Steps per Second: 11,640.99291

Timestep Collection Time: 2.92218
Timestep Consumption Time: 1.37402
PPO Batch Consumption Time: 0.11190
Total Iteration Time: 4.29620

Cumulative Model Updates: 2,338
Cumulative Timesteps: 19,657,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.27707
Policy Entropy: 1.04026
Value Function Loss: 2.47336

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06285
Policy Update Magnitude: 0.11096
Value Function Update Magnitude: 0.08600

Collected Steps per Second: 16,947.26739
Overall Steps per Second: 11,690.25964

Timestep Collection Time: 2.95080
Timestep Consumption Time: 1.32695
PPO Batch Consumption Time: 0.11068
Total Iteration Time: 4.27775

Cumulative Model Updates: 2,344
Cumulative Timesteps: 19,707,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 19707244...
Checkpoint 19707244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.84030
Policy Entropy: 1.01178
Value Function Loss: 2.51569

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05160
Policy Update Magnitude: 0.09608
Value Function Update Magnitude: 0.08335

Collected Steps per Second: 16,965.54439
Overall Steps per Second: 11,831.33823

Timestep Collection Time: 2.94762
Timestep Consumption Time: 1.27912
PPO Batch Consumption Time: 0.11282
Total Iteration Time: 4.22674

Cumulative Model Updates: 2,350
Cumulative Timesteps: 19,757,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.85012
Policy Entropy: 1.02681
Value Function Loss: 2.64790

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.06291
Policy Update Magnitude: 0.09248
Value Function Update Magnitude: 0.08630

Collected Steps per Second: 17,088.18491
Overall Steps per Second: 11,639.52918

Timestep Collection Time: 2.92600
Timestep Consumption Time: 1.36971
PPO Batch Consumption Time: 0.11361
Total Iteration Time: 4.29571

Cumulative Model Updates: 2,356
Cumulative Timesteps: 19,807,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 19807252...
Checkpoint 19807252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.96404
Policy Entropy: 1.01840
Value Function Loss: 2.70503

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.10032
Value Function Update Magnitude: 0.08809

Collected Steps per Second: 16,955.95725
Overall Steps per Second: 11,695.71530

Timestep Collection Time: 2.95035
Timestep Consumption Time: 1.32694
PPO Batch Consumption Time: 0.11293
Total Iteration Time: 4.27729

Cumulative Model Updates: 2,362
Cumulative Timesteps: 19,857,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.45028
Policy Entropy: 1.02642
Value Function Loss: 2.57568

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05140
Policy Update Magnitude: 0.14169
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 17,780.36062
Overall Steps per Second: 11,867.53262

Timestep Collection Time: 2.81378
Timestep Consumption Time: 1.40192
PPO Batch Consumption Time: 0.11395
Total Iteration Time: 4.21570

Cumulative Model Updates: 2,368
Cumulative Timesteps: 19,907,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 19907308...
Checkpoint 19907308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.49783
Policy Entropy: 1.01040
Value Function Loss: 2.49128

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.11963
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 17,013.15426
Overall Steps per Second: 11,632.93397

Timestep Collection Time: 2.93973
Timestep Consumption Time: 1.35962
PPO Batch Consumption Time: 0.11571
Total Iteration Time: 4.29935

Cumulative Model Updates: 2,374
Cumulative Timesteps: 19,957,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.76197
Policy Entropy: 1.04497
Value Function Loss: 2.44233

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.11720
Value Function Update Magnitude: 0.08553

Collected Steps per Second: 17,354.77142
Overall Steps per Second: 12,048.16926

Timestep Collection Time: 2.88197
Timestep Consumption Time: 1.26936
PPO Batch Consumption Time: 0.11401
Total Iteration Time: 4.15134

Cumulative Model Updates: 2,380
Cumulative Timesteps: 20,007,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20007338...
Checkpoint 20007338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.58834
Policy Entropy: 1.03536
Value Function Loss: 2.45064

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.12448
Value Function Update Magnitude: 0.08614

Collected Steps per Second: 16,667.23535
Overall Steps per Second: 11,431.44996

Timestep Collection Time: 3.00110
Timestep Consumption Time: 1.37455
PPO Batch Consumption Time: 0.11382
Total Iteration Time: 4.37565

Cumulative Model Updates: 2,386
Cumulative Timesteps: 20,057,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.32394
Policy Entropy: 1.02637
Value Function Loss: 2.42430

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04895
Policy Update Magnitude: 0.12858
Value Function Update Magnitude: 0.08398

Collected Steps per Second: 16,926.77319
Overall Steps per Second: 11,663.00837

Timestep Collection Time: 2.95437
Timestep Consumption Time: 1.33337
PPO Batch Consumption Time: 0.11136
Total Iteration Time: 4.28774

Cumulative Model Updates: 2,392
Cumulative Timesteps: 20,107,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20107366...
Checkpoint 20107366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.20853
Policy Entropy: 1.02251
Value Function Loss: 2.43955

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04544
Policy Update Magnitude: 0.14954
Value Function Update Magnitude: 0.08757

Collected Steps per Second: 17,270.21193
Overall Steps per Second: 11,583.70477

Timestep Collection Time: 2.89608
Timestep Consumption Time: 1.42170
PPO Batch Consumption Time: 0.11467
Total Iteration Time: 4.31779

Cumulative Model Updates: 2,398
Cumulative Timesteps: 20,157,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.67869
Policy Entropy: 1.01218
Value Function Loss: 2.50425

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05190
Policy Update Magnitude: 0.14029
Value Function Update Magnitude: 0.08899

Collected Steps per Second: 17,245.52478
Overall Steps per Second: 11,659.13013

Timestep Collection Time: 2.89930
Timestep Consumption Time: 1.38918
PPO Batch Consumption Time: 0.11618
Total Iteration Time: 4.28848

Cumulative Model Updates: 2,404
Cumulative Timesteps: 20,207,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20207382...
Checkpoint 20207382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.43923
Policy Entropy: 1.02018
Value Function Loss: 2.58511

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.12742
Value Function Update Magnitude: 0.08897

Collected Steps per Second: 17,079.38780
Overall Steps per Second: 11,847.41328

Timestep Collection Time: 2.92809
Timestep Consumption Time: 1.29308
PPO Batch Consumption Time: 0.11466
Total Iteration Time: 4.22117

Cumulative Model Updates: 2,410
Cumulative Timesteps: 20,257,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.41500
Policy Entropy: 1.04705
Value Function Loss: 2.58468

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05839
Policy Update Magnitude: 0.10954
Value Function Update Magnitude: 0.08865

Collected Steps per Second: 17,021.90099
Overall Steps per Second: 11,684.88321

Timestep Collection Time: 2.93868
Timestep Consumption Time: 1.34223
PPO Batch Consumption Time: 0.11286
Total Iteration Time: 4.28092

Cumulative Model Updates: 2,416
Cumulative Timesteps: 20,307,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 20307414...
Checkpoint 20307414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.84091
Policy Entropy: 1.05745
Value Function Loss: 2.63474

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.12198
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 16,625.69554
Overall Steps per Second: 11,550.23732

Timestep Collection Time: 3.00956
Timestep Consumption Time: 1.32247
PPO Batch Consumption Time: 0.11117
Total Iteration Time: 4.33203

Cumulative Model Updates: 2,422
Cumulative Timesteps: 20,357,450

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.35512
Policy Entropy: 1.04297
Value Function Loss: 2.63223

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05792
Policy Update Magnitude: 0.13293
Value Function Update Magnitude: 0.08454

Collected Steps per Second: 15,980.05797
Overall Steps per Second: 10,838.47189

Timestep Collection Time: 3.12915
Timestep Consumption Time: 1.48442
PPO Batch Consumption Time: 0.13163
Total Iteration Time: 4.61357

Cumulative Model Updates: 2,428
Cumulative Timesteps: 20,407,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20407454...
Checkpoint 20407454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.17098
Policy Entropy: 1.04179
Value Function Loss: 2.65871

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.11521
Value Function Update Magnitude: 0.08781

Collected Steps per Second: 15,297.28796
Overall Steps per Second: 10,452.72454

Timestep Collection Time: 3.26908
Timestep Consumption Time: 1.51513
PPO Batch Consumption Time: 0.13637
Total Iteration Time: 4.78421

Cumulative Model Updates: 2,434
Cumulative Timesteps: 20,457,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.03854
Policy Entropy: 1.05619
Value Function Loss: 2.65281

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.10579
Value Function Update Magnitude: 0.09073

Collected Steps per Second: 15,440.70603
Overall Steps per Second: 10,515.36913

Timestep Collection Time: 3.23962
Timestep Consumption Time: 1.51742
PPO Batch Consumption Time: 0.13160
Total Iteration Time: 4.75704

Cumulative Model Updates: 2,440
Cumulative Timesteps: 20,507,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 20507484...
Checkpoint 20507484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.86971
Policy Entropy: 1.09222
Value Function Loss: 2.58006

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.11006
Value Function Update Magnitude: 0.09216

Collected Steps per Second: 15,993.28249
Overall Steps per Second: 10,763.28072

Timestep Collection Time: 3.12806
Timestep Consumption Time: 1.51996
PPO Batch Consumption Time: 0.13688
Total Iteration Time: 4.64803

Cumulative Model Updates: 2,446
Cumulative Timesteps: 20,557,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.78931
Policy Entropy: 1.08436
Value Function Loss: 2.59081

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05812
Policy Update Magnitude: 0.09550
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 14,643.98899
Overall Steps per Second: 9,908.17376

Timestep Collection Time: 3.41505
Timestep Consumption Time: 1.63229
PPO Batch Consumption Time: 0.14678
Total Iteration Time: 5.04735

Cumulative Model Updates: 2,452
Cumulative Timesteps: 20,607,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 20607522...
Checkpoint 20607522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.04330
Policy Entropy: 1.08720
Value Function Loss: 2.50759

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.08890
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 15,024.75323
Overall Steps per Second: 10,258.60092

Timestep Collection Time: 3.32904
Timestep Consumption Time: 1.54667
PPO Batch Consumption Time: 0.15536
Total Iteration Time: 4.87571

Cumulative Model Updates: 2,458
Cumulative Timesteps: 20,657,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.94523
Policy Entropy: 1.08028
Value Function Loss: 2.50150

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04284
Policy Update Magnitude: 0.11087
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 14,350.42846
Overall Steps per Second: 9,934.20694

Timestep Collection Time: 3.48477
Timestep Consumption Time: 1.54915
PPO Batch Consumption Time: 0.13397
Total Iteration Time: 5.03392

Cumulative Model Updates: 2,464
Cumulative Timesteps: 20,707,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20707548...
Checkpoint 20707548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.58860
Policy Entropy: 1.07979
Value Function Loss: 2.50202

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.11051
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 14,338.51731
Overall Steps per Second: 9,921.85704

Timestep Collection Time: 3.48711
Timestep Consumption Time: 1.55227
PPO Batch Consumption Time: 0.14248
Total Iteration Time: 5.03938

Cumulative Model Updates: 2,470
Cumulative Timesteps: 20,757,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.46961
Policy Entropy: 1.09196
Value Function Loss: 2.48173

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04188
Policy Update Magnitude: 0.10242
Value Function Update Magnitude: 0.08241

Collected Steps per Second: 14,761.63007
Overall Steps per Second: 9,972.66418

Timestep Collection Time: 3.38919
Timestep Consumption Time: 1.62752
PPO Batch Consumption Time: 0.14275
Total Iteration Time: 5.01671

Cumulative Model Updates: 2,476
Cumulative Timesteps: 20,807,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 20807578...
Checkpoint 20807578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.65582
Policy Entropy: 1.05901
Value Function Loss: 2.57992

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.10553
Value Function Update Magnitude: 0.08308

Collected Steps per Second: 13,483.71749
Overall Steps per Second: 9,535.82160

Timestep Collection Time: 3.71159
Timestep Consumption Time: 1.53662
PPO Batch Consumption Time: 0.12518
Total Iteration Time: 5.24821

Cumulative Model Updates: 2,482
Cumulative Timesteps: 20,857,624

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.71554
Policy Entropy: 1.09722
Value Function Loss: 2.53440

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.09151
Value Function Update Magnitude: 0.08935

Collected Steps per Second: 15,370.77656
Overall Steps per Second: 10,889.08786

Timestep Collection Time: 3.25306
Timestep Consumption Time: 1.33888
PPO Batch Consumption Time: 0.12464
Total Iteration Time: 4.59194

Cumulative Model Updates: 2,488
Cumulative Timesteps: 20,907,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20907626...
Checkpoint 20907626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.55309
Policy Entropy: 1.07391
Value Function Loss: 2.59415

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.06197
Policy Update Magnitude: 0.08921
Value Function Update Magnitude: 0.09640

Collected Steps per Second: 17,032.19080
Overall Steps per Second: 11,448.58989

Timestep Collection Time: 2.93726
Timestep Consumption Time: 1.43253
PPO Batch Consumption Time: 0.12296
Total Iteration Time: 4.36980

Cumulative Model Updates: 2,494
Cumulative Timesteps: 20,957,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.46539
Policy Entropy: 1.07498
Value Function Loss: 2.50999

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.09428
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 15,856.84764
Overall Steps per Second: 10,956.85301

Timestep Collection Time: 3.15473
Timestep Consumption Time: 1.41082
PPO Batch Consumption Time: 0.12492
Total Iteration Time: 4.56554

Cumulative Model Updates: 2,500
Cumulative Timesteps: 21,007,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21007678...
Checkpoint 21007678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.52590
Policy Entropy: 1.11430
Value Function Loss: 2.54654

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.08752
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 15,869.93533
Overall Steps per Second: 10,929.59659

Timestep Collection Time: 3.15137
Timestep Consumption Time: 1.42446
PPO Batch Consumption Time: 0.12536
Total Iteration Time: 4.57583

Cumulative Model Updates: 2,506
Cumulative Timesteps: 21,057,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.25860
Policy Entropy: 1.09532
Value Function Loss: 2.56311

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.08563
Value Function Update Magnitude: 0.08627

Collected Steps per Second: 16,253.86937
Overall Steps per Second: 11,071.50770

Timestep Collection Time: 3.07828
Timestep Consumption Time: 1.44089
PPO Batch Consumption Time: 0.12690
Total Iteration Time: 4.51917

Cumulative Model Updates: 2,512
Cumulative Timesteps: 21,107,724

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 21107724...
Checkpoint 21107724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.62921
Policy Entropy: 1.09522
Value Function Loss: 2.59494

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05708
Policy Update Magnitude: 0.08900
Value Function Update Magnitude: 0.09658

Collected Steps per Second: 16,006.66711
Overall Steps per Second: 11,164.23221

Timestep Collection Time: 3.12507
Timestep Consumption Time: 1.35549
PPO Batch Consumption Time: 0.12437
Total Iteration Time: 4.48056

Cumulative Model Updates: 2,518
Cumulative Timesteps: 21,157,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.72644
Policy Entropy: 1.06697
Value Function Loss: 2.68177

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.09969
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 16,534.92437
Overall Steps per Second: 11,405.09123

Timestep Collection Time: 3.02487
Timestep Consumption Time: 1.36054
PPO Batch Consumption Time: 0.11437
Total Iteration Time: 4.38541

Cumulative Model Updates: 2,524
Cumulative Timesteps: 21,207,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21207762...
Checkpoint 21207762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.88815
Policy Entropy: 1.09977
Value Function Loss: 2.61170

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04834
Policy Update Magnitude: 0.10972
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 16,796.28984
Overall Steps per Second: 11,521.83363

Timestep Collection Time: 2.97863
Timestep Consumption Time: 1.36356
PPO Batch Consumption Time: 0.11434
Total Iteration Time: 4.34219

Cumulative Model Updates: 2,530
Cumulative Timesteps: 21,257,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.61002
Policy Entropy: 1.11800
Value Function Loss: 2.60967

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.12821
Value Function Update Magnitude: 0.08686

Collected Steps per Second: 16,643.68393
Overall Steps per Second: 11,694.31584

Timestep Collection Time: 3.00486
Timestep Consumption Time: 1.27174
PPO Batch Consumption Time: 0.11209
Total Iteration Time: 4.27661

Cumulative Model Updates: 2,536
Cumulative Timesteps: 21,307,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 21307804...
Checkpoint 21307804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.11540
Policy Entropy: 1.11599
Value Function Loss: 2.56713

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.10466
Value Function Update Magnitude: 0.09141

Collected Steps per Second: 16,875.82744
Overall Steps per Second: 11,585.97787

Timestep Collection Time: 2.96388
Timestep Consumption Time: 1.35323
PPO Batch Consumption Time: 0.11080
Total Iteration Time: 4.31712

Cumulative Model Updates: 2,542
Cumulative Timesteps: 21,357,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.32639
Policy Entropy: 1.11665
Value Function Loss: 2.58111

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.11566
Value Function Update Magnitude: 0.10240

Collected Steps per Second: 17,010.43335
Overall Steps per Second: 11,679.23361

Timestep Collection Time: 2.93984
Timestep Consumption Time: 1.34195
PPO Batch Consumption Time: 0.11231
Total Iteration Time: 4.28179

Cumulative Model Updates: 2,548
Cumulative Timesteps: 21,407,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 21407830...
Checkpoint 21407830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.71439
Policy Entropy: 1.12930
Value Function Loss: 2.53577

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05886
Policy Update Magnitude: 0.12075
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 17,624.99385
Overall Steps per Second: 11,931.70024

Timestep Collection Time: 2.83790
Timestep Consumption Time: 1.35412
PPO Batch Consumption Time: 0.11286
Total Iteration Time: 4.19203

Cumulative Model Updates: 2,554
Cumulative Timesteps: 21,457,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.87079
Policy Entropy: 1.12924
Value Function Loss: 2.55766

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05844
Policy Update Magnitude: 0.12160
Value Function Update Magnitude: 0.11811

Collected Steps per Second: 15,087.81012
Overall Steps per Second: 10,498.16731

Timestep Collection Time: 3.31592
Timestep Consumption Time: 1.44967
PPO Batch Consumption Time: 0.12112
Total Iteration Time: 4.76559

Cumulative Model Updates: 2,560
Cumulative Timesteps: 21,507,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21507878...
Checkpoint 21507878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.27776
Policy Entropy: 1.13252
Value Function Loss: 2.59583

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.10714
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 15,587.19993
Overall Steps per Second: 10,956.91933

Timestep Collection Time: 3.20866
Timestep Consumption Time: 1.35595
PPO Batch Consumption Time: 0.12362
Total Iteration Time: 4.56460

Cumulative Model Updates: 2,566
Cumulative Timesteps: 21,557,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.96403
Policy Entropy: 1.15391
Value Function Loss: 2.66840

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.10160
Value Function Update Magnitude: 0.09601

Collected Steps per Second: 15,648.76893
Overall Steps per Second: 10,705.88709

Timestep Collection Time: 3.19706
Timestep Consumption Time: 1.47607
PPO Batch Consumption Time: 0.12694
Total Iteration Time: 4.67313

Cumulative Model Updates: 2,572
Cumulative Timesteps: 21,607,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21607922...
Checkpoint 21607922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.00153
Policy Entropy: 1.13268
Value Function Loss: 2.66498

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.09987
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 15,475.26019
Overall Steps per Second: 10,521.72794

Timestep Collection Time: 3.23148
Timestep Consumption Time: 1.52135
PPO Batch Consumption Time: 0.12448
Total Iteration Time: 4.75283

Cumulative Model Updates: 2,578
Cumulative Timesteps: 21,657,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.23036
Policy Entropy: 1.13443
Value Function Loss: 2.65019

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.09149
Value Function Update Magnitude: 0.09770

Collected Steps per Second: 15,856.31571
Overall Steps per Second: 10,864.00297

Timestep Collection Time: 3.15433
Timestep Consumption Time: 1.44950
PPO Batch Consumption Time: 0.11740
Total Iteration Time: 4.60383

Cumulative Model Updates: 2,584
Cumulative Timesteps: 21,707,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 21707946...
Checkpoint 21707946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.57245
Policy Entropy: 1.13581
Value Function Loss: 2.61356

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05051
Policy Update Magnitude: 0.11623
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 15,278.09618
Overall Steps per Second: 10,681.87507

Timestep Collection Time: 3.27331
Timestep Consumption Time: 1.40845
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 4.68176

Cumulative Model Updates: 2,590
Cumulative Timesteps: 21,757,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.99844
Policy Entropy: 1.13609
Value Function Loss: 2.57062

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.11132
Value Function Update Magnitude: 0.11223

Collected Steps per Second: 15,762.23588
Overall Steps per Second: 11,103.50422

Timestep Collection Time: 3.17214
Timestep Consumption Time: 1.33094
PPO Batch Consumption Time: 0.11621
Total Iteration Time: 4.50308

Cumulative Model Updates: 2,596
Cumulative Timesteps: 21,807,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 21807956...
Checkpoint 21807956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.52592
Policy Entropy: 1.13596
Value Function Loss: 2.58616

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.10015
Value Function Update Magnitude: 0.12099

Collected Steps per Second: 16,449.78085
Overall Steps per Second: 11,144.28531

Timestep Collection Time: 3.04004
Timestep Consumption Time: 1.44728
PPO Batch Consumption Time: 0.12447
Total Iteration Time: 4.48732

Cumulative Model Updates: 2,602
Cumulative Timesteps: 21,857,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.86617
Policy Entropy: 1.12190
Value Function Loss: 2.51836

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.11712
Value Function Update Magnitude: 0.11820

Collected Steps per Second: 15,760.11072
Overall Steps per Second: 11,091.73534

Timestep Collection Time: 3.17523
Timestep Consumption Time: 1.33642
PPO Batch Consumption Time: 0.11068
Total Iteration Time: 4.51165

Cumulative Model Updates: 2,608
Cumulative Timesteps: 21,908,006

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 21908006...
Checkpoint 21908006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.31519
Policy Entropy: 1.15540
Value Function Loss: 2.45616

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.11405
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 16,326.28868
Overall Steps per Second: 11,212.59257

Timestep Collection Time: 3.06377
Timestep Consumption Time: 1.39729
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 4.46106

Cumulative Model Updates: 2,614
Cumulative Timesteps: 21,958,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.30280
Policy Entropy: 1.14405
Value Function Loss: 2.51673

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.06238
Policy Update Magnitude: 0.11212
Value Function Update Magnitude: 0.10696

Collected Steps per Second: 17,246.91470
Overall Steps per Second: 11,670.71279

Timestep Collection Time: 2.90046
Timestep Consumption Time: 1.38582
PPO Batch Consumption Time: 0.11517
Total Iteration Time: 4.28628

Cumulative Model Updates: 2,620
Cumulative Timesteps: 22,008,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 22008050...
Checkpoint 22008050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.41120
Policy Entropy: 1.13777
Value Function Loss: 2.62669

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.06059
Policy Update Magnitude: 0.10975
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 16,916.37475
Overall Steps per Second: 11,832.53457

Timestep Collection Time: 2.95643
Timestep Consumption Time: 1.27023
PPO Batch Consumption Time: 0.11475
Total Iteration Time: 4.22665

Cumulative Model Updates: 2,626
Cumulative Timesteps: 22,058,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.68409
Policy Entropy: 1.13812
Value Function Loss: 2.73970

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.10531
Value Function Update Magnitude: 0.10357

Collected Steps per Second: 17,490.09358
Overall Steps per Second: 11,877.19564

Timestep Collection Time: 2.85933
Timestep Consumption Time: 1.35126
PPO Batch Consumption Time: 0.11414
Total Iteration Time: 4.21059

Cumulative Model Updates: 2,632
Cumulative Timesteps: 22,108,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 22108072...
Checkpoint 22108072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.57709
Policy Entropy: 1.14091
Value Function Loss: 2.58834

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.09962
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 16,099.71043
Overall Steps per Second: 11,213.87846

Timestep Collection Time: 3.10652
Timestep Consumption Time: 1.35349
PPO Batch Consumption Time: 0.11527
Total Iteration Time: 4.46001

Cumulative Model Updates: 2,638
Cumulative Timesteps: 22,158,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.94919
Policy Entropy: 1.14043
Value Function Loss: 2.46019

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.09065
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 17,511.16317
Overall Steps per Second: 11,797.77009

Timestep Collection Time: 2.85566
Timestep Consumption Time: 1.38293
PPO Batch Consumption Time: 0.11477
Total Iteration Time: 4.23860

Cumulative Model Updates: 2,644
Cumulative Timesteps: 22,208,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 22208092...
Checkpoint 22208092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.44305
Policy Entropy: 1.14778
Value Function Loss: 2.36370

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.09732
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 17,015.23323
Overall Steps per Second: 11,391.26675

Timestep Collection Time: 2.94101
Timestep Consumption Time: 1.45200
PPO Batch Consumption Time: 0.11675
Total Iteration Time: 4.39301

Cumulative Model Updates: 2,650
Cumulative Timesteps: 22,258,134

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.75649
Policy Entropy: 1.13522
Value Function Loss: 2.32227

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.11240
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 17,217.34700
Overall Steps per Second: 12,007.12330

Timestep Collection Time: 2.90428
Timestep Consumption Time: 1.26025
PPO Batch Consumption Time: 0.11286
Total Iteration Time: 4.16453

Cumulative Model Updates: 2,656
Cumulative Timesteps: 22,308,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22308138...
Checkpoint 22308138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.72294
Policy Entropy: 1.17815
Value Function Loss: 2.39863

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.10032
Value Function Update Magnitude: 0.09410

Collected Steps per Second: 16,990.24335
Overall Steps per Second: 11,374.66466

Timestep Collection Time: 2.94334
Timestep Consumption Time: 1.45310
PPO Batch Consumption Time: 0.12185
Total Iteration Time: 4.39644

Cumulative Model Updates: 2,662
Cumulative Timesteps: 22,358,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.08203
Policy Entropy: 1.16727
Value Function Loss: 2.44669

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.10356
Value Function Update Magnitude: 0.09268

Collected Steps per Second: 15,380.19086
Overall Steps per Second: 10,848.38784

Timestep Collection Time: 3.25146
Timestep Consumption Time: 1.35826
PPO Batch Consumption Time: 0.11178
Total Iteration Time: 4.60972

Cumulative Model Updates: 2,668
Cumulative Timesteps: 22,408,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22408154...
Checkpoint 22408154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.07963
Policy Entropy: 1.19562
Value Function Loss: 2.60029

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.10283
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 16,358.04127
Overall Steps per Second: 11,251.46381

Timestep Collection Time: 3.05856
Timestep Consumption Time: 1.38815
PPO Batch Consumption Time: 0.11438
Total Iteration Time: 4.44671

Cumulative Model Updates: 2,674
Cumulative Timesteps: 22,458,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.09795
Policy Entropy: 1.16614
Value Function Loss: 2.63376

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05913
Policy Update Magnitude: 0.12477
Value Function Update Magnitude: 0.10231

Collected Steps per Second: 15,809.16317
Overall Steps per Second: 11,037.54342

Timestep Collection Time: 3.16487
Timestep Consumption Time: 1.36820
PPO Batch Consumption Time: 0.11152
Total Iteration Time: 4.53307

Cumulative Model Updates: 2,680
Cumulative Timesteps: 22,508,220

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 22508220...
Checkpoint 22508220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.88037
Policy Entropy: 1.18061
Value Function Loss: 2.71492

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.10734
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 15,978.28645
Overall Steps per Second: 11,370.37291

Timestep Collection Time: 3.13087
Timestep Consumption Time: 1.26881
PPO Batch Consumption Time: 0.11308
Total Iteration Time: 4.39968

Cumulative Model Updates: 2,686
Cumulative Timesteps: 22,558,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.06671
Policy Entropy: 1.18954
Value Function Loss: 2.72310

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.08678
Value Function Update Magnitude: 0.12335

Collected Steps per Second: 16,409.92576
Overall Steps per Second: 11,395.63161

Timestep Collection Time: 3.04852
Timestep Consumption Time: 1.34141
PPO Batch Consumption Time: 0.11004
Total Iteration Time: 4.38993

Cumulative Model Updates: 2,692
Cumulative Timesteps: 22,608,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22608272...
Checkpoint 22608272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.21847
Policy Entropy: 1.17481
Value Function Loss: 2.81716

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.07654
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 16,743.43306
Overall Steps per Second: 11,535.14642

Timestep Collection Time: 2.98768
Timestep Consumption Time: 1.34898
PPO Batch Consumption Time: 0.11436
Total Iteration Time: 4.33666

Cumulative Model Updates: 2,698
Cumulative Timesteps: 22,658,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.52201
Policy Entropy: 1.19762
Value Function Loss: 2.87338

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.07056
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 17,110.39220
Overall Steps per Second: 11,550.45427

Timestep Collection Time: 2.92314
Timestep Consumption Time: 1.40708
PPO Batch Consumption Time: 0.11794
Total Iteration Time: 4.33022

Cumulative Model Updates: 2,704
Cumulative Timesteps: 22,708,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 22708312...
Checkpoint 22708312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.97192
Policy Entropy: 1.21257
Value Function Loss: 3.04381

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.06936
Value Function Update Magnitude: 0.14163

Collected Steps per Second: 14,970.04868
Overall Steps per Second: 10,528.30858

Timestep Collection Time: 3.34120
Timestep Consumption Time: 1.40961
PPO Batch Consumption Time: 0.11148
Total Iteration Time: 4.75081

Cumulative Model Updates: 2,710
Cumulative Timesteps: 22,758,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.67550
Policy Entropy: 1.19496
Value Function Loss: 2.97250

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.08412
Value Function Update Magnitude: 0.16451

Collected Steps per Second: 16,348.52306
Overall Steps per Second: 11,464.15556

Timestep Collection Time: 3.05960
Timestep Consumption Time: 1.30356
PPO Batch Consumption Time: 0.11340
Total Iteration Time: 4.36316

Cumulative Model Updates: 2,716
Cumulative Timesteps: 22,808,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 22808350...
Checkpoint 22808350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.46830
Policy Entropy: 1.17826
Value Function Loss: 2.76711

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.10305
Value Function Update Magnitude: 0.17624

Collected Steps per Second: 16,354.70598
Overall Steps per Second: 11,073.66862

Timestep Collection Time: 3.05747
Timestep Consumption Time: 1.45811
PPO Batch Consumption Time: 0.12503
Total Iteration Time: 4.51558

Cumulative Model Updates: 2,722
Cumulative Timesteps: 22,858,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.96066
Policy Entropy: 1.16863
Value Function Loss: 2.39423

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.08526
Value Function Update Magnitude: 0.23411

Collected Steps per Second: 16,535.88596
Overall Steps per Second: 11,468.70166

Timestep Collection Time: 3.02469
Timestep Consumption Time: 1.33639
PPO Batch Consumption Time: 0.11584
Total Iteration Time: 4.36109

Cumulative Model Updates: 2,728
Cumulative Timesteps: 22,908,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 22908370...
Checkpoint 22908370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.22555
Policy Entropy: 1.15058
Value Function Loss: 2.30323

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.08676
Value Function Update Magnitude: 0.21561

Collected Steps per Second: 16,890.03595
Overall Steps per Second: 11,848.69878

Timestep Collection Time: 2.96163
Timestep Consumption Time: 1.26010
PPO Batch Consumption Time: 0.11300
Total Iteration Time: 4.22173

Cumulative Model Updates: 2,734
Cumulative Timesteps: 22,958,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.76894
Policy Entropy: 1.15846
Value Function Loss: 2.45449

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.10008
Value Function Update Magnitude: 0.22754

Collected Steps per Second: 17,153.65489
Overall Steps per Second: 11,716.23541

Timestep Collection Time: 2.91495
Timestep Consumption Time: 1.35281
PPO Batch Consumption Time: 0.11228
Total Iteration Time: 4.26775

Cumulative Model Updates: 2,740
Cumulative Timesteps: 23,008,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23008394...
Checkpoint 23008394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.74872
Policy Entropy: 1.16610
Value Function Loss: 2.48123

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.10745
Value Function Update Magnitude: 0.28324

Collected Steps per Second: 16,957.09882
Overall Steps per Second: 11,707.18180

Timestep Collection Time: 2.94968
Timestep Consumption Time: 1.32274
PPO Batch Consumption Time: 0.11167
Total Iteration Time: 4.27242

Cumulative Model Updates: 2,746
Cumulative Timesteps: 23,058,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.53051
Policy Entropy: 1.16684
Value Function Loss: 2.44689

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.14173
Value Function Update Magnitude: 0.28969

Collected Steps per Second: 17,457.23398
Overall Steps per Second: 11,859.64943

Timestep Collection Time: 2.86437
Timestep Consumption Time: 1.35194
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 4.21631

Cumulative Model Updates: 2,752
Cumulative Timesteps: 23,108,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23108416...
Checkpoint 23108416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.14231
Policy Entropy: 1.13547
Value Function Loss: 2.47711

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06229
Policy Update Magnitude: 0.12981
Value Function Update Magnitude: 0.24331

Collected Steps per Second: 17,209.01417
Overall Steps per Second: 11,770.53742

Timestep Collection Time: 2.90766
Timestep Consumption Time: 1.34346
PPO Batch Consumption Time: 0.11275
Total Iteration Time: 4.25112

Cumulative Model Updates: 2,758
Cumulative Timesteps: 23,158,454

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.91051
Policy Entropy: 1.12596
Value Function Loss: 2.54359

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.12147
Value Function Update Magnitude: 0.22376

Collected Steps per Second: 17,005.60042
Overall Steps per Second: 11,672.73516

Timestep Collection Time: 2.94080
Timestep Consumption Time: 1.34355
PPO Batch Consumption Time: 0.11381
Total Iteration Time: 4.28434

Cumulative Model Updates: 2,764
Cumulative Timesteps: 23,208,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 23208464...
Checkpoint 23208464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.85037
Policy Entropy: 1.11840
Value Function Loss: 2.64271

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06392
Policy Update Magnitude: 0.10941
Value Function Update Magnitude: 0.20655

Collected Steps per Second: 17,453.37833
Overall Steps per Second: 11,865.78455

Timestep Collection Time: 2.86592
Timestep Consumption Time: 1.34956
PPO Batch Consumption Time: 0.11251
Total Iteration Time: 4.21548

Cumulative Model Updates: 2,770
Cumulative Timesteps: 23,258,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.42372
Policy Entropy: 1.11596
Value Function Loss: 2.56646

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.11623
Value Function Update Magnitude: 0.19996

Collected Steps per Second: 17,097.80608
Overall Steps per Second: 11,667.51521

Timestep Collection Time: 2.92435
Timestep Consumption Time: 1.36105
PPO Batch Consumption Time: 0.11503
Total Iteration Time: 4.28540

Cumulative Model Updates: 2,776
Cumulative Timesteps: 23,308,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23308484...
Checkpoint 23308484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.40240
Policy Entropy: 1.09097
Value Function Loss: 2.51527

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.12202
Value Function Update Magnitude: 0.19155

Collected Steps per Second: 15,513.20561
Overall Steps per Second: 11,116.19814

Timestep Collection Time: 3.22603
Timestep Consumption Time: 1.27605
PPO Batch Consumption Time: 0.11332
Total Iteration Time: 4.50208

Cumulative Model Updates: 2,782
Cumulative Timesteps: 23,358,530

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.37023
Policy Entropy: 1.10159
Value Function Loss: 2.50202

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.10890
Value Function Update Magnitude: 0.19656

Collected Steps per Second: 17,264.18618
Overall Steps per Second: 11,779.56024

Timestep Collection Time: 2.89802
Timestep Consumption Time: 1.34933
PPO Batch Consumption Time: 0.11270
Total Iteration Time: 4.24736

Cumulative Model Updates: 2,788
Cumulative Timesteps: 23,408,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 23408562...
Checkpoint 23408562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.94546
Policy Entropy: 1.10664
Value Function Loss: 2.46649

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.09745
Value Function Update Magnitude: 0.19846

Collected Steps per Second: 16,862.74662
Overall Steps per Second: 11,685.90680

Timestep Collection Time: 2.96737
Timestep Consumption Time: 1.31454
PPO Batch Consumption Time: 0.11176
Total Iteration Time: 4.28191

Cumulative Model Updates: 2,794
Cumulative Timesteps: 23,458,600

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.87967
Policy Entropy: 1.09991
Value Function Loss: 2.46002

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.09216
Value Function Update Magnitude: 0.18567

Collected Steps per Second: 16,494.81353
Overall Steps per Second: 11,318.86508

Timestep Collection Time: 3.03162
Timestep Consumption Time: 1.38631
PPO Batch Consumption Time: 0.11366
Total Iteration Time: 4.41793

Cumulative Model Updates: 2,800
Cumulative Timesteps: 23,508,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 23508606...
Checkpoint 23508606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.70960
Policy Entropy: 1.08374
Value Function Loss: 2.34486

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.11986
Value Function Update Magnitude: 0.21476

Collected Steps per Second: 16,798.70609
Overall Steps per Second: 11,525.64749

Timestep Collection Time: 2.97701
Timestep Consumption Time: 1.36200
PPO Batch Consumption Time: 0.11179
Total Iteration Time: 4.33902

Cumulative Model Updates: 2,806
Cumulative Timesteps: 23,558,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.60868
Policy Entropy: 1.09839
Value Function Loss: 2.50627

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.11114
Value Function Update Magnitude: 0.17922

Collected Steps per Second: 15,290.43018
Overall Steps per Second: 10,729.48583

Timestep Collection Time: 3.27290
Timestep Consumption Time: 1.39126
PPO Batch Consumption Time: 0.11574
Total Iteration Time: 4.66416

Cumulative Model Updates: 2,812
Cumulative Timesteps: 23,608,660

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 23608660...
Checkpoint 23608660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.00183
Policy Entropy: 1.08643
Value Function Loss: 2.38676

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05438
Policy Update Magnitude: 0.12300
Value Function Update Magnitude: 0.14356

Collected Steps per Second: 15,853.38146
Overall Steps per Second: 10,885.73647

Timestep Collection Time: 3.15441
Timestep Consumption Time: 1.43950
PPO Batch Consumption Time: 0.11637
Total Iteration Time: 4.59390

Cumulative Model Updates: 2,818
Cumulative Timesteps: 23,658,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.42107
Policy Entropy: 1.07649
Value Function Loss: 2.33455

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.11851
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 14,693.94493
Overall Steps per Second: 10,448.44953

Timestep Collection Time: 3.40440
Timestep Consumption Time: 1.38330
PPO Batch Consumption Time: 0.11388
Total Iteration Time: 4.78770

Cumulative Model Updates: 2,824
Cumulative Timesteps: 23,708,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23708692...
Checkpoint 23708692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.80616
Policy Entropy: 1.07898
Value Function Loss: 2.29934

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.11685
Value Function Update Magnitude: 0.13385

Collected Steps per Second: 15,975.34466
Overall Steps per Second: 11,298.43429

Timestep Collection Time: 3.13032
Timestep Consumption Time: 1.29578
PPO Batch Consumption Time: 0.11370
Total Iteration Time: 4.42610

Cumulative Model Updates: 2,830
Cumulative Timesteps: 23,758,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.56195
Policy Entropy: 1.07534
Value Function Loss: 2.42036

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.09384
Value Function Update Magnitude: 0.20909

Collected Steps per Second: 16,765.17264
Overall Steps per Second: 11,521.15429

Timestep Collection Time: 2.98488
Timestep Consumption Time: 1.35861
PPO Batch Consumption Time: 0.11484
Total Iteration Time: 4.34349

Cumulative Model Updates: 2,836
Cumulative Timesteps: 23,808,742

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 23808742...
Checkpoint 23808742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.17486
Policy Entropy: 1.08480
Value Function Loss: 2.45496

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.09487
Value Function Update Magnitude: 0.23486

Collected Steps per Second: 15,863.04006
Overall Steps per Second: 11,171.13493

Timestep Collection Time: 3.15286
Timestep Consumption Time: 1.32421
PPO Batch Consumption Time: 0.11392
Total Iteration Time: 4.47707

Cumulative Model Updates: 2,842
Cumulative Timesteps: 23,858,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.53115
Policy Entropy: 1.08118
Value Function Loss: 2.55750

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05592
Policy Update Magnitude: 0.09419
Value Function Update Magnitude: 0.20122

Collected Steps per Second: 16,455.36613
Overall Steps per Second: 11,290.42748

Timestep Collection Time: 3.04035
Timestep Consumption Time: 1.39084
PPO Batch Consumption Time: 0.12903
Total Iteration Time: 4.43119

Cumulative Model Updates: 2,848
Cumulative Timesteps: 23,908,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 23908786...
Checkpoint 23908786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.62580
Policy Entropy: 1.06689
Value Function Loss: 2.57806

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.08635
Value Function Update Magnitude: 0.21134

Collected Steps per Second: 16,919.30306
Overall Steps per Second: 11,586.31311

Timestep Collection Time: 2.95568
Timestep Consumption Time: 1.36045
PPO Batch Consumption Time: 0.11515
Total Iteration Time: 4.31613

Cumulative Model Updates: 2,854
Cumulative Timesteps: 23,958,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.53825
Policy Entropy: 1.06387
Value Function Loss: 2.57294

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.07382
Value Function Update Magnitude: 0.19070

Collected Steps per Second: 15,899.48928
Overall Steps per Second: 11,281.63172

Timestep Collection Time: 3.14476
Timestep Consumption Time: 1.28723
PPO Batch Consumption Time: 0.11445
Total Iteration Time: 4.43198

Cumulative Model Updates: 2,860
Cumulative Timesteps: 24,008,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 24008794...
Checkpoint 24008794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.97457
Policy Entropy: 1.05112
Value Function Loss: 2.52293

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.09300
Value Function Update Magnitude: 0.20869

Collected Steps per Second: 16,116.86006
Overall Steps per Second: 11,044.49966

Timestep Collection Time: 3.10358
Timestep Consumption Time: 1.42537
PPO Batch Consumption Time: 0.12314
Total Iteration Time: 4.52895

Cumulative Model Updates: 2,866
Cumulative Timesteps: 24,058,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.37669
Policy Entropy: 1.05177
Value Function Loss: 2.50767

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.10026
Value Function Update Magnitude: 0.19293

Collected Steps per Second: 15,822.55863
Overall Steps per Second: 11,045.43380

Timestep Collection Time: 3.16207
Timestep Consumption Time: 1.36759
PPO Batch Consumption Time: 0.11933
Total Iteration Time: 4.52965

Cumulative Model Updates: 2,872
Cumulative Timesteps: 24,108,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 24108846...
Checkpoint 24108846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.34874
Policy Entropy: 1.04791
Value Function Loss: 2.62643

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.09392
Value Function Update Magnitude: 0.17414

Collected Steps per Second: 15,895.73486
Overall Steps per Second: 11,061.66737

Timestep Collection Time: 3.14764
Timestep Consumption Time: 1.37555
PPO Batch Consumption Time: 0.13355
Total Iteration Time: 4.52319

Cumulative Model Updates: 2,878
Cumulative Timesteps: 24,158,880

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.96811
Policy Entropy: 1.04941
Value Function Loss: 2.73515

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.11741
Value Function Update Magnitude: 0.17034

Collected Steps per Second: 14,331.54831
Overall Steps per Second: 10,031.98543

Timestep Collection Time: 3.49020
Timestep Consumption Time: 1.49585
PPO Batch Consumption Time: 0.13014
Total Iteration Time: 4.98605

Cumulative Model Updates: 2,884
Cumulative Timesteps: 24,208,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 24208900...
Checkpoint 24208900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.12050
Policy Entropy: 1.04529
Value Function Loss: 2.76502

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.09193
Value Function Update Magnitude: 0.17357

Collected Steps per Second: 15,243.69524
Overall Steps per Second: 10,836.76706

Timestep Collection Time: 3.28123
Timestep Consumption Time: 1.33436
PPO Batch Consumption Time: 0.12512
Total Iteration Time: 4.61558

Cumulative Model Updates: 2,890
Cumulative Timesteps: 24,258,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.86972
Policy Entropy: 1.04279
Value Function Loss: 2.67093

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.07656
Value Function Update Magnitude: 0.25301

Collected Steps per Second: 16,322.38285
Overall Steps per Second: 11,229.81794

Timestep Collection Time: 3.06475
Timestep Consumption Time: 1.38982
PPO Batch Consumption Time: 0.11822
Total Iteration Time: 4.45457

Cumulative Model Updates: 2,896
Cumulative Timesteps: 24,308,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 24308942...
Checkpoint 24308942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.86796
Policy Entropy: 1.03284
Value Function Loss: 2.54134

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.08591
Value Function Update Magnitude: 0.25937

Collected Steps per Second: 16,668.27511
Overall Steps per Second: 11,449.15410

Timestep Collection Time: 3.00187
Timestep Consumption Time: 1.36841
PPO Batch Consumption Time: 0.11608
Total Iteration Time: 4.37028

Cumulative Model Updates: 2,902
Cumulative Timesteps: 24,358,978

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.74110
Policy Entropy: 1.02301
Value Function Loss: 2.73694

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.08815
Value Function Update Magnitude: 0.22313

Collected Steps per Second: 16,613.81634
Overall Steps per Second: 11,687.54038

Timestep Collection Time: 3.01231
Timestep Consumption Time: 1.26968
PPO Batch Consumption Time: 0.11448
Total Iteration Time: 4.28200

Cumulative Model Updates: 2,908
Cumulative Timesteps: 24,409,024

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 24409024...
Checkpoint 24409024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.25549
Policy Entropy: 1.03162
Value Function Loss: 2.77302

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.09091
Value Function Update Magnitude: 0.18113

Collected Steps per Second: 16,388.81658
Overall Steps per Second: 11,235.82535

Timestep Collection Time: 3.05257
Timestep Consumption Time: 1.39997
PPO Batch Consumption Time: 0.11743
Total Iteration Time: 4.45254

Cumulative Model Updates: 2,914
Cumulative Timesteps: 24,459,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.45625
Policy Entropy: 1.02636
Value Function Loss: 2.83035

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.08495
Value Function Update Magnitude: 0.20840

Collected Steps per Second: 16,599.25721
Overall Steps per Second: 11,416.95274

Timestep Collection Time: 3.01387
Timestep Consumption Time: 1.36803
PPO Batch Consumption Time: 0.11495
Total Iteration Time: 4.38190

Cumulative Model Updates: 2,920
Cumulative Timesteps: 24,509,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24509080...
Checkpoint 24509080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.05697
Policy Entropy: 1.01244
Value Function Loss: 2.74021

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.07952
Value Function Update Magnitude: 0.18913

Collected Steps per Second: 16,900.32199
Overall Steps per Second: 11,479.76366

Timestep Collection Time: 2.95935
Timestep Consumption Time: 1.39736
PPO Batch Consumption Time: 0.11827
Total Iteration Time: 4.35671

Cumulative Model Updates: 2,926
Cumulative Timesteps: 24,559,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.92575
Policy Entropy: 1.01801
Value Function Loss: 2.62968

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.08841
Value Function Update Magnitude: 0.17479

Collected Steps per Second: 15,840.19234
Overall Steps per Second: 10,748.44868

Timestep Collection Time: 3.15792
Timestep Consumption Time: 1.49596
PPO Batch Consumption Time: 0.13369
Total Iteration Time: 4.65388

Cumulative Model Updates: 2,932
Cumulative Timesteps: 24,609,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 24609116...
Checkpoint 24609116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.48779
Policy Entropy: 1.01796
Value Function Loss: 2.51504

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.08163
Value Function Update Magnitude: 0.20751

Collected Steps per Second: 16,300.26271
Overall Steps per Second: 11,358.20058

Timestep Collection Time: 3.06854
Timestep Consumption Time: 1.33515
PPO Batch Consumption Time: 0.11447
Total Iteration Time: 4.40369

Cumulative Model Updates: 2,938
Cumulative Timesteps: 24,659,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.73887
Policy Entropy: 1.03431
Value Function Loss: 2.46948

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07844
Policy Update Magnitude: 0.07624
Value Function Update Magnitude: 0.18868

Collected Steps per Second: 15,578.54914
Overall Steps per Second: 10,823.30348

Timestep Collection Time: 3.21095
Timestep Consumption Time: 1.41074
PPO Batch Consumption Time: 0.12216
Total Iteration Time: 4.62169

Cumulative Model Updates: 2,944
Cumulative Timesteps: 24,709,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 24709156...
Checkpoint 24709156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.54030
Policy Entropy: 1.04061
Value Function Loss: 2.57740

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.08144
Value Function Update Magnitude: 0.18847

Collected Steps per Second: 15,353.27914
Overall Steps per Second: 10,908.33872

Timestep Collection Time: 3.25924
Timestep Consumption Time: 1.32808
PPO Batch Consumption Time: 0.11257
Total Iteration Time: 4.58732

Cumulative Model Updates: 2,950
Cumulative Timesteps: 24,759,196

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.48424
Policy Entropy: 1.03448
Value Function Loss: 2.60149

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05697
Policy Update Magnitude: 0.09867
Value Function Update Magnitude: 0.18413

Collected Steps per Second: 16,349.90776
Overall Steps per Second: 11,160.73968

Timestep Collection Time: 3.06045
Timestep Consumption Time: 1.42295
PPO Batch Consumption Time: 0.12285
Total Iteration Time: 4.48339

Cumulative Model Updates: 2,956
Cumulative Timesteps: 24,809,234

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 24809234...
Checkpoint 24809234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.92266
Policy Entropy: 1.03814
Value Function Loss: 2.55674

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.11655
Value Function Update Magnitude: 0.17894

Collected Steps per Second: 14,222.42720
Overall Steps per Second: 10,228.83209

Timestep Collection Time: 3.51782
Timestep Consumption Time: 1.37345
PPO Batch Consumption Time: 0.11454
Total Iteration Time: 4.89127

Cumulative Model Updates: 2,962
Cumulative Timesteps: 24,859,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.95381
Policy Entropy: 1.03564
Value Function Loss: 2.49736

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.18572

Collected Steps per Second: 16,474.77424
Overall Steps per Second: 11,428.47670

Timestep Collection Time: 3.03786
Timestep Consumption Time: 1.34138
PPO Batch Consumption Time: 0.11226
Total Iteration Time: 4.37924

Cumulative Model Updates: 2,968
Cumulative Timesteps: 24,909,314

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 24909314...
Checkpoint 24909314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.95045
Policy Entropy: 1.03174
Value Function Loss: 2.47207

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.11523
Value Function Update Magnitude: 0.18284

Collected Steps per Second: 15,558.91369
Overall Steps per Second: 10,789.88587

Timestep Collection Time: 3.21488
Timestep Consumption Time: 1.42095
PPO Batch Consumption Time: 0.12328
Total Iteration Time: 4.63582

Cumulative Model Updates: 2,974
Cumulative Timesteps: 24,959,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.01408
Policy Entropy: 1.03949
Value Function Loss: 2.44710

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.11604
Value Function Update Magnitude: 0.16389

Collected Steps per Second: 15,131.04154
Overall Steps per Second: 10,067.27163

Timestep Collection Time: 3.30499
Timestep Consumption Time: 1.66239
PPO Batch Consumption Time: 0.14879
Total Iteration Time: 4.96738

Cumulative Model Updates: 2,980
Cumulative Timesteps: 25,009,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 25009342...
Checkpoint 25009342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.21140
Policy Entropy: 1.03654
Value Function Loss: 2.37548

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.13990
Value Function Update Magnitude: 0.16727

Collected Steps per Second: 14,923.16378
Overall Steps per Second: 10,300.46566

Timestep Collection Time: 3.35277
Timestep Consumption Time: 1.50468
PPO Batch Consumption Time: 0.14064
Total Iteration Time: 4.85745

Cumulative Model Updates: 2,986
Cumulative Timesteps: 25,059,376

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.87380
Policy Entropy: 1.01891
Value Function Loss: 2.36825

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06332
Policy Update Magnitude: 0.14074
Value Function Update Magnitude: 0.16501

Collected Steps per Second: 15,054.21945
Overall Steps per Second: 10,378.59399

Timestep Collection Time: 3.32292
Timestep Consumption Time: 1.49700
PPO Batch Consumption Time: 0.12989
Total Iteration Time: 4.81992

Cumulative Model Updates: 2,992
Cumulative Timesteps: 25,109,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 25109400...
Checkpoint 25109400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.28280
Policy Entropy: 1.00548
Value Function Loss: 2.33175

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.11052
Value Function Update Magnitude: 0.17613

Collected Steps per Second: 14,552.15638
Overall Steps per Second: 10,146.19202

Timestep Collection Time: 3.43743
Timestep Consumption Time: 1.49270
PPO Batch Consumption Time: 0.13929
Total Iteration Time: 4.93013

Cumulative Model Updates: 2,998
Cumulative Timesteps: 25,159,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.03280
Policy Entropy: 0.99814
Value Function Loss: 2.32382

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.09498
Value Function Update Magnitude: 0.16255

Collected Steps per Second: 14,215.75418
Overall Steps per Second: 9,881.47603

Timestep Collection Time: 3.51821
Timestep Consumption Time: 1.54318
PPO Batch Consumption Time: 0.14713
Total Iteration Time: 5.06139

Cumulative Model Updates: 3,004
Cumulative Timesteps: 25,209,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25209436...
Checkpoint 25209436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.25329
Policy Entropy: 0.99210
Value Function Loss: 2.28229

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.10072
Value Function Update Magnitude: 0.16372

Collected Steps per Second: 14,405.50476
Overall Steps per Second: 10,149.56174

Timestep Collection Time: 3.47173
Timestep Consumption Time: 1.45578
PPO Batch Consumption Time: 0.12586
Total Iteration Time: 4.92750

Cumulative Model Updates: 3,010
Cumulative Timesteps: 25,259,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.24262
Policy Entropy: 0.99505
Value Function Loss: 2.21497

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.11060
Value Function Update Magnitude: 0.16170

Collected Steps per Second: 15,854.28005
Overall Steps per Second: 11,325.99252

Timestep Collection Time: 3.15574
Timestep Consumption Time: 1.26171
PPO Batch Consumption Time: 0.10998
Total Iteration Time: 4.41745

Cumulative Model Updates: 3,016
Cumulative Timesteps: 25,309,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 25309480...
Checkpoint 25309480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.19712
Policy Entropy: 0.98900
Value Function Loss: 2.22929

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.11487
Value Function Update Magnitude: 0.16729

Collected Steps per Second: 14,617.14289
Overall Steps per Second: 10,065.10122

Timestep Collection Time: 3.42215
Timestep Consumption Time: 1.54770
PPO Batch Consumption Time: 0.13566
Total Iteration Time: 4.96985

Cumulative Model Updates: 3,022
Cumulative Timesteps: 25,359,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.48986
Policy Entropy: 0.97859
Value Function Loss: 2.26571

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05711
Policy Update Magnitude: 0.12969
Value Function Update Magnitude: 0.16859

Collected Steps per Second: 16,086.29519
Overall Steps per Second: 11,192.21647

Timestep Collection Time: 3.10998
Timestep Consumption Time: 1.35992
PPO Batch Consumption Time: 0.11598
Total Iteration Time: 4.46989

Cumulative Model Updates: 3,028
Cumulative Timesteps: 25,409,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 25409530...
Checkpoint 25409530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.69248
Policy Entropy: 0.96436
Value Function Loss: 2.35521

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05525
Policy Update Magnitude: 0.13317
Value Function Update Magnitude: 0.18642

Collected Steps per Second: 14,966.87196
Overall Steps per Second: 10,679.96199

Timestep Collection Time: 3.34111
Timestep Consumption Time: 1.34111
PPO Batch Consumption Time: 0.12235
Total Iteration Time: 4.68223

Cumulative Model Updates: 3,034
Cumulative Timesteps: 25,459,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.38495
Policy Entropy: 0.95877
Value Function Loss: 2.32539

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.13289
Value Function Update Magnitude: 0.19689

Collected Steps per Second: 16,595.24330
Overall Steps per Second: 11,408.28315

Timestep Collection Time: 3.01484
Timestep Consumption Time: 1.37075
PPO Batch Consumption Time: 0.11396
Total Iteration Time: 4.38559

Cumulative Model Updates: 3,040
Cumulative Timesteps: 25,509,568

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 25509568...
Checkpoint 25509568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.04046
Policy Entropy: 0.96465
Value Function Loss: 2.40284

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06210
Policy Update Magnitude: 0.13544
Value Function Update Magnitude: 0.24676

Collected Steps per Second: 16,105.79594
Overall Steps per Second: 11,053.23765

Timestep Collection Time: 3.10484
Timestep Consumption Time: 1.41926
PPO Batch Consumption Time: 0.12503
Total Iteration Time: 4.52410

Cumulative Model Updates: 3,046
Cumulative Timesteps: 25,559,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.50416
Policy Entropy: 0.95143
Value Function Loss: 2.35785

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04009
Policy Update Magnitude: 0.15327
Value Function Update Magnitude: 0.24634

Collected Steps per Second: 16,630.95112
Overall Steps per Second: 11,316.63219

Timestep Collection Time: 3.00873
Timestep Consumption Time: 1.41291
PPO Batch Consumption Time: 0.12318
Total Iteration Time: 4.42163

Cumulative Model Updates: 3,052
Cumulative Timesteps: 25,609,612

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 25609612...
Checkpoint 25609612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.47275
Policy Entropy: 0.96591
Value Function Loss: 2.26606

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.15819
Value Function Update Magnitude: 0.26827

Collected Steps per Second: 16,054.46978
Overall Steps per Second: 11,181.92665

Timestep Collection Time: 3.11577
Timestep Consumption Time: 1.35770
PPO Batch Consumption Time: 0.11286
Total Iteration Time: 4.47347

Cumulative Model Updates: 3,058
Cumulative Timesteps: 25,659,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.12721
Policy Entropy: 0.95011
Value Function Loss: 2.09542

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03880
Policy Update Magnitude: 0.13678
Value Function Update Magnitude: 0.28116

Collected Steps per Second: 16,344.69851
Overall Steps per Second: 11,546.79599

Timestep Collection Time: 3.06142
Timestep Consumption Time: 1.27208
PPO Batch Consumption Time: 0.11253
Total Iteration Time: 4.33350

Cumulative Model Updates: 3,064
Cumulative Timesteps: 25,709,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 25709672...
Checkpoint 25709672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.28814
Policy Entropy: 0.95910
Value Function Loss: 2.04689

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.12622
Value Function Update Magnitude: 0.25925

Collected Steps per Second: 16,110.26622
Overall Steps per Second: 11,104.32008

Timestep Collection Time: 3.10547
Timestep Consumption Time: 1.39998
PPO Batch Consumption Time: 0.12042
Total Iteration Time: 4.50545

Cumulative Model Updates: 3,070
Cumulative Timesteps: 25,759,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.87185
Policy Entropy: 0.95440
Value Function Loss: 2.12736

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05264
Policy Update Magnitude: 0.11831
Value Function Update Magnitude: 0.27732

Collected Steps per Second: 16,429.94091
Overall Steps per Second: 11,429.90078

Timestep Collection Time: 3.04542
Timestep Consumption Time: 1.33223
PPO Batch Consumption Time: 0.11345
Total Iteration Time: 4.37764

Cumulative Model Updates: 3,076
Cumulative Timesteps: 25,809,738

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 25809738...
Checkpoint 25809738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.17410
Policy Entropy: 0.93961
Value Function Loss: 2.14473

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05042
Policy Update Magnitude: 0.11326
Value Function Update Magnitude: 0.21376

Collected Steps per Second: 17,095.72777
Overall Steps per Second: 11,661.30470

Timestep Collection Time: 2.92482
Timestep Consumption Time: 1.36303
PPO Batch Consumption Time: 0.11545
Total Iteration Time: 4.28786

Cumulative Model Updates: 3,082
Cumulative Timesteps: 25,859,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.31604
Policy Entropy: 0.95395
Value Function Loss: 2.20914

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05554
Policy Update Magnitude: 0.11030
Value Function Update Magnitude: 0.21514

Collected Steps per Second: 16,844.24036
Overall Steps per Second: 11,532.09428

Timestep Collection Time: 2.96873
Timestep Consumption Time: 1.36752
PPO Batch Consumption Time: 0.11384
Total Iteration Time: 4.33625

Cumulative Model Updates: 3,088
Cumulative Timesteps: 25,909,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 25909746...
Checkpoint 25909746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.17091
Policy Entropy: 0.93915
Value Function Loss: 2.22352

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05350
Policy Update Magnitude: 0.12372
Value Function Update Magnitude: 0.25041

Collected Steps per Second: 16,780.43589
Overall Steps per Second: 11,561.00551

Timestep Collection Time: 2.98038
Timestep Consumption Time: 1.34555
PPO Batch Consumption Time: 0.12656
Total Iteration Time: 4.32592

Cumulative Model Updates: 3,094
Cumulative Timesteps: 25,959,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.44077
Policy Entropy: 0.94387
Value Function Loss: 2.30383

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04962
Policy Update Magnitude: 0.13915
Value Function Update Magnitude: 0.19694

Collected Steps per Second: 16,913.61464
Overall Steps per Second: 11,503.43169

Timestep Collection Time: 2.95726
Timestep Consumption Time: 1.39083
PPO Batch Consumption Time: 0.11621
Total Iteration Time: 4.34809

Cumulative Model Updates: 3,100
Cumulative Timesteps: 26,009,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 26009776...
Checkpoint 26009776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.46673
Policy Entropy: 0.91705
Value Function Loss: 2.49926

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.11557
Value Function Update Magnitude: 0.21376

Collected Steps per Second: 16,801.89533
Overall Steps per Second: 11,647.44476

Timestep Collection Time: 2.97847
Timestep Consumption Time: 1.31809
PPO Batch Consumption Time: 0.11247
Total Iteration Time: 4.29656

Cumulative Model Updates: 3,106
Cumulative Timesteps: 26,059,820

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.55925
Policy Entropy: 0.91542
Value Function Loss: 2.60246

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.11113
Value Function Update Magnitude: 0.21798

Collected Steps per Second: 17,152.58042
Overall Steps per Second: 11,681.74857

Timestep Collection Time: 2.91583
Timestep Consumption Time: 1.36555
PPO Batch Consumption Time: 0.11477
Total Iteration Time: 4.28138

Cumulative Model Updates: 3,112
Cumulative Timesteps: 26,109,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26109834...
Checkpoint 26109834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.18837
Policy Entropy: 0.90137
Value Function Loss: 2.59249

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.08725
Value Function Update Magnitude: 0.19831

Collected Steps per Second: 16,582.61720
Overall Steps per Second: 11,401.33086

Timestep Collection Time: 3.01689
Timestep Consumption Time: 1.37101
PPO Batch Consumption Time: 0.11534
Total Iteration Time: 4.38791

Cumulative Model Updates: 3,118
Cumulative Timesteps: 26,159,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.23813
Policy Entropy: 0.89686
Value Function Loss: 2.54532

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06310
Policy Update Magnitude: 0.09697
Value Function Update Magnitude: 0.19687

Collected Steps per Second: 16,962.47482
Overall Steps per Second: 11,844.61427

Timestep Collection Time: 2.94804
Timestep Consumption Time: 1.27380
PPO Batch Consumption Time: 0.11414
Total Iteration Time: 4.22183

Cumulative Model Updates: 3,124
Cumulative Timesteps: 26,209,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 26209868...
Checkpoint 26209868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.80681
Policy Entropy: 0.88248
Value Function Loss: 2.43589

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.11691
Value Function Update Magnitude: 0.21846

Collected Steps per Second: 16,789.70251
Overall Steps per Second: 11,613.61557

Timestep Collection Time: 2.97837
Timestep Consumption Time: 1.32743
PPO Batch Consumption Time: 0.11234
Total Iteration Time: 4.30581

Cumulative Model Updates: 3,130
Cumulative Timesteps: 26,259,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.57200
Policy Entropy: 0.88857
Value Function Loss: 2.43401

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.12992
Value Function Update Magnitude: 0.24459

Collected Steps per Second: 16,230.39896
Overall Steps per Second: 11,352.95958

Timestep Collection Time: 3.08113
Timestep Consumption Time: 1.32371
PPO Batch Consumption Time: 0.11206
Total Iteration Time: 4.40484

Cumulative Model Updates: 3,136
Cumulative Timesteps: 26,309,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26309882...
Checkpoint 26309882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.65459
Policy Entropy: 0.88163
Value Function Loss: 2.40026

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07091
Policy Update Magnitude: 0.10892
Value Function Update Magnitude: 0.21601

Collected Steps per Second: 17,075.68134
Overall Steps per Second: 11,949.95860

Timestep Collection Time: 2.92884
Timestep Consumption Time: 1.25628
PPO Batch Consumption Time: 0.10868
Total Iteration Time: 4.18512

Cumulative Model Updates: 3,142
Cumulative Timesteps: 26,359,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.47643
Policy Entropy: 0.89502
Value Function Loss: 2.50864

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.10406
Value Function Update Magnitude: 0.19353

Collected Steps per Second: 15,907.06995
Overall Steps per Second: 10,938.44364

Timestep Collection Time: 3.14477
Timestep Consumption Time: 1.42846
PPO Batch Consumption Time: 0.12533
Total Iteration Time: 4.57323

Cumulative Model Updates: 3,148
Cumulative Timesteps: 26,409,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26409918...
Checkpoint 26409918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.97562
Policy Entropy: 0.89467
Value Function Loss: 2.43078

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06334
Policy Update Magnitude: 0.09168
Value Function Update Magnitude: 0.18366

Collected Steps per Second: 16,284.63245
Overall Steps per Second: 11,311.28261

Timestep Collection Time: 3.07038
Timestep Consumption Time: 1.34999
PPO Batch Consumption Time: 0.11443
Total Iteration Time: 4.42037

Cumulative Model Updates: 3,154
Cumulative Timesteps: 26,459,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.31600
Policy Entropy: 0.86431
Value Function Loss: 2.26607

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05202
Policy Update Magnitude: 0.11873
Value Function Update Magnitude: 0.17449

Collected Steps per Second: 17,353.96485
Overall Steps per Second: 11,393.91083

Timestep Collection Time: 2.88199
Timestep Consumption Time: 1.50754
PPO Batch Consumption Time: 0.13491
Total Iteration Time: 4.38954

Cumulative Model Updates: 3,160
Cumulative Timesteps: 26,509,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26509932...
Checkpoint 26509932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.88410
Policy Entropy: 0.86093
Value Function Loss: 2.13780

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.12845
Value Function Update Magnitude: 0.18145

Collected Steps per Second: 16,063.81426
Overall Steps per Second: 11,157.62663

Timestep Collection Time: 3.11296
Timestep Consumption Time: 1.36882
PPO Batch Consumption Time: 0.11371
Total Iteration Time: 4.48178

Cumulative Model Updates: 3,166
Cumulative Timesteps: 26,559,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.36433
Policy Entropy: 0.87304
Value Function Loss: 2.26376

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.13139
Value Function Update Magnitude: 0.22578

Collected Steps per Second: 16,086.34340
Overall Steps per Second: 11,165.47313

Timestep Collection Time: 3.10835
Timestep Consumption Time: 1.36992
PPO Batch Consumption Time: 0.12747
Total Iteration Time: 4.47827

Cumulative Model Updates: 3,172
Cumulative Timesteps: 26,609,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26609940...
Checkpoint 26609940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.32267
Policy Entropy: 0.87045
Value Function Loss: 2.50275

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.09373
Value Function Update Magnitude: 0.25609

Collected Steps per Second: 15,780.02983
Overall Steps per Second: 10,854.33805

Timestep Collection Time: 3.16970
Timestep Consumption Time: 1.43841
PPO Batch Consumption Time: 0.12706
Total Iteration Time: 4.60811

Cumulative Model Updates: 3,178
Cumulative Timesteps: 26,659,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.87219
Policy Entropy: 0.88178
Value Function Loss: 2.54126

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.10567
Value Function Update Magnitude: 0.21801

Collected Steps per Second: 15,918.58921
Overall Steps per Second: 11,102.24723

Timestep Collection Time: 3.14174
Timestep Consumption Time: 1.36294
PPO Batch Consumption Time: 0.11943
Total Iteration Time: 4.50467

Cumulative Model Updates: 3,184
Cumulative Timesteps: 26,709,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 26709970...
Checkpoint 26709970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.41923
Policy Entropy: 0.85994
Value Function Loss: 2.39697

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.08365
Value Function Update Magnitude: 0.20163

Collected Steps per Second: 16,892.10006
Overall Steps per Second: 11,521.53088

Timestep Collection Time: 2.96174
Timestep Consumption Time: 1.38057
PPO Batch Consumption Time: 0.11564
Total Iteration Time: 4.34230

Cumulative Model Updates: 3,190
Cumulative Timesteps: 26,760,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.35185
Policy Entropy: 0.87320
Value Function Loss: 2.20009

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.07445
Value Function Update Magnitude: 0.20325

Collected Steps per Second: 16,777.32816
Overall Steps per Second: 11,252.01828

Timestep Collection Time: 2.98140
Timestep Consumption Time: 1.46402
PPO Batch Consumption Time: 0.12786
Total Iteration Time: 4.44542

Cumulative Model Updates: 3,196
Cumulative Timesteps: 26,810,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 26810020...
Checkpoint 26810020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.76929
Policy Entropy: 0.87899
Value Function Loss: 2.34066

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.07243
Value Function Update Magnitude: 0.19743

Collected Steps per Second: 15,938.93120
Overall Steps per Second: 11,225.41401

Timestep Collection Time: 3.13697
Timestep Consumption Time: 1.31721
PPO Batch Consumption Time: 0.12243
Total Iteration Time: 4.45418

Cumulative Model Updates: 3,202
Cumulative Timesteps: 26,860,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.17981
Policy Entropy: 0.88460
Value Function Loss: 2.35108

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.08237
Value Function Update Magnitude: 0.17144

Collected Steps per Second: 16,696.46955
Overall Steps per Second: 11,467.88176

Timestep Collection Time: 2.99512
Timestep Consumption Time: 1.36558
PPO Batch Consumption Time: 0.11262
Total Iteration Time: 4.36070

Cumulative Model Updates: 3,208
Cumulative Timesteps: 26,910,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26910028...
Checkpoint 26910028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.00727
Policy Entropy: 0.87426
Value Function Loss: 2.36856

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10942
Policy Update Magnitude: 0.08297
Value Function Update Magnitude: 0.17246

Collected Steps per Second: 16,675.60006
Overall Steps per Second: 11,567.69890

Timestep Collection Time: 2.99923
Timestep Consumption Time: 1.32436
PPO Batch Consumption Time: 0.11276
Total Iteration Time: 4.32359

Cumulative Model Updates: 3,214
Cumulative Timesteps: 26,960,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.09266
Policy Entropy: 0.86847
Value Function Loss: 2.25738

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.07740
Value Function Update Magnitude: 0.16148

Collected Steps per Second: 16,863.81973
Overall Steps per Second: 11,563.53379

Timestep Collection Time: 2.96611
Timestep Consumption Time: 1.35955
PPO Batch Consumption Time: 0.12753
Total Iteration Time: 4.32567

Cumulative Model Updates: 3,220
Cumulative Timesteps: 27,010,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 27010062...
Checkpoint 27010062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.58538
Policy Entropy: 0.87061
Value Function Loss: 2.31098

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.09617
Value Function Update Magnitude: 0.18015

Collected Steps per Second: 15,951.20801
Overall Steps per Second: 11,073.55532

Timestep Collection Time: 3.13481
Timestep Consumption Time: 1.38081
PPO Batch Consumption Time: 0.11723
Total Iteration Time: 4.51562

Cumulative Model Updates: 3,226
Cumulative Timesteps: 27,060,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.74248
Policy Entropy: 0.87485
Value Function Loss: 2.39129

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.09926
Value Function Update Magnitude: 0.23029

Collected Steps per Second: 16,576.92113
Overall Steps per Second: 11,631.35727

Timestep Collection Time: 3.01757
Timestep Consumption Time: 1.28305
PPO Batch Consumption Time: 0.11784
Total Iteration Time: 4.30062

Cumulative Model Updates: 3,232
Cumulative Timesteps: 27,110,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 27110088...
Checkpoint 27110088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.52423
Policy Entropy: 0.88732
Value Function Loss: 2.52172

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07178
Policy Update Magnitude: 0.08960
Value Function Update Magnitude: 0.20069

Collected Steps per Second: 17,207.21938
Overall Steps per Second: 11,776.32016

Timestep Collection Time: 2.90727
Timestep Consumption Time: 1.34075
PPO Batch Consumption Time: 0.11061
Total Iteration Time: 4.24802

Cumulative Model Updates: 3,238
Cumulative Timesteps: 27,160,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.89345
Policy Entropy: 0.87054
Value Function Loss: 2.59182

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05943
Policy Update Magnitude: 0.09829
Value Function Update Magnitude: 0.14677

Collected Steps per Second: 16,315.16298
Overall Steps per Second: 11,435.57758

Timestep Collection Time: 3.06635
Timestep Consumption Time: 1.30842
PPO Batch Consumption Time: 0.11342
Total Iteration Time: 4.37477

Cumulative Model Updates: 3,244
Cumulative Timesteps: 27,210,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27210142...
Checkpoint 27210142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.79677
Policy Entropy: 0.88022
Value Function Loss: 2.56676

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.11247
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 16,138.22486
Overall Steps per Second: 11,222.41982

Timestep Collection Time: 3.09997
Timestep Consumption Time: 1.35789
PPO Batch Consumption Time: 0.13036
Total Iteration Time: 4.45786

Cumulative Model Updates: 3,250
Cumulative Timesteps: 27,260,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.61915
Policy Entropy: 0.89111
Value Function Loss: 2.47602

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.10352
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 15,469.91219
Overall Steps per Second: 10,688.07734

Timestep Collection Time: 3.23441
Timestep Consumption Time: 1.44707
PPO Batch Consumption Time: 0.12791
Total Iteration Time: 4.68148

Cumulative Model Updates: 3,256
Cumulative Timesteps: 27,310,206

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 27310206...
Checkpoint 27310206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.17379
Policy Entropy: 0.88466
Value Function Loss: 2.46530

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06151
Policy Update Magnitude: 0.11278
Value Function Update Magnitude: 0.11016

Collected Steps per Second: 15,708.28624
Overall Steps per Second: 11,048.20325

Timestep Collection Time: 3.18533
Timestep Consumption Time: 1.34356
PPO Batch Consumption Time: 0.12863
Total Iteration Time: 4.52888

Cumulative Model Updates: 3,262
Cumulative Timesteps: 27,360,242

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.64914
Policy Entropy: 0.87309
Value Function Loss: 2.40468

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.12244
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 15,793.63123
Overall Steps per Second: 11,029.99480

Timestep Collection Time: 3.16634
Timestep Consumption Time: 1.36748
PPO Batch Consumption Time: 0.11510
Total Iteration Time: 4.53382

Cumulative Model Updates: 3,268
Cumulative Timesteps: 27,410,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27410250...
Checkpoint 27410250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.73447
Policy Entropy: 0.87491
Value Function Loss: 2.61024

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06282
Policy Update Magnitude: 0.11301
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 16,237.51714
Overall Steps per Second: 11,154.16633

Timestep Collection Time: 3.08064
Timestep Consumption Time: 1.40396
PPO Batch Consumption Time: 0.12584
Total Iteration Time: 4.48460

Cumulative Model Updates: 3,274
Cumulative Timesteps: 27,460,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.09855
Policy Entropy: 0.89102
Value Function Loss: 2.58814

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.09508
Value Function Update Magnitude: 0.10850

Collected Steps per Second: 15,574.42438
Overall Steps per Second: 11,168.68758

Timestep Collection Time: 3.21103
Timestep Consumption Time: 1.26666
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 4.47770

Cumulative Model Updates: 3,280
Cumulative Timesteps: 27,510,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 27510282...
Checkpoint 27510282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.50307
Policy Entropy: 0.89032
Value Function Loss: 2.52931

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04808
Policy Update Magnitude: 0.10994
Value Function Update Magnitude: 0.10157

Collected Steps per Second: 16,566.40348
Overall Steps per Second: 11,419.48935

Timestep Collection Time: 3.01816
Timestep Consumption Time: 1.36032
PPO Batch Consumption Time: 0.11431
Total Iteration Time: 4.37848

Cumulative Model Updates: 3,286
Cumulative Timesteps: 27,560,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.57701
Policy Entropy: 0.88160
Value Function Loss: 2.48477

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.11522
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 16,621.35996
Overall Steps per Second: 11,668.43339

Timestep Collection Time: 3.00890
Timestep Consumption Time: 1.27719
PPO Batch Consumption Time: 0.11444
Total Iteration Time: 4.28609

Cumulative Model Updates: 3,292
Cumulative Timesteps: 27,610,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 27610294...
Checkpoint 27610294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.41700
Policy Entropy: 0.86801
Value Function Loss: 2.40896

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.09436
Value Function Update Magnitude: 0.10484

Collected Steps per Second: 16,750.86278
Overall Steps per Second: 11,505.61639

Timestep Collection Time: 2.98779
Timestep Consumption Time: 1.36209
PPO Batch Consumption Time: 0.11434
Total Iteration Time: 4.34988

Cumulative Model Updates: 3,298
Cumulative Timesteps: 27,660,342

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.12196
Policy Entropy: 0.86090
Value Function Loss: 2.62102

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.09015
Value Function Update Magnitude: 0.10340

Collected Steps per Second: 16,666.84442
Overall Steps per Second: 11,514.94549

Timestep Collection Time: 3.00045
Timestep Consumption Time: 1.34243
PPO Batch Consumption Time: 0.11597
Total Iteration Time: 4.34288

Cumulative Model Updates: 3,304
Cumulative Timesteps: 27,710,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27710350...
Checkpoint 27710350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.67174
Policy Entropy: 0.87851
Value Function Loss: 2.55876

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05830
Policy Update Magnitude: 0.09757
Value Function Update Magnitude: 0.10367

Collected Steps per Second: 16,549.35904
Overall Steps per Second: 11,651.80790

Timestep Collection Time: 3.02211
Timestep Consumption Time: 1.27027
PPO Batch Consumption Time: 0.11504
Total Iteration Time: 4.29238

Cumulative Model Updates: 3,310
Cumulative Timesteps: 27,760,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.82485
Policy Entropy: 0.86846
Value Function Loss: 2.58728

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05589
Policy Update Magnitude: 0.12164
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 16,579.10945
Overall Steps per Second: 11,439.99214

Timestep Collection Time: 3.01645
Timestep Consumption Time: 1.35506
PPO Batch Consumption Time: 0.11199
Total Iteration Time: 4.37151

Cumulative Model Updates: 3,316
Cumulative Timesteps: 27,810,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 27810374...
Checkpoint 27810374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.81394
Policy Entropy: 0.86969
Value Function Loss: 2.51054

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.10080
Value Function Update Magnitude: 0.10665

Collected Steps per Second: 14,926.76389
Overall Steps per Second: 10,383.50131

Timestep Collection Time: 3.35264
Timestep Consumption Time: 1.46693
PPO Batch Consumption Time: 0.12768
Total Iteration Time: 4.81957

Cumulative Model Updates: 3,322
Cumulative Timesteps: 27,860,418

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.35382
Policy Entropy: 0.88643
Value Function Loss: 2.52462

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.09826
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 15,256.23637
Overall Steps per Second: 10,715.73556

Timestep Collection Time: 3.27905
Timestep Consumption Time: 1.38941
PPO Batch Consumption Time: 0.11424
Total Iteration Time: 4.66846

Cumulative Model Updates: 3,328
Cumulative Timesteps: 27,910,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 27910444...
Checkpoint 27910444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.24258
Policy Entropy: 0.91466
Value Function Loss: 2.59330

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.10720
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 14,092.36757
Overall Steps per Second: 9,821.50238

Timestep Collection Time: 3.54830
Timestep Consumption Time: 1.54297
PPO Batch Consumption Time: 0.14137
Total Iteration Time: 5.09128

Cumulative Model Updates: 3,334
Cumulative Timesteps: 27,960,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.14273
Policy Entropy: 0.91379
Value Function Loss: 2.57205

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.12071
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 15,997.72885
Overall Steps per Second: 11,048.00243

Timestep Collection Time: 3.12582
Timestep Consumption Time: 1.40043
PPO Batch Consumption Time: 0.13384
Total Iteration Time: 4.52625

Cumulative Model Updates: 3,340
Cumulative Timesteps: 28,010,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 28010454...
Checkpoint 28010454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.92809
Policy Entropy: 0.91724
Value Function Loss: 2.52426

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.12480
Value Function Update Magnitude: 0.09649

Collected Steps per Second: 14,392.78249
Overall Steps per Second: 9,950.07425

Timestep Collection Time: 3.47674
Timestep Consumption Time: 1.55237
PPO Batch Consumption Time: 0.13740
Total Iteration Time: 5.02911

Cumulative Model Updates: 3,346
Cumulative Timesteps: 28,060,494

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.80551
Policy Entropy: 0.92468
Value Function Loss: 2.47984

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.10038
Value Function Update Magnitude: 0.09816

Collected Steps per Second: 14,796.21182
Overall Steps per Second: 10,327.92141

Timestep Collection Time: 3.38114
Timestep Consumption Time: 1.46282
PPO Batch Consumption Time: 0.12726
Total Iteration Time: 4.84396

Cumulative Model Updates: 3,352
Cumulative Timesteps: 28,110,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28110522...
Checkpoint 28110522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.38595
Policy Entropy: 0.92532
Value Function Loss: 2.41982

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.10498
Value Function Update Magnitude: 0.11324

Collected Steps per Second: 13,879.49456
Overall Steps per Second: 10,022.05047

Timestep Collection Time: 3.60575
Timestep Consumption Time: 1.38784
PPO Batch Consumption Time: 0.11940
Total Iteration Time: 4.99359

Cumulative Model Updates: 3,358
Cumulative Timesteps: 28,160,568

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.45516
Policy Entropy: 0.91825
Value Function Loss: 2.33614

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.10757
Value Function Update Magnitude: 0.11838

Collected Steps per Second: 14,395.51387
Overall Steps per Second: 10,176.97382

Timestep Collection Time: 3.47553
Timestep Consumption Time: 1.44067
PPO Batch Consumption Time: 0.11460
Total Iteration Time: 4.91620

Cumulative Model Updates: 3,364
Cumulative Timesteps: 28,210,600

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 28210600...
Checkpoint 28210600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.28952
Policy Entropy: 0.92387
Value Function Loss: 2.32118

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.10938
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 15,365.23703
Overall Steps per Second: 10,862.60080

Timestep Collection Time: 3.25605
Timestep Consumption Time: 1.34966
PPO Batch Consumption Time: 0.11475
Total Iteration Time: 4.60571

Cumulative Model Updates: 3,370
Cumulative Timesteps: 28,260,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.19664
Policy Entropy: 0.92045
Value Function Loss: 2.29706

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06434
Policy Update Magnitude: 0.09670
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 17,127.01646
Overall Steps per Second: 11,571.70644

Timestep Collection Time: 2.91971
Timestep Consumption Time: 1.40169
PPO Batch Consumption Time: 0.12364
Total Iteration Time: 4.32140

Cumulative Model Updates: 3,376
Cumulative Timesteps: 28,310,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 28310636...
Checkpoint 28310636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.21292
Policy Entropy: 0.93034
Value Function Loss: 2.49408

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06234
Policy Update Magnitude: 0.08456
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 15,022.96174
Overall Steps per Second: 10,558.25585

Timestep Collection Time: 3.32904
Timestep Consumption Time: 1.40773
PPO Batch Consumption Time: 0.11927
Total Iteration Time: 4.73677

Cumulative Model Updates: 3,382
Cumulative Timesteps: 28,360,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.14557
Policy Entropy: 0.94121
Value Function Loss: 2.46164

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05602
Policy Update Magnitude: 0.09379
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 16,071.22585
Overall Steps per Second: 10,973.11580

Timestep Collection Time: 3.11127
Timestep Consumption Time: 1.44550
PPO Batch Consumption Time: 0.12186
Total Iteration Time: 4.55677

Cumulative Model Updates: 3,388
Cumulative Timesteps: 28,410,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 28410650...
Checkpoint 28410650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.47355
Policy Entropy: 0.93622
Value Function Loss: 2.52948

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.11096
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 15,670.57280
Overall Steps per Second: 10,783.16521

Timestep Collection Time: 3.19146
Timestep Consumption Time: 1.44651
PPO Batch Consumption Time: 0.12600
Total Iteration Time: 4.63797

Cumulative Model Updates: 3,394
Cumulative Timesteps: 28,460,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.04457
Policy Entropy: 0.93670
Value Function Loss: 2.42126

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.12080
Value Function Update Magnitude: 0.10838

Collected Steps per Second: 15,174.74803
Overall Steps per Second: 10,432.60678

Timestep Collection Time: 3.29653
Timestep Consumption Time: 1.49844
PPO Batch Consumption Time: 0.13155
Total Iteration Time: 4.79497

Cumulative Model Updates: 3,400
Cumulative Timesteps: 28,510,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28510686...
Checkpoint 28510686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.60183
Policy Entropy: 0.93368
Value Function Loss: 2.52494

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.10079
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 13,633.58179
Overall Steps per Second: 9,792.06774

Timestep Collection Time: 3.66859
Timestep Consumption Time: 1.43922
PPO Batch Consumption Time: 0.13654
Total Iteration Time: 5.10781

Cumulative Model Updates: 3,406
Cumulative Timesteps: 28,560,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.37161
Policy Entropy: 0.92319
Value Function Loss: 2.47994

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06984
Policy Update Magnitude: 0.10156
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 14,584.82539
Overall Steps per Second: 10,101.44576

Timestep Collection Time: 3.43165
Timestep Consumption Time: 1.52309
PPO Batch Consumption Time: 0.13182
Total Iteration Time: 4.95474

Cumulative Model Updates: 3,412
Cumulative Timesteps: 28,610,752

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 28610752...
Checkpoint 28610752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.42311
Policy Entropy: 0.91994
Value Function Loss: 2.53117

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.11419
Value Function Update Magnitude: 0.11793

Collected Steps per Second: 14,131.20969
Overall Steps per Second: 9,839.65779

Timestep Collection Time: 3.54011
Timestep Consumption Time: 1.54401
PPO Batch Consumption Time: 0.14163
Total Iteration Time: 5.08412

Cumulative Model Updates: 3,418
Cumulative Timesteps: 28,660,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.24392
Policy Entropy: 0.93232
Value Function Loss: 2.54101

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.13178
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 14,480.25745
Overall Steps per Second: 9,995.53897

Timestep Collection Time: 3.45312
Timestep Consumption Time: 1.54932
PPO Batch Consumption Time: 0.15654
Total Iteration Time: 5.00243

Cumulative Model Updates: 3,424
Cumulative Timesteps: 28,710,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 28710780...
Checkpoint 28710780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.28588
Policy Entropy: 0.91245
Value Function Loss: 2.71628

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06022
Policy Update Magnitude: 0.12997
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 14,632.64754
Overall Steps per Second: 10,089.42465

Timestep Collection Time: 3.41866
Timestep Consumption Time: 1.53941
PPO Batch Consumption Time: 0.13653
Total Iteration Time: 4.95806

Cumulative Model Updates: 3,430
Cumulative Timesteps: 28,760,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.29693
Policy Entropy: 0.93106
Value Function Loss: 2.67341

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05593
Policy Update Magnitude: 0.13430
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 14,138.98263
Overall Steps per Second: 9,965.32486

Timestep Collection Time: 3.53972
Timestep Consumption Time: 1.48250
PPO Batch Consumption Time: 0.13476
Total Iteration Time: 5.02221

Cumulative Model Updates: 3,436
Cumulative Timesteps: 28,810,852

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 28810852...
Checkpoint 28810852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.77114
Policy Entropy: 0.92605
Value Function Loss: 2.61673

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.10874
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 14,399.38199
Overall Steps per Second: 9,996.38501

Timestep Collection Time: 3.47362
Timestep Consumption Time: 1.52999
PPO Batch Consumption Time: 0.13610
Total Iteration Time: 5.00361

Cumulative Model Updates: 3,442
Cumulative Timesteps: 28,860,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.92706
Policy Entropy: 0.92435
Value Function Loss: 2.56547

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.09860
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 14,045.85264
Overall Steps per Second: 9,427.41338

Timestep Collection Time: 3.56062
Timestep Consumption Time: 1.74433
PPO Batch Consumption Time: 0.15650
Total Iteration Time: 5.30495

Cumulative Model Updates: 3,448
Cumulative Timesteps: 28,910,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 28910882...
Checkpoint 28910882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.90097
Policy Entropy: 0.90795
Value Function Loss: 2.61762

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.08911
Value Function Update Magnitude: 0.11854

Collected Steps per Second: 13,726.57800
Overall Steps per Second: 9,474.36979

Timestep Collection Time: 3.64505
Timestep Consumption Time: 1.63594
PPO Batch Consumption Time: 0.15428
Total Iteration Time: 5.28098

Cumulative Model Updates: 3,454
Cumulative Timesteps: 28,960,916

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.50852
Policy Entropy: 0.90692
Value Function Loss: 2.58150

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.09361
Value Function Update Magnitude: 0.11662

Collected Steps per Second: 15,182.09665
Overall Steps per Second: 10,325.36185

Timestep Collection Time: 3.29348
Timestep Consumption Time: 1.54915
PPO Batch Consumption Time: 0.13932
Total Iteration Time: 4.84264

Cumulative Model Updates: 3,460
Cumulative Timesteps: 29,010,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 29010918...
Checkpoint 29010918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.33518
Policy Entropy: 0.91210
Value Function Loss: 2.60752

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05680
Policy Update Magnitude: 0.09361
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 14,840.99198
Overall Steps per Second: 10,135.80167

Timestep Collection Time: 3.37093
Timestep Consumption Time: 1.56484
PPO Batch Consumption Time: 0.14235
Total Iteration Time: 4.93577

Cumulative Model Updates: 3,466
Cumulative Timesteps: 29,060,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.97000
Policy Entropy: 0.92682
Value Function Loss: 2.47015

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.09564
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 14,964.88235
Overall Steps per Second: 10,458.20595

Timestep Collection Time: 3.34356
Timestep Consumption Time: 1.44082
PPO Batch Consumption Time: 0.13883
Total Iteration Time: 4.78438

Cumulative Model Updates: 3,472
Cumulative Timesteps: 29,110,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 29110982...
Checkpoint 29110982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.03591
Policy Entropy: 0.92812
Value Function Loss: 2.53616

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05437
Policy Update Magnitude: 0.10033
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 14,627.17705
Overall Steps per Second: 9,976.56363

Timestep Collection Time: 3.41925
Timestep Consumption Time: 1.59390
PPO Batch Consumption Time: 0.14782
Total Iteration Time: 5.01315

Cumulative Model Updates: 3,478
Cumulative Timesteps: 29,160,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.55573
Policy Entropy: 0.91060
Value Function Loss: 2.37329

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04473
Policy Update Magnitude: 0.11313
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 15,279.03996
Overall Steps per Second: 10,492.15859

Timestep Collection Time: 3.27377
Timestep Consumption Time: 1.49360
PPO Batch Consumption Time: 0.13700
Total Iteration Time: 4.76737

Cumulative Model Updates: 3,484
Cumulative Timesteps: 29,211,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29211016...
Checkpoint 29211016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.13329
Policy Entropy: 0.90412
Value Function Loss: 2.39331

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.13451
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 15,043.92177
Overall Steps per Second: 10,650.76670

Timestep Collection Time: 3.32440
Timestep Consumption Time: 1.37123
PPO Batch Consumption Time: 0.12676
Total Iteration Time: 4.69562

Cumulative Model Updates: 3,490
Cumulative Timesteps: 29,261,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.04384
Policy Entropy: 0.91085
Value Function Loss: 2.43867

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.11824
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 14,534.13571
Overall Steps per Second: 10,131.05431

Timestep Collection Time: 3.44128
Timestep Consumption Time: 1.49562
PPO Batch Consumption Time: 0.12888
Total Iteration Time: 4.93690

Cumulative Model Updates: 3,496
Cumulative Timesteps: 29,311,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 29311044...
Checkpoint 29311044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.86434
Policy Entropy: 0.91753
Value Function Loss: 2.48025

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.09964
Value Function Update Magnitude: 0.11860

Collected Steps per Second: 14,439.03542
Overall Steps per Second: 9,936.26128

Timestep Collection Time: 3.46602
Timestep Consumption Time: 1.57068
PPO Batch Consumption Time: 0.14369
Total Iteration Time: 5.03670

Cumulative Model Updates: 3,502
Cumulative Timesteps: 29,361,090

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.20706
Policy Entropy: 0.92421
Value Function Loss: 2.36267

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.10512
Value Function Update Magnitude: 0.18748

Collected Steps per Second: 15,902.83505
Overall Steps per Second: 10,866.82614

Timestep Collection Time: 3.14472
Timestep Consumption Time: 1.45736
PPO Batch Consumption Time: 0.12505
Total Iteration Time: 4.60208

Cumulative Model Updates: 3,508
Cumulative Timesteps: 29,411,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 29411100...
Checkpoint 29411100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.57232
Policy Entropy: 0.90900
Value Function Loss: 2.30909

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.10042
Value Function Update Magnitude: 0.17093

Collected Steps per Second: 15,752.79478
Overall Steps per Second: 10,790.37047

Timestep Collection Time: 3.17455
Timestep Consumption Time: 1.45995
PPO Batch Consumption Time: 0.13130
Total Iteration Time: 4.63450

Cumulative Model Updates: 3,514
Cumulative Timesteps: 29,461,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.18922
Policy Entropy: 0.91545
Value Function Loss: 2.21771

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.09604
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 15,494.00423
Overall Steps per Second: 10,655.58868

Timestep Collection Time: 3.22744
Timestep Consumption Time: 1.46549
PPO Batch Consumption Time: 0.14413
Total Iteration Time: 4.69294

Cumulative Model Updates: 3,520
Cumulative Timesteps: 29,511,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 29511114...
Checkpoint 29511114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.95440
Policy Entropy: 0.90332
Value Function Loss: 2.31178

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.10740
Value Function Update Magnitude: 0.15593

Collected Steps per Second: 15,705.28493
Overall Steps per Second: 10,802.44026

Timestep Collection Time: 3.18364
Timestep Consumption Time: 1.44494
PPO Batch Consumption Time: 0.12305
Total Iteration Time: 4.62858

Cumulative Model Updates: 3,526
Cumulative Timesteps: 29,561,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.66971
Policy Entropy: 0.88633
Value Function Loss: 2.30017

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.09395
Value Function Update Magnitude: 0.19681

Collected Steps per Second: 15,924.75171
Overall Steps per Second: 10,827.50455

Timestep Collection Time: 3.14215
Timestep Consumption Time: 1.47923
PPO Batch Consumption Time: 0.13227
Total Iteration Time: 4.62138

Cumulative Model Updates: 3,532
Cumulative Timesteps: 29,611,152

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 29611152...
Checkpoint 29611152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.75131
Policy Entropy: 0.89035
Value Function Loss: 2.26648

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.09613
Value Function Update Magnitude: 0.18009

Collected Steps per Second: 15,608.30099
Overall Steps per Second: 10,519.07391

Timestep Collection Time: 3.20406
Timestep Consumption Time: 1.55016
PPO Batch Consumption Time: 0.14474
Total Iteration Time: 4.75422

Cumulative Model Updates: 3,538
Cumulative Timesteps: 29,661,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.38417
Policy Entropy: 0.89582
Value Function Loss: 2.28853

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.10381
Value Function Update Magnitude: 0.17930

Collected Steps per Second: 15,915.78392
Overall Steps per Second: 10,943.73715

Timestep Collection Time: 3.14443
Timestep Consumption Time: 1.42860
PPO Batch Consumption Time: 0.12518
Total Iteration Time: 4.57303

Cumulative Model Updates: 3,544
Cumulative Timesteps: 29,711,208

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 29711208...
Checkpoint 29711208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.33223
Policy Entropy: 0.90795
Value Function Loss: 2.17313

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.12999
Value Function Update Magnitude: 0.18525

Collected Steps per Second: 15,534.85119
Overall Steps per Second: 10,898.42570

Timestep Collection Time: 3.21973
Timestep Consumption Time: 1.36974
PPO Batch Consumption Time: 0.12683
Total Iteration Time: 4.58947

Cumulative Model Updates: 3,550
Cumulative Timesteps: 29,761,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.95012
Policy Entropy: 0.89619
Value Function Loss: 2.16810

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.12287
Value Function Update Magnitude: 0.18628

Collected Steps per Second: 16,152.36905
Overall Steps per Second: 10,777.73403

Timestep Collection Time: 3.09701
Timestep Consumption Time: 1.54441
PPO Batch Consumption Time: 0.14333
Total Iteration Time: 4.64142

Cumulative Model Updates: 3,556
Cumulative Timesteps: 29,811,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 29811250...
Checkpoint 29811250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.54642
Policy Entropy: 0.88730
Value Function Loss: 2.10460

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.09704
Value Function Update Magnitude: 0.17688

Collected Steps per Second: 15,395.37574
Overall Steps per Second: 10,683.04320

Timestep Collection Time: 3.24968
Timestep Consumption Time: 1.43345
PPO Batch Consumption Time: 0.12187
Total Iteration Time: 4.68312

Cumulative Model Updates: 3,562
Cumulative Timesteps: 29,861,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.06067
Policy Entropy: 0.86811
Value Function Loss: 2.15271

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.12184
Value Function Update Magnitude: 0.17408

Collected Steps per Second: 17,611.02075
Overall Steps per Second: 11,479.17452

Timestep Collection Time: 2.84072
Timestep Consumption Time: 1.51743
PPO Batch Consumption Time: 0.13814
Total Iteration Time: 4.35815

Cumulative Model Updates: 3,568
Cumulative Timesteps: 29,911,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 29911308...
Checkpoint 29911308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.94118
Policy Entropy: 0.87841
Value Function Loss: 2.14279

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.13768
Value Function Update Magnitude: 0.25461

Collected Steps per Second: 15,675.93675
Overall Steps per Second: 10,584.89945

Timestep Collection Time: 3.19241
Timestep Consumption Time: 1.53546
PPO Batch Consumption Time: 0.13754
Total Iteration Time: 4.72787

Cumulative Model Updates: 3,574
Cumulative Timesteps: 29,961,352

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.49035
Policy Entropy: 0.87640
Value Function Loss: 2.22409

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05672
Policy Update Magnitude: 0.11580
Value Function Update Magnitude: 0.23045

Collected Steps per Second: 15,993.96554
Overall Steps per Second: 11,061.04114

Timestep Collection Time: 3.12843
Timestep Consumption Time: 1.39519
PPO Batch Consumption Time: 0.13269
Total Iteration Time: 4.52362

Cumulative Model Updates: 3,580
Cumulative Timesteps: 30,011,388

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 30011388...
Checkpoint 30011388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.19782
Policy Entropy: 0.88235
Value Function Loss: 2.31576

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05963
Policy Update Magnitude: 0.10937
Value Function Update Magnitude: 0.22410

Collected Steps per Second: 15,672.44551
Overall Steps per Second: 10,702.68302

Timestep Collection Time: 3.19057
Timestep Consumption Time: 1.48153
PPO Batch Consumption Time: 0.13275
Total Iteration Time: 4.67210

Cumulative Model Updates: 3,586
Cumulative Timesteps: 30,061,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.53286
Policy Entropy: 0.87473
Value Function Loss: 2.34441

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06089
Policy Update Magnitude: 0.11103
Value Function Update Magnitude: 0.25815

Collected Steps per Second: 15,680.03890
Overall Steps per Second: 10,824.91203

Timestep Collection Time: 3.18902
Timestep Consumption Time: 1.43032
PPO Batch Consumption Time: 0.12945
Total Iteration Time: 4.61934

Cumulative Model Updates: 3,592
Cumulative Timesteps: 30,111,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 30111396...
Checkpoint 30111396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.19753
Policy Entropy: 0.86713
Value Function Loss: 2.29753

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.11786
Value Function Update Magnitude: 0.27667

Collected Steps per Second: 15,929.89571
Overall Steps per Second: 11,007.91993

Timestep Collection Time: 3.13875
Timestep Consumption Time: 1.40343
PPO Batch Consumption Time: 0.13348
Total Iteration Time: 4.54218

Cumulative Model Updates: 3,598
Cumulative Timesteps: 30,161,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.28600
Policy Entropy: 0.85778
Value Function Loss: 2.22498

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05648
Policy Update Magnitude: 0.12353
Value Function Update Magnitude: 0.25568

Collected Steps per Second: 15,723.92748
Overall Steps per Second: 10,691.65228

Timestep Collection Time: 3.18038
Timestep Consumption Time: 1.49692
PPO Batch Consumption Time: 0.13320
Total Iteration Time: 4.67729

Cumulative Model Updates: 3,604
Cumulative Timesteps: 30,211,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30211404...
Checkpoint 30211404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.83409
Policy Entropy: 0.84477
Value Function Loss: 2.19734

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05714
Policy Update Magnitude: 0.11321
Value Function Update Magnitude: 0.21487

Collected Steps per Second: 15,913.26650
Overall Steps per Second: 10,884.41469

Timestep Collection Time: 3.14517
Timestep Consumption Time: 1.45314
PPO Batch Consumption Time: 0.13348
Total Iteration Time: 4.59832

Cumulative Model Updates: 3,610
Cumulative Timesteps: 30,261,454

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.74125
Policy Entropy: 0.84718
Value Function Loss: 2.08525

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05632
Policy Update Magnitude: 0.09881
Value Function Update Magnitude: 0.22258

Collected Steps per Second: 16,341.12722
Overall Steps per Second: 10,966.34739

Timestep Collection Time: 3.06160
Timestep Consumption Time: 1.50054
PPO Batch Consumption Time: 0.13313
Total Iteration Time: 4.56214

Cumulative Model Updates: 3,616
Cumulative Timesteps: 30,311,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 30311484...
Checkpoint 30311484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.58464
Policy Entropy: 0.84160
Value Function Loss: 2.06543

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.09910
Value Function Update Magnitude: 0.21818

Collected Steps per Second: 15,874.47719
Overall Steps per Second: 10,776.06426

Timestep Collection Time: 3.15110
Timestep Consumption Time: 1.49086
PPO Batch Consumption Time: 0.13584
Total Iteration Time: 4.64195

Cumulative Model Updates: 3,622
Cumulative Timesteps: 30,361,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.45094
Policy Entropy: 0.84193
Value Function Loss: 2.04625

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.09403
Value Function Update Magnitude: 0.18630

Collected Steps per Second: 15,364.71769
Overall Steps per Second: 10,735.31612

Timestep Collection Time: 3.25434
Timestep Consumption Time: 1.40337
PPO Batch Consumption Time: 0.13277
Total Iteration Time: 4.65771

Cumulative Model Updates: 3,628
Cumulative Timesteps: 30,411,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 30411508...
Checkpoint 30411508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.77459
Policy Entropy: 0.83601
Value Function Loss: 2.08983

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.09723
Value Function Update Magnitude: 0.18631

Collected Steps per Second: 16,085.28746
Overall Steps per Second: 10,843.07075

Timestep Collection Time: 3.11005
Timestep Consumption Time: 1.50359
PPO Batch Consumption Time: 0.13485
Total Iteration Time: 4.61364

Cumulative Model Updates: 3,634
Cumulative Timesteps: 30,461,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.00895
Policy Entropy: 0.81243
Value Function Loss: 2.09206

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05816
Policy Update Magnitude: 0.11266
Value Function Update Magnitude: 0.20036

Collected Steps per Second: 15,706.31015
Overall Steps per Second: 10,667.58915

Timestep Collection Time: 3.18382
Timestep Consumption Time: 1.50384
PPO Batch Consumption Time: 0.13759
Total Iteration Time: 4.68766

Cumulative Model Updates: 3,640
Cumulative Timesteps: 30,511,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 30511540...
Checkpoint 30511540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.56355
Policy Entropy: 0.80727
Value Function Loss: 2.17483

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05145
Policy Update Magnitude: 0.10664
Value Function Update Magnitude: 0.23569

Collected Steps per Second: 14,004.06303
Overall Steps per Second: 9,816.29422

Timestep Collection Time: 3.57054
Timestep Consumption Time: 1.52324
PPO Batch Consumption Time: 0.13307
Total Iteration Time: 5.09378

Cumulative Model Updates: 3,646
Cumulative Timesteps: 30,561,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.56690
Policy Entropy: 0.80023
Value Function Loss: 2.23613

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.10217
Value Function Update Magnitude: 0.23286

Collected Steps per Second: 15,082.37207
Overall Steps per Second: 10,245.13535

Timestep Collection Time: 3.31513
Timestep Consumption Time: 1.56524
PPO Batch Consumption Time: 0.14474
Total Iteration Time: 4.88036

Cumulative Model Updates: 3,652
Cumulative Timesteps: 30,611,542

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 30611542...
Checkpoint 30611542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.22784
Policy Entropy: 0.81020
Value Function Loss: 2.26492

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05579
Policy Update Magnitude: 0.09867
Value Function Update Magnitude: 0.24945

Collected Steps per Second: 15,391.99052
Overall Steps per Second: 10,622.63493

Timestep Collection Time: 3.24896
Timestep Consumption Time: 1.45872
PPO Batch Consumption Time: 0.13011
Total Iteration Time: 4.70768

Cumulative Model Updates: 3,658
Cumulative Timesteps: 30,661,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.37374
Policy Entropy: 0.81911
Value Function Loss: 2.17271

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06477
Policy Update Magnitude: 0.09047
Value Function Update Magnitude: 0.24474

Collected Steps per Second: 15,410.66947
Overall Steps per Second: 10,422.83839

Timestep Collection Time: 3.24502
Timestep Consumption Time: 1.55290
PPO Batch Consumption Time: 0.14098
Total Iteration Time: 4.79793

Cumulative Model Updates: 3,664
Cumulative Timesteps: 30,711,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30711558...
Checkpoint 30711558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.51947
Policy Entropy: 0.82312
Value Function Loss: 2.17497

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.10783
Value Function Update Magnitude: 0.29027

Collected Steps per Second: 14,985.01813
Overall Steps per Second: 10,370.30114

Timestep Collection Time: 3.33813
Timestep Consumption Time: 1.48545
PPO Batch Consumption Time: 0.13237
Total Iteration Time: 4.82358

Cumulative Model Updates: 3,670
Cumulative Timesteps: 30,761,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.22699
Policy Entropy: 0.81673
Value Function Loss: 2.24108

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.10139
Value Function Update Magnitude: 0.25728

Collected Steps per Second: 14,710.53687
Overall Steps per Second: 10,347.23384

Timestep Collection Time: 3.40056
Timestep Consumption Time: 1.43397
PPO Batch Consumption Time: 0.12215
Total Iteration Time: 4.83453

Cumulative Model Updates: 3,676
Cumulative Timesteps: 30,811,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 30811604...
Checkpoint 30811604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.01219
Policy Entropy: 0.82004
Value Function Loss: 2.28950

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06023
Policy Update Magnitude: 0.10334
Value Function Update Magnitude: 0.24880

Collected Steps per Second: 15,145.05714
Overall Steps per Second: 10,426.25611

Timestep Collection Time: 3.30339
Timestep Consumption Time: 1.49507
PPO Batch Consumption Time: 0.13311
Total Iteration Time: 4.79846

Cumulative Model Updates: 3,682
Cumulative Timesteps: 30,861,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.83339
Policy Entropy: 0.82854
Value Function Loss: 2.32511

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.11088
Value Function Update Magnitude: 0.19703

Collected Steps per Second: 16,747.57465
Overall Steps per Second: 11,191.28959

Timestep Collection Time: 2.98598
Timestep Consumption Time: 1.48249
PPO Batch Consumption Time: 0.12897
Total Iteration Time: 4.46848

Cumulative Model Updates: 3,688
Cumulative Timesteps: 30,911,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30911642...
Checkpoint 30911642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.00223
Policy Entropy: 0.83274
Value Function Loss: 2.29310

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.10584
Value Function Update Magnitude: 0.18788

Collected Steps per Second: 15,646.29110
Overall Steps per Second: 10,772.80176

Timestep Collection Time: 3.19705
Timestep Consumption Time: 1.44631
PPO Batch Consumption Time: 0.12829
Total Iteration Time: 4.64336

Cumulative Model Updates: 3,694
Cumulative Timesteps: 30,961,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.05123
Policy Entropy: 0.83229
Value Function Loss: 2.24376

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.09691
Value Function Update Magnitude: 0.17694

Collected Steps per Second: 16,063.21972
Overall Steps per Second: 10,987.97383

Timestep Collection Time: 3.11432
Timestep Consumption Time: 1.43848
PPO Batch Consumption Time: 0.12626
Total Iteration Time: 4.55280

Cumulative Model Updates: 3,700
Cumulative Timesteps: 31,011,690

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 31011690...
Checkpoint 31011690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.53869
Policy Entropy: 0.82991
Value Function Loss: 2.06817

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05692
Policy Update Magnitude: 0.10550
Value Function Update Magnitude: 0.17513

Collected Steps per Second: 15,865.07064
Overall Steps per Second: 11,030.77974

Timestep Collection Time: 3.15233
Timestep Consumption Time: 1.38153
PPO Batch Consumption Time: 0.11500
Total Iteration Time: 4.53386

Cumulative Model Updates: 3,706
Cumulative Timesteps: 31,061,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.84562
Policy Entropy: 0.81804
Value Function Loss: 2.01076

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06334
Policy Update Magnitude: 0.10410
Value Function Update Magnitude: 0.16467

Collected Steps per Second: 16,788.84356
Overall Steps per Second: 11,717.28781

Timestep Collection Time: 2.97817
Timestep Consumption Time: 1.28903
PPO Batch Consumption Time: 0.11342
Total Iteration Time: 4.26720

Cumulative Model Updates: 3,712
Cumulative Timesteps: 31,111,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31111702...
Checkpoint 31111702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.06550
Policy Entropy: 0.82004
Value Function Loss: 2.11705

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04713
Policy Update Magnitude: 0.11131
Value Function Update Magnitude: 0.21819

Collected Steps per Second: 16,337.48669
Overall Steps per Second: 11,065.91884

Timestep Collection Time: 3.06143
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.13043
Total Iteration Time: 4.51982

Cumulative Model Updates: 3,718
Cumulative Timesteps: 31,161,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.00026
Policy Entropy: 0.79977
Value Function Loss: 2.14675

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.10325
Value Function Update Magnitude: 0.24957

Collected Steps per Second: 16,107.39966
Overall Steps per Second: 11,075.35010

Timestep Collection Time: 3.10665
Timestep Consumption Time: 1.41149
PPO Batch Consumption Time: 0.12508
Total Iteration Time: 4.51814

Cumulative Model Updates: 3,724
Cumulative Timesteps: 31,211,758

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 31211758...
Checkpoint 31211758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.44205
Policy Entropy: 0.81725
Value Function Loss: 2.19597

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.10747
Value Function Update Magnitude: 0.25740

Collected Steps per Second: 16,203.67250
Overall Steps per Second: 11,057.38805

Timestep Collection Time: 3.08646
Timestep Consumption Time: 1.43649
PPO Batch Consumption Time: 0.12620
Total Iteration Time: 4.52295

Cumulative Model Updates: 3,730
Cumulative Timesteps: 31,261,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.63701
Policy Entropy: 0.80721
Value Function Loss: 2.10455

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.10176
Value Function Update Magnitude: 0.24734

Collected Steps per Second: 16,593.01817
Overall Steps per Second: 11,319.92734

Timestep Collection Time: 3.01380
Timestep Consumption Time: 1.40390
PPO Batch Consumption Time: 0.11626
Total Iteration Time: 4.41770

Cumulative Model Updates: 3,736
Cumulative Timesteps: 31,311,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31311778...
Checkpoint 31311778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.54303
Policy Entropy: 0.81158
Value Function Loss: 2.14137

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.10606
Value Function Update Magnitude: 0.29591

Collected Steps per Second: 16,324.75636
Overall Steps per Second: 11,363.80240

Timestep Collection Time: 3.06332
Timestep Consumption Time: 1.33732
PPO Batch Consumption Time: 0.11298
Total Iteration Time: 4.40064

Cumulative Model Updates: 3,742
Cumulative Timesteps: 31,361,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.52932
Policy Entropy: 0.80214
Value Function Loss: 2.14739

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04645
Policy Update Magnitude: 0.11308
Value Function Update Magnitude: 0.29537

Collected Steps per Second: 17,437.50819
Overall Steps per Second: 11,634.15291

Timestep Collection Time: 2.86899
Timestep Consumption Time: 1.43111
PPO Batch Consumption Time: 0.12403
Total Iteration Time: 4.30010

Cumulative Model Updates: 3,748
Cumulative Timesteps: 31,411,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 31411814...
Checkpoint 31411814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.73025
Policy Entropy: 0.80039
Value Function Loss: 2.14884

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.10043
Value Function Update Magnitude: 0.27310

Collected Steps per Second: 16,706.73093
Overall Steps per Second: 11,376.76226

Timestep Collection Time: 2.99352
Timestep Consumption Time: 1.40245
PPO Batch Consumption Time: 0.11689
Total Iteration Time: 4.39598

Cumulative Model Updates: 3,754
Cumulative Timesteps: 31,461,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.89988
Policy Entropy: 0.78275
Value Function Loss: 2.13208

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06040
Policy Update Magnitude: 0.10021
Value Function Update Magnitude: 0.23649

Collected Steps per Second: 16,480.70349
Overall Steps per Second: 11,680.97394

Timestep Collection Time: 3.03458
Timestep Consumption Time: 1.24691
PPO Batch Consumption Time: 0.11064
Total Iteration Time: 4.28149

Cumulative Model Updates: 3,760
Cumulative Timesteps: 31,511,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31511838...
Checkpoint 31511838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.34633
Policy Entropy: 0.77937
Value Function Loss: 2.20522

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.09515
Value Function Update Magnitude: 0.19442

Collected Steps per Second: 16,615.50948
Overall Steps per Second: 11,274.15589

Timestep Collection Time: 3.01020
Timestep Consumption Time: 1.42614
PPO Batch Consumption Time: 0.12334
Total Iteration Time: 4.43634

Cumulative Model Updates: 3,766
Cumulative Timesteps: 31,561,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.78485
Policy Entropy: 0.78091
Value Function Loss: 2.20405

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.08505
Value Function Update Magnitude: 0.17953

Collected Steps per Second: 15,698.80789
Overall Steps per Second: 11,114.65411

Timestep Collection Time: 3.18572
Timestep Consumption Time: 1.31393
PPO Batch Consumption Time: 0.11030
Total Iteration Time: 4.49965

Cumulative Model Updates: 3,772
Cumulative Timesteps: 31,611,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31611866...
Checkpoint 31611866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.32372
Policy Entropy: 0.78235
Value Function Loss: 2.12893

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05008
Policy Update Magnitude: 0.12195
Value Function Update Magnitude: 0.17694

Collected Steps per Second: 16,141.51401
Overall Steps per Second: 11,013.42974

Timestep Collection Time: 3.09872
Timestep Consumption Time: 1.44283
PPO Batch Consumption Time: 0.12661
Total Iteration Time: 4.54155

Cumulative Model Updates: 3,778
Cumulative Timesteps: 31,661,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.34412
Policy Entropy: 0.76522
Value Function Loss: 1.96480

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.14010
Value Function Update Magnitude: 0.20794

Collected Steps per Second: 15,462.73101
Overall Steps per Second: 10,688.30852

Timestep Collection Time: 3.23436
Timestep Consumption Time: 1.44477
PPO Batch Consumption Time: 0.12683
Total Iteration Time: 4.67913

Cumulative Model Updates: 3,784
Cumulative Timesteps: 31,711,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31711896...
Checkpoint 31711896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.92433
Policy Entropy: 0.77879
Value Function Loss: 2.03584

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.17323

Collected Steps per Second: 16,174.55610
Overall Steps per Second: 11,030.37203

Timestep Collection Time: 3.09214
Timestep Consumption Time: 1.44207
PPO Batch Consumption Time: 0.12838
Total Iteration Time: 4.53421

Cumulative Model Updates: 3,790
Cumulative Timesteps: 31,761,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.84346
Policy Entropy: 0.75953
Value Function Loss: 2.20380

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05693
Policy Update Magnitude: 0.09948
Value Function Update Magnitude: 0.16306

Collected Steps per Second: 16,041.34715
Overall Steps per Second: 10,989.10729

Timestep Collection Time: 3.11919
Timestep Consumption Time: 1.43405
PPO Batch Consumption Time: 0.12438
Total Iteration Time: 4.55324

Cumulative Model Updates: 3,796
Cumulative Timesteps: 31,811,946

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 31811946...
Checkpoint 31811946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.45221
Policy Entropy: 0.76422
Value Function Loss: 2.26924

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.11092
Value Function Update Magnitude: 0.16164

Collected Steps per Second: 16,145.29409
Overall Steps per Second: 11,047.31800

Timestep Collection Time: 3.09750
Timestep Consumption Time: 1.42939
PPO Batch Consumption Time: 0.12727
Total Iteration Time: 4.52689

Cumulative Model Updates: 3,802
Cumulative Timesteps: 31,861,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.60351
Policy Entropy: 0.75876
Value Function Loss: 2.21995

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04677
Policy Update Magnitude: 0.11414
Value Function Update Magnitude: 0.16685

Collected Steps per Second: 15,881.40429
Overall Steps per Second: 11,108.16822

Timestep Collection Time: 3.15023
Timestep Consumption Time: 1.35367
PPO Batch Consumption Time: 0.12570
Total Iteration Time: 4.50389

Cumulative Model Updates: 3,808
Cumulative Timesteps: 31,911,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 31911986...
Checkpoint 31911986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.46815
Policy Entropy: 0.76538
Value Function Loss: 2.20289

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05225
Policy Update Magnitude: 0.10252
Value Function Update Magnitude: 0.16092

Collected Steps per Second: 16,499.87126
Overall Steps per Second: 11,231.57434

Timestep Collection Time: 3.03057
Timestep Consumption Time: 1.42152
PPO Batch Consumption Time: 0.12496
Total Iteration Time: 4.45209

Cumulative Model Updates: 3,814
Cumulative Timesteps: 31,961,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.45543
Policy Entropy: 0.76210
Value Function Loss: 2.16284

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.10506
Value Function Update Magnitude: 0.16393

Collected Steps per Second: 15,929.09391
Overall Steps per Second: 11,024.67059

Timestep Collection Time: 3.14004
Timestep Consumption Time: 1.39688
PPO Batch Consumption Time: 0.12337
Total Iteration Time: 4.53692

Cumulative Model Updates: 3,820
Cumulative Timesteps: 32,012,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 32012008...
Checkpoint 32012008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.49161
Policy Entropy: 0.75647
Value Function Loss: 2.11211

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.10900
Value Function Update Magnitude: 0.16460

Collected Steps per Second: 15,873.50956
Overall Steps per Second: 11,178.98858

Timestep Collection Time: 3.15091
Timestep Consumption Time: 1.32320
PPO Batch Consumption Time: 0.12327
Total Iteration Time: 4.47411

Cumulative Model Updates: 3,826
Cumulative Timesteps: 32,062,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.79458
Policy Entropy: 0.74601
Value Function Loss: 2.09093

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06130
Policy Update Magnitude: 0.10759
Value Function Update Magnitude: 0.24854

Collected Steps per Second: 16,328.59971
Overall Steps per Second: 11,176.92177

Timestep Collection Time: 3.06236
Timestep Consumption Time: 1.41150
PPO Batch Consumption Time: 0.12344
Total Iteration Time: 4.47386

Cumulative Model Updates: 3,832
Cumulative Timesteps: 32,112,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32112028...
Checkpoint 32112028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.26980
Policy Entropy: 0.73681
Value Function Loss: 2.05539

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.13632
Value Function Update Magnitude: 0.23738

Collected Steps per Second: 14,078.92448
Overall Steps per Second: 9,907.99624

Timestep Collection Time: 3.55155
Timestep Consumption Time: 1.49508
PPO Batch Consumption Time: 0.13020
Total Iteration Time: 5.04663

Cumulative Model Updates: 3,838
Cumulative Timesteps: 32,162,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.92636
Policy Entropy: 0.73461
Value Function Loss: 2.07694

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.11715
Value Function Update Magnitude: 0.19503

Collected Steps per Second: 14,633.95790
Overall Steps per Second: 10,042.00839

Timestep Collection Time: 3.41698
Timestep Consumption Time: 1.56250
PPO Batch Consumption Time: 0.15318
Total Iteration Time: 4.97948

Cumulative Model Updates: 3,844
Cumulative Timesteps: 32,212,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32212034...
Checkpoint 32212034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.49636
Policy Entropy: 0.73422
Value Function Loss: 1.93901

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.10626
Value Function Update Magnitude: 0.17794

Collected Steps per Second: 15,398.42873
Overall Steps per Second: 10,831.75869

Timestep Collection Time: 3.24903
Timestep Consumption Time: 1.36979
PPO Batch Consumption Time: 0.11523
Total Iteration Time: 4.61883

Cumulative Model Updates: 3,850
Cumulative Timesteps: 32,262,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.19635
Policy Entropy: 0.71927
Value Function Loss: 2.02334

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.10196
Value Function Update Magnitude: 0.16056

Collected Steps per Second: 16,404.40451
Overall Steps per Second: 11,276.89947

Timestep Collection Time: 3.04991
Timestep Consumption Time: 1.38677
PPO Batch Consumption Time: 0.11868
Total Iteration Time: 4.43668

Cumulative Model Updates: 3,856
Cumulative Timesteps: 32,312,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 32312096...
Checkpoint 32312096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.90590
Policy Entropy: 0.72365
Value Function Loss: 2.01626

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.10826
Value Function Update Magnitude: 0.16279

Collected Steps per Second: 16,425.76530
Overall Steps per Second: 11,242.38871

Timestep Collection Time: 3.04461
Timestep Consumption Time: 1.40374
PPO Batch Consumption Time: 0.12260
Total Iteration Time: 4.44834

Cumulative Model Updates: 3,862
Cumulative Timesteps: 32,362,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.50817
Policy Entropy: 0.72125
Value Function Loss: 2.14380

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.10580
Value Function Update Magnitude: 0.15936

Collected Steps per Second: 16,013.63484
Overall Steps per Second: 10,974.27384

Timestep Collection Time: 3.12259
Timestep Consumption Time: 1.43389
PPO Batch Consumption Time: 0.12585
Total Iteration Time: 4.55647

Cumulative Model Updates: 3,868
Cumulative Timesteps: 32,412,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32412110...
Checkpoint 32412110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.49224
Policy Entropy: 0.71682
Value Function Loss: 2.11843

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.10300
Value Function Update Magnitude: 0.16391

Collected Steps per Second: 15,602.74772
Overall Steps per Second: 10,893.18098

Timestep Collection Time: 3.20726
Timestep Consumption Time: 1.38663
PPO Batch Consumption Time: 0.12391
Total Iteration Time: 4.59388

Cumulative Model Updates: 3,874
Cumulative Timesteps: 32,462,152

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.22113
Policy Entropy: 0.71711
Value Function Loss: 2.08636

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04744
Policy Update Magnitude: 0.09600
Value Function Update Magnitude: 0.16148

Collected Steps per Second: 16,281.62881
Overall Steps per Second: 11,099.56183

Timestep Collection Time: 3.07119
Timestep Consumption Time: 1.43385
PPO Batch Consumption Time: 0.12384
Total Iteration Time: 4.50504

Cumulative Model Updates: 3,880
Cumulative Timesteps: 32,512,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32512156...
Checkpoint 32512156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.65503
Policy Entropy: 0.71155
Value Function Loss: 2.05612

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04974
Policy Update Magnitude: 0.10712
Value Function Update Magnitude: 0.23398

Collected Steps per Second: 15,574.65888
Overall Steps per Second: 10,753.56715

Timestep Collection Time: 3.21047
Timestep Consumption Time: 1.43933
PPO Batch Consumption Time: 0.12680
Total Iteration Time: 4.64981

Cumulative Model Updates: 3,886
Cumulative Timesteps: 32,562,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.20106
Policy Entropy: 0.70914
Value Function Loss: 2.03414

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.09677
Value Function Update Magnitude: 0.22180

Collected Steps per Second: 15,788.27012
Overall Steps per Second: 11,251.90706

Timestep Collection Time: 3.16779
Timestep Consumption Time: 1.27714
PPO Batch Consumption Time: 0.11734
Total Iteration Time: 4.44494

Cumulative Model Updates: 3,892
Cumulative Timesteps: 32,612,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32612172...
Checkpoint 32612172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.77399
Policy Entropy: 0.70762
Value Function Loss: 2.06851

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05240
Policy Update Magnitude: 0.11113
Value Function Update Magnitude: 0.19145

Collected Steps per Second: 15,928.83346
Overall Steps per Second: 10,997.30447

Timestep Collection Time: 3.14022
Timestep Consumption Time: 1.40817
PPO Batch Consumption Time: 0.12359
Total Iteration Time: 4.54839

Cumulative Model Updates: 3,898
Cumulative Timesteps: 32,662,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.80796
Policy Entropy: 0.70587
Value Function Loss: 2.04086

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04559
Policy Update Magnitude: 0.10933
Value Function Update Magnitude: 0.17343

Collected Steps per Second: 13,711.61306
Overall Steps per Second: 9,717.43021

Timestep Collection Time: 3.64684
Timestep Consumption Time: 1.49897
PPO Batch Consumption Time: 0.13594
Total Iteration Time: 5.14580

Cumulative Model Updates: 3,904
Cumulative Timesteps: 32,712,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32712196...
Checkpoint 32712196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.37240
Policy Entropy: 0.70018
Value Function Loss: 2.07127

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.10222
Value Function Update Magnitude: 0.15963

Collected Steps per Second: 14,687.60861
Overall Steps per Second: 10,554.14695

Timestep Collection Time: 3.40532
Timestep Consumption Time: 1.33367
PPO Batch Consumption Time: 0.12155
Total Iteration Time: 4.73899

Cumulative Model Updates: 3,910
Cumulative Timesteps: 32,762,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.66457
Policy Entropy: 0.69863
Value Function Loss: 2.10069

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05677
Policy Update Magnitude: 0.09353
Value Function Update Magnitude: 0.19722

Collected Steps per Second: 16,607.08428
Overall Steps per Second: 11,399.91223

Timestep Collection Time: 3.01112
Timestep Consumption Time: 1.37540
PPO Batch Consumption Time: 0.11718
Total Iteration Time: 4.38653

Cumulative Model Updates: 3,916
Cumulative Timesteps: 32,812,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 32812218...
Checkpoint 32812218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.22846
Policy Entropy: 0.69565
Value Function Loss: 2.06328

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.09256
Value Function Update Magnitude: 0.22111

Collected Steps per Second: 16,549.41600
Overall Steps per Second: 11,517.73130

Timestep Collection Time: 3.02258
Timestep Consumption Time: 1.32046
PPO Batch Consumption Time: 0.11315
Total Iteration Time: 4.34304

Cumulative Model Updates: 3,922
Cumulative Timesteps: 32,862,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.72307
Policy Entropy: 0.70225
Value Function Loss: 2.09989

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.09140
Value Function Update Magnitude: 0.22082

Collected Steps per Second: 16,795.59148
Overall Steps per Second: 11,490.48890

Timestep Collection Time: 2.97792
Timestep Consumption Time: 1.37489
PPO Batch Consumption Time: 0.11613
Total Iteration Time: 4.35282

Cumulative Model Updates: 3,928
Cumulative Timesteps: 32,912,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 32912256...
Checkpoint 32912256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.86020
Policy Entropy: 0.71012
Value Function Loss: 2.10121

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05651
Policy Update Magnitude: 0.11141
Value Function Update Magnitude: 0.25934

Collected Steps per Second: 15,712.09062
Overall Steps per Second: 10,957.47648

Timestep Collection Time: 3.18366
Timestep Consumption Time: 1.38144
PPO Batch Consumption Time: 0.11601
Total Iteration Time: 4.56510

Cumulative Model Updates: 3,934
Cumulative Timesteps: 32,962,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.62756
Policy Entropy: 0.70641
Value Function Loss: 2.21356

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05360
Policy Update Magnitude: 0.11112
Value Function Update Magnitude: 0.21992

Collected Steps per Second: 15,779.71256
Overall Steps per Second: 11,034.14825

Timestep Collection Time: 3.17053
Timestep Consumption Time: 1.36358
PPO Batch Consumption Time: 0.11891
Total Iteration Time: 4.53411

Cumulative Model Updates: 3,940
Cumulative Timesteps: 33,012,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 33012308...
Checkpoint 33012308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.43309
Policy Entropy: 0.69191
Value Function Loss: 2.14109

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.09987
Value Function Update Magnitude: 0.18934

Collected Steps per Second: 16,602.48624
Overall Steps per Second: 11,293.60368

Timestep Collection Time: 3.01172
Timestep Consumption Time: 1.41574
PPO Batch Consumption Time: 0.12133
Total Iteration Time: 4.42746

Cumulative Model Updates: 3,946
Cumulative Timesteps: 33,062,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.60166
Policy Entropy: 0.69991
Value Function Loss: 2.35983

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05936
Policy Update Magnitude: 0.08205
Value Function Update Magnitude: 0.18706

Collected Steps per Second: 15,899.00622
Overall Steps per Second: 10,907.09947

Timestep Collection Time: 3.14586
Timestep Consumption Time: 1.43978
PPO Batch Consumption Time: 0.12658
Total Iteration Time: 4.58564

Cumulative Model Updates: 3,952
Cumulative Timesteps: 33,112,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 33112326...
Checkpoint 33112326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.41984
Policy Entropy: 0.68379
Value Function Loss: 2.26560

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.08372
Value Function Update Magnitude: 0.18919

Collected Steps per Second: 15,678.39501
Overall Steps per Second: 10,828.16142

Timestep Collection Time: 3.18961
Timestep Consumption Time: 1.42872
PPO Batch Consumption Time: 0.12909
Total Iteration Time: 4.61833

Cumulative Model Updates: 3,958
Cumulative Timesteps: 33,162,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.67336
Policy Entropy: 0.68878
Value Function Loss: 2.39300

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05248
Policy Update Magnitude: 0.10043
Value Function Update Magnitude: 0.19734

Collected Steps per Second: 16,695.78233
Overall Steps per Second: 11,463.94137

Timestep Collection Time: 2.99633
Timestep Consumption Time: 1.36744
PPO Batch Consumption Time: 0.11280
Total Iteration Time: 4.36377

Cumulative Model Updates: 3,964
Cumulative Timesteps: 33,212,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 33212360...
Checkpoint 33212360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.65986
Policy Entropy: 0.68553
Value Function Loss: 2.19961

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.08931
Value Function Update Magnitude: 0.15038

Collected Steps per Second: 16,113.79644
Overall Steps per Second: 11,197.25980

Timestep Collection Time: 3.10442
Timestep Consumption Time: 1.36310
PPO Batch Consumption Time: 0.11457
Total Iteration Time: 4.46752

Cumulative Model Updates: 3,970
Cumulative Timesteps: 33,262,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.21771
Policy Entropy: 0.68978
Value Function Loss: 2.31834

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05492
Policy Update Magnitude: 0.09800
Value Function Update Magnitude: 0.14102

Collected Steps per Second: 15,968.30699
Overall Steps per Second: 11,277.10968

Timestep Collection Time: 3.13296
Timestep Consumption Time: 1.30329
PPO Batch Consumption Time: 0.10992
Total Iteration Time: 4.43624

Cumulative Model Updates: 3,976
Cumulative Timesteps: 33,312,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33312412...
Checkpoint 33312412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.02233
Policy Entropy: 0.68741
Value Function Loss: 2.36988

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05674
Policy Update Magnitude: 0.09303
Value Function Update Magnitude: 0.20271

Collected Steps per Second: 16,291.43567
Overall Steps per Second: 11,323.24750

Timestep Collection Time: 3.07020
Timestep Consumption Time: 1.34708
PPO Batch Consumption Time: 0.11139
Total Iteration Time: 4.41728

Cumulative Model Updates: 3,982
Cumulative Timesteps: 33,362,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.14649
Policy Entropy: 0.68012
Value Function Loss: 2.45925

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.10823
Value Function Update Magnitude: 0.21111

Collected Steps per Second: 16,309.11070
Overall Steps per Second: 11,290.46156

Timestep Collection Time: 3.06663
Timestep Consumption Time: 1.36313
PPO Batch Consumption Time: 0.11205
Total Iteration Time: 4.42976

Cumulative Model Updates: 3,988
Cumulative Timesteps: 33,412,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 33412444...
Checkpoint 33412444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.92417
Policy Entropy: 0.68261
Value Function Loss: 2.35498

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06109
Policy Update Magnitude: 0.09893
Value Function Update Magnitude: 0.21239

Collected Steps per Second: 15,930.29063
Overall Steps per Second: 11,060.65578

Timestep Collection Time: 3.14031
Timestep Consumption Time: 1.38257
PPO Batch Consumption Time: 0.12554
Total Iteration Time: 4.52288

Cumulative Model Updates: 3,994
Cumulative Timesteps: 33,462,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.02084
Policy Entropy: 0.68232
Value Function Loss: 2.35492

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.09861
Value Function Update Magnitude: 0.28961

Collected Steps per Second: 15,683.76562
Overall Steps per Second: 10,876.57402

Timestep Collection Time: 3.18929
Timestep Consumption Time: 1.40959
PPO Batch Consumption Time: 0.12291
Total Iteration Time: 4.59887

Cumulative Model Updates: 4,000
Cumulative Timesteps: 33,512,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 33512490...
Checkpoint 33512490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.95367
Policy Entropy: 0.68704
Value Function Loss: 2.27418

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05429
Policy Update Magnitude: 0.10688
Value Function Update Magnitude: 0.26085

Collected Steps per Second: 15,853.17320
Overall Steps per Second: 11,080.32407

Timestep Collection Time: 3.15546
Timestep Consumption Time: 1.35921
PPO Batch Consumption Time: 0.11380
Total Iteration Time: 4.51467

Cumulative Model Updates: 4,006
Cumulative Timesteps: 33,562,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.22638
Policy Entropy: 0.67577
Value Function Loss: 2.24679

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05066
Policy Update Magnitude: 0.13616
Value Function Update Magnitude: 0.20998

Collected Steps per Second: 16,256.60811
Overall Steps per Second: 11,460.19563

Timestep Collection Time: 3.07592
Timestep Consumption Time: 1.28736
PPO Batch Consumption Time: 0.11444
Total Iteration Time: 4.36328

Cumulative Model Updates: 4,012
Cumulative Timesteps: 33,612,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 33612518...
Checkpoint 33612518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.36845
Policy Entropy: 0.67021
Value Function Loss: 2.18306

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.20987

Collected Steps per Second: 16,531.41435
Overall Steps per Second: 11,280.07918

Timestep Collection Time: 3.02454
Timestep Consumption Time: 1.40805
PPO Batch Consumption Time: 0.11922
Total Iteration Time: 4.43259

Cumulative Model Updates: 4,018
Cumulative Timesteps: 33,662,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.62389
Policy Entropy: 0.65398
Value Function Loss: 2.20311

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.09542
Value Function Update Magnitude: 0.18190

Collected Steps per Second: 16,467.51981
Overall Steps per Second: 11,410.08427

Timestep Collection Time: 3.03762
Timestep Consumption Time: 1.34640
PPO Batch Consumption Time: 0.11436
Total Iteration Time: 4.38402

Cumulative Model Updates: 4,024
Cumulative Timesteps: 33,712,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 33712540...
Checkpoint 33712540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.42772
Policy Entropy: 0.64518
Value Function Loss: 2.25133

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.07370
Value Function Update Magnitude: 0.19397

Collected Steps per Second: 15,515.61882
Overall Steps per Second: 11,118.25131

Timestep Collection Time: 3.22320
Timestep Consumption Time: 1.27481
PPO Batch Consumption Time: 0.11591
Total Iteration Time: 4.49801

Cumulative Model Updates: 4,030
Cumulative Timesteps: 33,762,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.21527
Policy Entropy: 0.65788
Value Function Loss: 2.30546

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.17842

Collected Steps per Second: 15,943.93425
Overall Steps per Second: 11,184.95173

Timestep Collection Time: 3.13837
Timestep Consumption Time: 1.33532
PPO Batch Consumption Time: 0.11101
Total Iteration Time: 4.47369

Cumulative Model Updates: 4,036
Cumulative Timesteps: 33,812,588

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 33812588...
Checkpoint 33812588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.42742
Policy Entropy: 0.65323
Value Function Loss: 2.37809

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.19892

Collected Steps per Second: 16,194.65972
Overall Steps per Second: 11,144.69529

Timestep Collection Time: 3.08830
Timestep Consumption Time: 1.39939
PPO Batch Consumption Time: 0.12517
Total Iteration Time: 4.48770

Cumulative Model Updates: 4,042
Cumulative Timesteps: 33,862,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.52609
Policy Entropy: 0.66160
Value Function Loss: 2.35605

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.18548

Collected Steps per Second: 15,717.77899
Overall Steps per Second: 11,161.23938

Timestep Collection Time: 3.18162
Timestep Consumption Time: 1.29889
PPO Batch Consumption Time: 0.11768
Total Iteration Time: 4.48051

Cumulative Model Updates: 4,048
Cumulative Timesteps: 33,912,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 33912610...
Checkpoint 33912610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.83798
Policy Entropy: 0.65578
Value Function Loss: 2.35501

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.07133
Value Function Update Magnitude: 0.17644

Collected Steps per Second: 16,424.52473
Overall Steps per Second: 11,368.25102

Timestep Collection Time: 3.04666
Timestep Consumption Time: 1.35507
PPO Batch Consumption Time: 0.11351
Total Iteration Time: 4.40173

Cumulative Model Updates: 4,054
Cumulative Timesteps: 33,962,650

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.34275
Policy Entropy: 0.66525
Value Function Loss: 2.27593

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.20138

Collected Steps per Second: 16,142.38543
Overall Steps per Second: 11,093.08724

Timestep Collection Time: 3.09954
Timestep Consumption Time: 1.41083
PPO Batch Consumption Time: 0.12730
Total Iteration Time: 4.51038

Cumulative Model Updates: 4,060
Cumulative Timesteps: 34,012,684

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 34012684...
Checkpoint 34012684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.47794
Policy Entropy: 0.65933
Value Function Loss: 2.33003

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.18071

Collected Steps per Second: 15,520.30981
Overall Steps per Second: 11,073.20117

Timestep Collection Time: 3.22326
Timestep Consumption Time: 1.29449
PPO Batch Consumption Time: 0.11609
Total Iteration Time: 4.51775

Cumulative Model Updates: 4,066
Cumulative Timesteps: 34,062,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.11949
Policy Entropy: 0.65321
Value Function Loss: 2.32388

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.17958

Collected Steps per Second: 16,049.00538
Overall Steps per Second: 11,210.05893

Timestep Collection Time: 3.11708
Timestep Consumption Time: 1.34552
PPO Batch Consumption Time: 0.11315
Total Iteration Time: 4.46260

Cumulative Model Updates: 4,072
Cumulative Timesteps: 34,112,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 34112736...
Checkpoint 34112736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.64657
Policy Entropy: 0.64919
Value Function Loss: 2.36031

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.21870

Collected Steps per Second: 16,403.65549
Overall Steps per Second: 11,385.75913

Timestep Collection Time: 3.04871
Timestep Consumption Time: 1.34362
PPO Batch Consumption Time: 0.11444
Total Iteration Time: 4.39233

Cumulative Model Updates: 4,078
Cumulative Timesteps: 34,162,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.98422
Policy Entropy: 0.66398
Value Function Loss: 2.42967

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.06647
Value Function Update Magnitude: 0.25656

Collected Steps per Second: 17,359.16402
Overall Steps per Second: 11,764.76539

Timestep Collection Time: 2.88090
Timestep Consumption Time: 1.36993
PPO Batch Consumption Time: 0.11615
Total Iteration Time: 4.25083

Cumulative Model Updates: 4,084
Cumulative Timesteps: 34,212,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 34212756...
Checkpoint 34212756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.17277
Policy Entropy: 0.66411
Value Function Loss: 2.37649

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.29066

Collected Steps per Second: 16,832.84896
Overall Steps per Second: 11,491.99897

Timestep Collection Time: 2.97193
Timestep Consumption Time: 1.38119
PPO Batch Consumption Time: 0.11782
Total Iteration Time: 4.35312

Cumulative Model Updates: 4,090
Cumulative Timesteps: 34,262,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.57056
Policy Entropy: 0.67301
Value Function Loss: 2.31362

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.07195
Value Function Update Magnitude: 0.28078

Collected Steps per Second: 16,706.62072
Overall Steps per Second: 11,686.13800

Timestep Collection Time: 2.99402
Timestep Consumption Time: 1.28626
PPO Batch Consumption Time: 0.11540
Total Iteration Time: 4.28028

Cumulative Model Updates: 4,096
Cumulative Timesteps: 34,312,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 34312802...
Checkpoint 34312802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.61151
Policy Entropy: 0.66444
Value Function Loss: 2.35359

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.07406
Value Function Update Magnitude: 0.24705

Collected Steps per Second: 15,706.38353
Overall Steps per Second: 10,745.85287

Timestep Collection Time: 3.18406
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.12662
Total Iteration Time: 4.65389

Cumulative Model Updates: 4,102
Cumulative Timesteps: 34,362,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.61549
Policy Entropy: 0.65935
Value Function Loss: 2.35252

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.08308
Value Function Update Magnitude: 0.22273

Collected Steps per Second: 15,311.93951
Overall Steps per Second: 10,555.35776

Timestep Collection Time: 3.26582
Timestep Consumption Time: 1.47168
PPO Batch Consumption Time: 0.13181
Total Iteration Time: 4.73750

Cumulative Model Updates: 4,108
Cumulative Timesteps: 34,412,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 34412818...
Checkpoint 34412818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.27016
Policy Entropy: 0.65838
Value Function Loss: 2.44936

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.08101
Value Function Update Magnitude: 0.21349

Collected Steps per Second: 15,908.39775
Overall Steps per Second: 11,281.00359

Timestep Collection Time: 3.14501
Timestep Consumption Time: 1.29006
PPO Batch Consumption Time: 0.11891
Total Iteration Time: 4.43507

Cumulative Model Updates: 4,114
Cumulative Timesteps: 34,462,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.94798
Policy Entropy: 0.65935
Value Function Loss: 2.40765

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.08517
Value Function Update Magnitude: 0.20685

Collected Steps per Second: 16,019.03463
Overall Steps per Second: 11,013.52875

Timestep Collection Time: 3.12416
Timestep Consumption Time: 1.41989
PPO Batch Consumption Time: 0.12549
Total Iteration Time: 4.54405

Cumulative Model Updates: 4,120
Cumulative Timesteps: 34,512,896

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 34512896...
Checkpoint 34512896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.88099
Policy Entropy: 0.66135
Value Function Loss: 2.27331

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.11016
Value Function Update Magnitude: 0.20443

Collected Steps per Second: 15,585.72941
Overall Steps per Second: 11,050.61090

Timestep Collection Time: 3.21101
Timestep Consumption Time: 1.31779
PPO Batch Consumption Time: 0.10990
Total Iteration Time: 4.52880

Cumulative Model Updates: 4,126
Cumulative Timesteps: 34,562,942

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.35942
Policy Entropy: 0.67114
Value Function Loss: 2.08526

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.08837
Value Function Update Magnitude: 0.22997

Collected Steps per Second: 16,424.37394
Overall Steps per Second: 11,522.25531

Timestep Collection Time: 3.04657
Timestep Consumption Time: 1.29616
PPO Batch Consumption Time: 0.11639
Total Iteration Time: 4.34273

Cumulative Model Updates: 4,132
Cumulative Timesteps: 34,612,980

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 34612980...
Checkpoint 34612980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.32518
Policy Entropy: 0.67612
Value Function Loss: 2.03762

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.08351
Value Function Update Magnitude: 0.21582

Collected Steps per Second: 16,327.35688
Overall Steps per Second: 11,207.25634

Timestep Collection Time: 3.06271
Timestep Consumption Time: 1.39922
PPO Batch Consumption Time: 0.11537
Total Iteration Time: 4.46193

Cumulative Model Updates: 4,138
Cumulative Timesteps: 34,662,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.41658
Policy Entropy: 0.68998
Value Function Loss: 2.12804

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.07050
Value Function Update Magnitude: 0.18946

Collected Steps per Second: 16,328.04069
Overall Steps per Second: 11,164.39740

Timestep Collection Time: 3.06295
Timestep Consumption Time: 1.41665
PPO Batch Consumption Time: 0.12681
Total Iteration Time: 4.47960

Cumulative Model Updates: 4,144
Cumulative Timesteps: 34,712,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 34712998...
Checkpoint 34712998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.96244
Policy Entropy: 0.67270
Value Function Loss: 2.11935

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.07795
Value Function Update Magnitude: 0.18811

Collected Steps per Second: 16,307.86441
Overall Steps per Second: 11,103.16970

Timestep Collection Time: 3.06699
Timestep Consumption Time: 1.43767
PPO Batch Consumption Time: 0.12678
Total Iteration Time: 4.50466

Cumulative Model Updates: 4,150
Cumulative Timesteps: 34,763,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.97885
Policy Entropy: 0.67959
Value Function Loss: 2.20050

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05139
Policy Update Magnitude: 0.08388
Value Function Update Magnitude: 0.21855

Collected Steps per Second: 16,211.47005
Overall Steps per Second: 10,937.83567

Timestep Collection Time: 3.08596
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.13577
Total Iteration Time: 4.57385

Cumulative Model Updates: 4,156
Cumulative Timesteps: 34,813,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 34813042...
Checkpoint 34813042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.40976
Policy Entropy: 0.68284
Value Function Loss: 2.09837

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.11872
Value Function Update Magnitude: 0.19164

Collected Steps per Second: 15,990.18196
Overall Steps per Second: 11,180.13308

Timestep Collection Time: 3.12779
Timestep Consumption Time: 1.34568
PPO Batch Consumption Time: 0.11653
Total Iteration Time: 4.47347

Cumulative Model Updates: 4,162
Cumulative Timesteps: 34,863,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.92875
Policy Entropy: 0.69047
Value Function Loss: 2.21077

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.10945
Value Function Update Magnitude: 0.18591

Collected Steps per Second: 16,787.95532
Overall Steps per Second: 11,545.05018

Timestep Collection Time: 2.98059
Timestep Consumption Time: 1.35356
PPO Batch Consumption Time: 0.11596
Total Iteration Time: 4.33415

Cumulative Model Updates: 4,168
Cumulative Timesteps: 34,913,094

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 34913094...
Checkpoint 34913094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.19262
Policy Entropy: 0.69055
Value Function Loss: 2.24647

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.11917
Value Function Update Magnitude: 0.18102

Collected Steps per Second: 16,075.12231
Overall Steps per Second: 11,119.60902

Timestep Collection Time: 3.11164
Timestep Consumption Time: 1.38672
PPO Batch Consumption Time: 0.12037
Total Iteration Time: 4.49836

Cumulative Model Updates: 4,174
Cumulative Timesteps: 34,963,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.52439
Policy Entropy: 0.69358
Value Function Loss: 2.28929

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.11105
Value Function Update Magnitude: 0.18568

Collected Steps per Second: 16,873.31087
Overall Steps per Second: 11,659.56829

Timestep Collection Time: 2.96492
Timestep Consumption Time: 1.32581
PPO Batch Consumption Time: 0.11073
Total Iteration Time: 4.29072

Cumulative Model Updates: 4,180
Cumulative Timesteps: 35,013,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 35013142...
Checkpoint 35013142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.20090
Policy Entropy: 0.69966
Value Function Loss: 2.21795

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.09843
Value Function Update Magnitude: 0.20200

Collected Steps per Second: 16,290.37726
Overall Steps per Second: 11,180.33499

Timestep Collection Time: 3.06942
Timestep Consumption Time: 1.40290
PPO Batch Consumption Time: 0.11942
Total Iteration Time: 4.47232

Cumulative Model Updates: 4,186
Cumulative Timesteps: 35,063,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.35503
Policy Entropy: 0.71061
Value Function Loss: 2.17222

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07139
Policy Update Magnitude: 0.10431
Value Function Update Magnitude: 0.24059

Collected Steps per Second: 17,055.67559
Overall Steps per Second: 11,559.97619

Timestep Collection Time: 2.93240
Timestep Consumption Time: 1.39408
PPO Batch Consumption Time: 0.11755
Total Iteration Time: 4.32648

Cumulative Model Updates: 4,192
Cumulative Timesteps: 35,113,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 35113158...
Checkpoint 35113158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.94499
Policy Entropy: 0.71050
Value Function Loss: 2.14846

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.08722
Value Function Update Magnitude: 0.24178

Collected Steps per Second: 15,933.28947
Overall Steps per Second: 10,762.51043

Timestep Collection Time: 3.13833
Timestep Consumption Time: 1.50779
PPO Batch Consumption Time: 0.13225
Total Iteration Time: 4.64613

Cumulative Model Updates: 4,198
Cumulative Timesteps: 35,163,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.03590
Policy Entropy: 0.69705
Value Function Loss: 2.19819

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.08289
Value Function Update Magnitude: 0.22840

Collected Steps per Second: 16,367.82856
Overall Steps per Second: 11,150.73851

Timestep Collection Time: 3.05551
Timestep Consumption Time: 1.42958
PPO Batch Consumption Time: 0.12306
Total Iteration Time: 4.48508

Cumulative Model Updates: 4,204
Cumulative Timesteps: 35,213,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35213174...
Checkpoint 35213174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.50514
Policy Entropy: 0.69845
Value Function Loss: 2.11488

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05535
Policy Update Magnitude: 0.08690
Value Function Update Magnitude: 0.20878

Collected Steps per Second: 16,148.98817
Overall Steps per Second: 11,058.07915

Timestep Collection Time: 3.09666
Timestep Consumption Time: 1.42564
PPO Batch Consumption Time: 0.12364
Total Iteration Time: 4.52230

Cumulative Model Updates: 4,210
Cumulative Timesteps: 35,263,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.37939
Policy Entropy: 0.69591
Value Function Loss: 2.02502

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.09888
Value Function Update Magnitude: 0.20654

Collected Steps per Second: 15,368.32592
Overall Steps per Second: 10,670.14055

Timestep Collection Time: 3.25449
Timestep Consumption Time: 1.43299
PPO Batch Consumption Time: 0.13567
Total Iteration Time: 4.68747

Cumulative Model Updates: 4,216
Cumulative Timesteps: 35,313,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 35313198...
Checkpoint 35313198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.10041
Policy Entropy: 0.68135
Value Function Loss: 1.96452

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05133
Policy Update Magnitude: 0.12874
Value Function Update Magnitude: 0.19939

Collected Steps per Second: 14,704.62314
Overall Steps per Second: 10,428.01867

Timestep Collection Time: 3.40315
Timestep Consumption Time: 1.39565
PPO Batch Consumption Time: 0.12093
Total Iteration Time: 4.79880

Cumulative Model Updates: 4,222
Cumulative Timesteps: 35,363,240

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.00417
Policy Entropy: 0.68392
Value Function Loss: 2.06293

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.12066
Value Function Update Magnitude: 0.18965

Collected Steps per Second: 15,916.76654
Overall Steps per Second: 11,418.62392

Timestep Collection Time: 3.14147
Timestep Consumption Time: 1.23752
PPO Batch Consumption Time: 0.09589
Total Iteration Time: 4.37899

Cumulative Model Updates: 4,228
Cumulative Timesteps: 35,413,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 35413242...
Checkpoint 35413242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.87909
Policy Entropy: 0.69087
Value Function Loss: 2.14235

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.11571
Value Function Update Magnitude: 0.19035

Collected Steps per Second: 15,947.79534
Overall Steps per Second: 11,376.43641

Timestep Collection Time: 3.13523
Timestep Consumption Time: 1.25982
PPO Batch Consumption Time: 0.11234
Total Iteration Time: 4.39505

Cumulative Model Updates: 4,234
Cumulative Timesteps: 35,463,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.44786
Policy Entropy: 0.68673
Value Function Loss: 2.18476

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.09465
Value Function Update Magnitude: 0.19210

Collected Steps per Second: 16,473.36086
Overall Steps per Second: 11,398.36826

Timestep Collection Time: 3.03751
Timestep Consumption Time: 1.35242
PPO Batch Consumption Time: 0.11249
Total Iteration Time: 4.38993

Cumulative Model Updates: 4,240
Cumulative Timesteps: 35,513,280

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 35513280...
Checkpoint 35513280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.64994
Policy Entropy: 0.69183
Value Function Loss: 2.09885

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.09119
Value Function Update Magnitude: 0.20291

Collected Steps per Second: 15,953.65677
Overall Steps per Second: 11,179.93132

Timestep Collection Time: 3.13546
Timestep Consumption Time: 1.33881
PPO Batch Consumption Time: 0.11211
Total Iteration Time: 4.47427

Cumulative Model Updates: 4,246
Cumulative Timesteps: 35,563,302

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.28997
Policy Entropy: 0.67957
Value Function Loss: 2.19959

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.09128
Value Function Update Magnitude: 0.19443

Collected Steps per Second: 16,248.96275
Overall Steps per Second: 11,434.10290

Timestep Collection Time: 3.07786
Timestep Consumption Time: 1.29607
PPO Batch Consumption Time: 0.11558
Total Iteration Time: 4.37393

Cumulative Model Updates: 4,252
Cumulative Timesteps: 35,613,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35613314...
Checkpoint 35613314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.48415
Policy Entropy: 0.69110
Value Function Loss: 2.22525

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04347
Policy Update Magnitude: 0.10077
Value Function Update Magnitude: 0.21955

Collected Steps per Second: 15,941.23830
Overall Steps per Second: 11,130.05422

Timestep Collection Time: 3.13652
Timestep Consumption Time: 1.35582
PPO Batch Consumption Time: 0.11262
Total Iteration Time: 4.49234

Cumulative Model Updates: 4,258
Cumulative Timesteps: 35,663,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.73487
Policy Entropy: 0.69018
Value Function Loss: 2.28132

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.09780
Value Function Update Magnitude: 0.21537

Collected Steps per Second: 16,412.41655
Overall Steps per Second: 11,402.62478

Timestep Collection Time: 3.04672
Timestep Consumption Time: 1.33859
PPO Batch Consumption Time: 0.11437
Total Iteration Time: 4.38531

Cumulative Model Updates: 4,264
Cumulative Timesteps: 35,713,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35713318...
Checkpoint 35713318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.74718
Policy Entropy: 0.68983
Value Function Loss: 2.22996

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05849
Policy Update Magnitude: 0.09791
Value Function Update Magnitude: 0.19357

Collected Steps per Second: 16,085.49523
Overall Steps per Second: 11,359.54890

Timestep Collection Time: 3.10851
Timestep Consumption Time: 1.29324
PPO Batch Consumption Time: 0.11773
Total Iteration Time: 4.40176

Cumulative Model Updates: 4,270
Cumulative Timesteps: 35,763,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.52904
Policy Entropy: 0.69311
Value Function Loss: 2.17744

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05212
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.17265

Collected Steps per Second: 16,565.72593
Overall Steps per Second: 11,389.07602

Timestep Collection Time: 3.01888
Timestep Consumption Time: 1.37217
PPO Batch Consumption Time: 0.11488
Total Iteration Time: 4.39105

Cumulative Model Updates: 4,276
Cumulative Timesteps: 35,813,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35813330...
Checkpoint 35813330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.53115
Policy Entropy: 0.68163
Value Function Loss: 2.12964

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.12081
Value Function Update Magnitude: 0.21078

Collected Steps per Second: 15,924.10850
Overall Steps per Second: 11,129.07765

Timestep Collection Time: 3.13989
Timestep Consumption Time: 1.35284
PPO Batch Consumption Time: 0.11552
Total Iteration Time: 4.49274

Cumulative Model Updates: 4,282
Cumulative Timesteps: 35,863,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.88944
Policy Entropy: 0.67469
Value Function Loss: 2.05686

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.10745
Value Function Update Magnitude: 0.26327

Collected Steps per Second: 15,851.23660
Overall Steps per Second: 11,157.59925

Timestep Collection Time: 3.15496
Timestep Consumption Time: 1.32719
PPO Batch Consumption Time: 0.12468
Total Iteration Time: 4.48215

Cumulative Model Updates: 4,288
Cumulative Timesteps: 35,913,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 35913340...
Checkpoint 35913340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.99177
Policy Entropy: 0.67473
Value Function Loss: 2.11203

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.09813
Value Function Update Magnitude: 0.27273

Collected Steps per Second: 15,871.25993
Overall Steps per Second: 10,968.08548

Timestep Collection Time: 3.15211
Timestep Consumption Time: 1.40912
PPO Batch Consumption Time: 0.12454
Total Iteration Time: 4.56123

Cumulative Model Updates: 4,294
Cumulative Timesteps: 35,963,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.15131
Policy Entropy: 0.68280
Value Function Loss: 2.17679

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.08203
Value Function Update Magnitude: 0.26620

Collected Steps per Second: 15,852.65024
Overall Steps per Second: 10,916.70836

Timestep Collection Time: 3.15455
Timestep Consumption Time: 1.42632
PPO Batch Consumption Time: 0.12513
Total Iteration Time: 4.58087

Cumulative Model Updates: 4,300
Cumulative Timesteps: 36,013,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 36013376...
Checkpoint 36013376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.25197
Policy Entropy: 0.68963
Value Function Loss: 2.27895

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.10315
Value Function Update Magnitude: 0.21286

Collected Steps per Second: 15,546.49611
Overall Steps per Second: 11,008.52486

Timestep Collection Time: 3.21732
Timestep Consumption Time: 1.32625
PPO Batch Consumption Time: 0.12577
Total Iteration Time: 4.54357

Cumulative Model Updates: 4,306
Cumulative Timesteps: 36,063,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.41857
Policy Entropy: 0.68778
Value Function Loss: 2.29674

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05644
Policy Update Magnitude: 0.09682
Value Function Update Magnitude: 0.18345

Collected Steps per Second: 16,048.88938
Overall Steps per Second: 10,945.32405

Timestep Collection Time: 3.11560
Timestep Consumption Time: 1.45274
PPO Batch Consumption Time: 0.12807
Total Iteration Time: 4.56834

Cumulative Model Updates: 4,312
Cumulative Timesteps: 36,113,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 36113396...
Checkpoint 36113396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.88135
Policy Entropy: 0.67680
Value Function Loss: 2.25581

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04374
Policy Update Magnitude: 0.11995
Value Function Update Magnitude: 0.19917

Collected Steps per Second: 15,854.26002
Overall Steps per Second: 10,977.20890

Timestep Collection Time: 3.15398
Timestep Consumption Time: 1.40128
PPO Batch Consumption Time: 0.12345
Total Iteration Time: 4.55526

Cumulative Model Updates: 4,318
Cumulative Timesteps: 36,163,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.38992
Policy Entropy: 0.66575
Value Function Loss: 2.17865

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.12580
Value Function Update Magnitude: 0.21442

Collected Steps per Second: 16,715.74343
Overall Steps per Second: 11,453.32101

Timestep Collection Time: 2.99215
Timestep Consumption Time: 1.37479
PPO Batch Consumption Time: 0.11598
Total Iteration Time: 4.36694

Cumulative Model Updates: 4,324
Cumulative Timesteps: 36,213,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 36213416...
Checkpoint 36213416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.82529
Policy Entropy: 0.67194
Value Function Loss: 2.20786

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.05133
Policy Update Magnitude: 0.10284
Value Function Update Magnitude: 0.19375

Collected Steps per Second: 16,912.78910
Overall Steps per Second: 11,571.18394

Timestep Collection Time: 2.95906
Timestep Consumption Time: 1.36599
PPO Batch Consumption Time: 0.11608
Total Iteration Time: 4.32505

Cumulative Model Updates: 4,330
Cumulative Timesteps: 36,263,462

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.40700
Policy Entropy: 0.65407
Value Function Loss: 2.14560

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05385
Policy Update Magnitude: 0.12298
Value Function Update Magnitude: 0.16616

Collected Steps per Second: 16,547.18896
Overall Steps per Second: 11,533.15429

Timestep Collection Time: 3.02335
Timestep Consumption Time: 1.31440
PPO Batch Consumption Time: 0.11361
Total Iteration Time: 4.33776

Cumulative Model Updates: 4,336
Cumulative Timesteps: 36,313,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 36313490...
Checkpoint 36313490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.79497
Policy Entropy: 0.65623
Value Function Loss: 2.19268

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.09316
Value Function Update Magnitude: 0.16589

Collected Steps per Second: 16,635.09646
Overall Steps per Second: 11,659.47689

Timestep Collection Time: 3.00690
Timestep Consumption Time: 1.28318
PPO Batch Consumption Time: 0.11410
Total Iteration Time: 4.29007

Cumulative Model Updates: 4,342
Cumulative Timesteps: 36,363,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.25219
Policy Entropy: 0.64702
Value Function Loss: 2.22088

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06063
Policy Update Magnitude: 0.09396
Value Function Update Magnitude: 0.19180

Collected Steps per Second: 16,627.25049
Overall Steps per Second: 11,492.52913

Timestep Collection Time: 3.00735
Timestep Consumption Time: 1.34365
PPO Batch Consumption Time: 0.11209
Total Iteration Time: 4.35100

Cumulative Model Updates: 4,348
Cumulative Timesteps: 36,413,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 36413514...
Checkpoint 36413514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.48708
Policy Entropy: 0.64612
Value Function Loss: 2.34195

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.09602
Value Function Update Magnitude: 0.19846

Collected Steps per Second: 16,586.69188
Overall Steps per Second: 11,547.92825

Timestep Collection Time: 3.01543
Timestep Consumption Time: 1.31574
PPO Batch Consumption Time: 0.11355
Total Iteration Time: 4.33117

Cumulative Model Updates: 4,354
Cumulative Timesteps: 36,463,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.80324
Policy Entropy: 0.63789
Value Function Loss: 2.31504

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.10637
Value Function Update Magnitude: 0.20202

Collected Steps per Second: 16,096.84244
Overall Steps per Second: 11,470.19604

Timestep Collection Time: 3.10657
Timestep Consumption Time: 1.25307
PPO Batch Consumption Time: 0.11130
Total Iteration Time: 4.35965

Cumulative Model Updates: 4,360
Cumulative Timesteps: 36,513,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 36513536...
Checkpoint 36513536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.64895
Policy Entropy: 0.63703
Value Function Loss: 2.21448

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05107
Policy Update Magnitude: 0.10849
Value Function Update Magnitude: 0.18675

Collected Steps per Second: 17,252.86247
Overall Steps per Second: 11,777.74480

Timestep Collection Time: 2.89900
Timestep Consumption Time: 1.34766
PPO Batch Consumption Time: 0.11482
Total Iteration Time: 4.24665

Cumulative Model Updates: 4,366
Cumulative Timesteps: 36,563,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.84684
Policy Entropy: 0.64641
Value Function Loss: 2.19534

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.10143
Value Function Update Magnitude: 0.17586

Collected Steps per Second: 16,766.76379
Overall Steps per Second: 11,621.25338

Timestep Collection Time: 2.98269
Timestep Consumption Time: 1.32064
PPO Batch Consumption Time: 0.11263
Total Iteration Time: 4.30332

Cumulative Model Updates: 4,372
Cumulative Timesteps: 36,613,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 36613562...
Checkpoint 36613562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.85230
Policy Entropy: 0.65042
Value Function Loss: 2.11704

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.09625
Value Function Update Magnitude: 0.16907

Collected Steps per Second: 16,595.09465
Overall Steps per Second: 11,388.27928

Timestep Collection Time: 3.01414
Timestep Consumption Time: 1.37809
PPO Batch Consumption Time: 0.11562
Total Iteration Time: 4.39224

Cumulative Model Updates: 4,378
Cumulative Timesteps: 36,663,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.90846
Policy Entropy: 0.64893
Value Function Loss: 2.10942

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.11133
Value Function Update Magnitude: 0.16203

Collected Steps per Second: 16,897.54963
Overall Steps per Second: 11,538.31455

Timestep Collection Time: 2.96055
Timestep Consumption Time: 1.37509
PPO Batch Consumption Time: 0.11289
Total Iteration Time: 4.33564

Cumulative Model Updates: 4,384
Cumulative Timesteps: 36,713,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36713608...
Checkpoint 36713608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.41507
Policy Entropy: 0.65728
Value Function Loss: 2.06941

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04897
Policy Update Magnitude: 0.11093
Value Function Update Magnitude: 0.17184

Collected Steps per Second: 16,344.31679
Overall Steps per Second: 11,370.46918

Timestep Collection Time: 3.05966
Timestep Consumption Time: 1.33840
PPO Batch Consumption Time: 0.11308
Total Iteration Time: 4.39806

Cumulative Model Updates: 4,390
Cumulative Timesteps: 36,763,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.49266
Policy Entropy: 0.65374
Value Function Loss: 2.06923

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04499
Policy Update Magnitude: 0.10388
Value Function Update Magnitude: 0.25293

Collected Steps per Second: 17,263.54702
Overall Steps per Second: 11,724.20673

Timestep Collection Time: 2.89859
Timestep Consumption Time: 1.36950
PPO Batch Consumption Time: 0.11598
Total Iteration Time: 4.26809

Cumulative Model Updates: 4,396
Cumulative Timesteps: 36,813,656

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 36813656...
Checkpoint 36813656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.95729
Policy Entropy: 0.65985
Value Function Loss: 2.09323

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.13261
Value Function Update Magnitude: 0.28967

Collected Steps per Second: 16,581.69558
Overall Steps per Second: 11,421.73433

Timestep Collection Time: 3.01803
Timestep Consumption Time: 1.36344
PPO Batch Consumption Time: 0.11354
Total Iteration Time: 4.38147

Cumulative Model Updates: 4,402
Cumulative Timesteps: 36,863,700

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.75875
Policy Entropy: 0.64799
Value Function Loss: 2.03057

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05568
Policy Update Magnitude: 0.11933
Value Function Update Magnitude: 0.25077

Collected Steps per Second: 16,668.76040
Overall Steps per Second: 11,534.52258

Timestep Collection Time: 3.00022
Timestep Consumption Time: 1.33546
PPO Batch Consumption Time: 0.11443
Total Iteration Time: 4.33568

Cumulative Model Updates: 4,408
Cumulative Timesteps: 36,913,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 36913710...
Checkpoint 36913710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.72000
Policy Entropy: 0.64773
Value Function Loss: 2.04058

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04623
Policy Update Magnitude: 0.09611
Value Function Update Magnitude: 0.21142

Collected Steps per Second: 16,913.24005
Overall Steps per Second: 11,761.94500

Timestep Collection Time: 2.95804
Timestep Consumption Time: 1.29551
PPO Batch Consumption Time: 0.11533
Total Iteration Time: 4.25355

Cumulative Model Updates: 4,414
Cumulative Timesteps: 36,963,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.94220
Policy Entropy: 0.64485
Value Function Loss: 2.03915

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.10058
Value Function Update Magnitude: 0.16523

Collected Steps per Second: 16,667.84049
Overall Steps per Second: 11,453.19818

Timestep Collection Time: 3.00159
Timestep Consumption Time: 1.36662
PPO Batch Consumption Time: 0.11505
Total Iteration Time: 4.36821

Cumulative Model Updates: 4,420
Cumulative Timesteps: 37,013,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 37013770...
Checkpoint 37013770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.26469
Policy Entropy: 0.64560
Value Function Loss: 2.18928

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06920
Policy Update Magnitude: 0.09550
Value Function Update Magnitude: 0.17589

Collected Steps per Second: 16,557.95805
Overall Steps per Second: 11,509.48523

Timestep Collection Time: 3.02187
Timestep Consumption Time: 1.32550
PPO Batch Consumption Time: 0.11405
Total Iteration Time: 4.34737

Cumulative Model Updates: 4,426
Cumulative Timesteps: 37,063,806

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.42276
Policy Entropy: 0.62815
Value Function Loss: 2.20309

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.08746
Value Function Update Magnitude: 0.20718

Collected Steps per Second: 16,426.50980
Overall Steps per Second: 11,689.88393

Timestep Collection Time: 3.04423
Timestep Consumption Time: 1.23349
PPO Batch Consumption Time: 0.10986
Total Iteration Time: 4.27772

Cumulative Model Updates: 4,432
Cumulative Timesteps: 37,113,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 37113812...
Checkpoint 37113812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.62499
Policy Entropy: 0.63282
Value Function Loss: 2.19604

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05824
Policy Update Magnitude: 0.10063
Value Function Update Magnitude: 0.18906

Collected Steps per Second: 15,761.01132
Overall Steps per Second: 10,984.13898

Timestep Collection Time: 3.17403
Timestep Consumption Time: 1.38035
PPO Batch Consumption Time: 0.11549
Total Iteration Time: 4.55439

Cumulative Model Updates: 4,438
Cumulative Timesteps: 37,163,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.94073
Policy Entropy: 0.63076
Value Function Loss: 2.16240

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04373
Policy Update Magnitude: 0.10216
Value Function Update Magnitude: 0.21079

Collected Steps per Second: 16,562.76354
Overall Steps per Second: 11,498.39348

Timestep Collection Time: 3.01930
Timestep Consumption Time: 1.32983
PPO Batch Consumption Time: 0.11319
Total Iteration Time: 4.34913

Cumulative Model Updates: 4,444
Cumulative Timesteps: 37,213,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 37213846...
Checkpoint 37213846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.87769
Policy Entropy: 0.63238
Value Function Loss: 2.23843

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.09704
Value Function Update Magnitude: 0.19088

Collected Steps per Second: 16,759.14827
Overall Steps per Second: 11,723.80459

Timestep Collection Time: 2.98416
Timestep Consumption Time: 1.28169
PPO Batch Consumption Time: 0.11470
Total Iteration Time: 4.26585

Cumulative Model Updates: 4,450
Cumulative Timesteps: 37,263,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.10365
Policy Entropy: 0.63425
Value Function Loss: 2.22054

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04752
Policy Update Magnitude: 0.09839
Value Function Update Magnitude: 0.26919

Collected Steps per Second: 16,856.13081
Overall Steps per Second: 11,534.50188

Timestep Collection Time: 2.96818
Timestep Consumption Time: 1.36942
PPO Batch Consumption Time: 0.11581
Total Iteration Time: 4.33760

Cumulative Model Updates: 4,456
Cumulative Timesteps: 37,313,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 37313890...
Checkpoint 37313890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.71161
Policy Entropy: 0.63184
Value Function Loss: 2.23047

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05080
Policy Update Magnitude: 0.11201
Value Function Update Magnitude: 0.23405

Collected Steps per Second: 16,685.74669
Overall Steps per Second: 11,533.23779

Timestep Collection Time: 2.99729
Timestep Consumption Time: 1.33905
PPO Batch Consumption Time: 0.11527
Total Iteration Time: 4.33634

Cumulative Model Updates: 4,462
Cumulative Timesteps: 37,363,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.18021
Policy Entropy: 0.63433
Value Function Loss: 2.21691

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.11040
Value Function Update Magnitude: 0.20659

Collected Steps per Second: 16,019.81041
Overall Steps per Second: 10,981.93706

Timestep Collection Time: 3.12151
Timestep Consumption Time: 1.43197
PPO Batch Consumption Time: 0.13759
Total Iteration Time: 4.55348

Cumulative Model Updates: 4,468
Cumulative Timesteps: 37,413,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 37413908...
Checkpoint 37413908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.61766
Policy Entropy: 0.63179
Value Function Loss: 2.26401

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04619
Policy Update Magnitude: 0.10929
Value Function Update Magnitude: 0.18102

Collected Steps per Second: 15,529.97024
Overall Steps per Second: 10,744.29600

Timestep Collection Time: 3.22177
Timestep Consumption Time: 1.43503
PPO Batch Consumption Time: 0.12543
Total Iteration Time: 4.65680

Cumulative Model Updates: 4,474
Cumulative Timesteps: 37,463,942

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.07070
Policy Entropy: 0.62536
Value Function Loss: 2.29382

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05177
Policy Update Magnitude: 0.10087
Value Function Update Magnitude: 0.17886

Collected Steps per Second: 16,038.80104
Overall Steps per Second: 10,912.10360

Timestep Collection Time: 3.11769
Timestep Consumption Time: 1.46475
PPO Batch Consumption Time: 0.13059
Total Iteration Time: 4.58243

Cumulative Model Updates: 4,480
Cumulative Timesteps: 37,513,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 37513946...
Checkpoint 37513946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.94467
Policy Entropy: 0.61926
Value Function Loss: 2.26315

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05409
Policy Update Magnitude: 0.10853
Value Function Update Magnitude: 0.17292

Collected Steps per Second: 15,810.57263
Overall Steps per Second: 10,844.76894

Timestep Collection Time: 3.16257
Timestep Consumption Time: 1.44813
PPO Batch Consumption Time: 0.13510
Total Iteration Time: 4.61070

Cumulative Model Updates: 4,486
Cumulative Timesteps: 37,563,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.18509
Policy Entropy: 0.61464
Value Function Loss: 2.26106

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05470
Policy Update Magnitude: 0.11711
Value Function Update Magnitude: 0.17128

Collected Steps per Second: 16,086.10293
Overall Steps per Second: 10,930.03500

Timestep Collection Time: 3.11014
Timestep Consumption Time: 1.46716
PPO Batch Consumption Time: 0.13209
Total Iteration Time: 4.57730

Cumulative Model Updates: 4,492
Cumulative Timesteps: 37,613,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 37613978...
Checkpoint 37613978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.61636
Policy Entropy: 0.62304
Value Function Loss: 2.24733

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04929
Policy Update Magnitude: 0.11047
Value Function Update Magnitude: 0.17923

Collected Steps per Second: 14,096.12945
Overall Steps per Second: 9,957.00367

Timestep Collection Time: 3.54863
Timestep Consumption Time: 1.47517
PPO Batch Consumption Time: 0.12840
Total Iteration Time: 5.02380

Cumulative Model Updates: 4,498
Cumulative Timesteps: 37,664,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 37664000...
Checkpoint 37664000 saved!
