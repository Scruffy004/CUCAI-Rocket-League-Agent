Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.24551
Policy Entropy: 2.91894
Value Function Loss: 0.00782

Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00703
Policy Update Magnitude: 0.21807
Value Function Update Magnitude: 0.17402

Collected Steps per Second: 13,176.97972
Overall Steps per Second: 9,641.42420

Timestep Collection Time: 3.79480
Timestep Consumption Time: 1.39157
PPO Batch Consumption Time: 0.33748
Total Iteration Time: 5.18637

Cumulative Model Updates: 179,056
Cumulative Timesteps: 1,493,317,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.00992
Policy Entropy: 2.95238
Value Function Loss: 0.00739

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03875
Policy Update Magnitude: 0.24544
Value Function Update Magnitude: 0.19399

Collected Steps per Second: 21,449.44866
Overall Steps per Second: 13,716.80880

Timestep Collection Time: 2.33227
Timestep Consumption Time: 1.31478
PPO Batch Consumption Time: 0.31741
Total Iteration Time: 3.64706

Cumulative Model Updates: 179,058
Cumulative Timesteps: 1,493,367,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1493367820...
Checkpoint 1493367820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.42905
Policy Entropy: 2.98196
Value Function Loss: 0.00641

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.47406
Value Function Update Magnitude: 0.38692

Collected Steps per Second: 22,271.22295
Overall Steps per Second: 12,213.18653

Timestep Collection Time: 2.24541
Timestep Consumption Time: 1.84918
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.09459

Cumulative Model Updates: 179,062
Cumulative Timesteps: 1,493,417,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.92752
Policy Entropy: 2.99906
Value Function Loss: 0.00574

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.64509
Value Function Update Magnitude: 0.54256

Collected Steps per Second: 22,098.51094
Overall Steps per Second: 10,664.83242

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.68887

Cumulative Model Updates: 179,068
Cumulative Timesteps: 1,493,467,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493467834...
Checkpoint 1493467834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.43774
Policy Entropy: 2.98148
Value Function Loss: 0.00559

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.54167

Collected Steps per Second: 22,653.28734
Overall Steps per Second: 10,673.36030

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68568

Cumulative Model Updates: 179,074
Cumulative Timesteps: 1,493,517,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.42182
Policy Entropy: 2.94133
Value Function Loss: 0.00574

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.59539
Value Function Update Magnitude: 0.55148

Collected Steps per Second: 22,590.74584
Overall Steps per Second: 10,639.07327

Timestep Collection Time: 2.21365
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.70041

Cumulative Model Updates: 179,080
Cumulative Timesteps: 1,493,567,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1493567854...
Checkpoint 1493567854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.55415
Policy Entropy: 2.92273
Value Function Loss: 0.00548

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.59966
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 22,283.93088
Overall Steps per Second: 10,629.49529

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.70389

Cumulative Model Updates: 179,086
Cumulative Timesteps: 1,493,617,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.76014
Policy Entropy: 2.91789
Value Function Loss: 0.00522

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.60602
Value Function Update Magnitude: 0.56892

Collected Steps per Second: 22,771.78726
Overall Steps per Second: 10,738.44216

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.46076
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.65673

Cumulative Model Updates: 179,092
Cumulative Timesteps: 1,493,667,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493667860...
Checkpoint 1493667860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,586.42831
Policy Entropy: 2.91763
Value Function Loss: 0.00561

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.60830
Value Function Update Magnitude: 0.58569

Collected Steps per Second: 22,339.85106
Overall Steps per Second: 10,642.29946

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.69974

Cumulative Model Updates: 179,098
Cumulative Timesteps: 1,493,717,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.61538
Policy Entropy: 2.92763
Value Function Loss: 0.00587

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.61568
Value Function Update Magnitude: 0.62096

Collected Steps per Second: 22,426.61297
Overall Steps per Second: 10,640.43215

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.70037

Cumulative Model Updates: 179,104
Cumulative Timesteps: 1,493,767,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1493767890...
Checkpoint 1493767890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.36666
Policy Entropy: 2.91889
Value Function Loss: 0.00578

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.61695
Value Function Update Magnitude: 0.62258

Collected Steps per Second: 23,004.93011
Overall Steps per Second: 10,878.92576

Timestep Collection Time: 2.17423
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.59770

Cumulative Model Updates: 179,110
Cumulative Timesteps: 1,493,817,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.19949
Policy Entropy: 2.93408
Value Function Loss: 0.00491

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.60973
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 23,014.12507
Overall Steps per Second: 10,806.32246

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62748

Cumulative Model Updates: 179,116
Cumulative Timesteps: 1,493,867,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493867914...
Checkpoint 1493867914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,509.15615
Policy Entropy: 2.92176
Value Function Loss: 0.00511

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.60778
Value Function Update Magnitude: 0.58084

Collected Steps per Second: 22,835.83333
Overall Steps per Second: 10,801.91088

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.62974

Cumulative Model Updates: 179,122
Cumulative Timesteps: 1,493,917,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,431.69744
Policy Entropy: 2.92185
Value Function Loss: 0.00551

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.61580
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 23,073.08064
Overall Steps per Second: 10,874.70713

Timestep Collection Time: 2.16789
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.59966

Cumulative Model Updates: 179,128
Cumulative Timesteps: 1,493,967,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1493967944...
Checkpoint 1493967944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.52647
Policy Entropy: 2.89809
Value Function Loss: 0.00602

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.62759
Value Function Update Magnitude: 0.65216

Collected Steps per Second: 23,030.65250
Overall Steps per Second: 10,655.31917

Timestep Collection Time: 2.17232
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.69531

Cumulative Model Updates: 179,134
Cumulative Timesteps: 1,494,017,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.63136
Policy Entropy: 2.89143
Value Function Loss: 0.00611

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.63908
Value Function Update Magnitude: 0.68541

Collected Steps per Second: 23,239.15404
Overall Steps per Second: 10,886.65106

Timestep Collection Time: 2.15292
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.59572

Cumulative Model Updates: 179,140
Cumulative Timesteps: 1,494,068,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1494068006...
Checkpoint 1494068006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,648.74538
Policy Entropy: 2.88626
Value Function Loss: 0.00620

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.63908
Value Function Update Magnitude: 0.69326

Collected Steps per Second: 22,458.71884
Overall Steps per Second: 10,662.88792

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69179

Cumulative Model Updates: 179,146
Cumulative Timesteps: 1,494,118,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.50759
Policy Entropy: 2.88928
Value Function Loss: 0.00611

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.64317
Value Function Update Magnitude: 0.68480

Collected Steps per Second: 22,163.55223
Overall Steps per Second: 10,457.48539

Timestep Collection Time: 2.25605
Timestep Consumption Time: 2.52541
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.78146

Cumulative Model Updates: 179,152
Cumulative Timesteps: 1,494,168,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1494168036...
Checkpoint 1494168036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,606.99556
Policy Entropy: 2.89820
Value Function Loss: 0.00573

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.64120
Value Function Update Magnitude: 0.64974

Collected Steps per Second: 22,112.84130
Overall Steps per Second: 10,630.78033

Timestep Collection Time: 2.26113
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.70332

Cumulative Model Updates: 179,158
Cumulative Timesteps: 1,494,218,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.23247
Policy Entropy: 2.90518
Value Function Loss: 0.00633

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15090
Policy Update Magnitude: 0.64210
Value Function Update Magnitude: 0.66292

Collected Steps per Second: 22,585.12809
Overall Steps per Second: 10,796.16622

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63368

Cumulative Model Updates: 179,164
Cumulative Timesteps: 1,494,268,062

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1494268062...
Checkpoint 1494268062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.61934
Policy Entropy: 2.90059
Value Function Loss: 0.00609

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.64115
Value Function Update Magnitude: 0.67541

Collected Steps per Second: 22,353.41934
Overall Steps per Second: 10,662.89338

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.68953

Cumulative Model Updates: 179,170
Cumulative Timesteps: 1,494,318,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.03654
Policy Entropy: 2.89881
Value Function Loss: 0.00634

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.64013
Value Function Update Magnitude: 0.64710

Collected Steps per Second: 22,752.44747
Overall Steps per Second: 10,488.83367

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.57013
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.76831

Cumulative Model Updates: 179,176
Cumulative Timesteps: 1,494,368,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1494368080...
Checkpoint 1494368080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,126.56906
Policy Entropy: 2.89222
Value Function Loss: 0.00719

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.65556
Value Function Update Magnitude: 0.66595

Collected Steps per Second: 22,653.25387
Overall Steps per Second: 10,545.88300

Timestep Collection Time: 2.20816
Timestep Consumption Time: 2.53511
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.74327

Cumulative Model Updates: 179,182
Cumulative Timesteps: 1,494,418,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.58787
Policy Entropy: 2.88280
Value Function Loss: 0.00795

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.67419
Value Function Update Magnitude: 0.72040

Collected Steps per Second: 22,927.21924
Overall Steps per Second: 10,736.54784

Timestep Collection Time: 2.18116
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.65774

Cumulative Model Updates: 179,188
Cumulative Timesteps: 1,494,468,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1494468110...
Checkpoint 1494468110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.84308
Policy Entropy: 2.86070
Value Function Loss: 0.00793

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.68651
Value Function Update Magnitude: 0.74443

Collected Steps per Second: 22,805.28749
Overall Steps per Second: 10,839.88800

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.61352

Cumulative Model Updates: 179,194
Cumulative Timesteps: 1,494,518,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.97347
Policy Entropy: 2.84256
Value Function Loss: 0.00735

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.68099
Value Function Update Magnitude: 0.72003

Collected Steps per Second: 22,813.73678
Overall Steps per Second: 10,589.50145

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.53030
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.72222

Cumulative Model Updates: 179,200
Cumulative Timesteps: 1,494,568,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1494568126...
Checkpoint 1494568126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,690.84832
Policy Entropy: 2.85060
Value Function Loss: 0.00692

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.67640
Value Function Update Magnitude: 0.68426

Collected Steps per Second: 22,189.18434
Overall Steps per Second: 10,562.10276

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.73410

Cumulative Model Updates: 179,206
Cumulative Timesteps: 1,494,618,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,943.12655
Policy Entropy: 2.85249
Value Function Loss: 0.00688

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.66775
Value Function Update Magnitude: 0.65467

Collected Steps per Second: 22,913.85418
Overall Steps per Second: 10,772.53519

Timestep Collection Time: 2.18305
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.64348

Cumulative Model Updates: 179,212
Cumulative Timesteps: 1,494,668,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1494668150...
Checkpoint 1494668150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.97471
Policy Entropy: 2.85297
Value Function Loss: 0.00825

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.68495
Value Function Update Magnitude: 0.67787

Collected Steps per Second: 22,536.45494
Overall Steps per Second: 10,791.37443

Timestep Collection Time: 2.21969
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63555

Cumulative Model Updates: 179,218
Cumulative Timesteps: 1,494,718,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,128.36451
Policy Entropy: 2.84982
Value Function Loss: 0.00766

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.68229
Value Function Update Magnitude: 0.71496

Collected Steps per Second: 22,195.64983
Overall Steps per Second: 10,514.13891

Timestep Collection Time: 2.25414
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.75854

Cumulative Model Updates: 179,224
Cumulative Timesteps: 1,494,768,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1494768206...
Checkpoint 1494768206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.95738
Policy Entropy: 2.84592
Value Function Loss: 0.00754

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.68541
Value Function Update Magnitude: 0.71107

Collected Steps per Second: 22,248.73189
Overall Steps per Second: 10,631.57271

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.70542

Cumulative Model Updates: 179,230
Cumulative Timesteps: 1,494,818,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,702.58189
Policy Entropy: 2.84428
Value Function Loss: 0.00695

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.68522
Value Function Update Magnitude: 0.68702

Collected Steps per Second: 19,184.46759
Overall Steps per Second: 9,665.48233

Timestep Collection Time: 2.60732
Timestep Consumption Time: 2.56780
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 5.17512

Cumulative Model Updates: 179,236
Cumulative Timesteps: 1,494,868,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1494868252...
Checkpoint 1494868252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.77463
Policy Entropy: 2.84729
Value Function Loss: 0.00749

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.67081
Value Function Update Magnitude: 0.66591

Collected Steps per Second: 22,340.81266
Overall Steps per Second: 10,636.61787

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.70112

Cumulative Model Updates: 179,242
Cumulative Timesteps: 1,494,918,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.54550
Policy Entropy: 2.84687
Value Function Loss: 0.00782

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.67797
Value Function Update Magnitude: 0.66735

Collected Steps per Second: 23,359.97752
Overall Steps per Second: 10,868.12275

Timestep Collection Time: 2.14135
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.60263

Cumulative Model Updates: 179,248
Cumulative Timesteps: 1,494,968,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1494968278...
Checkpoint 1494968278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.57546
Policy Entropy: 2.83792
Value Function Loss: 0.00769

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.68697
Value Function Update Magnitude: 0.65725

Collected Steps per Second: 22,554.75977
Overall Steps per Second: 10,550.18678

Timestep Collection Time: 2.21709
Timestep Consumption Time: 2.52273
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73982

Cumulative Model Updates: 179,254
Cumulative Timesteps: 1,495,018,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.84331
Policy Entropy: 2.82482
Value Function Loss: 0.00808

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.69479
Value Function Update Magnitude: 0.66197

Collected Steps per Second: 22,896.94461
Overall Steps per Second: 10,638.90090

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.51694
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.70143

Cumulative Model Updates: 179,260
Cumulative Timesteps: 1,495,068,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1495068302...
Checkpoint 1495068302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.71878
Policy Entropy: 2.82527
Value Function Loss: 0.00798

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.69377
Value Function Update Magnitude: 0.67838

Collected Steps per Second: 22,622.63386
Overall Steps per Second: 10,558.14544

Timestep Collection Time: 2.21026
Timestep Consumption Time: 2.52561
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.73587

Cumulative Model Updates: 179,266
Cumulative Timesteps: 1,495,118,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.19567
Policy Entropy: 2.81867
Value Function Loss: 0.00796

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.17824
Policy Update Magnitude: 0.69889
Value Function Update Magnitude: 0.70348

Collected Steps per Second: 22,972.53737
Overall Steps per Second: 10,877.06730

Timestep Collection Time: 2.17686
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.59756

Cumulative Model Updates: 179,272
Cumulative Timesteps: 1,495,168,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1495168312...
Checkpoint 1495168312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.49284
Policy Entropy: 2.84446
Value Function Loss: 0.00743

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.68729
Value Function Update Magnitude: 0.73627

Collected Steps per Second: 22,447.11007
Overall Steps per Second: 10,691.18996

Timestep Collection Time: 2.22888
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.67974

Cumulative Model Updates: 179,278
Cumulative Timesteps: 1,495,218,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.13124
Policy Entropy: 2.87074
Value Function Loss: 0.00697

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.66653
Value Function Update Magnitude: 0.72326

Collected Steps per Second: 22,391.42296
Overall Steps per Second: 10,618.03495

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.70916

Cumulative Model Updates: 179,284
Cumulative Timesteps: 1,495,268,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1495268346...
Checkpoint 1495268346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.23752
Policy Entropy: 2.89126
Value Function Loss: 0.00708

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.66821
Value Function Update Magnitude: 0.69434

Collected Steps per Second: 22,059.20777
Overall Steps per Second: 10,497.99824

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.76491

Cumulative Model Updates: 179,290
Cumulative Timesteps: 1,495,318,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.35948
Policy Entropy: 2.89429
Value Function Loss: 0.00732

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.66413
Value Function Update Magnitude: 0.66870

Collected Steps per Second: 21,558.55865
Overall Steps per Second: 10,409.30902

Timestep Collection Time: 2.32056
Timestep Consumption Time: 2.48552
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.80608

Cumulative Model Updates: 179,296
Cumulative Timesteps: 1,495,368,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1495368396...
Checkpoint 1495368396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.01921
Policy Entropy: 2.89327
Value Function Loss: 0.00801

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.66491
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 22,327.40929
Overall Steps per Second: 10,620.01445

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.71110

Cumulative Model Updates: 179,302
Cumulative Timesteps: 1,495,418,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.84676
Policy Entropy: 2.87639
Value Function Loss: 0.00733

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.66209
Value Function Update Magnitude: 0.70655

Collected Steps per Second: 22,902.20609
Overall Steps per Second: 10,684.10617

Timestep Collection Time: 2.18416
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.68191

Cumulative Model Updates: 179,308
Cumulative Timesteps: 1,495,468,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1495468450...
Checkpoint 1495468450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.55145
Policy Entropy: 2.86062
Value Function Loss: 0.00782

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.67289
Value Function Update Magnitude: 0.69805

Collected Steps per Second: 22,932.69918
Overall Steps per Second: 10,846.92131

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.61200

Cumulative Model Updates: 179,314
Cumulative Timesteps: 1,495,518,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,415.12406
Policy Entropy: 2.84582
Value Function Loss: 0.00797

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.69325
Value Function Update Magnitude: 0.69793

Collected Steps per Second: 22,870.57700
Overall Steps per Second: 10,684.77369

Timestep Collection Time: 2.18718
Timestep Consumption Time: 2.49444
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.68162

Cumulative Model Updates: 179,320
Cumulative Timesteps: 1,495,568,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1495568498...
Checkpoint 1495568498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.23678
Policy Entropy: 2.83266
Value Function Loss: 0.00871

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.69886
Value Function Update Magnitude: 0.71689

Collected Steps per Second: 22,924.59496
Overall Steps per Second: 10,870.56400

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.41938
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.60123

Cumulative Model Updates: 179,326
Cumulative Timesteps: 1,495,618,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.14718
Policy Entropy: 2.82796
Value Function Loss: 0.00866

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15679
Policy Update Magnitude: 0.70978
Value Function Update Magnitude: 0.72619

Collected Steps per Second: 23,024.10559
Overall Steps per Second: 10,892.40899

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.59311

Cumulative Model Updates: 179,332
Cumulative Timesteps: 1,495,668,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1495668546...
Checkpoint 1495668546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.81663
Policy Entropy: 2.83357
Value Function Loss: 0.00784

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.70345
Value Function Update Magnitude: 0.70943

Collected Steps per Second: 22,234.12156
Overall Steps per Second: 10,668.15740

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.68816

Cumulative Model Updates: 179,338
Cumulative Timesteps: 1,495,718,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.24774
Policy Entropy: 2.82622
Value Function Loss: 0.00808

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.16021
Policy Update Magnitude: 0.70315
Value Function Update Magnitude: 0.68032

Collected Steps per Second: 22,140.88817
Overall Steps per Second: 10,502.65971

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.50333
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.76241

Cumulative Model Updates: 179,344
Cumulative Timesteps: 1,495,768,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1495768578...
Checkpoint 1495768578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.95987
Policy Entropy: 2.83969
Value Function Loss: 0.00802

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.16451
Policy Update Magnitude: 0.70209
Value Function Update Magnitude: 0.66977

Collected Steps per Second: 21,678.45837
Overall Steps per Second: 10,553.46406

Timestep Collection Time: 2.30681
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.73854

Cumulative Model Updates: 179,350
Cumulative Timesteps: 1,495,818,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.89967
Policy Entropy: 2.83678
Value Function Loss: 0.00832

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.69423
Value Function Update Magnitude: 0.66585

Collected Steps per Second: 22,034.60229
Overall Steps per Second: 10,573.70846

Timestep Collection Time: 2.26988
Timestep Consumption Time: 2.46034
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.73022

Cumulative Model Updates: 179,356
Cumulative Timesteps: 1,495,868,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1495868602...
Checkpoint 1495868602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.68204
Policy Entropy: 2.82838
Value Function Loss: 0.00860

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.70197
Value Function Update Magnitude: 0.66802

Collected Steps per Second: 22,376.02747
Overall Steps per Second: 10,529.31131

Timestep Collection Time: 2.23579
Timestep Consumption Time: 2.51552
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75131

Cumulative Model Updates: 179,362
Cumulative Timesteps: 1,495,918,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.57420
Policy Entropy: 2.82283
Value Function Loss: 0.00853

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.69830
Value Function Update Magnitude: 0.67002

Collected Steps per Second: 22,230.28120
Overall Steps per Second: 10,571.70914

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.73206

Cumulative Model Updates: 179,368
Cumulative Timesteps: 1,495,968,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1495968656...
Checkpoint 1495968656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.70163
Policy Entropy: 2.80181
Value Function Loss: 0.00932

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.15571
Policy Update Magnitude: 0.70997
Value Function Update Magnitude: 0.68873

Collected Steps per Second: 21,831.88792
Overall Steps per Second: 10,349.75927

Timestep Collection Time: 2.29169
Timestep Consumption Time: 2.54243
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.83412

Cumulative Model Updates: 179,374
Cumulative Timesteps: 1,496,018,688

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.76782
Policy Entropy: 2.79259
Value Function Loss: 0.00974

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.73178
Value Function Update Magnitude: 0.71460

Collected Steps per Second: 22,538.18764
Overall Steps per Second: 10,574.01605

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.73009

Cumulative Model Updates: 179,380
Cumulative Timesteps: 1,496,068,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1496068704...
Checkpoint 1496068704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.45642
Policy Entropy: 2.77561
Value Function Loss: 0.01028

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.74522
Value Function Update Magnitude: 0.74174

Collected Steps per Second: 22,291.25276
Overall Steps per Second: 10,728.35305

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.41887
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.66316

Cumulative Model Updates: 179,386
Cumulative Timesteps: 1,496,118,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.25028
Policy Entropy: 2.76660
Value Function Loss: 0.01021

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.75260
Value Function Update Magnitude: 0.73723

Collected Steps per Second: 22,873.34114
Overall Steps per Second: 10,654.05280

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.50770
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.69418

Cumulative Model Updates: 179,392
Cumulative Timesteps: 1,496,168,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1496168744...
Checkpoint 1496168744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.16686
Policy Entropy: 2.77850
Value Function Loss: 0.01100

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.16236
Policy Update Magnitude: 0.74456
Value Function Update Magnitude: 0.71480

Collected Steps per Second: 22,499.29901
Overall Steps per Second: 10,588.90545

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.50033
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.72325

Cumulative Model Updates: 179,398
Cumulative Timesteps: 1,496,218,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.68703
Policy Entropy: 2.78179
Value Function Loss: 0.00978

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.16039
Policy Update Magnitude: 0.73172
Value Function Update Magnitude: 0.68842

Collected Steps per Second: 22,800.76286
Overall Steps per Second: 10,846.48035

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.60997

Cumulative Model Updates: 179,404
Cumulative Timesteps: 1,496,268,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1496268760...
Checkpoint 1496268760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.48811
Policy Entropy: 2.79005
Value Function Loss: 0.01028

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.72946
Value Function Update Magnitude: 0.70233

Collected Steps per Second: 21,116.69055
Overall Steps per Second: 10,552.08731

Timestep Collection Time: 2.36884
Timestep Consumption Time: 2.37165
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.74048

Cumulative Model Updates: 179,410
Cumulative Timesteps: 1,496,318,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.14881
Policy Entropy: 2.78915
Value Function Loss: 0.00980

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.72776
Value Function Update Magnitude: 0.72578

Collected Steps per Second: 21,376.26774
Overall Steps per Second: 10,509.07149

Timestep Collection Time: 2.34017
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.76008

Cumulative Model Updates: 179,416
Cumulative Timesteps: 1,496,368,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1496368806...
Checkpoint 1496368806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.15427
Policy Entropy: 2.78518
Value Function Loss: 0.01042

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.16493
Policy Update Magnitude: 0.74094
Value Function Update Magnitude: 0.73413

Collected Steps per Second: 21,362.17405
Overall Steps per Second: 10,606.87563

Timestep Collection Time: 2.34162
Timestep Consumption Time: 2.37438
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.71600

Cumulative Model Updates: 179,422
Cumulative Timesteps: 1,496,418,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.13751
Policy Entropy: 2.77772
Value Function Loss: 0.01089

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.19214
Policy Update Magnitude: 0.74722
Value Function Update Magnitude: 0.74603

Collected Steps per Second: 22,733.09617
Overall Steps per Second: 10,609.37238

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.71395

Cumulative Model Updates: 179,428
Cumulative Timesteps: 1,496,468,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1496468840...
Checkpoint 1496468840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.27814
Policy Entropy: 2.78580
Value Function Loss: 0.01147

Mean KL Divergence: 0.03040
SB3 Clip Fraction: 0.22004
Policy Update Magnitude: 0.73665
Value Function Update Magnitude: 0.75608

Collected Steps per Second: 22,214.73497
Overall Steps per Second: 10,595.92321

Timestep Collection Time: 2.25094
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.71917

Cumulative Model Updates: 179,434
Cumulative Timesteps: 1,496,518,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.72422
Policy Entropy: 2.78635
Value Function Loss: 0.01166

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.20826
Policy Update Magnitude: 0.75394
Value Function Update Magnitude: 0.77823

Collected Steps per Second: 22,774.33994
Overall Steps per Second: 10,609.33769

Timestep Collection Time: 2.19589
Timestep Consumption Time: 2.51788
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.71377

Cumulative Model Updates: 179,440
Cumulative Timesteps: 1,496,568,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1496568854...
Checkpoint 1496568854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,385.63960
Policy Entropy: 2.80342
Value Function Loss: 0.01027

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.18699
Policy Update Magnitude: 0.74361
Value Function Update Magnitude: 0.77257

Collected Steps per Second: 22,806.82711
Overall Steps per Second: 10,579.02438

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.72898

Cumulative Model Updates: 179,446
Cumulative Timesteps: 1,496,618,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.16361
Policy Entropy: 2.79522
Value Function Loss: 0.00962

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.16118
Policy Update Magnitude: 0.72785
Value Function Update Magnitude: 0.73328

Collected Steps per Second: 23,466.42374
Overall Steps per Second: 10,753.11978

Timestep Collection Time: 2.13139
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.65130

Cumulative Model Updates: 179,452
Cumulative Timesteps: 1,496,668,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1496668898...
Checkpoint 1496668898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.80473
Policy Entropy: 2.80067
Value Function Loss: 0.01011

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.16152
Policy Update Magnitude: 0.73288
Value Function Update Magnitude: 0.71545

Collected Steps per Second: 22,224.42493
Overall Steps per Second: 10,701.55654

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.67427

Cumulative Model Updates: 179,458
Cumulative Timesteps: 1,496,718,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.52095
Policy Entropy: 2.76930
Value Function Loss: 0.01099

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.16057
Policy Update Magnitude: 0.73562
Value Function Update Magnitude: 0.73389

Collected Steps per Second: 22,519.81413
Overall Steps per Second: 10,592.20708

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.50118
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.72234

Cumulative Model Updates: 179,464
Cumulative Timesteps: 1,496,768,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1496768940...
Checkpoint 1496768940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.51437
Policy Entropy: 2.77287
Value Function Loss: 0.01145

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.73779
Value Function Update Magnitude: 0.74954

Collected Steps per Second: 22,873.42560
Overall Steps per Second: 10,694.87696

Timestep Collection Time: 2.18594
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.67514

Cumulative Model Updates: 179,470
Cumulative Timesteps: 1,496,818,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.66539
Policy Entropy: 2.75612
Value Function Loss: 0.01137

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.73823
Value Function Update Magnitude: 0.78702

Collected Steps per Second: 22,998.12401
Overall Steps per Second: 10,674.51630

Timestep Collection Time: 2.17522
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.68649

Cumulative Model Updates: 179,476
Cumulative Timesteps: 1,496,868,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1496868966...
Checkpoint 1496868966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.23798
Policy Entropy: 2.75980
Value Function Loss: 0.01143

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.17210
Policy Update Magnitude: 0.73472
Value Function Update Magnitude: 0.78435

Collected Steps per Second: 22,019.38821
Overall Steps per Second: 10,565.14419

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.46310
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.73500

Cumulative Model Updates: 179,482
Cumulative Timesteps: 1,496,918,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.93296
Policy Entropy: 2.74515
Value Function Loss: 0.01239

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.17091
Policy Update Magnitude: 0.74473
Value Function Update Magnitude: 0.78437

Collected Steps per Second: 22,446.42010
Overall Steps per Second: 10,549.83727

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.74017

Cumulative Model Updates: 179,488
Cumulative Timesteps: 1,496,969,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1496969000...
Checkpoint 1496969000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.77729
Policy Entropy: 2.73934
Value Function Loss: 0.01276

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.76480
Value Function Update Magnitude: 0.78730

Collected Steps per Second: 22,277.23875
Overall Steps per Second: 10,555.32776

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.49310
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.73808

Cumulative Model Updates: 179,494
Cumulative Timesteps: 1,497,019,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.26634
Policy Entropy: 2.73294
Value Function Loss: 0.01297

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.17168
Policy Update Magnitude: 0.76823
Value Function Update Magnitude: 0.78353

Collected Steps per Second: 22,437.31514
Overall Steps per Second: 10,750.72008

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.42368
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.65327

Cumulative Model Updates: 179,500
Cumulative Timesteps: 1,497,069,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1497069038...
Checkpoint 1497069038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.76652
Policy Entropy: 2.74390
Value Function Loss: 0.01169

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.17384
Policy Update Magnitude: 0.75543
Value Function Update Magnitude: 0.75796

Collected Steps per Second: 21,826.34872
Overall Steps per Second: 10,596.04792

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72119

Cumulative Model Updates: 179,506
Cumulative Timesteps: 1,497,119,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.10545
Policy Entropy: 2.74009
Value Function Loss: 0.01157

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.74019
Value Function Update Magnitude: 0.72836

Collected Steps per Second: 22,569.06716
Overall Steps per Second: 10,746.11211

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.43772
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.65340

Cumulative Model Updates: 179,512
Cumulative Timesteps: 1,497,169,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1497169070...
Checkpoint 1497169070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.16716
Policy Entropy: 2.74135
Value Function Loss: 0.01141

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.73964
Value Function Update Magnitude: 0.71112

Collected Steps per Second: 22,820.54592
Overall Steps per Second: 10,627.10298

Timestep Collection Time: 2.19153
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70608

Cumulative Model Updates: 179,518
Cumulative Timesteps: 1,497,219,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.05514
Policy Entropy: 2.73405
Value Function Loss: 0.01287

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.17641
Policy Update Magnitude: 0.75048
Value Function Update Magnitude: 0.73983

Collected Steps per Second: 23,367.08319
Overall Steps per Second: 10,869.59686

Timestep Collection Time: 2.14105
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.60275

Cumulative Model Updates: 179,524
Cumulative Timesteps: 1,497,269,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1497269112...
Checkpoint 1497269112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.92555
Policy Entropy: 2.73328
Value Function Loss: 0.01316

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.17961
Policy Update Magnitude: 0.76697
Value Function Update Magnitude: 0.79182

Collected Steps per Second: 22,517.97677
Overall Steps per Second: 10,746.44960

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.65419

Cumulative Model Updates: 179,530
Cumulative Timesteps: 1,497,319,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.38065
Policy Entropy: 2.72400
Value Function Loss: 0.01225

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.17368
Policy Update Magnitude: 0.77393
Value Function Update Magnitude: 0.78379

Collected Steps per Second: 22,587.44088
Overall Steps per Second: 10,462.21990

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.56682
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.78159

Cumulative Model Updates: 179,536
Cumulative Timesteps: 1,497,369,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1497369154...
Checkpoint 1497369154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.06097
Policy Entropy: 2.70120
Value Function Loss: 0.01241

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.77285
Value Function Update Magnitude: 0.74919

Collected Steps per Second: 22,757.99531
Overall Steps per Second: 10,608.32727

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71498

Cumulative Model Updates: 179,542
Cumulative Timesteps: 1,497,419,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.39549
Policy Entropy: 2.69866
Value Function Loss: 0.01223

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.16891
Policy Update Magnitude: 0.76696
Value Function Update Magnitude: 0.73193

Collected Steps per Second: 22,758.12200
Overall Steps per Second: 10,636.77739

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.70105

Cumulative Model Updates: 179,548
Cumulative Timesteps: 1,497,469,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1497469176...
Checkpoint 1497469176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.26643
Policy Entropy: 2.69517
Value Function Loss: 0.01305

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.17112
Policy Update Magnitude: 0.75365
Value Function Update Magnitude: 0.72257

Collected Steps per Second: 22,278.06362
Overall Steps per Second: 10,614.71302

Timestep Collection Time: 2.24517
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.71214

Cumulative Model Updates: 179,554
Cumulative Timesteps: 1,497,519,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.26988
Policy Entropy: 2.73216
Value Function Loss: 0.01197

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.72607
Value Function Update Magnitude: 0.70480

Collected Steps per Second: 22,279.69198
Overall Steps per Second: 10,698.01316

Timestep Collection Time: 2.24447
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.67433

Cumulative Model Updates: 179,560
Cumulative Timesteps: 1,497,569,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1497569200...
Checkpoint 1497569200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.83640
Policy Entropy: 2.73246
Value Function Loss: 0.01147

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.72738
Value Function Update Magnitude: 0.66360

Collected Steps per Second: 22,244.86866
Overall Steps per Second: 10,714.80341

Timestep Collection Time: 2.24897
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.66905

Cumulative Model Updates: 179,566
Cumulative Timesteps: 1,497,619,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.17688
Policy Entropy: 2.73208
Value Function Loss: 0.01140

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.73465
Value Function Update Magnitude: 0.64140

Collected Steps per Second: 22,569.00657
Overall Steps per Second: 10,599.61450

Timestep Collection Time: 2.21596
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71828

Cumulative Model Updates: 179,572
Cumulative Timesteps: 1,497,669,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1497669240...
Checkpoint 1497669240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.86527
Policy Entropy: 2.70732
Value Function Loss: 0.01244

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.74258
Value Function Update Magnitude: 0.65423

Collected Steps per Second: 22,152.46461
Overall Steps per Second: 10,506.27154

Timestep Collection Time: 2.25763
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.76020

Cumulative Model Updates: 179,578
Cumulative Timesteps: 1,497,719,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.56849
Policy Entropy: 2.70615
Value Function Loss: 0.01228

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.16232
Policy Update Magnitude: 0.74015
Value Function Update Magnitude: 0.68636

Collected Steps per Second: 22,859.89539
Overall Steps per Second: 10,869.53546

Timestep Collection Time: 2.18811
Timestep Consumption Time: 2.41374
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.60185

Cumulative Model Updates: 179,584
Cumulative Timesteps: 1,497,769,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1497769272...
Checkpoint 1497769272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.25818
Policy Entropy: 2.69715
Value Function Loss: 0.01196

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.73661
Value Function Update Magnitude: 0.69635

Collected Steps per Second: 21,993.55592
Overall Steps per Second: 10,623.35867

Timestep Collection Time: 2.27421
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70830

Cumulative Model Updates: 179,590
Cumulative Timesteps: 1,497,819,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.88502
Policy Entropy: 2.70223
Value Function Loss: 0.01185

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.74377
Value Function Update Magnitude: 0.71369

Collected Steps per Second: 23,181.55214
Overall Steps per Second: 10,779.65688

Timestep Collection Time: 2.15723
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.63911

Cumulative Model Updates: 179,596
Cumulative Timesteps: 1,497,869,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1497869298...
Checkpoint 1497869298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.99616
Policy Entropy: 2.69730
Value Function Loss: 0.01179

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.16658
Policy Update Magnitude: 0.74800
Value Function Update Magnitude: 0.73936

Collected Steps per Second: 22,477.65204
Overall Steps per Second: 10,699.73695

Timestep Collection Time: 2.22452
Timestep Consumption Time: 2.44868
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.67320

Cumulative Model Updates: 179,602
Cumulative Timesteps: 1,497,919,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.35208
Policy Entropy: 2.70384
Value Function Loss: 0.01195

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.74529
Value Function Update Magnitude: 0.73227

Collected Steps per Second: 23,087.69433
Overall Steps per Second: 10,670.79948

Timestep Collection Time: 2.16652
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.68756

Cumulative Model Updates: 179,608
Cumulative Timesteps: 1,497,969,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1497969320...
Checkpoint 1497969320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.12906
Policy Entropy: 2.71027
Value Function Loss: 0.01211

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.74783
Value Function Update Magnitude: 0.73275

Collected Steps per Second: 22,622.99927
Overall Steps per Second: 10,447.66670

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.57572
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 4.78595

Cumulative Model Updates: 179,614
Cumulative Timesteps: 1,498,019,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.70728
Policy Entropy: 2.71444
Value Function Loss: 0.01250

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.17952
Policy Update Magnitude: 0.72633
Value Function Update Magnitude: 0.72448

Collected Steps per Second: 22,495.35223
Overall Steps per Second: 10,478.40656

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.54965
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.77286

Cumulative Model Updates: 179,620
Cumulative Timesteps: 1,498,069,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1498069334...
Checkpoint 1498069334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.46906
Policy Entropy: 2.71506
Value Function Loss: 0.01237

Mean KL Divergence: 0.03349
SB3 Clip Fraction: 0.21873
Policy Update Magnitude: 0.72011
Value Function Update Magnitude: 0.74185

Collected Steps per Second: 22,385.57897
Overall Steps per Second: 10,681.58546

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.44776
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.68170

Cumulative Model Updates: 179,626
Cumulative Timesteps: 1,498,119,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.09831
Policy Entropy: 2.72456
Value Function Loss: 0.01240

Mean KL Divergence: 0.03048
SB3 Clip Fraction: 0.21365
Policy Update Magnitude: 0.74689
Value Function Update Magnitude: 0.75224

Collected Steps per Second: 22,953.81568
Overall Steps per Second: 10,796.52573

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.63186

Cumulative Model Updates: 179,632
Cumulative Timesteps: 1,498,169,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1498169350...
Checkpoint 1498169350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.45019
Policy Entropy: 2.71703
Value Function Loss: 0.01244

Mean KL Divergence: 0.02887
SB3 Clip Fraction: 0.20610
Policy Update Magnitude: 0.76115
Value Function Update Magnitude: 0.75152

Collected Steps per Second: 22,914.88539
Overall Steps per Second: 10,743.97183

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.65545

Cumulative Model Updates: 179,638
Cumulative Timesteps: 1,498,219,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.75489
Policy Entropy: 2.72780
Value Function Loss: 0.01278

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.19359
Policy Update Magnitude: 0.76815
Value Function Update Magnitude: 0.75759

Collected Steps per Second: 22,402.98181
Overall Steps per Second: 10,833.10169

Timestep Collection Time: 2.23274
Timestep Consumption Time: 2.38459
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.61733

Cumulative Model Updates: 179,644
Cumulative Timesteps: 1,498,269,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1498269388...
Checkpoint 1498269388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.19377
Policy Entropy: 2.72131
Value Function Loss: 0.01269

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.19341
Policy Update Magnitude: 0.76083
Value Function Update Magnitude: 0.76442

Collected Steps per Second: 22,302.59259
Overall Steps per Second: 10,665.57592

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.68817

Cumulative Model Updates: 179,650
Cumulative Timesteps: 1,498,319,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.36444
Policy Entropy: 2.73467
Value Function Loss: 0.01283

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.18392
Policy Update Magnitude: 0.75196
Value Function Update Magnitude: 0.74975

Collected Steps per Second: 23,005.15392
Overall Steps per Second: 10,695.92944

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.50175
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67561

Cumulative Model Updates: 179,656
Cumulative Timesteps: 1,498,369,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1498369400...
Checkpoint 1498369400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.32878
Policy Entropy: 2.71281
Value Function Loss: 0.01203

Mean KL Divergence: 0.02224
SB3 Clip Fraction: 0.18242
Policy Update Magnitude: 0.73758
Value Function Update Magnitude: 0.71936

Collected Steps per Second: 22,923.44332
Overall Steps per Second: 10,809.62856

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.44560
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.62791

Cumulative Model Updates: 179,662
Cumulative Timesteps: 1,498,419,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.67707
Policy Entropy: 2.72476
Value Function Loss: 0.01209

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.16790
Policy Update Magnitude: 0.72419
Value Function Update Magnitude: 0.72522

Collected Steps per Second: 22,951.66969
Overall Steps per Second: 10,656.35073

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.69467

Cumulative Model Updates: 179,668
Cumulative Timesteps: 1,498,469,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1498469454...
Checkpoint 1498469454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.58013
Policy Entropy: 2.72513
Value Function Loss: 0.01268

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.15531
Policy Update Magnitude: 0.72879
Value Function Update Magnitude: 0.73204

Collected Steps per Second: 22,505.13483
Overall Steps per Second: 10,568.30452

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.73170

Cumulative Model Updates: 179,674
Cumulative Timesteps: 1,498,519,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.50966
Policy Entropy: 2.73097
Value Function Loss: 0.01223

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.72734
Value Function Update Magnitude: 0.72521

Collected Steps per Second: 22,543.18711
Overall Steps per Second: 10,649.73546

Timestep Collection Time: 2.21797
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.69495

Cumulative Model Updates: 179,680
Cumulative Timesteps: 1,498,569,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1498569460...
Checkpoint 1498569460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.78329
Policy Entropy: 2.73450
Value Function Loss: 0.01233

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.72231
Value Function Update Magnitude: 0.71357

Collected Steps per Second: 22,364.30714
Overall Steps per Second: 10,652.81312

Timestep Collection Time: 2.23571
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.69360

Cumulative Model Updates: 179,686
Cumulative Timesteps: 1,498,619,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.95149
Policy Entropy: 2.73689
Value Function Loss: 0.01157

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.72697
Value Function Update Magnitude: 0.72036

Collected Steps per Second: 22,683.29213
Overall Steps per Second: 10,747.28901

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.44866
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.65345

Cumulative Model Updates: 179,692
Cumulative Timesteps: 1,498,669,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1498669472...
Checkpoint 1498669472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.07894
Policy Entropy: 2.74576
Value Function Loss: 0.01191

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.72235
Value Function Update Magnitude: 0.70498

Collected Steps per Second: 21,422.76024
Overall Steps per Second: 10,497.39564

Timestep Collection Time: 2.33527
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.76575

Cumulative Model Updates: 179,698
Cumulative Timesteps: 1,498,719,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.67555
Policy Entropy: 2.72803
Value Function Loss: 0.01232

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.72288
Value Function Update Magnitude: 0.69149

Collected Steps per Second: 22,997.84265
Overall Steps per Second: 10,571.59062

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.55574
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.73004

Cumulative Model Updates: 179,704
Cumulative Timesteps: 1,498,769,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1498769504...
Checkpoint 1498769504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.01983
Policy Entropy: 2.71544
Value Function Loss: 0.01323

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.74072
Value Function Update Magnitude: 0.73593

Collected Steps per Second: 22,904.53948
Overall Steps per Second: 10,588.74431

Timestep Collection Time: 2.18306
Timestep Consumption Time: 2.53912
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.72218

Cumulative Model Updates: 179,710
Cumulative Timesteps: 1,498,819,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.33877
Policy Entropy: 2.70298
Value Function Loss: 0.01301

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.16613
Policy Update Magnitude: 0.72643
Value Function Update Magnitude: 0.77043

Collected Steps per Second: 22,631.49479
Overall Steps per Second: 10,610.08048

Timestep Collection Time: 2.21072
Timestep Consumption Time: 2.50479
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.71552

Cumulative Model Updates: 179,716
Cumulative Timesteps: 1,498,869,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1498869538...
Checkpoint 1498869538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.34123
Policy Entropy: 2.70729
Value Function Loss: 0.01288

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.17178
Policy Update Magnitude: 0.71803
Value Function Update Magnitude: 0.75094

Collected Steps per Second: 22,636.62861
Overall Steps per Second: 10,708.62894

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.46091
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.67025

Cumulative Model Updates: 179,722
Cumulative Timesteps: 1,498,919,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.69058
Policy Entropy: 2.72960
Value Function Loss: 0.01264

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.72918
Value Function Update Magnitude: 0.73988

Collected Steps per Second: 22,930.57100
Overall Steps per Second: 10,679.53337

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.68185

Cumulative Model Updates: 179,728
Cumulative Timesteps: 1,498,969,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1498969550...
Checkpoint 1498969550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.58747
Policy Entropy: 2.74725
Value Function Loss: 0.01235

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.17157
Policy Update Magnitude: 0.71874
Value Function Update Magnitude: 0.75246

Collected Steps per Second: 22,723.63856
Overall Steps per Second: 10,840.00196

Timestep Collection Time: 2.20070
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.61328

Cumulative Model Updates: 179,734
Cumulative Timesteps: 1,499,019,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.34350
Policy Entropy: 2.73389
Value Function Loss: 0.01282

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.18876
Policy Update Magnitude: 0.68543
Value Function Update Magnitude: 0.76439

Collected Steps per Second: 23,045.74455
Overall Steps per Second: 10,748.07717

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.65367

Cumulative Model Updates: 179,740
Cumulative Timesteps: 1,499,069,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1499069576...
Checkpoint 1499069576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.79507
Policy Entropy: 2.70776
Value Function Loss: 0.01380

Mean KL Divergence: 0.03132
SB3 Clip Fraction: 0.21309
Policy Update Magnitude: 0.69172
Value Function Update Magnitude: 0.76453

Collected Steps per Second: 22,219.83965
Overall Steps per Second: 10,663.24883

Timestep Collection Time: 2.25060
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.68975

Cumulative Model Updates: 179,746
Cumulative Timesteps: 1,499,119,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.68235
Policy Entropy: 2.70002
Value Function Loss: 0.01398

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.19849
Policy Update Magnitude: 0.75636
Value Function Update Magnitude: 0.76467

Collected Steps per Second: 22,489.43818
Overall Steps per Second: 10,601.39854

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.71787

Cumulative Model Updates: 179,752
Cumulative Timesteps: 1,499,169,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1499169600...
Checkpoint 1499169600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.15120
Policy Entropy: 2.69896
Value Function Loss: 0.01395

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.20849
Policy Update Magnitude: 0.77241
Value Function Update Magnitude: 0.78322

Collected Steps per Second: 22,480.76788
Overall Steps per Second: 10,581.24274

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.72704

Cumulative Model Updates: 179,758
Cumulative Timesteps: 1,499,219,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.53197
Policy Entropy: 2.71665
Value Function Loss: 0.01344

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.18717
Policy Update Magnitude: 0.75999
Value Function Update Magnitude: 0.79378

Collected Steps per Second: 22,271.22900
Overall Steps per Second: 10,719.93684

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.66589

Cumulative Model Updates: 179,764
Cumulative Timesteps: 1,499,269,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1499269636...
Checkpoint 1499269636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.05558
Policy Entropy: 2.71545
Value Function Loss: 0.01349

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.75068
Value Function Update Magnitude: 0.78463

Collected Steps per Second: 22,277.15772
Overall Steps per Second: 10,682.55477

Timestep Collection Time: 2.24526
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.68221

Cumulative Model Updates: 179,770
Cumulative Timesteps: 1,499,319,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.76350
Policy Entropy: 2.73220
Value Function Loss: 0.01338

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.75506
Value Function Update Magnitude: 0.77567

Collected Steps per Second: 22,735.63923
Overall Steps per Second: 10,885.56033

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.39530
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59563

Cumulative Model Updates: 179,776
Cumulative Timesteps: 1,499,369,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1499369680...
Checkpoint 1499369680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.19200
Policy Entropy: 2.72262
Value Function Loss: 0.01464

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.76072
Value Function Update Magnitude: 0.79505

Collected Steps per Second: 22,759.50381
Overall Steps per Second: 10,695.23406

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.67535

Cumulative Model Updates: 179,782
Cumulative Timesteps: 1,499,419,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.68842
Policy Entropy: 2.71320
Value Function Loss: 0.01487

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.75483
Value Function Update Magnitude: 0.80180

Collected Steps per Second: 23,113.30584
Overall Steps per Second: 10,842.09879

Timestep Collection Time: 2.16438
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.61405

Cumulative Model Updates: 179,788
Cumulative Timesteps: 1,499,469,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1499469710...
Checkpoint 1499469710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.68671
Policy Entropy: 2.69905
Value Function Loss: 0.01472

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.74632
Value Function Update Magnitude: 0.79468

Collected Steps per Second: 22,936.85582
Overall Steps per Second: 10,673.10490

Timestep Collection Time: 2.18060
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68617

Cumulative Model Updates: 179,794
Cumulative Timesteps: 1,499,519,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.16056
Policy Entropy: 2.68252
Value Function Loss: 0.01515

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.75085
Value Function Update Magnitude: 0.78626

Collected Steps per Second: 22,769.82152
Overall Steps per Second: 10,639.95351

Timestep Collection Time: 2.19694
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70152

Cumulative Model Updates: 179,800
Cumulative Timesteps: 1,499,569,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1499569750...
Checkpoint 1499569750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.05179
Policy Entropy: 2.68768
Value Function Loss: 0.01580

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.16583
Policy Update Magnitude: 0.75228
Value Function Update Magnitude: 0.77763

Collected Steps per Second: 22,996.72141
Overall Steps per Second: 10,859.42125

Timestep Collection Time: 2.17527
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.60651

Cumulative Model Updates: 179,806
Cumulative Timesteps: 1,499,619,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.53874
Policy Entropy: 2.69408
Value Function Loss: 0.01547

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.16786
Policy Update Magnitude: 0.73529
Value Function Update Magnitude: 0.77926

Collected Steps per Second: 22,266.04330
Overall Steps per Second: 10,709.90584

Timestep Collection Time: 2.24656
Timestep Consumption Time: 2.42407
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.67063

Cumulative Model Updates: 179,812
Cumulative Timesteps: 1,499,669,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1499669796...
Checkpoint 1499669796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.58607
Policy Entropy: 2.73118
Value Function Loss: 0.01438

Mean KL Divergence: 0.02944
SB3 Clip Fraction: 0.20061
Policy Update Magnitude: 0.69428
Value Function Update Magnitude: 0.77107

Collected Steps per Second: 22,561.21332
Overall Steps per Second: 10,624.06177

Timestep Collection Time: 2.21681
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.70762

Cumulative Model Updates: 179,818
Cumulative Timesteps: 1,499,719,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.35164
Policy Entropy: 2.73703
Value Function Loss: 0.01342

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.19154
Policy Update Magnitude: 0.68588
Value Function Update Magnitude: 0.71026

Collected Steps per Second: 22,425.92296
Overall Steps per Second: 10,685.43717

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.45049
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.68076

Cumulative Model Updates: 179,824
Cumulative Timesteps: 1,499,769,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1499769826...
Checkpoint 1499769826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.04415
Policy Entropy: 2.73238
Value Function Loss: 0.01385

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.71929
Value Function Update Magnitude: 0.69635

Collected Steps per Second: 22,535.02796
Overall Steps per Second: 10,733.43055

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.65890

Cumulative Model Updates: 179,830
Cumulative Timesteps: 1,499,819,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.40354
Policy Entropy: 2.72928
Value Function Loss: 0.01391

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.73589
Value Function Update Magnitude: 0.73584

Collected Steps per Second: 22,764.69602
Overall Steps per Second: 10,555.57262

Timestep Collection Time: 2.19753
Timestep Consumption Time: 2.54177
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.73930

Cumulative Model Updates: 179,836
Cumulative Timesteps: 1,499,869,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1499869858...
Checkpoint 1499869858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.16207
Policy Entropy: 2.72508
Value Function Loss: 0.01372

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.72648
Value Function Update Magnitude: 0.73549

Collected Steps per Second: 22,710.71617
Overall Steps per Second: 10,685.47648

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.68000

Cumulative Model Updates: 179,842
Cumulative Timesteps: 1,499,919,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.33176
Policy Entropy: 2.74759
Value Function Loss: 0.01353

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.17769
Policy Update Magnitude: 0.72393
Value Function Update Magnitude: 0.72647

Collected Steps per Second: 22,897.14290
Overall Steps per Second: 10,710.10988

Timestep Collection Time: 2.18394
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.66905

Cumulative Model Updates: 179,848
Cumulative Timesteps: 1,499,969,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1499969872...
Checkpoint 1499969872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.28714
Policy Entropy: 2.73114
Value Function Loss: 0.01403

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.16402
Policy Update Magnitude: 0.72436
Value Function Update Magnitude: 0.74068

Collected Steps per Second: 22,799.22329
Overall Steps per Second: 10,656.18182

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.50055
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 4.69493

Cumulative Model Updates: 179,854
Cumulative Timesteps: 1,500,019,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.97930
Policy Entropy: 2.73263
Value Function Loss: 0.01332

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.72667
Value Function Update Magnitude: 0.74848

Collected Steps per Second: 22,282.95667
Overall Steps per Second: 10,742.74061

Timestep Collection Time: 2.24485
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.65635

Cumulative Model Updates: 179,860
Cumulative Timesteps: 1,500,069,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1500069924...
Checkpoint 1500069924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.14039
Policy Entropy: 2.70872
Value Function Loss: 0.01318

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.71883
Value Function Update Magnitude: 0.74837

Collected Steps per Second: 22,824.59654
Overall Steps per Second: 10,813.70924

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62432

Cumulative Model Updates: 179,866
Cumulative Timesteps: 1,500,119,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.80618
Policy Entropy: 2.69614
Value Function Loss: 0.01330

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.72326
Value Function Update Magnitude: 0.73460

Collected Steps per Second: 22,850.82680
Overall Steps per Second: 10,778.51976

Timestep Collection Time: 2.18907
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.64090

Cumulative Model Updates: 179,872
Cumulative Timesteps: 1,500,169,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1500169952...
Checkpoint 1500169952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.57955
Policy Entropy: 2.69681
Value Function Loss: 0.01407

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.72407
Value Function Update Magnitude: 0.72761

Collected Steps per Second: 22,284.84187
Overall Steps per Second: 10,735.46246

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.41465
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.65914

Cumulative Model Updates: 179,878
Cumulative Timesteps: 1,500,219,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.39942
Policy Entropy: 2.70036
Value Function Loss: 0.01355

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.70263
Value Function Update Magnitude: 0.72061

Collected Steps per Second: 22,301.51372
Overall Steps per Second: 10,586.66704

Timestep Collection Time: 2.24281
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.72462

Cumulative Model Updates: 179,884
Cumulative Timesteps: 1,500,269,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1500269988...
Checkpoint 1500269988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.34600
Policy Entropy: 2.69680
Value Function Loss: 0.01312

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.70353
Value Function Update Magnitude: 0.70228

Collected Steps per Second: 22,323.62506
Overall Steps per Second: 10,557.17296

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.73612

Cumulative Model Updates: 179,890
Cumulative Timesteps: 1,500,319,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.38450
Policy Entropy: 2.70081
Value Function Loss: 0.01174

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.15598
Policy Update Magnitude: 0.70467
Value Function Update Magnitude: 0.71329

Collected Steps per Second: 22,779.86139
Overall Steps per Second: 10,882.86515

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.40157
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.59842

Cumulative Model Updates: 179,896
Cumulative Timesteps: 1,500,370,032

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1500370032...
Checkpoint 1500370032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.04460
Policy Entropy: 2.68397
Value Function Loss: 0.01206

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.70376
Value Function Update Magnitude: 0.71269

Collected Steps per Second: 22,286.03705
Overall Steps per Second: 10,638.03274

Timestep Collection Time: 2.24472
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.70256

Cumulative Model Updates: 179,902
Cumulative Timesteps: 1,500,420,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.08893
Policy Entropy: 2.70329
Value Function Loss: 0.01292

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.71435
Value Function Update Magnitude: 0.70895

Collected Steps per Second: 22,823.73976
Overall Steps per Second: 10,657.21246

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69260

Cumulative Model Updates: 179,908
Cumulative Timesteps: 1,500,470,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1500470068...
Checkpoint 1500470068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.02923
Policy Entropy: 2.68506
Value Function Loss: 0.01444

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.72984
Value Function Update Magnitude: 0.72411

Collected Steps per Second: 22,960.57668
Overall Steps per Second: 10,830.70343

Timestep Collection Time: 2.17834
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.61798

Cumulative Model Updates: 179,914
Cumulative Timesteps: 1,500,520,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.45309
Policy Entropy: 2.70062
Value Function Loss: 0.01505

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.73735
Value Function Update Magnitude: 0.74336

Collected Steps per Second: 22,703.67053
Overall Steps per Second: 10,562.61511

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.53220
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.73519

Cumulative Model Updates: 179,920
Cumulative Timesteps: 1,500,570,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1500570100...
Checkpoint 1500570100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.82633
Policy Entropy: 2.69654
Value Function Loss: 0.01503

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.72862
Value Function Update Magnitude: 0.76101

Collected Steps per Second: 22,932.19730
Overall Steps per Second: 10,634.51192

Timestep Collection Time: 2.18121
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.70355

Cumulative Model Updates: 179,926
Cumulative Timesteps: 1,500,620,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.03781
Policy Entropy: 2.69202
Value Function Loss: 0.01470

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.72547
Value Function Update Magnitude: 0.75452

Collected Steps per Second: 22,783.83640
Overall Steps per Second: 10,827.41085

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.42405
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.61920

Cumulative Model Updates: 179,932
Cumulative Timesteps: 1,500,670,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1500670134...
Checkpoint 1500670134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.86480
Policy Entropy: 2.68513
Value Function Loss: 0.01357

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.70952
Value Function Update Magnitude: 0.72810

Collected Steps per Second: 22,317.53820
Overall Steps per Second: 10,533.92439

Timestep Collection Time: 2.24111
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.30687
Total Iteration Time: 4.74809

Cumulative Model Updates: 179,938
Cumulative Timesteps: 1,500,720,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.62537
Policy Entropy: 2.66621
Value Function Loss: 0.01461

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.70962
Value Function Update Magnitude: 0.71636

Collected Steps per Second: 21,315.98731
Overall Steps per Second: 10,296.54744

Timestep Collection Time: 2.34622
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.85716

Cumulative Model Updates: 179,944
Cumulative Timesteps: 1,500,770,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1500770162...
Checkpoint 1500770162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.89731
Policy Entropy: 2.68500
Value Function Loss: 0.01434

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.70901
Value Function Update Magnitude: 0.71153

Collected Steps per Second: 22,630.47251
Overall Steps per Second: 10,604.24004

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.71623

Cumulative Model Updates: 179,950
Cumulative Timesteps: 1,500,820,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.74940
Policy Entropy: 2.67328
Value Function Loss: 0.01461

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.70696
Value Function Update Magnitude: 0.71213

Collected Steps per Second: 22,683.75261
Overall Steps per Second: 10,742.49459

Timestep Collection Time: 2.20572
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.65758

Cumulative Model Updates: 179,956
Cumulative Timesteps: 1,500,870,208

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1500870208...
Checkpoint 1500870208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.57566
Policy Entropy: 2.67834
Value Function Loss: 0.01486

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.71651
Value Function Update Magnitude: 0.70974

Collected Steps per Second: 22,756.95101
Overall Steps per Second: 10,656.17510

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.69324

Cumulative Model Updates: 179,962
Cumulative Timesteps: 1,500,920,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.54058
Policy Entropy: 2.67421
Value Function Loss: 0.01429

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.71087
Value Function Update Magnitude: 0.71553

Collected Steps per Second: 23,107.78241
Overall Steps per Second: 10,850.90998

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.61049

Cumulative Model Updates: 179,968
Cumulative Timesteps: 1,500,970,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1500970248...
Checkpoint 1500970248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.70815
Policy Entropy: 2.68132
Value Function Loss: 0.01416

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.70425
Value Function Update Magnitude: 0.70149

Collected Steps per Second: 22,890.61320
Overall Steps per Second: 10,807.53008

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.62751

Cumulative Model Updates: 179,974
Cumulative Timesteps: 1,501,020,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.71246
Policy Entropy: 2.70271
Value Function Loss: 0.01346

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.69920
Value Function Update Magnitude: 0.68083

Collected Steps per Second: 23,069.79878
Overall Steps per Second: 10,832.80561

Timestep Collection Time: 2.16820
Timestep Consumption Time: 2.44925
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.61746

Cumulative Model Updates: 179,980
Cumulative Timesteps: 1,501,070,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1501070280...
Checkpoint 1501070280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.22146
Policy Entropy: 2.70178
Value Function Loss: 0.01376

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.69969
Value Function Update Magnitude: 0.67758

Collected Steps per Second: 22,788.64712
Overall Steps per Second: 10,670.43003

Timestep Collection Time: 2.19469
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68716

Cumulative Model Updates: 179,986
Cumulative Timesteps: 1,501,120,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.52077
Policy Entropy: 2.69007
Value Function Loss: 0.01354

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.70006
Value Function Update Magnitude: 0.68467

Collected Steps per Second: 22,950.31598
Overall Steps per Second: 10,825.83038

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.62006

Cumulative Model Updates: 179,992
Cumulative Timesteps: 1,501,170,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1501170310...
Checkpoint 1501170310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.86524
Policy Entropy: 2.67136
Value Function Loss: 0.01538

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.70895
Value Function Update Magnitude: 0.68203

Collected Steps per Second: 22,264.74956
Overall Steps per Second: 10,716.60262

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.66678

Cumulative Model Updates: 179,998
Cumulative Timesteps: 1,501,220,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.29633
Policy Entropy: 2.66249
Value Function Loss: 0.01571

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.72671
Value Function Update Magnitude: 0.71195

Collected Steps per Second: 22,332.68992
Overall Steps per Second: 10,525.92964

Timestep Collection Time: 2.23941
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.75131

Cumulative Model Updates: 180,004
Cumulative Timesteps: 1,501,270,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1501270334...
Checkpoint 1501270334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.77290
Policy Entropy: 2.65304
Value Function Loss: 0.01536

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.73069
Value Function Update Magnitude: 0.73063

Collected Steps per Second: 22,138.20772
Overall Steps per Second: 10,663.79592

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.68989

Cumulative Model Updates: 180,010
Cumulative Timesteps: 1,501,320,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.82177
Policy Entropy: 2.64459
Value Function Loss: 0.01489

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.72543
Value Function Update Magnitude: 0.71779

Collected Steps per Second: 21,858.19199
Overall Steps per Second: 10,460.22304

Timestep Collection Time: 2.28765
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.78040

Cumulative Model Updates: 180,016
Cumulative Timesteps: 1,501,370,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1501370350...
Checkpoint 1501370350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.45321
Policy Entropy: 2.66213
Value Function Loss: 0.01522

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.71182
Value Function Update Magnitude: 0.70767

Collected Steps per Second: 22,061.59623
Overall Steps per Second: 10,593.16246

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.45472
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.72210

Cumulative Model Updates: 180,022
Cumulative Timesteps: 1,501,420,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.28715
Policy Entropy: 2.69451
Value Function Loss: 0.01530

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.71396
Value Function Update Magnitude: 0.69705

Collected Steps per Second: 23,096.08348
Overall Steps per Second: 10,621.40734

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.54281
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70785

Cumulative Model Updates: 180,028
Cumulative Timesteps: 1,501,470,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1501470376...
Checkpoint 1501470376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.58777
Policy Entropy: 2.70863
Value Function Loss: 0.01528

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.70678
Value Function Update Magnitude: 0.69991

Collected Steps per Second: 22,540.68400
Overall Steps per Second: 10,559.61528

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.51822
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.73767

Cumulative Model Updates: 180,034
Cumulative Timesteps: 1,501,520,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.23577
Policy Entropy: 2.71679
Value Function Loss: 0.01456

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.70213
Value Function Update Magnitude: 0.70847

Collected Steps per Second: 22,969.75398
Overall Steps per Second: 10,886.89313

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.41590
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.59268

Cumulative Model Updates: 180,040
Cumulative Timesteps: 1,501,570,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1501570404...
Checkpoint 1501570404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.11845
Policy Entropy: 2.69719
Value Function Loss: 0.01445

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.70108
Value Function Update Magnitude: 0.70946

Collected Steps per Second: 22,851.95298
Overall Steps per Second: 10,685.20273

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.67937

Cumulative Model Updates: 180,046
Cumulative Timesteps: 1,501,620,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.43690
Policy Entropy: 2.68648
Value Function Loss: 0.01393

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.69925
Value Function Update Magnitude: 0.68823

Collected Steps per Second: 22,988.00610
Overall Steps per Second: 10,825.63679

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.62125

Cumulative Model Updates: 180,052
Cumulative Timesteps: 1,501,670,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1501670432...
Checkpoint 1501670432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.29522
Policy Entropy: 2.67109
Value Function Loss: 0.01361

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.69122
Value Function Update Magnitude: 0.67013

Collected Steps per Second: 22,880.90458
Overall Steps per Second: 10,621.05304

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.70989

Cumulative Model Updates: 180,058
Cumulative Timesteps: 1,501,720,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.94358
Policy Entropy: 2.67201
Value Function Loss: 0.01339

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.67763
Value Function Update Magnitude: 0.63950

Collected Steps per Second: 22,660.60922
Overall Steps per Second: 10,615.91312

Timestep Collection Time: 2.20735
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71179

Cumulative Model Updates: 180,064
Cumulative Timesteps: 1,501,770,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1501770476...
Checkpoint 1501770476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.28493
Policy Entropy: 2.67228
Value Function Loss: 0.01381

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.67953
Value Function Update Magnitude: 0.65195

Collected Steps per Second: 22,496.13736
Overall Steps per Second: 10,562.83646

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.73433

Cumulative Model Updates: 180,070
Cumulative Timesteps: 1,501,820,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.08228
Policy Entropy: 2.67795
Value Function Loss: 0.01476

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.68473
Value Function Update Magnitude: 0.65520

Collected Steps per Second: 22,621.24720
Overall Steps per Second: 10,807.36698

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62684

Cumulative Model Updates: 180,076
Cumulative Timesteps: 1,501,870,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1501870488...
Checkpoint 1501870488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.74683
Policy Entropy: 2.66359
Value Function Loss: 0.01447

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.68118
Value Function Update Magnitude: 0.65620

Collected Steps per Second: 21,960.11576
Overall Steps per Second: 10,630.89595

Timestep Collection Time: 2.27731
Timestep Consumption Time: 2.42690
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.70421

Cumulative Model Updates: 180,082
Cumulative Timesteps: 1,501,920,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.76608
Policy Entropy: 2.67268
Value Function Loss: 0.01449

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.68202
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 22,742.81536
Overall Steps per Second: 10,917.54168

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.38224
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.58162

Cumulative Model Updates: 180,088
Cumulative Timesteps: 1,501,970,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1501970518...
Checkpoint 1501970518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.79115
Policy Entropy: 2.67126
Value Function Loss: 0.01416

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.68031
Value Function Update Magnitude: 0.64774

Collected Steps per Second: 22,909.39937
Overall Steps per Second: 10,559.88458

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.55331
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.73660

Cumulative Model Updates: 180,094
Cumulative Timesteps: 1,502,020,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.45255
Policy Entropy: 2.68080
Value Function Loss: 0.01450

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.67964
Value Function Update Magnitude: 0.66347

Collected Steps per Second: 22,596.74026
Overall Steps per Second: 10,573.70667

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.51681
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.73022

Cumulative Model Updates: 180,100
Cumulative Timesteps: 1,502,070,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1502070552...
Checkpoint 1502070552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.49263
Policy Entropy: 2.66106
Value Function Loss: 0.01496

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.69243
Value Function Update Magnitude: 0.66061

Collected Steps per Second: 22,992.19920
Overall Steps per Second: 10,648.16597

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.52251
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.69846

Cumulative Model Updates: 180,106
Cumulative Timesteps: 1,502,120,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.41147
Policy Entropy: 2.65704
Value Function Loss: 0.01432

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.68346
Value Function Update Magnitude: 0.66936

Collected Steps per Second: 22,586.07997
Overall Steps per Second: 10,617.46255

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71111

Cumulative Model Updates: 180,112
Cumulative Timesteps: 1,502,170,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1502170602...
Checkpoint 1502170602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.03854
Policy Entropy: 2.66407
Value Function Loss: 0.01430

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.68044
Value Function Update Magnitude: 0.66595

Collected Steps per Second: 22,997.11856
Overall Steps per Second: 10,867.04672

Timestep Collection Time: 2.17506
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.60291

Cumulative Model Updates: 180,118
Cumulative Timesteps: 1,502,220,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.81832
Policy Entropy: 2.66376
Value Function Loss: 0.01430

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.68304
Value Function Update Magnitude: 0.66782

Collected Steps per Second: 22,842.86017
Overall Steps per Second: 10,952.51520

Timestep Collection Time: 2.18974
Timestep Consumption Time: 2.37724
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.56699

Cumulative Model Updates: 180,124
Cumulative Timesteps: 1,502,270,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1502270642...
Checkpoint 1502270642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.86960
Policy Entropy: 2.68109
Value Function Loss: 0.01441

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.69394
Value Function Update Magnitude: 0.68120

Collected Steps per Second: 22,749.35604
Overall Steps per Second: 10,705.80753

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.67279

Cumulative Model Updates: 180,130
Cumulative Timesteps: 1,502,320,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.91794
Policy Entropy: 2.68386
Value Function Loss: 0.01474

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.68988
Value Function Update Magnitude: 0.69099

Collected Steps per Second: 22,614.01137
Overall Steps per Second: 10,565.89353

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.73448

Cumulative Model Updates: 180,136
Cumulative Timesteps: 1,502,370,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1502370692...
Checkpoint 1502370692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.73257
Policy Entropy: 2.69595
Value Function Loss: 0.01412

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.68137
Value Function Update Magnitude: 0.69030

Collected Steps per Second: 22,611.85758
Overall Steps per Second: 10,579.67160

Timestep Collection Time: 2.21247
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.72869

Cumulative Model Updates: 180,142
Cumulative Timesteps: 1,502,420,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.72321
Policy Entropy: 2.66461
Value Function Loss: 0.01454

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.67383
Value Function Update Magnitude: 0.67322

Collected Steps per Second: 22,390.18317
Overall Steps per Second: 10,740.70391

Timestep Collection Time: 2.23339
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.65575

Cumulative Model Updates: 180,148
Cumulative Timesteps: 1,502,470,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1502470726...
Checkpoint 1502470726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.71230
Policy Entropy: 2.64775
Value Function Loss: 0.01478

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.67660
Value Function Update Magnitude: 0.66889

Collected Steps per Second: 22,404.21390
Overall Steps per Second: 10,764.61461

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.64559

Cumulative Model Updates: 180,154
Cumulative Timesteps: 1,502,520,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.51602
Policy Entropy: 2.64164
Value Function Loss: 0.01520

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.67903
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 23,296.59055
Overall Steps per Second: 10,858.72617

Timestep Collection Time: 2.14658
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.60533

Cumulative Model Updates: 180,160
Cumulative Timesteps: 1,502,570,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1502570742...
Checkpoint 1502570742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.80677
Policy Entropy: 2.64166
Value Function Loss: 0.01548

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.67411
Value Function Update Magnitude: 0.69545

Collected Steps per Second: 22,781.23456
Overall Steps per Second: 10,629.81980

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.70525

Cumulative Model Updates: 180,166
Cumulative Timesteps: 1,502,620,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.50497
Policy Entropy: 2.64239
Value Function Loss: 0.01548

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.68761
Value Function Update Magnitude: 0.72144

Collected Steps per Second: 21,698.75538
Overall Steps per Second: 10,355.96330

Timestep Collection Time: 2.30437
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.82833

Cumulative Model Updates: 180,172
Cumulative Timesteps: 1,502,670,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1502670760...
Checkpoint 1502670760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.35017
Policy Entropy: 2.62739
Value Function Loss: 0.01512

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.68807
Value Function Update Magnitude: 0.70065

Collected Steps per Second: 22,804.81430
Overall Steps per Second: 10,623.02921

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.70732

Cumulative Model Updates: 180,178
Cumulative Timesteps: 1,502,720,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.28317
Policy Entropy: 2.62337
Value Function Loss: 0.01460

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.67244
Value Function Update Magnitude: 0.65322

Collected Steps per Second: 23,071.55430
Overall Steps per Second: 10,790.38467

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.63450

Cumulative Model Updates: 180,184
Cumulative Timesteps: 1,502,770,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1502770774...
Checkpoint 1502770774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.71293
Policy Entropy: 2.62992
Value Function Loss: 0.01510

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.67076
Value Function Update Magnitude: 0.63118

Collected Steps per Second: 22,713.64351
Overall Steps per Second: 10,972.02003

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.35573
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.55705

Cumulative Model Updates: 180,190
Cumulative Timesteps: 1,502,820,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.04251
Policy Entropy: 2.62429
Value Function Loss: 0.01593

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.69091
Value Function Update Magnitude: 0.65344

Collected Steps per Second: 22,613.34969
Overall Steps per Second: 10,627.92736

Timestep Collection Time: 2.21250
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.70760

Cumulative Model Updates: 180,196
Cumulative Timesteps: 1,502,870,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1502870806...
Checkpoint 1502870806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.74197
Policy Entropy: 2.66105
Value Function Loss: 0.01525

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.67908
Value Function Update Magnitude: 0.67833

Collected Steps per Second: 22,673.99257
Overall Steps per Second: 10,690.17225

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67888

Cumulative Model Updates: 180,202
Cumulative Timesteps: 1,502,920,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.49227
Policy Entropy: 2.64879
Value Function Loss: 0.01470

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.65204
Value Function Update Magnitude: 0.67339

Collected Steps per Second: 22,808.51222
Overall Steps per Second: 10,656.18387

Timestep Collection Time: 2.19234
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.69249

Cumulative Model Updates: 180,208
Cumulative Timesteps: 1,502,970,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1502970828...
Checkpoint 1502970828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.98741
Policy Entropy: 2.65280
Value Function Loss: 0.01531

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.67537
Value Function Update Magnitude: 0.67640

Collected Steps per Second: 22,289.10131
Overall Steps per Second: 10,629.05021

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.70654

Cumulative Model Updates: 180,214
Cumulative Timesteps: 1,503,020,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.62531
Policy Entropy: 2.63485
Value Function Loss: 0.01607

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.68428
Value Function Update Magnitude: 0.69717

Collected Steps per Second: 22,994.51166
Overall Steps per Second: 10,840.31377

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.61334

Cumulative Model Updates: 180,220
Cumulative Timesteps: 1,503,070,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1503070864...
Checkpoint 1503070864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.85333
Policy Entropy: 2.62797
Value Function Loss: 0.01647

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.15580
Policy Update Magnitude: 0.68914
Value Function Update Magnitude: 0.70840

Collected Steps per Second: 22,735.81972
Overall Steps per Second: 10,753.06670

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.65300

Cumulative Model Updates: 180,226
Cumulative Timesteps: 1,503,120,898

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.93012
Policy Entropy: 2.61138
Value Function Loss: 0.01496

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.17374
Policy Update Magnitude: 0.68378
Value Function Update Magnitude: 0.71209

Collected Steps per Second: 23,053.26216
Overall Steps per Second: 10,828.74906

Timestep Collection Time: 2.16898
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.61752

Cumulative Model Updates: 180,232
Cumulative Timesteps: 1,503,170,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1503170900...
Checkpoint 1503170900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.32620
Policy Entropy: 2.59844
Value Function Loss: 0.01452

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.69934
Value Function Update Magnitude: 0.71268

Collected Steps per Second: 22,640.07363
Overall Steps per Second: 10,665.72365

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.68848

Cumulative Model Updates: 180,238
Cumulative Timesteps: 1,503,220,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.77617
Policy Entropy: 2.60644
Value Function Loss: 0.01473

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.18243
Policy Update Magnitude: 0.70638
Value Function Update Magnitude: 0.72199

Collected Steps per Second: 22,786.23106
Overall Steps per Second: 10,650.92965

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.50012
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.69443

Cumulative Model Updates: 180,244
Cumulative Timesteps: 1,503,270,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1503270906...
Checkpoint 1503270906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.36617
Policy Entropy: 2.62968
Value Function Loss: 0.01582

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.68765
Value Function Update Magnitude: 0.71718

Collected Steps per Second: 22,643.61102
Overall Steps per Second: 10,829.63938

Timestep Collection Time: 2.20857
Timestep Consumption Time: 2.40931
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61788

Cumulative Model Updates: 180,250
Cumulative Timesteps: 1,503,320,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.68510
Policy Entropy: 2.63403
Value Function Loss: 0.01566

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.69064
Value Function Update Magnitude: 0.73762

Collected Steps per Second: 22,097.36428
Overall Steps per Second: 10,541.17038

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74558

Cumulative Model Updates: 180,256
Cumulative Timesteps: 1,503,370,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1503370940...
Checkpoint 1503370940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.04687
Policy Entropy: 2.63859
Value Function Loss: 0.01543

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.68526
Value Function Update Magnitude: 0.75437

Collected Steps per Second: 22,054.03857
Overall Steps per Second: 10,653.33889

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.69412

Cumulative Model Updates: 180,262
Cumulative Timesteps: 1,503,420,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.78544
Policy Entropy: 2.64092
Value Function Loss: 0.01478

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.68652
Value Function Update Magnitude: 0.74301

Collected Steps per Second: 21,934.25222
Overall Steps per Second: 10,650.94774

Timestep Collection Time: 2.28082
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.69705

Cumulative Model Updates: 180,268
Cumulative Timesteps: 1,503,470,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1503470976...
Checkpoint 1503470976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.63583
Policy Entropy: 2.65246
Value Function Loss: 0.01520

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.66956
Value Function Update Magnitude: 0.71618

Collected Steps per Second: 22,574.72740
Overall Steps per Second: 10,595.35222

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.72150

Cumulative Model Updates: 180,274
Cumulative Timesteps: 1,503,521,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.15199
Policy Entropy: 2.64033
Value Function Loss: 0.01577

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.66453
Value Function Update Magnitude: 0.69374

Collected Steps per Second: 23,352.70616
Overall Steps per Second: 10,755.65485

Timestep Collection Time: 2.14211
Timestep Consumption Time: 2.50884
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.65095

Cumulative Model Updates: 180,280
Cumulative Timesteps: 1,503,571,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1503571026...
Checkpoint 1503571026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.37051
Policy Entropy: 2.60842
Value Function Loss: 0.01618

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.67524
Value Function Update Magnitude: 0.69443

Collected Steps per Second: 22,538.46273
Overall Steps per Second: 10,625.29859

Timestep Collection Time: 2.21958
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.70820

Cumulative Model Updates: 180,286
Cumulative Timesteps: 1,503,621,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.81347
Policy Entropy: 2.58586
Value Function Loss: 0.01575

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.68142
Value Function Update Magnitude: 0.69259

Collected Steps per Second: 22,971.77821
Overall Steps per Second: 10,852.66499

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.61011

Cumulative Model Updates: 180,292
Cumulative Timesteps: 1,503,671,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1503671084...
Checkpoint 1503671084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.60195
Policy Entropy: 2.60220
Value Function Loss: 0.01480

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.67755
Value Function Update Magnitude: 0.66968

Collected Steps per Second: 22,606.44421
Overall Steps per Second: 10,733.35564

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.44799
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.66098

Cumulative Model Updates: 180,298
Cumulative Timesteps: 1,503,721,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.49565
Policy Entropy: 2.60829
Value Function Loss: 0.01415

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.67111
Value Function Update Magnitude: 0.66560

Collected Steps per Second: 22,071.10496
Overall Steps per Second: 10,792.55427

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.36751
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.63301

Cumulative Model Updates: 180,304
Cumulative Timesteps: 1,503,771,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1503771114...
Checkpoint 1503771114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.79633
Policy Entropy: 2.60810
Value Function Loss: 0.01343

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.66728
Value Function Update Magnitude: 0.66237

Collected Steps per Second: 22,463.86956
Overall Steps per Second: 10,706.41550

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.67010

Cumulative Model Updates: 180,310
Cumulative Timesteps: 1,503,821,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.44952
Policy Entropy: 2.58947
Value Function Loss: 0.01402

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.66905
Value Function Update Magnitude: 0.63849

Collected Steps per Second: 22,787.98908
Overall Steps per Second: 10,651.97791

Timestep Collection Time: 2.19545
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69678

Cumulative Model Updates: 180,316
Cumulative Timesteps: 1,503,871,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1503871144...
Checkpoint 1503871144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.56557
Policy Entropy: 2.59457
Value Function Loss: 0.01440

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.67499
Value Function Update Magnitude: 0.64294

Collected Steps per Second: 22,525.10244
Overall Steps per Second: 10,603.12170

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.49714
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.71804

Cumulative Model Updates: 180,322
Cumulative Timesteps: 1,503,921,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.57175
Policy Entropy: 2.58553
Value Function Loss: 0.01469

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15294
Policy Update Magnitude: 0.67910
Value Function Update Magnitude: 0.64352

Collected Steps per Second: 22,556.37741
Overall Steps per Second: 10,777.69522

Timestep Collection Time: 2.21693
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.63977

Cumulative Model Updates: 180,328
Cumulative Timesteps: 1,503,971,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1503971176...
Checkpoint 1503971176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.59375
Policy Entropy: 2.59352
Value Function Loss: 0.01445

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.16417
Policy Update Magnitude: 0.66973
Value Function Update Magnitude: 0.62025

Collected Steps per Second: 22,357.37140
Overall Steps per Second: 10,641.08788

Timestep Collection Time: 2.23694
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.69990

Cumulative Model Updates: 180,334
Cumulative Timesteps: 1,504,021,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.74681
Policy Entropy: 2.59812
Value Function Loss: 0.01424

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.65249
Value Function Update Magnitude: 0.60306

Collected Steps per Second: 22,436.60226
Overall Steps per Second: 10,891.52006

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.36242
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.59109

Cumulative Model Updates: 180,340
Cumulative Timesteps: 1,504,071,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1504071192...
Checkpoint 1504071192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.62908
Policy Entropy: 2.59602
Value Function Loss: 0.01359

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.62803
Value Function Update Magnitude: 0.59230

Collected Steps per Second: 22,593.20465
Overall Steps per Second: 10,670.01893

Timestep Collection Time: 2.21305
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.68603

Cumulative Model Updates: 180,346
Cumulative Timesteps: 1,504,121,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.26867
Policy Entropy: 2.59135
Value Function Loss: 0.01352

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.62778
Value Function Update Magnitude: 0.59729

Collected Steps per Second: 22,909.66274
Overall Steps per Second: 10,783.98353

Timestep Collection Time: 2.18336
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63836

Cumulative Model Updates: 180,352
Cumulative Timesteps: 1,504,171,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1504171212...
Checkpoint 1504171212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.08455
Policy Entropy: 2.58711
Value Function Loss: 0.01445

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.66009
Value Function Update Magnitude: 0.60917

Collected Steps per Second: 22,565.65030
Overall Steps per Second: 10,710.73106

Timestep Collection Time: 2.21691
Timestep Consumption Time: 2.45373
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.67064

Cumulative Model Updates: 180,358
Cumulative Timesteps: 1,504,221,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.14947
Policy Entropy: 2.56842
Value Function Loss: 0.01491

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.67653
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 22,903.39956
Overall Steps per Second: 10,853.56733

Timestep Collection Time: 2.18334
Timestep Consumption Time: 2.42399
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.60733

Cumulative Model Updates: 180,364
Cumulative Timesteps: 1,504,271,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1504271244...
Checkpoint 1504271244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.06490
Policy Entropy: 2.56397
Value Function Loss: 0.01468

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.67419
Value Function Update Magnitude: 0.66036

Collected Steps per Second: 22,461.01620
Overall Steps per Second: 10,786.01004

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.63582

Cumulative Model Updates: 180,370
Cumulative Timesteps: 1,504,321,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.89634
Policy Entropy: 2.54453
Value Function Loss: 0.01471

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.67855
Value Function Update Magnitude: 0.66463

Collected Steps per Second: 22,650.43511
Overall Steps per Second: 10,877.82987

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.38990
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.59816

Cumulative Model Updates: 180,376
Cumulative Timesteps: 1,504,371,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1504371264...
Checkpoint 1504371264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.60942
Policy Entropy: 2.54673
Value Function Loss: 0.01479

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.67250
Value Function Update Magnitude: 0.68203

Collected Steps per Second: 22,230.70274
Overall Steps per Second: 10,665.65242

Timestep Collection Time: 2.24986
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.68945

Cumulative Model Updates: 180,382
Cumulative Timesteps: 1,504,421,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.56599
Policy Entropy: 2.53629
Value Function Loss: 0.01535

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.66322
Value Function Update Magnitude: 0.69515

Collected Steps per Second: 22,571.43244
Overall Steps per Second: 10,612.74247

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.71396

Cumulative Model Updates: 180,388
Cumulative Timesteps: 1,504,471,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1504471308...
Checkpoint 1504471308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.35802
Policy Entropy: 2.54868
Value Function Loss: 0.01567

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15660
Policy Update Magnitude: 0.67260
Value Function Update Magnitude: 0.68727

Collected Steps per Second: 21,998.60695
Overall Steps per Second: 10,467.92315

Timestep Collection Time: 2.27414
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.77917

Cumulative Model Updates: 180,394
Cumulative Timesteps: 1,504,521,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.59736
Policy Entropy: 2.56511
Value Function Loss: 0.01587

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.67278
Value Function Update Magnitude: 0.69284

Collected Steps per Second: 22,404.50476
Overall Steps per Second: 10,560.15715

Timestep Collection Time: 2.23294
Timestep Consumption Time: 2.50449
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73743

Cumulative Model Updates: 180,400
Cumulative Timesteps: 1,504,571,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1504571364...
Checkpoint 1504571364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.73921
Policy Entropy: 2.58596
Value Function Loss: 0.01544

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.67064
Value Function Update Magnitude: 0.69548

Collected Steps per Second: 22,085.79354
Overall Steps per Second: 10,610.71918

Timestep Collection Time: 2.26417
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71278

Cumulative Model Updates: 180,406
Cumulative Timesteps: 1,504,621,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.16945
Policy Entropy: 2.59138
Value Function Loss: 0.01466

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.66496
Value Function Update Magnitude: 0.69323

Collected Steps per Second: 23,315.28879
Overall Steps per Second: 10,748.51818

Timestep Collection Time: 2.14486
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.65255

Cumulative Model Updates: 180,412
Cumulative Timesteps: 1,504,671,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1504671378...
Checkpoint 1504671378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.40510
Policy Entropy: 2.58764
Value Function Loss: 0.01521

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.16735
Policy Update Magnitude: 0.65623
Value Function Update Magnitude: 0.67636

Collected Steps per Second: 22,953.08325
Overall Steps per Second: 10,547.62352

Timestep Collection Time: 2.17992
Timestep Consumption Time: 2.56389
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.74382

Cumulative Model Updates: 180,418
Cumulative Timesteps: 1,504,721,414

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.36456
Policy Entropy: 2.57384
Value Function Loss: 0.01482

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.65691
Value Function Update Magnitude: 0.67461

Collected Steps per Second: 23,067.22713
Overall Steps per Second: 10,671.11761

Timestep Collection Time: 2.16784
Timestep Consumption Time: 2.51827
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.68611

Cumulative Model Updates: 180,424
Cumulative Timesteps: 1,504,771,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1504771420...
Checkpoint 1504771420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.02789
Policy Entropy: 2.57899
Value Function Loss: 0.01497

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.67207
Value Function Update Magnitude: 0.67094

Collected Steps per Second: 22,778.49257
Overall Steps per Second: 10,601.60563

Timestep Collection Time: 2.19637
Timestep Consumption Time: 2.52273
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.71910

Cumulative Model Updates: 180,430
Cumulative Timesteps: 1,504,821,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.03701
Policy Entropy: 2.58485
Value Function Loss: 0.01440

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.67266
Value Function Update Magnitude: 0.66535

Collected Steps per Second: 22,943.24389
Overall Steps per Second: 10,856.11822

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.60625

Cumulative Model Updates: 180,436
Cumulative Timesteps: 1,504,871,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1504871456...
Checkpoint 1504871456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.20406
Policy Entropy: 2.58740
Value Function Loss: 0.01440

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.67158
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 22,770.43546
Overall Steps per Second: 10,669.02195

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.68778

Cumulative Model Updates: 180,442
Cumulative Timesteps: 1,504,921,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.76221
Policy Entropy: 2.58281
Value Function Loss: 0.01430

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.66358
Value Function Update Magnitude: 0.64238

Collected Steps per Second: 22,434.66925
Overall Steps per Second: 10,878.35970

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.36891
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.59886

Cumulative Model Updates: 180,448
Cumulative Timesteps: 1,504,971,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1504971498...
Checkpoint 1504971498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.32944
Policy Entropy: 2.57968
Value Function Loss: 0.01487

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.66381
Value Function Update Magnitude: 0.65337

Collected Steps per Second: 22,158.64602
Overall Steps per Second: 10,632.95953

Timestep Collection Time: 2.25745
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.70443

Cumulative Model Updates: 180,454
Cumulative Timesteps: 1,505,021,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.54549
Policy Entropy: 2.58217
Value Function Loss: 0.01536

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.67153
Value Function Update Magnitude: 0.68759

Collected Steps per Second: 22,256.92202
Overall Steps per Second: 10,542.25368

Timestep Collection Time: 2.24721
Timestep Consumption Time: 2.49713
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74434

Cumulative Model Updates: 180,460
Cumulative Timesteps: 1,505,071,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1505071536...
Checkpoint 1505071536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.08367
Policy Entropy: 2.57388
Value Function Loss: 0.01549

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.66700
Value Function Update Magnitude: 0.69299

Collected Steps per Second: 22,205.62170
Overall Steps per Second: 10,619.65254

Timestep Collection Time: 2.25267
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.71032

Cumulative Model Updates: 180,466
Cumulative Timesteps: 1,505,121,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.09866
Policy Entropy: 2.56552
Value Function Loss: 0.01584

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.16079
Policy Update Magnitude: 0.65501
Value Function Update Magnitude: 0.69210

Collected Steps per Second: 22,867.73461
Overall Steps per Second: 10,617.74449

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.52362
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71098

Cumulative Model Updates: 180,472
Cumulative Timesteps: 1,505,171,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1505171578...
Checkpoint 1505171578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.39455
Policy Entropy: 2.57881
Value Function Loss: 0.01480

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.65255
Value Function Update Magnitude: 0.67281

Collected Steps per Second: 23,056.13650
Overall Steps per Second: 10,948.46072

Timestep Collection Time: 2.16871
Timestep Consumption Time: 2.39833
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.56703

Cumulative Model Updates: 180,478
Cumulative Timesteps: 1,505,221,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.60442
Policy Entropy: 2.58761
Value Function Loss: 0.01481

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.65340
Value Function Update Magnitude: 0.64652

Collected Steps per Second: 23,066.86458
Overall Steps per Second: 10,824.80429

Timestep Collection Time: 2.16839
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.62068

Cumulative Model Updates: 180,484
Cumulative Timesteps: 1,505,271,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1505271598...
Checkpoint 1505271598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.22867
Policy Entropy: 2.61332
Value Function Loss: 0.01322

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.65008
Value Function Update Magnitude: 0.63214

Collected Steps per Second: 22,609.35846
Overall Steps per Second: 10,723.69757

Timestep Collection Time: 2.21218
Timestep Consumption Time: 2.45188
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.66406

Cumulative Model Updates: 180,490
Cumulative Timesteps: 1,505,321,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.25607
Policy Entropy: 2.62420
Value Function Loss: 0.01331

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.64633
Value Function Update Magnitude: 0.64167

Collected Steps per Second: 22,779.26523
Overall Steps per Second: 10,595.66014

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.52545
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.72174

Cumulative Model Updates: 180,496
Cumulative Timesteps: 1,505,371,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1505371644...
Checkpoint 1505371644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.25388
Policy Entropy: 2.63685
Value Function Loss: 0.01274

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.63996
Value Function Update Magnitude: 0.64597

Collected Steps per Second: 22,226.32044
Overall Steps per Second: 10,523.44461

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.50311
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.75396

Cumulative Model Updates: 180,502
Cumulative Timesteps: 1,505,421,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.82449
Policy Entropy: 2.63450
Value Function Loss: 0.01299

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.63420
Value Function Update Magnitude: 0.64033

Collected Steps per Second: 22,393.97503
Overall Steps per Second: 10,620.61868

Timestep Collection Time: 2.23364
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70971

Cumulative Model Updates: 180,508
Cumulative Timesteps: 1,505,471,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1505471692...
Checkpoint 1505471692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.67221
Policy Entropy: 2.62008
Value Function Loss: 0.01293

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.63127
Value Function Update Magnitude: 0.62643

Collected Steps per Second: 22,525.75096
Overall Steps per Second: 10,929.61580

Timestep Collection Time: 2.21986
Timestep Consumption Time: 2.35523
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.57509

Cumulative Model Updates: 180,514
Cumulative Timesteps: 1,505,521,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.63337
Policy Entropy: 2.62645
Value Function Loss: 0.01346

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.62648
Value Function Update Magnitude: 0.61674

Collected Steps per Second: 23,019.23623
Overall Steps per Second: 10,820.84119

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.44979
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.62293

Cumulative Model Updates: 180,520
Cumulative Timesteps: 1,505,571,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1505571720...
Checkpoint 1505571720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.53508
Policy Entropy: 2.61073
Value Function Loss: 0.01340

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.62599
Value Function Update Magnitude: 0.60472

Collected Steps per Second: 22,576.67165
Overall Steps per Second: 10,638.66646

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.70172

Cumulative Model Updates: 180,526
Cumulative Timesteps: 1,505,621,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.39210
Policy Entropy: 2.60665
Value Function Loss: 0.01410

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.64188
Value Function Update Magnitude: 0.60619

Collected Steps per Second: 22,971.00443
Overall Steps per Second: 10,649.24707

Timestep Collection Time: 2.17770
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.69742

Cumulative Model Updates: 180,532
Cumulative Timesteps: 1,505,671,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1505671764...
Checkpoint 1505671764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.01147
Policy Entropy: 2.61007
Value Function Loss: 0.01364

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.64301
Value Function Update Magnitude: 0.61357

Collected Steps per Second: 22,748.28542
Overall Steps per Second: 10,696.40651

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.67596

Cumulative Model Updates: 180,538
Cumulative Timesteps: 1,505,721,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.96519
Policy Entropy: 2.60813
Value Function Loss: 0.01370

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.63647
Value Function Update Magnitude: 0.60275

Collected Steps per Second: 22,912.52543
Overall Steps per Second: 10,789.34700

Timestep Collection Time: 2.18317
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.63624

Cumulative Model Updates: 180,544
Cumulative Timesteps: 1,505,771,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1505771802...
Checkpoint 1505771802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.45964
Policy Entropy: 2.60251
Value Function Loss: 0.01379

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.63666
Value Function Update Magnitude: 0.60143

Collected Steps per Second: 22,841.23537
Overall Steps per Second: 10,612.75525

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.52269
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.71207

Cumulative Model Updates: 180,550
Cumulative Timesteps: 1,505,821,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.13009
Policy Entropy: 2.59601
Value Function Loss: 0.01355

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.63616
Value Function Update Magnitude: 0.59348

Collected Steps per Second: 22,867.23136
Overall Steps per Second: 10,810.47414

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62718

Cumulative Model Updates: 180,556
Cumulative Timesteps: 1,505,871,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1505871832...
Checkpoint 1505871832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.61249
Policy Entropy: 2.59104
Value Function Loss: 0.01396

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.62848
Value Function Update Magnitude: 0.58238

Collected Steps per Second: 22,541.99247
Overall Steps per Second: 10,745.92376

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.65497

Cumulative Model Updates: 180,562
Cumulative Timesteps: 1,505,921,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.36575
Policy Entropy: 2.58644
Value Function Loss: 0.01473

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.63778
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 22,350.44012
Overall Steps per Second: 10,507.03137

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.76119

Cumulative Model Updates: 180,568
Cumulative Timesteps: 1,505,971,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1505971880...
Checkpoint 1505971880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.48449
Policy Entropy: 2.57424
Value Function Loss: 0.01432

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.64993
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 21,939.33819
Overall Steps per Second: 10,555.89260

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.73821

Cumulative Model Updates: 180,574
Cumulative Timesteps: 1,506,021,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.28035
Policy Entropy: 2.57244
Value Function Loss: 0.01402

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.65324
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 22,440.31996
Overall Steps per Second: 10,916.27403

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.35284
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.58160

Cumulative Model Updates: 180,580
Cumulative Timesteps: 1,506,071,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1506071910...
Checkpoint 1506071910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.63977
Policy Entropy: 2.58443
Value Function Loss: 0.01495

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.65540
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 22,058.61563
Overall Steps per Second: 10,615.91813

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.71066

Cumulative Model Updates: 180,586
Cumulative Timesteps: 1,506,121,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.08785
Policy Entropy: 2.57537
Value Function Loss: 0.01567

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.66331
Value Function Update Magnitude: 0.64145

Collected Steps per Second: 23,042.11141
Overall Steps per Second: 10,587.84195

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.55389
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.72504

Cumulative Model Updates: 180,592
Cumulative Timesteps: 1,506,171,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1506171946...
Checkpoint 1506171946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.89073
Policy Entropy: 2.58322
Value Function Loss: 0.01627

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.66476
Value Function Update Magnitude: 0.65182

Collected Steps per Second: 22,432.92779
Overall Steps per Second: 10,553.73545

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.73993

Cumulative Model Updates: 180,598
Cumulative Timesteps: 1,506,221,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.36255
Policy Entropy: 2.58536
Value Function Loss: 0.01579

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.65905
Value Function Update Magnitude: 0.65224

Collected Steps per Second: 23,035.72975
Overall Steps per Second: 10,869.58270

Timestep Collection Time: 2.17063
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.60018

Cumulative Model Updates: 180,604
Cumulative Timesteps: 1,506,271,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1506271972...
Checkpoint 1506271972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.28449
Policy Entropy: 2.58930
Value Function Loss: 0.01565

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.65369
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,696.37841
Overall Steps per Second: 10,749.53027

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.44867
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.65192

Cumulative Model Updates: 180,610
Cumulative Timesteps: 1,506,321,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.21311
Policy Entropy: 2.56211
Value Function Loss: 0.01446

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.67084
Value Function Update Magnitude: 0.66542

Collected Steps per Second: 23,486.08619
Overall Steps per Second: 10,870.24964

Timestep Collection Time: 2.12943
Timestep Consumption Time: 2.47138
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.60081

Cumulative Model Updates: 180,616
Cumulative Timesteps: 1,506,371,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1506371990...
Checkpoint 1506371990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.71509
Policy Entropy: 2.55409
Value Function Loss: 0.01406

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.65822
Value Function Update Magnitude: 0.67231

Collected Steps per Second: 22,541.41925
Overall Steps per Second: 10,614.07465

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71110

Cumulative Model Updates: 180,622
Cumulative Timesteps: 1,506,421,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.70062
Policy Entropy: 2.56604
Value Function Loss: 0.01426

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.65025
Value Function Update Magnitude: 0.66736

Collected Steps per Second: 22,645.16850
Overall Steps per Second: 10,587.93528

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.72330

Cumulative Model Updates: 180,628
Cumulative Timesteps: 1,506,472,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1506472004...
Checkpoint 1506472004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.36455
Policy Entropy: 2.59816
Value Function Loss: 0.01382

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.63226
Value Function Update Magnitude: 0.64815

Collected Steps per Second: 21,833.65594
Overall Steps per Second: 10,528.74284

Timestep Collection Time: 2.29013
Timestep Consumption Time: 2.45896
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.74909

Cumulative Model Updates: 180,634
Cumulative Timesteps: 1,506,522,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.38170
Policy Entropy: 2.60158
Value Function Loss: 0.01349

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.62519
Value Function Update Magnitude: 0.64442

Collected Steps per Second: 22,582.61013
Overall Steps per Second: 10,680.08579

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.68442

Cumulative Model Updates: 180,640
Cumulative Timesteps: 1,506,572,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1506572036...
Checkpoint 1506572036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.57679
Policy Entropy: 2.59274
Value Function Loss: 0.01296

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.62518
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,192.97642
Overall Steps per Second: 10,813.78346

Timestep Collection Time: 2.25423
Timestep Consumption Time: 2.37209
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.62632

Cumulative Model Updates: 180,646
Cumulative Timesteps: 1,506,622,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.91041
Policy Entropy: 2.56606
Value Function Loss: 0.01401

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.63244
Value Function Update Magnitude: 0.63302

Collected Steps per Second: 22,566.03940
Overall Steps per Second: 10,342.23297

Timestep Collection Time: 2.21572
Timestep Consumption Time: 2.61883
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 4.83455

Cumulative Model Updates: 180,652
Cumulative Timesteps: 1,506,672,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1506672064...
Checkpoint 1506672064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.28741
Policy Entropy: 2.55793
Value Function Loss: 0.01460

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.64746
Value Function Update Magnitude: 0.64133

Collected Steps per Second: 22,843.84916
Overall Steps per Second: 10,570.78119

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.54247
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.73229

Cumulative Model Updates: 180,658
Cumulative Timesteps: 1,506,722,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.00998
Policy Entropy: 2.55464
Value Function Loss: 0.01469

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.64617
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 23,176.49058
Overall Steps per Second: 10,713.82417

Timestep Collection Time: 2.15805
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.66836

Cumulative Model Updates: 180,664
Cumulative Timesteps: 1,506,772,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1506772104...
Checkpoint 1506772104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.81753
Policy Entropy: 2.56236
Value Function Loss: 0.01513

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.64844
Value Function Update Magnitude: 0.64389

Collected Steps per Second: 22,413.35829
Overall Steps per Second: 10,647.76395

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69751

Cumulative Model Updates: 180,670
Cumulative Timesteps: 1,506,822,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.80395
Policy Entropy: 2.56739
Value Function Loss: 0.01520

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.65792
Value Function Update Magnitude: 0.66916

Collected Steps per Second: 22,827.65735
Overall Steps per Second: 10,967.38668

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.36865
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.55897

Cumulative Model Updates: 180,676
Cumulative Timesteps: 1,506,872,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1506872122...
Checkpoint 1506872122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.16850
Policy Entropy: 2.55553
Value Function Loss: 0.01443

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.64388
Value Function Update Magnitude: 0.65036

Collected Steps per Second: 22,793.36248
Overall Steps per Second: 10,615.29946

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.51777
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.71244

Cumulative Model Updates: 180,682
Cumulative Timesteps: 1,506,922,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.60813
Policy Entropy: 2.54928
Value Function Loss: 0.01432

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.63157
Value Function Update Magnitude: 0.61394

Collected Steps per Second: 23,241.02077
Overall Steps per Second: 10,867.96101

Timestep Collection Time: 2.15137
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.60068

Cumulative Model Updates: 180,688
Cumulative Timesteps: 1,506,972,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1506972146...
Checkpoint 1506972146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.30352
Policy Entropy: 2.54414
Value Function Loss: 0.01372

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.61861
Value Function Update Magnitude: 0.62134

Collected Steps per Second: 21,767.57668
Overall Steps per Second: 10,579.56742

Timestep Collection Time: 2.29709
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.72628

Cumulative Model Updates: 180,694
Cumulative Timesteps: 1,507,022,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.97976
Policy Entropy: 2.55895
Value Function Loss: 0.01400

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.62046
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 22,550.69081
Overall Steps per Second: 10,627.00724

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70631

Cumulative Model Updates: 180,700
Cumulative Timesteps: 1,507,072,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1507072162...
Checkpoint 1507072162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.52364
Policy Entropy: 2.56486
Value Function Loss: 0.01343

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.61969
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 22,461.84538
Overall Steps per Second: 10,581.52007

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.72673

Cumulative Model Updates: 180,706
Cumulative Timesteps: 1,507,122,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.52183
Policy Entropy: 2.57782
Value Function Loss: 0.01373

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.62000
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 22,440.23962
Overall Steps per Second: 10,846.48743

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.38165
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.60979

Cumulative Model Updates: 180,712
Cumulative Timesteps: 1,507,172,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1507172178...
Checkpoint 1507172178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.18601
Policy Entropy: 2.56970
Value Function Loss: 0.01417

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.62004
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 21,633.45195
Overall Steps per Second: 10,656.42413

Timestep Collection Time: 2.31142
Timestep Consumption Time: 2.38096
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69238

Cumulative Model Updates: 180,718
Cumulative Timesteps: 1,507,222,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.90061
Policy Entropy: 2.56557
Value Function Loss: 0.01482

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.62956
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 23,082.64442
Overall Steps per Second: 10,694.13036

Timestep Collection Time: 2.16665
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67658

Cumulative Model Updates: 180,724
Cumulative Timesteps: 1,507,272,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1507272194...
Checkpoint 1507272194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.50627
Policy Entropy: 2.54601
Value Function Loss: 0.01489

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.63575
Value Function Update Magnitude: 0.60518

Collected Steps per Second: 22,619.37091
Overall Steps per Second: 10,637.52139

Timestep Collection Time: 2.21129
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.70204

Cumulative Model Updates: 180,730
Cumulative Timesteps: 1,507,322,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.15316
Policy Entropy: 2.52803
Value Function Loss: 0.01472

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.63380
Value Function Update Magnitude: 0.58670

Collected Steps per Second: 22,638.02707
Overall Steps per Second: 10,529.75615

Timestep Collection Time: 2.20973
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.75073

Cumulative Model Updates: 180,736
Cumulative Timesteps: 1,507,372,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1507372236...
Checkpoint 1507372236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.63603
Policy Entropy: 2.52589
Value Function Loss: 0.01408

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.62932
Value Function Update Magnitude: 0.58500

Collected Steps per Second: 22,509.02582
Overall Steps per Second: 10,726.21237

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.66204

Cumulative Model Updates: 180,742
Cumulative Timesteps: 1,507,422,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.05884
Policy Entropy: 2.50954
Value Function Loss: 0.01477

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.63232
Value Function Update Magnitude: 0.58173

Collected Steps per Second: 22,950.26754
Overall Steps per Second: 10,979.66196

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.37601
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.55533

Cumulative Model Updates: 180,748
Cumulative Timesteps: 1,507,472,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1507472258...
Checkpoint 1507472258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.72614
Policy Entropy: 2.52580
Value Function Loss: 0.01390

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.63423
Value Function Update Magnitude: 0.58274

Collected Steps per Second: 22,746.13967
Overall Steps per Second: 10,649.31920

Timestep Collection Time: 2.19949
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.69795

Cumulative Model Updates: 180,754
Cumulative Timesteps: 1,507,522,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.23933
Policy Entropy: 2.51082
Value Function Loss: 0.01470

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.63462
Value Function Update Magnitude: 0.60361

Collected Steps per Second: 22,279.68181
Overall Steps per Second: 10,488.53178

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.76902

Cumulative Model Updates: 180,760
Cumulative Timesteps: 1,507,572,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1507572308...
Checkpoint 1507572308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.87793
Policy Entropy: 2.52632
Value Function Loss: 0.01463

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.63731
Value Function Update Magnitude: 0.63496

Collected Steps per Second: 22,631.75701
Overall Steps per Second: 10,593.97323

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.72193

Cumulative Model Updates: 180,766
Cumulative Timesteps: 1,507,622,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.94280
Policy Entropy: 2.52626
Value Function Loss: 0.01490

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.63374
Value Function Update Magnitude: 0.64798

Collected Steps per Second: 22,583.94305
Overall Steps per Second: 10,676.94062

Timestep Collection Time: 2.21432
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.68374

Cumulative Model Updates: 180,772
Cumulative Timesteps: 1,507,672,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1507672340...
Checkpoint 1507672340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64580
Policy Entropy: 2.53078
Value Function Loss: 0.01431

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.62337
Value Function Update Magnitude: 0.60824

Collected Steps per Second: 22,218.43977
Overall Steps per Second: 10,847.89130

Timestep Collection Time: 2.25074
Timestep Consumption Time: 2.35919
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.60993

Cumulative Model Updates: 180,778
Cumulative Timesteps: 1,507,722,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.83077
Policy Entropy: 2.53515
Value Function Loss: 0.01469

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.62747
Value Function Update Magnitude: 0.58747

Collected Steps per Second: 22,703.68640
Overall Steps per Second: 10,550.49991

Timestep Collection Time: 2.20361
Timestep Consumption Time: 2.53835
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.74196

Cumulative Model Updates: 180,784
Cumulative Timesteps: 1,507,772,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1507772378...
Checkpoint 1507772378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.58637
Policy Entropy: 2.53313
Value Function Loss: 0.01466

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.61377
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 23,093.71122
Overall Steps per Second: 10,612.89647

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.54636
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.71163

Cumulative Model Updates: 180,790
Cumulative Timesteps: 1,507,822,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.63971
Policy Entropy: 2.52836
Value Function Loss: 0.01533

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.61904
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 22,893.89656
Overall Steps per Second: 10,794.86980

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.63276

Cumulative Model Updates: 180,796
Cumulative Timesteps: 1,507,872,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1507872392...
Checkpoint 1507872392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.46690
Policy Entropy: 2.52254
Value Function Loss: 0.01598

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.18807
Policy Update Magnitude: 0.61508
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 22,687.20174
Overall Steps per Second: 10,751.95141

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.65125

Cumulative Model Updates: 180,802
Cumulative Timesteps: 1,507,922,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.55661
Policy Entropy: 2.52025
Value Function Loss: 0.01543

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.20224
Policy Update Magnitude: 0.61360
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,911.64272
Overall Steps per Second: 10,846.07921

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.60996

Cumulative Model Updates: 180,808
Cumulative Timesteps: 1,507,972,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1507972402...
Checkpoint 1507972402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.34283
Policy Entropy: 2.53427
Value Function Loss: 0.01532

Mean KL Divergence: 0.03193
SB3 Clip Fraction: 0.20926
Policy Update Magnitude: 0.60201
Value Function Update Magnitude: 0.65465

Collected Steps per Second: 22,370.87735
Overall Steps per Second: 10,724.92573

Timestep Collection Time: 2.23576
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.66353

Cumulative Model Updates: 180,814
Cumulative Timesteps: 1,508,022,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.45644
Policy Entropy: 2.52954
Value Function Loss: 0.01576

Mean KL Divergence: 0.03137
SB3 Clip Fraction: 0.21368
Policy Update Magnitude: 0.60379
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 22,640.42804
Overall Steps per Second: 10,716.95798

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.66793

Cumulative Model Updates: 180,820
Cumulative Timesteps: 1,508,072,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1508072444...
Checkpoint 1508072444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.11955
Policy Entropy: 2.52832
Value Function Loss: 0.01663

Mean KL Divergence: 0.02911
SB3 Clip Fraction: 0.20657
Policy Update Magnitude: 0.61848
Value Function Update Magnitude: 0.66030

Collected Steps per Second: 21,925.19538
Overall Steps per Second: 10,458.94600

Timestep Collection Time: 2.28148
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.78270

Cumulative Model Updates: 180,826
Cumulative Timesteps: 1,508,122,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.45654
Policy Entropy: 2.52474
Value Function Loss: 0.01642

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.18782
Policy Update Magnitude: 0.63800
Value Function Update Magnitude: 0.66757

Collected Steps per Second: 22,383.37116
Overall Steps per Second: 10,725.16368

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.66287

Cumulative Model Updates: 180,832
Cumulative Timesteps: 1,508,172,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1508172476...
Checkpoint 1508172476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.89109
Policy Entropy: 2.54938
Value Function Loss: 0.01537

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.64112
Value Function Update Magnitude: 0.68050

Collected Steps per Second: 22,311.40301
Overall Steps per Second: 10,726.52970

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.66302

Cumulative Model Updates: 180,838
Cumulative Timesteps: 1,508,222,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.97959
Policy Entropy: 2.55002
Value Function Loss: 0.01548

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.65327
Value Function Update Magnitude: 0.67807

Collected Steps per Second: 22,228.65977
Overall Steps per Second: 10,822.39094

Timestep Collection Time: 2.25034
Timestep Consumption Time: 2.37175
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.62208

Cumulative Model Updates: 180,844
Cumulative Timesteps: 1,508,272,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1508272516...
Checkpoint 1508272516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.72655
Policy Entropy: 2.53470
Value Function Loss: 0.01539

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.65586
Value Function Update Magnitude: 0.65458

Collected Steps per Second: 22,807.13606
Overall Steps per Second: 10,761.75999

Timestep Collection Time: 2.19230
Timestep Consumption Time: 2.45378
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.64608

Cumulative Model Updates: 180,850
Cumulative Timesteps: 1,508,322,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.45697
Policy Entropy: 2.54186
Value Function Loss: 0.01531

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.64293
Value Function Update Magnitude: 0.63332

Collected Steps per Second: 22,922.69915
Overall Steps per Second: 10,789.96417

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.63431

Cumulative Model Updates: 180,856
Cumulative Timesteps: 1,508,372,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1508372520...
Checkpoint 1508372520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.15393
Policy Entropy: 2.54944
Value Function Loss: 0.01516

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.62093
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 21,363.33744
Overall Steps per Second: 10,322.06050

Timestep Collection Time: 2.34158
Timestep Consumption Time: 2.50474
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.84632

Cumulative Model Updates: 180,862
Cumulative Timesteps: 1,508,422,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.76535
Policy Entropy: 2.55209
Value Function Loss: 0.01533

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.62760
Value Function Update Magnitude: 0.57711

Collected Steps per Second: 22,822.91129
Overall Steps per Second: 10,833.24375

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.61672

Cumulative Model Updates: 180,868
Cumulative Timesteps: 1,508,472,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1508472558...
Checkpoint 1508472558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.76068
Policy Entropy: 2.53812
Value Function Loss: 0.01460

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.62530
Value Function Update Magnitude: 0.59129

Collected Steps per Second: 22,447.90782
Overall Steps per Second: 10,699.92200

Timestep Collection Time: 2.22863
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.67555

Cumulative Model Updates: 180,874
Cumulative Timesteps: 1,508,522,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.83025
Policy Entropy: 2.53280
Value Function Loss: 0.01449

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.18406
Policy Update Magnitude: 0.58987
Value Function Update Magnitude: 0.58715

Collected Steps per Second: 22,148.88947
Overall Steps per Second: 10,801.44013

Timestep Collection Time: 2.25853
Timestep Consumption Time: 2.37270
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.63123

Cumulative Model Updates: 180,880
Cumulative Timesteps: 1,508,572,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1508572610...
Checkpoint 1508572610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.72752
Policy Entropy: 2.53002
Value Function Loss: 0.01436

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.59675
Value Function Update Magnitude: 0.59240

Collected Steps per Second: 21,416.53111
Overall Steps per Second: 10,271.84639

Timestep Collection Time: 2.33549
Timestep Consumption Time: 2.53394
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.86943

Cumulative Model Updates: 180,886
Cumulative Timesteps: 1,508,622,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.10723
Policy Entropy: 2.53324
Value Function Loss: 0.01463

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.18194
Policy Update Magnitude: 0.62797
Value Function Update Magnitude: 0.60110

Collected Steps per Second: 22,355.52774
Overall Steps per Second: 10,462.12088

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.54256
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.77915

Cumulative Model Updates: 180,892
Cumulative Timesteps: 1,508,672,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1508672628...
Checkpoint 1508672628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.42882
Policy Entropy: 2.52915
Value Function Loss: 0.01428

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.18753
Policy Update Magnitude: 0.63294
Value Function Update Magnitude: 0.60257

Collected Steps per Second: 22,462.03884
Overall Steps per Second: 10,741.87947

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65654

Cumulative Model Updates: 180,898
Cumulative Timesteps: 1,508,722,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.99460
Policy Entropy: 2.54317
Value Function Loss: 0.01394

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.19241
Policy Update Magnitude: 0.62586
Value Function Update Magnitude: 0.58418

Collected Steps per Second: 22,507.46258
Overall Steps per Second: 10,800.87007

Timestep Collection Time: 2.22175
Timestep Consumption Time: 2.40806
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62981

Cumulative Model Updates: 180,904
Cumulative Timesteps: 1,508,772,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1508772654...
Checkpoint 1508772654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.59097
Policy Entropy: 2.53728
Value Function Loss: 0.01495

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.63490
Value Function Update Magnitude: 0.58568

Collected Steps per Second: 22,985.97943
Overall Steps per Second: 10,783.40260

Timestep Collection Time: 2.17663
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.63972

Cumulative Model Updates: 180,910
Cumulative Timesteps: 1,508,822,686

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.96456
Policy Entropy: 2.54340
Value Function Loss: 0.01558

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.64588
Value Function Update Magnitude: 0.61274

Collected Steps per Second: 23,216.77618
Overall Steps per Second: 10,766.84834

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.64426

Cumulative Model Updates: 180,916
Cumulative Timesteps: 1,508,872,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1508872690...
Checkpoint 1508872690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.54714
Policy Entropy: 2.53996
Value Function Loss: 0.01473

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.63702
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 23,017.64852
Overall Steps per Second: 10,683.98325

Timestep Collection Time: 2.17242
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.68028

Cumulative Model Updates: 180,922
Cumulative Timesteps: 1,508,922,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.16805
Policy Entropy: 2.53349
Value Function Loss: 0.01380

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.62131
Value Function Update Magnitude: 0.61841

Collected Steps per Second: 23,223.26389
Overall Steps per Second: 10,908.64295

Timestep Collection Time: 2.15439
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.58646

Cumulative Model Updates: 180,928
Cumulative Timesteps: 1,508,972,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1508972726...
Checkpoint 1508972726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.44604
Policy Entropy: 2.50463
Value Function Loss: 0.01391

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.62531
Value Function Update Magnitude: 0.61256

Collected Steps per Second: 23,045.93391
Overall Steps per Second: 10,689.02858

Timestep Collection Time: 2.17019
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.67900

Cumulative Model Updates: 180,934
Cumulative Timesteps: 1,509,022,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.41043
Policy Entropy: 2.48965
Value Function Loss: 0.01443

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.63771
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 23,136.33192
Overall Steps per Second: 10,840.84564

Timestep Collection Time: 2.16197
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.61403

Cumulative Model Updates: 180,940
Cumulative Timesteps: 1,509,072,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1509072760...
Checkpoint 1509072760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.20410
Policy Entropy: 2.48862
Value Function Loss: 0.01491

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.63210
Value Function Update Magnitude: 0.62395

Collected Steps per Second: 22,846.04112
Overall Steps per Second: 10,882.31722

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.59553

Cumulative Model Updates: 180,946
Cumulative Timesteps: 1,509,122,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.63292
Policy Entropy: 2.50679
Value Function Loss: 0.01409

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.61861
Value Function Update Magnitude: 0.60010

Collected Steps per Second: 22,848.34824
Overall Steps per Second: 10,729.34402

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.47296
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.66235

Cumulative Model Updates: 180,952
Cumulative Timesteps: 1,509,172,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1509172794...
Checkpoint 1509172794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.80231
Policy Entropy: 2.50243
Value Function Loss: 0.01402

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.60509
Value Function Update Magnitude: 0.58862

Collected Steps per Second: 22,447.30870
Overall Steps per Second: 10,616.51121

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.71096

Cumulative Model Updates: 180,958
Cumulative Timesteps: 1,509,222,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.33918
Policy Entropy: 2.51472
Value Function Loss: 0.01490

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.62405
Value Function Update Magnitude: 0.59067

Collected Steps per Second: 22,713.41689
Overall Steps per Second: 10,574.84024

Timestep Collection Time: 2.20222
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.73010

Cumulative Model Updates: 180,964
Cumulative Timesteps: 1,509,272,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1509272828...
Checkpoint 1509272828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.81255
Policy Entropy: 2.52240
Value Function Loss: 0.01564

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.62403
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 23,129.72970
Overall Steps per Second: 10,881.43734

Timestep Collection Time: 2.16181
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59517

Cumulative Model Updates: 180,970
Cumulative Timesteps: 1,509,322,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.73250
Policy Entropy: 2.52919
Value Function Loss: 0.01597

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.61851
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 23,062.32345
Overall Steps per Second: 11,069.41085

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.35032
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.51966

Cumulative Model Updates: 180,976
Cumulative Timesteps: 1,509,372,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1509372860...
Checkpoint 1509372860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.62976
Policy Entropy: 2.53691
Value Function Loss: 0.01459

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.61263
Value Function Update Magnitude: 0.60179

Collected Steps per Second: 23,262.52196
Overall Steps per Second: 10,844.78696

Timestep Collection Time: 2.15015
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.61217

Cumulative Model Updates: 180,982
Cumulative Timesteps: 1,509,422,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.33704
Policy Entropy: 2.53375
Value Function Loss: 0.01406

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.61266
Value Function Update Magnitude: 0.59604

Collected Steps per Second: 23,299.73872
Overall Steps per Second: 10,754.16062

Timestep Collection Time: 2.14638
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.65029

Cumulative Model Updates: 180,988
Cumulative Timesteps: 1,509,472,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1509472888...
Checkpoint 1509472888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.90703
Policy Entropy: 2.52813
Value Function Loss: 0.01406

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.60955
Value Function Update Magnitude: 0.58613

Collected Steps per Second: 23,111.67771
Overall Steps per Second: 10,782.20800

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.63727

Cumulative Model Updates: 180,994
Cumulative Timesteps: 1,509,522,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.65938
Policy Entropy: 2.52420
Value Function Loss: 0.01449

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.61601
Value Function Update Magnitude: 0.59187

Collected Steps per Second: 22,584.90895
Overall Steps per Second: 10,688.46971

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.67869

Cumulative Model Updates: 181,000
Cumulative Timesteps: 1,509,572,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1509572896...
Checkpoint 1509572896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.75053
Policy Entropy: 2.49250
Value Function Loss: 0.01517

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.61829
Value Function Update Magnitude: 0.63809

Collected Steps per Second: 22,768.82954
Overall Steps per Second: 11,016.79817

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.34291
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.53925

Cumulative Model Updates: 181,006
Cumulative Timesteps: 1,509,622,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.20575
Policy Entropy: 2.48255
Value Function Loss: 0.01548

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.62542
Value Function Update Magnitude: 0.64731

Collected Steps per Second: 22,165.94535
Overall Steps per Second: 10,706.39556

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.67011

Cumulative Model Updates: 181,012
Cumulative Timesteps: 1,509,672,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1509672904...
Checkpoint 1509672904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.13409
Policy Entropy: 2.48749
Value Function Loss: 0.01500

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.62084
Value Function Update Magnitude: 0.62248

Collected Steps per Second: 23,184.71472
Overall Steps per Second: 10,832.45265

Timestep Collection Time: 2.15702
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.61668

Cumulative Model Updates: 181,018
Cumulative Timesteps: 1,509,722,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.40127
Policy Entropy: 2.50381
Value Function Loss: 0.01578

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.61519
Value Function Update Magnitude: 0.60735

Collected Steps per Second: 23,023.93466
Overall Steps per Second: 10,707.08726

Timestep Collection Time: 2.17278
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.67223

Cumulative Model Updates: 181,024
Cumulative Timesteps: 1,509,772,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1509772940...
Checkpoint 1509772940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.66389
Policy Entropy: 2.50094
Value Function Loss: 0.01532

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.61856
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 23,170.62795
Overall Steps per Second: 10,981.97191

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.55292

Cumulative Model Updates: 181,030
Cumulative Timesteps: 1,509,822,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.61487
Policy Entropy: 2.49296
Value Function Loss: 0.01485

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.61685
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 23,343.05439
Overall Steps per Second: 10,804.07665

Timestep Collection Time: 2.14222
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.62844

Cumulative Model Updates: 181,036
Cumulative Timesteps: 1,509,872,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1509872946...
Checkpoint 1509872946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.20970
Policy Entropy: 2.49333
Value Function Loss: 0.01459

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.61410
Value Function Update Magnitude: 0.59848

Collected Steps per Second: 23,271.65148
Overall Steps per Second: 11,101.77872

Timestep Collection Time: 2.14871
Timestep Consumption Time: 2.35543
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.50414

Cumulative Model Updates: 181,042
Cumulative Timesteps: 1,509,922,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.04272
Policy Entropy: 2.50537
Value Function Loss: 0.01399

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.61455
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 23,231.76015
Overall Steps per Second: 10,912.73458

Timestep Collection Time: 2.15283
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.58309

Cumulative Model Updates: 181,048
Cumulative Timesteps: 1,509,972,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1509972964...
Checkpoint 1509972964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.42537
Policy Entropy: 2.51124
Value Function Loss: 0.01405

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.61191
Value Function Update Magnitude: 0.61478

Collected Steps per Second: 22,859.55462
Overall Steps per Second: 10,701.90886

Timestep Collection Time: 2.18832
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67431

Cumulative Model Updates: 181,054
Cumulative Timesteps: 1,510,022,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.70984
Policy Entropy: 2.50641
Value Function Loss: 0.01418

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.61899
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 22,814.87157
Overall Steps per Second: 10,785.34314

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.63685

Cumulative Model Updates: 181,060
Cumulative Timesteps: 1,510,072,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1510072998...
Checkpoint 1510072998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.33130
Policy Entropy: 2.48746
Value Function Loss: 0.01429

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.62638
Value Function Update Magnitude: 0.64377

Collected Steps per Second: 22,174.21002
Overall Steps per Second: 10,713.24665

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.41341
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.66936

Cumulative Model Updates: 181,066
Cumulative Timesteps: 1,510,123,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.44147
Policy Entropy: 2.49594
Value Function Loss: 0.01362

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.15847
Policy Update Magnitude: 0.60826
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 22,483.45817
Overall Steps per Second: 10,628.02538

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.48217
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70737

Cumulative Model Updates: 181,072
Cumulative Timesteps: 1,510,173,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1510173052...
Checkpoint 1510173052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.06436
Policy Entropy: 2.49606
Value Function Loss: 0.01420

Mean KL Divergence: 0.03103
SB3 Clip Fraction: 0.19850
Policy Update Magnitude: 0.54198
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 22,889.88007
Overall Steps per Second: 10,979.00864

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.37101
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.55651

Cumulative Model Updates: 181,078
Cumulative Timesteps: 1,510,223,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.54457
Policy Entropy: 2.49967
Value Function Loss: 0.01417

Mean KL Divergence: 0.03106
SB3 Clip Fraction: 0.19791
Policy Update Magnitude: 0.58609
Value Function Update Magnitude: 0.65589

Collected Steps per Second: 23,229.93059
Overall Steps per Second: 10,852.59378

Timestep Collection Time: 2.15412
Timestep Consumption Time: 2.45676
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61088

Cumulative Model Updates: 181,084
Cumulative Timesteps: 1,510,273,118

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1510273118...
Checkpoint 1510273118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.82628
Policy Entropy: 2.50173
Value Function Loss: 0.01565

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.19141
Policy Update Magnitude: 0.62418
Value Function Update Magnitude: 0.66767

Collected Steps per Second: 23,228.70556
Overall Steps per Second: 10,689.14331

Timestep Collection Time: 2.15346
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.67970

Cumulative Model Updates: 181,090
Cumulative Timesteps: 1,510,323,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.93769
Policy Entropy: 2.50195
Value Function Loss: 0.01549

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.16616
Policy Update Magnitude: 0.63863
Value Function Update Magnitude: 0.66543

Collected Steps per Second: 22,916.33316
Overall Steps per Second: 10,711.52673

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66955

Cumulative Model Updates: 181,096
Cumulative Timesteps: 1,510,373,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1510373158...
Checkpoint 1510373158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.31693
Policy Entropy: 2.49764
Value Function Loss: 0.01664

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.63802
Value Function Update Magnitude: 0.65588

Collected Steps per Second: 22,634.52536
Overall Steps per Second: 10,841.80239

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.40382
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61381

Cumulative Model Updates: 181,102
Cumulative Timesteps: 1,510,423,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.28516
Policy Entropy: 2.51889
Value Function Loss: 0.01516

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.62691
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 22,897.54598
Overall Steps per Second: 10,862.91723

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.41956
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.60355

Cumulative Model Updates: 181,108
Cumulative Timesteps: 1,510,473,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1510473188...
Checkpoint 1510473188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.68531
Policy Entropy: 2.54126
Value Function Loss: 0.01503

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.60852
Value Function Update Magnitude: 0.63520

Collected Steps per Second: 22,510.64144
Overall Steps per Second: 10,751.89659

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.65109

Cumulative Model Updates: 181,114
Cumulative Timesteps: 1,510,523,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.68655
Policy Entropy: 2.56108
Value Function Loss: 0.01445

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.59187
Value Function Update Magnitude: 0.60542

Collected Steps per Second: 23,229.06269
Overall Steps per Second: 10,837.03939

Timestep Collection Time: 2.15273
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.61436

Cumulative Model Updates: 181,120
Cumulative Timesteps: 1,510,573,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1510573202...
Checkpoint 1510573202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.82829
Policy Entropy: 2.53209
Value Function Loss: 0.01554

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.61184
Value Function Update Magnitude: 0.61930

Collected Steps per Second: 23,315.49077
Overall Steps per Second: 10,662.75074

Timestep Collection Time: 2.14450
Timestep Consumption Time: 2.54472
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68922

Cumulative Model Updates: 181,126
Cumulative Timesteps: 1,510,623,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.01143
Policy Entropy: 2.50235
Value Function Loss: 0.01482

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.62322
Value Function Update Magnitude: 0.66753

Collected Steps per Second: 22,760.63178
Overall Steps per Second: 10,657.40097

Timestep Collection Time: 2.19792
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69402

Cumulative Model Updates: 181,132
Cumulative Timesteps: 1,510,673,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1510673228...
Checkpoint 1510673228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.24930
Policy Entropy: 2.49620
Value Function Loss: 0.01445

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.61696
Value Function Update Magnitude: 0.69552

Collected Steps per Second: 23,342.43506
Overall Steps per Second: 10,895.94851

Timestep Collection Time: 2.14245
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.58978

Cumulative Model Updates: 181,138
Cumulative Timesteps: 1,510,723,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.31811
Policy Entropy: 2.49898
Value Function Loss: 0.01420

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14713
Policy Update Magnitude: 0.61680
Value Function Update Magnitude: 0.69154

Collected Steps per Second: 23,205.07609
Overall Steps per Second: 10,907.78142

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.58498

Cumulative Model Updates: 181,144
Cumulative Timesteps: 1,510,773,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1510773250...
Checkpoint 1510773250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.22869
Policy Entropy: 2.49255
Value Function Loss: 0.01504

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.63029
Value Function Update Magnitude: 0.67699

Collected Steps per Second: 23,147.01116
Overall Steps per Second: 11,076.81385

Timestep Collection Time: 2.16011
Timestep Consumption Time: 2.35383
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.51393

Cumulative Model Updates: 181,150
Cumulative Timesteps: 1,510,823,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.27025
Policy Entropy: 2.50890
Value Function Loss: 0.01466

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.63311
Value Function Update Magnitude: 0.64709

Collected Steps per Second: 22,021.61585
Overall Steps per Second: 10,580.26018

Timestep Collection Time: 2.27222
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.72937

Cumulative Model Updates: 181,156
Cumulative Timesteps: 1,510,873,288

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1510873288...
Checkpoint 1510873288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.27969
Policy Entropy: 2.51036
Value Function Loss: 0.01468

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.61759
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,748.44682
Overall Steps per Second: 10,675.21640

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.48659
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.68524

Cumulative Model Updates: 181,162
Cumulative Timesteps: 1,510,923,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.73264
Policy Entropy: 2.52142
Value Function Loss: 0.01411

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.59858
Value Function Update Magnitude: 0.58475

Collected Steps per Second: 22,886.40969
Overall Steps per Second: 10,838.71519

Timestep Collection Time: 2.18584
Timestep Consumption Time: 2.42965
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.61549

Cumulative Model Updates: 181,168
Cumulative Timesteps: 1,510,973,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1510973330...
Checkpoint 1510973330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.22645
Policy Entropy: 2.48883
Value Function Loss: 0.01410

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.58117

Collected Steps per Second: 22,615.34861
Overall Steps per Second: 10,687.21387

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.46878
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.68073

Cumulative Model Updates: 181,174
Cumulative Timesteps: 1,511,023,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.25655
Policy Entropy: 2.48594
Value Function Loss: 0.01451

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.60305
Value Function Update Magnitude: 0.58358

Collected Steps per Second: 23,136.38436
Overall Steps per Second: 10,912.21611

Timestep Collection Time: 2.16196
Timestep Consumption Time: 2.42189
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.58385

Cumulative Model Updates: 181,180
Cumulative Timesteps: 1,511,073,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1511073374...
Checkpoint 1511073374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.74253
Policy Entropy: 2.49207
Value Function Loss: 0.01527

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.60389
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 23,366.28359
Overall Steps per Second: 10,892.64128

Timestep Collection Time: 2.14069
Timestep Consumption Time: 2.45140
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59209

Cumulative Model Updates: 181,186
Cumulative Timesteps: 1,511,123,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.63908
Policy Entropy: 2.50591
Value Function Loss: 0.01471

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.60568
Value Function Update Magnitude: 0.61245

Collected Steps per Second: 23,345.45634
Overall Steps per Second: 10,898.84542

Timestep Collection Time: 2.14312
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59058

Cumulative Model Updates: 181,192
Cumulative Timesteps: 1,511,173,426

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1511173426...
Checkpoint 1511173426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.36443
Policy Entropy: 2.50478
Value Function Loss: 0.01507

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.61711

Collected Steps per Second: 23,283.71519
Overall Steps per Second: 10,766.94958

Timestep Collection Time: 2.14802
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.64514

Cumulative Model Updates: 181,198
Cumulative Timesteps: 1,511,223,440

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.39930
Policy Entropy: 2.52522
Value Function Loss: 0.01470

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 23,267.83386
Overall Steps per Second: 10,897.97306

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.58856

Cumulative Model Updates: 181,204
Cumulative Timesteps: 1,511,273,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1511273446...
Checkpoint 1511273446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.86480
Policy Entropy: 2.51914
Value Function Loss: 0.01513

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15110
Policy Update Magnitude: 0.61151
Value Function Update Magnitude: 0.62517

Collected Steps per Second: 23,085.52549
Overall Steps per Second: 10,790.21715

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.46826
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.63438

Cumulative Model Updates: 181,210
Cumulative Timesteps: 1,511,323,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.21821
Policy Entropy: 2.54528
Value Function Loss: 0.01417

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.61089
Value Function Update Magnitude: 0.60716

Collected Steps per Second: 22,699.35406
Overall Steps per Second: 10,791.14997

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.63454

Cumulative Model Updates: 181,216
Cumulative Timesteps: 1,511,373,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1511373464...
Checkpoint 1511373464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.00012
Policy Entropy: 2.53202
Value Function Loss: 0.01375

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.60018
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 22,910.31767
Overall Steps per Second: 10,693.42968

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.67670

Cumulative Model Updates: 181,222
Cumulative Timesteps: 1,511,423,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.08284
Policy Entropy: 2.54504
Value Function Loss: 0.01276

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.59064
Value Function Update Magnitude: 0.57921

Collected Steps per Second: 22,767.11054
Overall Steps per Second: 10,805.27486

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62959

Cumulative Model Updates: 181,228
Cumulative Timesteps: 1,511,473,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1511473498...
Checkpoint 1511473498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.52091
Policy Entropy: 2.50787
Value Function Loss: 0.01402

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.60224
Value Function Update Magnitude: 0.57031

Collected Steps per Second: 22,273.01778
Overall Steps per Second: 10,669.26192

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68917

Cumulative Model Updates: 181,234
Cumulative Timesteps: 1,511,523,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.54985
Policy Entropy: 2.50094
Value Function Loss: 0.01424

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.61561
Value Function Update Magnitude: 0.58693

Collected Steps per Second: 22,610.55031
Overall Steps per Second: 10,817.87247

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62383

Cumulative Model Updates: 181,240
Cumulative Timesteps: 1,511,573,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1511573548...
Checkpoint 1511573548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.71295
Policy Entropy: 2.48070
Value Function Loss: 0.01584

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.62144
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 23,004.39897
Overall Steps per Second: 10,824.48554

Timestep Collection Time: 2.17471
Timestep Consumption Time: 2.44703
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.62174

Cumulative Model Updates: 181,246
Cumulative Timesteps: 1,511,623,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.51920
Policy Entropy: 2.48138
Value Function Loss: 0.01546

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.62913
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 23,444.67665
Overall Steps per Second: 10,777.06197

Timestep Collection Time: 2.13387
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.64208

Cumulative Model Updates: 181,252
Cumulative Timesteps: 1,511,673,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1511673604...
Checkpoint 1511673604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.98630
Policy Entropy: 2.47024
Value Function Loss: 0.01568

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.63047
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 22,983.55332
Overall Steps per Second: 10,656.72687

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.69225

Cumulative Model Updates: 181,258
Cumulative Timesteps: 1,511,723,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.42585
Policy Entropy: 2.47625
Value Function Loss: 0.01556

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.62791
Value Function Update Magnitude: 0.65274

Collected Steps per Second: 23,203.45888
Overall Steps per Second: 10,903.70327

Timestep Collection Time: 2.15554
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.58707

Cumulative Model Updates: 181,264
Cumulative Timesteps: 1,511,773,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1511773624...
Checkpoint 1511773624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.21228
Policy Entropy: 2.47846
Value Function Loss: 0.01503

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.16128
Policy Update Magnitude: 0.61413
Value Function Update Magnitude: 0.65437

Collected Steps per Second: 23,119.35204
Overall Steps per Second: 10,777.32769

Timestep Collection Time: 2.16304
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.64011

Cumulative Model Updates: 181,270
Cumulative Timesteps: 1,511,823,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.42129
Policy Entropy: 2.47489
Value Function Loss: 0.01548

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.62313
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 23,260.55243
Overall Steps per Second: 10,788.68451

Timestep Collection Time: 2.14965
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.63467

Cumulative Model Updates: 181,276
Cumulative Timesteps: 1,511,873,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1511873634...
Checkpoint 1511873634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.90031
Policy Entropy: 2.49913
Value Function Loss: 0.01444

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.60748
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,718.27549
Overall Steps per Second: 10,838.59226

Timestep Collection Time: 2.20219
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.61591

Cumulative Model Updates: 181,282
Cumulative Timesteps: 1,511,923,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.98864
Policy Entropy: 2.50462
Value Function Loss: 0.01443

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.60526

Collected Steps per Second: 22,790.50660
Overall Steps per Second: 10,723.62692

Timestep Collection Time: 2.19398
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.66279

Cumulative Model Updates: 181,288
Cumulative Timesteps: 1,511,973,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1511973666...
Checkpoint 1511973666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.59742
Policy Entropy: 2.51375
Value Function Loss: 0.01401

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.60468
Value Function Update Magnitude: 0.62063

Collected Steps per Second: 22,483.43688
Overall Steps per Second: 10,639.66575

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.69977

Cumulative Model Updates: 181,294
Cumulative Timesteps: 1,512,023,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.28179
Policy Entropy: 2.49460
Value Function Loss: 0.01444

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.61504

Collected Steps per Second: 22,830.11670
Overall Steps per Second: 10,783.38392

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.63936

Cumulative Model Updates: 181,300
Cumulative Timesteps: 1,512,073,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1512073698...
Checkpoint 1512073698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.99232
Policy Entropy: 2.49944
Value Function Loss: 0.01437

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.58338
Value Function Update Magnitude: 0.58261

Collected Steps per Second: 23,290.32882
Overall Steps per Second: 10,737.03048

Timestep Collection Time: 2.14784
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.65902

Cumulative Model Updates: 181,306
Cumulative Timesteps: 1,512,123,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.47588
Policy Entropy: 2.52028
Value Function Loss: 0.01472

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.58713
Value Function Update Magnitude: 0.54753

Collected Steps per Second: 22,754.02718
Overall Steps per Second: 10,892.16806

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.39342
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.59119

Cumulative Model Updates: 181,312
Cumulative Timesteps: 1,512,173,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1512173730...
Checkpoint 1512173730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.82585
Policy Entropy: 2.51619
Value Function Loss: 0.01440

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 22,810.66555
Overall Steps per Second: 10,648.68185

Timestep Collection Time: 2.19231
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69617

Cumulative Model Updates: 181,318
Cumulative Timesteps: 1,512,223,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.74276
Policy Entropy: 2.50849
Value Function Loss: 0.01482

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.60661
Value Function Update Magnitude: 0.57727

Collected Steps per Second: 22,765.31338
Overall Steps per Second: 10,567.57280

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.53625
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.73354

Cumulative Model Updates: 181,324
Cumulative Timesteps: 1,512,273,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1512273760...
Checkpoint 1512273760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.17606
Policy Entropy: 2.50541
Value Function Loss: 0.01445

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.60318
Value Function Update Magnitude: 0.60130

Collected Steps per Second: 23,216.39681
Overall Steps per Second: 10,897.31454

Timestep Collection Time: 2.15477
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.59067

Cumulative Model Updates: 181,330
Cumulative Timesteps: 1,512,323,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.17784
Policy Entropy: 2.50482
Value Function Loss: 0.01393

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.59502
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,927.09731
Overall Steps per Second: 10,798.44108

Timestep Collection Time: 2.18091
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.63048

Cumulative Model Updates: 181,336
Cumulative Timesteps: 1,512,373,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1512373788...
Checkpoint 1512373788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.51657
Policy Entropy: 2.50073
Value Function Loss: 0.01483

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.60529
Value Function Update Magnitude: 0.58343

Collected Steps per Second: 22,730.61113
Overall Steps per Second: 10,833.19541

Timestep Collection Time: 2.20029
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61674

Cumulative Model Updates: 181,342
Cumulative Timesteps: 1,512,423,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.61906
Policy Entropy: 2.49050
Value Function Loss: 0.01450

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.61162
Value Function Update Magnitude: 0.59761

Collected Steps per Second: 22,765.76203
Overall Steps per Second: 10,932.61218

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.37843
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.57585

Cumulative Model Updates: 181,348
Cumulative Timesteps: 1,512,473,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1512473828...
Checkpoint 1512473828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.82315
Policy Entropy: 2.48787
Value Function Loss: 0.01501

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.61414
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 22,833.79830
Overall Steps per Second: 10,666.91331

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68795

Cumulative Model Updates: 181,354
Cumulative Timesteps: 1,512,523,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.28347
Policy Entropy: 2.46538
Value Function Loss: 0.01481

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.61950
Value Function Update Magnitude: 0.61494

Collected Steps per Second: 22,845.90783
Overall Steps per Second: 10,826.63675

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61972

Cumulative Model Updates: 181,360
Cumulative Timesteps: 1,512,573,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1512573850...
Checkpoint 1512573850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.60124
Policy Entropy: 2.47179
Value Function Loss: 0.01383

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.61398
Value Function Update Magnitude: 0.61916

Collected Steps per Second: 23,094.14766
Overall Steps per Second: 10,720.83606

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.66605

Cumulative Model Updates: 181,366
Cumulative Timesteps: 1,512,623,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.92817
Policy Entropy: 2.46539
Value Function Loss: 0.01449

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.61053
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 23,294.96332
Overall Steps per Second: 10,876.40028

Timestep Collection Time: 2.14759
Timestep Consumption Time: 2.45209
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.59968

Cumulative Model Updates: 181,372
Cumulative Timesteps: 1,512,673,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1512673902...
Checkpoint 1512673902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.12432
Policy Entropy: 2.47879
Value Function Loss: 0.01434

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.61571
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 23,253.84596
Overall Steps per Second: 10,834.70820

Timestep Collection Time: 2.15070
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.61591

Cumulative Model Updates: 181,378
Cumulative Timesteps: 1,512,723,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.36580
Policy Entropy: 2.47461
Value Function Loss: 0.01492

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.62367
Value Function Update Magnitude: 0.61407

Collected Steps per Second: 23,175.36088
Overall Steps per Second: 10,957.75945

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.40599
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.56389

Cumulative Model Updates: 181,384
Cumulative Timesteps: 1,512,773,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1512773924...
Checkpoint 1512773924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.29566
Policy Entropy: 2.49120
Value Function Loss: 0.01550

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.62148
Value Function Update Magnitude: 0.61060

Collected Steps per Second: 23,213.07167
Overall Steps per Second: 10,954.75031

Timestep Collection Time: 2.15396
Timestep Consumption Time: 2.41027
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.56423

Cumulative Model Updates: 181,390
Cumulative Timesteps: 1,512,823,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.21210
Policy Entropy: 2.47873
Value Function Loss: 0.01602

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.61957
Value Function Update Magnitude: 0.60919

Collected Steps per Second: 23,520.32714
Overall Steps per Second: 10,921.48084

Timestep Collection Time: 2.12667
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.57996

Cumulative Model Updates: 181,396
Cumulative Timesteps: 1,512,873,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1512873944...
Checkpoint 1512873944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.32440
Policy Entropy: 2.48808
Value Function Loss: 0.01692

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.63189
Value Function Update Magnitude: 0.61187

Collected Steps per Second: 22,669.07838
Overall Steps per Second: 10,615.61299

Timestep Collection Time: 2.20574
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71023

Cumulative Model Updates: 181,402
Cumulative Timesteps: 1,512,923,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.57895
Policy Entropy: 2.48307
Value Function Loss: 0.01626

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14990
Policy Update Magnitude: 0.62911
Value Function Update Magnitude: 0.61488

Collected Steps per Second: 22,448.49528
Overall Steps per Second: 10,697.53913

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.67603

Cumulative Model Updates: 181,408
Cumulative Timesteps: 1,512,973,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1512973968...
Checkpoint 1512973968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.59526
Policy Entropy: 2.47735
Value Function Loss: 0.01639

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.62701
Value Function Update Magnitude: 0.62996

Collected Steps per Second: 22,553.24263
Overall Steps per Second: 10,885.42329

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.37680
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.59422

Cumulative Model Updates: 181,414
Cumulative Timesteps: 1,513,023,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.93948
Policy Entropy: 2.46234
Value Function Loss: 0.01517

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.62748
Value Function Update Magnitude: 0.63222

Collected Steps per Second: 22,947.52994
Overall Steps per Second: 10,827.95520

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61952

Cumulative Model Updates: 181,420
Cumulative Timesteps: 1,513,073,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1513073998...
Checkpoint 1513073998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.49390
Policy Entropy: 2.45265
Value Function Loss: 0.01494

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.62468
Value Function Update Magnitude: 0.62142

Collected Steps per Second: 22,902.32505
Overall Steps per Second: 10,617.12816

Timestep Collection Time: 2.18397
Timestep Consumption Time: 2.52710
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.71107

Cumulative Model Updates: 181,426
Cumulative Timesteps: 1,513,124,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.50061
Policy Entropy: 2.47686
Value Function Loss: 0.01384

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.61447
Value Function Update Magnitude: 0.59736

Collected Steps per Second: 22,776.06809
Overall Steps per Second: 10,623.79808

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70924

Cumulative Model Updates: 181,432
Cumulative Timesteps: 1,513,174,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1513174046...
Checkpoint 1513174046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.84097
Policy Entropy: 2.47484
Value Function Loss: 0.01377

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.60966
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 23,284.91680
Overall Steps per Second: 10,945.41061

Timestep Collection Time: 2.14852
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.57068

Cumulative Model Updates: 181,438
Cumulative Timesteps: 1,513,224,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.76833
Policy Entropy: 2.47479
Value Function Loss: 0.01382

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.59838
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 23,246.34226
Overall Steps per Second: 10,946.70699

Timestep Collection Time: 2.15182
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.56959

Cumulative Model Updates: 181,444
Cumulative Timesteps: 1,513,274,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1513274096...
Checkpoint 1513274096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.46477
Policy Entropy: 2.46550
Value Function Loss: 0.01515

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.18760
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.58696

Collected Steps per Second: 23,309.05621
Overall Steps per Second: 11,104.29680

Timestep Collection Time: 2.14517
Timestep Consumption Time: 2.35777
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.50294

Cumulative Model Updates: 181,450
Cumulative Timesteps: 1,513,324,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.19299
Policy Entropy: 2.44781
Value Function Loss: 0.01569

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.16679
Policy Update Magnitude: 0.57493
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 22,998.30375
Overall Steps per Second: 10,875.02306

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60008

Cumulative Model Updates: 181,456
Cumulative Timesteps: 1,513,374,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1513374124...
Checkpoint 1513374124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.86010
Policy Entropy: 2.44114
Value Function Loss: 0.01552

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.61872
Value Function Update Magnitude: 0.60081

Collected Steps per Second: 22,482.32449
Overall Steps per Second: 10,726.75422

Timestep Collection Time: 2.22424
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.66180

Cumulative Model Updates: 181,462
Cumulative Timesteps: 1,513,424,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.81868
Policy Entropy: 2.45072
Value Function Loss: 0.01508

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.61976
Value Function Update Magnitude: 0.60013

Collected Steps per Second: 22,612.66085
Overall Steps per Second: 10,618.86858

Timestep Collection Time: 2.21142
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.70916

Cumulative Model Updates: 181,468
Cumulative Timesteps: 1,513,474,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1513474136...
Checkpoint 1513474136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.77291
Policy Entropy: 2.45847
Value Function Loss: 0.01494

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.61230
Value Function Update Magnitude: 0.59708

Collected Steps per Second: 22,658.06663
Overall Steps per Second: 10,818.47775

Timestep Collection Time: 2.20760
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.62357

Cumulative Model Updates: 181,474
Cumulative Timesteps: 1,513,524,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.09717
Policy Entropy: 2.46836
Value Function Loss: 0.01469

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.61248
Value Function Update Magnitude: 0.60293

Collected Steps per Second: 22,585.18323
Overall Steps per Second: 10,818.92657

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.62430

Cumulative Model Updates: 181,480
Cumulative Timesteps: 1,513,574,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1513574186...
Checkpoint 1513574186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.78377
Policy Entropy: 2.45110
Value Function Loss: 0.01546

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.62350
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 23,020.71312
Overall Steps per Second: 10,815.98640

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62316

Cumulative Model Updates: 181,486
Cumulative Timesteps: 1,513,624,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.27770
Policy Entropy: 2.45528
Value Function Loss: 0.01514

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.62026
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 23,318.01909
Overall Steps per Second: 10,940.44108

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.57130

Cumulative Model Updates: 181,492
Cumulative Timesteps: 1,513,674,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1513674202...
Checkpoint 1513674202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.86013
Policy Entropy: 2.44566
Value Function Loss: 0.01547

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.61246
Value Function Update Magnitude: 0.61750

Collected Steps per Second: 23,089.15162
Overall Steps per Second: 10,739.23802

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.65806

Cumulative Model Updates: 181,498
Cumulative Timesteps: 1,513,724,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.01695
Policy Entropy: 2.45671
Value Function Loss: 0.01480

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.61141
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 23,004.57616
Overall Steps per Second: 10,865.52442

Timestep Collection Time: 2.17348
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.60171

Cumulative Model Updates: 181,504
Cumulative Timesteps: 1,513,774,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1513774226...
Checkpoint 1513774226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.02034
Policy Entropy: 2.45029
Value Function Loss: 0.01460

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.61248
Value Function Update Magnitude: 0.63801

Collected Steps per Second: 23,156.58891
Overall Steps per Second: 10,968.88650

Timestep Collection Time: 2.15939
Timestep Consumption Time: 2.39933
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.55871

Cumulative Model Updates: 181,510
Cumulative Timesteps: 1,513,824,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.71996
Policy Entropy: 2.44295
Value Function Loss: 0.01485

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.61809
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 22,846.58053
Overall Steps per Second: 11,017.89573

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.35069
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.54025

Cumulative Model Updates: 181,516
Cumulative Timesteps: 1,513,874,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1513874254...
Checkpoint 1513874254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.34562
Policy Entropy: 2.42227
Value Function Loss: 0.01493

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.62293
Value Function Update Magnitude: 0.65179

Collected Steps per Second: 22,173.60389
Overall Steps per Second: 10,679.56439

Timestep Collection Time: 2.25493
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.68184

Cumulative Model Updates: 181,522
Cumulative Timesteps: 1,513,924,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.72369
Policy Entropy: 2.43058
Value Function Loss: 0.01469

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.62185
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 22,769.59152
Overall Steps per Second: 10,819.95192

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62183

Cumulative Model Updates: 181,528
Cumulative Timesteps: 1,513,974,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1513974262...
Checkpoint 1513974262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.16583
Policy Entropy: 2.44227
Value Function Loss: 0.01563

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.62592
Value Function Update Magnitude: 0.64923

Collected Steps per Second: 23,003.10647
Overall Steps per Second: 10,707.88279

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.49614
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.67002

Cumulative Model Updates: 181,534
Cumulative Timesteps: 1,514,024,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.30399
Policy Entropy: 2.43854
Value Function Loss: 0.01574

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.63740
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 22,646.95670
Overall Steps per Second: 10,521.16768

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.54483
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.75289

Cumulative Model Updates: 181,540
Cumulative Timesteps: 1,514,074,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1514074274...
Checkpoint 1514074274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.85967
Policy Entropy: 2.44568
Value Function Loss: 0.01528

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.63023
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 23,277.05973
Overall Steps per Second: 10,909.08964

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.58572

Cumulative Model Updates: 181,546
Cumulative Timesteps: 1,514,124,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.22540
Policy Entropy: 2.45275
Value Function Loss: 0.01432

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.61022
Value Function Update Magnitude: 0.62939

Collected Steps per Second: 22,994.97088
Overall Steps per Second: 11,025.65421

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.36238
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.53851

Cumulative Model Updates: 181,552
Cumulative Timesteps: 1,514,174,340

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1514174340...
Checkpoint 1514174340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.23757
Policy Entropy: 2.47139
Value Function Loss: 0.01337

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.58677
Value Function Update Magnitude: 0.59560

Collected Steps per Second: 22,001.85273
Overall Steps per Second: 10,579.72412

Timestep Collection Time: 2.27308
Timestep Consumption Time: 2.45407
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.72716

Cumulative Model Updates: 181,558
Cumulative Timesteps: 1,514,224,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.31193
Policy Entropy: 2.46203
Value Function Loss: 0.01423

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.59520
Value Function Update Magnitude: 0.57647

Collected Steps per Second: 23,062.30317
Overall Steps per Second: 10,860.76892

Timestep Collection Time: 2.16891
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60557

Cumulative Model Updates: 181,564
Cumulative Timesteps: 1,514,274,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1514274372...
Checkpoint 1514274372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.24635
Policy Entropy: 2.45627
Value Function Loss: 0.01495

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.60500
Value Function Update Magnitude: 0.57592

Collected Steps per Second: 23,118.86633
Overall Steps per Second: 10,700.20247

Timestep Collection Time: 2.16360
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.67468

Cumulative Model Updates: 181,570
Cumulative Timesteps: 1,514,324,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.72433
Policy Entropy: 2.46047
Value Function Loss: 0.01567

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.60238
Value Function Update Magnitude: 0.56246

Collected Steps per Second: 23,135.72344
Overall Steps per Second: 11,003.87808

Timestep Collection Time: 2.16228
Timestep Consumption Time: 2.38393
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.54622

Cumulative Model Updates: 181,576
Cumulative Timesteps: 1,514,374,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1514374418...
Checkpoint 1514374418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.71888
Policy Entropy: 2.46242
Value Function Loss: 0.01538

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.60846
Value Function Update Magnitude: 0.56385

Collected Steps per Second: 22,429.09532
Overall Steps per Second: 10,616.74602

Timestep Collection Time: 2.23041
Timestep Consumption Time: 2.48158
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71199

Cumulative Model Updates: 181,582
Cumulative Timesteps: 1,514,424,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.06871
Policy Entropy: 2.45439
Value Function Loss: 0.01437

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.58921

Collected Steps per Second: 22,799.73385
Overall Steps per Second: 10,881.16299

Timestep Collection Time: 2.19406
Timestep Consumption Time: 2.40324
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.59730

Cumulative Model Updates: 181,588
Cumulative Timesteps: 1,514,474,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1514474468...
Checkpoint 1514474468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.83200
Policy Entropy: 2.44965
Value Function Loss: 0.01359

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.59713
Value Function Update Magnitude: 0.58760

Collected Steps per Second: 22,570.42367
Overall Steps per Second: 10,610.49161

Timestep Collection Time: 2.21529
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.71232

Cumulative Model Updates: 181,594
Cumulative Timesteps: 1,514,524,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.42254
Policy Entropy: 2.45665
Value Function Loss: 0.01358

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.59799
Value Function Update Magnitude: 0.59294

Collected Steps per Second: 22,614.29948
Overall Steps per Second: 10,649.76901

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69569

Cumulative Model Updates: 181,600
Cumulative Timesteps: 1,514,574,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1514574476...
Checkpoint 1514574476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.87129
Policy Entropy: 2.45319
Value Function Loss: 0.01520

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.60414
Value Function Update Magnitude: 0.60788

Collected Steps per Second: 22,949.10922
Overall Steps per Second: 10,652.99620

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.69427

Cumulative Model Updates: 181,606
Cumulative Timesteps: 1,514,624,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.71530
Policy Entropy: 2.43777
Value Function Loss: 0.01603

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.61663
Value Function Update Magnitude: 0.62279

Collected Steps per Second: 23,249.54125
Overall Steps per Second: 10,766.23478

Timestep Collection Time: 2.15144
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.64601

Cumulative Model Updates: 181,612
Cumulative Timesteps: 1,514,674,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1514674504...
Checkpoint 1514674504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.85250
Policy Entropy: 2.43534
Value Function Loss: 0.01670

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.61328
Value Function Update Magnitude: 0.63060

Collected Steps per Second: 23,035.49357
Overall Steps per Second: 11,048.72717

Timestep Collection Time: 2.17082
Timestep Consumption Time: 2.35513
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.52595

Cumulative Model Updates: 181,618
Cumulative Timesteps: 1,514,724,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.74307
Policy Entropy: 2.44393
Value Function Loss: 0.01609

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.61597
Value Function Update Magnitude: 0.63161

Collected Steps per Second: 23,161.07395
Overall Steps per Second: 10,894.70802

Timestep Collection Time: 2.15923
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.59030

Cumulative Model Updates: 181,624
Cumulative Timesteps: 1,514,774,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1514774520...
Checkpoint 1514774520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.68270
Policy Entropy: 2.44356
Value Function Loss: 0.01565

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.61133
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 23,368.16344
Overall Steps per Second: 10,801.03415

Timestep Collection Time: 2.13983
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.62956

Cumulative Model Updates: 181,630
Cumulative Timesteps: 1,514,824,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.15201
Policy Entropy: 2.44511
Value Function Loss: 0.01559

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.60598
Value Function Update Magnitude: 0.58289

Collected Steps per Second: 23,240.36027
Overall Steps per Second: 10,771.57798

Timestep Collection Time: 2.15152
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.64203

Cumulative Model Updates: 181,636
Cumulative Timesteps: 1,514,874,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1514874526...
Checkpoint 1514874526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.12465
Policy Entropy: 2.45383
Value Function Loss: 0.01450

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.55700

Collected Steps per Second: 22,410.62476
Overall Steps per Second: 10,612.32104

Timestep Collection Time: 2.23189
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.71320

Cumulative Model Updates: 181,642
Cumulative Timesteps: 1,514,924,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.69459
Policy Entropy: 2.44077
Value Function Loss: 0.01492

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.60583
Value Function Update Magnitude: 0.55704

Collected Steps per Second: 22,754.45908
Overall Steps per Second: 10,945.19731

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.37094
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.56840

Cumulative Model Updates: 181,648
Cumulative Timesteps: 1,514,974,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1514974546...
Checkpoint 1514974546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.10026
Policy Entropy: 2.44674
Value Function Loss: 0.01489

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.59748
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 22,648.01972
Overall Steps per Second: 10,626.88125

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.70655

Cumulative Model Updates: 181,654
Cumulative Timesteps: 1,515,024,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.18693
Policy Entropy: 2.41917
Value Function Loss: 0.01510

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.59782
Value Function Update Magnitude: 0.59467

Collected Steps per Second: 22,542.65384
Overall Steps per Second: 10,555.99425

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.52024
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.73968

Cumulative Model Updates: 181,660
Cumulative Timesteps: 1,515,074,594

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1515074594...
Checkpoint 1515074594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.36530
Policy Entropy: 2.45540
Value Function Loss: 0.01447

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.60475
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 23,366.84000
Overall Steps per Second: 10,704.21065

Timestep Collection Time: 2.14090
Timestep Consumption Time: 2.53259
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.67349

Cumulative Model Updates: 181,666
Cumulative Timesteps: 1,515,124,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.48476
Policy Entropy: 2.44921
Value Function Loss: 0.01424

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.59413
Value Function Update Magnitude: 0.57315

Collected Steps per Second: 22,409.80357
Overall Steps per Second: 10,676.72503

Timestep Collection Time: 2.23161
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.68402

Cumulative Model Updates: 181,672
Cumulative Timesteps: 1,515,174,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1515174630...
Checkpoint 1515174630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.25013
Policy Entropy: 2.44470
Value Function Loss: 0.01464

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.59112
Value Function Update Magnitude: 0.58123

Collected Steps per Second: 22,065.51041
Overall Steps per Second: 10,621.89019

Timestep Collection Time: 2.26607
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.70745

Cumulative Model Updates: 181,678
Cumulative Timesteps: 1,515,224,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.62399
Policy Entropy: 2.44025
Value Function Loss: 0.01465

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.59782

Collected Steps per Second: 22,870.70357
Overall Steps per Second: 11,021.13245

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.35138
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.53837

Cumulative Model Updates: 181,684
Cumulative Timesteps: 1,515,274,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1515274650...
Checkpoint 1515274650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.40119
Policy Entropy: 2.44104
Value Function Loss: 0.01506

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.59970
Value Function Update Magnitude: 0.60366

Collected Steps per Second: 23,296.71151
Overall Steps per Second: 10,846.35459

Timestep Collection Time: 2.14700
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.61150

Cumulative Model Updates: 181,690
Cumulative Timesteps: 1,515,324,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.99301
Policy Entropy: 2.44730
Value Function Loss: 0.01536

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.60663
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 23,433.62920
Overall Steps per Second: 10,811.31907

Timestep Collection Time: 2.13437
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.62626

Cumulative Model Updates: 181,696
Cumulative Timesteps: 1,515,374,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1515374684...
Checkpoint 1515374684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.78949
Policy Entropy: 2.43772
Value Function Loss: 0.01608

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.60663
Value Function Update Magnitude: 0.59598

Collected Steps per Second: 22,616.79165
Overall Steps per Second: 10,610.31483

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.71296

Cumulative Model Updates: 181,702
Cumulative Timesteps: 1,515,424,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.60187
Policy Entropy: 2.43132
Value Function Loss: 0.01579

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.59945
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 22,731.34485
Overall Steps per Second: 10,858.73246

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.40614
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.60680

Cumulative Model Updates: 181,708
Cumulative Timesteps: 1,515,474,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1515474714...
Checkpoint 1515474714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.88624
Policy Entropy: 2.43845
Value Function Loss: 0.01501

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.59765
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,724.99409
Overall Steps per Second: 10,956.24395

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.36452
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.56580

Cumulative Model Updates: 181,714
Cumulative Timesteps: 1,515,524,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.74556
Policy Entropy: 2.46043
Value Function Loss: 0.01473

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.59629
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,256.60669
Overall Steps per Second: 10,632.62255

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.45687
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70420

Cumulative Model Updates: 181,720
Cumulative Timesteps: 1,515,574,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1515574756...
Checkpoint 1515574756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.16434
Policy Entropy: 2.42085
Value Function Loss: 0.01571

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.60578
Value Function Update Magnitude: 0.63635

Collected Steps per Second: 23,287.93533
Overall Steps per Second: 10,914.33435

Timestep Collection Time: 2.14738
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58186

Cumulative Model Updates: 181,726
Cumulative Timesteps: 1,515,624,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.19871
Policy Entropy: 2.40435
Value Function Loss: 0.01616

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.15686
Policy Update Magnitude: 0.61053
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 23,100.16436
Overall Steps per Second: 10,740.86176

Timestep Collection Time: 2.16518
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.65661

Cumulative Model Updates: 181,732
Cumulative Timesteps: 1,515,674,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1515674780...
Checkpoint 1515674780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.67903
Policy Entropy: 2.40262
Value Function Loss: 0.01550

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.59573
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 22,782.04011
Overall Steps per Second: 10,862.15807

Timestep Collection Time: 2.19594
Timestep Consumption Time: 2.40977
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60571

Cumulative Model Updates: 181,738
Cumulative Timesteps: 1,515,724,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.51275
Policy Entropy: 2.43065
Value Function Loss: 0.01525

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.15081
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.57014

Collected Steps per Second: 23,175.83025
Overall Steps per Second: 10,917.98038

Timestep Collection Time: 2.15777
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.58033

Cumulative Model Updates: 181,744
Cumulative Timesteps: 1,515,774,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1515774816...
Checkpoint 1515774816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.81391
Policy Entropy: 2.45310
Value Function Loss: 0.01496

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.58414
Value Function Update Magnitude: 0.54883

Collected Steps per Second: 23,083.29629
Overall Steps per Second: 11,072.32928

Timestep Collection Time: 2.16676
Timestep Consumption Time: 2.35045
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.51721

Cumulative Model Updates: 181,750
Cumulative Timesteps: 1,515,824,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.37582
Policy Entropy: 2.43718
Value Function Loss: 0.01539

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.54238

Collected Steps per Second: 22,734.47564
Overall Steps per Second: 10,704.52808

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.47261
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.67279

Cumulative Model Updates: 181,756
Cumulative Timesteps: 1,515,874,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1515874852...
Checkpoint 1515874852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.15241
Policy Entropy: 2.43165
Value Function Loss: 0.01603

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.58749
Value Function Update Magnitude: 0.56028

Collected Steps per Second: 22,533.88442
Overall Steps per Second: 10,630.08657

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70382

Cumulative Model Updates: 181,762
Cumulative Timesteps: 1,515,924,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.14461
Policy Entropy: 2.42100
Value Function Loss: 0.01520

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15971
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,762.06833
Overall Steps per Second: 10,710.75918

Timestep Collection Time: 2.19672
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.66839

Cumulative Model Updates: 181,768
Cumulative Timesteps: 1,515,974,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1515974856...
Checkpoint 1515974856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.56350
Policy Entropy: 2.42082
Value Function Loss: 0.01509

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.60042
Value Function Update Magnitude: 0.59079

Collected Steps per Second: 22,730.05808
Overall Steps per Second: 10,878.79267

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.39646
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.59628

Cumulative Model Updates: 181,774
Cumulative Timesteps: 1,516,024,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.34457
Policy Entropy: 2.42987
Value Function Loss: 0.01524

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.59426
Value Function Update Magnitude: 0.59444

Collected Steps per Second: 23,399.71519
Overall Steps per Second: 10,741.36073

Timestep Collection Time: 2.13721
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.65583

Cumulative Model Updates: 181,780
Cumulative Timesteps: 1,516,074,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1516074868...
Checkpoint 1516074868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.67913
Policy Entropy: 2.43152
Value Function Loss: 0.01597

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14282
Policy Update Magnitude: 0.59888
Value Function Update Magnitude: 0.57696

Collected Steps per Second: 23,357.07462
Overall Steps per Second: 10,854.55296

Timestep Collection Time: 2.14119
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60747

Cumulative Model Updates: 181,786
Cumulative Timesteps: 1,516,124,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.44110
Policy Entropy: 2.40897
Value Function Loss: 0.01665

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.61151
Value Function Update Magnitude: 0.57661

Collected Steps per Second: 22,872.62352
Overall Steps per Second: 10,649.41591

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69622

Cumulative Model Updates: 181,792
Cumulative Timesteps: 1,516,174,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1516174892...
Checkpoint 1516174892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.27126
Policy Entropy: 2.39829
Value Function Loss: 0.01593

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.61730
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 22,972.44771
Overall Steps per Second: 10,821.71377

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.62200

Cumulative Model Updates: 181,798
Cumulative Timesteps: 1,516,224,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.70401
Policy Entropy: 2.39002
Value Function Loss: 0.01594

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.61256
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 23,310.59926
Overall Steps per Second: 10,849.17666

Timestep Collection Time: 2.14503
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.60883

Cumulative Model Updates: 181,804
Cumulative Timesteps: 1,516,274,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1516274912...
Checkpoint 1516274912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.34054
Policy Entropy: 2.42044
Value Function Loss: 0.01489

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.60511
Value Function Update Magnitude: 0.57547

Collected Steps per Second: 23,344.48006
Overall Steps per Second: 10,950.08140

Timestep Collection Time: 2.14329
Timestep Consumption Time: 2.42599
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.56928

Cumulative Model Updates: 181,810
Cumulative Timesteps: 1,516,324,946

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.75098
Policy Entropy: 2.41864
Value Function Loss: 0.01536

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.60179
Value Function Update Magnitude: 0.57159

Collected Steps per Second: 22,285.53448
Overall Steps per Second: 10,547.82625

Timestep Collection Time: 2.24433
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.74183

Cumulative Model Updates: 181,816
Cumulative Timesteps: 1,516,374,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1516374962...
Checkpoint 1516374962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.40880
Policy Entropy: 2.42308
Value Function Loss: 0.01430

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.59391
Value Function Update Magnitude: 0.55751

Collected Steps per Second: 22,465.61494
Overall Steps per Second: 10,580.11700

Timestep Collection Time: 2.22678
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.72830

Cumulative Model Updates: 181,822
Cumulative Timesteps: 1,516,424,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.70167
Policy Entropy: 2.42902
Value Function Loss: 0.01358

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.58468
Value Function Update Magnitude: 0.53775

Collected Steps per Second: 22,838.81909
Overall Steps per Second: 10,805.81777

Timestep Collection Time: 2.18969
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62806

Cumulative Model Updates: 181,828
Cumulative Timesteps: 1,516,474,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1516474998...
Checkpoint 1516474998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.23365
Policy Entropy: 2.42368
Value Function Loss: 0.01345

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.53194

Collected Steps per Second: 22,737.95233
Overall Steps per Second: 10,676.80548

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.68305

Cumulative Model Updates: 181,834
Cumulative Timesteps: 1,516,524,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.60034
Policy Entropy: 2.42536
Value Function Loss: 0.01357

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.59379
Value Function Update Magnitude: 0.54652

Collected Steps per Second: 22,883.21455
Overall Steps per Second: 10,971.37986

Timestep Collection Time: 2.18501
Timestep Consumption Time: 2.37230
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.55731

Cumulative Model Updates: 181,840
Cumulative Timesteps: 1,516,574,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1516574998...
Checkpoint 1516574998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.52178
Policy Entropy: 2.42536
Value Function Loss: 0.01467

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 23,177.79907
Overall Steps per Second: 10,777.07494

Timestep Collection Time: 2.15767
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.64041

Cumulative Model Updates: 181,846
Cumulative Timesteps: 1,516,625,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.63104
Policy Entropy: 2.42301
Value Function Loss: 0.01413

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.54638

Collected Steps per Second: 23,456.83707
Overall Steps per Second: 10,806.37374

Timestep Collection Time: 2.13268
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.62931

Cumulative Model Updates: 181,852
Cumulative Timesteps: 1,516,675,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1516675034...
Checkpoint 1516675034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.38103
Policy Entropy: 2.41952
Value Function Loss: 0.01476

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.58162
Value Function Update Magnitude: 0.53311

Collected Steps per Second: 23,222.48038
Overall Steps per Second: 10,973.82012

Timestep Collection Time: 2.15378
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.55776

Cumulative Model Updates: 181,858
Cumulative Timesteps: 1,516,725,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.21075
Policy Entropy: 2.41261
Value Function Loss: 0.01611

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.58991
Value Function Update Magnitude: 0.54292

Collected Steps per Second: 23,115.14956
Overall Steps per Second: 10,947.66688

Timestep Collection Time: 2.16360
Timestep Consumption Time: 2.40468
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.56828

Cumulative Model Updates: 181,864
Cumulative Timesteps: 1,516,775,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1516775062...
Checkpoint 1516775062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.63877
Policy Entropy: 2.42530
Value Function Loss: 0.01632

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.60207
Value Function Update Magnitude: 0.55153

Collected Steps per Second: 23,053.60680
Overall Steps per Second: 11,049.83313

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.35676
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.52622

Cumulative Model Updates: 181,870
Cumulative Timesteps: 1,516,825,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.46461
Policy Entropy: 2.43034
Value Function Loss: 0.01476

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.55597

Collected Steps per Second: 22,714.84488
Overall Steps per Second: 10,631.66693

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70538

Cumulative Model Updates: 181,876
Cumulative Timesteps: 1,516,875,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1516875102...
Checkpoint 1516875102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.49584
Policy Entropy: 2.43721
Value Function Loss: 0.01471

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.59076
Value Function Update Magnitude: 0.54990

Collected Steps per Second: 22,802.61749
Overall Steps per Second: 10,727.69855

Timestep Collection Time: 2.19343
Timestep Consumption Time: 2.46889
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.66232

Cumulative Model Updates: 181,882
Cumulative Timesteps: 1,516,925,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.84751
Policy Entropy: 2.45300
Value Function Loss: 0.01481

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.54773

Collected Steps per Second: 22,716.45067
Overall Steps per Second: 10,703.98261

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.47041
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.67172

Cumulative Model Updates: 181,888
Cumulative Timesteps: 1,516,975,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1516975124...
Checkpoint 1516975124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.84743
Policy Entropy: 2.43908
Value Function Loss: 0.01570

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.54067

Collected Steps per Second: 22,571.59727
Overall Steps per Second: 10,631.84518

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.70511

Cumulative Model Updates: 181,894
Cumulative Timesteps: 1,517,025,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.23281
Policy Entropy: 2.43205
Value Function Loss: 0.01515

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.57037

Collected Steps per Second: 23,286.91488
Overall Steps per Second: 10,922.45778

Timestep Collection Time: 2.14747
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.57846

Cumulative Model Updates: 181,900
Cumulative Timesteps: 1,517,075,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1517075156...
Checkpoint 1517075156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.03436
Policy Entropy: 2.42540
Value Function Loss: 0.01446

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.58799
Value Function Update Magnitude: 0.57388

Collected Steps per Second: 23,395.77102
Overall Steps per Second: 10,835.49088

Timestep Collection Time: 2.13757
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.61539

Cumulative Model Updates: 181,906
Cumulative Timesteps: 1,517,125,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.70241
Policy Entropy: 2.43559
Value Function Loss: 0.01464

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.59234
Value Function Update Magnitude: 0.55864

Collected Steps per Second: 23,448.03478
Overall Steps per Second: 10,804.08587

Timestep Collection Time: 2.13348
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.63029

Cumulative Model Updates: 181,912
Cumulative Timesteps: 1,517,175,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1517175192...
Checkpoint 1517175192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.52288
Policy Entropy: 2.45412
Value Function Loss: 0.01561

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.59452
Value Function Update Magnitude: 0.58904

Collected Steps per Second: 23,305.13343
Overall Steps per Second: 10,930.32608

Timestep Collection Time: 2.14562
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.57479

Cumulative Model Updates: 181,918
Cumulative Timesteps: 1,517,225,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.50858
Policy Entropy: 2.44052
Value Function Loss: 0.01599

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.60116
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,631.65956
Overall Steps per Second: 10,635.81427

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70147

Cumulative Model Updates: 181,924
Cumulative Timesteps: 1,517,275,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1517275200...
Checkpoint 1517275200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.26547
Policy Entropy: 2.43137
Value Function Loss: 0.01572

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.59956
Value Function Update Magnitude: 0.61370

Collected Steps per Second: 23,298.68924
Overall Steps per Second: 10,991.71502

Timestep Collection Time: 2.14733
Timestep Consumption Time: 2.40428
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.55161

Cumulative Model Updates: 181,930
Cumulative Timesteps: 1,517,325,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.87575
Policy Entropy: 2.39610
Value Function Loss: 0.01589

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.58596
Value Function Update Magnitude: 0.60761

Collected Steps per Second: 22,688.42920
Overall Steps per Second: 10,653.02230

Timestep Collection Time: 2.20500
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.69613

Cumulative Model Updates: 181,936
Cumulative Timesteps: 1,517,375,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1517375258...
Checkpoint 1517375258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.73532
Policy Entropy: 2.40262
Value Function Loss: 0.01572

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.19334
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.58543

Collected Steps per Second: 22,806.70329
Overall Steps per Second: 10,824.62186

Timestep Collection Time: 2.19234
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.61910

Cumulative Model Updates: 181,942
Cumulative Timesteps: 1,517,425,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.88156
Policy Entropy: 2.40437
Value Function Loss: 0.01674

Mean KL Divergence: 0.02754
SB3 Clip Fraction: 0.19028
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.58645

Collected Steps per Second: 22,651.26504
Overall Steps per Second: 10,597.30949

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71950

Cumulative Model Updates: 181,948
Cumulative Timesteps: 1,517,475,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1517475272...
Checkpoint 1517475272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.86970
Policy Entropy: 2.42101
Value Function Loss: 0.01702

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.17538
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.58398

Collected Steps per Second: 22,807.24191
Overall Steps per Second: 10,754.50558

Timestep Collection Time: 2.19255
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.64977

Cumulative Model Updates: 181,954
Cumulative Timesteps: 1,517,525,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.77499
Policy Entropy: 2.43515
Value Function Loss: 0.01700

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.57593

Collected Steps per Second: 23,427.01313
Overall Steps per Second: 10,945.29351

Timestep Collection Time: 2.13548
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.57073

Cumulative Model Updates: 181,960
Cumulative Timesteps: 1,517,575,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1517575306...
Checkpoint 1517575306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.64615
Policy Entropy: 2.45033
Value Function Loss: 0.01583

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.17721
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 23,311.28154
Overall Steps per Second: 10,852.79440

Timestep Collection Time: 2.14531
Timestep Consumption Time: 2.46272
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.60803

Cumulative Model Updates: 181,966
Cumulative Timesteps: 1,517,625,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.26751
Policy Entropy: 2.45624
Value Function Loss: 0.01514

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.55773

Collected Steps per Second: 23,001.82883
Overall Steps per Second: 10,837.12734

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.61377

Cumulative Model Updates: 181,972
Cumulative Timesteps: 1,517,675,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1517675316...
Checkpoint 1517675316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.74213
Policy Entropy: 2.45546
Value Function Loss: 0.01559

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.59460
Value Function Update Magnitude: 0.55742

Collected Steps per Second: 22,988.33242
Overall Steps per Second: 10,723.45904

Timestep Collection Time: 2.17510
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.66286

Cumulative Model Updates: 181,978
Cumulative Timesteps: 1,517,725,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.98877
Policy Entropy: 2.44363
Value Function Loss: 0.01623

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.59330
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 23,208.83109
Overall Steps per Second: 10,929.31708

Timestep Collection Time: 2.15521
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.57668

Cumulative Model Updates: 181,984
Cumulative Timesteps: 1,517,775,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1517775338...
Checkpoint 1517775338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.68394
Policy Entropy: 2.42803
Value Function Loss: 0.01652

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.59633
Value Function Update Magnitude: 0.59565

Collected Steps per Second: 22,954.36102
Overall Steps per Second: 10,784.22295

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.63752

Cumulative Model Updates: 181,990
Cumulative Timesteps: 1,517,825,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.35053
Policy Entropy: 2.43716
Value Function Loss: 0.01602

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15165
Policy Update Magnitude: 0.59260
Value Function Update Magnitude: 0.57712

Collected Steps per Second: 22,577.01463
Overall Steps per Second: 10,733.22646

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.44438
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.65955

Cumulative Model Updates: 181,996
Cumulative Timesteps: 1,517,875,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1517875362...
Checkpoint 1517875362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.13614
Policy Entropy: 2.43615
Value Function Loss: 0.01581

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.56296

Collected Steps per Second: 22,677.52949
Overall Steps per Second: 10,622.60800

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.70713

Cumulative Model Updates: 182,002
Cumulative Timesteps: 1,517,925,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.38936
Policy Entropy: 2.44606
Value Function Loss: 0.01498

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.59290
Value Function Update Magnitude: 0.57196

Collected Steps per Second: 22,508.73016
Overall Steps per Second: 10,611.09796

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.71337

Cumulative Model Updates: 182,008
Cumulative Timesteps: 1,517,975,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1517975378...
Checkpoint 1517975378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.58560
Policy Entropy: 2.43518
Value Function Loss: 0.01550

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.57098

Collected Steps per Second: 22,894.53694
Overall Steps per Second: 10,691.70848

Timestep Collection Time: 2.18498
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.67877

Cumulative Model Updates: 182,014
Cumulative Timesteps: 1,518,025,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.15580
Policy Entropy: 2.43944
Value Function Loss: 0.01577

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.59995
Value Function Update Magnitude: 0.57923

Collected Steps per Second: 22,763.17786
Overall Steps per Second: 10,745.94365

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.65515

Cumulative Model Updates: 182,020
Cumulative Timesteps: 1,518,075,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1518075426...
Checkpoint 1518075426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.29704
Policy Entropy: 2.45545
Value Function Loss: 0.01681

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.61193
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,897.35123
Overall Steps per Second: 10,971.71175

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.37456
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.55918

Cumulative Model Updates: 182,026
Cumulative Timesteps: 1,518,125,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.78734
Policy Entropy: 2.45633
Value Function Loss: 0.01621

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.60763
Value Function Update Magnitude: 0.59145

Collected Steps per Second: 23,359.15699
Overall Steps per Second: 10,931.55442

Timestep Collection Time: 2.14134
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57574

Cumulative Model Updates: 182,032
Cumulative Timesteps: 1,518,175,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1518175468...
Checkpoint 1518175468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.40176
Policy Entropy: 2.44635
Value Function Loss: 0.01697

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.60516
Value Function Update Magnitude: 0.58112

Collected Steps per Second: 23,006.20023
Overall Steps per Second: 10,695.61007

Timestep Collection Time: 2.17394
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.67612

Cumulative Model Updates: 182,038
Cumulative Timesteps: 1,518,225,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.18760
Policy Entropy: 2.43295
Value Function Loss: 0.01767

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.62152
Value Function Update Magnitude: 0.59269

Collected Steps per Second: 23,227.36109
Overall Steps per Second: 10,922.11109

Timestep Collection Time: 2.15281
Timestep Consumption Time: 2.42543
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.57824

Cumulative Model Updates: 182,044
Cumulative Timesteps: 1,518,275,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1518275486...
Checkpoint 1518275486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.88670
Policy Entropy: 2.40896
Value Function Loss: 0.01674

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.62152
Value Function Update Magnitude: 0.59845

Collected Steps per Second: 22,272.30616
Overall Steps per Second: 10,644.10048

Timestep Collection Time: 2.24512
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.69781

Cumulative Model Updates: 182,050
Cumulative Timesteps: 1,518,325,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.22125
Policy Entropy: 2.40174
Value Function Loss: 0.01621

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.60389
Value Function Update Magnitude: 0.58976

Collected Steps per Second: 22,760.93066
Overall Steps per Second: 10,940.45798

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.37354
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.57038

Cumulative Model Updates: 182,056
Cumulative Timesteps: 1,518,375,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1518375492...
Checkpoint 1518375492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.33999
Policy Entropy: 2.39796
Value Function Loss: 0.01537

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.60718
Value Function Update Magnitude: 0.58624

Collected Steps per Second: 22,937.52405
Overall Steps per Second: 10,703.93941

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.49174
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.67192

Cumulative Model Updates: 182,062
Cumulative Timesteps: 1,518,425,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.80131
Policy Entropy: 2.38880
Value Function Loss: 0.01543

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.61175
Value Function Update Magnitude: 0.59301

Collected Steps per Second: 23,280.33827
Overall Steps per Second: 10,872.79753

Timestep Collection Time: 2.14851
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.60029

Cumulative Model Updates: 182,068
Cumulative Timesteps: 1,518,475,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1518475518...
Checkpoint 1518475518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.95363
Policy Entropy: 2.39200
Value Function Loss: 0.01531

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.60199
Value Function Update Magnitude: 0.61522

Collected Steps per Second: 22,947.96653
Overall Steps per Second: 10,697.97459

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.67416

Cumulative Model Updates: 182,074
Cumulative Timesteps: 1,518,525,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.04003
Policy Entropy: 2.39784
Value Function Loss: 0.01456

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 23,350.47048
Overall Steps per Second: 10,814.12822

Timestep Collection Time: 2.14265
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.62654

Cumulative Model Updates: 182,080
Cumulative Timesteps: 1,518,575,554

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1518575554...
Checkpoint 1518575554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.74078
Policy Entropy: 2.41689
Value Function Loss: 0.01525

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 23,023.73932
Overall Steps per Second: 11,057.67128

Timestep Collection Time: 2.17263
Timestep Consumption Time: 2.35111
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.52374

Cumulative Model Updates: 182,086
Cumulative Timesteps: 1,518,625,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.08321
Policy Entropy: 2.42285
Value Function Loss: 0.01442

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.57753
Value Function Update Magnitude: 0.56498

Collected Steps per Second: 23,384.78628
Overall Steps per Second: 10,969.31310

Timestep Collection Time: 2.13891
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.55981

Cumulative Model Updates: 182,092
Cumulative Timesteps: 1,518,675,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1518675594...
Checkpoint 1518675594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.09369
Policy Entropy: 2.41865
Value Function Loss: 0.01471

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.57575

Collected Steps per Second: 22,871.86501
Overall Steps per Second: 10,662.68539

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.69075

Cumulative Model Updates: 182,098
Cumulative Timesteps: 1,518,725,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.26621
Policy Entropy: 2.42255
Value Function Loss: 0.01413

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.18867
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.59933

Collected Steps per Second: 22,690.05644
Overall Steps per Second: 10,771.47387

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64338

Cumulative Model Updates: 182,104
Cumulative Timesteps: 1,518,775,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1518775626...
Checkpoint 1518775626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.87663
Policy Entropy: 2.42976
Value Function Loss: 0.01514

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.17460
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.59571

Collected Steps per Second: 22,437.64442
Overall Steps per Second: 10,726.05640

Timestep Collection Time: 2.22911
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.66304

Cumulative Model Updates: 182,110
Cumulative Timesteps: 1,518,825,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.60675
Policy Entropy: 2.43001
Value Function Loss: 0.01467

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.21336
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.58563

Collected Steps per Second: 22,682.66338
Overall Steps per Second: 10,822.92664

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.41685
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62241

Cumulative Model Updates: 182,116
Cumulative Timesteps: 1,518,875,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1518875670...
Checkpoint 1518875670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.11966
Policy Entropy: 2.43956
Value Function Loss: 0.01472

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.19207
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.57129

Collected Steps per Second: 22,576.24256
Overall Steps per Second: 10,729.77098

Timestep Collection Time: 2.21489
Timestep Consumption Time: 2.44541
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.66030

Cumulative Model Updates: 182,122
Cumulative Timesteps: 1,518,925,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.33747
Policy Entropy: 2.43115
Value Function Loss: 0.01345

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.16032
Policy Update Magnitude: 0.56839
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 22,561.86774
Overall Steps per Second: 10,868.50465

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.38499
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60174

Cumulative Model Updates: 182,128
Cumulative Timesteps: 1,518,975,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1518975688...
Checkpoint 1518975688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.17133
Policy Entropy: 2.43870
Value Function Loss: 0.01498

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.57613
Value Function Update Magnitude: 0.56735

Collected Steps per Second: 23,111.83666
Overall Steps per Second: 10,701.09184

Timestep Collection Time: 2.16383
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67335

Cumulative Model Updates: 182,134
Cumulative Timesteps: 1,519,025,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.01415
Policy Entropy: 2.43973
Value Function Loss: 0.01530

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.59736

Collected Steps per Second: 23,277.14878
Overall Steps per Second: 10,910.99835

Timestep Collection Time: 2.14923
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.58510

Cumulative Model Updates: 182,140
Cumulative Timesteps: 1,519,075,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1519075726...
Checkpoint 1519075726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.07451
Policy Entropy: 2.44205
Value Function Loss: 0.01581

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.61664

Collected Steps per Second: 23,125.27935
Overall Steps per Second: 10,864.63020

Timestep Collection Time: 2.16240
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.60264

Cumulative Model Updates: 182,146
Cumulative Timesteps: 1,519,125,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.98175
Policy Entropy: 2.44360
Value Function Loss: 0.01480

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.61257

Collected Steps per Second: 23,338.62638
Overall Steps per Second: 10,877.85759

Timestep Collection Time: 2.14331
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.59852

Cumulative Model Updates: 182,152
Cumulative Timesteps: 1,519,175,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1519175754...
Checkpoint 1519175754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.65369
Policy Entropy: 2.43700
Value Function Loss: 0.01521

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 23,469.76195
Overall Steps per Second: 11,029.28716

Timestep Collection Time: 2.13245
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.53774

Cumulative Model Updates: 182,158
Cumulative Timesteps: 1,519,225,802

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.24298
Policy Entropy: 2.44095
Value Function Loss: 0.01560

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.56243

Collected Steps per Second: 22,923.04268
Overall Steps per Second: 10,797.66358

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.45020
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.63211

Cumulative Model Updates: 182,164
Cumulative Timesteps: 1,519,275,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1519275818...
Checkpoint 1519275818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.65459
Policy Entropy: 2.44728
Value Function Loss: 0.01581

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.57436
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 22,457.73669
Overall Steps per Second: 10,637.22862

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.47437
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.70104

Cumulative Model Updates: 182,170
Cumulative Timesteps: 1,519,325,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.22953
Policy Entropy: 2.47748
Value Function Loss: 0.01466

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.55152

Collected Steps per Second: 22,367.66310
Overall Steps per Second: 10,541.14668

Timestep Collection Time: 2.23680
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74635

Cumulative Model Updates: 182,176
Cumulative Timesteps: 1,519,375,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1519375856...
Checkpoint 1519375856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.82932
Policy Entropy: 2.48737
Value Function Loss: 0.01522

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 22,814.75435
Overall Steps per Second: 10,766.46473

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.64479

Cumulative Model Updates: 182,182
Cumulative Timesteps: 1,519,425,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.59560
Policy Entropy: 2.46172
Value Function Loss: 0.01590

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.59306
Value Function Update Magnitude: 0.58939

Collected Steps per Second: 23,426.97441
Overall Steps per Second: 11,060.32141

Timestep Collection Time: 2.13497
Timestep Consumption Time: 2.38714
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.52211

Cumulative Model Updates: 182,188
Cumulative Timesteps: 1,519,475,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1519475880...
Checkpoint 1519475880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.31215
Policy Entropy: 2.46064
Value Function Loss: 0.01664

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.60203
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 23,023.73968
Overall Steps per Second: 10,698.87733

Timestep Collection Time: 2.17280
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67582

Cumulative Model Updates: 182,194
Cumulative Timesteps: 1,519,525,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.74546
Policy Entropy: 2.46263
Value Function Loss: 0.01659

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.58932
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 23,299.68041
Overall Steps per Second: 10,920.68143

Timestep Collection Time: 2.14690
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58048

Cumulative Model Updates: 182,200
Cumulative Timesteps: 1,519,575,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1519575928...
Checkpoint 1519575928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.70168
Policy Entropy: 2.49647
Value Function Loss: 0.01516

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.18450
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.63179

Collected Steps per Second: 22,524.91620
Overall Steps per Second: 10,653.86573

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.47426
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.69482

Cumulative Model Updates: 182,206
Cumulative Timesteps: 1,519,625,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.19683
Policy Entropy: 2.46860
Value Function Loss: 0.01541

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.63306

Collected Steps per Second: 23,304.40684
Overall Steps per Second: 10,921.89446

Timestep Collection Time: 2.14612
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.57924

Cumulative Model Updates: 182,212
Cumulative Timesteps: 1,519,675,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1519675960...
Checkpoint 1519675960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.67062
Policy Entropy: 2.47353
Value Function Loss: 0.01544

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 22,882.24113
Overall Steps per Second: 11,018.03212

Timestep Collection Time: 2.18615
Timestep Consumption Time: 2.35404
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.54019

Cumulative Model Updates: 182,218
Cumulative Timesteps: 1,519,725,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.89993
Policy Entropy: 2.47202
Value Function Loss: 0.01542

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.58258

Collected Steps per Second: 22,744.27581
Overall Steps per Second: 10,659.35181

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.69109

Cumulative Model Updates: 182,224
Cumulative Timesteps: 1,519,775,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1519775988...
Checkpoint 1519775988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.95670
Policy Entropy: 2.46383
Value Function Loss: 0.01523

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.58873
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 22,936.86533
Overall Steps per Second: 10,893.29459

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.41076
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59126

Cumulative Model Updates: 182,230
Cumulative Timesteps: 1,519,826,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.07626
Policy Entropy: 2.45001
Value Function Loss: 0.01558

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.58964
Value Function Update Magnitude: 0.56589

Collected Steps per Second: 22,601.53697
Overall Steps per Second: 10,579.09647

Timestep Collection Time: 2.21250
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.72687

Cumulative Model Updates: 182,236
Cumulative Timesteps: 1,519,876,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1519876008...
Checkpoint 1519876008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.47704
Policy Entropy: 2.43449
Value Function Loss: 0.01603

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 22,717.24387
Overall Steps per Second: 10,710.06575

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.66888

Cumulative Model Updates: 182,242
Cumulative Timesteps: 1,519,926,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.16573
Policy Entropy: 2.44502
Value Function Loss: 0.01599

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.56964

Collected Steps per Second: 23,477.69534
Overall Steps per Second: 10,755.81906

Timestep Collection Time: 2.13053
Timestep Consumption Time: 2.51997
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.65051

Cumulative Model Updates: 182,248
Cumulative Timesteps: 1,519,976,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1519976032...
Checkpoint 1519976032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.25155
Policy Entropy: 2.43374
Value Function Loss: 0.01683

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.59989
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 21,408.54896
Overall Steps per Second: 10,653.57476

Timestep Collection Time: 2.33598
Timestep Consumption Time: 2.35822
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.69420

Cumulative Model Updates: 182,254
Cumulative Timesteps: 1,520,026,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.80296
Policy Entropy: 2.44694
Value Function Loss: 0.01641

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.59944
Value Function Update Magnitude: 0.59484

Collected Steps per Second: 22,854.49978
Overall Steps per Second: 10,676.00546

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.68377

Cumulative Model Updates: 182,260
Cumulative Timesteps: 1,520,076,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1520076046...
Checkpoint 1520076046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.33493
Policy Entropy: 2.43243
Value Function Loss: 0.01694

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.59753
Value Function Update Magnitude: 0.59427

Collected Steps per Second: 22,556.91907
Overall Steps per Second: 10,763.70238

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.64561

Cumulative Model Updates: 182,266
Cumulative Timesteps: 1,520,126,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.66697
Policy Entropy: 2.45479
Value Function Loss: 0.01674

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.59938
Value Function Update Magnitude: 0.58602

Collected Steps per Second: 23,241.47832
Overall Steps per Second: 10,764.74583

Timestep Collection Time: 2.15141
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.64498

Cumulative Model Updates: 182,272
Cumulative Timesteps: 1,520,176,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1520176052...
Checkpoint 1520176052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.03146
Policy Entropy: 2.44867
Value Function Loss: 0.01629

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.60113
Value Function Update Magnitude: 0.59908

Collected Steps per Second: 23,320.92663
Overall Steps per Second: 10,941.83074

Timestep Collection Time: 2.14408
Timestep Consumption Time: 2.42572
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.56980

Cumulative Model Updates: 182,278
Cumulative Timesteps: 1,520,226,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.28442
Policy Entropy: 2.45123
Value Function Loss: 0.01587

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.58728
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 23,382.59221
Overall Steps per Second: 10,861.21371

Timestep Collection Time: 2.13860
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.60409

Cumulative Model Updates: 182,284
Cumulative Timesteps: 1,520,276,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1520276060...
Checkpoint 1520276060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.90900
Policy Entropy: 2.42211
Value Function Loss: 0.01487

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 22,956.24996
Overall Steps per Second: 10,656.33090

Timestep Collection Time: 2.17849
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69298

Cumulative Model Updates: 182,290
Cumulative Timesteps: 1,520,326,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.32766
Policy Entropy: 2.39568
Value Function Loss: 0.01527

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.59069
Value Function Update Magnitude: 0.57201

Collected Steps per Second: 23,466.78120
Overall Steps per Second: 10,828.46530

Timestep Collection Time: 2.13093
Timestep Consumption Time: 2.48709
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.61801

Cumulative Model Updates: 182,296
Cumulative Timesteps: 1,520,376,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1520376076...
Checkpoint 1520376076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.25264
Policy Entropy: 2.37406
Value Function Loss: 0.01481

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.59629
Value Function Update Magnitude: 0.58486

Collected Steps per Second: 23,197.57436
Overall Steps per Second: 10,790.91489

Timestep Collection Time: 2.15557
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.63390

Cumulative Model Updates: 182,302
Cumulative Timesteps: 1,520,426,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.29235
Policy Entropy: 2.38452
Value Function Loss: 0.01446

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.58736
Value Function Update Magnitude: 0.58615

Collected Steps per Second: 20,994.24025
Overall Steps per Second: 10,294.33966

Timestep Collection Time: 2.38265
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.85918

Cumulative Model Updates: 182,308
Cumulative Timesteps: 1,520,476,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1520476102...
Checkpoint 1520476102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.57947
Policy Entropy: 2.38858
Value Function Loss: 0.01454

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.59486
Value Function Update Magnitude: 0.57710

Collected Steps per Second: 20,924.21852
Overall Steps per Second: 10,286.62598

Timestep Collection Time: 2.39072
Timestep Consumption Time: 2.47229
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.86301

Cumulative Model Updates: 182,314
Cumulative Timesteps: 1,520,526,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.87721
Policy Entropy: 2.38562
Value Function Loss: 0.01505

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.60348
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 22,192.68030
Overall Steps per Second: 10,457.62120

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.52871
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.78216

Cumulative Model Updates: 182,320
Cumulative Timesteps: 1,520,576,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1520576136...
Checkpoint 1520576136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.18987
Policy Entropy: 2.40394
Value Function Loss: 0.01542

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.60233
Value Function Update Magnitude: 0.63664

Collected Steps per Second: 21,420.26453
Overall Steps per Second: 10,322.29506

Timestep Collection Time: 2.33489
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.84524

Cumulative Model Updates: 182,326
Cumulative Timesteps: 1,520,626,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.36743
Policy Entropy: 2.39486
Value Function Loss: 0.01523

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.58477
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 23,253.29239
Overall Steps per Second: 10,781.73485

Timestep Collection Time: 2.15075
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63859

Cumulative Model Updates: 182,332
Cumulative Timesteps: 1,520,676,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1520676162...
Checkpoint 1520676162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.20568
Policy Entropy: 2.38304
Value Function Loss: 0.01644

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.57923
Value Function Update Magnitude: 0.61317

Collected Steps per Second: 22,735.22362
Overall Steps per Second: 10,642.37325

Timestep Collection Time: 2.19958
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69895

Cumulative Model Updates: 182,338
Cumulative Timesteps: 1,520,726,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.40122
Policy Entropy: 2.37194
Value Function Loss: 0.01568

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.59015
Value Function Update Magnitude: 0.62775

Collected Steps per Second: 23,446.35448
Overall Steps per Second: 10,938.09310

Timestep Collection Time: 2.13381
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.57392

Cumulative Model Updates: 182,344
Cumulative Timesteps: 1,520,776,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1520776200...
Checkpoint 1520776200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.44912
Policy Entropy: 2.39793
Value Function Loss: 0.01540

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.58711
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 23,075.51676
Overall Steps per Second: 10,680.23905

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.68229

Cumulative Model Updates: 182,350
Cumulative Timesteps: 1,520,826,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.40491
Policy Entropy: 2.41800
Value Function Loss: 0.01506

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.58821
Value Function Update Magnitude: 0.58117

Collected Steps per Second: 23,469.51535
Overall Steps per Second: 10,880.02991

Timestep Collection Time: 2.13042
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.59558

Cumulative Model Updates: 182,356
Cumulative Timesteps: 1,520,876,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1520876208...
Checkpoint 1520876208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.04974
Policy Entropy: 2.42207
Value Function Loss: 0.01529

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.59457
Value Function Update Magnitude: 0.56988

Collected Steps per Second: 22,760.55989
Overall Steps per Second: 10,625.24538

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.70653

Cumulative Model Updates: 182,362
Cumulative Timesteps: 1,520,926,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.55768
Policy Entropy: 2.41481
Value Function Loss: 0.01511

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.59872
Value Function Update Magnitude: 0.59988

Collected Steps per Second: 22,804.30680
Overall Steps per Second: 10,876.42553

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.40482
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.59765

Cumulative Model Updates: 182,368
Cumulative Timesteps: 1,520,976,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1520976222...
Checkpoint 1520976222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.38448
Policy Entropy: 2.41840
Value Function Loss: 0.01594

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 22,385.58829
Overall Steps per Second: 10,752.37656

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.65144

Cumulative Model Updates: 182,374
Cumulative Timesteps: 1,521,026,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.89662
Policy Entropy: 2.40677
Value Function Loss: 0.01562

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.60045
Value Function Update Magnitude: 0.67423

Collected Steps per Second: 23,072.12092
Overall Steps per Second: 10,830.30162

Timestep Collection Time: 2.16842
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61945

Cumulative Model Updates: 182,380
Cumulative Timesteps: 1,521,076,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1521076266...
Checkpoint 1521076266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.59695
Policy Entropy: 2.42577
Value Function Loss: 0.01512

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.58861
Value Function Update Magnitude: 0.66976

Collected Steps per Second: 22,749.13130
Overall Steps per Second: 10,629.72321

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.70473

Cumulative Model Updates: 182,386
Cumulative Timesteps: 1,521,126,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.87182
Policy Entropy: 2.42351
Value Function Loss: 0.01555

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.62795

Collected Steps per Second: 23,469.25592
Overall Steps per Second: 10,835.08585

Timestep Collection Time: 2.13164
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.61722

Cumulative Model Updates: 182,392
Cumulative Timesteps: 1,521,176,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1521176304...
Checkpoint 1521176304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.21122
Policy Entropy: 2.42288
Value Function Loss: 0.01658

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.60509

Collected Steps per Second: 22,395.39244
Overall Steps per Second: 10,721.76355

Timestep Collection Time: 2.23278
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.66378

Cumulative Model Updates: 182,398
Cumulative Timesteps: 1,521,226,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.35760
Policy Entropy: 2.38243
Value Function Loss: 0.01653

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.59666
Value Function Update Magnitude: 0.61415

Collected Steps per Second: 23,244.82797
Overall Steps per Second: 10,977.96799

Timestep Collection Time: 2.15179
Timestep Consumption Time: 2.40443
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.55622

Cumulative Model Updates: 182,404
Cumulative Timesteps: 1,521,276,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1521276326...
Checkpoint 1521276326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.64716
Policy Entropy: 2.36373
Value Function Loss: 0.01566

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.59794
Value Function Update Magnitude: 0.61326

Collected Steps per Second: 23,021.37325
Overall Steps per Second: 11,015.44285

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.36861
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.54181

Cumulative Model Updates: 182,410
Cumulative Timesteps: 1,521,326,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.31730
Policy Entropy: 2.37894
Value Function Loss: 0.01486

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.59126
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 23,297.04742
Overall Steps per Second: 10,920.55387

Timestep Collection Time: 2.14671
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57962

Cumulative Model Updates: 182,416
Cumulative Timesteps: 1,521,376,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1521376368...
Checkpoint 1521376368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.76703
Policy Entropy: 2.38921
Value Function Loss: 0.01543

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.58603
Value Function Update Magnitude: 0.59797

Collected Steps per Second: 22,592.71399
Overall Steps per Second: 10,689.91308

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.46558
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.67993

Cumulative Model Updates: 182,422
Cumulative Timesteps: 1,521,426,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.49717
Policy Entropy: 2.40019
Value Function Loss: 0.01550

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.59610
Value Function Update Magnitude: 0.60082

Collected Steps per Second: 22,669.64443
Overall Steps per Second: 10,817.62205

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62209

Cumulative Model Updates: 182,428
Cumulative Timesteps: 1,521,476,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1521476396...
Checkpoint 1521476396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.84048
Policy Entropy: 2.41859
Value Function Loss: 0.01505

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.58907
Value Function Update Magnitude: 0.60002

Collected Steps per Second: 22,057.52860
Overall Steps per Second: 10,636.76262

Timestep Collection Time: 2.26789
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70293

Cumulative Model Updates: 182,434
Cumulative Timesteps: 1,521,526,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.74216
Policy Entropy: 2.42021
Value Function Loss: 0.01479

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 22,977.58397
Overall Steps per Second: 11,047.12246

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.35088
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.52769

Cumulative Model Updates: 182,440
Cumulative Timesteps: 1,521,576,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1521576438...
Checkpoint 1521576438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.45036
Policy Entropy: 2.42447
Value Function Loss: 0.01414

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.58762
Value Function Update Magnitude: 0.59706

Collected Steps per Second: 23,317.02056
Overall Steps per Second: 10,796.65766

Timestep Collection Time: 2.14470
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.63180

Cumulative Model Updates: 182,446
Cumulative Timesteps: 1,521,626,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.34671
Policy Entropy: 2.41311
Value Function Loss: 0.01499

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.59282
Value Function Update Magnitude: 0.62865

Collected Steps per Second: 23,467.83945
Overall Steps per Second: 10,815.61394

Timestep Collection Time: 2.13117
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.62424

Cumulative Model Updates: 182,452
Cumulative Timesteps: 1,521,676,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1521676460...
Checkpoint 1521676460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.42241
Policy Entropy: 2.43382
Value Function Loss: 0.01461

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.60013
Value Function Update Magnitude: 0.65975

Collected Steps per Second: 23,113.62600
Overall Steps per Second: 10,898.51576

Timestep Collection Time: 2.16340
Timestep Consumption Time: 2.42475
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.58815

Cumulative Model Updates: 182,458
Cumulative Timesteps: 1,521,726,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.60250
Policy Entropy: 2.45182
Value Function Loss: 0.01506

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.59255
Value Function Update Magnitude: 0.64459

Collected Steps per Second: 23,581.16561
Overall Steps per Second: 10,963.07949

Timestep Collection Time: 2.12135
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.56295

Cumulative Model Updates: 182,464
Cumulative Timesteps: 1,521,776,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1521776488...
Checkpoint 1521776488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.05761
Policy Entropy: 2.44288
Value Function Loss: 0.01462

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.58869
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 22,725.34938
Overall Steps per Second: 10,650.04146

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69745

Cumulative Model Updates: 182,470
Cumulative Timesteps: 1,521,826,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.61287
Policy Entropy: 2.41626
Value Function Loss: 0.01517

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.59312
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 22,554.49979
Overall Steps per Second: 10,656.45856

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69368

Cumulative Model Updates: 182,476
Cumulative Timesteps: 1,521,876,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1521876534...
Checkpoint 1521876534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.56521
Policy Entropy: 2.41099
Value Function Loss: 0.01484

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.58858

Collected Steps per Second: 22,820.55319
Overall Steps per Second: 10,900.91785

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.39586
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.58695

Cumulative Model Updates: 182,482
Cumulative Timesteps: 1,521,926,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.65668
Policy Entropy: 2.40635
Value Function Loss: 0.01532

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.58415
Value Function Update Magnitude: 0.56609

Collected Steps per Second: 23,012.10972
Overall Steps per Second: 10,849.40289

Timestep Collection Time: 2.17390
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61094

Cumulative Model Updates: 182,488
Cumulative Timesteps: 1,521,976,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1521976562...
Checkpoint 1521976562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.60529
Policy Entropy: 2.41826
Value Function Loss: 0.01565

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.57797
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 22,574.15123
Overall Steps per Second: 10,700.91347

Timestep Collection Time: 2.21492
Timestep Consumption Time: 2.45758
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67250

Cumulative Model Updates: 182,494
Cumulative Timesteps: 1,522,026,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.44414
Policy Entropy: 2.40176
Value Function Loss: 0.01575

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 22,744.64893
Overall Steps per Second: 10,658.46091

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69186

Cumulative Model Updates: 182,500
Cumulative Timesteps: 1,522,076,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1522076570...
Checkpoint 1522076570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.14436
Policy Entropy: 2.42318
Value Function Loss: 0.01622

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.58449
Value Function Update Magnitude: 0.60757

Collected Steps per Second: 23,019.42745
Overall Steps per Second: 10,831.25543

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61682

Cumulative Model Updates: 182,506
Cumulative Timesteps: 1,522,126,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.48215
Policy Entropy: 2.42972
Value Function Loss: 0.01580

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.59059
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 23,229.58890
Overall Steps per Second: 11,003.36358

Timestep Collection Time: 2.15372
Timestep Consumption Time: 2.39307
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.54679

Cumulative Model Updates: 182,512
Cumulative Timesteps: 1,522,176,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1522176606...
Checkpoint 1522176606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.75423
Policy Entropy: 2.42227
Value Function Loss: 0.01580

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.59215
Value Function Update Magnitude: 0.60821

Collected Steps per Second: 22,504.81801
Overall Steps per Second: 10,802.29023

Timestep Collection Time: 2.22255
Timestep Consumption Time: 2.40777
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.63031

Cumulative Model Updates: 182,518
Cumulative Timesteps: 1,522,226,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.23006
Policy Entropy: 2.42985
Value Function Loss: 0.01514

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.59485
Value Function Update Magnitude: 0.59207

Collected Steps per Second: 23,691.73170
Overall Steps per Second: 10,860.08406

Timestep Collection Time: 2.11179
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.60696

Cumulative Model Updates: 182,524
Cumulative Timesteps: 1,522,276,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1522276656...
Checkpoint 1522276656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.36540
Policy Entropy: 2.42782
Value Function Loss: 0.01552

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.59194
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 23,281.90195
Overall Steps per Second: 10,921.38372

Timestep Collection Time: 2.14836
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.57982

Cumulative Model Updates: 182,530
Cumulative Timesteps: 1,522,326,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.44642
Policy Entropy: 2.43920
Value Function Loss: 0.01523

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.62903

Collected Steps per Second: 22,934.99396
Overall Steps per Second: 10,916.57628

Timestep Collection Time: 2.18016
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.58037

Cumulative Model Updates: 182,536
Cumulative Timesteps: 1,522,376,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1522376676...
Checkpoint 1522376676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.10405
Policy Entropy: 2.40989
Value Function Loss: 0.01685

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,551.36130
Overall Steps per Second: 10,789.69857

Timestep Collection Time: 2.21752
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.63479

Cumulative Model Updates: 182,542
Cumulative Timesteps: 1,522,426,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.90354
Policy Entropy: 2.41552
Value Function Loss: 0.01677

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 22,492.64256
Overall Steps per Second: 10,825.14646

Timestep Collection Time: 2.22384
Timestep Consumption Time: 2.39688
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.62072

Cumulative Model Updates: 182,548
Cumulative Timesteps: 1,522,476,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1522476704...
Checkpoint 1522476704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.92941
Policy Entropy: 2.39842
Value Function Loss: 0.01586

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.58261
Value Function Update Magnitude: 0.64388

Collected Steps per Second: 22,421.69760
Overall Steps per Second: 10,638.03080

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.70031

Cumulative Model Updates: 182,554
Cumulative Timesteps: 1,522,526,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.48903
Policy Entropy: 2.40014
Value Function Loss: 0.01420

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.55810
Value Function Update Magnitude: 0.60417

Collected Steps per Second: 23,017.27644
Overall Steps per Second: 10,833.05331

Timestep Collection Time: 2.17263
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.61624

Cumulative Model Updates: 182,560
Cumulative Timesteps: 1,522,576,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1522576714...
Checkpoint 1522576714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.81225
Policy Entropy: 2.37935
Value Function Loss: 0.01539

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.18930
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.58399

Collected Steps per Second: 22,999.00390
Overall Steps per Second: 10,717.70115

Timestep Collection Time: 2.17488
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.66705

Cumulative Model Updates: 182,566
Cumulative Timesteps: 1,522,626,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.74158
Policy Entropy: 2.37314
Value Function Loss: 0.01573

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.17209
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.57677

Collected Steps per Second: 23,263.78225
Overall Steps per Second: 10,885.18751

Timestep Collection Time: 2.15038
Timestep Consumption Time: 2.44541
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.59579

Cumulative Model Updates: 182,572
Cumulative Timesteps: 1,522,676,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1522676760...
Checkpoint 1522676760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.29084
Policy Entropy: 2.38690
Value Function Loss: 0.01593

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16140
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 22,672.81219
Overall Steps per Second: 10,809.04386

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.62668

Cumulative Model Updates: 182,578
Cumulative Timesteps: 1,522,726,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.72799
Policy Entropy: 2.41045
Value Function Loss: 0.01538

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.57311
Value Function Update Magnitude: 0.56731

Collected Steps per Second: 23,731.02135
Overall Steps per Second: 10,888.13081

Timestep Collection Time: 2.10779
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.59399

Cumulative Model Updates: 182,584
Cumulative Timesteps: 1,522,776,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1522776790...
Checkpoint 1522776790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.92085
Policy Entropy: 2.42249
Value Function Loss: 0.01490

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.57630
Value Function Update Magnitude: 0.55730

Collected Steps per Second: 23,190.32663
Overall Steps per Second: 10,883.17250

Timestep Collection Time: 2.15607
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.59425

Cumulative Model Updates: 182,590
Cumulative Timesteps: 1,522,826,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.33310
Policy Entropy: 2.42885
Value Function Loss: 0.01481

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.56802

Collected Steps per Second: 22,968.96544
Overall Steps per Second: 10,904.98701

Timestep Collection Time: 2.17729
Timestep Consumption Time: 2.40869
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.58598

Cumulative Model Updates: 182,596
Cumulative Timesteps: 1,522,876,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1522876800...
Checkpoint 1522876800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.45699
Policy Entropy: 2.43283
Value Function Loss: 0.01540

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.57229

Collected Steps per Second: 22,715.21419
Overall Steps per Second: 10,810.47881

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.62718

Cumulative Model Updates: 182,602
Cumulative Timesteps: 1,522,926,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.72446
Policy Entropy: 2.41291
Value Function Loss: 0.01562

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 22,984.09069
Overall Steps per Second: 10,880.07285

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.59666

Cumulative Model Updates: 182,608
Cumulative Timesteps: 1,522,976,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1522976834...
Checkpoint 1522976834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.45687
Policy Entropy: 2.39300
Value Function Loss: 0.01609

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.58009

Collected Steps per Second: 22,658.88704
Overall Steps per Second: 10,588.84131

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.51652
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.72422

Cumulative Model Updates: 182,614
Cumulative Timesteps: 1,523,026,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.40100
Policy Entropy: 2.41453
Value Function Loss: 0.01519

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.57573

Collected Steps per Second: 23,004.78402
Overall Steps per Second: 10,823.49727

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.44749
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62217

Cumulative Model Updates: 182,620
Cumulative Timesteps: 1,523,076,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1523076886...
Checkpoint 1523076886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.35779
Policy Entropy: 2.43690
Value Function Loss: 0.01465

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.58769

Collected Steps per Second: 22,698.22893
Overall Steps per Second: 10,764.85350

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64567

Cumulative Model Updates: 182,626
Cumulative Timesteps: 1,523,126,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.66684
Policy Entropy: 2.47716
Value Function Loss: 0.01439

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.56683
Value Function Update Magnitude: 0.57843

Collected Steps per Second: 23,166.64518
Overall Steps per Second: 10,892.91000

Timestep Collection Time: 2.15888
Timestep Consumption Time: 2.43255
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.59143

Cumulative Model Updates: 182,632
Cumulative Timesteps: 1,523,176,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1523176910...
Checkpoint 1523176910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.69406
Policy Entropy: 2.45685
Value Function Loss: 0.01571

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.58170

Collected Steps per Second: 23,016.60413
Overall Steps per Second: 11,051.33330

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.35331
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.52687

Cumulative Model Updates: 182,638
Cumulative Timesteps: 1,523,226,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.77242
Policy Entropy: 2.45758
Value Function Loss: 0.01524

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 23,242.47808
Overall Steps per Second: 10,903.69030

Timestep Collection Time: 2.15244
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.58817

Cumulative Model Updates: 182,644
Cumulative Timesteps: 1,523,276,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1523276966...
Checkpoint 1523276966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.84441
Policy Entropy: 2.42833
Value Function Loss: 0.01455

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.60202

Collected Steps per Second: 22,972.66675
Overall Steps per Second: 10,655.61733

Timestep Collection Time: 2.17650
Timestep Consumption Time: 2.51586
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69236

Cumulative Model Updates: 182,650
Cumulative Timesteps: 1,523,326,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.75232
Policy Entropy: 2.44330
Value Function Loss: 0.01362

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.56185
Value Function Update Magnitude: 0.56983

Collected Steps per Second: 22,483.64401
Overall Steps per Second: 10,550.84697

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.51643
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74142

Cumulative Model Updates: 182,656
Cumulative Timesteps: 1,523,376,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1523376992...
Checkpoint 1523376992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.70954
Policy Entropy: 2.42311
Value Function Loss: 0.01367

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.55481

Collected Steps per Second: 22,615.57885
Overall Steps per Second: 10,715.62305

Timestep Collection Time: 2.21095
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.66627

Cumulative Model Updates: 182,662
Cumulative Timesteps: 1,523,426,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.68094
Policy Entropy: 2.42580
Value Function Loss: 0.01373

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.56849
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 22,825.25046
Overall Steps per Second: 10,822.74573

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.62101

Cumulative Model Updates: 182,668
Cumulative Timesteps: 1,523,477,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1523477006...
Checkpoint 1523477006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.79167
Policy Entropy: 2.43498
Value Function Loss: 0.01347

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.59128

Collected Steps per Second: 23,107.25906
Overall Steps per Second: 10,632.15185

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.53910
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.70309

Cumulative Model Updates: 182,674
Cumulative Timesteps: 1,523,527,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.19886
Policy Entropy: 2.43226
Value Function Loss: 0.01462

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.57098
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 23,481.53940
Overall Steps per Second: 10,832.24751

Timestep Collection Time: 2.12993
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.61714

Cumulative Model Updates: 182,680
Cumulative Timesteps: 1,523,577,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1523577024...
Checkpoint 1523577024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.79841
Policy Entropy: 2.44933
Value Function Loss: 0.01564

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.58102

Collected Steps per Second: 22,973.20629
Overall Steps per Second: 10,700.17156

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.67320

Cumulative Model Updates: 182,686
Cumulative Timesteps: 1,523,627,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.15062
Policy Entropy: 2.43730
Value Function Loss: 0.01615

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.57319
Value Function Update Magnitude: 0.59564

Collected Steps per Second: 22,802.81344
Overall Steps per Second: 10,833.13113

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61584

Cumulative Model Updates: 182,692
Cumulative Timesteps: 1,523,677,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1523677032...
Checkpoint 1523677032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.48424
Policy Entropy: 2.43264
Value Function Loss: 0.01506

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 22,695.71160
Overall Steps per Second: 10,869.77665

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.39743
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.60101

Cumulative Model Updates: 182,698
Cumulative Timesteps: 1,523,727,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.86968
Policy Entropy: 2.42532
Value Function Loss: 0.01408

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.17939
Policy Update Magnitude: 0.52305
Value Function Update Magnitude: 0.57946

Collected Steps per Second: 23,275.23800
Overall Steps per Second: 10,753.05757

Timestep Collection Time: 2.14898
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.65151

Cumulative Model Updates: 182,704
Cumulative Timesteps: 1,523,777,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1523777062...
Checkpoint 1523777062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.40285
Policy Entropy: 2.43172
Value Function Loss: 0.01414

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.60088

Collected Steps per Second: 22,393.40582
Overall Steps per Second: 10,630.11548

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.70588

Cumulative Model Updates: 182,710
Cumulative Timesteps: 1,523,827,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.01309
Policy Entropy: 2.44388
Value Function Loss: 0.01563

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.57585
Value Function Update Magnitude: 0.60906

Collected Steps per Second: 21,940.12597
Overall Steps per Second: 10,417.13388

Timestep Collection Time: 2.27911
Timestep Consumption Time: 2.52106
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.80017

Cumulative Model Updates: 182,716
Cumulative Timesteps: 1,523,877,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1523877090...
Checkpoint 1523877090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.56029
Policy Entropy: 2.45182
Value Function Loss: 0.01641

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,234.75168
Overall Steps per Second: 10,639.10092

Timestep Collection Time: 2.24963
Timestep Consumption Time: 2.45189
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.70153

Cumulative Model Updates: 182,722
Cumulative Timesteps: 1,523,927,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.49748
Policy Entropy: 2.44664
Value Function Loss: 0.01504

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 22,952.65258
Overall Steps per Second: 10,960.72528

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.38373
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.56247

Cumulative Model Updates: 182,728
Cumulative Timesteps: 1,523,977,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1523977118...
Checkpoint 1523977118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.88797
Policy Entropy: 2.43451
Value Function Loss: 0.01375

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.60996

Collected Steps per Second: 23,025.37504
Overall Steps per Second: 10,711.93700

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.67049

Cumulative Model Updates: 182,734
Cumulative Timesteps: 1,524,027,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.69429
Policy Entropy: 2.42276
Value Function Loss: 0.01348

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.60211

Collected Steps per Second: 23,386.07058
Overall Steps per Second: 10,783.12859

Timestep Collection Time: 2.13905
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.63910

Cumulative Model Updates: 182,740
Cumulative Timesteps: 1,524,077,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1524077172...
Checkpoint 1524077172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.80553
Policy Entropy: 2.41390
Value Function Loss: 0.01402

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.59259

Collected Steps per Second: 22,957.04234
Overall Steps per Second: 10,641.91961

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.52193
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.70122

Cumulative Model Updates: 182,746
Cumulative Timesteps: 1,524,127,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.52287
Policy Entropy: 2.42014
Value Function Loss: 0.01503

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 23,286.97702
Overall Steps per Second: 11,011.54243

Timestep Collection Time: 2.14729
Timestep Consumption Time: 2.39376
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.54105

Cumulative Model Updates: 182,752
Cumulative Timesteps: 1,524,177,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1524177206...
Checkpoint 1524177206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.25918
Policy Entropy: 2.41680
Value Function Loss: 0.01485

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.59271
Value Function Update Magnitude: 0.61147

Collected Steps per Second: 23,056.50920
Overall Steps per Second: 10,940.19512

Timestep Collection Time: 2.16858
Timestep Consumption Time: 2.40172
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.57030

Cumulative Model Updates: 182,758
Cumulative Timesteps: 1,524,227,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.31422
Policy Entropy: 2.41776
Value Function Loss: 0.01494

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.59149
Value Function Update Magnitude: 0.62016

Collected Steps per Second: 23,239.69378
Overall Steps per Second: 11,012.26835

Timestep Collection Time: 2.15244
Timestep Consumption Time: 2.38995
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.54239

Cumulative Model Updates: 182,764
Cumulative Timesteps: 1,524,277,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1524277228...
Checkpoint 1524277228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.18265
Policy Entropy: 2.42670
Value Function Loss: 0.01451

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.61303

Collected Steps per Second: 22,824.30337
Overall Steps per Second: 10,642.05528

Timestep Collection Time: 2.19179
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70078

Cumulative Model Updates: 182,770
Cumulative Timesteps: 1,524,327,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.15328
Policy Entropy: 2.43467
Value Function Loss: 0.01571

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.60718

Collected Steps per Second: 23,129.59744
Overall Steps per Second: 10,873.53902

Timestep Collection Time: 2.16199
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.59887

Cumulative Model Updates: 182,776
Cumulative Timesteps: 1,524,377,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1524377260...
Checkpoint 1524377260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.04324
Policy Entropy: 2.43161
Value Function Loss: 0.01602

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.58758
Value Function Update Magnitude: 0.64306

Collected Steps per Second: 22,536.04002
Overall Steps per Second: 10,698.85721

Timestep Collection Time: 2.21885
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.67377

Cumulative Model Updates: 182,782
Cumulative Timesteps: 1,524,427,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.98285
Policy Entropy: 2.42636
Value Function Loss: 0.01622

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.59730
Value Function Update Magnitude: 0.67060

Collected Steps per Second: 22,640.49313
Overall Steps per Second: 10,800.66350

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.42101
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62953

Cumulative Model Updates: 182,788
Cumulative Timesteps: 1,524,477,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1524477266...
Checkpoint 1524477266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.90162
Policy Entropy: 2.43660
Value Function Loss: 0.01499

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.59513
Value Function Update Magnitude: 0.65319

Collected Steps per Second: 22,385.14975
Overall Steps per Second: 10,740.63328

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.65541

Cumulative Model Updates: 182,794
Cumulative Timesteps: 1,524,527,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.89058
Policy Entropy: 2.46292
Value Function Loss: 0.01496

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.64158

Collected Steps per Second: 23,307.80325
Overall Steps per Second: 10,886.18845

Timestep Collection Time: 2.14615
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.59500

Cumulative Model Updates: 182,800
Cumulative Timesteps: 1,524,577,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1524577290...
Checkpoint 1524577290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.53376
Policy Entropy: 2.44338
Value Function Loss: 0.01455

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.62956

Collected Steps per Second: 23,142.73427
Overall Steps per Second: 10,743.77325

Timestep Collection Time: 2.16137
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65572

Cumulative Model Updates: 182,806
Cumulative Timesteps: 1,524,627,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.18831
Policy Entropy: 2.41914
Value Function Loss: 0.01518

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.59263
Value Function Update Magnitude: 0.62932

Collected Steps per Second: 23,492.15971
Overall Steps per Second: 10,804.59887

Timestep Collection Time: 2.12871
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.62840

Cumulative Model Updates: 182,812
Cumulative Timesteps: 1,524,677,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1524677318...
Checkpoint 1524677318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.98957
Policy Entropy: 2.40042
Value Function Loss: 0.01599

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.59564
Value Function Update Magnitude: 0.62174

Collected Steps per Second: 22,894.91241
Overall Steps per Second: 10,616.74551

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.52656
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.71124

Cumulative Model Updates: 182,818
Cumulative Timesteps: 1,524,727,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.06737
Policy Entropy: 2.39984
Value Function Loss: 0.01600

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.59574

Collected Steps per Second: 23,245.51570
Overall Steps per Second: 10,978.36827

Timestep Collection Time: 2.15164
Timestep Consumption Time: 2.40423
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.55587

Cumulative Model Updates: 182,824
Cumulative Timesteps: 1,524,777,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1524777352...
Checkpoint 1524777352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.42867
Policy Entropy: 2.40665
Value Function Loss: 0.01520

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.58237
Value Function Update Magnitude: 0.56955

Collected Steps per Second: 23,037.30658
Overall Steps per Second: 11,038.48137

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.36035
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.53178

Cumulative Model Updates: 182,830
Cumulative Timesteps: 1,524,827,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.03394
Policy Entropy: 2.40992
Value Function Loss: 0.01333

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.56630
Value Function Update Magnitude: 0.55604

Collected Steps per Second: 22,999.52877
Overall Steps per Second: 10,850.21526

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61078

Cumulative Model Updates: 182,836
Cumulative Timesteps: 1,524,877,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1524877404...
Checkpoint 1524877404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.35768
Policy Entropy: 2.41646
Value Function Loss: 0.01338

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 22,689.49101
Overall Steps per Second: 10,780.21964

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.63868

Cumulative Model Updates: 182,842
Cumulative Timesteps: 1,524,927,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.58757
Policy Entropy: 2.40746
Value Function Loss: 0.01493

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.57781

Collected Steps per Second: 23,045.53650
Overall Steps per Second: 10,840.09712

Timestep Collection Time: 2.16979
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61287

Cumulative Model Updates: 182,848
Cumulative Timesteps: 1,524,977,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1524977414...
Checkpoint 1524977414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.00844
Policy Entropy: 2.40507
Value Function Loss: 0.01521

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.56532
Value Function Update Magnitude: 0.58097

Collected Steps per Second: 22,549.28345
Overall Steps per Second: 10,648.66012

Timestep Collection Time: 2.21834
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.69749

Cumulative Model Updates: 182,854
Cumulative Timesteps: 1,525,027,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.00925
Policy Entropy: 2.40842
Value Function Loss: 0.01569

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.58923

Collected Steps per Second: 22,742.58232
Overall Steps per Second: 10,803.94755

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.63053

Cumulative Model Updates: 182,860
Cumulative Timesteps: 1,525,077,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1525077464...
Checkpoint 1525077464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.32093
Policy Entropy: 2.40068
Value Function Loss: 0.01576

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.59603

Collected Steps per Second: 22,604.15505
Overall Steps per Second: 10,729.43280

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.66101

Cumulative Model Updates: 182,866
Cumulative Timesteps: 1,525,127,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.64995
Policy Entropy: 2.39641
Value Function Loss: 0.01558

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.58518
Value Function Update Magnitude: 0.58956

Collected Steps per Second: 23,361.65827
Overall Steps per Second: 10,960.00761

Timestep Collection Time: 2.14086
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.56332

Cumulative Model Updates: 182,872
Cumulative Timesteps: 1,525,177,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1525177488...
Checkpoint 1525177488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.07553
Policy Entropy: 2.39538
Value Function Loss: 0.01511

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.57878
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 23,199.06903
Overall Steps per Second: 10,803.13393

Timestep Collection Time: 2.15526
Timestep Consumption Time: 2.47303
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.62829

Cumulative Model Updates: 182,878
Cumulative Timesteps: 1,525,227,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.08443
Policy Entropy: 2.41553
Value Function Loss: 0.01452

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.59039

Collected Steps per Second: 23,298.01282
Overall Steps per Second: 10,858.18018

Timestep Collection Time: 2.14731
Timestep Consumption Time: 2.46009
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.60740

Cumulative Model Updates: 182,884
Cumulative Timesteps: 1,525,277,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1525277516...
Checkpoint 1525277516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.61098
Policy Entropy: 2.41628
Value Function Loss: 0.01524

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.58031

Collected Steps per Second: 22,414.74832
Overall Steps per Second: 10,606.28278

Timestep Collection Time: 2.23112
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.71513

Cumulative Model Updates: 182,890
Cumulative Timesteps: 1,525,327,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.49170
Policy Entropy: 2.43913
Value Function Loss: 0.01637

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,952.01766
Overall Steps per Second: 10,842.01160

Timestep Collection Time: 2.17933
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.61354

Cumulative Model Updates: 182,896
Cumulative Timesteps: 1,525,377,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1525377546...
Checkpoint 1525377546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.20921
Policy Entropy: 2.47472
Value Function Loss: 0.01576

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 22,543.30409
Overall Steps per Second: 10,599.07178

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.71853

Cumulative Model Updates: 182,902
Cumulative Timesteps: 1,525,427,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.83595
Policy Entropy: 2.47742
Value Function Loss: 0.01632

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 23,206.78385
Overall Steps per Second: 10,811.06905

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62600

Cumulative Model Updates: 182,908
Cumulative Timesteps: 1,525,477,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1525477570...
Checkpoint 1525477570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.73645
Policy Entropy: 2.46693
Value Function Loss: 0.01471

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.64706

Collected Steps per Second: 22,707.99285
Overall Steps per Second: 10,759.89968

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.64818

Cumulative Model Updates: 182,914
Cumulative Timesteps: 1,525,527,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.39830
Policy Entropy: 2.44159
Value Function Loss: 0.01483

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.65048

Collected Steps per Second: 23,249.74920
Overall Steps per Second: 10,892.98279

Timestep Collection Time: 2.15082
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59066

Cumulative Model Updates: 182,920
Cumulative Timesteps: 1,525,577,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1525577590...
Checkpoint 1525577590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.87814
Policy Entropy: 2.43397
Value Function Loss: 0.01397

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.61693

Collected Steps per Second: 23,059.61262
Overall Steps per Second: 11,036.69146

Timestep Collection Time: 2.16899
Timestep Consumption Time: 2.36281
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.53179

Cumulative Model Updates: 182,926
Cumulative Timesteps: 1,525,627,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.03006
Policy Entropy: 2.43812
Value Function Loss: 0.01464

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.57205
Value Function Update Magnitude: 0.59123

Collected Steps per Second: 23,584.43738
Overall Steps per Second: 11,004.51012

Timestep Collection Time: 2.12038
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.54432

Cumulative Model Updates: 182,932
Cumulative Timesteps: 1,525,677,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1525677614...
Checkpoint 1525677614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.68711
Policy Entropy: 2.44758
Value Function Loss: 0.01411

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 22,963.87257
Overall Steps per Second: 10,727.44945

Timestep Collection Time: 2.17742
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.66113

Cumulative Model Updates: 182,938
Cumulative Timesteps: 1,525,727,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.94252
Policy Entropy: 2.43912
Value Function Loss: 0.01500

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.56737
Value Function Update Magnitude: 0.56873

Collected Steps per Second: 22,418.35405
Overall Steps per Second: 10,722.33388

Timestep Collection Time: 2.23040
Timestep Consumption Time: 2.43295
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.66335

Cumulative Model Updates: 182,944
Cumulative Timesteps: 1,525,777,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1525777618...
Checkpoint 1525777618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.56859
Policy Entropy: 2.44199
Value Function Loss: 0.01528

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.57660

Collected Steps per Second: 21,222.75878
Overall Steps per Second: 10,373.89017

Timestep Collection Time: 2.35700
Timestep Consumption Time: 2.46492
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.82191

Cumulative Model Updates: 182,950
Cumulative Timesteps: 1,525,827,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.45280
Policy Entropy: 2.45484
Value Function Loss: 0.01516

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.58139

Collected Steps per Second: 22,896.33357
Overall Steps per Second: 10,779.89584

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.45598
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.64105

Cumulative Model Updates: 182,956
Cumulative Timesteps: 1,525,877,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1525877670...
Checkpoint 1525877670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.48741
Policy Entropy: 2.46483
Value Function Loss: 0.01555

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 22,314.16489
Overall Steps per Second: 10,705.60921

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.67325

Cumulative Model Updates: 182,962
Cumulative Timesteps: 1,525,927,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.93340
Policy Entropy: 2.44728
Value Function Loss: 0.01515

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.58184
Value Function Update Magnitude: 0.62826

Collected Steps per Second: 23,477.36552
Overall Steps per Second: 10,808.92790

Timestep Collection Time: 2.13005
Timestep Consumption Time: 2.49649
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.62655

Cumulative Model Updates: 182,968
Cumulative Timesteps: 1,525,977,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1525977708...
Checkpoint 1525977708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.96508
Policy Entropy: 2.43215
Value Function Loss: 0.01575

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.63615

Collected Steps per Second: 22,561.20703
Overall Steps per Second: 10,653.17778

Timestep Collection Time: 2.21752
Timestep Consumption Time: 2.47873
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.69625

Cumulative Model Updates: 182,974
Cumulative Timesteps: 1,526,027,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.63429
Policy Entropy: 2.41870
Value Function Loss: 0.01477

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.58177
Value Function Update Magnitude: 0.62968

Collected Steps per Second: 23,417.61177
Overall Steps per Second: 10,942.95333

Timestep Collection Time: 2.13600
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.57098

Cumulative Model Updates: 182,980
Cumulative Timesteps: 1,526,077,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1526077758...
Checkpoint 1526077758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.55558
Policy Entropy: 2.44093
Value Function Loss: 0.01437

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.61436

Collected Steps per Second: 22,742.93246
Overall Steps per Second: 10,681.39691

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.68160

Cumulative Model Updates: 182,986
Cumulative Timesteps: 1,526,127,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.83382
Policy Entropy: 2.43912
Value Function Loss: 0.01419

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.58104

Collected Steps per Second: 23,563.86329
Overall Steps per Second: 11,062.81043

Timestep Collection Time: 2.12240
Timestep Consumption Time: 2.39833
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.52073

Cumulative Model Updates: 182,992
Cumulative Timesteps: 1,526,177,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1526177776...
Checkpoint 1526177776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.90325
Policy Entropy: 2.42583
Value Function Loss: 0.01511

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.57401
Value Function Update Magnitude: 0.57015

Collected Steps per Second: 23,498.30043
Overall Steps per Second: 10,912.67313

Timestep Collection Time: 2.12875
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.58384

Cumulative Model Updates: 182,998
Cumulative Timesteps: 1,526,227,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.14398
Policy Entropy: 2.43993
Value Function Loss: 0.01481

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.57000

Collected Steps per Second: 22,981.92683
Overall Steps per Second: 10,839.85850

Timestep Collection Time: 2.17693
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61537

Cumulative Model Updates: 183,004
Cumulative Timesteps: 1,526,277,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1526277828...
Checkpoint 1526277828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.86835
Policy Entropy: 2.46250
Value Function Loss: 0.01490

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 22,543.05305
Overall Steps per Second: 10,702.48935

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.67387

Cumulative Model Updates: 183,010
Cumulative Timesteps: 1,526,327,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.13022
Policy Entropy: 2.46488
Value Function Loss: 0.01470

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.56517

Collected Steps per Second: 22,654.00919
Overall Steps per Second: 10,864.20013

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.39544
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.60282

Cumulative Model Updates: 183,016
Cumulative Timesteps: 1,526,377,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1526377856...
Checkpoint 1526377856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.93320
Policy Entropy: 2.45558
Value Function Loss: 0.01440

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.57103

Collected Steps per Second: 21,005.95737
Overall Steps per Second: 10,268.63553

Timestep Collection Time: 2.38085
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.87036

Cumulative Model Updates: 183,022
Cumulative Timesteps: 1,526,427,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.93569
Policy Entropy: 2.43948
Value Function Loss: 0.01505

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.56956
Value Function Update Magnitude: 0.57095

Collected Steps per Second: 23,276.16299
Overall Steps per Second: 10,851.74199

Timestep Collection Time: 2.14889
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.60921

Cumulative Model Updates: 183,028
Cumulative Timesteps: 1,526,477,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1526477886...
Checkpoint 1526477886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.55206
Policy Entropy: 2.42999
Value Function Loss: 0.01558

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.57712
Value Function Update Magnitude: 0.59004

Collected Steps per Second: 23,218.00727
Overall Steps per Second: 10,742.76117

Timestep Collection Time: 2.15410
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.65560

Cumulative Model Updates: 183,034
Cumulative Timesteps: 1,526,527,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.71363
Policy Entropy: 2.43046
Value Function Loss: 0.01640

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.58798

Collected Steps per Second: 23,319.42530
Overall Steps per Second: 10,842.50867

Timestep Collection Time: 2.14456
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.61240

Cumulative Model Updates: 183,040
Cumulative Timesteps: 1,526,577,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1526577910...
Checkpoint 1526577910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.91560
Policy Entropy: 2.40081
Value Function Loss: 0.01601

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 23,008.67368
Overall Steps per Second: 10,650.90887

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.69575

Cumulative Model Updates: 183,046
Cumulative Timesteps: 1,526,627,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.26109
Policy Entropy: 2.40900
Value Function Loss: 0.01585

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.61615

Collected Steps per Second: 23,388.33145
Overall Steps per Second: 10,881.01859

Timestep Collection Time: 2.13867
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.59700

Cumulative Model Updates: 183,052
Cumulative Timesteps: 1,526,677,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1526677944...
Checkpoint 1526677944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.45535
Policy Entropy: 2.39154
Value Function Loss: 0.01581

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.57614
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,856.11317
Overall Steps per Second: 10,997.68111

Timestep Collection Time: 2.18874
Timestep Consumption Time: 2.36004
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.54878

Cumulative Model Updates: 183,058
Cumulative Timesteps: 1,526,727,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.82594
Policy Entropy: 2.39860
Value Function Loss: 0.01619

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 22,544.05425
Overall Steps per Second: 10,586.09038

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.72582

Cumulative Model Updates: 183,064
Cumulative Timesteps: 1,526,777,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1526777998...
Checkpoint 1526777998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.87841
Policy Entropy: 2.39955
Value Function Loss: 0.01591

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.59092
Value Function Update Magnitude: 0.63136

Collected Steps per Second: 22,612.01614
Overall Steps per Second: 10,604.94681

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.71554

Cumulative Model Updates: 183,070
Cumulative Timesteps: 1,526,828,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.01246
Policy Entropy: 2.40221
Value Function Loss: 0.01620

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.59164
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 21,946.64445
Overall Steps per Second: 10,478.57122

Timestep Collection Time: 2.27853
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.77222

Cumulative Model Updates: 183,076
Cumulative Timesteps: 1,526,878,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1526878012...
Checkpoint 1526878012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.88716
Policy Entropy: 2.41007
Value Function Loss: 0.01609

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.59556
Value Function Update Magnitude: 0.61232

Collected Steps per Second: 22,395.69768
Overall Steps per Second: 10,647.74793

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.69827

Cumulative Model Updates: 183,082
Cumulative Timesteps: 1,526,928,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.15538
Policy Entropy: 2.44385
Value Function Loss: 0.01478

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.61338

Collected Steps per Second: 23,198.81813
Overall Steps per Second: 10,917.46665

Timestep Collection Time: 2.15597
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.58128

Cumulative Model Updates: 183,088
Cumulative Timesteps: 1,526,978,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1526978054...
Checkpoint 1526978054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.94549
Policy Entropy: 2.45280
Value Function Loss: 0.01421

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.60111

Collected Steps per Second: 23,120.04435
Overall Steps per Second: 10,779.97316

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.64157

Cumulative Model Updates: 183,094
Cumulative Timesteps: 1,527,028,090

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.52674
Policy Entropy: 2.42127
Value Function Loss: 0.01452

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.57346
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 23,172.93254
Overall Steps per Second: 10,759.61524

Timestep Collection Time: 2.15778
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.64719

Cumulative Model Updates: 183,100
Cumulative Timesteps: 1,527,078,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1527078092...
Checkpoint 1527078092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.97010
Policy Entropy: 2.40623
Value Function Loss: 0.01641

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.58340

Collected Steps per Second: 23,259.87529
Overall Steps per Second: 10,735.80987

Timestep Collection Time: 2.15074
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.65973

Cumulative Model Updates: 183,106
Cumulative Timesteps: 1,527,128,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.13010
Policy Entropy: 2.40797
Value Function Loss: 0.01587

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.59468

Collected Steps per Second: 23,338.56583
Overall Steps per Second: 10,828.96477

Timestep Collection Time: 2.14263
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.61780

Cumulative Model Updates: 183,112
Cumulative Timesteps: 1,527,178,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1527178124...
Checkpoint 1527178124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.79645
Policy Entropy: 2.42118
Value Function Loss: 0.01524

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.57816
Value Function Update Magnitude: 0.57954

Collected Steps per Second: 23,039.32031
Overall Steps per Second: 11,087.66682

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.34034
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.51150

Cumulative Model Updates: 183,118
Cumulative Timesteps: 1,527,228,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.56425
Policy Entropy: 2.41762
Value Function Loss: 0.01544

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.57782
Value Function Update Magnitude: 0.57097

Collected Steps per Second: 23,129.68089
Overall Steps per Second: 10,870.51320

Timestep Collection Time: 2.16198
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60015

Cumulative Model Updates: 183,124
Cumulative Timesteps: 1,527,278,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1527278152...
Checkpoint 1527278152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.48493
Policy Entropy: 2.40422
Value Function Loss: 0.01581

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.57527

Collected Steps per Second: 22,436.32394
Overall Steps per Second: 10,728.03850

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.66311

Cumulative Model Updates: 183,130
Cumulative Timesteps: 1,527,328,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.09996
Policy Entropy: 2.41717
Value Function Loss: 0.01620

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.59214

Collected Steps per Second: 22,772.30036
Overall Steps per Second: 10,767.81715

Timestep Collection Time: 2.19618
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.64458

Cumulative Model Updates: 183,136
Cumulative Timesteps: 1,527,378,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1527378190...
Checkpoint 1527378190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.30332
Policy Entropy: 2.42153
Value Function Loss: 0.01512

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.60434

Collected Steps per Second: 22,113.74371
Overall Steps per Second: 10,688.87334

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.68169

Cumulative Model Updates: 183,142
Cumulative Timesteps: 1,527,428,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.70582
Policy Entropy: 2.43401
Value Function Loss: 0.01439

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.60184

Collected Steps per Second: 22,514.70619
Overall Steps per Second: 10,891.38538

Timestep Collection Time: 2.22104
Timestep Consumption Time: 2.37030
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59134

Cumulative Model Updates: 183,148
Cumulative Timesteps: 1,527,478,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1527478238...
Checkpoint 1527478238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.69805
Policy Entropy: 2.42802
Value Function Loss: 0.01432

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 22,347.09258
Overall Steps per Second: 10,735.47260

Timestep Collection Time: 2.23814
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65895

Cumulative Model Updates: 183,154
Cumulative Timesteps: 1,527,528,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.51822
Policy Entropy: 2.42194
Value Function Loss: 0.01503

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.58259
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 23,299.51069
Overall Steps per Second: 10,956.46597

Timestep Collection Time: 2.14683
Timestep Consumption Time: 2.41851
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56534

Cumulative Model Updates: 183,160
Cumulative Timesteps: 1,527,578,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1527578274...
Checkpoint 1527578274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.88970
Policy Entropy: 2.42543
Value Function Loss: 0.01376

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 23,119.51266
Overall Steps per Second: 10,770.65529

Timestep Collection Time: 2.16337
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.64373

Cumulative Model Updates: 183,166
Cumulative Timesteps: 1,527,628,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.58127
Policy Entropy: 2.43408
Value Function Loss: 0.01487

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.58561

Collected Steps per Second: 23,290.81128
Overall Steps per Second: 10,806.59482

Timestep Collection Time: 2.14694
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.62717

Cumulative Model Updates: 183,172
Cumulative Timesteps: 1,527,678,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1527678294...
Checkpoint 1527678294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.79977
Policy Entropy: 2.45442
Value Function Loss: 0.01488

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.56554

Collected Steps per Second: 22,424.00228
Overall Steps per Second: 10,545.69914

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.74336

Cumulative Model Updates: 183,178
Cumulative Timesteps: 1,527,728,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.98321
Policy Entropy: 2.45138
Value Function Loss: 0.01576

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.56910

Collected Steps per Second: 22,963.05190
Overall Steps per Second: 10,984.70940

Timestep Collection Time: 2.17793
Timestep Consumption Time: 2.37494
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.55287

Cumulative Model Updates: 183,184
Cumulative Timesteps: 1,527,778,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1527778328...
Checkpoint 1527778328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.19672
Policy Entropy: 2.44046
Value Function Loss: 0.01607

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.58349

Collected Steps per Second: 22,618.47699
Overall Steps per Second: 10,615.17339

Timestep Collection Time: 2.21102
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71118

Cumulative Model Updates: 183,190
Cumulative Timesteps: 1,527,828,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.27452
Policy Entropy: 2.42818
Value Function Loss: 0.01468

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.57877
Value Function Update Magnitude: 0.60494

Collected Steps per Second: 22,738.11784
Overall Steps per Second: 10,641.74710

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.69979

Cumulative Model Updates: 183,196
Cumulative Timesteps: 1,527,878,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1527878352...
Checkpoint 1527878352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.49299
Policy Entropy: 2.44000
Value Function Loss: 0.01405

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.56245
Value Function Update Magnitude: 0.59881

Collected Steps per Second: 22,913.18153
Overall Steps per Second: 10,655.27786

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.69439

Cumulative Model Updates: 183,202
Cumulative Timesteps: 1,527,928,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.29383
Policy Entropy: 2.43930
Value Function Loss: 0.01278

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.55116

Collected Steps per Second: 23,537.54765
Overall Steps per Second: 10,862.21579

Timestep Collection Time: 2.12537
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.60551

Cumulative Model Updates: 183,208
Cumulative Timesteps: 1,527,978,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1527978398...
Checkpoint 1527978398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.25125
Policy Entropy: 2.42301
Value Function Loss: 0.01405

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.53829

Collected Steps per Second: 23,097.95181
Overall Steps per Second: 10,900.27437

Timestep Collection Time: 2.16469
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.58704

Cumulative Model Updates: 183,214
Cumulative Timesteps: 1,528,028,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.29420
Policy Entropy: 2.43665
Value Function Loss: 0.01450

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.56838
Value Function Update Magnitude: 0.56013

Collected Steps per Second: 23,214.80102
Overall Steps per Second: 10,948.36495

Timestep Collection Time: 2.15406
Timestep Consumption Time: 2.41338
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.56744

Cumulative Model Updates: 183,220
Cumulative Timesteps: 1,528,078,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1528078404...
Checkpoint 1528078404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.93743
Policy Entropy: 2.42582
Value Function Loss: 0.01471

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.57059

Collected Steps per Second: 23,056.77085
Overall Steps per Second: 10,737.90444

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.65864

Cumulative Model Updates: 183,226
Cumulative Timesteps: 1,528,128,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.47964
Policy Entropy: 2.43233
Value Function Loss: 0.01490

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 23,488.22596
Overall Steps per Second: 10,822.73955

Timestep Collection Time: 2.13009
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.62286

Cumulative Model Updates: 183,232
Cumulative Timesteps: 1,528,178,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1528178460...
Checkpoint 1528178460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.07002
Policy Entropy: 2.39838
Value Function Loss: 0.01470

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.58058
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 22,660.15342
Overall Steps per Second: 10,664.13377

Timestep Collection Time: 2.20740
Timestep Consumption Time: 2.48309
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.69049

Cumulative Model Updates: 183,238
Cumulative Timesteps: 1,528,228,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.90476
Policy Entropy: 2.42337
Value Function Loss: 0.01462

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.56731

Collected Steps per Second: 22,918.77033
Overall Steps per Second: 10,870.87988

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60110

Cumulative Model Updates: 183,244
Cumulative Timesteps: 1,528,278,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1528278498...
Checkpoint 1528278498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.60630
Policy Entropy: 2.41991
Value Function Loss: 0.01471

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.56815

Collected Steps per Second: 22,609.84949
Overall Steps per Second: 10,844.81461

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.39974
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.61179

Cumulative Model Updates: 183,250
Cumulative Timesteps: 1,528,328,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.99442
Policy Entropy: 2.42400
Value Function Loss: 0.01515

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.57384
Value Function Update Magnitude: 0.57881

Collected Steps per Second: 22,907.23495
Overall Steps per Second: 10,745.11624

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.47155
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.65514

Cumulative Model Updates: 183,256
Cumulative Timesteps: 1,528,378,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1528378532...
Checkpoint 1528378532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.74121
Policy Entropy: 2.40894
Value Function Loss: 0.01538

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.59250

Collected Steps per Second: 22,737.58279
Overall Steps per Second: 10,654.71864

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.69482

Cumulative Model Updates: 183,262
Cumulative Timesteps: 1,528,428,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.10799
Policy Entropy: 2.41581
Value Function Loss: 0.01553

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.58077
Value Function Update Magnitude: 0.62720

Collected Steps per Second: 22,982.09759
Overall Steps per Second: 10,783.65703

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.46242
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.63924

Cumulative Model Updates: 183,268
Cumulative Timesteps: 1,528,478,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1528478582...
Checkpoint 1528478582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.05645
Policy Entropy: 2.42030
Value Function Loss: 0.01548

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.61751

Collected Steps per Second: 22,874.10693
Overall Steps per Second: 10,717.43076

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.48001
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.66642

Cumulative Model Updates: 183,274
Cumulative Timesteps: 1,528,528,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.17759
Policy Entropy: 2.40828
Value Function Loss: 0.01586

Mean KL Divergence: 0.02648
SB3 Clip Fraction: 0.19052
Policy Update Magnitude: 0.52322
Value Function Update Magnitude: 0.61015

Collected Steps per Second: 23,179.77382
Overall Steps per Second: 10,983.38791

Timestep Collection Time: 2.15740
Timestep Consumption Time: 2.39566
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.55306

Cumulative Model Updates: 183,280
Cumulative Timesteps: 1,528,578,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1528578602...
Checkpoint 1528578602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.34078
Policy Entropy: 2.42748
Value Function Loss: 0.01617

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.18739
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.59916

Collected Steps per Second: 23,068.31352
Overall Steps per Second: 11,095.52640

Timestep Collection Time: 2.16834
Timestep Consumption Time: 2.33978
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.50812

Cumulative Model Updates: 183,286
Cumulative Timesteps: 1,528,628,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.71891
Policy Entropy: 2.43715
Value Function Loss: 0.01501

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.17854
Policy Update Magnitude: 0.59104
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 23,446.45227
Overall Steps per Second: 10,876.16498

Timestep Collection Time: 2.13380
Timestep Consumption Time: 2.46617
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.59997

Cumulative Model Updates: 183,292
Cumulative Timesteps: 1,528,678,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1528678652...
Checkpoint 1528678652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.29923
Policy Entropy: 2.43983
Value Function Loss: 0.01444

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.57045
Value Function Update Magnitude: 0.56479

Collected Steps per Second: 22,804.23183
Overall Steps per Second: 10,647.87756

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.69577

Cumulative Model Updates: 183,298
Cumulative Timesteps: 1,528,728,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.21536
Policy Entropy: 2.43471
Value Function Loss: 0.01455

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.58850

Collected Steps per Second: 23,061.75132
Overall Steps per Second: 10,877.56909

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59845

Cumulative Model Updates: 183,304
Cumulative Timesteps: 1,528,778,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1528778672...
Checkpoint 1528778672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.63325
Policy Entropy: 2.41876
Value Function Loss: 0.01504

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.58727
Value Function Update Magnitude: 0.62619

Collected Steps per Second: 22,668.61727
Overall Steps per Second: 10,686.71055

Timestep Collection Time: 2.20684
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.68114

Cumulative Model Updates: 183,310
Cumulative Timesteps: 1,528,828,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.67783
Policy Entropy: 2.42599
Value Function Loss: 0.01499

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 23,230.07745
Overall Steps per Second: 10,847.46750

Timestep Collection Time: 2.15376
Timestep Consumption Time: 2.45856
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61232

Cumulative Model Updates: 183,316
Cumulative Timesteps: 1,528,878,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1528878730...
Checkpoint 1528878730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.33870
Policy Entropy: 2.42568
Value Function Loss: 0.01454

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.57763
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 22,930.84509
Overall Steps per Second: 10,903.08196

Timestep Collection Time: 2.18169
Timestep Consumption Time: 2.40674
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.58843

Cumulative Model Updates: 183,322
Cumulative Timesteps: 1,528,928,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.18997
Policy Entropy: 2.42460
Value Function Loss: 0.01437

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 22,926.20588
Overall Steps per Second: 10,901.57594

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.40568
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.58668

Cumulative Model Updates: 183,328
Cumulative Timesteps: 1,528,978,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1528978760...
Checkpoint 1528978760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.10737
Policy Entropy: 2.41581
Value Function Loss: 0.01452

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.58565

Collected Steps per Second: 23,307.95772
Overall Steps per Second: 10,977.33692

Timestep Collection Time: 2.14639
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.55739

Cumulative Model Updates: 183,334
Cumulative Timesteps: 1,529,028,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.66080
Policy Entropy: 2.41438
Value Function Loss: 0.01332

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.58078

Collected Steps per Second: 23,355.82413
Overall Steps per Second: 10,859.16765

Timestep Collection Time: 2.14174
Timestep Consumption Time: 2.46469
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.60643

Cumulative Model Updates: 183,340
Cumulative Timesteps: 1,529,078,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1529078810...
Checkpoint 1529078810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.05614
Policy Entropy: 2.40694
Value Function Loss: 0.01366

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.55770
Value Function Update Magnitude: 0.55908

Collected Steps per Second: 22,912.43319
Overall Steps per Second: 10,780.37501

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.63991

Cumulative Model Updates: 183,346
Cumulative Timesteps: 1,529,128,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.30216
Policy Entropy: 2.40350
Value Function Loss: 0.01299

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 22,648.58235
Overall Steps per Second: 10,787.58287

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.63514

Cumulative Model Updates: 183,352
Cumulative Timesteps: 1,529,178,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529178832...
Checkpoint 1529178832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.34114
Policy Entropy: 2.40988
Value Function Loss: 0.01342

Mean KL Divergence: 0.02871
SB3 Clip Fraction: 0.19705
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.58014

Collected Steps per Second: 22,236.31694
Overall Steps per Second: 10,721.81941

Timestep Collection Time: 2.24875
Timestep Consumption Time: 2.41501
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.66376

Cumulative Model Updates: 183,358
Cumulative Timesteps: 1,529,228,836

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.74548
Policy Entropy: 2.40682
Value Function Loss: 0.01458

Mean KL Divergence: 0.02547
SB3 Clip Fraction: 0.18256
Policy Update Magnitude: 0.51635
Value Function Update Magnitude: 0.58073

Collected Steps per Second: 23,112.62923
Overall Steps per Second: 10,801.12677

Timestep Collection Time: 2.16349
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.62952

Cumulative Model Updates: 183,364
Cumulative Timesteps: 1,529,278,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1529278840...
Checkpoint 1529278840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.21654
Policy Entropy: 2.39558
Value Function Loss: 0.01608

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.58687

Collected Steps per Second: 22,701.99509
Overall Steps per Second: 10,625.74051

Timestep Collection Time: 2.20245
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70555

Cumulative Model Updates: 183,370
Cumulative Timesteps: 1,529,328,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.98961
Policy Entropy: 2.40119
Value Function Loss: 0.01695

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.19447
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.62569

Collected Steps per Second: 23,666.08042
Overall Steps per Second: 10,942.67434

Timestep Collection Time: 2.11281
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.56945

Cumulative Model Updates: 183,376
Cumulative Timesteps: 1,529,378,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529378842...
Checkpoint 1529378842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.01776
Policy Entropy: 2.41060
Value Function Loss: 0.01625

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.60104
Value Function Update Magnitude: 0.65414

Collected Steps per Second: 23,223.08743
Overall Steps per Second: 10,978.02899

Timestep Collection Time: 2.15372
Timestep Consumption Time: 2.40229
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.55601

Cumulative Model Updates: 183,382
Cumulative Timesteps: 1,529,428,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.40807
Policy Entropy: 2.43728
Value Function Loss: 0.01507

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.61103
Value Function Update Magnitude: 0.66147

Collected Steps per Second: 23,180.87482
Overall Steps per Second: 10,926.96488

Timestep Collection Time: 2.15781
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.57767

Cumulative Model Updates: 183,388
Cumulative Timesteps: 1,529,478,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1529478878...
Checkpoint 1529478878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.96100
Policy Entropy: 2.43156
Value Function Loss: 0.01457

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.64046

Collected Steps per Second: 22,905.61053
Overall Steps per Second: 10,903.75703

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.40395
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.58796

Cumulative Model Updates: 183,394
Cumulative Timesteps: 1,529,528,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.00291
Policy Entropy: 2.42644
Value Function Loss: 0.01503

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.58409
Value Function Update Magnitude: 0.63108

Collected Steps per Second: 23,425.36978
Overall Steps per Second: 10,801.16742

Timestep Collection Time: 2.13529
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.63098

Cumulative Model Updates: 183,400
Cumulative Timesteps: 1,529,578,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1529578924...
Checkpoint 1529578924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.87201
Policy Entropy: 2.40252
Value Function Loss: 0.01519

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 23,088.10969
Overall Steps per Second: 10,738.32939

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.65715

Cumulative Model Updates: 183,406
Cumulative Timesteps: 1,529,628,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.94608
Policy Entropy: 2.42278
Value Function Loss: 0.01528

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 21,556.90584
Overall Steps per Second: 10,312.18016

Timestep Collection Time: 2.32000
Timestep Consumption Time: 2.52980
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.84980

Cumulative Model Updates: 183,412
Cumulative Timesteps: 1,529,678,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1529678946...
Checkpoint 1529678946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.28707
Policy Entropy: 2.43278
Value Function Loss: 0.01457

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.59572

Collected Steps per Second: 22,467.93248
Overall Steps per Second: 10,651.60080

Timestep Collection Time: 2.22593
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.69526

Cumulative Model Updates: 183,418
Cumulative Timesteps: 1,529,728,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.09916
Policy Entropy: 2.44970
Value Function Loss: 0.01456

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.58751

Collected Steps per Second: 22,240.44383
Overall Steps per Second: 10,859.17388

Timestep Collection Time: 2.24825
Timestep Consumption Time: 2.35634
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60459

Cumulative Model Updates: 183,424
Cumulative Timesteps: 1,529,778,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529778960...
Checkpoint 1529778960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.02242
Policy Entropy: 2.44914
Value Function Loss: 0.01438

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.58290

Collected Steps per Second: 21,991.81599
Overall Steps per Second: 10,721.22099

Timestep Collection Time: 2.27412
Timestep Consumption Time: 2.39065
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.66477

Cumulative Model Updates: 183,430
Cumulative Timesteps: 1,529,828,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.90852
Policy Entropy: 2.42836
Value Function Loss: 0.01537

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.55281

Collected Steps per Second: 23,360.94776
Overall Steps per Second: 10,835.60164

Timestep Collection Time: 2.14084
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61553

Cumulative Model Updates: 183,436
Cumulative Timesteps: 1,529,878,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1529878984...
Checkpoint 1529878984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.60365
Policy Entropy: 2.42800
Value Function Loss: 0.01615

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.56440
Value Function Update Magnitude: 0.54984

Collected Steps per Second: 22,912.53140
Overall Steps per Second: 10,675.03331

Timestep Collection Time: 2.18265
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68476

Cumulative Model Updates: 183,442
Cumulative Timesteps: 1,529,928,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.15145
Policy Entropy: 2.40267
Value Function Loss: 0.01667

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 23,246.81149
Overall Steps per Second: 10,877.76796

Timestep Collection Time: 2.15109
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59708

Cumulative Model Updates: 183,448
Cumulative Timesteps: 1,529,979,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1529979000...
Checkpoint 1529979000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.81394
Policy Entropy: 2.40365
Value Function Loss: 0.01609

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.58277
Value Function Update Magnitude: 0.57352

Collected Steps per Second: 22,761.18996
Overall Steps per Second: 10,682.58028

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.68295

Cumulative Model Updates: 183,454
Cumulative Timesteps: 1,530,029,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.93747
Policy Entropy: 2.40992
Value Function Loss: 0.01533

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.57072

Collected Steps per Second: 23,013.92758
Overall Steps per Second: 10,950.98926

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.39483
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.56890

Cumulative Model Updates: 183,460
Cumulative Timesteps: 1,530,079,060

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1530079060...
Checkpoint 1530079060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.05843
Policy Entropy: 2.41382
Value Function Loss: 0.01494

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.57150
Value Function Update Magnitude: 0.56309

Collected Steps per Second: 23,260.87184
Overall Steps per Second: 10,812.73209

Timestep Collection Time: 2.14953
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.62418

Cumulative Model Updates: 183,466
Cumulative Timesteps: 1,530,129,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.80525
Policy Entropy: 2.41137
Value Function Loss: 0.01466

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.57356

Collected Steps per Second: 22,973.06362
Overall Steps per Second: 10,739.45693

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.65573

Cumulative Model Updates: 183,472
Cumulative Timesteps: 1,530,179,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1530179060...
Checkpoint 1530179060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.50164
Policy Entropy: 2.42093
Value Function Loss: 0.01511

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.59231

Collected Steps per Second: 22,735.65601
Overall Steps per Second: 10,630.92564

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.70382

Cumulative Model Updates: 183,478
Cumulative Timesteps: 1,530,229,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.76803
Policy Entropy: 2.42196
Value Function Loss: 0.01435

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.59575

Collected Steps per Second: 22,667.25807
Overall Steps per Second: 10,639.00050

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.69969

Cumulative Model Updates: 183,484
Cumulative Timesteps: 1,530,279,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1530279066...
Checkpoint 1530279066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.18619
Policy Entropy: 2.42413
Value Function Loss: 0.01431

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 22,529.69986
Overall Steps per Second: 10,803.14020

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.40957
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62939

Cumulative Model Updates: 183,490
Cumulative Timesteps: 1,530,329,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.03960
Policy Entropy: 2.43418
Value Function Loss: 0.01357

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.55469
Value Function Update Magnitude: 0.54209

Collected Steps per Second: 23,388.47063
Overall Steps per Second: 11,006.20477

Timestep Collection Time: 2.13815
Timestep Consumption Time: 2.40547
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.54362

Cumulative Model Updates: 183,496
Cumulative Timesteps: 1,530,379,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1530379086...
Checkpoint 1530379086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.40705
Policy Entropy: 2.43418
Value Function Loss: 0.01450

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.54053

Collected Steps per Second: 23,275.23305
Overall Steps per Second: 10,799.59172

Timestep Collection Time: 2.14881
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.63110

Cumulative Model Updates: 183,502
Cumulative Timesteps: 1,530,429,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.04617
Policy Entropy: 2.42446
Value Function Loss: 0.01540

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.55306

Collected Steps per Second: 23,391.02540
Overall Steps per Second: 10,746.76598

Timestep Collection Time: 2.13877
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.65517

Cumulative Model Updates: 183,508
Cumulative Timesteps: 1,530,479,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1530479128...
Checkpoint 1530479128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.08768
Policy Entropy: 2.40917
Value Function Loss: 0.01632

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.58084

Collected Steps per Second: 22,962.24852
Overall Steps per Second: 10,673.59293

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.68540

Cumulative Model Updates: 183,514
Cumulative Timesteps: 1,530,529,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.52862
Policy Entropy: 2.43288
Value Function Loss: 0.01555

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.59855

Collected Steps per Second: 23,359.36077
Overall Steps per Second: 10,883.20998

Timestep Collection Time: 2.14124
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.59589

Cumulative Model Updates: 183,520
Cumulative Timesteps: 1,530,579,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1530579156...
Checkpoint 1530579156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.99914
Policy Entropy: 2.45426
Value Function Loss: 0.01500

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.59547

Collected Steps per Second: 23,025.16890
Overall Steps per Second: 11,051.98539

Timestep Collection Time: 2.17206
Timestep Consumption Time: 2.35310
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.52516

Cumulative Model Updates: 183,526
Cumulative Timesteps: 1,530,629,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.09938
Policy Entropy: 2.45506
Value Function Loss: 0.01478

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.57744

Collected Steps per Second: 22,626.74454
Overall Steps per Second: 10,645.42922

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69817

Cumulative Model Updates: 183,532
Cumulative Timesteps: 1,530,679,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1530679182...
Checkpoint 1530679182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.83542
Policy Entropy: 2.43448
Value Function Loss: 0.01448

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.56844

Collected Steps per Second: 22,953.61057
Overall Steps per Second: 10,865.18860

Timestep Collection Time: 2.17874
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60277

Cumulative Model Updates: 183,538
Cumulative Timesteps: 1,530,729,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.60371
Policy Entropy: 2.40782
Value Function Loss: 0.01363

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.15764
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.56093

Collected Steps per Second: 22,847.57998
Overall Steps per Second: 10,695.09133

Timestep Collection Time: 2.18894
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.67616

Cumulative Model Updates: 183,544
Cumulative Timesteps: 1,530,779,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1530779204...
Checkpoint 1530779204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.70982
Policy Entropy: 2.41402
Value Function Loss: 0.01351

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.55713

Collected Steps per Second: 23,147.69809
Overall Steps per Second: 10,883.42154

Timestep Collection Time: 2.16021
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.59451

Cumulative Model Updates: 183,550
Cumulative Timesteps: 1,530,829,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.35394
Policy Entropy: 2.41048
Value Function Loss: 0.01382

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.56630

Collected Steps per Second: 23,002.38438
Overall Steps per Second: 10,718.83601

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.49100
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.66469

Cumulative Model Updates: 183,556
Cumulative Timesteps: 1,530,879,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1530879208...
Checkpoint 1530879208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.98886
Policy Entropy: 2.41890
Value Function Loss: 0.01394

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.57496

Collected Steps per Second: 23,274.74986
Overall Steps per Second: 10,933.33763

Timestep Collection Time: 2.14911
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.57500

Cumulative Model Updates: 183,562
Cumulative Timesteps: 1,530,929,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.70242
Policy Entropy: 2.41140
Value Function Loss: 0.01442

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 23,081.40280
Overall Steps per Second: 10,912.59053

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.41668
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.58388

Cumulative Model Updates: 183,568
Cumulative Timesteps: 1,530,979,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1530979250...
Checkpoint 1530979250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.55196
Policy Entropy: 2.41830
Value Function Loss: 0.01407

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.56789

Collected Steps per Second: 23,477.91088
Overall Steps per Second: 10,967.44045

Timestep Collection Time: 2.13077
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.56132

Cumulative Model Updates: 183,574
Cumulative Timesteps: 1,531,029,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.09448
Policy Entropy: 2.41235
Value Function Loss: 0.01509

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.55038

Collected Steps per Second: 23,121.89385
Overall Steps per Second: 10,871.21543

Timestep Collection Time: 2.16349
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60151

Cumulative Model Updates: 183,580
Cumulative Timesteps: 1,531,079,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1531079300...
Checkpoint 1531079300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.64689
Policy Entropy: 2.42957
Value Function Loss: 0.01454

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.54007

Collected Steps per Second: 22,831.08983
Overall Steps per Second: 10,752.31944

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.46075
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.65128

Cumulative Model Updates: 183,586
Cumulative Timesteps: 1,531,129,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.14701
Policy Entropy: 2.43215
Value Function Loss: 0.01486

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.55620
Value Function Update Magnitude: 0.53857

Collected Steps per Second: 22,618.69955
Overall Steps per Second: 10,903.62239

Timestep Collection Time: 2.21083
Timestep Consumption Time: 2.37536
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.58618

Cumulative Model Updates: 183,592
Cumulative Timesteps: 1,531,179,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1531179318...
Checkpoint 1531179318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.37609
Policy Entropy: 2.42976
Value Function Loss: 0.01458

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14622
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.54596

Collected Steps per Second: 22,086.96909
Overall Steps per Second: 10,633.27444

Timestep Collection Time: 2.26459
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.70391

Cumulative Model Updates: 183,598
Cumulative Timesteps: 1,531,229,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.06620
Policy Entropy: 2.43130
Value Function Loss: 0.01457

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.57484

Collected Steps per Second: 22,634.72714
Overall Steps per Second: 10,684.06241

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68099

Cumulative Model Updates: 183,604
Cumulative Timesteps: 1,531,279,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1531279348...
Checkpoint 1531279348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.61323
Policy Entropy: 2.43398
Value Function Loss: 0.01463

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.59473

Collected Steps per Second: 22,909.61241
Overall Steps per Second: 10,847.82250

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.42692
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60959

Cumulative Model Updates: 183,610
Cumulative Timesteps: 1,531,329,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.21384
Policy Entropy: 2.42122
Value Function Loss: 0.01435

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.58666

Collected Steps per Second: 22,817.98928
Overall Steps per Second: 10,660.65191

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.49899
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69033

Cumulative Model Updates: 183,616
Cumulative Timesteps: 1,531,379,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1531379354...
Checkpoint 1531379354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.27152
Policy Entropy: 2.40647
Value Function Loss: 0.01551

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.15019
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.56613

Collected Steps per Second: 23,290.59571
Overall Steps per Second: 10,939.77388

Timestep Collection Time: 2.14688
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.57066

Cumulative Model Updates: 183,622
Cumulative Timesteps: 1,531,429,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.10609
Policy Entropy: 2.43742
Value Function Loss: 0.01605

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.57539

Collected Steps per Second: 23,028.55368
Overall Steps per Second: 10,839.61941

Timestep Collection Time: 2.17148
Timestep Consumption Time: 2.44178
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.61326

Cumulative Model Updates: 183,628
Cumulative Timesteps: 1,531,479,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1531479362...
Checkpoint 1531479362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.27648
Policy Entropy: 2.43863
Value Function Loss: 0.01542

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.59704

Collected Steps per Second: 23,247.73682
Overall Steps per Second: 10,783.07960

Timestep Collection Time: 2.15135
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.63819

Cumulative Model Updates: 183,634
Cumulative Timesteps: 1,531,529,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.31881
Policy Entropy: 2.46331
Value Function Loss: 0.01518

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.56698
Value Function Update Magnitude: 0.58375

Collected Steps per Second: 23,084.77190
Overall Steps per Second: 10,798.97700

Timestep Collection Time: 2.16593
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.63007

Cumulative Model Updates: 183,640
Cumulative Timesteps: 1,531,579,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1531579376...
Checkpoint 1531579376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.99571
Policy Entropy: 2.45820
Value Function Loss: 0.01494

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.57197

Collected Steps per Second: 21,893.53482
Overall Steps per Second: 10,609.26461

Timestep Collection Time: 2.28570
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71682

Cumulative Model Updates: 183,646
Cumulative Timesteps: 1,531,629,418

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.76554
Policy Entropy: 2.45118
Value Function Loss: 0.01597

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 22,317.65724
Overall Steps per Second: 10,632.82804

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.70336

Cumulative Model Updates: 183,652
Cumulative Timesteps: 1,531,679,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1531679428...
Checkpoint 1531679428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.00680
Policy Entropy: 2.43679
Value Function Loss: 0.01594

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.58472
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 22,859.59311
Overall Steps per Second: 10,894.49665

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.40250
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59002

Cumulative Model Updates: 183,658
Cumulative Timesteps: 1,531,729,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.75653
Policy Entropy: 2.42559
Value Function Loss: 0.01546

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.58419

Collected Steps per Second: 23,232.24942
Overall Steps per Second: 11,004.34182

Timestep Collection Time: 2.15253
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.54439

Cumulative Model Updates: 183,664
Cumulative Timesteps: 1,531,779,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1531779442...
Checkpoint 1531779442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.48754
Policy Entropy: 2.44180
Value Function Loss: 0.01496

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.57858

Collected Steps per Second: 23,123.50899
Overall Steps per Second: 10,774.43828

Timestep Collection Time: 2.16317
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.64247

Cumulative Model Updates: 183,670
Cumulative Timesteps: 1,531,829,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.85702
Policy Entropy: 2.42812
Value Function Loss: 0.01445

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 23,296.84652
Overall Steps per Second: 10,727.37214

Timestep Collection Time: 2.14742
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.66358

Cumulative Model Updates: 183,676
Cumulative Timesteps: 1,531,879,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1531879490...
Checkpoint 1531879490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.70438
Policy Entropy: 2.43809
Value Function Loss: 0.01465

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.55950
Value Function Update Magnitude: 0.57551

Collected Steps per Second: 22,995.51803
Overall Steps per Second: 10,669.42809

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.68666

Cumulative Model Updates: 183,682
Cumulative Timesteps: 1,531,929,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.91918
Policy Entropy: 2.42073
Value Function Loss: 0.01512

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.59629

Collected Steps per Second: 23,249.87206
Overall Steps per Second: 10,888.98437

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.44183
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.59290

Cumulative Model Updates: 183,688
Cumulative Timesteps: 1,531,979,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1531979506...
Checkpoint 1531979506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.76698
Policy Entropy: 2.42851
Value Function Loss: 0.01527

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.62964

Collected Steps per Second: 23,301.09135
Overall Steps per Second: 11,117.65480

Timestep Collection Time: 2.14677
Timestep Consumption Time: 2.35256
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.49933

Cumulative Model Updates: 183,694
Cumulative Timesteps: 1,532,029,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.80164
Policy Entropy: 2.42474
Value Function Loss: 0.01589

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.58562
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 22,864.34418
Overall Steps per Second: 10,788.27902

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.63484

Cumulative Model Updates: 183,700
Cumulative Timesteps: 1,532,079,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1532079530...
Checkpoint 1532079530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.04654
Policy Entropy: 2.43929
Value Function Loss: 0.01505

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.61723

Collected Steps per Second: 22,729.30904
Overall Steps per Second: 10,734.92084

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.66012

Cumulative Model Updates: 183,706
Cumulative Timesteps: 1,532,129,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.78333
Policy Entropy: 2.45787
Value Function Loss: 0.01567

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.60745

Collected Steps per Second: 22,842.05278
Overall Steps per Second: 10,815.51771

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.43502
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62484

Cumulative Model Updates: 183,712
Cumulative Timesteps: 1,532,179,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1532179576...
Checkpoint 1532179576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.35128
Policy Entropy: 2.44786
Value Function Loss: 0.01457

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 22,638.60942
Overall Steps per Second: 10,772.51291

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.64219

Cumulative Model Updates: 183,718
Cumulative Timesteps: 1,532,229,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.40904
Policy Entropy: 2.42630
Value Function Loss: 0.01465

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.57314
Value Function Update Magnitude: 0.61176

Collected Steps per Second: 22,973.72786
Overall Steps per Second: 10,820.70831

Timestep Collection Time: 2.17753
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.62317

Cumulative Model Updates: 183,724
Cumulative Timesteps: 1,532,279,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1532279610...
Checkpoint 1532279610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.51981
Policy Entropy: 2.41071
Value Function Loss: 0.01440

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 23,290.66436
Overall Steps per Second: 11,076.71008

Timestep Collection Time: 2.14738
Timestep Consumption Time: 2.36786
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.51524

Cumulative Model Updates: 183,730
Cumulative Timesteps: 1,532,329,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.60010
Policy Entropy: 2.42154
Value Function Loss: 0.01448

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.16840
Policy Update Magnitude: 0.51740
Value Function Update Magnitude: 0.58013

Collected Steps per Second: 22,996.27143
Overall Steps per Second: 10,715.99717

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66667

Cumulative Model Updates: 183,736
Cumulative Timesteps: 1,532,379,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1532379632...
Checkpoint 1532379632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.90153
Policy Entropy: 2.40745
Value Function Loss: 0.01455

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.52545
Value Function Update Magnitude: 0.57592

Collected Steps per Second: 23,227.78773
Overall Steps per Second: 10,945.06690

Timestep Collection Time: 2.15371
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.57064

Cumulative Model Updates: 183,742
Cumulative Timesteps: 1,532,429,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.63493
Policy Entropy: 2.41813
Value Function Loss: 0.01475

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 23,165.59929
Overall Steps per Second: 10,868.61747

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.44252
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.60132

Cumulative Model Updates: 183,748
Cumulative Timesteps: 1,532,479,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1532479668...
Checkpoint 1532479668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.93987
Policy Entropy: 2.41232
Value Function Loss: 0.01489

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.56446

Collected Steps per Second: 22,794.57871
Overall Steps per Second: 10,658.54207

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.69239

Cumulative Model Updates: 183,754
Cumulative Timesteps: 1,532,529,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.75775
Policy Entropy: 2.43272
Value Function Loss: 0.01506

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 22,389.61184
Overall Steps per Second: 10,643.67935

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.69894

Cumulative Model Updates: 183,760
Cumulative Timesteps: 1,532,579,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1532579696...
Checkpoint 1532579696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.80879
Policy Entropy: 2.42900
Value Function Loss: 0.01569

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.56868

Collected Steps per Second: 22,813.52800
Overall Steps per Second: 10,947.84512

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.37676
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.56967

Cumulative Model Updates: 183,766
Cumulative Timesteps: 1,532,629,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.83131
Policy Entropy: 2.42689
Value Function Loss: 0.01531

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 23,018.85643
Overall Steps per Second: 10,853.00124

Timestep Collection Time: 2.17291
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.60868

Cumulative Model Updates: 183,772
Cumulative Timesteps: 1,532,679,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1532679742...
Checkpoint 1532679742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.61248
Policy Entropy: 2.44089
Value Function Loss: 0.01450

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 22,768.54942
Overall Steps per Second: 10,653.23084

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.69360

Cumulative Model Updates: 183,778
Cumulative Timesteps: 1,532,729,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.29143
Policy Entropy: 2.45377
Value Function Loss: 0.01389

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.57620

Collected Steps per Second: 23,242.39606
Overall Steps per Second: 10,797.26858

Timestep Collection Time: 2.15124
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.63080

Cumulative Model Updates: 183,784
Cumulative Timesteps: 1,532,779,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1532779744...
Checkpoint 1532779744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.59170
Policy Entropy: 2.43653
Value Function Loss: 0.01432

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.55592
Value Function Update Magnitude: 0.57520

Collected Steps per Second: 23,058.53266
Overall Steps per Second: 10,729.42585

Timestep Collection Time: 2.16839
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.66008

Cumulative Model Updates: 183,790
Cumulative Timesteps: 1,532,829,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.97479
Policy Entropy: 2.43504
Value Function Loss: 0.01404

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.58964

Collected Steps per Second: 22,859.82079
Overall Steps per Second: 10,834.09119

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61765

Cumulative Model Updates: 183,796
Cumulative Timesteps: 1,532,879,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1532879772...
Checkpoint 1532879772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.40845
Policy Entropy: 2.41486
Value Function Loss: 0.01473

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.58980

Collected Steps per Second: 23,277.96513
Overall Steps per Second: 11,104.64015

Timestep Collection Time: 2.14856
Timestep Consumption Time: 2.35533
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.50388

Cumulative Model Updates: 183,802
Cumulative Timesteps: 1,532,929,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.94600
Policy Entropy: 2.43446
Value Function Loss: 0.01545

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.58746

Collected Steps per Second: 23,319.35065
Overall Steps per Second: 10,926.55089

Timestep Collection Time: 2.14449
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.57674

Cumulative Model Updates: 183,808
Cumulative Timesteps: 1,532,979,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1532979794...
Checkpoint 1532979794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.13997
Policy Entropy: 2.44202
Value Function Loss: 0.01534

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.60604

Collected Steps per Second: 23,113.69318
Overall Steps per Second: 10,731.04263

Timestep Collection Time: 2.16426
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.66162

Cumulative Model Updates: 183,814
Cumulative Timesteps: 1,533,029,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.97688
Policy Entropy: 2.46653
Value Function Loss: 0.01455

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.62638

Collected Steps per Second: 22,616.29996
Overall Steps per Second: 10,642.49918

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69890

Cumulative Model Updates: 183,820
Cumulative Timesteps: 1,533,079,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1533079826...
Checkpoint 1533079826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.48463
Policy Entropy: 2.46616
Value Function Loss: 0.01439

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.56584
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,641.82106
Overall Steps per Second: 10,839.26328

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.40504
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61378

Cumulative Model Updates: 183,826
Cumulative Timesteps: 1,533,129,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.54996
Policy Entropy: 2.46074
Value Function Loss: 0.01398

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.58815

Collected Steps per Second: 22,754.12351
Overall Steps per Second: 10,980.73275

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.35631
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.55398

Cumulative Model Updates: 183,832
Cumulative Timesteps: 1,533,179,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1533179842...
Checkpoint 1533179842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.88222
Policy Entropy: 2.46965
Value Function Loss: 0.01388

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.58095

Collected Steps per Second: 22,793.28764
Overall Steps per Second: 10,638.48391

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.70048

Cumulative Model Updates: 183,838
Cumulative Timesteps: 1,533,229,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.48109
Policy Entropy: 2.46118
Value Function Loss: 0.01386

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.58705

Collected Steps per Second: 22,794.97333
Overall Steps per Second: 10,636.82932

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.70140

Cumulative Model Updates: 183,844
Cumulative Timesteps: 1,533,279,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1533279856...
Checkpoint 1533279856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.68371
Policy Entropy: 2.43540
Value Function Loss: 0.01448

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 23,255.47979
Overall Steps per Second: 10,924.32885

Timestep Collection Time: 2.15046
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57786

Cumulative Model Updates: 183,850
Cumulative Timesteps: 1,533,329,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.34052
Policy Entropy: 2.41996
Value Function Loss: 0.01523

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.58051

Collected Steps per Second: 23,284.00796
Overall Steps per Second: 10,872.75313

Timestep Collection Time: 2.14783
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.59957

Cumulative Model Updates: 183,856
Cumulative Timesteps: 1,533,379,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1533379876...
Checkpoint 1533379876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.86875
Policy Entropy: 2.42652
Value Function Loss: 0.01520

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 22,990.07516
Overall Steps per Second: 10,756.72997

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.64900

Cumulative Model Updates: 183,862
Cumulative Timesteps: 1,533,429,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.16103
Policy Entropy: 2.45321
Value Function Loss: 0.01445

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.56619

Collected Steps per Second: 23,225.16202
Overall Steps per Second: 10,911.63804

Timestep Collection Time: 2.15404
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.58483

Cumulative Model Updates: 183,868
Cumulative Timesteps: 1,533,479,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1533479912...
Checkpoint 1533479912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.55497
Policy Entropy: 2.44609
Value Function Loss: 0.01465

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.54141

Collected Steps per Second: 22,995.42982
Overall Steps per Second: 10,637.66067

Timestep Collection Time: 2.17565
Timestep Consumption Time: 2.52745
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.70310

Cumulative Model Updates: 183,874
Cumulative Timesteps: 1,533,529,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.25519
Policy Entropy: 2.42235
Value Function Loss: 0.01510

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.54352

Collected Steps per Second: 22,823.93559
Overall Steps per Second: 10,812.62594

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62718

Cumulative Model Updates: 183,880
Cumulative Timesteps: 1,533,579,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1533579974...
Checkpoint 1533579974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.88570
Policy Entropy: 2.41947
Value Function Loss: 0.01512

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.54272

Collected Steps per Second: 22,578.60709
Overall Steps per Second: 10,679.01893

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.68470

Cumulative Model Updates: 183,886
Cumulative Timesteps: 1,533,630,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.92212
Policy Entropy: 2.42463
Value Function Loss: 0.01444

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.54690

Collected Steps per Second: 22,422.97852
Overall Steps per Second: 10,529.06199

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.51911
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.74914

Cumulative Model Updates: 183,892
Cumulative Timesteps: 1,533,680,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1533680006...
Checkpoint 1533680006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.17186
Policy Entropy: 2.43739
Value Function Loss: 0.01503

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.57112
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 22,821.21018
Overall Steps per Second: 10,723.44839

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.47282
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.66473

Cumulative Model Updates: 183,898
Cumulative Timesteps: 1,533,730,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.01995
Policy Entropy: 2.42825
Value Function Loss: 0.01456

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.58155

Collected Steps per Second: 23,402.26762
Overall Steps per Second: 10,736.24976

Timestep Collection Time: 2.13697
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.65805

Cumulative Model Updates: 183,904
Cumulative Timesteps: 1,533,780,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1533780038...
Checkpoint 1533780038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.83724
Policy Entropy: 2.43085
Value Function Loss: 0.01526

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.56564

Collected Steps per Second: 23,295.58647
Overall Steps per Second: 11,128.93609

Timestep Collection Time: 2.14745
Timestep Consumption Time: 2.34768
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.49513

Cumulative Model Updates: 183,910
Cumulative Timesteps: 1,533,830,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.12967
Policy Entropy: 2.43372
Value Function Loss: 0.01500

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.56745

Collected Steps per Second: 23,134.70915
Overall Steps per Second: 10,863.93854

Timestep Collection Time: 2.16203
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.60404

Cumulative Model Updates: 183,916
Cumulative Timesteps: 1,533,880,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1533880082...
Checkpoint 1533880082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.05040
Policy Entropy: 2.43850
Value Function Loss: 0.01555

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.56308

Collected Steps per Second: 23,369.99474
Overall Steps per Second: 10,816.65414

Timestep Collection Time: 2.13975
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.62306

Cumulative Model Updates: 183,922
Cumulative Timesteps: 1,533,930,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.52801
Policy Entropy: 2.44931
Value Function Loss: 0.01491

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.55979

Collected Steps per Second: 23,534.62994
Overall Steps per Second: 10,775.45059

Timestep Collection Time: 2.12470
Timestep Consumption Time: 2.51585
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.64055

Cumulative Model Updates: 183,928
Cumulative Timesteps: 1,533,980,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1533980092...
Checkpoint 1533980092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.64501
Policy Entropy: 2.45662
Value Function Loss: 0.01509

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.55411

Collected Steps per Second: 23,010.02070
Overall Steps per Second: 10,789.02771

Timestep Collection Time: 2.17427
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.63712

Cumulative Model Updates: 183,934
Cumulative Timesteps: 1,534,030,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.48987
Policy Entropy: 2.44774
Value Function Loss: 0.01540

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.56394

Collected Steps per Second: 22,982.93796
Overall Steps per Second: 10,875.11780

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.59931

Cumulative Model Updates: 183,940
Cumulative Timesteps: 1,534,080,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1534080140...
Checkpoint 1534080140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.37624
Policy Entropy: 2.44233
Value Function Loss: 0.01507

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.58951

Collected Steps per Second: 22,718.10604
Overall Steps per Second: 10,689.43363

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.67808

Cumulative Model Updates: 183,946
Cumulative Timesteps: 1,534,130,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.74118
Policy Entropy: 2.44620
Value Function Loss: 0.01456

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.58474

Collected Steps per Second: 22,760.75020
Overall Steps per Second: 10,765.98324

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.44798
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.64519

Cumulative Model Updates: 183,952
Cumulative Timesteps: 1,534,180,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1534180156...
Checkpoint 1534180156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.30315
Policy Entropy: 2.44325
Value Function Loss: 0.01457

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.58588

Collected Steps per Second: 22,735.71088
Overall Steps per Second: 10,682.41478

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.68340

Cumulative Model Updates: 183,958
Cumulative Timesteps: 1,534,230,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.96075
Policy Entropy: 2.44924
Value Function Loss: 0.01494

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 23,497.95703
Overall Steps per Second: 10,999.90781

Timestep Collection Time: 2.12810
Timestep Consumption Time: 2.41794
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.54604

Cumulative Model Updates: 183,964
Cumulative Timesteps: 1,534,280,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1534280192...
Checkpoint 1534280192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.39796
Policy Entropy: 2.42877
Value Function Loss: 0.01532

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.56427
Value Function Update Magnitude: 0.60524

Collected Steps per Second: 23,349.69984
Overall Steps per Second: 10,900.15889

Timestep Collection Time: 2.14238
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.58929

Cumulative Model Updates: 183,970
Cumulative Timesteps: 1,534,330,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.75040
Policy Entropy: 2.42903
Value Function Loss: 0.01479

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.59456

Collected Steps per Second: 23,392.17602
Overall Steps per Second: 10,927.16626

Timestep Collection Time: 2.13849
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.57795

Cumulative Model Updates: 183,976
Cumulative Timesteps: 1,534,380,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1534380240...
Checkpoint 1534380240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.31537
Policy Entropy: 2.44274
Value Function Loss: 0.01436

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.58142

Collected Steps per Second: 23,272.17589
Overall Steps per Second: 10,835.83037

Timestep Collection Time: 2.14892
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.61524

Cumulative Model Updates: 183,982
Cumulative Timesteps: 1,534,430,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.46352
Policy Entropy: 2.45082
Value Function Loss: 0.01477

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.55655

Collected Steps per Second: 23,265.88120
Overall Steps per Second: 10,792.31147

Timestep Collection Time: 2.14950
Timestep Consumption Time: 2.48435
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.63385

Cumulative Model Updates: 183,988
Cumulative Timesteps: 1,534,480,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1534480260...
Checkpoint 1534480260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.14426
Policy Entropy: 2.46383
Value Function Loss: 0.01475

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.56644

Collected Steps per Second: 22,501.80179
Overall Steps per Second: 10,804.91474

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.40644
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.62937

Cumulative Model Updates: 183,994
Cumulative Timesteps: 1,534,530,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.85732
Policy Entropy: 2.43897
Value Function Loss: 0.01592

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.58868

Collected Steps per Second: 23,334.74093
Overall Steps per Second: 10,750.28667

Timestep Collection Time: 2.14384
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.65346

Cumulative Model Updates: 184,000
Cumulative Timesteps: 1,534,580,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1534580306...
Checkpoint 1534580306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.59114
Policy Entropy: 2.44046
Value Function Loss: 0.01517

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.58248

Collected Steps per Second: 22,787.85314
Overall Steps per Second: 10,648.54239

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69717

Cumulative Model Updates: 184,006
Cumulative Timesteps: 1,534,630,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.47721
Policy Entropy: 2.41211
Value Function Loss: 0.01651

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.56916

Collected Steps per Second: 22,924.01532
Overall Steps per Second: 10,736.57278

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.65754

Cumulative Model Updates: 184,012
Cumulative Timesteps: 1,534,680,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1534680330...
Checkpoint 1534680330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.60579
Policy Entropy: 2.42732
Value Function Loss: 0.01573

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.56741
Value Function Update Magnitude: 0.57496

Collected Steps per Second: 23,177.48638
Overall Steps per Second: 10,772.48719

Timestep Collection Time: 2.15778
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.64257

Cumulative Model Updates: 184,018
Cumulative Timesteps: 1,534,730,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.00837
Policy Entropy: 2.44755
Value Function Loss: 0.01538

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.58636

Collected Steps per Second: 22,867.89537
Overall Steps per Second: 10,865.85716

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.41635
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60396

Cumulative Model Updates: 184,024
Cumulative Timesteps: 1,534,780,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1534780368...
Checkpoint 1534780368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.60993
Policy Entropy: 2.44505
Value Function Loss: 0.01529

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.59493

Collected Steps per Second: 23,117.72976
Overall Steps per Second: 11,097.55493

Timestep Collection Time: 2.16388
Timestep Consumption Time: 2.34378
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.50766

Cumulative Model Updates: 184,030
Cumulative Timesteps: 1,534,830,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.61560
Policy Entropy: 2.41043
Value Function Loss: 0.01684

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 23,115.03489
Overall Steps per Second: 10,858.26057

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60718

Cumulative Model Updates: 184,036
Cumulative Timesteps: 1,534,880,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1534880418...
Checkpoint 1534880418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.60516
Policy Entropy: 2.39620
Value Function Loss: 0.01691

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.56665
Value Function Update Magnitude: 0.65344

Collected Steps per Second: 22,992.59318
Overall Steps per Second: 10,731.40470

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.65978

Cumulative Model Updates: 184,042
Cumulative Timesteps: 1,534,930,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.97595
Policy Entropy: 2.42037
Value Function Loss: 0.01670

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.57434
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 22,365.98267
Overall Steps per Second: 10,642.65795

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.69883

Cumulative Model Updates: 184,048
Cumulative Timesteps: 1,534,980,432

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1534980432...
Checkpoint 1534980432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.45706
Policy Entropy: 2.45138
Value Function Loss: 0.01519

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,774.39792
Overall Steps per Second: 10,934.04291

Timestep Collection Time: 2.19633
Timestep Consumption Time: 2.37838
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.57470

Cumulative Model Updates: 184,054
Cumulative Timesteps: 1,535,030,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.19139
Policy Entropy: 2.46807
Value Function Loss: 0.01429

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.61251

Collected Steps per Second: 22,809.86636
Overall Steps per Second: 10,807.95585

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62807

Cumulative Model Updates: 184,060
Cumulative Timesteps: 1,535,080,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1535080472...
Checkpoint 1535080472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.73346
Policy Entropy: 2.47004
Value Function Loss: 0.01403

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.59305

Collected Steps per Second: 22,899.76125
Overall Steps per Second: 10,683.77346

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68112

Cumulative Model Updates: 184,066
Cumulative Timesteps: 1,535,130,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.91580
Policy Entropy: 2.45241
Value Function Loss: 0.01471

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.56740

Collected Steps per Second: 23,165.40522
Overall Steps per Second: 10,675.69040

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.52626
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68560

Cumulative Model Updates: 184,072
Cumulative Timesteps: 1,535,180,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1535180506...
Checkpoint 1535180506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.55829
Policy Entropy: 2.43756
Value Function Loss: 0.01505

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.58273

Collected Steps per Second: 23,260.23918
Overall Steps per Second: 10,915.93462

Timestep Collection Time: 2.14993
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.58119

Cumulative Model Updates: 184,078
Cumulative Timesteps: 1,535,230,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.58782
Policy Entropy: 2.43796
Value Function Loss: 0.01468

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.59815

Collected Steps per Second: 22,906.18174
Overall Steps per Second: 10,914.67699

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.39913
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.58282

Cumulative Model Updates: 184,084
Cumulative Timesteps: 1,535,280,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1535280534...
Checkpoint 1535280534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.90729
Policy Entropy: 2.43864
Value Function Loss: 0.01512

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.54568
Value Function Update Magnitude: 0.60300

Collected Steps per Second: 22,547.36132
Overall Steps per Second: 10,828.82518

Timestep Collection Time: 2.21809
Timestep Consumption Time: 2.40033
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.61841

Cumulative Model Updates: 184,090
Cumulative Timesteps: 1,535,330,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.83035
Policy Entropy: 2.42359
Value Function Loss: 0.01556

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.56587
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 23,460.45290
Overall Steps per Second: 10,818.57729

Timestep Collection Time: 2.13304
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.62556

Cumulative Model Updates: 184,096
Cumulative Timesteps: 1,535,380,588

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1535380588...
Checkpoint 1535380588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.38134
Policy Entropy: 2.41633
Value Function Loss: 0.01486

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.56834
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 23,297.53678
Overall Steps per Second: 10,936.51138

Timestep Collection Time: 2.14684
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.57330

Cumulative Model Updates: 184,102
Cumulative Timesteps: 1,535,430,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.68253
Policy Entropy: 2.42126
Value Function Loss: 0.01480

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.62260

Collected Steps per Second: 21,459.12708
Overall Steps per Second: 10,432.83452

Timestep Collection Time: 2.33010
Timestep Consumption Time: 2.46265
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.79275

Cumulative Model Updates: 184,108
Cumulative Timesteps: 1,535,480,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1535480606...
Checkpoint 1535480606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.78330
Policy Entropy: 2.42031
Value Function Loss: 0.01483

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.61342

Collected Steps per Second: 22,281.10968
Overall Steps per Second: 10,761.15484

Timestep Collection Time: 2.24477
Timestep Consumption Time: 2.40306
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.64783

Cumulative Model Updates: 184,114
Cumulative Timesteps: 1,535,530,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.60386
Policy Entropy: 2.42591
Value Function Loss: 0.01528

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.62628

Collected Steps per Second: 22,738.01911
Overall Steps per Second: 10,880.64648

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.39645
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.59550

Cumulative Model Updates: 184,120
Cumulative Timesteps: 1,535,580,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1535580624...
Checkpoint 1535580624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.90766
Policy Entropy: 2.42583
Value Function Loss: 0.01503

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.62541

Collected Steps per Second: 22,684.77675
Overall Steps per Second: 10,606.04612

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.51107
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.71599

Cumulative Model Updates: 184,126
Cumulative Timesteps: 1,535,630,642

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.75881
Policy Entropy: 2.43276
Value Function Loss: 0.01511

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.62324

Collected Steps per Second: 23,080.57787
Overall Steps per Second: 10,686.05060

Timestep Collection Time: 2.16702
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68049

Cumulative Model Updates: 184,132
Cumulative Timesteps: 1,535,680,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1535680658...
Checkpoint 1535680658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.48975
Policy Entropy: 2.43074
Value Function Loss: 0.01475

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.53099
Value Function Update Magnitude: 0.59983

Collected Steps per Second: 23,457.87239
Overall Steps per Second: 10,887.46465

Timestep Collection Time: 2.13191
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.59336

Cumulative Model Updates: 184,138
Cumulative Timesteps: 1,535,730,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.37594
Policy Entropy: 2.43188
Value Function Loss: 0.01506

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.18229
Policy Update Magnitude: 0.51035
Value Function Update Magnitude: 0.57839

Collected Steps per Second: 23,179.55320
Overall Steps per Second: 10,994.27079

Timestep Collection Time: 2.15759
Timestep Consumption Time: 2.39132
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.54891

Cumulative Model Updates: 184,144
Cumulative Timesteps: 1,535,780,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1535780680...
Checkpoint 1535780680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.48968
Policy Entropy: 2.44404
Value Function Loss: 0.01503

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.16631
Policy Update Magnitude: 0.53921
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 22,952.24778
Overall Steps per Second: 10,799.96881

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.45258
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.63224

Cumulative Model Updates: 184,150
Cumulative Timesteps: 1,535,830,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.43733
Policy Entropy: 2.44488
Value Function Loss: 0.01579

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.55597
Value Function Update Magnitude: 0.59374

Collected Steps per Second: 23,327.71447
Overall Steps per Second: 11,066.18309

Timestep Collection Time: 2.14414
Timestep Consumption Time: 2.37575
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.51990

Cumulative Model Updates: 184,156
Cumulative Timesteps: 1,535,880,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1535880726...
Checkpoint 1535880726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.61527
Policy Entropy: 2.43621
Value Function Loss: 0.01635

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 23,366.87612
Overall Steps per Second: 10,757.31923

Timestep Collection Time: 2.14081
Timestep Consumption Time: 2.50942
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.65023

Cumulative Model Updates: 184,162
Cumulative Timesteps: 1,535,930,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.33215
Policy Entropy: 2.42513
Value Function Loss: 0.01546

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.61939

Collected Steps per Second: 22,909.07398
Overall Steps per Second: 10,843.18056

Timestep Collection Time: 2.18280
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61175

Cumulative Model Updates: 184,168
Cumulative Timesteps: 1,535,980,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1535980756...
Checkpoint 1535980756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.24055
Policy Entropy: 2.42015
Value Function Loss: 0.01518

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.59038

Collected Steps per Second: 22,699.89232
Overall Steps per Second: 10,704.62660

Timestep Collection Time: 2.20380
Timestep Consumption Time: 2.46951
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.67331

Cumulative Model Updates: 184,174
Cumulative Timesteps: 1,536,030,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.07355
Policy Entropy: 2.39815
Value Function Loss: 0.01524

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.57385

Collected Steps per Second: 22,623.38366
Overall Steps per Second: 10,799.95785

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63224

Cumulative Model Updates: 184,180
Cumulative Timesteps: 1,536,080,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1536080810...
Checkpoint 1536080810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.88924
Policy Entropy: 2.39481
Value Function Loss: 0.01636

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.59167

Collected Steps per Second: 22,641.38751
Overall Steps per Second: 10,787.41767

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.63818

Cumulative Model Updates: 184,186
Cumulative Timesteps: 1,536,130,844

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.31121
Policy Entropy: 2.39626
Value Function Loss: 0.01659

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.57677
Value Function Update Magnitude: 0.61148

Collected Steps per Second: 23,004.47345
Overall Steps per Second: 10,782.82164

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63886

Cumulative Model Updates: 184,192
Cumulative Timesteps: 1,536,180,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1536180864...
Checkpoint 1536180864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.61600
Policy Entropy: 2.41696
Value Function Loss: 0.01517

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.60886

Collected Steps per Second: 23,156.37172
Overall Steps per Second: 10,687.62587

Timestep Collection Time: 2.15984
Timestep Consumption Time: 2.51978
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.67962

Cumulative Model Updates: 184,198
Cumulative Timesteps: 1,536,230,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.68222
Policy Entropy: 2.41379
Value Function Loss: 0.01533

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.58875

Collected Steps per Second: 22,889.62637
Overall Steps per Second: 10,897.70510

Timestep Collection Time: 2.18562
Timestep Consumption Time: 2.40507
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.59069

Cumulative Model Updates: 184,204
Cumulative Timesteps: 1,536,280,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1536280906...
Checkpoint 1536280906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.35454
Policy Entropy: 2.41424
Value Function Loss: 0.01505

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 23,094.40883
Overall Steps per Second: 10,789.22993

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.63573

Cumulative Model Updates: 184,210
Cumulative Timesteps: 1,536,330,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.31814
Policy Entropy: 2.40877
Value Function Loss: 0.01519

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.60134

Collected Steps per Second: 23,254.06061
Overall Steps per Second: 10,939.00208

Timestep Collection Time: 2.15137
Timestep Consumption Time: 2.42199
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.57336

Cumulative Model Updates: 184,216
Cumulative Timesteps: 1,536,380,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1536380950...
Checkpoint 1536380950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.15036
Policy Entropy: 2.42285
Value Function Loss: 0.01442

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.56705
Value Function Update Magnitude: 0.60477

Collected Steps per Second: 23,351.82338
Overall Steps per Second: 10,931.34696

Timestep Collection Time: 2.14167
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.57510

Cumulative Model Updates: 184,222
Cumulative Timesteps: 1,536,430,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.46257
Policy Entropy: 2.43091
Value Function Loss: 0.01435

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.61107

Collected Steps per Second: 21,912.55008
Overall Steps per Second: 10,466.03810

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.77946

Cumulative Model Updates: 184,228
Cumulative Timesteps: 1,536,480,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1536480984...
Checkpoint 1536480984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.73476
Policy Entropy: 2.42477
Value Function Loss: 0.01480

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,638.45736
Overall Steps per Second: 10,646.12355

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69880

Cumulative Model Updates: 184,234
Cumulative Timesteps: 1,536,531,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.35846
Policy Entropy: 2.42024
Value Function Loss: 0.01438

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.58904

Collected Steps per Second: 23,071.45651
Overall Steps per Second: 10,964.05065

Timestep Collection Time: 2.16744
Timestep Consumption Time: 2.39347
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.56091

Cumulative Model Updates: 184,240
Cumulative Timesteps: 1,536,581,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1536581014...
Checkpoint 1536581014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.44083
Policy Entropy: 2.41142
Value Function Loss: 0.01576

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.58250

Collected Steps per Second: 23,024.52007
Overall Steps per Second: 11,094.10159

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.33614
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.50852

Cumulative Model Updates: 184,246
Cumulative Timesteps: 1,536,631,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.74440
Policy Entropy: 2.41322
Value Function Loss: 0.01558

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.58647

Collected Steps per Second: 23,081.95951
Overall Steps per Second: 10,816.14526

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62309

Cumulative Model Updates: 184,252
Cumulative Timesteps: 1,536,681,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1536681036...
Checkpoint 1536681036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.07741
Policy Entropy: 2.39383
Value Function Loss: 0.01655

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.60650

Collected Steps per Second: 23,215.52740
Overall Steps per Second: 10,733.26778

Timestep Collection Time: 2.15433
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.65972

Cumulative Model Updates: 184,258
Cumulative Timesteps: 1,536,731,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.62402
Policy Entropy: 2.39318
Value Function Loss: 0.01622

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.56772
Value Function Update Magnitude: 0.61033

Collected Steps per Second: 23,267.93455
Overall Steps per Second: 10,835.59570

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.46584
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.61497

Cumulative Model Updates: 184,264
Cumulative Timesteps: 1,536,781,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1536781056...
Checkpoint 1536781056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.53603
Policy Entropy: 2.40685
Value Function Loss: 0.01560

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.16392
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 22,495.52356
Overall Steps per Second: 10,657.77353

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.69348

Cumulative Model Updates: 184,270
Cumulative Timesteps: 1,536,831,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.05039
Policy Entropy: 2.41550
Value Function Loss: 0.01549

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.16416
Policy Update Magnitude: 0.52638
Value Function Update Magnitude: 0.58571

Collected Steps per Second: 23,150.11199
Overall Steps per Second: 10,910.72201

Timestep Collection Time: 2.16059
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.58430

Cumulative Model Updates: 184,276
Cumulative Timesteps: 1,536,881,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1536881096...
Checkpoint 1536881096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.59368
Policy Entropy: 2.42631
Value Function Loss: 0.01491

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.16610
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.56091

Collected Steps per Second: 23,223.00933
Overall Steps per Second: 10,791.31133

Timestep Collection Time: 2.15355
Timestep Consumption Time: 2.48092
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.63447

Cumulative Model Updates: 184,282
Cumulative Timesteps: 1,536,931,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.07850
Policy Entropy: 2.43799
Value Function Loss: 0.01547

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.15735
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.54727

Collected Steps per Second: 23,079.04689
Overall Steps per Second: 10,806.77092

Timestep Collection Time: 2.16664
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.62710

Cumulative Model Updates: 184,288
Cumulative Timesteps: 1,536,981,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1536981112...
Checkpoint 1536981112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.75065
Policy Entropy: 2.43080
Value Function Loss: 0.01525

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.54680

Collected Steps per Second: 22,750.84059
Overall Steps per Second: 10,707.38177

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.67192

Cumulative Model Updates: 184,294
Cumulative Timesteps: 1,537,031,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.14939
Policy Entropy: 2.42214
Value Function Loss: 0.01550

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.56851

Collected Steps per Second: 22,494.37910
Overall Steps per Second: 10,789.14378

Timestep Collection Time: 2.22509
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.63911

Cumulative Model Updates: 184,300
Cumulative Timesteps: 1,537,081,188

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1537081188...
Checkpoint 1537081188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.50129
Policy Entropy: 2.40906
Value Function Loss: 0.01538

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.57588

Collected Steps per Second: 22,494.62524
Overall Steps per Second: 10,758.13805

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.64783

Cumulative Model Updates: 184,306
Cumulative Timesteps: 1,537,131,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.16818
Policy Entropy: 2.41632
Value Function Loss: 0.01602

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.57157
Value Function Update Magnitude: 0.59439

Collected Steps per Second: 23,580.38700
Overall Steps per Second: 10,799.88147

Timestep Collection Time: 2.12066
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.63024

Cumulative Model Updates: 184,312
Cumulative Timesteps: 1,537,181,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1537181196...
Checkpoint 1537181196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.05418
Policy Entropy: 2.41193
Value Function Loss: 0.01560

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.61613

Collected Steps per Second: 23,069.99061
Overall Steps per Second: 10,703.48948

Timestep Collection Time: 2.16784
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67249

Cumulative Model Updates: 184,318
Cumulative Timesteps: 1,537,231,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.77310
Policy Entropy: 2.42190
Value Function Loss: 0.01459

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 23,269.21489
Overall Steps per Second: 10,831.53165

Timestep Collection Time: 2.14928
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.61726

Cumulative Model Updates: 184,324
Cumulative Timesteps: 1,537,281,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1537281220...
Checkpoint 1537281220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.11955
Policy Entropy: 2.42738
Value Function Loss: 0.01498

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 23,284.17986
Overall Steps per Second: 10,894.00953

Timestep Collection Time: 2.14858
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.59225

Cumulative Model Updates: 184,330
Cumulative Timesteps: 1,537,331,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.45117
Policy Entropy: 2.42606
Value Function Loss: 0.01581

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.57518

Collected Steps per Second: 23,564.16530
Overall Steps per Second: 11,199.58624

Timestep Collection Time: 2.12204
Timestep Consumption Time: 2.34277
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.46481

Cumulative Model Updates: 184,336
Cumulative Timesteps: 1,537,381,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1537381252...
Checkpoint 1537381252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.45055
Policy Entropy: 2.41842
Value Function Loss: 0.01572

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.56826

Collected Steps per Second: 21,714.79594
Overall Steps per Second: 10,554.17924

Timestep Collection Time: 2.30331
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.73898

Cumulative Model Updates: 184,342
Cumulative Timesteps: 1,537,431,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.26044
Policy Entropy: 2.42151
Value Function Loss: 0.01507

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.56149

Collected Steps per Second: 22,658.20271
Overall Steps per Second: 10,630.65302

Timestep Collection Time: 2.20715
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70432

Cumulative Model Updates: 184,348
Cumulative Timesteps: 1,537,481,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1537481278...
Checkpoint 1537481278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.79894
Policy Entropy: 2.40705
Value Function Loss: 0.01437

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.55949

Collected Steps per Second: 22,843.44521
Overall Steps per Second: 10,659.49462

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.69497

Cumulative Model Updates: 184,354
Cumulative Timesteps: 1,537,531,324

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.12986
Policy Entropy: 2.42984
Value Function Loss: 0.01403

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 23,174.76168
Overall Steps per Second: 10,721.77205

Timestep Collection Time: 2.15864
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.66583

Cumulative Model Updates: 184,360
Cumulative Timesteps: 1,537,581,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1537581350...
Checkpoint 1537581350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.36635
Policy Entropy: 2.43128
Value Function Loss: 0.01466

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.55580

Collected Steps per Second: 22,990.09550
Overall Steps per Second: 10,721.20150

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.66366

Cumulative Model Updates: 184,366
Cumulative Timesteps: 1,537,631,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.13332
Policy Entropy: 2.43244
Value Function Loss: 0.01398

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.56297

Collected Steps per Second: 23,131.52860
Overall Steps per Second: 10,867.54002

Timestep Collection Time: 2.16250
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.60288

Cumulative Model Updates: 184,372
Cumulative Timesteps: 1,537,681,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1537681372...
Checkpoint 1537681372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.59128
Policy Entropy: 2.41092
Value Function Loss: 0.01354

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.57243

Collected Steps per Second: 23,422.08652
Overall Steps per Second: 10,834.09164

Timestep Collection Time: 2.13576
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.61728

Cumulative Model Updates: 184,378
Cumulative Timesteps: 1,537,731,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.63561
Policy Entropy: 2.43465
Value Function Loss: 0.01304

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 23,303.03169
Overall Steps per Second: 10,751.76077

Timestep Collection Time: 2.14676
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.65282

Cumulative Model Updates: 184,384
Cumulative Timesteps: 1,537,781,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1537781422...
Checkpoint 1537781422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.26412
Policy Entropy: 2.43540
Value Function Loss: 0.01398

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.53632

Collected Steps per Second: 23,378.98478
Overall Steps per Second: 10,883.29186

Timestep Collection Time: 2.14004
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.59714

Cumulative Model Updates: 184,390
Cumulative Timesteps: 1,537,831,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.14516
Policy Entropy: 2.42582
Value Function Loss: 0.01520

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.55664

Collected Steps per Second: 22,702.07314
Overall Steps per Second: 10,656.52470

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69421

Cumulative Model Updates: 184,396
Cumulative Timesteps: 1,537,881,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1537881478...
Checkpoint 1537881478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.48304
Policy Entropy: 2.41627
Value Function Loss: 0.01586

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.15440
Policy Update Magnitude: 0.55920
Value Function Update Magnitude: 0.57640

Collected Steps per Second: 22,863.11989
Overall Steps per Second: 11,038.46366

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.34362
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.53143

Cumulative Model Updates: 184,402
Cumulative Timesteps: 1,537,931,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.81716
Policy Entropy: 2.40858
Value Function Loss: 0.01544

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.17282
Policy Update Magnitude: 0.53007
Value Function Update Magnitude: 0.56516

Collected Steps per Second: 22,715.27541
Overall Steps per Second: 10,673.01444

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.68490

Cumulative Model Updates: 184,408
Cumulative Timesteps: 1,537,981,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1537981500...
Checkpoint 1537981500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.74318
Policy Entropy: 2.40891
Value Function Loss: 0.01539

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.19023
Policy Update Magnitude: 0.50296
Value Function Update Magnitude: 0.56897

Collected Steps per Second: 23,113.29875
Overall Steps per Second: 10,857.32643

Timestep Collection Time: 2.16334
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60537

Cumulative Model Updates: 184,414
Cumulative Timesteps: 1,538,031,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.38798
Policy Entropy: 2.39261
Value Function Loss: 0.01398

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.18750
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.56005

Collected Steps per Second: 22,997.03472
Overall Steps per Second: 10,663.83139

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.69137

Cumulative Model Updates: 184,420
Cumulative Timesteps: 1,538,081,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1538081530...
Checkpoint 1538081530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.47416
Policy Entropy: 2.39113
Value Function Loss: 0.01490

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.17125
Policy Update Magnitude: 0.56890
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 23,195.89780
Overall Steps per Second: 10,884.14782

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.59586

Cumulative Model Updates: 184,426
Cumulative Timesteps: 1,538,131,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.80093
Policy Entropy: 2.39187
Value Function Loss: 0.01563

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.56351

Collected Steps per Second: 22,967.49536
Overall Steps per Second: 10,906.65875

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.40814
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.58582

Cumulative Model Updates: 184,432
Cumulative Timesteps: 1,538,181,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1538181568...
Checkpoint 1538181568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.50405
Policy Entropy: 2.38816
Value Function Loss: 0.01522

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.57091

Collected Steps per Second: 22,938.75437
Overall Steps per Second: 10,896.47298

Timestep Collection Time: 2.17980
Timestep Consumption Time: 2.40902
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.58882

Cumulative Model Updates: 184,438
Cumulative Timesteps: 1,538,231,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.86556
Policy Entropy: 2.40246
Value Function Loss: 0.01463

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.56704
Value Function Update Magnitude: 0.55746

Collected Steps per Second: 23,533.14340
Overall Steps per Second: 10,809.31264

Timestep Collection Time: 2.12492
Timestep Consumption Time: 2.50128
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.62620

Cumulative Model Updates: 184,444
Cumulative Timesteps: 1,538,281,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1538281576...
Checkpoint 1538281576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.68523
Policy Entropy: 2.38901
Value Function Loss: 0.01450

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.55949

Collected Steps per Second: 23,143.65496
Overall Steps per Second: 10,938.03146

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.41108
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.57175

Cumulative Model Updates: 184,450
Cumulative Timesteps: 1,538,331,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.96675
Policy Entropy: 2.38487
Value Function Loss: 0.01433

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.57150

Collected Steps per Second: 22,911.61554
Overall Steps per Second: 10,704.58910

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.67295

Cumulative Model Updates: 184,456
Cumulative Timesteps: 1,538,381,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1538381604...
Checkpoint 1538381604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.07789
Policy Entropy: 2.39774
Value Function Loss: 0.01418

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.54936
Value Function Update Magnitude: 0.56913

Collected Steps per Second: 22,282.58227
Overall Steps per Second: 10,526.15690

Timestep Collection Time: 2.24391
Timestep Consumption Time: 2.50617
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.75007

Cumulative Model Updates: 184,462
Cumulative Timesteps: 1,538,431,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.60667
Policy Entropy: 2.41634
Value Function Loss: 0.01404

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.56068

Collected Steps per Second: 22,665.15505
Overall Steps per Second: 10,819.83740

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.41588
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62262

Cumulative Model Updates: 184,468
Cumulative Timesteps: 1,538,481,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1538481620...
Checkpoint 1538481620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.55415
Policy Entropy: 2.42990
Value Function Loss: 0.01497

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.54923
Value Function Update Magnitude: 0.56973

Collected Steps per Second: 22,773.26403
Overall Steps per Second: 10,848.24343

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.41377
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.60959

Cumulative Model Updates: 184,474
Cumulative Timesteps: 1,538,531,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.73458
Policy Entropy: 2.42191
Value Function Loss: 0.01585

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.57445

Collected Steps per Second: 23,629.12729
Overall Steps per Second: 10,759.81266

Timestep Collection Time: 2.11696
Timestep Consumption Time: 2.53200
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.64897

Cumulative Model Updates: 184,480
Cumulative Timesteps: 1,538,581,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1538581648...
Checkpoint 1538581648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.50831
Policy Entropy: 2.41738
Value Function Loss: 0.01549

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.58043

Collected Steps per Second: 23,262.53170
Overall Steps per Second: 10,811.32022

Timestep Collection Time: 2.15015
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.62645

Cumulative Model Updates: 184,486
Cumulative Timesteps: 1,538,631,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.75980
Policy Entropy: 2.40147
Value Function Loss: 0.01617

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.59084

Collected Steps per Second: 23,158.16890
Overall Steps per Second: 10,702.75215

Timestep Collection Time: 2.16010
Timestep Consumption Time: 2.51384
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.67394

Cumulative Model Updates: 184,492
Cumulative Timesteps: 1,538,681,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1538681690...
Checkpoint 1538681690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.26506
Policy Entropy: 2.41974
Value Function Loss: 0.01531

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.59203

Collected Steps per Second: 23,211.44156
Overall Steps per Second: 10,844.12539

Timestep Collection Time: 2.15549
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.61374

Cumulative Model Updates: 184,498
Cumulative Timesteps: 1,538,731,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.13932
Policy Entropy: 2.42364
Value Function Loss: 0.01461

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 23,398.50790
Overall Steps per Second: 11,115.71179

Timestep Collection Time: 2.13757
Timestep Consumption Time: 2.36200
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.49958

Cumulative Model Updates: 184,504
Cumulative Timesteps: 1,538,781,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1538781738...
Checkpoint 1538781738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.92331
Policy Entropy: 2.44032
Value Function Loss: 0.01401

Mean KL Divergence: 0.02370
SB3 Clip Fraction: 0.17266
Policy Update Magnitude: 0.50858
Value Function Update Magnitude: 0.57446

Collected Steps per Second: 22,963.45394
Overall Steps per Second: 10,734.63183

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.65782

Cumulative Model Updates: 184,510
Cumulative Timesteps: 1,538,831,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.16410
Policy Entropy: 2.42750
Value Function Loss: 0.01459

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.18832
Policy Update Magnitude: 0.50412
Value Function Update Magnitude: 0.58443

Collected Steps per Second: 22,716.20934
Overall Steps per Second: 10,796.75855

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.63120

Cumulative Model Updates: 184,516
Cumulative Timesteps: 1,538,881,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1538881740...
Checkpoint 1538881740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.86528
Policy Entropy: 2.42903
Value Function Loss: 0.01486

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.51854
Value Function Update Magnitude: 0.57802

Collected Steps per Second: 22,545.29116
Overall Steps per Second: 10,781.63537

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.42063
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.63918

Cumulative Model Updates: 184,522
Cumulative Timesteps: 1,538,931,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.77938
Policy Entropy: 2.41801
Value Function Loss: 0.01498

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.56765

Collected Steps per Second: 22,514.61198
Overall Steps per Second: 10,788.21597

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.63765

Cumulative Model Updates: 184,528
Cumulative Timesteps: 1,538,981,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1538981790...
Checkpoint 1538981790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.43841
Policy Entropy: 2.41909
Value Function Loss: 0.01473

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 22,755.57910
Overall Steps per Second: 10,722.44280

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.46743
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.66610

Cumulative Model Updates: 184,534
Cumulative Timesteps: 1,539,031,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.13686
Policy Entropy: 2.42050
Value Function Loss: 0.01471

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.56436

Collected Steps per Second: 22,890.83426
Overall Steps per Second: 10,890.53844

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.40744
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.59224

Cumulative Model Updates: 184,540
Cumulative Timesteps: 1,539,081,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1539081834...
Checkpoint 1539081834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.18446
Policy Entropy: 2.42952
Value Function Loss: 0.01471

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 23,374.68936
Overall Steps per Second: 10,848.75846

Timestep Collection Time: 2.14035
Timestep Consumption Time: 2.47124
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.61159

Cumulative Model Updates: 184,546
Cumulative Timesteps: 1,539,131,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.61089
Policy Entropy: 2.42192
Value Function Loss: 0.01549

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.56415
Value Function Update Magnitude: 0.56575

Collected Steps per Second: 23,519.38228
Overall Steps per Second: 10,824.61946

Timestep Collection Time: 2.12667
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.62076

Cumulative Model Updates: 184,552
Cumulative Timesteps: 1,539,181,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1539181882...
Checkpoint 1539181882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.43251
Policy Entropy: 2.42481
Value Function Loss: 0.01633

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.57368

Collected Steps per Second: 23,208.58260
Overall Steps per Second: 10,906.34743

Timestep Collection Time: 2.15550
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.58687

Cumulative Model Updates: 184,558
Cumulative Timesteps: 1,539,231,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.92967
Policy Entropy: 2.42405
Value Function Loss: 0.01711

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.56594

Collected Steps per Second: 23,208.12478
Overall Steps per Second: 10,946.04671

Timestep Collection Time: 2.15450
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.56804

Cumulative Model Updates: 184,564
Cumulative Timesteps: 1,539,281,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1539281910...
Checkpoint 1539281910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.22046
Policy Entropy: 2.44278
Value Function Loss: 0.01646

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.57157
Value Function Update Magnitude: 0.56255

Collected Steps per Second: 23,025.54225
Overall Steps per Second: 10,936.78294

Timestep Collection Time: 2.17176
Timestep Consumption Time: 2.40051
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.57228

Cumulative Model Updates: 184,570
Cumulative Timesteps: 1,539,331,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.83139
Policy Entropy: 2.44221
Value Function Loss: 0.01528

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.53683

Collected Steps per Second: 21,954.64562
Overall Steps per Second: 10,692.51307

Timestep Collection Time: 2.27806
Timestep Consumption Time: 2.39942
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.67748

Cumulative Model Updates: 184,576
Cumulative Timesteps: 1,539,381,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1539381930...
Checkpoint 1539381930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.27400
Policy Entropy: 2.43949
Value Function Loss: 0.01484

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.53239

Collected Steps per Second: 22,933.00101
Overall Steps per Second: 10,699.03209

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.67594

Cumulative Model Updates: 184,582
Cumulative Timesteps: 1,539,431,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.02693
Policy Entropy: 2.45033
Value Function Loss: 0.01426

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.56109

Collected Steps per Second: 22,463.40368
Overall Steps per Second: 10,618.59729

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.71117

Cumulative Model Updates: 184,588
Cumulative Timesteps: 1,539,481,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1539481984...
Checkpoint 1539481984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.52207
Policy Entropy: 2.44527
Value Function Loss: 0.01418

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.54984

Collected Steps per Second: 22,746.21826
Overall Steps per Second: 10,873.83982

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.40002
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59819

Cumulative Model Updates: 184,594
Cumulative Timesteps: 1,539,531,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.87010
Policy Entropy: 2.42102
Value Function Loss: 0.01441

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 23,059.14697
Overall Steps per Second: 10,892.27035

Timestep Collection Time: 2.16877
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.59133

Cumulative Model Updates: 184,600
Cumulative Timesteps: 1,539,581,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1539581994...
Checkpoint 1539581994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.80739
Policy Entropy: 2.40690
Value Function Loss: 0.01568

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.58796

Collected Steps per Second: 23,564.69661
Overall Steps per Second: 10,996.49031

Timestep Collection Time: 2.12216
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.54763

Cumulative Model Updates: 184,606
Cumulative Timesteps: 1,539,632,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.61052
Policy Entropy: 2.40582
Value Function Loss: 0.01558

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.59458

Collected Steps per Second: 22,428.83517
Overall Steps per Second: 10,547.40358

Timestep Collection Time: 2.23034
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74278

Cumulative Model Updates: 184,612
Cumulative Timesteps: 1,539,682,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1539682026...
Checkpoint 1539682026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.57222
Policy Entropy: 2.43206
Value Function Loss: 0.01563

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.58622

Collected Steps per Second: 22,874.01068
Overall Steps per Second: 10,623.20118

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.52140
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.70781

Cumulative Model Updates: 184,618
Cumulative Timesteps: 1,539,732,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.10236
Policy Entropy: 2.45476
Value Function Loss: 0.01458

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 23,195.77886
Overall Steps per Second: 10,959.39309

Timestep Collection Time: 2.15591
Timestep Consumption Time: 2.40712
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.56303

Cumulative Model Updates: 184,624
Cumulative Timesteps: 1,539,782,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1539782046...
Checkpoint 1539782046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.74819
Policy Entropy: 2.45048
Value Function Loss: 0.01497

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.55016

Collected Steps per Second: 23,201.59239
Overall Steps per Second: 11,138.24319

Timestep Collection Time: 2.15520
Timestep Consumption Time: 2.33420
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.48940

Cumulative Model Updates: 184,630
Cumulative Timesteps: 1,539,832,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.52803
Policy Entropy: 2.44311
Value Function Loss: 0.01438

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.55937

Collected Steps per Second: 22,991.29525
Overall Steps per Second: 10,851.01403

Timestep Collection Time: 2.17482
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60805

Cumulative Model Updates: 184,636
Cumulative Timesteps: 1,539,882,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1539882052...
Checkpoint 1539882052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.08004
Policy Entropy: 2.44518
Value Function Loss: 0.01459

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.56958

Collected Steps per Second: 22,814.72340
Overall Steps per Second: 10,700.85556

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.67514

Cumulative Model Updates: 184,642
Cumulative Timesteps: 1,539,932,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.37906
Policy Entropy: 2.45237
Value Function Loss: 0.01465

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.57543

Collected Steps per Second: 22,730.30364
Overall Steps per Second: 10,669.33568

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68708

Cumulative Model Updates: 184,648
Cumulative Timesteps: 1,539,982,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1539982088...
Checkpoint 1539982088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.11801
Policy Entropy: 2.45318
Value Function Loss: 0.01601

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.57182
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 22,844.12301
Overall Steps per Second: 10,765.59945

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.64535

Cumulative Model Updates: 184,654
Cumulative Timesteps: 1,540,032,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.98390
Policy Entropy: 2.42251
Value Function Loss: 0.01561

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.57680
Value Function Update Magnitude: 0.58051

Collected Steps per Second: 22,902.08760
Overall Steps per Second: 10,697.64208

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.67598

Cumulative Model Updates: 184,660
Cumulative Timesteps: 1,540,082,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1540082120...
Checkpoint 1540082120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.48763
Policy Entropy: 2.40744
Value Function Loss: 0.01594

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.57111

Collected Steps per Second: 23,106.53938
Overall Steps per Second: 10,969.80444

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.39513
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.55997

Cumulative Model Updates: 184,666
Cumulative Timesteps: 1,540,132,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.99421
Policy Entropy: 2.39436
Value Function Loss: 0.01575

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 23,487.55762
Overall Steps per Second: 10,911.67722

Timestep Collection Time: 2.12947
Timestep Consumption Time: 2.45425
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.58371

Cumulative Model Updates: 184,672
Cumulative Timesteps: 1,540,182,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1540182158...
Checkpoint 1540182158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.00527
Policy Entropy: 2.41091
Value Function Loss: 0.01575

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 23,253.26958
Overall Steps per Second: 10,769.87600

Timestep Collection Time: 2.15067
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.64351

Cumulative Model Updates: 184,678
Cumulative Timesteps: 1,540,232,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.63661
Policy Entropy: 2.41685
Value Function Loss: 0.01512

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.17651
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 23,033.12417
Overall Steps per Second: 10,773.16627

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.64283

Cumulative Model Updates: 184,684
Cumulative Timesteps: 1,540,282,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1540282186...
Checkpoint 1540282186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.16534
Policy Entropy: 2.43669
Value Function Loss: 0.01612

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.18334
Policy Update Magnitude: 0.51712
Value Function Update Magnitude: 0.57313

Collected Steps per Second: 22,795.26336
Overall Steps per Second: 10,699.31217

Timestep Collection Time: 2.19405
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67451

Cumulative Model Updates: 184,690
Cumulative Timesteps: 1,540,332,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.37020
Policy Entropy: 2.42471
Value Function Loss: 0.01522

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.17863
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,672.91394
Overall Steps per Second: 10,811.08719

Timestep Collection Time: 2.20651
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62747

Cumulative Model Updates: 184,696
Cumulative Timesteps: 1,540,382,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1540382228...
Checkpoint 1540382228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.34620
Policy Entropy: 2.42981
Value Function Loss: 0.01557

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.16781
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,580.40668
Overall Steps per Second: 10,815.88481

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.40852
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.62283

Cumulative Model Updates: 184,702
Cumulative Timesteps: 1,540,432,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.78726
Policy Entropy: 2.41460
Value Function Loss: 0.01419

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.57138

Collected Steps per Second: 22,628.73658
Overall Steps per Second: 10,791.75817

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.63354

Cumulative Model Updates: 184,708
Cumulative Timesteps: 1,540,482,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1540482232...
Checkpoint 1540482232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.25929
Policy Entropy: 2.40940
Value Function Loss: 0.01560

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.56214

Collected Steps per Second: 22,658.54935
Overall Steps per Second: 10,605.97380

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.71432

Cumulative Model Updates: 184,714
Cumulative Timesteps: 1,540,532,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.32314
Policy Entropy: 2.42830
Value Function Loss: 0.01522

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.56942
Value Function Update Magnitude: 0.57382

Collected Steps per Second: 23,307.88837
Overall Steps per Second: 10,856.63840

Timestep Collection Time: 2.14545
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60603

Cumulative Model Updates: 184,720
Cumulative Timesteps: 1,540,582,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1540582238...
Checkpoint 1540582238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.66697
Policy Entropy: 2.42369
Value Function Loss: 0.01541

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.56993

Collected Steps per Second: 23,131.77742
Overall Steps per Second: 10,800.96832

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.63144

Cumulative Model Updates: 184,726
Cumulative Timesteps: 1,540,632,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.95276
Policy Entropy: 2.41679
Value Function Loss: 0.01540

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.58505

Collected Steps per Second: 23,248.14562
Overall Steps per Second: 10,928.99662

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.57517

Cumulative Model Updates: 184,732
Cumulative Timesteps: 1,540,682,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1540682264...
Checkpoint 1540682264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.89942
Policy Entropy: 2.38038
Value Function Loss: 0.01512

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.60035

Collected Steps per Second: 23,335.10339
Overall Steps per Second: 10,929.44598

Timestep Collection Time: 2.14381
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.57718

Cumulative Model Updates: 184,738
Cumulative Timesteps: 1,540,732,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.14223
Policy Entropy: 2.39214
Value Function Loss: 0.01616

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.58980

Collected Steps per Second: 23,319.97157
Overall Steps per Second: 10,924.56636

Timestep Collection Time: 2.14443
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.57757

Cumulative Model Updates: 184,744
Cumulative Timesteps: 1,540,782,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1540782298...
Checkpoint 1540782298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.95494
Policy Entropy: 2.40596
Value Function Loss: 0.01553

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 22,831.80083
Overall Steps per Second: 10,674.97129

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.68404

Cumulative Model Updates: 184,750
Cumulative Timesteps: 1,540,832,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.90566
Policy Entropy: 2.41532
Value Function Loss: 0.01568

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.55349
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 22,772.95045
Overall Steps per Second: 10,838.69365

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61495

Cumulative Model Updates: 184,756
Cumulative Timesteps: 1,540,882,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1540882320...
Checkpoint 1540882320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.44016
Policy Entropy: 2.41205
Value Function Loss: 0.01516

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.57458

Collected Steps per Second: 22,960.63845
Overall Steps per Second: 10,914.93203

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.40334
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.58106

Cumulative Model Updates: 184,762
Cumulative Timesteps: 1,540,932,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.97620
Policy Entropy: 2.41168
Value Function Loss: 0.01525

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.56610

Collected Steps per Second: 22,343.71896
Overall Steps per Second: 10,717.98452

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.66599

Cumulative Model Updates: 184,768
Cumulative Timesteps: 1,540,982,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1540982332...
Checkpoint 1540982332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.54583
Policy Entropy: 2.40330
Value Function Loss: 0.01584

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.58317

Collected Steps per Second: 23,131.27493
Overall Steps per Second: 10,761.58876

Timestep Collection Time: 2.16209
Timestep Consumption Time: 2.48517
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.64727

Cumulative Model Updates: 184,774
Cumulative Timesteps: 1,541,032,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.02605
Policy Entropy: 2.40859
Value Function Loss: 0.01600

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.64373

Collected Steps per Second: 23,318.95628
Overall Steps per Second: 10,767.14521

Timestep Collection Time: 2.14444
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.64431

Cumulative Model Updates: 184,780
Cumulative Timesteps: 1,541,082,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1541082350...
Checkpoint 1541082350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.33689
Policy Entropy: 2.41227
Value Function Loss: 0.01695

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.64472

Collected Steps per Second: 22,976.21330
Overall Steps per Second: 10,766.30506

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.46914
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.64635

Cumulative Model Updates: 184,786
Cumulative Timesteps: 1,541,132,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.41533
Policy Entropy: 2.40628
Value Function Loss: 0.01710

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.57930
Value Function Update Magnitude: 0.62543

Collected Steps per Second: 23,359.40781
Overall Steps per Second: 10,828.25479

Timestep Collection Time: 2.14175
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.62032

Cumulative Model Updates: 184,792
Cumulative Timesteps: 1,541,182,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1541182404...
Checkpoint 1541182404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.24075
Policy Entropy: 2.39198
Value Function Loss: 0.01646

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.62717

Collected Steps per Second: 23,143.26254
Overall Steps per Second: 11,131.56789

Timestep Collection Time: 2.16054
Timestep Consumption Time: 2.33137
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.49191

Cumulative Model Updates: 184,798
Cumulative Timesteps: 1,541,232,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.51072
Policy Entropy: 2.36945
Value Function Loss: 0.01583

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.61790

Collected Steps per Second: 22,177.44376
Overall Steps per Second: 10,366.82597

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.56894
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.82385

Cumulative Model Updates: 184,804
Cumulative Timesteps: 1,541,282,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1541282414...
Checkpoint 1541282414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.37516
Policy Entropy: 2.37429
Value Function Loss: 0.01663

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.59606
Value Function Update Magnitude: 0.61344

Collected Steps per Second: 22,457.18182
Overall Steps per Second: 10,621.16075

Timestep Collection Time: 2.22655
Timestep Consumption Time: 2.48122
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.70777

Cumulative Model Updates: 184,810
Cumulative Timesteps: 1,541,332,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.48662
Policy Entropy: 2.38066
Value Function Loss: 0.01583

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,737.54143
Overall Steps per Second: 10,686.21016

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.68005

Cumulative Model Updates: 184,816
Cumulative Timesteps: 1,541,382,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1541382428...
Checkpoint 1541382428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.36319
Policy Entropy: 2.38375
Value Function Loss: 0.01606

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.59669

Collected Steps per Second: 22,787.29187
Overall Steps per Second: 10,876.42215

Timestep Collection Time: 2.19517
Timestep Consumption Time: 2.40395
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59912

Cumulative Model Updates: 184,822
Cumulative Timesteps: 1,541,432,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.36936
Policy Entropy: 2.37858
Value Function Loss: 0.01546

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.58669
Value Function Update Magnitude: 0.60205

Collected Steps per Second: 22,983.46287
Overall Steps per Second: 10,827.49255

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61861

Cumulative Model Updates: 184,828
Cumulative Timesteps: 1,541,482,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1541482458...
Checkpoint 1541482458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.99435
Policy Entropy: 2.37217
Value Function Loss: 0.01594

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 23,038.73256
Overall Steps per Second: 10,896.73788

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.41943
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.59073

Cumulative Model Updates: 184,834
Cumulative Timesteps: 1,541,532,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.95460
Policy Entropy: 2.38780
Value Function Loss: 0.01512

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.18524
Policy Update Magnitude: 0.52336
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 23,817.75711
Overall Steps per Second: 10,918.00985

Timestep Collection Time: 2.09978
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.58069

Cumulative Model Updates: 184,840
Cumulative Timesteps: 1,541,582,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1541582494...
Checkpoint 1541582494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.91191
Policy Entropy: 2.40477
Value Function Loss: 0.01481

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.58266

Collected Steps per Second: 23,363.40580
Overall Steps per Second: 10,973.41206

Timestep Collection Time: 2.14138
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.55920

Cumulative Model Updates: 184,846
Cumulative Timesteps: 1,541,632,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.31378
Policy Entropy: 2.40652
Value Function Loss: 0.01424

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.57837

Collected Steps per Second: 23,155.33608
Overall Steps per Second: 10,876.37665

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.59841

Cumulative Model Updates: 184,852
Cumulative Timesteps: 1,541,682,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1541682538...
Checkpoint 1541682538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.73444
Policy Entropy: 2.39727
Value Function Loss: 0.01484

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 23,189.07864
Overall Steps per Second: 10,841.26228

Timestep Collection Time: 2.15739
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.61459

Cumulative Model Updates: 184,858
Cumulative Timesteps: 1,541,732,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.40497
Policy Entropy: 2.38162
Value Function Loss: 0.01483

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.56849
Value Function Update Magnitude: 0.59373

Collected Steps per Second: 22,823.52134
Overall Steps per Second: 10,886.64577

Timestep Collection Time: 2.19186
Timestep Consumption Time: 2.40331
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.59517

Cumulative Model Updates: 184,864
Cumulative Timesteps: 1,541,782,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1541782592...
Checkpoint 1541782592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.75005
Policy Entropy: 2.36256
Value Function Loss: 0.01667

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.58934
Value Function Update Magnitude: 0.57709

Collected Steps per Second: 22,834.55520
Overall Steps per Second: 10,853.36191

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60889

Cumulative Model Updates: 184,870
Cumulative Timesteps: 1,541,832,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.61187
Policy Entropy: 2.34350
Value Function Loss: 0.01733

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.60426
Value Function Update Magnitude: 0.59720

Collected Steps per Second: 22,853.24417
Overall Steps per Second: 10,696.43625

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67595

Cumulative Model Updates: 184,876
Cumulative Timesteps: 1,541,882,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1541882630...
Checkpoint 1541882630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.74820
Policy Entropy: 2.34847
Value Function Loss: 0.01813

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.61100
Value Function Update Magnitude: 0.63118

Collected Steps per Second: 22,898.97719
Overall Steps per Second: 10,718.31707

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.66752

Cumulative Model Updates: 184,882
Cumulative Timesteps: 1,541,932,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.22870
Policy Entropy: 2.36895
Value Function Loss: 0.01690

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.58542
Value Function Update Magnitude: 0.64156

Collected Steps per Second: 23,510.32844
Overall Steps per Second: 10,807.72274

Timestep Collection Time: 2.12690
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.62669

Cumulative Model Updates: 184,888
Cumulative Timesteps: 1,541,982,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1541982662...
Checkpoint 1541982662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.32168
Policy Entropy: 2.38747
Value Function Loss: 0.01643

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.62013

Collected Steps per Second: 23,056.86560
Overall Steps per Second: 10,975.39946

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.38805
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.55747

Cumulative Model Updates: 184,894
Cumulative Timesteps: 1,542,032,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.72108
Policy Entropy: 2.42268
Value Function Loss: 0.01573

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.16480
Policy Update Magnitude: 0.57336
Value Function Update Magnitude: 0.59006

Collected Steps per Second: 23,195.43354
Overall Steps per Second: 10,928.38941

Timestep Collection Time: 2.15560
Timestep Consumption Time: 2.41964
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.57524

Cumulative Model Updates: 184,900
Cumulative Timesteps: 1,542,082,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1542082682...
Checkpoint 1542082682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.52395
Policy Entropy: 2.42225
Value Function Loss: 0.01540

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.57821

Collected Steps per Second: 23,335.03438
Overall Steps per Second: 10,817.72048

Timestep Collection Time: 2.14339
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.62352

Cumulative Model Updates: 184,906
Cumulative Timesteps: 1,542,132,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.41515
Policy Entropy: 2.43874
Value Function Loss: 0.01499

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.56124

Collected Steps per Second: 23,066.60349
Overall Steps per Second: 10,682.83236

Timestep Collection Time: 2.16772
Timestep Consumption Time: 2.51287
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68059

Cumulative Model Updates: 184,912
Cumulative Timesteps: 1,542,182,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1542182700...
Checkpoint 1542182700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.91953
Policy Entropy: 2.39251
Value Function Loss: 0.01601

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.56126
Value Function Update Magnitude: 0.55754

Collected Steps per Second: 23,047.18554
Overall Steps per Second: 10,775.35901

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64189

Cumulative Model Updates: 184,918
Cumulative Timesteps: 1,542,232,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.96101
Policy Entropy: 2.39123
Value Function Loss: 0.01644

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.56247

Collected Steps per Second: 22,973.37140
Overall Steps per Second: 10,857.13801

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.60674

Cumulative Model Updates: 184,924
Cumulative Timesteps: 1,542,282,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1542282734...
Checkpoint 1542282734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.79968
Policy Entropy: 2.40150
Value Function Loss: 0.01635

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.58240

Collected Steps per Second: 22,530.95539
Overall Steps per Second: 10,562.23673

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.73385

Cumulative Model Updates: 184,930
Cumulative Timesteps: 1,542,332,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.46290
Policy Entropy: 2.41879
Value Function Loss: 0.01548

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.57688

Collected Steps per Second: 23,044.69972
Overall Steps per Second: 10,853.99790

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60678

Cumulative Model Updates: 184,936
Cumulative Timesteps: 1,542,382,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1542382736...
Checkpoint 1542382736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.07283
Policy Entropy: 2.40633
Value Function Loss: 0.01606

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.57804

Collected Steps per Second: 22,774.52248
Overall Steps per Second: 10,697.16374

Timestep Collection Time: 2.19587
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.67507

Cumulative Model Updates: 184,942
Cumulative Timesteps: 1,542,432,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.76356
Policy Entropy: 2.38554
Value Function Loss: 0.01516

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 23,189.73292
Overall Steps per Second: 10,859.11450

Timestep Collection Time: 2.15613
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60443

Cumulative Model Updates: 184,948
Cumulative Timesteps: 1,542,482,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1542482746...
Checkpoint 1542482746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.67720
Policy Entropy: 2.38776
Value Function Loss: 0.01488

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 22,597.02385
Overall Steps per Second: 10,637.31197

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.48825
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70138

Cumulative Model Updates: 184,954
Cumulative Timesteps: 1,542,532,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.24794
Policy Entropy: 2.38736
Value Function Loss: 0.01522

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.58852

Collected Steps per Second: 22,429.29692
Overall Steps per Second: 10,901.09150

Timestep Collection Time: 2.22967
Timestep Consumption Time: 2.35794
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58761

Cumulative Model Updates: 184,960
Cumulative Timesteps: 1,542,582,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1542582766...
Checkpoint 1542582766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.78327
Policy Entropy: 2.40319
Value Function Loss: 0.01571

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.59534

Collected Steps per Second: 23,059.41772
Overall Steps per Second: 10,720.42136

Timestep Collection Time: 2.16892
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.66530

Cumulative Model Updates: 184,966
Cumulative Timesteps: 1,542,632,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.11102
Policy Entropy: 2.41401
Value Function Loss: 0.01572

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.57887

Collected Steps per Second: 23,195.92409
Overall Steps per Second: 10,901.36740

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.43229
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.58897

Cumulative Model Updates: 184,972
Cumulative Timesteps: 1,542,682,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1542682806...
Checkpoint 1542682806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.87136
Policy Entropy: 2.40311
Value Function Loss: 0.01482

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.56105

Collected Steps per Second: 23,041.54682
Overall Steps per Second: 10,721.25563

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.49484
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66587

Cumulative Model Updates: 184,978
Cumulative Timesteps: 1,542,732,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.62488
Policy Entropy: 2.39978
Value Function Loss: 0.01440

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 22,929.46622
Overall Steps per Second: 10,837.08697

Timestep Collection Time: 2.18147
Timestep Consumption Time: 2.43416
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.61563

Cumulative Model Updates: 184,984
Cumulative Timesteps: 1,542,782,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1542782850...
Checkpoint 1542782850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.74501
Policy Entropy: 2.40173
Value Function Loss: 0.01492

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.56932

Collected Steps per Second: 22,830.52402
Overall Steps per Second: 10,727.48652

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.47206
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.66316

Cumulative Model Updates: 184,990
Cumulative Timesteps: 1,542,832,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.89810
Policy Entropy: 2.39823
Value Function Loss: 0.01536

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.57121
Value Function Update Magnitude: 0.56902

Collected Steps per Second: 22,350.25310
Overall Steps per Second: 10,797.98360

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.39357
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.63086

Cumulative Model Updates: 184,996
Cumulative Timesteps: 1,542,882,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1542882878...
Checkpoint 1542882878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.10949
Policy Entropy: 2.40566
Value Function Loss: 0.01596

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.56617

Collected Steps per Second: 22,725.64171
Overall Steps per Second: 10,615.49422

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.51004
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.71028

Cumulative Model Updates: 185,002
Cumulative Timesteps: 1,542,932,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.51935
Policy Entropy: 2.39405
Value Function Loss: 0.01588

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.57990

Collected Steps per Second: 23,275.57112
Overall Steps per Second: 10,853.70771

Timestep Collection Time: 2.14818
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60672

Cumulative Model Updates: 185,008
Cumulative Timesteps: 1,542,982,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1542982880...
Checkpoint 1542982880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.53973
Policy Entropy: 2.39315
Value Function Loss: 0.01689

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.58917

Collected Steps per Second: 22,953.26469
Overall Steps per Second: 10,731.53819

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.66159

Cumulative Model Updates: 185,014
Cumulative Timesteps: 1,543,032,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.43739
Policy Entropy: 2.39090
Value Function Loss: 0.01639

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.57616

Collected Steps per Second: 23,412.82581
Overall Steps per Second: 10,907.60525

Timestep Collection Time: 2.13558
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.58396

Cumulative Model Updates: 185,020
Cumulative Timesteps: 1,543,082,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1543082906...
Checkpoint 1543082906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.29156
Policy Entropy: 2.40130
Value Function Loss: 0.01620

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 23,137.69300
Overall Steps per Second: 11,053.14725

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.36376
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.52577

Cumulative Model Updates: 185,026
Cumulative Timesteps: 1,543,132,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.77647
Policy Entropy: 2.39610
Value Function Loss: 0.01558

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.18906
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 23,386.15861
Overall Steps per Second: 10,931.19338

Timestep Collection Time: 2.13802
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.57407

Cumulative Model Updates: 185,032
Cumulative Timesteps: 1,543,182,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1543182930...
Checkpoint 1543182930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.38868
Policy Entropy: 2.40244
Value Function Loss: 0.01553

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 21,460.12519
Overall Steps per Second: 10,288.70138

Timestep Collection Time: 2.33065
Timestep Consumption Time: 2.53061
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.86125

Cumulative Model Updates: 185,038
Cumulative Timesteps: 1,543,232,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.82913
Policy Entropy: 2.39268
Value Function Loss: 0.01479

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.55280

Collected Steps per Second: 22,201.45407
Overall Steps per Second: 10,487.40167

Timestep Collection Time: 2.25292
Timestep Consumption Time: 2.51643
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.76934

Cumulative Model Updates: 185,044
Cumulative Timesteps: 1,543,282,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1543282964...
Checkpoint 1543282964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.81839
Policy Entropy: 2.38907
Value Function Loss: 0.01506

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.54755

Collected Steps per Second: 22,546.61826
Overall Steps per Second: 10,656.40079

Timestep Collection Time: 2.21816
Timestep Consumption Time: 2.47498
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.69314

Cumulative Model Updates: 185,050
Cumulative Timesteps: 1,543,332,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.57346
Policy Entropy: 2.37345
Value Function Loss: 0.01483

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.56174
Value Function Update Magnitude: 0.54214

Collected Steps per Second: 23,047.64407
Overall Steps per Second: 10,873.30485

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.60026

Cumulative Model Updates: 185,056
Cumulative Timesteps: 1,543,382,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1543382996...
Checkpoint 1543382996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.22582
Policy Entropy: 2.38025
Value Function Loss: 0.01530

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.54721

Collected Steps per Second: 22,376.33131
Overall Steps per Second: 10,713.78068

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66801

Cumulative Model Updates: 185,062
Cumulative Timesteps: 1,543,433,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.21848
Policy Entropy: 2.36814
Value Function Loss: 0.01688

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.58066

Collected Steps per Second: 23,466.13763
Overall Steps per Second: 10,773.62629

Timestep Collection Time: 2.13116
Timestep Consumption Time: 2.51074
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.64189

Cumulative Model Updates: 185,068
Cumulative Timesteps: 1,543,483,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1543483018...
Checkpoint 1543483018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.78740
Policy Entropy: 2.38726
Value Function Loss: 0.01675

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.59194
Value Function Update Magnitude: 0.62542

Collected Steps per Second: 22,929.57009
Overall Steps per Second: 10,667.37586

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.68813

Cumulative Model Updates: 185,074
Cumulative Timesteps: 1,543,533,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.67689
Policy Entropy: 2.34243
Value Function Loss: 0.01712

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.64642

Collected Steps per Second: 23,423.38537
Overall Steps per Second: 10,854.62084

Timestep Collection Time: 2.13547
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.60818

Cumulative Model Updates: 185,080
Cumulative Timesteps: 1,543,583,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1543583048...
Checkpoint 1543583048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.84373
Policy Entropy: 2.31637
Value Function Loss: 0.01770

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.15409
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.63051

Collected Steps per Second: 22,877.55978
Overall Steps per Second: 11,019.80302

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.35268
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.53910

Cumulative Model Updates: 185,086
Cumulative Timesteps: 1,543,633,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.08553
Policy Entropy: 2.33079
Value Function Loss: 0.01631

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.61079

Collected Steps per Second: 22,976.20549
Overall Steps per Second: 10,728.17861

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.48535
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66230

Cumulative Model Updates: 185,092
Cumulative Timesteps: 1,543,683,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1543683086...
Checkpoint 1543683086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.91718
Policy Entropy: 2.36202
Value Function Loss: 0.01568

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.57244
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 22,795.60574
Overall Steps per Second: 10,821.21534

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62314

Cumulative Model Updates: 185,098
Cumulative Timesteps: 1,543,733,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.67353
Policy Entropy: 2.39806
Value Function Loss: 0.01460

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.57478

Collected Steps per Second: 22,662.12016
Overall Steps per Second: 10,617.70427

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70912

Cumulative Model Updates: 185,104
Cumulative Timesteps: 1,543,783,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1543783114...
Checkpoint 1543783114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.22103
Policy Entropy: 2.38289
Value Function Loss: 0.01529

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.57029

Collected Steps per Second: 22,845.74126
Overall Steps per Second: 10,769.81822

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.45421
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.64298

Cumulative Model Updates: 185,110
Cumulative Timesteps: 1,543,833,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.90752
Policy Entropy: 2.37785
Value Function Loss: 0.01550

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.56462
Value Function Update Magnitude: 0.56588

Collected Steps per Second: 23,024.08911
Overall Steps per Second: 10,911.17758

Timestep Collection Time: 2.17207
Timestep Consumption Time: 2.41130
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.58337

Cumulative Model Updates: 185,116
Cumulative Timesteps: 1,543,883,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1543883128...
Checkpoint 1543883128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.65308
Policy Entropy: 2.36056
Value Function Loss: 0.01512

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.56923
Value Function Update Magnitude: 0.56411

Collected Steps per Second: 23,110.64429
Overall Steps per Second: 10,804.11403

Timestep Collection Time: 2.16385
Timestep Consumption Time: 2.46476
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62861

Cumulative Model Updates: 185,122
Cumulative Timesteps: 1,543,933,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.92537
Policy Entropy: 2.35782
Value Function Loss: 0.01554

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.58691

Collected Steps per Second: 23,190.74207
Overall Steps per Second: 10,836.87124

Timestep Collection Time: 2.15629
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.61443

Cumulative Model Updates: 185,128
Cumulative Timesteps: 1,543,983,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1543983142...
Checkpoint 1543983142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.26693
Policy Entropy: 2.35683
Value Function Loss: 0.01534

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 22,687.27882
Overall Steps per Second: 10,758.90260

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.44373
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.64787

Cumulative Model Updates: 185,134
Cumulative Timesteps: 1,544,033,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.98739
Policy Entropy: 2.37385
Value Function Loss: 0.01587

Mean KL Divergence: 0.02387
SB3 Clip Fraction: 0.17322
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.60565

Collected Steps per Second: 23,211.76155
Overall Steps per Second: 10,966.09224

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.40562
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.55987

Cumulative Model Updates: 185,140
Cumulative Timesteps: 1,544,083,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1544083152...
Checkpoint 1544083152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.53499
Policy Entropy: 2.35893
Value Function Loss: 0.01587

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.16848
Policy Update Magnitude: 0.54038
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 22,920.70654
Overall Steps per Second: 10,740.30759

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.47492
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.65722

Cumulative Model Updates: 185,146
Cumulative Timesteps: 1,544,133,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.22148
Policy Entropy: 2.35317
Value Function Loss: 0.01611

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.61418

Collected Steps per Second: 23,279.54190
Overall Steps per Second: 10,986.36205

Timestep Collection Time: 2.14789
Timestep Consumption Time: 2.40338
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.55128

Cumulative Model Updates: 185,152
Cumulative Timesteps: 1,544,183,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1544183174...
Checkpoint 1544183174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.49193
Policy Entropy: 2.34328
Value Function Loss: 0.01545

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.58113
Value Function Update Magnitude: 0.62597

Collected Steps per Second: 22,847.82423
Overall Steps per Second: 10,858.69355

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.41679
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60571

Cumulative Model Updates: 185,158
Cumulative Timesteps: 1,544,233,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.69325
Policy Entropy: 2.34356
Value Function Loss: 0.01554

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.59996

Collected Steps per Second: 22,900.02814
Overall Steps per Second: 10,696.10941

Timestep Collection Time: 2.18454
Timestep Consumption Time: 2.49249
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67703

Cumulative Model Updates: 185,164
Cumulative Timesteps: 1,544,283,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1544283212...
Checkpoint 1544283212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.98653
Policy Entropy: 2.34449
Value Function Loss: 0.01523

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.56760
Value Function Update Magnitude: 0.59344

Collected Steps per Second: 22,934.05576
Overall Steps per Second: 10,820.54814

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62139

Cumulative Model Updates: 185,170
Cumulative Timesteps: 1,544,333,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.08982
Policy Entropy: 2.34680
Value Function Loss: 0.01555

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.56718
Value Function Update Magnitude: 0.61438

Collected Steps per Second: 22,611.42730
Overall Steps per Second: 10,660.27789

Timestep Collection Time: 2.21233
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.69256

Cumulative Model Updates: 185,176
Cumulative Timesteps: 1,544,383,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1544383242...
Checkpoint 1544383242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.49288
Policy Entropy: 2.33569
Value Function Loss: 0.01574

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.63345

Collected Steps per Second: 23,086.11525
Overall Steps per Second: 10,975.78461

Timestep Collection Time: 2.16589
Timestep Consumption Time: 2.38977
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.55567

Cumulative Model Updates: 185,182
Cumulative Timesteps: 1,544,433,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.61082
Policy Entropy: 2.34253
Value Function Loss: 0.01599

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.65730

Collected Steps per Second: 22,682.48145
Overall Steps per Second: 10,912.50725

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.37812
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.58300

Cumulative Model Updates: 185,188
Cumulative Timesteps: 1,544,483,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1544483256...
Checkpoint 1544483256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.08966
Policy Entropy: 2.34370
Value Function Loss: 0.01565

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.58293
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 23,350.40017
Overall Steps per Second: 10,826.36991

Timestep Collection Time: 2.14258
Timestep Consumption Time: 2.47855
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.62112

Cumulative Model Updates: 185,194
Cumulative Timesteps: 1,544,533,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.68285
Policy Entropy: 2.36688
Value Function Loss: 0.01498

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.64383

Collected Steps per Second: 23,527.01646
Overall Steps per Second: 10,795.18500

Timestep Collection Time: 2.12573
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.63281

Cumulative Model Updates: 185,200
Cumulative Timesteps: 1,544,583,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1544583298...
Checkpoint 1544583298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.84421
Policy Entropy: 2.34367
Value Function Loss: 0.01463

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 22,894.58826
Overall Steps per Second: 10,914.50023

Timestep Collection Time: 2.18558
Timestep Consumption Time: 2.39896
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58454

Cumulative Model Updates: 185,206
Cumulative Timesteps: 1,544,633,336

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.10824
Policy Entropy: 2.34641
Value Function Loss: 0.01478

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.56413
Value Function Update Magnitude: 0.62914

Collected Steps per Second: 22,820.78375
Overall Steps per Second: 10,989.51540

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.35947
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.55107

Cumulative Model Updates: 185,212
Cumulative Timesteps: 1,544,683,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1544683350...
Checkpoint 1544683350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.51072
Policy Entropy: 2.32908
Value Function Loss: 0.01408

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.65237

Collected Steps per Second: 21,793.61675
Overall Steps per Second: 10,653.82242

Timestep Collection Time: 2.29443
Timestep Consumption Time: 2.39909
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.69353

Cumulative Model Updates: 185,218
Cumulative Timesteps: 1,544,733,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.41137
Policy Entropy: 2.33359
Value Function Loss: 0.01413

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.61922

Collected Steps per Second: 23,108.93720
Overall Steps per Second: 10,879.15309

Timestep Collection Time: 2.16392
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.59650

Cumulative Model Updates: 185,224
Cumulative Timesteps: 1,544,783,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1544783360...
Checkpoint 1544783360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.52460
Policy Entropy: 2.34475
Value Function Loss: 0.01435

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.58248

Collected Steps per Second: 22,828.94246
Overall Steps per Second: 10,671.52628

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.68537

Cumulative Model Updates: 185,230
Cumulative Timesteps: 1,544,833,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.07801
Policy Entropy: 2.33652
Value Function Loss: 0.01527

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.58251

Collected Steps per Second: 23,237.06943
Overall Steps per Second: 10,855.75805

Timestep Collection Time: 2.15294
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.60843

Cumulative Model Updates: 185,236
Cumulative Timesteps: 1,544,883,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1544883388...
Checkpoint 1544883388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.81165
Policy Entropy: 2.33869
Value Function Loss: 0.01635

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.18011
Policy Update Magnitude: 0.51733
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 22,869.99398
Overall Steps per Second: 10,670.71245

Timestep Collection Time: 2.18645
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68610

Cumulative Model Updates: 185,242
Cumulative Timesteps: 1,544,933,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.89715
Policy Entropy: 2.31787
Value Function Loss: 0.01616

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.17254
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 23,362.69323
Overall Steps per Second: 10,907.38778

Timestep Collection Time: 2.14128
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.58643

Cumulative Model Updates: 185,248
Cumulative Timesteps: 1,544,983,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1544983418...
Checkpoint 1544983418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.69242
Policy Entropy: 2.32454
Value Function Loss: 0.01671

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.63570

Collected Steps per Second: 22,987.87173
Overall Steps per Second: 10,686.77704

Timestep Collection Time: 2.17550
Timestep Consumption Time: 2.50412
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.67961

Cumulative Model Updates: 185,254
Cumulative Timesteps: 1,545,033,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.95693
Policy Entropy: 2.33765
Value Function Loss: 0.01543

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.65659

Collected Steps per Second: 23,368.61408
Overall Steps per Second: 10,907.98640

Timestep Collection Time: 2.14056
Timestep Consumption Time: 2.44525
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.58581

Cumulative Model Updates: 185,260
Cumulative Timesteps: 1,545,083,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1545083450...
Checkpoint 1545083450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.52552
Policy Entropy: 2.34404
Value Function Loss: 0.01476

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.64564

Collected Steps per Second: 22,784.22148
Overall Steps per Second: 10,632.17961

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.70496

Cumulative Model Updates: 185,266
Cumulative Timesteps: 1,545,133,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.32343
Policy Entropy: 2.36157
Value Function Loss: 0.01490

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.62705

Collected Steps per Second: 22,634.28798
Overall Steps per Second: 10,842.48605

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.40370
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.61389

Cumulative Model Updates: 185,272
Cumulative Timesteps: 1,545,183,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1545183500...
Checkpoint 1545183500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.66870
Policy Entropy: 2.35780
Value Function Loss: 0.01589

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.57317
Value Function Update Magnitude: 0.62312

Collected Steps per Second: 22,261.57065
Overall Steps per Second: 10,723.41085

Timestep Collection Time: 2.24665
Timestep Consumption Time: 2.41735
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.66400

Cumulative Model Updates: 185,278
Cumulative Timesteps: 1,545,233,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.23249
Policy Entropy: 2.37238
Value Function Loss: 0.01560

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.57111
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 23,173.29942
Overall Steps per Second: 10,883.21646

Timestep Collection Time: 2.15860
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.59625

Cumulative Model Updates: 185,284
Cumulative Timesteps: 1,545,283,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1545283536...
Checkpoint 1545283536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.93533
Policy Entropy: 2.35903
Value Function Loss: 0.01480

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.56861
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,826.19587
Overall Steps per Second: 10,673.88307

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.68695

Cumulative Model Updates: 185,290
Cumulative Timesteps: 1,545,333,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.50265
Policy Entropy: 2.37801
Value Function Loss: 0.01435

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 23,318.69461
Overall Steps per Second: 10,882.41596

Timestep Collection Time: 2.14463
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.59549

Cumulative Model Updates: 185,296
Cumulative Timesteps: 1,545,383,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1545383574...
Checkpoint 1545383574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.27885
Policy Entropy: 2.36991
Value Function Loss: 0.01462

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 22,963.32996
Overall Steps per Second: 10,713.17827

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.66939

Cumulative Model Updates: 185,302
Cumulative Timesteps: 1,545,433,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.06404
Policy Entropy: 2.36444
Value Function Loss: 0.01480

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 23,190.93781
Overall Steps per Second: 10,891.28409

Timestep Collection Time: 2.15627
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.59138

Cumulative Model Updates: 185,308
Cumulative Timesteps: 1,545,483,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1545483604...
Checkpoint 1545483604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.61793
Policy Entropy: 2.34950
Value Function Loss: 0.01504

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.56581
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 23,147.84702
Overall Steps per Second: 10,746.58089

Timestep Collection Time: 2.16011
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.65283

Cumulative Model Updates: 185,314
Cumulative Timesteps: 1,545,533,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.57844
Policy Entropy: 2.35640
Value Function Loss: 0.01481

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.62785

Collected Steps per Second: 23,581.58239
Overall Steps per Second: 10,821.43771

Timestep Collection Time: 2.12055
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.62101

Cumulative Model Updates: 185,320
Cumulative Timesteps: 1,545,583,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1545583612...
Checkpoint 1545583612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.56811
Policy Entropy: 2.35771
Value Function Loss: 0.01573

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.16007
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.60822

Collected Steps per Second: 22,445.59935
Overall Steps per Second: 10,608.33716

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.71554

Cumulative Model Updates: 185,326
Cumulative Timesteps: 1,545,633,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.15052
Policy Entropy: 2.35542
Value Function Loss: 0.01606

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.57205
Value Function Update Magnitude: 0.61844

Collected Steps per Second: 22,966.55094
Overall Steps per Second: 10,865.47687

Timestep Collection Time: 2.17804
Timestep Consumption Time: 2.42572
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60376

Cumulative Model Updates: 185,332
Cumulative Timesteps: 1,545,683,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1545683658...
Checkpoint 1545683658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.48416
Policy Entropy: 2.33622
Value Function Loss: 0.01604

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 22,753.84689
Overall Steps per Second: 10,865.81125

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.40502
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.60325

Cumulative Model Updates: 185,338
Cumulative Timesteps: 1,545,733,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.20812
Policy Entropy: 2.36855
Value Function Loss: 0.01379

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.56187
Value Function Update Magnitude: 0.62551

Collected Steps per Second: 23,766.94425
Overall Steps per Second: 10,844.36538

Timestep Collection Time: 2.10452
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.61235

Cumulative Model Updates: 185,344
Cumulative Timesteps: 1,545,783,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1545783694...
Checkpoint 1545783694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.31740
Policy Entropy: 2.35932
Value Function Loss: 0.01419

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.61395

Collected Steps per Second: 23,200.23143
Overall Steps per Second: 10,873.88162

Timestep Collection Time: 2.15636
Timestep Consumption Time: 2.44439
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60075

Cumulative Model Updates: 185,350
Cumulative Timesteps: 1,545,833,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.30780
Policy Entropy: 2.35585
Value Function Loss: 0.01366

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.55569
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 23,180.14351
Overall Steps per Second: 10,902.84933

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.43030
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58853

Cumulative Model Updates: 185,356
Cumulative Timesteps: 1,545,883,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1545883750...
Checkpoint 1545883750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.98489
Policy Entropy: 2.33723
Value Function Loss: 0.01419

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.57107

Collected Steps per Second: 22,947.73034
Overall Steps per Second: 10,725.97322

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66289

Cumulative Model Updates: 185,362
Cumulative Timesteps: 1,545,933,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.51182
Policy Entropy: 2.34026
Value Function Loss: 0.01541

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.57995

Collected Steps per Second: 23,501.05938
Overall Steps per Second: 10,980.81159

Timestep Collection Time: 2.12876
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.55595

Cumulative Model Updates: 185,368
Cumulative Timesteps: 1,545,983,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1545983792...
Checkpoint 1545983792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.92370
Policy Entropy: 2.34843
Value Function Loss: 0.01556

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.61174

Collected Steps per Second: 22,960.31789
Overall Steps per Second: 10,721.44273

Timestep Collection Time: 2.17898
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.66635

Cumulative Model Updates: 185,374
Cumulative Timesteps: 1,546,033,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.44561
Policy Entropy: 2.34998
Value Function Loss: 0.01578

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.63067

Collected Steps per Second: 22,272.73027
Overall Steps per Second: 10,708.94509

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.67161

Cumulative Model Updates: 185,380
Cumulative Timesteps: 1,546,083,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1546083850...
Checkpoint 1546083850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.93963
Policy Entropy: 2.34339
Value Function Loss: 0.01465

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.56692
Value Function Update Magnitude: 0.59677

Collected Steps per Second: 22,463.79985
Overall Steps per Second: 10,745.21268

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.65435

Cumulative Model Updates: 185,386
Cumulative Timesteps: 1,546,133,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.51964
Policy Entropy: 2.36174
Value Function Loss: 0.01454

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.56980

Collected Steps per Second: 22,670.14607
Overall Steps per Second: 10,827.82989

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.62032

Cumulative Model Updates: 185,392
Cumulative Timesteps: 1,546,183,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1546183890...
Checkpoint 1546183890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.09007
Policy Entropy: 2.38895
Value Function Loss: 0.01514

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.56238
Value Function Update Magnitude: 0.56415

Collected Steps per Second: 22,373.73909
Overall Steps per Second: 10,690.10269

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.68134

Cumulative Model Updates: 185,398
Cumulative Timesteps: 1,546,233,934

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.96288
Policy Entropy: 2.38160
Value Function Loss: 0.01596

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.56357
Value Function Update Magnitude: 0.56549

Collected Steps per Second: 23,173.09071
Overall Steps per Second: 10,994.12743

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.39069
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.54879

Cumulative Model Updates: 185,404
Cumulative Timesteps: 1,546,283,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1546283944...
Checkpoint 1546283944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.23065
Policy Entropy: 2.37068
Value Function Loss: 0.01580

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 23,054.50050
Overall Steps per Second: 10,700.01139

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67383

Cumulative Model Updates: 185,410
Cumulative Timesteps: 1,546,333,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.19917
Policy Entropy: 2.34656
Value Function Loss: 0.01472

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.53762

Collected Steps per Second: 23,449.46673
Overall Steps per Second: 10,805.54577

Timestep Collection Time: 2.13267
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.62818

Cumulative Model Updates: 185,416
Cumulative Timesteps: 1,546,383,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1546383964...
Checkpoint 1546383964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.24410
Policy Entropy: 2.35247
Value Function Loss: 0.01472

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.55756

Collected Steps per Second: 22,883.27425
Overall Steps per Second: 10,645.06963

Timestep Collection Time: 2.18518
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.69739

Cumulative Model Updates: 185,422
Cumulative Timesteps: 1,546,433,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.03678
Policy Entropy: 2.32461
Value Function Loss: 0.01566

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.56253

Collected Steps per Second: 23,077.62813
Overall Steps per Second: 10,953.95104

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.56493

Cumulative Model Updates: 185,428
Cumulative Timesteps: 1,546,483,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1546483972...
Checkpoint 1546483972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.24551
Policy Entropy: 2.33447
Value Function Loss: 0.01617

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.58043

Collected Steps per Second: 23,014.47060
Overall Steps per Second: 10,793.77760

Timestep Collection Time: 2.17385
Timestep Consumption Time: 2.46123
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.63508

Cumulative Model Updates: 185,434
Cumulative Timesteps: 1,546,534,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.29324
Policy Entropy: 2.35209
Value Function Loss: 0.01625

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.58107
Value Function Update Magnitude: 0.56002

Collected Steps per Second: 22,775.32378
Overall Steps per Second: 10,790.94446

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.63389

Cumulative Model Updates: 185,440
Cumulative Timesteps: 1,546,584,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1546584006...
Checkpoint 1546584006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.31341
Policy Entropy: 2.38089
Value Function Loss: 0.01565

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.58259
Value Function Update Magnitude: 0.56158

Collected Steps per Second: 22,320.48700
Overall Steps per Second: 10,525.56754

Timestep Collection Time: 2.24027
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.75072

Cumulative Model Updates: 185,446
Cumulative Timesteps: 1,546,634,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.96374
Policy Entropy: 2.37650
Value Function Loss: 0.01479

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.56713

Collected Steps per Second: 22,966.05482
Overall Steps per Second: 10,833.56930

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.61547

Cumulative Model Updates: 185,452
Cumulative Timesteps: 1,546,684,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1546684012...
Checkpoint 1546684012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.17176
Policy Entropy: 2.36469
Value Function Loss: 0.01385

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.54796

Collected Steps per Second: 23,100.15109
Overall Steps per Second: 10,742.01978

Timestep Collection Time: 2.16579
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.65741

Cumulative Model Updates: 185,458
Cumulative Timesteps: 1,546,734,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.83171
Policy Entropy: 2.35076
Value Function Loss: 0.01455

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.54783

Collected Steps per Second: 23,187.79261
Overall Steps per Second: 10,845.66249

Timestep Collection Time: 2.15743
Timestep Consumption Time: 2.45511
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.61254

Cumulative Model Updates: 185,464
Cumulative Timesteps: 1,546,784,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1546784068...
Checkpoint 1546784068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.12746
Policy Entropy: 2.33986
Value Function Loss: 0.01505

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.56545

Collected Steps per Second: 22,769.96994
Overall Steps per Second: 10,700.29346

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.67725

Cumulative Model Updates: 185,470
Cumulative Timesteps: 1,546,834,116

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.62398
Policy Entropy: 2.32276
Value Function Loss: 0.01545

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.56684

Collected Steps per Second: 23,248.48825
Overall Steps per Second: 10,965.05745

Timestep Collection Time: 2.15171
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.56213

Cumulative Model Updates: 185,476
Cumulative Timesteps: 1,546,884,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1546884140...
Checkpoint 1546884140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.13557
Policy Entropy: 2.34281
Value Function Loss: 0.01444

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.56169

Collected Steps per Second: 23,080.38239
Overall Steps per Second: 10,775.38683

Timestep Collection Time: 2.16695
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.64150

Cumulative Model Updates: 185,482
Cumulative Timesteps: 1,546,934,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.64607
Policy Entropy: 2.33408
Value Function Loss: 0.01405

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.54946

Collected Steps per Second: 23,214.12060
Overall Steps per Second: 10,831.58795

Timestep Collection Time: 2.15438
Timestep Consumption Time: 2.46286
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.61724

Cumulative Model Updates: 185,488
Cumulative Timesteps: 1,546,984,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1546984166...
Checkpoint 1546984166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.14531
Policy Entropy: 2.33257
Value Function Loss: 0.01424

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.55086

Collected Steps per Second: 22,563.19318
Overall Steps per Second: 10,950.61520

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.35090
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.56778

Cumulative Model Updates: 185,494
Cumulative Timesteps: 1,547,034,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.04758
Policy Entropy: 2.34278
Value Function Loss: 0.01483

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.53534

Collected Steps per Second: 22,775.57261
Overall Steps per Second: 10,615.89764

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.71011

Cumulative Model Updates: 185,500
Cumulative Timesteps: 1,547,084,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1547084188...
Checkpoint 1547084188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.47631
Policy Entropy: 2.37112
Value Function Loss: 0.01511

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.52160

Collected Steps per Second: 22,675.66398
Overall Steps per Second: 10,645.74027

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.69878

Cumulative Model Updates: 185,506
Cumulative Timesteps: 1,547,134,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.84083
Policy Entropy: 2.40625
Value Function Loss: 0.01529

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.54083
Value Function Update Magnitude: 0.52733

Collected Steps per Second: 22,924.42023
Overall Steps per Second: 10,814.16626

Timestep Collection Time: 2.18160
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.62467

Cumulative Model Updates: 185,512
Cumulative Timesteps: 1,547,184,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1547184222...
Checkpoint 1547184222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.24309
Policy Entropy: 2.38733
Value Function Loss: 0.01488

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.53710
Value Function Update Magnitude: 0.52606

Collected Steps per Second: 22,857.18359
Overall Steps per Second: 10,682.37886

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.68229

Cumulative Model Updates: 185,518
Cumulative Timesteps: 1,547,234,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.54996
Policy Entropy: 2.35298
Value Function Loss: 0.01481

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.53911

Collected Steps per Second: 23,524.57248
Overall Steps per Second: 10,819.57420

Timestep Collection Time: 2.12671
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.62403

Cumulative Model Updates: 185,524
Cumulative Timesteps: 1,547,284,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1547284270...
Checkpoint 1547284270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.93333
Policy Entropy: 2.35192
Value Function Loss: 0.01541

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.54862

Collected Steps per Second: 23,048.31128
Overall Steps per Second: 11,090.26596

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.33994
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.51008

Cumulative Model Updates: 185,530
Cumulative Timesteps: 1,547,334,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.03698
Policy Entropy: 2.36137
Value Function Loss: 0.01482

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.58069

Collected Steps per Second: 23,558.07999
Overall Steps per Second: 10,997.49790

Timestep Collection Time: 2.12369
Timestep Consumption Time: 2.42553
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.54922

Cumulative Model Updates: 185,536
Cumulative Timesteps: 1,547,384,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1547384318...
Checkpoint 1547384318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.53352
Policy Entropy: 2.35432
Value Function Loss: 0.01495

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.59217

Collected Steps per Second: 23,179.32852
Overall Steps per Second: 10,793.73502

Timestep Collection Time: 2.15822
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.63473

Cumulative Model Updates: 185,542
Cumulative Timesteps: 1,547,434,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.52989
Policy Entropy: 2.34336
Value Function Loss: 0.01524

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.60072

Collected Steps per Second: 22,994.56202
Overall Steps per Second: 10,716.63415

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.49231
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.66770

Cumulative Model Updates: 185,548
Cumulative Timesteps: 1,547,484,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1547484366...
Checkpoint 1547484366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.31780
Policy Entropy: 2.35520
Value Function Loss: 0.01543

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.58979

Collected Steps per Second: 22,720.05465
Overall Steps per Second: 10,975.35369

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.35553
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.55676

Cumulative Model Updates: 185,554
Cumulative Timesteps: 1,547,534,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.14159
Policy Entropy: 2.37251
Value Function Loss: 0.01595

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.56230
Value Function Update Magnitude: 0.58337

Collected Steps per Second: 22,809.27866
Overall Steps per Second: 10,670.35830

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68663

Cumulative Model Updates: 185,560
Cumulative Timesteps: 1,547,584,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1547584386...
Checkpoint 1547584386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.41444
Policy Entropy: 2.38733
Value Function Loss: 0.01516

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.56541

Collected Steps per Second: 23,046.08101
Overall Steps per Second: 10,688.51334

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.67867

Cumulative Model Updates: 185,566
Cumulative Timesteps: 1,547,634,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.48177
Policy Entropy: 2.35630
Value Function Loss: 0.01588

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.56761

Collected Steps per Second: 23,528.94242
Overall Steps per Second: 10,816.65929

Timestep Collection Time: 2.12564
Timestep Consumption Time: 2.49816
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.62379

Cumulative Model Updates: 185,572
Cumulative Timesteps: 1,547,684,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1547684408...
Checkpoint 1547684408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.32183
Policy Entropy: 2.34892
Value Function Loss: 0.01500

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.56218
Value Function Update Magnitude: 0.57289

Collected Steps per Second: 23,255.82693
Overall Steps per Second: 10,984.05458

Timestep Collection Time: 2.15060
Timestep Consumption Time: 2.40273
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.55333

Cumulative Model Updates: 185,578
Cumulative Timesteps: 1,547,734,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.39686
Policy Entropy: 2.33580
Value Function Loss: 0.01481

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.56530
Value Function Update Magnitude: 0.56799

Collected Steps per Second: 23,364.56237
Overall Steps per Second: 10,927.78689

Timestep Collection Time: 2.14102
Timestep Consumption Time: 2.43667
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.57769

Cumulative Model Updates: 185,584
Cumulative Timesteps: 1,547,784,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1547784446...
Checkpoint 1547784446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.12633
Policy Entropy: 2.35077
Value Function Loss: 0.01407

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.55629

Collected Steps per Second: 22,662.40956
Overall Steps per Second: 10,668.59432

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68909

Cumulative Model Updates: 185,590
Cumulative Timesteps: 1,547,834,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.07088
Policy Entropy: 2.34469
Value Function Loss: 0.01460

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.56693

Collected Steps per Second: 23,439.58384
Overall Steps per Second: 10,913.30018

Timestep Collection Time: 2.13323
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.58175

Cumulative Model Updates: 185,596
Cumulative Timesteps: 1,547,884,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1547884474...
Checkpoint 1547884474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.68690
Policy Entropy: 2.33649
Value Function Loss: 0.01468

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.55857
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 22,498.05838
Overall Steps per Second: 10,639.92662

Timestep Collection Time: 2.22250
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.69947

Cumulative Model Updates: 185,602
Cumulative Timesteps: 1,547,934,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.86179
Policy Entropy: 2.33254
Value Function Loss: 0.01513

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.56341
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 22,766.95988
Overall Steps per Second: 10,818.94092

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.42623
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.62319

Cumulative Model Updates: 185,608
Cumulative Timesteps: 1,547,984,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1547984494...
Checkpoint 1547984494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.64864
Policy Entropy: 2.34822
Value Function Loss: 0.01517

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.55802

Collected Steps per Second: 22,589.64687
Overall Steps per Second: 10,777.45246

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.64061

Cumulative Model Updates: 185,614
Cumulative Timesteps: 1,548,034,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.76619
Policy Entropy: 2.37757
Value Function Loss: 0.01561

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 23,244.29141
Overall Steps per Second: 10,861.79563

Timestep Collection Time: 2.15150
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.60421

Cumulative Model Updates: 185,620
Cumulative Timesteps: 1,548,084,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548084518...
Checkpoint 1548084518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.52521
Policy Entropy: 2.37677
Value Function Loss: 0.01606

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.56798

Collected Steps per Second: 23,114.24156
Overall Steps per Second: 10,676.51405

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68505

Cumulative Model Updates: 185,626
Cumulative Timesteps: 1,548,134,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.75552
Policy Entropy: 2.35514
Value Function Loss: 0.01598

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.57165

Collected Steps per Second: 21,690.52227
Overall Steps per Second: 10,331.65458

Timestep Collection Time: 2.30562
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.84046

Cumulative Model Updates: 185,632
Cumulative Timesteps: 1,548,184,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548184548...
Checkpoint 1548184548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.12980
Policy Entropy: 2.32523
Value Function Loss: 0.01525

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.54442
Value Function Update Magnitude: 0.54676

Collected Steps per Second: 22,863.96926
Overall Steps per Second: 10,684.67213

Timestep Collection Time: 2.18781
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.68166

Cumulative Model Updates: 185,638
Cumulative Timesteps: 1,548,234,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.81110
Policy Entropy: 2.32385
Value Function Loss: 0.01532

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.53093

Collected Steps per Second: 23,145.96079
Overall Steps per Second: 10,934.65815

Timestep Collection Time: 2.16098
Timestep Consumption Time: 2.41328
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.57426

Cumulative Model Updates: 185,644
Cumulative Timesteps: 1,548,284,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1548284588...
Checkpoint 1548284588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.61392
Policy Entropy: 2.34004
Value Function Loss: 0.01533

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 23,043.57853
Overall Steps per Second: 10,751.35900

Timestep Collection Time: 2.17067
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.65244

Cumulative Model Updates: 185,650
Cumulative Timesteps: 1,548,334,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.13170
Policy Entropy: 2.35414
Value Function Loss: 0.01567

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.53359

Collected Steps per Second: 23,328.75319
Overall Steps per Second: 10,821.29042

Timestep Collection Time: 2.14396
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.62200

Cumulative Model Updates: 185,656
Cumulative Timesteps: 1,548,384,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1548384624...
Checkpoint 1548384624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.30914
Policy Entropy: 2.33205
Value Function Loss: 0.01680

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.57378

Collected Steps per Second: 22,465.61267
Overall Steps per Second: 10,631.70312

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.47808
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.70442

Cumulative Model Updates: 185,662
Cumulative Timesteps: 1,548,434,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.65538
Policy Entropy: 2.32354
Value Function Loss: 0.01688

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.53852
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,562.85413
Overall Steps per Second: 10,839.26687

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.39683
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.61286

Cumulative Model Updates: 185,668
Cumulative Timesteps: 1,548,484,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1548484640...
Checkpoint 1548484640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.75130
Policy Entropy: 2.30813
Value Function Loss: 0.01681

Mean KL Divergence: 0.03021
SB3 Clip Fraction: 0.20483
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.60510

Collected Steps per Second: 22,514.67173
Overall Steps per Second: 10,723.73296

Timestep Collection Time: 2.22104
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.66312

Cumulative Model Updates: 185,674
Cumulative Timesteps: 1,548,534,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.62166
Policy Entropy: 2.33970
Value Function Loss: 0.01546

Mean KL Divergence: 0.02787
SB3 Clip Fraction: 0.19756
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.58949

Collected Steps per Second: 22,945.74053
Overall Steps per Second: 10,899.96951

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.58845

Cumulative Model Updates: 185,680
Cumulative Timesteps: 1,548,584,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1548584660...
Checkpoint 1548584660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.13210
Policy Entropy: 2.34464
Value Function Loss: 0.01503

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.16416
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.57593

Collected Steps per Second: 22,519.81630
Overall Steps per Second: 10,628.24300

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.48438
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.70482

Cumulative Model Updates: 185,686
Cumulative Timesteps: 1,548,634,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.44982
Policy Entropy: 2.36024
Value Function Loss: 0.01449

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.15035
Policy Update Magnitude: 0.55229
Value Function Update Magnitude: 0.54495

Collected Steps per Second: 23,558.77587
Overall Steps per Second: 10,954.97150

Timestep Collection Time: 2.12320
Timestep Consumption Time: 2.44276
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.56596

Cumulative Model Updates: 185,692
Cumulative Timesteps: 1,548,684,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1548684684...
Checkpoint 1548684684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.85340
Policy Entropy: 2.34594
Value Function Loss: 0.01420

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.54297

Collected Steps per Second: 23,108.71985
Overall Steps per Second: 10,773.23814

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.47784
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.64187

Cumulative Model Updates: 185,698
Cumulative Timesteps: 1,548,734,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.12863
Policy Entropy: 2.34413
Value Function Loss: 0.01389

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.53171

Collected Steps per Second: 23,326.14503
Overall Steps per Second: 10,823.40439

Timestep Collection Time: 2.14395
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.62054

Cumulative Model Updates: 185,704
Cumulative Timesteps: 1,548,784,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548784702...
Checkpoint 1548784702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.61005
Policy Entropy: 2.33004
Value Function Loss: 0.01469

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 22,750.72894
Overall Steps per Second: 10,992.72822

Timestep Collection Time: 2.19887
Timestep Consumption Time: 2.35195
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.55083

Cumulative Model Updates: 185,710
Cumulative Timesteps: 1,548,834,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.09374
Policy Entropy: 2.33844
Value Function Loss: 0.01608

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.55196

Collected Steps per Second: 23,724.59543
Overall Steps per Second: 10,935.17840

Timestep Collection Time: 2.10777
Timestep Consumption Time: 2.46518
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.57295

Cumulative Model Updates: 185,716
Cumulative Timesteps: 1,548,884,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1548884734...
Checkpoint 1548884734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.71513
Policy Entropy: 2.31755
Value Function Loss: 0.01571

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.58136

Collected Steps per Second: 22,624.87252
Overall Steps per Second: 10,664.84190

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.47854
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68868

Cumulative Model Updates: 185,722
Cumulative Timesteps: 1,548,934,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.28163
Policy Entropy: 2.32646
Value Function Loss: 0.01582

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.56078

Collected Steps per Second: 22,662.63636
Overall Steps per Second: 10,791.66102

Timestep Collection Time: 2.20672
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63413

Cumulative Model Updates: 185,728
Cumulative Timesteps: 1,548,984,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548984748...
Checkpoint 1548984748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.00680
Policy Entropy: 2.31307
Value Function Loss: 0.01502

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.54311

Collected Steps per Second: 21,611.64787
Overall Steps per Second: 10,461.22481

Timestep Collection Time: 2.31440
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.78128

Cumulative Model Updates: 185,734
Cumulative Timesteps: 1,549,034,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.34238
Policy Entropy: 2.33300
Value Function Loss: 0.01487

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.54536

Collected Steps per Second: 23,642.15965
Overall Steps per Second: 10,822.23304

Timestep Collection Time: 2.11512
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.62067

Cumulative Model Updates: 185,740
Cumulative Timesteps: 1,549,084,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1549084772...
Checkpoint 1549084772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.32581
Policy Entropy: 2.32650
Value Function Loss: 0.01498

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.55076

Collected Steps per Second: 22,502.86597
Overall Steps per Second: 10,593.52513

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.71986

Cumulative Model Updates: 185,746
Cumulative Timesteps: 1,549,134,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.54195
Policy Entropy: 2.32354
Value Function Loss: 0.01521

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.57229

Collected Steps per Second: 23,290.74120
Overall Steps per Second: 10,836.96383

Timestep Collection Time: 2.14772
Timestep Consumption Time: 2.46815
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61587

Cumulative Model Updates: 185,752
Cumulative Timesteps: 1,549,184,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1549184794...
Checkpoint 1549184794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.15173
Policy Entropy: 2.33241
Value Function Loss: 0.01493

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.55418
Value Function Update Magnitude: 0.56648

Collected Steps per Second: 23,030.25905
Overall Steps per Second: 10,754.46345

Timestep Collection Time: 2.17193
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.65109

Cumulative Model Updates: 185,758
Cumulative Timesteps: 1,549,234,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.82089
Policy Entropy: 2.32174
Value Function Loss: 0.01522

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.56688

Collected Steps per Second: 23,061.33587
Overall Steps per Second: 10,886.28480

Timestep Collection Time: 2.16943
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.59569

Cumulative Model Updates: 185,764
Cumulative Timesteps: 1,549,284,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1549284844...
Checkpoint 1549284844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.58354
Policy Entropy: 2.36318
Value Function Loss: 0.01500

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.54970

Collected Steps per Second: 23,192.73551
Overall Steps per Second: 10,798.05284

Timestep Collection Time: 2.15645
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.63176

Cumulative Model Updates: 185,770
Cumulative Timesteps: 1,549,334,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.44406
Policy Entropy: 2.34722
Value Function Loss: 0.01532

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.53904

Collected Steps per Second: 23,619.58249
Overall Steps per Second: 10,878.98478

Timestep Collection Time: 2.11773
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.59786

Cumulative Model Updates: 185,776
Cumulative Timesteps: 1,549,384,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1549384878...
Checkpoint 1549384878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.57710
Policy Entropy: 2.35172
Value Function Loss: 0.01472

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.53340

Collected Steps per Second: 23,129.48832
Overall Steps per Second: 10,881.88274

Timestep Collection Time: 2.16200
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.59534

Cumulative Model Updates: 185,782
Cumulative Timesteps: 1,549,434,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.42440
Policy Entropy: 2.32152
Value Function Loss: 0.01452

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.53295

Collected Steps per Second: 22,732.12829
Overall Steps per Second: 10,993.45813

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.35004
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.55089

Cumulative Model Updates: 185,788
Cumulative Timesteps: 1,549,484,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1549484914...
Checkpoint 1549484914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.93345
Policy Entropy: 2.32800
Value Function Loss: 0.01571

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.53705

Collected Steps per Second: 22,596.09858
Overall Steps per Second: 10,629.39133

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.70620

Cumulative Model Updates: 185,794
Cumulative Timesteps: 1,549,534,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.48891
Policy Entropy: 2.34690
Value Function Loss: 0.01554

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.56846

Collected Steps per Second: 23,086.97108
Overall Steps per Second: 10,906.49615

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.58644

Cumulative Model Updates: 185,800
Cumulative Timesteps: 1,549,584,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1549584960...
Checkpoint 1549584960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.00340
Policy Entropy: 2.36364
Value Function Loss: 0.01540

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.57500

Collected Steps per Second: 23,040.35074
Overall Steps per Second: 10,593.32959

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.55097
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72203

Cumulative Model Updates: 185,806
Cumulative Timesteps: 1,549,634,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.06038
Policy Entropy: 2.35762
Value Function Loss: 0.01567

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.55349

Collected Steps per Second: 22,976.14032
Overall Steps per Second: 10,893.88484

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.41366
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.58991

Cumulative Model Updates: 185,812
Cumulative Timesteps: 1,549,684,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1549684984...
Checkpoint 1549684984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.83072
Policy Entropy: 2.34963
Value Function Loss: 0.01485

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.54726

Collected Steps per Second: 23,045.41861
Overall Steps per Second: 11,033.24300

Timestep Collection Time: 2.16980
Timestep Consumption Time: 2.36232
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.53212

Cumulative Model Updates: 185,818
Cumulative Timesteps: 1,549,734,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.86629
Policy Entropy: 2.34168
Value Function Loss: 0.01503

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.54753
Value Function Update Magnitude: 0.55427

Collected Steps per Second: 23,060.53869
Overall Steps per Second: 10,735.04646

Timestep Collection Time: 2.16829
Timestep Consumption Time: 2.48954
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.65783

Cumulative Model Updates: 185,824
Cumulative Timesteps: 1,549,784,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1549784990...
Checkpoint 1549784990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.54975
Policy Entropy: 2.34920
Value Function Loss: 0.01498

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 23,102.67247
Overall Steps per Second: 10,893.44992

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.59285

Cumulative Model Updates: 185,830
Cumulative Timesteps: 1,549,835,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.94818
Policy Entropy: 2.34414
Value Function Loss: 0.01615

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.58444

Collected Steps per Second: 23,186.98714
Overall Steps per Second: 10,975.24922

Timestep Collection Time: 2.15759
Timestep Consumption Time: 2.40067
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.55826

Cumulative Model Updates: 185,836
Cumulative Timesteps: 1,549,885,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1549885050...
Checkpoint 1549885050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.67717
Policy Entropy: 2.34056
Value Function Loss: 0.01640

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 22,554.85151
Overall Steps per Second: 10,620.31634

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.49174
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70909

Cumulative Model Updates: 185,842
Cumulative Timesteps: 1,549,935,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.77190
Policy Entropy: 2.34602
Value Function Loss: 0.01574

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.62028

Collected Steps per Second: 22,912.69163
Overall Steps per Second: 10,896.05452

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.40739
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.59029

Cumulative Model Updates: 185,848
Cumulative Timesteps: 1,549,985,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1549985078...
Checkpoint 1549985078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.13829
Policy Entropy: 2.33974
Value Function Loss: 0.01631

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.57731
Value Function Update Magnitude: 0.63008

Collected Steps per Second: 22,603.96767
Overall Steps per Second: 10,628.00604

Timestep Collection Time: 2.21218
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70493

Cumulative Model Updates: 185,854
Cumulative Timesteps: 1,550,035,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.69819
Policy Entropy: 2.34783
Value Function Loss: 0.01544

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.63080

Collected Steps per Second: 23,154.06650
Overall Steps per Second: 10,862.63266

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.60367

Cumulative Model Updates: 185,860
Cumulative Timesteps: 1,550,085,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1550085090...
Checkpoint 1550085090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.30464
Policy Entropy: 2.31030
Value Function Loss: 0.01551

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 22,721.59939
Overall Steps per Second: 10,672.70341

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.68897

Cumulative Model Updates: 185,866
Cumulative Timesteps: 1,550,135,134

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.37803
Policy Entropy: 2.30887
Value Function Loss: 0.01549

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 23,379.01835
Overall Steps per Second: 10,942.64529

Timestep Collection Time: 2.13944
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.57092

Cumulative Model Updates: 185,872
Cumulative Timesteps: 1,550,185,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1550185152...
Checkpoint 1550185152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.86960
Policy Entropy: 2.30532
Value Function Loss: 0.01533

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.60096

Collected Steps per Second: 22,983.59174
Overall Steps per Second: 10,734.13471

Timestep Collection Time: 2.17581
Timestep Consumption Time: 2.48297
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.65878

Cumulative Model Updates: 185,878
Cumulative Timesteps: 1,550,235,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.24939
Policy Entropy: 2.32529
Value Function Loss: 0.01537

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.57794

Collected Steps per Second: 23,513.44131
Overall Steps per Second: 10,794.84114

Timestep Collection Time: 2.12687
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.63277

Cumulative Model Updates: 185,884
Cumulative Timesteps: 1,550,285,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1550285170...
Checkpoint 1550285170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.19346
Policy Entropy: 2.33006
Value Function Loss: 0.01554

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.56141

Collected Steps per Second: 23,009.90660
Overall Steps per Second: 10,696.78048

Timestep Collection Time: 2.17437
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.67730

Cumulative Model Updates: 185,890
Cumulative Timesteps: 1,550,335,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.26326
Policy Entropy: 2.30726
Value Function Loss: 0.01732

Mean KL Divergence: 0.02546
SB3 Clip Fraction: 0.18387
Policy Update Magnitude: 0.54668
Value Function Update Magnitude: 0.56322

Collected Steps per Second: 23,401.93297
Overall Steps per Second: 10,845.51622

Timestep Collection Time: 2.13760
Timestep Consumption Time: 2.47481
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.61241

Cumulative Model Updates: 185,896
Cumulative Timesteps: 1,550,385,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1550385226...
Checkpoint 1550385226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.86086
Policy Entropy: 2.31497
Value Function Loss: 0.01712

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.60237

Collected Steps per Second: 22,494.78238
Overall Steps per Second: 10,808.54407

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.40362
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.62671

Cumulative Model Updates: 185,902
Cumulative Timesteps: 1,550,435,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.61135
Policy Entropy: 2.32012
Value Function Loss: 0.01666

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 22,931.98313
Overall Steps per Second: 10,785.37211

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.63813

Cumulative Model Updates: 185,908
Cumulative Timesteps: 1,550,485,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1550485258...
Checkpoint 1550485258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.76197
Policy Entropy: 2.35070
Value Function Loss: 0.01598

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.57152
Value Function Update Magnitude: 0.62136

Collected Steps per Second: 22,702.51946
Overall Steps per Second: 10,640.71852

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.70025

Cumulative Model Updates: 185,914
Cumulative Timesteps: 1,550,535,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.37989
Policy Entropy: 2.34897
Value Function Loss: 0.01671

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.59321

Collected Steps per Second: 23,088.10196
Overall Steps per Second: 10,866.80806

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60264

Cumulative Model Updates: 185,920
Cumulative Timesteps: 1,550,585,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1550585288...
Checkpoint 1550585288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.22462
Policy Entropy: 2.33791
Value Function Loss: 0.01613

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.59506

Collected Steps per Second: 22,761.50536
Overall Steps per Second: 10,634.42793

Timestep Collection Time: 2.19687
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.70209

Cumulative Model Updates: 185,926
Cumulative Timesteps: 1,550,635,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.53644
Policy Entropy: 2.33695
Value Function Loss: 0.01566

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.56553
Value Function Update Magnitude: 0.59159

Collected Steps per Second: 23,343.48073
Overall Steps per Second: 10,922.78090

Timestep Collection Time: 2.14321
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.58034

Cumulative Model Updates: 185,932
Cumulative Timesteps: 1,550,685,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1550685322...
Checkpoint 1550685322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.71466
Policy Entropy: 2.32847
Value Function Loss: 0.01497

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 23,299.75313
Overall Steps per Second: 10,801.05422

Timestep Collection Time: 2.14689
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.63121

Cumulative Model Updates: 185,938
Cumulative Timesteps: 1,550,735,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.84452
Policy Entropy: 2.34822
Value Function Loss: 0.01487

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.57447

Collected Steps per Second: 23,638.41787
Overall Steps per Second: 10,891.09400

Timestep Collection Time: 2.11537
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.59127

Cumulative Model Updates: 185,944
Cumulative Timesteps: 1,550,785,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1550785348...
Checkpoint 1550785348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.07063
Policy Entropy: 2.33020
Value Function Loss: 0.01508

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.58400

Collected Steps per Second: 23,005.87958
Overall Steps per Second: 10,867.14748

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60231

Cumulative Model Updates: 185,950
Cumulative Timesteps: 1,550,835,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.41950
Policy Entropy: 2.31951
Value Function Loss: 0.01493

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.59101

Collected Steps per Second: 23,220.10391
Overall Steps per Second: 10,966.50457

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.40642
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.56007

Cumulative Model Updates: 185,956
Cumulative Timesteps: 1,550,885,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1550885370...
Checkpoint 1550885370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.20106
Policy Entropy: 2.31293
Value Function Loss: 0.01470

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 22,784.86606
Overall Steps per Second: 10,819.53675

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.62256

Cumulative Model Updates: 185,962
Cumulative Timesteps: 1,550,935,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.87364
Policy Entropy: 2.35091
Value Function Loss: 0.01575

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 22,859.87219
Overall Steps per Second: 10,848.56799

Timestep Collection Time: 2.18829
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61112

Cumulative Model Updates: 185,968
Cumulative Timesteps: 1,550,985,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1550985408...
Checkpoint 1550985408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.67067
Policy Entropy: 2.36356
Value Function Loss: 0.01611

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.57626

Collected Steps per Second: 22,727.97205
Overall Steps per Second: 10,656.41410

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.69257

Cumulative Model Updates: 185,974
Cumulative Timesteps: 1,551,035,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.06569
Policy Entropy: 2.33991
Value Function Loss: 0.01550

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 22,956.44860
Overall Steps per Second: 10,910.90292

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.40569
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.58477

Cumulative Model Updates: 185,980
Cumulative Timesteps: 1,551,085,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1551085438...
Checkpoint 1551085438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.73115
Policy Entropy: 2.31620
Value Function Loss: 0.01469

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.55458

Collected Steps per Second: 23,156.54896
Overall Steps per Second: 10,763.62440

Timestep Collection Time: 2.15973
Timestep Consumption Time: 2.48666
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.64639

Cumulative Model Updates: 185,986
Cumulative Timesteps: 1,551,135,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.20874
Policy Entropy: 2.30635
Value Function Loss: 0.01530

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.55215

Collected Steps per Second: 23,459.36215
Overall Steps per Second: 11,131.19637

Timestep Collection Time: 2.13254
Timestep Consumption Time: 2.36186
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.49440

Cumulative Model Updates: 185,992
Cumulative Timesteps: 1,551,185,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1551185478...
Checkpoint 1551185478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.30732
Policy Entropy: 2.32033
Value Function Loss: 0.01529

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.56510
Value Function Update Magnitude: 0.57743

Collected Steps per Second: 23,041.62007
Overall Steps per Second: 10,735.53619

Timestep Collection Time: 2.17077
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.65911

Cumulative Model Updates: 185,998
Cumulative Timesteps: 1,551,235,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.72447
Policy Entropy: 2.33260
Value Function Loss: 0.01501

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.57671

Collected Steps per Second: 23,456.32433
Overall Steps per Second: 10,923.22862

Timestep Collection Time: 2.13205
Timestep Consumption Time: 2.44627
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.57832

Cumulative Model Updates: 186,004
Cumulative Timesteps: 1,551,285,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1551285506...
Checkpoint 1551285506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.99632
Policy Entropy: 2.35889
Value Function Loss: 0.01450

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.55711
Value Function Update Magnitude: 0.57185

Collected Steps per Second: 23,393.19911
Overall Steps per Second: 10,879.11867

Timestep Collection Time: 2.13797
Timestep Consumption Time: 2.45928
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.59725

Cumulative Model Updates: 186,010
Cumulative Timesteps: 1,551,335,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.43980
Policy Entropy: 2.33126
Value Function Loss: 0.01538

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.58108

Collected Steps per Second: 22,667.63369
Overall Steps per Second: 10,668.48320

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68820

Cumulative Model Updates: 186,016
Cumulative Timesteps: 1,551,385,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1551385536...
Checkpoint 1551385536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.78678
Policy Entropy: 2.32042
Value Function Loss: 0.01484

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.58959

Collected Steps per Second: 22,404.59873
Overall Steps per Second: 10,635.68637

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.47065
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70341

Cumulative Model Updates: 186,022
Cumulative Timesteps: 1,551,435,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.51978
Policy Entropy: 2.30690
Value Function Loss: 0.01585

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.57304
Value Function Update Magnitude: 0.60046

Collected Steps per Second: 23,051.23573
Overall Steps per Second: 10,912.55005

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.41309
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.58243

Cumulative Model Updates: 186,028
Cumulative Timesteps: 1,551,485,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1551485566...
Checkpoint 1551485566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.65750
Policy Entropy: 2.31991
Value Function Loss: 0.01542

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 22,916.93315
Overall Steps per Second: 10,650.60206

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.69664

Cumulative Model Updates: 186,034
Cumulative Timesteps: 1,551,535,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.63196
Policy Entropy: 2.32488
Value Function Loss: 0.01638

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.58041

Collected Steps per Second: 23,385.67649
Overall Steps per Second: 10,827.04206

Timestep Collection Time: 2.13815
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.61825

Cumulative Model Updates: 186,040
Cumulative Timesteps: 1,551,585,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1551585590...
Checkpoint 1551585590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.25356
Policy Entropy: 2.33532
Value Function Loss: 0.01547

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.56204

Collected Steps per Second: 22,773.90437
Overall Steps per Second: 10,719.57506

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.66436

Cumulative Model Updates: 186,046
Cumulative Timesteps: 1,551,635,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.20187
Policy Entropy: 2.34193
Value Function Loss: 0.01516

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.56156

Collected Steps per Second: 23,394.00270
Overall Steps per Second: 10,966.12760

Timestep Collection Time: 2.13747
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.55986

Cumulative Model Updates: 186,052
Cumulative Timesteps: 1,551,685,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1551685594...
Checkpoint 1551685594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.30156
Policy Entropy: 2.33259
Value Function Loss: 0.01544

Mean KL Divergence: 0.02757
SB3 Clip Fraction: 0.18338
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.56750

Collected Steps per Second: 22,852.01831
Overall Steps per Second: 10,676.64958

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.49642
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68555

Cumulative Model Updates: 186,058
Cumulative Timesteps: 1,551,735,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.69643
Policy Entropy: 2.32146
Value Function Loss: 0.01645

Mean KL Divergence: 0.02812
SB3 Clip Fraction: 0.19140
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 23,403.34831
Overall Steps per Second: 10,848.29363

Timestep Collection Time: 2.13773
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.61179

Cumulative Model Updates: 186,064
Cumulative Timesteps: 1,551,785,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1551785650...
Checkpoint 1551785650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.53029
Policy Entropy: 2.29437
Value Function Loss: 0.01688

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.18440
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 22,317.95031
Overall Steps per Second: 10,652.96491

Timestep Collection Time: 2.24160
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.69616

Cumulative Model Updates: 186,070
Cumulative Timesteps: 1,551,835,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.58473
Policy Entropy: 2.30051
Value Function Loss: 0.01733

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.19613
Policy Update Magnitude: 0.51696
Value Function Update Magnitude: 0.60268

Collected Steps per Second: 22,962.98861
Overall Steps per Second: 10,936.05350

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.39529
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57331

Cumulative Model Updates: 186,076
Cumulative Timesteps: 1,551,885,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1551885692...
Checkpoint 1551885692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.37526
Policy Entropy: 2.31718
Value Function Loss: 0.01622

Mean KL Divergence: 0.03199
SB3 Clip Fraction: 0.20593
Policy Update Magnitude: 0.52589
Value Function Update Magnitude: 0.60174

Collected Steps per Second: 22,591.47918
Overall Steps per Second: 10,947.88664

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.35443
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.56819

Cumulative Model Updates: 186,082
Cumulative Timesteps: 1,551,935,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.31784
Policy Entropy: 2.31216
Value Function Loss: 0.01544

Mean KL Divergence: 0.02490
SB3 Clip Fraction: 0.17981
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 23,204.04423
Overall Steps per Second: 10,809.13818

Timestep Collection Time: 2.15574
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.62775

Cumulative Model Updates: 186,088
Cumulative Timesteps: 1,551,985,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1551985726...
Checkpoint 1551985726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.48331
Policy Entropy: 2.32042
Value Function Loss: 0.01449

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.53909

Collected Steps per Second: 23,008.43210
Overall Steps per Second: 10,776.92226

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.46662
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63991

Cumulative Model Updates: 186,094
Cumulative Timesteps: 1,552,035,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.94012
Policy Entropy: 2.30821
Value Function Loss: 0.01565

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.18059
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.51996

Collected Steps per Second: 23,321.50179
Overall Steps per Second: 10,882.34895

Timestep Collection Time: 2.14489
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.59662

Cumulative Model Updates: 186,100
Cumulative Timesteps: 1,552,085,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1552085752...
Checkpoint 1552085752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.62691
Policy Entropy: 2.33997
Value Function Loss: 0.01623

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.53673

Collected Steps per Second: 22,989.35546
Overall Steps per Second: 10,697.90971

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.49919
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.67437

Cumulative Model Updates: 186,106
Cumulative Timesteps: 1,552,135,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.96802
Policy Entropy: 2.32656
Value Function Loss: 0.01592

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.56100

Collected Steps per Second: 23,247.24828
Overall Steps per Second: 10,961.78739

Timestep Collection Time: 2.15191
Timestep Consumption Time: 2.41176
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.56367

Cumulative Model Updates: 186,112
Cumulative Timesteps: 1,552,185,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1552185784...
Checkpoint 1552185784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.58306
Policy Entropy: 2.33919
Value Function Loss: 0.01499

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.56234

Collected Steps per Second: 22,999.55750
Overall Steps per Second: 10,713.09281

Timestep Collection Time: 2.17535
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.67017

Cumulative Model Updates: 186,118
Cumulative Timesteps: 1,552,235,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.74591
Policy Entropy: 2.32295
Value Function Loss: 0.01546

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.55356
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 23,412.03301
Overall Steps per Second: 10,842.19516

Timestep Collection Time: 2.13625
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.61290

Cumulative Model Updates: 186,124
Cumulative Timesteps: 1,552,285,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1552285830...
Checkpoint 1552285830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.41815
Policy Entropy: 2.32156
Value Function Loss: 0.01625

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.56935

Collected Steps per Second: 22,468.23672
Overall Steps per Second: 10,636.66358

Timestep Collection Time: 2.22554
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70110

Cumulative Model Updates: 186,130
Cumulative Timesteps: 1,552,335,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.77487
Policy Entropy: 2.32540
Value Function Loss: 0.01571

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.58086

Collected Steps per Second: 22,461.01191
Overall Steps per Second: 10,805.73093

Timestep Collection Time: 2.22715
Timestep Consumption Time: 2.40225
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62940

Cumulative Model Updates: 186,136
Cumulative Timesteps: 1,552,385,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1552385858...
Checkpoint 1552385858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.94988
Policy Entropy: 2.33774
Value Function Loss: 0.01610

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.59429

Collected Steps per Second: 22,360.62413
Overall Steps per Second: 10,708.41134

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67035

Cumulative Model Updates: 186,142
Cumulative Timesteps: 1,552,435,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.07232
Policy Entropy: 2.34783
Value Function Loss: 0.01522

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 22,419.32610
Overall Steps per Second: 10,571.97433

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.50057
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.73194

Cumulative Model Updates: 186,148
Cumulative Timesteps: 1,552,485,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1552485896...
Checkpoint 1552485896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.39143
Policy Entropy: 2.33306
Value Function Loss: 0.01560

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.61468

Collected Steps per Second: 23,151.96746
Overall Steps per Second: 10,718.52469

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.66706

Cumulative Model Updates: 186,154
Cumulative Timesteps: 1,552,535,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.13537
Policy Entropy: 2.31296
Value Function Loss: 0.01564

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.61252

Collected Steps per Second: 23,552.97782
Overall Steps per Second: 10,868.84444

Timestep Collection Time: 2.12389
Timestep Consumption Time: 2.47862
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.60251

Cumulative Model Updates: 186,160
Cumulative Timesteps: 1,552,585,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1552585944...
Checkpoint 1552585944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.86196
Policy Entropy: 2.33009
Value Function Loss: 0.01634

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.55655
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 23,051.71978
Overall Steps per Second: 10,989.11721

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.38206
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.55214

Cumulative Model Updates: 186,166
Cumulative Timesteps: 1,552,635,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.41770
Policy Entropy: 2.34333
Value Function Loss: 0.01572

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.61459

Collected Steps per Second: 22,655.29804
Overall Steps per Second: 10,873.27356

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.39230
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.60009

Cumulative Model Updates: 186,172
Cumulative Timesteps: 1,552,685,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1552685986...
Checkpoint 1552685986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.06797
Policy Entropy: 2.35938
Value Function Loss: 0.01624

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.58651

Collected Steps per Second: 23,051.58306
Overall Steps per Second: 10,716.09010

Timestep Collection Time: 2.16957
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.66700

Cumulative Model Updates: 186,178
Cumulative Timesteps: 1,552,735,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.96876
Policy Entropy: 2.33773
Value Function Loss: 0.01560

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.57185

Collected Steps per Second: 23,435.06976
Overall Steps per Second: 10,847.73148

Timestep Collection Time: 2.13424
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.61073

Cumulative Model Updates: 186,184
Cumulative Timesteps: 1,552,786,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1552786014...
Checkpoint 1552786014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.23942
Policy Entropy: 2.33150
Value Function Loss: 0.01635

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.57217

Collected Steps per Second: 22,511.00421
Overall Steps per Second: 10,635.75950

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.48038
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.70187

Cumulative Model Updates: 186,190
Cumulative Timesteps: 1,552,836,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.79766
Policy Entropy: 2.31551
Value Function Loss: 0.01554

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.58222

Collected Steps per Second: 22,302.24016
Overall Steps per Second: 10,445.74200

Timestep Collection Time: 2.24291
Timestep Consumption Time: 2.54583
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.78875

Cumulative Model Updates: 186,196
Cumulative Timesteps: 1,552,886,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1552886044...
Checkpoint 1552886044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.31037
Policy Entropy: 2.32619
Value Function Loss: 0.01671

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.58217

Collected Steps per Second: 22,522.78218
Overall Steps per Second: 10,790.16374

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.41445
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.63496

Cumulative Model Updates: 186,202
Cumulative Timesteps: 1,552,936,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.84273
Policy Entropy: 2.32902
Value Function Loss: 0.01635

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.55686
Value Function Update Magnitude: 0.56927

Collected Steps per Second: 23,512.66876
Overall Steps per Second: 10,790.22657

Timestep Collection Time: 2.12668
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.63419

Cumulative Model Updates: 186,208
Cumulative Timesteps: 1,552,986,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1552986060...
Checkpoint 1552986060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.80317
Policy Entropy: 2.35056
Value Function Loss: 0.01709

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.56552

Collected Steps per Second: 22,987.14254
Overall Steps per Second: 10,627.70716

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.70525

Cumulative Model Updates: 186,214
Cumulative Timesteps: 1,553,036,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.33653
Policy Entropy: 2.36219
Value Function Loss: 0.01662

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 23,357.08285
Overall Steps per Second: 10,935.43871

Timestep Collection Time: 2.14136
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.57375

Cumulative Model Updates: 186,220
Cumulative Timesteps: 1,553,086,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1553086082...
Checkpoint 1553086082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.36385
Policy Entropy: 2.34804
Value Function Loss: 0.01571

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 22,961.81095
Overall Steps per Second: 10,786.17832

Timestep Collection Time: 2.17770
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.63593

Cumulative Model Updates: 186,226
Cumulative Timesteps: 1,553,136,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.55208
Policy Entropy: 2.33489
Value Function Loss: 0.01451

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.54855

Collected Steps per Second: 23,641.30794
Overall Steps per Second: 10,926.58088

Timestep Collection Time: 2.11520
Timestep Consumption Time: 2.46135
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.57655

Cumulative Model Updates: 186,232
Cumulative Timesteps: 1,553,186,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1553186092...
Checkpoint 1553186092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.93413
Policy Entropy: 2.33047
Value Function Loss: 0.01526

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.55132
Value Function Update Magnitude: 0.53135

Collected Steps per Second: 23,057.50733
Overall Steps per Second: 10,927.62074

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.57776

Cumulative Model Updates: 186,238
Cumulative Timesteps: 1,553,236,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.50766
Policy Entropy: 2.34739
Value Function Loss: 0.01657

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.56444
Value Function Update Magnitude: 0.56127

Collected Steps per Second: 23,087.62613
Overall Steps per Second: 10,888.01112

Timestep Collection Time: 2.16653
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.59404

Cumulative Model Updates: 186,244
Cumulative Timesteps: 1,553,286,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1553286136...
Checkpoint 1553286136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.69628
Policy Entropy: 2.34296
Value Function Loss: 0.01666

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.58543

Collected Steps per Second: 22,356.99816
Overall Steps per Second: 10,624.19076

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.70624

Cumulative Model Updates: 186,250
Cumulative Timesteps: 1,553,336,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.68916
Policy Entropy: 2.33176
Value Function Loss: 0.01690

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 22,755.84661
Overall Steps per Second: 10,861.32355

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.40645
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.60386

Cumulative Model Updates: 186,256
Cumulative Timesteps: 1,553,386,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1553386140...
Checkpoint 1553386140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.89713
Policy Entropy: 2.34259
Value Function Loss: 0.01616

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.60129

Collected Steps per Second: 22,684.74285
Overall Steps per Second: 10,838.65044

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.40957
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.61423

Cumulative Model Updates: 186,262
Cumulative Timesteps: 1,553,436,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.94430
Policy Entropy: 2.34128
Value Function Loss: 0.01662

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.56664
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 23,054.97126
Overall Steps per Second: 10,711.84912

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.67016

Cumulative Model Updates: 186,268
Cumulative Timesteps: 1,553,486,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1553486178...
Checkpoint 1553486178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.61033
Policy Entropy: 2.33857
Value Function Loss: 0.01621

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.57846
Value Function Update Magnitude: 0.63488

Collected Steps per Second: 21,823.41639
Overall Steps per Second: 10,206.20622

Timestep Collection Time: 2.29176
Timestep Consumption Time: 2.60859
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.90035

Cumulative Model Updates: 186,274
Cumulative Timesteps: 1,553,536,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.30594
Policy Entropy: 2.32521
Value Function Loss: 0.01651

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.63981

Collected Steps per Second: 22,950.26564
Overall Steps per Second: 10,855.42734

Timestep Collection Time: 2.17897
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60673

Cumulative Model Updates: 186,280
Cumulative Timesteps: 1,553,586,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1553586200...
Checkpoint 1553586200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.66378
Policy Entropy: 2.30826
Value Function Loss: 0.01756

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.59549
Value Function Update Magnitude: 0.66209

Collected Steps per Second: 23,857.60369
Overall Steps per Second: 10,955.13006

Timestep Collection Time: 2.09686
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.56645

Cumulative Model Updates: 186,286
Cumulative Timesteps: 1,553,636,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.31162
Policy Entropy: 2.31763
Value Function Loss: 0.01762

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.59021
Value Function Update Magnitude: 0.68825

Collected Steps per Second: 23,018.65833
Overall Steps per Second: 10,734.25682

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.48673
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.65966

Cumulative Model Updates: 186,292
Cumulative Timesteps: 1,553,686,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1553686244...
Checkpoint 1553686244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.47692
Policy Entropy: 2.33699
Value Function Loss: 0.01742

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.69371

Collected Steps per Second: 22,892.61959
Overall Steps per Second: 10,659.12987

Timestep Collection Time: 2.18516
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69307

Cumulative Model Updates: 186,298
Cumulative Timesteps: 1,553,736,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.68153
Policy Entropy: 2.35109
Value Function Loss: 0.01703

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.57767
Value Function Update Magnitude: 0.69159

Collected Steps per Second: 23,024.01597
Overall Steps per Second: 10,912.39968

Timestep Collection Time: 2.17208
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.58286

Cumulative Model Updates: 186,304
Cumulative Timesteps: 1,553,786,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1553786278...
Checkpoint 1553786278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.50417
Policy Entropy: 2.36205
Value Function Loss: 0.01629

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.57550
Value Function Update Magnitude: 0.67803

Collected Steps per Second: 22,222.51837
Overall Steps per Second: 10,706.49284

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.67249

Cumulative Model Updates: 186,310
Cumulative Timesteps: 1,553,836,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.11247
Policy Entropy: 2.37216
Value Function Loss: 0.01528

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.56551
Value Function Update Magnitude: 0.65168

Collected Steps per Second: 23,217.40273
Overall Steps per Second: 10,822.93042

Timestep Collection Time: 2.15459
Timestep Consumption Time: 2.46745
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.62204

Cumulative Model Updates: 186,316
Cumulative Timesteps: 1,553,886,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1553886328...
Checkpoint 1553886328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.67655
Policy Entropy: 2.38195
Value Function Loss: 0.01556

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.56044
Value Function Update Magnitude: 0.65294

Collected Steps per Second: 22,656.78201
Overall Steps per Second: 10,621.33019

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.70845

Cumulative Model Updates: 186,322
Cumulative Timesteps: 1,553,936,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.98262
Policy Entropy: 2.36990
Value Function Loss: 0.01555

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.66795

Collected Steps per Second: 23,143.50328
Overall Steps per Second: 10,845.82237

Timestep Collection Time: 2.16138
Timestep Consumption Time: 2.45071
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61210

Cumulative Model Updates: 186,328
Cumulative Timesteps: 1,553,986,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1553986360...
Checkpoint 1553986360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.56739
Policy Entropy: 2.34889
Value Function Loss: 0.01614

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.67487

Collected Steps per Second: 22,937.32985
Overall Steps per Second: 10,729.60683

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.48154
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.66261

Cumulative Model Updates: 186,334
Cumulative Timesteps: 1,554,036,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.06720
Policy Entropy: 2.33197
Value Function Loss: 0.01548

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.67182

Collected Steps per Second: 23,423.13074
Overall Steps per Second: 10,836.37609

Timestep Collection Time: 2.13618
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.61741

Cumulative Model Updates: 186,340
Cumulative Timesteps: 1,554,086,424

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1554086424...
Checkpoint 1554086424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.92000
Policy Entropy: 2.32883
Value Function Loss: 0.01545

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.18098
Policy Update Magnitude: 0.51570
Value Function Update Magnitude: 0.65326

Collected Steps per Second: 23,964.72880
Overall Steps per Second: 11,091.14728

Timestep Collection Time: 2.08673
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.50882

Cumulative Model Updates: 186,346
Cumulative Timesteps: 1,554,136,432

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.55861
Policy Entropy: 2.34613
Value Function Loss: 0.01527

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.64652

Collected Steps per Second: 23,194.06109
Overall Steps per Second: 10,901.91558

Timestep Collection Time: 2.15676
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58855

Cumulative Model Updates: 186,352
Cumulative Timesteps: 1,554,186,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1554186456...
Checkpoint 1554186456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.23586
Policy Entropy: 2.34269
Value Function Loss: 0.01492

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 22,756.40492
Overall Steps per Second: 10,727.90318

Timestep Collection Time: 2.19797
Timestep Consumption Time: 2.46445
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.66242

Cumulative Model Updates: 186,358
Cumulative Timesteps: 1,554,236,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.34275
Policy Entropy: 2.33298
Value Function Loss: 0.01580

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.16422
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.60747

Collected Steps per Second: 23,437.99719
Overall Steps per Second: 10,765.35487

Timestep Collection Time: 2.13389
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.64583

Cumulative Model Updates: 186,364
Cumulative Timesteps: 1,554,286,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1554286488...
Checkpoint 1554286488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.13671
Policy Entropy: 2.34073
Value Function Loss: 0.01593

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.61248

Collected Steps per Second: 22,353.72042
Overall Steps per Second: 10,821.02241

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.38397
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.62082

Cumulative Model Updates: 186,370
Cumulative Timesteps: 1,554,336,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.50284
Policy Entropy: 2.34075
Value Function Loss: 0.01645

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.61072

Collected Steps per Second: 22,984.78771
Overall Steps per Second: 10,869.72705

Timestep Collection Time: 2.17579
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60085

Cumulative Model Updates: 186,376
Cumulative Timesteps: 1,554,386,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1554386500...
Checkpoint 1554386500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.53254
Policy Entropy: 2.36351
Value Function Loss: 0.01521

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.56356
Value Function Update Magnitude: 0.60104

Collected Steps per Second: 22,545.57192
Overall Steps per Second: 10,675.86388

Timestep Collection Time: 2.21879
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.68571

Cumulative Model Updates: 186,382
Cumulative Timesteps: 1,554,436,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.75417
Policy Entropy: 2.33805
Value Function Loss: 0.01604

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.56971
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 22,989.30691
Overall Steps per Second: 10,907.87308

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.40902
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.58403

Cumulative Model Updates: 186,388
Cumulative Timesteps: 1,554,486,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1554486526...
Checkpoint 1554486526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.37013
Policy Entropy: 2.30912
Value Function Loss: 0.01752

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.64611

Collected Steps per Second: 23,251.04904
Overall Steps per Second: 11,047.47936

Timestep Collection Time: 2.15139
Timestep Consumption Time: 2.37652
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.52791

Cumulative Model Updates: 186,394
Cumulative Timesteps: 1,554,536,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.94914
Policy Entropy: 2.28722
Value Function Loss: 0.01797

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.67531

Collected Steps per Second: 23,500.29974
Overall Steps per Second: 11,001.38802

Timestep Collection Time: 2.12865
Timestep Consumption Time: 2.41841
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.54706

Cumulative Model Updates: 186,400
Cumulative Timesteps: 1,554,586,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1554586572...
Checkpoint 1554586572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.64689
Policy Entropy: 2.30087
Value Function Loss: 0.01756

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.58683
Value Function Update Magnitude: 0.66499

Collected Steps per Second: 23,065.24014
Overall Steps per Second: 10,738.30885

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.65939

Cumulative Model Updates: 186,406
Cumulative Timesteps: 1,554,636,606

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.86525
Policy Entropy: 2.32866
Value Function Loss: 0.01769

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.64259

Collected Steps per Second: 23,467.49556
Overall Steps per Second: 10,877.48763

Timestep Collection Time: 2.13180
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.59922

Cumulative Model Updates: 186,412
Cumulative Timesteps: 1,554,686,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1554686634...
Checkpoint 1554686634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.23887
Policy Entropy: 2.36517
Value Function Loss: 0.01688

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 23,236.88595
Overall Steps per Second: 10,956.37037

Timestep Collection Time: 2.15296
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.56611

Cumulative Model Updates: 186,418
Cumulative Timesteps: 1,554,736,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.67465
Policy Entropy: 2.37661
Value Function Loss: 0.01655

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.56774
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,588.07074
Overall Steps per Second: 10,952.77494

Timestep Collection Time: 2.21462
Timestep Consumption Time: 2.35262
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.56724

Cumulative Model Updates: 186,424
Cumulative Timesteps: 1,554,786,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1554786686...
Checkpoint 1554786686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.41536
Policy Entropy: 2.35596
Value Function Loss: 0.01587

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 21,488.67961
Overall Steps per Second: 10,347.74482

Timestep Collection Time: 2.32690
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.83216

Cumulative Model Updates: 186,430
Cumulative Timesteps: 1,554,836,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.31232
Policy Entropy: 2.31399
Value Function Loss: 0.01578

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.64538

Collected Steps per Second: 22,779.72790
Overall Steps per Second: 10,754.15327

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.65160

Cumulative Model Updates: 186,436
Cumulative Timesteps: 1,554,886,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1554886712...
Checkpoint 1554886712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.92074
Policy Entropy: 2.28368
Value Function Loss: 0.01529

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.64560

Collected Steps per Second: 22,465.75953
Overall Steps per Second: 10,652.74774

Timestep Collection Time: 2.22579
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.69400

Cumulative Model Updates: 186,442
Cumulative Timesteps: 1,554,936,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.67258
Policy Entropy: 2.28775
Value Function Loss: 0.01407

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.18435
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.62044

Collected Steps per Second: 22,831.63078
Overall Steps per Second: 10,827.17476

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.61912

Cumulative Model Updates: 186,448
Cumulative Timesteps: 1,554,986,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1554986728...
Checkpoint 1554986728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.73177
Policy Entropy: 2.29097
Value Function Loss: 0.01458

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.17496
Policy Update Magnitude: 0.47732
Value Function Update Magnitude: 0.58946

Collected Steps per Second: 22,919.59336
Overall Steps per Second: 10,925.34366

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.39517
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.57688

Cumulative Model Updates: 186,454
Cumulative Timesteps: 1,555,036,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.83476
Policy Entropy: 2.32514
Value Function Loss: 0.01560

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.16590
Policy Update Magnitude: 0.50617
Value Function Update Magnitude: 0.59651

Collected Steps per Second: 23,441.16752
Overall Steps per Second: 10,827.36092

Timestep Collection Time: 2.13360
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.61922

Cumulative Model Updates: 186,460
Cumulative Timesteps: 1,555,086,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1555086746...
Checkpoint 1555086746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.15063
Policy Entropy: 2.34513
Value Function Loss: 0.01670

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.17417
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.62969

Collected Steps per Second: 23,187.51461
Overall Steps per Second: 10,901.02071

Timestep Collection Time: 2.15702
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58819

Cumulative Model Updates: 186,466
Cumulative Timesteps: 1,555,136,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.96731
Policy Entropy: 2.34103
Value Function Loss: 0.01731

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.15832
Policy Update Magnitude: 0.58387
Value Function Update Magnitude: 0.67737

Collected Steps per Second: 23,402.33720
Overall Steps per Second: 10,925.53126

Timestep Collection Time: 2.13774
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.57900

Cumulative Model Updates: 186,472
Cumulative Timesteps: 1,555,186,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1555186790...
Checkpoint 1555186790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.35292
Policy Entropy: 2.32982
Value Function Loss: 0.01730

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.68883

Collected Steps per Second: 22,993.60557
Overall Steps per Second: 10,750.02794

Timestep Collection Time: 2.17452
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.65115

Cumulative Model Updates: 186,478
Cumulative Timesteps: 1,555,236,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.02983
Policy Entropy: 2.31502
Value Function Loss: 0.01782

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.68303

Collected Steps per Second: 22,804.70302
Overall Steps per Second: 10,870.48792

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.60016

Cumulative Model Updates: 186,484
Cumulative Timesteps: 1,555,286,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1555286796...
Checkpoint 1555286796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.05073
Policy Entropy: 2.30668
Value Function Loss: 0.01758

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.59138
Value Function Update Magnitude: 0.68336

Collected Steps per Second: 22,751.41577
Overall Steps per Second: 10,663.48834

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69077

Cumulative Model Updates: 186,490
Cumulative Timesteps: 1,555,336,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.58842
Policy Entropy: 2.30066
Value Function Loss: 0.01793

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.59993
Value Function Update Magnitude: 0.69525

Collected Steps per Second: 23,095.05816
Overall Steps per Second: 10,848.51428

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.61169

Cumulative Model Updates: 186,496
Cumulative Timesteps: 1,555,386,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1555386846...
Checkpoint 1555386846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.49200
Policy Entropy: 2.30139
Value Function Loss: 0.01804

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.58945
Value Function Update Magnitude: 0.69131

Collected Steps per Second: 23,028.77307
Overall Steps per Second: 10,655.29261

Timestep Collection Time: 2.17198
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.69419

Cumulative Model Updates: 186,502
Cumulative Timesteps: 1,555,436,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.53102
Policy Entropy: 2.32072
Value Function Loss: 0.01859

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.68322

Collected Steps per Second: 23,512.31693
Overall Steps per Second: 10,875.38544

Timestep Collection Time: 2.12655
Timestep Consumption Time: 2.47099
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.59754

Cumulative Model Updates: 186,508
Cumulative Timesteps: 1,555,486,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1555486864...
Checkpoint 1555486864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.65999
Policy Entropy: 2.34173
Value Function Loss: 0.01771

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.67844

Collected Steps per Second: 23,087.32326
Overall Steps per Second: 11,076.50497

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.34856
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.51442

Cumulative Model Updates: 186,514
Cumulative Timesteps: 1,555,536,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.65655
Policy Entropy: 2.33434
Value Function Loss: 0.01680

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.57741
Value Function Update Magnitude: 0.67104

Collected Steps per Second: 23,292.98946
Overall Steps per Second: 10,943.88719

Timestep Collection Time: 2.14751
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.57077

Cumulative Model Updates: 186,520
Cumulative Timesteps: 1,555,586,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1555586890...
Checkpoint 1555586890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.75424
Policy Entropy: 2.34336
Value Function Loss: 0.01614

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.58137
Value Function Update Magnitude: 0.65182

Collected Steps per Second: 22,724.17356
Overall Steps per Second: 10,697.71521

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67483

Cumulative Model Updates: 186,526
Cumulative Timesteps: 1,555,636,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.58275
Policy Entropy: 2.33646
Value Function Loss: 0.01638

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.65297

Collected Steps per Second: 22,689.79181
Overall Steps per Second: 10,815.51795

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62484

Cumulative Model Updates: 186,532
Cumulative Timesteps: 1,555,686,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1555686920...
Checkpoint 1555686920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.79620
Policy Entropy: 2.36286
Value Function Loss: 0.01587

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.65218

Collected Steps per Second: 22,208.01522
Overall Steps per Second: 10,760.53047

Timestep Collection Time: 2.25288
Timestep Consumption Time: 2.39670
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.64958

Cumulative Model Updates: 186,538
Cumulative Timesteps: 1,555,736,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.87779
Policy Entropy: 2.36146
Value Function Loss: 0.01583

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.63537

Collected Steps per Second: 23,024.16811
Overall Steps per Second: 10,877.54195

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.59938

Cumulative Model Updates: 186,544
Cumulative Timesteps: 1,555,786,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1555786982...
Checkpoint 1555786982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.43359
Policy Entropy: 2.36581
Value Function Loss: 0.01552

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.56705
Value Function Update Magnitude: 0.62709

Collected Steps per Second: 22,613.63580
Overall Steps per Second: 10,630.38131

Timestep Collection Time: 2.21141
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70425

Cumulative Model Updates: 186,550
Cumulative Timesteps: 1,555,836,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.24025
Policy Entropy: 2.37169
Value Function Loss: 0.01563

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.61769

Collected Steps per Second: 23,028.71810
Overall Steps per Second: 10,844.79646

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61069

Cumulative Model Updates: 186,556
Cumulative Timesteps: 1,555,886,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1555886992...
Checkpoint 1555886992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.80708
Policy Entropy: 2.38546
Value Function Loss: 0.01559

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.56018
Value Function Update Magnitude: 0.58298

Collected Steps per Second: 22,983.35593
Overall Steps per Second: 10,714.69771

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.66891

Cumulative Model Updates: 186,562
Cumulative Timesteps: 1,555,937,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.24034
Policy Entropy: 2.37304
Value Function Loss: 0.01609

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.58719

Collected Steps per Second: 23,213.02320
Overall Steps per Second: 10,858.16560

Timestep Collection Time: 2.15500
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.60704

Cumulative Model Updates: 186,568
Cumulative Timesteps: 1,555,987,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1555987042...
Checkpoint 1555987042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.24713
Policy Entropy: 2.36112
Value Function Loss: 0.01750

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 23,127.27828
Overall Steps per Second: 10,760.30231

Timestep Collection Time: 2.16221
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.64727

Cumulative Model Updates: 186,574
Cumulative Timesteps: 1,556,037,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.39214
Policy Entropy: 2.34580
Value Function Loss: 0.01656

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.59189

Collected Steps per Second: 23,399.30103
Overall Steps per Second: 11,023.79349

Timestep Collection Time: 2.13733
Timestep Consumption Time: 2.39940
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.53673

Cumulative Model Updates: 186,580
Cumulative Timesteps: 1,556,087,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1556087060...
Checkpoint 1556087060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.82166
Policy Entropy: 2.36204
Value Function Loss: 0.01609

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.57565

Collected Steps per Second: 23,274.98505
Overall Steps per Second: 10,960.37540

Timestep Collection Time: 2.14943
Timestep Consumption Time: 2.41501
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.56444

Cumulative Model Updates: 186,586
Cumulative Timesteps: 1,556,137,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.34248
Policy Entropy: 2.35834
Value Function Loss: 0.01584

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 23,242.81095
Overall Steps per Second: 10,878.65433

Timestep Collection Time: 2.15120
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.59616

Cumulative Model Updates: 186,592
Cumulative Timesteps: 1,556,187,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1556187088...
Checkpoint 1556187088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.19763
Policy Entropy: 2.37889
Value Function Loss: 0.01524

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.54793

Collected Steps per Second: 22,601.57025
Overall Steps per Second: 10,662.35039

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.69071

Cumulative Model Updates: 186,598
Cumulative Timesteps: 1,556,237,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.05145
Policy Entropy: 2.36934
Value Function Loss: 0.01561

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.54404

Collected Steps per Second: 22,557.22804
Overall Steps per Second: 10,803.79724

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.41171
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.62856

Cumulative Model Updates: 186,604
Cumulative Timesteps: 1,556,287,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1556287108...
Checkpoint 1556287108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.64033
Policy Entropy: 2.38028
Value Function Loss: 0.01570

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.56137

Collected Steps per Second: 22,238.61324
Overall Steps per Second: 10,713.02000

Timestep Collection Time: 2.24852
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.66759

Cumulative Model Updates: 186,610
Cumulative Timesteps: 1,556,337,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.68027
Policy Entropy: 2.36968
Value Function Loss: 0.01543

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 22,940.10495
Overall Steps per Second: 10,801.77229

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62980

Cumulative Model Updates: 186,616
Cumulative Timesteps: 1,556,387,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1556387122...
Checkpoint 1556387122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.90958
Policy Entropy: 2.37950
Value Function Loss: 0.01492

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.56119

Collected Steps per Second: 23,059.76565
Overall Steps per Second: 10,715.61165

Timestep Collection Time: 2.16923
Timestep Consumption Time: 2.49891
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.66814

Cumulative Model Updates: 186,622
Cumulative Timesteps: 1,556,437,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.44640
Policy Entropy: 2.37040
Value Function Loss: 0.01439

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.54492

Collected Steps per Second: 23,093.68717
Overall Steps per Second: 10,915.70784

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.58312

Cumulative Model Updates: 186,628
Cumulative Timesteps: 1,556,487,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1556487172...
Checkpoint 1556487172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.64487
Policy Entropy: 2.35613
Value Function Loss: 0.01517

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.54358

Collected Steps per Second: 22,762.89056
Overall Steps per Second: 10,894.69449

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.39331
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.59031

Cumulative Model Updates: 186,634
Cumulative Timesteps: 1,556,537,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.02947
Policy Entropy: 2.33599
Value Function Loss: 0.01618

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.58089

Collected Steps per Second: 23,475.43528
Overall Steps per Second: 10,736.00087

Timestep Collection Time: 2.13099
Timestep Consumption Time: 2.52866
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.65965

Cumulative Model Updates: 186,640
Cumulative Timesteps: 1,556,587,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1556587208...
Checkpoint 1556587208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.89752
Policy Entropy: 2.35855
Value Function Loss: 0.01590

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 23,239.77756
Overall Steps per Second: 10,832.01569

Timestep Collection Time: 2.15252
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.61816

Cumulative Model Updates: 186,646
Cumulative Timesteps: 1,556,637,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.33410
Policy Entropy: 2.35645
Value Function Loss: 0.01605

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.59419

Collected Steps per Second: 23,274.94353
Overall Steps per Second: 10,741.39463

Timestep Collection Time: 2.14875
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.65601

Cumulative Model Updates: 186,652
Cumulative Timesteps: 1,556,687,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1556687244...
Checkpoint 1556687244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.95553
Policy Entropy: 2.35833
Value Function Loss: 0.01651

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.58648

Collected Steps per Second: 22,620.14270
Overall Steps per Second: 10,668.18195

Timestep Collection Time: 2.21042
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.68683

Cumulative Model Updates: 186,658
Cumulative Timesteps: 1,556,737,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.05611
Policy Entropy: 2.36746
Value Function Loss: 0.01620

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.57254

Collected Steps per Second: 22,679.99868
Overall Steps per Second: 10,772.01262

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.64240

Cumulative Model Updates: 186,664
Cumulative Timesteps: 1,556,787,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1556787252...
Checkpoint 1556787252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.48566
Policy Entropy: 2.37088
Value Function Loss: 0.01613

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.55284

Collected Steps per Second: 22,520.88830
Overall Steps per Second: 10,633.65206

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.70224

Cumulative Model Updates: 186,670
Cumulative Timesteps: 1,556,837,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.38483
Policy Entropy: 2.36445
Value Function Loss: 0.01525

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.55512

Collected Steps per Second: 22,791.74495
Overall Steps per Second: 10,687.73162

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.67957

Cumulative Model Updates: 186,676
Cumulative Timesteps: 1,556,887,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1556887268...
Checkpoint 1556887268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.32857
Policy Entropy: 2.35221
Value Function Loss: 0.01539

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.54666
Value Function Update Magnitude: 0.54995

Collected Steps per Second: 23,280.84839
Overall Steps per Second: 10,921.63730

Timestep Collection Time: 2.14820
Timestep Consumption Time: 2.43096
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.57917

Cumulative Model Updates: 186,682
Cumulative Timesteps: 1,556,937,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.93740
Policy Entropy: 2.33999
Value Function Loss: 0.01536

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.55271
Value Function Update Magnitude: 0.55489

Collected Steps per Second: 23,078.04019
Overall Steps per Second: 10,816.27726

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.62359

Cumulative Model Updates: 186,688
Cumulative Timesteps: 1,556,987,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1556987290...
Checkpoint 1556987290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.35688
Policy Entropy: 2.35892
Value Function Loss: 0.01544

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.57060

Collected Steps per Second: 22,982.36048
Overall Steps per Second: 10,952.90875

Timestep Collection Time: 2.17680
Timestep Consumption Time: 2.39075
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.56755

Cumulative Model Updates: 186,694
Cumulative Timesteps: 1,557,037,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.10455
Policy Entropy: 2.33943
Value Function Loss: 0.01496

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.57068

Collected Steps per Second: 23,225.08885
Overall Steps per Second: 10,737.60569

Timestep Collection Time: 2.15414
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.65933

Cumulative Model Updates: 186,700
Cumulative Timesteps: 1,557,087,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1557087348...
Checkpoint 1557087348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.46641
Policy Entropy: 2.33750
Value Function Loss: 0.01529

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 23,487.49414
Overall Steps per Second: 10,972.70327

Timestep Collection Time: 2.12922
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.55767

Cumulative Model Updates: 186,706
Cumulative Timesteps: 1,557,137,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.66694
Policy Entropy: 2.32265
Value Function Loss: 0.01518

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 23,056.81994
Overall Steps per Second: 10,868.62047

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60095

Cumulative Model Updates: 186,712
Cumulative Timesteps: 1,557,187,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1557187364...
Checkpoint 1557187364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.25914
Policy Entropy: 2.30862
Value Function Loss: 0.01570

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.54963
Value Function Update Magnitude: 0.54116

Collected Steps per Second: 22,364.17453
Overall Steps per Second: 10,742.83123

Timestep Collection Time: 2.23617
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.65520

Cumulative Model Updates: 186,718
Cumulative Timesteps: 1,557,237,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.52310
Policy Entropy: 2.30874
Value Function Loss: 0.01585

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.54395

Collected Steps per Second: 23,092.48083
Overall Steps per Second: 10,871.02773

Timestep Collection Time: 2.16573
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.60048

Cumulative Model Updates: 186,724
Cumulative Timesteps: 1,557,287,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1557287386...
Checkpoint 1557287386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.80642
Policy Entropy: 2.31710
Value Function Loss: 0.01640

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.56634

Collected Steps per Second: 22,606.50457
Overall Steps per Second: 10,678.89379

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.47107
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.68344

Cumulative Model Updates: 186,730
Cumulative Timesteps: 1,557,337,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.63017
Policy Entropy: 2.32895
Value Function Loss: 0.01633

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.58640

Collected Steps per Second: 23,059.12748
Overall Steps per Second: 10,845.05553

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61224

Cumulative Model Updates: 186,736
Cumulative Timesteps: 1,557,387,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1557387420...
Checkpoint 1557387420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.97781
Policy Entropy: 2.32597
Value Function Loss: 0.01657

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.58259

Collected Steps per Second: 22,918.91300
Overall Steps per Second: 10,688.96843

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.68053

Cumulative Model Updates: 186,742
Cumulative Timesteps: 1,557,437,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.77859
Policy Entropy: 2.29166
Value Function Loss: 0.01610

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.58803

Collected Steps per Second: 23,225.81232
Overall Steps per Second: 10,934.83193

Timestep Collection Time: 2.15329
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.57364

Cumulative Model Updates: 186,748
Cumulative Timesteps: 1,557,487,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1557487462...
Checkpoint 1557487462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.29544
Policy Entropy: 2.29707
Value Function Loss: 0.01538

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.58057

Collected Steps per Second: 23,392.41351
Overall Steps per Second: 10,831.60260

Timestep Collection Time: 2.13804
Timestep Consumption Time: 2.47937
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.61741

Cumulative Model Updates: 186,754
Cumulative Timesteps: 1,557,537,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.32241
Policy Entropy: 2.29400
Value Function Loss: 0.01687

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.58296

Collected Steps per Second: 23,395.60013
Overall Steps per Second: 10,796.73268

Timestep Collection Time: 2.13767
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.63214

Cumulative Model Updates: 186,760
Cumulative Timesteps: 1,557,587,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1557587488...
Checkpoint 1557587488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.64188
Policy Entropy: 2.31137
Value Function Loss: 0.01780

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 23,235.94325
Overall Steps per Second: 10,916.74730

Timestep Collection Time: 2.15287
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58232

Cumulative Model Updates: 186,766
Cumulative Timesteps: 1,557,637,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.94600
Policy Entropy: 2.32410
Value Function Loss: 0.01822

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 23,058.27554
Overall Steps per Second: 10,912.80966

Timestep Collection Time: 2.16894
Timestep Consumption Time: 2.41393
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.58287

Cumulative Model Updates: 186,772
Cumulative Timesteps: 1,557,687,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1557687524...
Checkpoint 1557687524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.19214
Policy Entropy: 2.34910
Value Function Loss: 0.01613

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.60277

Collected Steps per Second: 22,690.57231
Overall Steps per Second: 10,832.08671

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.61702

Cumulative Model Updates: 186,778
Cumulative Timesteps: 1,557,737,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.51131
Policy Entropy: 2.33270
Value Function Loss: 0.01558

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.59455

Collected Steps per Second: 22,138.34376
Overall Steps per Second: 10,855.95597

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.34799
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.60724

Cumulative Model Updates: 186,784
Cumulative Timesteps: 1,557,787,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1557787552...
Checkpoint 1557787552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.73398
Policy Entropy: 2.33613
Value Function Loss: 0.01629

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,807.70076
Overall Steps per Second: 10,633.65111

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70243

Cumulative Model Updates: 186,790
Cumulative Timesteps: 1,557,837,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.78736
Policy Entropy: 2.33005
Value Function Loss: 0.01673

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.63346

Collected Steps per Second: 22,998.28260
Overall Steps per Second: 10,803.39851

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63058

Cumulative Model Updates: 186,796
Cumulative Timesteps: 1,557,887,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1557887582...
Checkpoint 1557887582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.35458
Policy Entropy: 2.35347
Value Function Loss: 0.01620

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.55960
Value Function Update Magnitude: 0.62814

Collected Steps per Second: 23,095.04120
Overall Steps per Second: 10,743.22307

Timestep Collection Time: 2.16566
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.65559

Cumulative Model Updates: 186,802
Cumulative Timesteps: 1,557,937,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.18164
Policy Entropy: 2.32026
Value Function Loss: 0.01531

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.60055

Collected Steps per Second: 23,325.68461
Overall Steps per Second: 10,932.54394

Timestep Collection Time: 2.14476
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.57606

Cumulative Model Updates: 186,808
Cumulative Timesteps: 1,557,987,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1557987626...
Checkpoint 1557987626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.50344
Policy Entropy: 2.32239
Value Function Loss: 0.01614

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.59985

Collected Steps per Second: 23,301.17462
Overall Steps per Second: 10,931.59351

Timestep Collection Time: 2.14616
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.57463

Cumulative Model Updates: 186,814
Cumulative Timesteps: 1,558,037,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.96131
Policy Entropy: 2.33381
Value Function Loss: 0.01635

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 23,228.42495
Overall Steps per Second: 10,902.97914

Timestep Collection Time: 2.15262
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.58609

Cumulative Model Updates: 186,820
Cumulative Timesteps: 1,558,087,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1558087636...
Checkpoint 1558087636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.40910
Policy Entropy: 2.33695
Value Function Loss: 0.01582

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.61049

Collected Steps per Second: 22,922.57516
Overall Steps per Second: 10,724.42408

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.48120
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.66263

Cumulative Model Updates: 186,826
Cumulative Timesteps: 1,558,137,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.27663
Policy Entropy: 2.33390
Value Function Loss: 0.01561

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.59933

Collected Steps per Second: 22,492.45678
Overall Steps per Second: 10,689.93342

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.45443
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.67748

Cumulative Model Updates: 186,832
Cumulative Timesteps: 1,558,187,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1558187642...
Checkpoint 1558187642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.68567
Policy Entropy: 2.32442
Value Function Loss: 0.01504

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 22,629.98539
Overall Steps per Second: 10,881.59222

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.38546
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.59492

Cumulative Model Updates: 186,838
Cumulative Timesteps: 1,558,237,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.84003
Policy Entropy: 2.30462
Value Function Loss: 0.01537

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.57988

Collected Steps per Second: 23,187.12908
Overall Steps per Second: 10,862.44702

Timestep Collection Time: 2.15680
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60393

Cumulative Model Updates: 186,844
Cumulative Timesteps: 1,558,287,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1558287652...
Checkpoint 1558287652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.05646
Policy Entropy: 2.31945
Value Function Loss: 0.01553

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.17637
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.57559

Collected Steps per Second: 23,187.15468
Overall Steps per Second: 10,693.31368

Timestep Collection Time: 2.15645
Timestep Consumption Time: 2.51955
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.67601

Cumulative Model Updates: 186,850
Cumulative Timesteps: 1,558,337,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.60126
Policy Entropy: 2.35675
Value Function Loss: 0.01596

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.51846
Value Function Update Magnitude: 0.58484

Collected Steps per Second: 23,300.53054
Overall Steps per Second: 10,810.52832

Timestep Collection Time: 2.14665
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.62679

Cumulative Model Updates: 186,856
Cumulative Timesteps: 1,558,387,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1558387672...
Checkpoint 1558387672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.59590
Policy Entropy: 2.36863
Value Function Loss: 0.01599

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.58337

Collected Steps per Second: 23,172.20444
Overall Steps per Second: 11,059.47379

Timestep Collection Time: 2.15784
Timestep Consumption Time: 2.36335
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.52119

Cumulative Model Updates: 186,862
Cumulative Timesteps: 1,558,437,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.36019
Policy Entropy: 2.38450
Value Function Loss: 0.01535

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.58516

Collected Steps per Second: 23,242.59268
Overall Steps per Second: 10,933.15783

Timestep Collection Time: 2.15140
Timestep Consumption Time: 2.42221
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.57361

Cumulative Model Updates: 186,868
Cumulative Timesteps: 1,558,487,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1558487678...
Checkpoint 1558487678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.38880
Policy Entropy: 2.33617
Value Function Loss: 0.01588

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 23,155.58861
Overall Steps per Second: 10,724.44310

Timestep Collection Time: 2.15974
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66318

Cumulative Model Updates: 186,874
Cumulative Timesteps: 1,558,537,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.29598
Policy Entropy: 2.33646
Value Function Loss: 0.01533

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.57063

Collected Steps per Second: 23,105.31134
Overall Steps per Second: 10,868.92668

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60119

Cumulative Model Updates: 186,880
Cumulative Timesteps: 1,558,587,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1558587698...
Checkpoint 1558587698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.02558
Policy Entropy: 2.32180
Value Function Loss: 0.01583

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.57666

Collected Steps per Second: 22,648.94979
Overall Steps per Second: 10,656.61474

Timestep Collection Time: 2.20805
Timestep Consumption Time: 2.48481
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69286

Cumulative Model Updates: 186,886
Cumulative Timesteps: 1,558,637,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.15038
Policy Entropy: 2.34856
Value Function Loss: 0.01565

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.55752

Collected Steps per Second: 22,580.21191
Overall Steps per Second: 10,872.70341

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.38434
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.59867

Cumulative Model Updates: 186,892
Cumulative Timesteps: 1,558,687,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1558687708...
Checkpoint 1558687708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.62605
Policy Entropy: 2.37091
Value Function Loss: 0.01626

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.53391

Collected Steps per Second: 22,457.99691
Overall Steps per Second: 10,757.50163

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.64848

Cumulative Model Updates: 186,898
Cumulative Timesteps: 1,558,737,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.76120
Policy Entropy: 2.37162
Value Function Loss: 0.01566

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.53811

Collected Steps per Second: 22,505.82927
Overall Steps per Second: 10,739.97044

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.65737

Cumulative Model Updates: 186,904
Cumulative Timesteps: 1,558,787,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1558787734...
Checkpoint 1558787734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.03490
Policy Entropy: 2.36486
Value Function Loss: 0.01515

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.53304
Value Function Update Magnitude: 0.52004

Collected Steps per Second: 22,975.83335
Overall Steps per Second: 10,753.25350

Timestep Collection Time: 2.17742
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.65236

Cumulative Model Updates: 186,910
Cumulative Timesteps: 1,558,837,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.74625
Policy Entropy: 2.35325
Value Function Loss: 0.01467

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.51713

Collected Steps per Second: 22,519.45206
Overall Steps per Second: 10,801.02079

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.40976
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63086

Cumulative Model Updates: 186,916
Cumulative Timesteps: 1,558,887,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1558887780...
Checkpoint 1558887780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.44739
Policy Entropy: 2.35359
Value Function Loss: 0.01461

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.52797

Collected Steps per Second: 22,908.04585
Overall Steps per Second: 10,894.22442

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.40782
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.59124

Cumulative Model Updates: 186,922
Cumulative Timesteps: 1,558,937,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.53217
Policy Entropy: 2.34696
Value Function Loss: 0.01484

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 23,557.23478
Overall Steps per Second: 10,789.56821

Timestep Collection Time: 2.12283
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.63485

Cumulative Model Updates: 186,928
Cumulative Timesteps: 1,558,987,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1558987806...
Checkpoint 1558987806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.27988
Policy Entropy: 2.36359
Value Function Loss: 0.01498

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.58146

Collected Steps per Second: 23,240.95666
Overall Steps per Second: 10,811.06277

Timestep Collection Time: 2.15163
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.62545

Cumulative Model Updates: 186,934
Cumulative Timesteps: 1,559,037,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.82600
Policy Entropy: 2.34312
Value Function Loss: 0.01435

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 23,052.37639
Overall Steps per Second: 10,724.27964

Timestep Collection Time: 2.16915
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.66269

Cumulative Model Updates: 186,940
Cumulative Timesteps: 1,559,087,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1559087816...
Checkpoint 1559087816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.43873
Policy Entropy: 2.35330
Value Function Loss: 0.01474

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.57811

Collected Steps per Second: 22,618.08161
Overall Steps per Second: 10,666.40460

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.47769
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.68893

Cumulative Model Updates: 186,946
Cumulative Timesteps: 1,559,137,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.99798
Policy Entropy: 2.34231
Value Function Loss: 0.01481

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.55534

Collected Steps per Second: 22,778.06829
Overall Steps per Second: 10,874.13749

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.40413
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.60027

Cumulative Model Updates: 186,952
Cumulative Timesteps: 1,559,187,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1559187854...
Checkpoint 1559187854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.24163
Policy Entropy: 2.35657
Value Function Loss: 0.01565

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.55592
Value Function Update Magnitude: 0.54246

Collected Steps per Second: 22,766.56970
Overall Steps per Second: 10,635.77232

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.70300

Cumulative Model Updates: 186,958
Cumulative Timesteps: 1,559,237,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.02745
Policy Entropy: 2.34478
Value Function Loss: 0.01623

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.55028

Collected Steps per Second: 23,365.34706
Overall Steps per Second: 10,944.51837

Timestep Collection Time: 2.14086
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.57051

Cumulative Model Updates: 186,964
Cumulative Timesteps: 1,559,287,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1559287896...
Checkpoint 1559287896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.76081
Policy Entropy: 2.33278
Value Function Loss: 0.01681

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.57029

Collected Steps per Second: 23,110.54239
Overall Steps per Second: 10,626.72427

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.54191
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.70568

Cumulative Model Updates: 186,970
Cumulative Timesteps: 1,559,337,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.10574
Policy Entropy: 2.35239
Value Function Loss: 0.01619

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.55080

Collected Steps per Second: 22,940.13161
Overall Steps per Second: 10,889.49078

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.59324

Cumulative Model Updates: 186,976
Cumulative Timesteps: 1,559,387,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1559387920...
Checkpoint 1559387920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.68231
Policy Entropy: 2.36548
Value Function Loss: 0.01552

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.54559
Value Function Update Magnitude: 0.53409

Collected Steps per Second: 23,211.50587
Overall Steps per Second: 11,087.05041

Timestep Collection Time: 2.15531
Timestep Consumption Time: 2.35698
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.51229

Cumulative Model Updates: 186,982
Cumulative Timesteps: 1,559,437,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.71049
Policy Entropy: 2.38492
Value Function Loss: 0.01601

Mean KL Divergence: 0.02765
SB3 Clip Fraction: 0.17968
Policy Update Magnitude: 0.51428
Value Function Update Magnitude: 0.54823

Collected Steps per Second: 23,368.58356
Overall Steps per Second: 10,961.88599

Timestep Collection Time: 2.13997
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.56199

Cumulative Model Updates: 186,988
Cumulative Timesteps: 1,559,487,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1559487956...
Checkpoint 1559487956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.03554
Policy Entropy: 2.38416
Value Function Loss: 0.01583

Mean KL Divergence: 0.05228
SB3 Clip Fraction: 0.25024
Policy Update Magnitude: 0.47786
Value Function Update Magnitude: 0.57035

Collected Steps per Second: 23,137.99635
Overall Steps per Second: 10,814.93779

Timestep Collection Time: 2.16095
Timestep Consumption Time: 2.46229
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.62324

Cumulative Model Updates: 186,994
Cumulative Timesteps: 1,559,537,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.75868
Policy Entropy: 2.35444
Value Function Loss: 0.01719

Mean KL Divergence: 0.03835
SB3 Clip Fraction: 0.21797
Policy Update Magnitude: 0.51581
Value Function Update Magnitude: 0.58359

Collected Steps per Second: 22,409.76060
Overall Steps per Second: 10,723.78220

Timestep Collection Time: 2.23242
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.66515

Cumulative Model Updates: 187,000
Cumulative Timesteps: 1,559,587,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1559587984...
Checkpoint 1559587984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.41560
Policy Entropy: 2.35132
Value Function Loss: 0.01751

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 22,164.37757
Overall Steps per Second: 10,600.14061

Timestep Collection Time: 2.25650
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.71824

Cumulative Model Updates: 187,006
Cumulative Timesteps: 1,559,637,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.73379
Policy Entropy: 2.33770
Value Function Loss: 0.01716

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.17967
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.59227

Collected Steps per Second: 22,592.27646
Overall Steps per Second: 10,929.69819

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.36183
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.57524

Cumulative Model Updates: 187,012
Cumulative Timesteps: 1,559,688,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1559688004...
Checkpoint 1559688004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.86212
Policy Entropy: 2.34694
Value Function Loss: 0.01683

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.17062
Policy Update Magnitude: 0.57228
Value Function Update Magnitude: 0.58350

Collected Steps per Second: 22,431.36009
Overall Steps per Second: 10,678.89530

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.68269

Cumulative Model Updates: 187,018
Cumulative Timesteps: 1,559,738,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.36372
Policy Entropy: 2.34741
Value Function Loss: 0.01670

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.16602
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.57839

Collected Steps per Second: 23,260.53925
Overall Steps per Second: 10,764.34468

Timestep Collection Time: 2.14974
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.64534

Cumulative Model Updates: 187,024
Cumulative Timesteps: 1,559,788,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1559788014...
Checkpoint 1559788014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.83428
Policy Entropy: 2.34090
Value Function Loss: 0.01691

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 22,977.41508
Overall Steps per Second: 10,740.79881

Timestep Collection Time: 2.17683
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.65682

Cumulative Model Updates: 187,030
Cumulative Timesteps: 1,559,838,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.73045
Policy Entropy: 2.34817
Value Function Loss: 0.01679

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.56907

Collected Steps per Second: 23,113.32153
Overall Steps per Second: 10,869.89494

Timestep Collection Time: 2.16429
Timestep Consumption Time: 2.43778
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.60207

Cumulative Model Updates: 187,036
Cumulative Timesteps: 1,559,888,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1559888056...
Checkpoint 1559888056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.01070
Policy Entropy: 2.36067
Value Function Loss: 0.01592

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.56864

Collected Steps per Second: 23,305.77398
Overall Steps per Second: 10,811.06594

Timestep Collection Time: 2.14651
Timestep Consumption Time: 2.48079
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.62730

Cumulative Model Updates: 187,042
Cumulative Timesteps: 1,559,938,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.83339
Policy Entropy: 2.36830
Value Function Loss: 0.01600

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.57585
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 23,008.48875
Overall Steps per Second: 10,828.98735

Timestep Collection Time: 2.17311
Timestep Consumption Time: 2.44413
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.61724

Cumulative Model Updates: 187,048
Cumulative Timesteps: 1,559,988,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1559988082...
Checkpoint 1559988082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.49746
Policy Entropy: 2.38593
Value Function Loss: 0.01514

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.57274
Value Function Update Magnitude: 0.58877

Collected Steps per Second: 22,784.07077
Overall Steps per Second: 10,613.53178

Timestep Collection Time: 2.19522
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.71247

Cumulative Model Updates: 187,054
Cumulative Timesteps: 1,560,038,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.73713
Policy Entropy: 2.38314
Value Function Loss: 0.01512

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.56403

Collected Steps per Second: 22,906.94165
Overall Steps per Second: 10,841.92368

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61247

Cumulative Model Updates: 187,060
Cumulative Timesteps: 1,560,088,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1560088106...
Checkpoint 1560088106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.23406
Policy Entropy: 2.38719
Value Function Loss: 0.01449

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.55319
Value Function Update Magnitude: 0.55426

Collected Steps per Second: 22,489.42652
Overall Steps per Second: 10,733.61556

Timestep Collection Time: 2.22353
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.65882

Cumulative Model Updates: 187,066
Cumulative Timesteps: 1,560,138,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.44746
Policy Entropy: 2.39934
Value Function Loss: 0.01566

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.55865

Collected Steps per Second: 23,248.04896
Overall Steps per Second: 10,895.38916

Timestep Collection Time: 2.15098
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.58965

Cumulative Model Updates: 187,072
Cumulative Timesteps: 1,560,188,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1560188118...
Checkpoint 1560188118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.86393
Policy Entropy: 2.40439
Value Function Loss: 0.01540

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.55417

Collected Steps per Second: 23,207.92391
Overall Steps per Second: 11,047.08129

Timestep Collection Time: 2.15547
Timestep Consumption Time: 2.37278
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.52825

Cumulative Model Updates: 187,078
Cumulative Timesteps: 1,560,238,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.95936
Policy Entropy: 2.37709
Value Function Loss: 0.01476

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 22,888.36378
Overall Steps per Second: 10,702.74016

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.67301

Cumulative Model Updates: 187,084
Cumulative Timesteps: 1,560,288,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1560288156...
Checkpoint 1560288156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.54398
Policy Entropy: 2.37379
Value Function Loss: 0.01382

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.54704
Value Function Update Magnitude: 0.54015

Collected Steps per Second: 23,533.30336
Overall Steps per Second: 10,916.28952

Timestep Collection Time: 2.12524
Timestep Consumption Time: 2.45635
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.58159

Cumulative Model Updates: 187,090
Cumulative Timesteps: 1,560,338,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.62746
Policy Entropy: 2.36780
Value Function Loss: 0.01452

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.53238

Collected Steps per Second: 23,233.23882
Overall Steps per Second: 10,868.92056

Timestep Collection Time: 2.15261
Timestep Consumption Time: 2.44877
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.60138

Cumulative Model Updates: 187,096
Cumulative Timesteps: 1,560,388,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1560388182...
Checkpoint 1560388182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.14564
Policy Entropy: 2.36717
Value Function Loss: 0.01499

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.55170

Collected Steps per Second: 22,917.52983
Overall Steps per Second: 10,734.20526

Timestep Collection Time: 2.18261
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.65987

Cumulative Model Updates: 187,102
Cumulative Timesteps: 1,560,438,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.13105
Policy Entropy: 2.35956
Value Function Loss: 0.01536

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 22,534.08651
Overall Steps per Second: 10,868.31754

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.38176
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.60071

Cumulative Model Updates: 187,108
Cumulative Timesteps: 1,560,488,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1560488204...
Checkpoint 1560488204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.52924
Policy Entropy: 2.36122
Value Function Loss: 0.01617

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 22,948.81228
Overall Steps per Second: 10,745.58378

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.65531

Cumulative Model Updates: 187,114
Cumulative Timesteps: 1,560,538,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.43931
Policy Entropy: 2.36343
Value Function Loss: 0.01703

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,859.94752
Overall Steps per Second: 10,818.54460

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.62373

Cumulative Model Updates: 187,120
Cumulative Timesteps: 1,560,588,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1560588250...
Checkpoint 1560588250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.33533
Policy Entropy: 2.35037
Value Function Loss: 0.01725

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.60162

Collected Steps per Second: 21,754.61219
Overall Steps per Second: 10,578.79434

Timestep Collection Time: 2.29864
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.72700

Cumulative Model Updates: 187,126
Cumulative Timesteps: 1,560,638,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.96608
Policy Entropy: 2.33994
Value Function Loss: 0.01615

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.58905

Collected Steps per Second: 23,164.75767
Overall Steps per Second: 10,875.65503

Timestep Collection Time: 2.15949
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59963

Cumulative Model Updates: 187,132
Cumulative Timesteps: 1,560,688,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1560688280...
Checkpoint 1560688280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.70828
Policy Entropy: 2.34213
Value Function Loss: 0.01619

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.57473

Collected Steps per Second: 23,236.81240
Overall Steps per Second: 11,093.25760

Timestep Collection Time: 2.15184
Timestep Consumption Time: 2.35558
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.50742

Cumulative Model Updates: 187,138
Cumulative Timesteps: 1,560,738,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.82381
Policy Entropy: 2.35304
Value Function Loss: 0.01517

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.57140

Collected Steps per Second: 23,189.64551
Overall Steps per Second: 10,886.35552

Timestep Collection Time: 2.15665
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59401

Cumulative Model Updates: 187,144
Cumulative Timesteps: 1,560,788,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1560788294...
Checkpoint 1560788294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.22806
Policy Entropy: 2.36255
Value Function Loss: 0.01725

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.56361

Collected Steps per Second: 22,934.16560
Overall Steps per Second: 10,742.82950

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.47510
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.65613

Cumulative Model Updates: 187,150
Cumulative Timesteps: 1,560,838,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.89999
Policy Entropy: 2.36243
Value Function Loss: 0.01708

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.56995

Collected Steps per Second: 23,333.84776
Overall Steps per Second: 10,874.05642

Timestep Collection Time: 2.14350
Timestep Consumption Time: 2.45608
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.59957

Cumulative Model Updates: 187,156
Cumulative Timesteps: 1,560,888,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1560888330...
Checkpoint 1560888330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.09959
Policy Entropy: 2.35726
Value Function Loss: 0.01801

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.17036
Policy Update Magnitude: 0.56097
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 23,008.74865
Overall Steps per Second: 10,768.36960

Timestep Collection Time: 2.17326
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.64360

Cumulative Model Updates: 187,162
Cumulative Timesteps: 1,560,938,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.72782
Policy Entropy: 2.35317
Value Function Loss: 0.01678

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.16528
Policy Update Magnitude: 0.57755
Value Function Update Magnitude: 0.62878

Collected Steps per Second: 22,944.27487
Overall Steps per Second: 10,831.03704

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.61729

Cumulative Model Updates: 187,168
Cumulative Timesteps: 1,560,988,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1560988344...
Checkpoint 1560988344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.98792
Policy Entropy: 2.34182
Value Function Loss: 0.01707

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.58586
Value Function Update Magnitude: 0.62285

Collected Steps per Second: 22,706.41122
Overall Steps per Second: 10,617.58830

Timestep Collection Time: 2.20317
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.71162

Cumulative Model Updates: 187,174
Cumulative Timesteps: 1,561,038,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.31519
Policy Entropy: 2.33583
Value Function Loss: 0.01649

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.58630
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 22,701.23659
Overall Steps per Second: 10,665.71148

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.48659
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69017

Cumulative Model Updates: 187,180
Cumulative Timesteps: 1,561,088,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1561088394...
Checkpoint 1561088394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.14825
Policy Entropy: 2.32789
Value Function Loss: 0.01629

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.59180

Collected Steps per Second: 22,746.91332
Overall Steps per Second: 10,848.87913

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61006

Cumulative Model Updates: 187,186
Cumulative Timesteps: 1,561,138,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.13920
Policy Entropy: 2.35170
Value Function Loss: 0.01602

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.60198

Collected Steps per Second: 23,114.57322
Overall Steps per Second: 10,951.17155

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.40374
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.56791

Cumulative Model Updates: 187,192
Cumulative Timesteps: 1,561,188,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1561188432...
Checkpoint 1561188432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.20900
Policy Entropy: 2.33983
Value Function Loss: 0.01555

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.59975

Collected Steps per Second: 23,057.40616
Overall Steps per Second: 10,698.09394

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.50613
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.67541

Cumulative Model Updates: 187,198
Cumulative Timesteps: 1,561,238,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.89882
Policy Entropy: 2.34693
Value Function Loss: 0.01582

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.57392

Collected Steps per Second: 23,317.15760
Overall Steps per Second: 10,882.27406

Timestep Collection Time: 2.14434
Timestep Consumption Time: 2.45028
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.59463

Cumulative Model Updates: 187,204
Cumulative Timesteps: 1,561,288,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1561288450...
Checkpoint 1561288450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.38198
Policy Entropy: 2.35776
Value Function Loss: 0.01547

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.54154

Collected Steps per Second: 23,073.81794
Overall Steps per Second: 10,712.31955

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.66790

Cumulative Model Updates: 187,210
Cumulative Timesteps: 1,561,338,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.19591
Policy Entropy: 2.38843
Value Function Loss: 0.01594

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.54230

Collected Steps per Second: 23,191.44182
Overall Steps per Second: 10,940.71987

Timestep Collection Time: 2.15614
Timestep Consumption Time: 2.41431
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.57045

Cumulative Model Updates: 187,216
Cumulative Timesteps: 1,561,388,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1561388458...
Checkpoint 1561388458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.72656
Policy Entropy: 2.39711
Value Function Loss: 0.01641

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.55638
Value Function Update Magnitude: 0.56364

Collected Steps per Second: 23,077.98150
Overall Steps per Second: 10,916.89145

Timestep Collection Time: 2.16795
Timestep Consumption Time: 2.41504
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58299

Cumulative Model Updates: 187,222
Cumulative Timesteps: 1,561,438,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.81482
Policy Entropy: 2.37776
Value Function Loss: 0.01626

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.58501

Collected Steps per Second: 22,809.13564
Overall Steps per Second: 10,684.47895

Timestep Collection Time: 2.19272
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68100

Cumulative Model Updates: 187,228
Cumulative Timesteps: 1,561,488,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1561488504...
Checkpoint 1561488504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.86393
Policy Entropy: 2.36742
Value Function Loss: 0.01630

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.59685

Collected Steps per Second: 22,861.93907
Overall Steps per Second: 10,692.21855

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67817

Cumulative Model Updates: 187,234
Cumulative Timesteps: 1,561,538,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.83724
Policy Entropy: 2.36479
Value Function Loss: 0.01551

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.60155

Collected Steps per Second: 22,759.58385
Overall Steps per Second: 10,695.04769

Timestep Collection Time: 2.19802
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.67749

Cumulative Model Updates: 187,240
Cumulative Timesteps: 1,561,588,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1561588550...
Checkpoint 1561588550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.64077
Policy Entropy: 2.34370
Value Function Loss: 0.01551

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 22,778.04627
Overall Steps per Second: 10,997.85187

Timestep Collection Time: 2.19562
Timestep Consumption Time: 2.35181
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.54743

Cumulative Model Updates: 187,246
Cumulative Timesteps: 1,561,638,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.44817
Policy Entropy: 2.35002
Value Function Loss: 0.01608

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.57792

Collected Steps per Second: 23,504.16778
Overall Steps per Second: 10,931.94754

Timestep Collection Time: 2.12822
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.57576

Cumulative Model Updates: 187,252
Cumulative Timesteps: 1,561,688,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1561688584...
Checkpoint 1561688584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.53021
Policy Entropy: 2.35178
Value Function Loss: 0.01599

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.56002
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 23,274.06973
Overall Steps per Second: 10,749.14003

Timestep Collection Time: 2.14943
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.65395

Cumulative Model Updates: 187,258
Cumulative Timesteps: 1,561,738,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.02989
Policy Entropy: 2.38277
Value Function Loss: 0.01558

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.58781

Collected Steps per Second: 22,767.50060
Overall Steps per Second: 10,783.61341

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.63741

Cumulative Model Updates: 187,264
Cumulative Timesteps: 1,561,788,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1561788618...
Checkpoint 1561788618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.65604
Policy Entropy: 2.37965
Value Function Loss: 0.01495

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.57887

Collected Steps per Second: 23,063.42090
Overall Steps per Second: 10,761.62733

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.64707

Cumulative Model Updates: 187,270
Cumulative Timesteps: 1,561,838,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.33385
Policy Entropy: 2.38025
Value Function Loss: 0.01580

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.57516

Collected Steps per Second: 23,256.64565
Overall Steps per Second: 10,917.14067

Timestep Collection Time: 2.15027
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.58069

Cumulative Model Updates: 187,276
Cumulative Timesteps: 1,561,888,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1561888636...
Checkpoint 1561888636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.22833
Policy Entropy: 2.35912
Value Function Loss: 0.01674

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 22,330.78469
Overall Steps per Second: 10,762.57318

Timestep Collection Time: 2.23951
Timestep Consumption Time: 2.40715
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.64666

Cumulative Model Updates: 187,282
Cumulative Timesteps: 1,561,938,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.54649
Policy Entropy: 2.36343
Value Function Loss: 0.01649

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 22,821.86392
Overall Steps per Second: 10,771.35687

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.64287

Cumulative Model Updates: 187,288
Cumulative Timesteps: 1,561,988,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1561988656...
Checkpoint 1561988656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.05826
Policy Entropy: 2.34755
Value Function Loss: 0.01634

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.54807

Collected Steps per Second: 22,454.56648
Overall Steps per Second: 10,627.93940

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.70496

Cumulative Model Updates: 187,294
Cumulative Timesteps: 1,562,038,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.75749
Policy Entropy: 2.37081
Value Function Loss: 0.01590

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.52967

Collected Steps per Second: 22,135.47137
Overall Steps per Second: 10,487.40466

Timestep Collection Time: 2.25891
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.76781

Cumulative Model Updates: 187,300
Cumulative Timesteps: 1,562,088,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1562088662...
Checkpoint 1562088662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499.16442
Policy Entropy: 2.35728
Value Function Loss: 0.01529

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.53596

Collected Steps per Second: 22,780.82366
Overall Steps per Second: 10,995.31956

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.35331
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.54884

Cumulative Model Updates: 187,306
Cumulative Timesteps: 1,562,138,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.61306
Policy Entropy: 2.36329
Value Function Loss: 0.01465

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.52187

Collected Steps per Second: 22,625.46840
Overall Steps per Second: 10,858.41716

Timestep Collection Time: 2.20990
Timestep Consumption Time: 2.39482
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60472

Cumulative Model Updates: 187,312
Cumulative Timesteps: 1,562,188,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1562188678...
Checkpoint 1562188678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.45605
Policy Entropy: 2.34539
Value Function Loss: 0.01484

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.51303

Collected Steps per Second: 23,089.26736
Overall Steps per Second: 10,729.31345

Timestep Collection Time: 2.16681
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.66293

Cumulative Model Updates: 187,318
Cumulative Timesteps: 1,562,238,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.65556
Policy Entropy: 2.35476
Value Function Loss: 0.01525

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.51632

Collected Steps per Second: 23,042.86952
Overall Steps per Second: 10,854.55911

Timestep Collection Time: 2.17056
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60783

Cumulative Model Updates: 187,324
Cumulative Timesteps: 1,562,288,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1562288724...
Checkpoint 1562288724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.46362
Policy Entropy: 2.38182
Value Function Loss: 0.01593

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.52547

Collected Steps per Second: 23,015.55405
Overall Steps per Second: 10,732.50276

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.65875

Cumulative Model Updates: 187,330
Cumulative Timesteps: 1,562,338,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.31247
Policy Entropy: 2.40185
Value Function Loss: 0.01460

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 23,008.53736
Overall Steps per Second: 10,887.76627

Timestep Collection Time: 2.17415
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.59451

Cumulative Model Updates: 187,336
Cumulative Timesteps: 1,562,388,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1562388748...
Checkpoint 1562388748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.03654
Policy Entropy: 2.39328
Value Function Loss: 0.01424

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.52873
Value Function Update Magnitude: 0.53446

Collected Steps per Second: 22,870.37098
Overall Steps per Second: 10,661.79076

Timestep Collection Time: 2.18755
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.69246

Cumulative Model Updates: 187,342
Cumulative Timesteps: 1,562,438,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.45860
Policy Entropy: 2.36254
Value Function Loss: 0.01456

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.52670

Collected Steps per Second: 22,512.78999
Overall Steps per Second: 10,678.67377

Timestep Collection Time: 2.22158
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.68354

Cumulative Model Updates: 187,348
Cumulative Timesteps: 1,562,488,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1562488792...
Checkpoint 1562488792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.94624
Policy Entropy: 2.32911
Value Function Loss: 0.01589

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.57016
Value Function Update Magnitude: 0.54971

Collected Steps per Second: 22,638.28485
Overall Steps per Second: 10,779.29371

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.64019

Cumulative Model Updates: 187,354
Cumulative Timesteps: 1,562,538,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.32007
Policy Entropy: 2.31492
Value Function Loss: 0.01670

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.57486

Collected Steps per Second: 21,914.06493
Overall Steps per Second: 10,525.92081

Timestep Collection Time: 2.28237
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.75170

Cumulative Model Updates: 187,360
Cumulative Timesteps: 1,562,588,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1562588826...
Checkpoint 1562588826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.74449
Policy Entropy: 2.31423
Value Function Loss: 0.01651

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.58189

Collected Steps per Second: 22,427.60740
Overall Steps per Second: 10,785.82770

Timestep Collection Time: 2.23082
Timestep Consumption Time: 2.40786
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.63868

Cumulative Model Updates: 187,366
Cumulative Timesteps: 1,562,638,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.04594
Policy Entropy: 2.33532
Value Function Loss: 0.01558

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 23,172.68218
Overall Steps per Second: 10,784.79663

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.64042

Cumulative Model Updates: 187,372
Cumulative Timesteps: 1,562,688,904

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1562688904...
Checkpoint 1562688904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.25678
Policy Entropy: 2.32532
Value Function Loss: 0.01541

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.56720

Collected Steps per Second: 23,057.83525
Overall Steps per Second: 10,630.40747

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.53665
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.70650

Cumulative Model Updates: 187,378
Cumulative Timesteps: 1,562,738,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.59023
Policy Entropy: 2.33554
Value Function Loss: 0.01503

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.57043

Collected Steps per Second: 23,092.57573
Overall Steps per Second: 10,824.74412

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62016

Cumulative Model Updates: 187,384
Cumulative Timesteps: 1,562,788,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1562788948...
Checkpoint 1562788948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.08216
Policy Entropy: 2.33440
Value Function Loss: 0.01539

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.55774

Collected Steps per Second: 22,847.50895
Overall Steps per Second: 10,692.22816

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.67891

Cumulative Model Updates: 187,390
Cumulative Timesteps: 1,562,838,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.07222
Policy Entropy: 2.34478
Value Function Loss: 0.01502

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.54411
Value Function Update Magnitude: 0.54504

Collected Steps per Second: 23,192.28727
Overall Steps per Second: 10,929.75173

Timestep Collection Time: 2.15606
Timestep Consumption Time: 2.41897
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.57504

Cumulative Model Updates: 187,396
Cumulative Timesteps: 1,562,888,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1562888980...
Checkpoint 1562888980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.15779
Policy Entropy: 2.33751
Value Function Loss: 0.01566

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.52864

Collected Steps per Second: 23,309.28246
Overall Steps per Second: 10,832.99817

Timestep Collection Time: 2.14584
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.61719

Cumulative Model Updates: 187,402
Cumulative Timesteps: 1,562,938,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.56006
Policy Entropy: 2.33356
Value Function Loss: 0.01562

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.53107

Collected Steps per Second: 23,295.66674
Overall Steps per Second: 10,750.06421

Timestep Collection Time: 2.14744
Timestep Consumption Time: 2.50612
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.65355

Cumulative Model Updates: 187,408
Cumulative Timesteps: 1,562,989,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1562989024...
Checkpoint 1562989024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.60684
Policy Entropy: 2.34091
Value Function Loss: 0.01559

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 22,972.66084
Overall Steps per Second: 10,704.39055

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.67173

Cumulative Model Updates: 187,414
Cumulative Timesteps: 1,563,039,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.44552
Policy Entropy: 2.35584
Value Function Loss: 0.01538

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.54715
Value Function Update Magnitude: 0.54274

Collected Steps per Second: 22,539.32083
Overall Steps per Second: 10,843.28072

Timestep Collection Time: 2.21977
Timestep Consumption Time: 2.39434
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61410

Cumulative Model Updates: 187,420
Cumulative Timesteps: 1,563,089,064

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1563089064...
Checkpoint 1563089064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.65926
Policy Entropy: 2.36213
Value Function Loss: 0.01518

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.55393

Collected Steps per Second: 22,653.45583
Overall Steps per Second: 10,852.05110

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.40141
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.60964

Cumulative Model Updates: 187,426
Cumulative Timesteps: 1,563,139,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.12993
Policy Entropy: 2.35144
Value Function Loss: 0.01503

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.55519

Collected Steps per Second: 23,194.39818
Overall Steps per Second: 10,666.48038

Timestep Collection Time: 2.15656
Timestep Consumption Time: 2.53290
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68946

Cumulative Model Updates: 187,432
Cumulative Timesteps: 1,563,189,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1563189108...
Checkpoint 1563189108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.85306
Policy Entropy: 2.33669
Value Function Loss: 0.01519

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.54081

Collected Steps per Second: 23,256.96796
Overall Steps per Second: 10,769.74286

Timestep Collection Time: 2.15024
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.64338

Cumulative Model Updates: 187,438
Cumulative Timesteps: 1,563,239,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.51367
Policy Entropy: 2.33089
Value Function Loss: 0.01566

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.53118

Collected Steps per Second: 23,256.56976
Overall Steps per Second: 10,802.75856

Timestep Collection Time: 2.15079
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.63030

Cumulative Model Updates: 187,444
Cumulative Timesteps: 1,563,289,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1563289136...
Checkpoint 1563289136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.45840
Policy Entropy: 2.32486
Value Function Loss: 0.01538

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.54795

Collected Steps per Second: 23,073.11404
Overall Steps per Second: 10,834.11321

Timestep Collection Time: 2.16772
Timestep Consumption Time: 2.44881
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.61653

Cumulative Model Updates: 187,450
Cumulative Timesteps: 1,563,339,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.63339
Policy Entropy: 2.31487
Value Function Loss: 0.01563

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.55955

Collected Steps per Second: 23,215.84801
Overall Steps per Second: 11,097.06609

Timestep Collection Time: 2.15422
Timestep Consumption Time: 2.35256
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.50678

Cumulative Model Updates: 187,456
Cumulative Timesteps: 1,563,389,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1563389164...
Checkpoint 1563389164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.93862
Policy Entropy: 2.29851
Value Function Loss: 0.01625

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.55349

Collected Steps per Second: 22,806.78221
Overall Steps per Second: 10,698.67088

Timestep Collection Time: 2.19251
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.67385

Cumulative Model Updates: 187,462
Cumulative Timesteps: 1,563,439,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.75800
Policy Entropy: 2.32820
Value Function Loss: 0.01609

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.55849
Value Function Update Magnitude: 0.54239

Collected Steps per Second: 22,593.44908
Overall Steps per Second: 10,651.19793

Timestep Collection Time: 2.21321
Timestep Consumption Time: 2.48148
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69468

Cumulative Model Updates: 187,468
Cumulative Timesteps: 1,563,489,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1563489172...
Checkpoint 1563489172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.05142
Policy Entropy: 2.31898
Value Function Loss: 0.01583

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.54349

Collected Steps per Second: 22,653.30453
Overall Steps per Second: 10,867.66989

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.39438
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.60227

Cumulative Model Updates: 187,474
Cumulative Timesteps: 1,563,539,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.25133
Policy Entropy: 2.33997
Value Function Loss: 0.01642

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.55031

Collected Steps per Second: 22,649.84218
Overall Steps per Second: 10,956.69884

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.35590
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.56342

Cumulative Model Updates: 187,480
Cumulative Timesteps: 1,563,589,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1563589188...
Checkpoint 1563589188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.40254
Policy Entropy: 2.34481
Value Function Loss: 0.01637

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.56395

Collected Steps per Second: 23,003.96986
Overall Steps per Second: 10,737.93899

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.65825

Cumulative Model Updates: 187,486
Cumulative Timesteps: 1,563,639,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.51296
Policy Entropy: 2.35680
Value Function Loss: 0.01695

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.56419
Value Function Update Magnitude: 0.57613

Collected Steps per Second: 23,185.52177
Overall Steps per Second: 10,791.77671

Timestep Collection Time: 2.15721
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.63464

Cumulative Model Updates: 187,492
Cumulative Timesteps: 1,563,689,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1563689224...
Checkpoint 1563689224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.58457
Policy Entropy: 2.35537
Value Function Loss: 0.01533

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.55117
Value Function Update Magnitude: 0.57771

Collected Steps per Second: 22,922.87517
Overall Steps per Second: 10,653.84756

Timestep Collection Time: 2.18131
Timestep Consumption Time: 2.51201
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.69333

Cumulative Model Updates: 187,498
Cumulative Timesteps: 1,563,739,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.87209
Policy Entropy: 2.34632
Value Function Loss: 0.01551

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.54680
Value Function Update Magnitude: 0.56026

Collected Steps per Second: 23,128.73324
Overall Steps per Second: 10,870.16411

Timestep Collection Time: 2.16233
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.60085

Cumulative Model Updates: 187,504
Cumulative Timesteps: 1,563,789,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1563789238...
Checkpoint 1563789238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.03891
Policy Entropy: 2.37407
Value Function Loss: 0.01573

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 23,394.07238
Overall Steps per Second: 10,868.50083

Timestep Collection Time: 2.13781
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.60155

Cumulative Model Updates: 187,510
Cumulative Timesteps: 1,563,839,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.35681
Policy Entropy: 2.37215
Value Function Loss: 0.01643

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 23,408.67090
Overall Steps per Second: 10,801.63074

Timestep Collection Time: 2.13673
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.63060

Cumulative Model Updates: 187,516
Cumulative Timesteps: 1,563,889,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1563889268...
Checkpoint 1563889268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.61130
Policy Entropy: 2.36735
Value Function Loss: 0.01571

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.59330

Collected Steps per Second: 23,076.81055
Overall Steps per Second: 10,894.30720

Timestep Collection Time: 2.16702
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.59029

Cumulative Model Updates: 187,522
Cumulative Timesteps: 1,563,939,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.46222
Policy Entropy: 2.33482
Value Function Loss: 0.01591

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.57693

Collected Steps per Second: 22,180.07988
Overall Steps per Second: 10,729.77530

Timestep Collection Time: 2.25527
Timestep Consumption Time: 2.40671
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.66198

Cumulative Model Updates: 187,528
Cumulative Timesteps: 1,563,989,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1563989298...
Checkpoint 1563989298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.25247
Policy Entropy: 2.32197
Value Function Loss: 0.01668

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.59605

Collected Steps per Second: 23,197.65137
Overall Steps per Second: 10,939.22678

Timestep Collection Time: 2.15643
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.57290

Cumulative Model Updates: 187,534
Cumulative Timesteps: 1,564,039,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.50655
Policy Entropy: 2.32193
Value Function Loss: 0.01657

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 22,834.83831
Overall Steps per Second: 10,806.43870

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62687

Cumulative Model Updates: 187,540
Cumulative Timesteps: 1,564,089,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1564089322...
Checkpoint 1564089322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.08355
Policy Entropy: 2.34327
Value Function Loss: 0.01636

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.60003

Collected Steps per Second: 22,640.30412
Overall Steps per Second: 10,720.93300

Timestep Collection Time: 2.20845
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66377

Cumulative Model Updates: 187,546
Cumulative Timesteps: 1,564,139,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.28829
Policy Entropy: 2.36210
Value Function Loss: 0.01545

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.59014

Collected Steps per Second: 22,840.87713
Overall Steps per Second: 10,806.08523

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62943

Cumulative Model Updates: 187,552
Cumulative Timesteps: 1,564,189,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1564189348...
Checkpoint 1564189348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.95671
Policy Entropy: 2.35919
Value Function Loss: 0.01632

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 23,955.29010
Overall Steps per Second: 10,949.52586

Timestep Collection Time: 2.08756
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.56714

Cumulative Model Updates: 187,558
Cumulative Timesteps: 1,564,239,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.83895
Policy Entropy: 2.34019
Value Function Loss: 0.01560

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.61149

Collected Steps per Second: 23,514.49452
Overall Steps per Second: 10,847.67642

Timestep Collection Time: 2.12703
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.61076

Cumulative Model Updates: 187,564
Cumulative Timesteps: 1,564,289,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1564289372...
Checkpoint 1564289372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.88434
Policy Entropy: 2.34791
Value Function Loss: 0.01564

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.56404
Value Function Update Magnitude: 0.60530

Collected Steps per Second: 23,516.05121
Overall Steps per Second: 10,970.22411

Timestep Collection Time: 2.12672
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.55889

Cumulative Model Updates: 187,570
Cumulative Timesteps: 1,564,339,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.19617
Policy Entropy: 2.33811
Value Function Loss: 0.01524

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.58613

Collected Steps per Second: 22,944.33519
Overall Steps per Second: 10,907.30750

Timestep Collection Time: 2.17927
Timestep Consumption Time: 2.40499
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.58427

Cumulative Model Updates: 187,576
Cumulative Timesteps: 1,564,389,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1564389386...
Checkpoint 1564389386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.50901
Policy Entropy: 2.33289
Value Function Loss: 0.01557

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.56364
Value Function Update Magnitude: 0.57084

Collected Steps per Second: 22,849.42061
Overall Steps per Second: 11,033.07907

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.34424
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.53310

Cumulative Model Updates: 187,582
Cumulative Timesteps: 1,564,439,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.19428
Policy Entropy: 2.30734
Value Function Loss: 0.01502

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.56771

Collected Steps per Second: 22,533.37378
Overall Steps per Second: 10,538.91794

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.52569
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.74489

Cumulative Model Updates: 187,588
Cumulative Timesteps: 1,564,489,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1564489406...
Checkpoint 1564489406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.01645
Policy Entropy: 2.30466
Value Function Loss: 0.01550

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.56958
Value Function Update Magnitude: 0.57790

Collected Steps per Second: 22,688.76364
Overall Steps per Second: 10,605.14816

Timestep Collection Time: 2.20462
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.71658

Cumulative Model Updates: 187,594
Cumulative Timesteps: 1,564,539,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.15601
Policy Entropy: 2.28015
Value Function Loss: 0.01499

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.58158

Collected Steps per Second: 22,470.60046
Overall Steps per Second: 10,609.59201

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.71347

Cumulative Model Updates: 187,600
Cumulative Timesteps: 1,564,589,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1564589434...
Checkpoint 1564589434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.81780
Policy Entropy: 2.30420
Value Function Loss: 0.01547

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.57044

Collected Steps per Second: 22,695.88494
Overall Steps per Second: 10,861.29736

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.40161
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60571

Cumulative Model Updates: 187,606
Cumulative Timesteps: 1,564,639,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.39645
Policy Entropy: 2.31485
Value Function Loss: 0.01513

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.56284

Collected Steps per Second: 23,412.31165
Overall Steps per Second: 10,979.68043

Timestep Collection Time: 2.13563
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.55387

Cumulative Model Updates: 187,612
Cumulative Timesteps: 1,564,689,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1564689458...
Checkpoint 1564689458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.02358
Policy Entropy: 2.30428
Value Function Loss: 0.01570

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.57150

Collected Steps per Second: 23,305.70963
Overall Steps per Second: 10,802.05764

Timestep Collection Time: 2.14583
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.62967

Cumulative Model Updates: 187,618
Cumulative Timesteps: 1,564,739,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.63746
Policy Entropy: 2.29343
Value Function Loss: 0.01566

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.61027

Collected Steps per Second: 23,312.62173
Overall Steps per Second: 10,775.89295

Timestep Collection Time: 2.14493
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.64036

Cumulative Model Updates: 187,624
Cumulative Timesteps: 1,564,789,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1564789472...
Checkpoint 1564789472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.65250
Policy Entropy: 2.30469
Value Function Loss: 0.01634

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.63689

Collected Steps per Second: 22,890.08904
Overall Steps per Second: 10,674.66841

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.68605

Cumulative Model Updates: 187,630
Cumulative Timesteps: 1,564,839,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.55389
Policy Entropy: 2.33879
Value Function Loss: 0.01622

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.63345

Collected Steps per Second: 23,315.35248
Overall Steps per Second: 10,863.46067

Timestep Collection Time: 2.14460
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.60277

Cumulative Model Updates: 187,636
Cumulative Timesteps: 1,564,889,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1564889496...
Checkpoint 1564889496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.99536
Policy Entropy: 2.34155
Value Function Loss: 0.01639

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 23,218.86135
Overall Steps per Second: 11,091.69945

Timestep Collection Time: 2.15411
Timestep Consumption Time: 2.35521
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.50932

Cumulative Model Updates: 187,642
Cumulative Timesteps: 1,564,939,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.91981
Policy Entropy: 2.32181
Value Function Loss: 0.01656

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.56154
Value Function Update Magnitude: 0.60341

Collected Steps per Second: 22,546.94353
Overall Steps per Second: 10,664.09175

Timestep Collection Time: 2.21813
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.68976

Cumulative Model Updates: 187,648
Cumulative Timesteps: 1,564,989,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1564989524...
Checkpoint 1564989524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.81890
Policy Entropy: 2.29461
Value Function Loss: 0.01739

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.60370

Collected Steps per Second: 22,598.20757
Overall Steps per Second: 10,808.50350

Timestep Collection Time: 2.21389
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62876

Cumulative Model Updates: 187,654
Cumulative Timesteps: 1,565,039,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.20732
Policy Entropy: 2.28629
Value Function Loss: 0.01687

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.16464
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,647.59887
Overall Steps per Second: 10,570.79548

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.52268
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.73077

Cumulative Model Updates: 187,660
Cumulative Timesteps: 1,565,089,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1565089562...
Checkpoint 1565089562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.48123
Policy Entropy: 2.27573
Value Function Loss: 0.01704

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.55593
Value Function Update Magnitude: 0.60973

Collected Steps per Second: 22,614.72943
Overall Steps per Second: 10,650.91718

Timestep Collection Time: 2.21210
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.69687

Cumulative Model Updates: 187,666
Cumulative Timesteps: 1,565,139,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.02501
Policy Entropy: 2.30088
Value Function Loss: 0.01676

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.62798

Collected Steps per Second: 23,281.68704
Overall Steps per Second: 10,876.37068

Timestep Collection Time: 2.14778
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.59749

Cumulative Model Updates: 187,672
Cumulative Timesteps: 1,565,189,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1565189592...
Checkpoint 1565189592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.47315
Policy Entropy: 2.31659
Value Function Loss: 0.01708

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.15418
Policy Update Magnitude: 0.56290
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 23,173.14647
Overall Steps per Second: 10,772.26833

Timestep Collection Time: 2.15802
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.64229

Cumulative Model Updates: 187,678
Cumulative Timesteps: 1,565,239,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.39402
Policy Entropy: 2.31723
Value Function Loss: 0.01729

Mean KL Divergence: 0.03315
SB3 Clip Fraction: 0.19415
Policy Update Magnitude: 0.50889
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 22,866.87111
Overall Steps per Second: 10,765.56025

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.64630

Cumulative Model Updates: 187,684
Cumulative Timesteps: 1,565,289,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1565289620...
Checkpoint 1565289620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.60600
Policy Entropy: 2.30568
Value Function Loss: 0.01628

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 23,000.99681
Overall Steps per Second: 10,693.95959

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.67685

Cumulative Model Updates: 187,690
Cumulative Timesteps: 1,565,339,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.45860
Policy Entropy: 2.31187
Value Function Loss: 0.01533

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.61589

Collected Steps per Second: 23,301.71617
Overall Steps per Second: 10,878.35374

Timestep Collection Time: 2.14576
Timestep Consumption Time: 2.45052
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.59628

Cumulative Model Updates: 187,696
Cumulative Timesteps: 1,565,389,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1565389634...
Checkpoint 1565389634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.85850
Policy Entropy: 2.31813
Value Function Loss: 0.01509

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 22,992.34079
Overall Steps per Second: 11,059.33680

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.34784
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.52378

Cumulative Model Updates: 187,702
Cumulative Timesteps: 1,565,439,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.45264
Policy Entropy: 2.32420
Value Function Loss: 0.01474

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.56218
Value Function Update Magnitude: 0.60578

Collected Steps per Second: 22,730.84139
Overall Steps per Second: 10,688.59688

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68069

Cumulative Model Updates: 187,708
Cumulative Timesteps: 1,565,489,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1565489694...
Checkpoint 1565489694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.55575
Policy Entropy: 2.31648
Value Function Loss: 0.01543

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.60661

Collected Steps per Second: 22,857.38414
Overall Steps per Second: 10,824.66045

Timestep Collection Time: 2.18826
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62075

Cumulative Model Updates: 187,714
Cumulative Timesteps: 1,565,539,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.41215
Policy Entropy: 2.33260
Value Function Loss: 0.01474

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.59254

Collected Steps per Second: 22,681.87509
Overall Steps per Second: 10,719.97774

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.46097
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.66643

Cumulative Model Updates: 187,720
Cumulative Timesteps: 1,565,589,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1565589736...
Checkpoint 1565589736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.61376
Policy Entropy: 2.32913
Value Function Loss: 0.01494

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.57843

Collected Steps per Second: 22,794.33518
Overall Steps per Second: 10,890.58373

Timestep Collection Time: 2.19405
Timestep Consumption Time: 2.39817
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.59222

Cumulative Model Updates: 187,726
Cumulative Timesteps: 1,565,639,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.60692
Policy Entropy: 2.32545
Value Function Loss: 0.01492

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.58477

Collected Steps per Second: 23,237.52008
Overall Steps per Second: 10,858.17971

Timestep Collection Time: 2.15169
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60482

Cumulative Model Updates: 187,732
Cumulative Timesteps: 1,565,689,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1565689748...
Checkpoint 1565689748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.61538
Policy Entropy: 2.32762
Value Function Loss: 0.01516

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.59475

Collected Steps per Second: 23,350.69217
Overall Steps per Second: 10,790.86985

Timestep Collection Time: 2.14135
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.63373

Cumulative Model Updates: 187,738
Cumulative Timesteps: 1,565,739,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.95509
Policy Entropy: 2.33795
Value Function Loss: 0.01571

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 23,277.61609
Overall Steps per Second: 10,792.21231

Timestep Collection Time: 2.14807
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.63316

Cumulative Model Updates: 187,744
Cumulative Timesteps: 1,565,789,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1565789752...
Checkpoint 1565789752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.80677
Policy Entropy: 2.34169
Value Function Loss: 0.01670

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.58514

Collected Steps per Second: 22,801.07588
Overall Steps per Second: 10,721.04148

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.66522

Cumulative Model Updates: 187,750
Cumulative Timesteps: 1,565,839,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.98691
Policy Entropy: 2.34108
Value Function Loss: 0.01723

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.60884

Collected Steps per Second: 23,391.89491
Overall Steps per Second: 11,002.30777

Timestep Collection Time: 2.13843
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.54650

Cumulative Model Updates: 187,756
Cumulative Timesteps: 1,565,889,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1565889790...
Checkpoint 1565889790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.94258
Policy Entropy: 2.34641
Value Function Loss: 0.01717

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.56577
Value Function Update Magnitude: 0.60392

Collected Steps per Second: 22,513.79865
Overall Steps per Second: 10,651.67483

Timestep Collection Time: 2.22130
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69504

Cumulative Model Updates: 187,762
Cumulative Timesteps: 1,565,939,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.89475
Policy Entropy: 2.34323
Value Function Loss: 0.01675

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.59098

Collected Steps per Second: 22,776.48172
Overall Steps per Second: 10,744.36459

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.65435

Cumulative Model Updates: 187,768
Cumulative Timesteps: 1,565,989,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1565989808...
Checkpoint 1565989808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.03291
Policy Entropy: 2.32796
Value Function Loss: 0.01593

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.17506
Policy Update Magnitude: 0.49677
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 22,637.35919
Overall Steps per Second: 10,603.02499

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.71564

Cumulative Model Updates: 187,774
Cumulative Timesteps: 1,566,039,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.09568
Policy Entropy: 2.32074
Value Function Loss: 0.01655

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.51532
Value Function Update Magnitude: 0.57737

Collected Steps per Second: 22,844.73793
Overall Steps per Second: 10,852.42916

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60984

Cumulative Model Updates: 187,780
Cumulative Timesteps: 1,566,089,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1566089836...
Checkpoint 1566089836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.86316
Policy Entropy: 2.34153
Value Function Loss: 0.01640

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.59445

Collected Steps per Second: 22,611.75235
Overall Steps per Second: 10,667.00341

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68810

Cumulative Model Updates: 187,786
Cumulative Timesteps: 1,566,139,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.29795
Policy Entropy: 2.35454
Value Function Loss: 0.01671

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.15548
Policy Update Magnitude: 0.56211
Value Function Update Magnitude: 0.59600

Collected Steps per Second: 23,054.22370
Overall Steps per Second: 10,930.94660

Timestep Collection Time: 2.16949
Timestep Consumption Time: 2.40614
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.57563

Cumulative Model Updates: 187,792
Cumulative Timesteps: 1,566,189,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1566189860...
Checkpoint 1566189860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.80672
Policy Entropy: 2.36073
Value Function Loss: 0.01563

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.58854

Collected Steps per Second: 23,008.77742
Overall Steps per Second: 10,715.15095

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66760

Cumulative Model Updates: 187,798
Cumulative Timesteps: 1,566,239,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.31310
Policy Entropy: 2.36641
Value Function Loss: 0.01546

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 23,190.61185
Overall Steps per Second: 10,843.20462

Timestep Collection Time: 2.15691
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.61303

Cumulative Model Updates: 187,804
Cumulative Timesteps: 1,566,289,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1566289894...
Checkpoint 1566289894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.01544
Policy Entropy: 2.37894
Value Function Loss: 0.01492

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.54611
Value Function Update Magnitude: 0.59589

Collected Steps per Second: 22,797.09207
Overall Steps per Second: 10,694.85692

Timestep Collection Time: 2.19388
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.67645

Cumulative Model Updates: 187,810
Cumulative Timesteps: 1,566,339,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.51658
Policy Entropy: 2.40253
Value Function Loss: 0.01563

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.58783

Collected Steps per Second: 23,116.04040
Overall Steps per Second: 10,850.25909

Timestep Collection Time: 2.16430
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.61095

Cumulative Model Updates: 187,816
Cumulative Timesteps: 1,566,389,938

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1566389938...
Checkpoint 1566389938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.94595
Policy Entropy: 2.39442
Value Function Loss: 0.01580

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 21,914.55645
Overall Steps per Second: 10,587.50067

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.72463

Cumulative Model Updates: 187,822
Cumulative Timesteps: 1,566,439,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.38986
Policy Entropy: 2.37117
Value Function Loss: 0.01606

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.55163
Value Function Update Magnitude: 0.57035

Collected Steps per Second: 22,402.52682
Overall Steps per Second: 10,518.41167

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.52329
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75661

Cumulative Model Updates: 187,828
Cumulative Timesteps: 1,566,489,992

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1566489992...
Checkpoint 1566489992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.22694
Policy Entropy: 2.33628
Value Function Loss: 0.01643

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.56963

Collected Steps per Second: 22,494.19200
Overall Steps per Second: 10,623.36007

Timestep Collection Time: 2.22280
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70661

Cumulative Model Updates: 187,834
Cumulative Timesteps: 1,566,539,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.08917
Policy Entropy: 2.34127
Value Function Loss: 0.01655

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 22,674.15329
Overall Steps per Second: 10,956.32393

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.35984
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.56631

Cumulative Model Updates: 187,840
Cumulative Timesteps: 1,566,590,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1566590022...
Checkpoint 1566590022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.25784
Policy Entropy: 2.35745
Value Function Loss: 0.01709

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.58508
Value Function Update Magnitude: 0.61300

Collected Steps per Second: 23,360.95529
Overall Steps per Second: 10,728.11511

Timestep Collection Time: 2.14144
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.66307

Cumulative Model Updates: 187,846
Cumulative Timesteps: 1,566,640,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.25943
Policy Entropy: 2.36021
Value Function Loss: 0.01627

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.61848

Collected Steps per Second: 23,177.84158
Overall Steps per Second: 10,739.00514

Timestep Collection Time: 2.15801
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.65760

Cumulative Model Updates: 187,852
Cumulative Timesteps: 1,566,690,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1566690066...
Checkpoint 1566690066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.17590
Policy Entropy: 2.36280
Value Function Loss: 0.01600

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.59813

Collected Steps per Second: 23,223.37619
Overall Steps per Second: 10,729.65610

Timestep Collection Time: 2.15318
Timestep Consumption Time: 2.50718
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.66035

Cumulative Model Updates: 187,858
Cumulative Timesteps: 1,566,740,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.57964
Policy Entropy: 2.32541
Value Function Loss: 0.01563

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.56283

Collected Steps per Second: 23,017.45081
Overall Steps per Second: 10,944.65774

Timestep Collection Time: 2.17392
Timestep Consumption Time: 2.39800
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.57191

Cumulative Model Updates: 187,864
Cumulative Timesteps: 1,566,790,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1566790108...
Checkpoint 1566790108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.62385
Policy Entropy: 2.34767
Value Function Loss: 0.01587

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 23,133.52895
Overall Steps per Second: 11,079.95417

Timestep Collection Time: 2.16214
Timestep Consumption Time: 2.35214
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.51428

Cumulative Model Updates: 187,870
Cumulative Timesteps: 1,566,840,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.38822
Policy Entropy: 2.35491
Value Function Loss: 0.01587

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 23,055.79212
Overall Steps per Second: 10,847.86175

Timestep Collection Time: 2.16969
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.61142

Cumulative Model Updates: 187,876
Cumulative Timesteps: 1,566,890,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1566890150...
Checkpoint 1566890150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.93735
Policy Entropy: 2.38081
Value Function Loss: 0.01593

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.56490

Collected Steps per Second: 22,776.02985
Overall Steps per Second: 10,676.45905

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.68620

Cumulative Model Updates: 187,882
Cumulative Timesteps: 1,566,940,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.44372
Policy Entropy: 2.37420
Value Function Loss: 0.01563

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.56576

Collected Steps per Second: 22,295.82131
Overall Steps per Second: 10,535.38334

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.74648

Cumulative Model Updates: 187,888
Cumulative Timesteps: 1,566,990,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1566990188...
Checkpoint 1566990188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.19136
Policy Entropy: 2.35924
Value Function Loss: 0.01592

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.55497
Value Function Update Magnitude: 0.55900

Collected Steps per Second: 22,555.93450
Overall Steps per Second: 10,661.49721

Timestep Collection Time: 2.21707
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.69052

Cumulative Model Updates: 187,894
Cumulative Timesteps: 1,567,040,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.07661
Policy Entropy: 2.34537
Value Function Loss: 0.01577

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.55336

Collected Steps per Second: 23,069.16385
Overall Steps per Second: 10,873.39275

Timestep Collection Time: 2.16774
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.59912

Cumulative Model Updates: 187,900
Cumulative Timesteps: 1,567,090,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1567090204...
Checkpoint 1567090204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.55447
Policy Entropy: 2.33298
Value Function Loss: 0.01537

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.55167

Collected Steps per Second: 23,174.88406
Overall Steps per Second: 10,684.80363

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.68142

Cumulative Model Updates: 187,906
Cumulative Timesteps: 1,567,140,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.79976
Policy Entropy: 2.33253
Value Function Loss: 0.01495

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.56148

Collected Steps per Second: 23,285.88150
Overall Steps per Second: 10,773.68214

Timestep Collection Time: 2.14757
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.64168

Cumulative Model Updates: 187,912
Cumulative Timesteps: 1,567,190,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1567190232...
Checkpoint 1567190232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.99600
Policy Entropy: 2.32338
Value Function Loss: 0.01531

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.57741

Collected Steps per Second: 23,081.26594
Overall Steps per Second: 10,743.07931

Timestep Collection Time: 2.16695
Timestep Consumption Time: 2.48870
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.65565

Cumulative Model Updates: 187,918
Cumulative Timesteps: 1,567,240,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.49592
Policy Entropy: 2.30041
Value Function Loss: 0.01564

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.57896
Value Function Update Magnitude: 0.58085

Collected Steps per Second: 23,270.48491
Overall Steps per Second: 10,795.20854

Timestep Collection Time: 2.14916
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.63280

Cumulative Model Updates: 187,924
Cumulative Timesteps: 1,567,290,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1567290260...
Checkpoint 1567290260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.58318
Policy Entropy: 2.29383
Value Function Loss: 0.01561

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.58762

Collected Steps per Second: 23,027.94930
Overall Steps per Second: 11,029.60146

Timestep Collection Time: 2.17223
Timestep Consumption Time: 2.36302
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.53525

Cumulative Model Updates: 187,930
Cumulative Timesteps: 1,567,340,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.82091
Policy Entropy: 2.30713
Value Function Loss: 0.01464

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.57399

Collected Steps per Second: 23,475.44645
Overall Steps per Second: 10,967.48116

Timestep Collection Time: 2.13074
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.56076

Cumulative Model Updates: 187,936
Cumulative Timesteps: 1,567,390,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1567390302...
Checkpoint 1567390302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.48970
Policy Entropy: 2.31679
Value Function Loss: 0.01422

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.54225

Collected Steps per Second: 22,647.31370
Overall Steps per Second: 10,662.86504

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.69161

Cumulative Model Updates: 187,942
Cumulative Timesteps: 1,567,440,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.29532
Policy Entropy: 2.32304
Value Function Loss: 0.01511

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.52895

Collected Steps per Second: 22,770.01249
Overall Steps per Second: 10,693.51236

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.48056
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67704

Cumulative Model Updates: 187,948
Cumulative Timesteps: 1,567,490,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1567490342...
Checkpoint 1567490342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.83402
Policy Entropy: 2.31862
Value Function Loss: 0.01616

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.54667

Collected Steps per Second: 23,036.02356
Overall Steps per Second: 10,858.63754

Timestep Collection Time: 2.17138
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.60647

Cumulative Model Updates: 187,954
Cumulative Timesteps: 1,567,540,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.02508
Policy Entropy: 2.32564
Value Function Loss: 0.01575

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.56183

Collected Steps per Second: 22,885.32123
Overall Steps per Second: 10,803.86772

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.44395
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62945

Cumulative Model Updates: 187,960
Cumulative Timesteps: 1,567,590,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1567590378...
Checkpoint 1567590378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.43584
Policy Entropy: 2.33527
Value Function Loss: 0.01516

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.55761

Collected Steps per Second: 22,761.85622
Overall Steps per Second: 10,736.63364

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.65919

Cumulative Model Updates: 187,966
Cumulative Timesteps: 1,567,640,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.46917
Policy Entropy: 2.33930
Value Function Loss: 0.01541

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 23,217.10726
Overall Steps per Second: 10,860.35186

Timestep Collection Time: 2.15358
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60390

Cumulative Model Updates: 187,972
Cumulative Timesteps: 1,567,690,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1567690402...
Checkpoint 1567690402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.06772
Policy Entropy: 2.33316
Value Function Loss: 0.01476

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.55663
Value Function Update Magnitude: 0.56624

Collected Steps per Second: 22,916.67115
Overall Steps per Second: 10,717.54805

Timestep Collection Time: 2.18295
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.66767

Cumulative Model Updates: 187,978
Cumulative Timesteps: 1,567,740,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.25457
Policy Entropy: 2.33404
Value Function Loss: 0.01535

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 22,964.89145
Overall Steps per Second: 10,912.35799

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.40569
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.58379

Cumulative Model Updates: 187,984
Cumulative Timesteps: 1,567,790,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1567790448...
Checkpoint 1567790448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.53851
Policy Entropy: 2.32265
Value Function Loss: 0.01521

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.57822

Collected Steps per Second: 23,265.28839
Overall Steps per Second: 10,817.48023

Timestep Collection Time: 2.14973
Timestep Consumption Time: 2.47372
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.62344

Cumulative Model Updates: 187,990
Cumulative Timesteps: 1,567,840,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.75337
Policy Entropy: 2.31915
Value Function Loss: 0.01609

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.55291
Value Function Update Magnitude: 0.57547

Collected Steps per Second: 23,403.84381
Overall Steps per Second: 10,790.54256

Timestep Collection Time: 2.13640
Timestep Consumption Time: 2.49729
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.63369

Cumulative Model Updates: 187,996
Cumulative Timesteps: 1,567,890,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1567890462...
Checkpoint 1567890462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.92324
Policy Entropy: 2.30494
Value Function Loss: 0.01630

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.58774

Collected Steps per Second: 22,878.45766
Overall Steps per Second: 10,655.66540

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.69328

Cumulative Model Updates: 188,002
Cumulative Timesteps: 1,567,940,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.77355
Policy Entropy: 2.30791
Value Function Loss: 0.01589

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.58815

Collected Steps per Second: 22,454.34290
Overall Steps per Second: 10,766.88009

Timestep Collection Time: 2.22772
Timestep Consumption Time: 2.41819
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.64591

Cumulative Model Updates: 188,008
Cumulative Timesteps: 1,567,990,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1567990494...
Checkpoint 1567990494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.20005
Policy Entropy: 2.30224
Value Function Loss: 0.01534

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.60487

Collected Steps per Second: 22,808.95704
Overall Steps per Second: 10,690.34284

Timestep Collection Time: 2.19256
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.67805

Cumulative Model Updates: 188,014
Cumulative Timesteps: 1,568,040,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.97663
Policy Entropy: 2.32452
Value Function Loss: 0.01506

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.60501

Collected Steps per Second: 24,154.13679
Overall Steps per Second: 10,934.20756

Timestep Collection Time: 2.07078
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.57445

Cumulative Model Updates: 188,020
Cumulative Timesteps: 1,568,090,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1568090522...
Checkpoint 1568090522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.68443
Policy Entropy: 2.32596
Value Function Loss: 0.01554

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.17719
Policy Update Magnitude: 0.51730
Value Function Update Magnitude: 0.59663

Collected Steps per Second: 23,456.40866
Overall Steps per Second: 10,960.09916

Timestep Collection Time: 2.13213
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.56310

Cumulative Model Updates: 188,026
Cumulative Timesteps: 1,568,140,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.85484
Policy Entropy: 2.32596
Value Function Loss: 0.01628

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.16926
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.60954

Collected Steps per Second: 23,135.72073
Overall Steps per Second: 10,787.64748

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.63753

Cumulative Model Updates: 188,032
Cumulative Timesteps: 1,568,190,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1568190562...
Checkpoint 1568190562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.16126
Policy Entropy: 2.32480
Value Function Loss: 0.01588

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.18091
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.63412

Collected Steps per Second: 23,312.94756
Overall Steps per Second: 10,901.99085

Timestep Collection Time: 2.14507
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.58705

Cumulative Model Updates: 188,038
Cumulative Timesteps: 1,568,240,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.50364
Policy Entropy: 2.33653
Value Function Loss: 0.01588

Mean KL Divergence: 0.02766
SB3 Clip Fraction: 0.18759
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 23,241.35014
Overall Steps per Second: 10,880.14813

Timestep Collection Time: 2.15228
Timestep Consumption Time: 2.44526
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.59755

Cumulative Model Updates: 188,044
Cumulative Timesteps: 1,568,290,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1568290592...
Checkpoint 1568290592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.93607
Policy Entropy: 2.34170
Value Function Loss: 0.01590

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.63211

Collected Steps per Second: 22,403.78017
Overall Steps per Second: 10,700.94347

Timestep Collection Time: 2.23186
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.67267

Cumulative Model Updates: 188,050
Cumulative Timesteps: 1,568,340,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.24426
Policy Entropy: 2.33180
Value Function Loss: 0.01624

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.19612
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.63590

Collected Steps per Second: 22,424.82044
Overall Steps per Second: 10,628.42202

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.70663

Cumulative Model Updates: 188,056
Cumulative Timesteps: 1,568,390,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1568390618...
Checkpoint 1568390618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.14669
Policy Entropy: 2.33278
Value Function Loss: 0.01675

Mean KL Divergence: 0.02989
SB3 Clip Fraction: 0.20089
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 22,514.67252
Overall Steps per Second: 10,644.33348

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.69959

Cumulative Model Updates: 188,062
Cumulative Timesteps: 1,568,440,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.56078
Policy Entropy: 2.36042
Value Function Loss: 0.01618

Mean KL Divergence: 0.02960
SB3 Clip Fraction: 0.19983
Policy Update Magnitude: 0.56680
Value Function Update Magnitude: 0.64141

Collected Steps per Second: 22,537.09461
Overall Steps per Second: 10,669.39589

Timestep Collection Time: 2.21901
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.68724

Cumulative Model Updates: 188,068
Cumulative Timesteps: 1,568,490,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1568490652...
Checkpoint 1568490652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.31370
Policy Entropy: 2.38287
Value Function Loss: 0.01590

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.18695
Policy Update Magnitude: 0.57817
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 22,893.62286
Overall Steps per Second: 10,688.52899

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.68034

Cumulative Model Updates: 188,074
Cumulative Timesteps: 1,568,540,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.07942
Policy Entropy: 2.38904
Value Function Loss: 0.01549

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.16210
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 22,884.37331
Overall Steps per Second: 10,938.12419

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.38770
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.57391

Cumulative Model Updates: 188,080
Cumulative Timesteps: 1,568,590,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1568590708...
Checkpoint 1568590708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.93998
Policy Entropy: 2.36778
Value Function Loss: 0.01504

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 23,072.57492
Overall Steps per Second: 10,745.55926

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.65513

Cumulative Model Updates: 188,086
Cumulative Timesteps: 1,568,640,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.83659
Policy Entropy: 2.32792
Value Function Loss: 0.01589

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.60938

Collected Steps per Second: 23,371.78023
Overall Steps per Second: 10,788.81427

Timestep Collection Time: 2.14002
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.63591

Cumulative Model Updates: 188,092
Cumulative Timesteps: 1,568,690,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1568690746...
Checkpoint 1568690746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.82867
Policy Entropy: 2.33437
Value Function Loss: 0.01522

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 22,921.88004
Overall Steps per Second: 10,646.45296

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.69659

Cumulative Model Updates: 188,098
Cumulative Timesteps: 1,568,740,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.75373
Policy Entropy: 2.34047
Value Function Loss: 0.01508

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.59435

Collected Steps per Second: 23,300.07416
Overall Steps per Second: 10,896.08192

Timestep Collection Time: 2.14635
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.58972

Cumulative Model Updates: 188,104
Cumulative Timesteps: 1,568,790,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1568790758...
Checkpoint 1568790758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.63137
Policy Entropy: 2.39080
Value Function Loss: 0.01497

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.59152

Collected Steps per Second: 22,915.40062
Overall Steps per Second: 11,026.98291

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.35333
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.53615

Cumulative Model Updates: 188,110
Cumulative Timesteps: 1,568,840,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.85575
Policy Entropy: 2.38742
Value Function Loss: 0.01546

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.58632

Collected Steps per Second: 22,850.18122
Overall Steps per Second: 10,692.52720

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.67859

Cumulative Model Updates: 188,116
Cumulative Timesteps: 1,568,890,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1568890804...
Checkpoint 1568890804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.15618
Policy Entropy: 2.37648
Value Function Loss: 0.01617

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.57623

Collected Steps per Second: 22,827.18571
Overall Steps per Second: 10,701.61835

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.67275

Cumulative Model Updates: 188,122
Cumulative Timesteps: 1,568,940,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.31989
Policy Entropy: 2.34154
Value Function Loss: 0.01564

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 22,803.58307
Overall Steps per Second: 10,691.18142

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67750

Cumulative Model Updates: 188,128
Cumulative Timesteps: 1,568,990,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1568990818...
Checkpoint 1568990818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.76680
Policy Entropy: 2.31693
Value Function Loss: 0.01528

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.58927

Collected Steps per Second: 22,599.65431
Overall Steps per Second: 10,623.14109

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70802

Cumulative Model Updates: 188,134
Cumulative Timesteps: 1,569,040,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.68335
Policy Entropy: 2.33564
Value Function Loss: 0.01533

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.56753

Collected Steps per Second: 23,218.08593
Overall Steps per Second: 10,912.23958

Timestep Collection Time: 2.15453
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.58421

Cumulative Model Updates: 188,140
Cumulative Timesteps: 1,569,090,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1569090856...
Checkpoint 1569090856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.16663
Policy Entropy: 2.35208
Value Function Loss: 0.01602

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.56016
Value Function Update Magnitude: 0.56034

Collected Steps per Second: 23,158.85161
Overall Steps per Second: 10,780.70711

Timestep Collection Time: 2.15900
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.63791

Cumulative Model Updates: 188,146
Cumulative Timesteps: 1,569,140,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.74115
Policy Entropy: 2.36096
Value Function Loss: 0.01640

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.56298

Collected Steps per Second: 23,645.65851
Overall Steps per Second: 10,844.04078

Timestep Collection Time: 2.11540
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.61267

Cumulative Model Updates: 188,152
Cumulative Timesteps: 1,569,190,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1569190876...
Checkpoint 1569190876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.14392
Policy Entropy: 2.35663
Value Function Loss: 0.01522

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.58039

Collected Steps per Second: 22,995.00147
Overall Steps per Second: 10,743.20115

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.65560

Cumulative Model Updates: 188,158
Cumulative Timesteps: 1,569,240,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.67142
Policy Entropy: 2.35953
Value Function Loss: 0.01542

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.55667
Value Function Update Magnitude: 0.57994

Collected Steps per Second: 23,173.07069
Overall Steps per Second: 10,744.55560

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.65538

Cumulative Model Updates: 188,164
Cumulative Timesteps: 1,569,290,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1569290912...
Checkpoint 1569290912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.68395
Policy Entropy: 2.36157
Value Function Loss: 0.01510

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.55576
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 22,964.98762
Overall Steps per Second: 11,045.45852

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.35027
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.52820

Cumulative Model Updates: 188,170
Cumulative Timesteps: 1,569,340,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.58314
Policy Entropy: 2.36172
Value Function Loss: 0.01628

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.56421

Collected Steps per Second: 22,618.00643
Overall Steps per Second: 10,669.84866

Timestep Collection Time: 2.21107
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68704

Cumulative Model Updates: 188,176
Cumulative Timesteps: 1,569,390,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1569390938...
Checkpoint 1569390938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.26175
Policy Entropy: 2.34558
Value Function Loss: 0.01547

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.56849

Collected Steps per Second: 22,671.06170
Overall Steps per Second: 10,604.89431

Timestep Collection Time: 2.20634
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.71669

Cumulative Model Updates: 188,182
Cumulative Timesteps: 1,569,440,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.59823
Policy Entropy: 2.35910
Value Function Loss: 0.01590

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.57866

Collected Steps per Second: 22,790.32003
Overall Steps per Second: 10,817.05957

Timestep Collection Time: 2.19453
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.62362

Cumulative Model Updates: 188,188
Cumulative Timesteps: 1,569,490,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1569490972...
Checkpoint 1569490972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.85017
Policy Entropy: 2.36837
Value Function Loss: 0.01510

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.57711

Collected Steps per Second: 22,515.26650
Overall Steps per Second: 10,639.93108

Timestep Collection Time: 2.22214
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.70229

Cumulative Model Updates: 188,194
Cumulative Timesteps: 1,569,541,004

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.66511
Policy Entropy: 2.38710
Value Function Loss: 0.01526

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 23,125.55681
Overall Steps per Second: 10,868.33868

Timestep Collection Time: 2.16323
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.60291

Cumulative Model Updates: 188,200
Cumulative Timesteps: 1,569,591,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1569591030...
Checkpoint 1569591030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.47192
Policy Entropy: 2.37903
Value Function Loss: 0.01528

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.56870

Collected Steps per Second: 23,172.97439
Overall Steps per Second: 10,795.59928

Timestep Collection Time: 2.15889
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.63411

Cumulative Model Updates: 188,206
Cumulative Timesteps: 1,569,641,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.84376
Policy Entropy: 2.37027
Value Function Loss: 0.01550

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.55576

Collected Steps per Second: 23,465.67271
Overall Steps per Second: 10,784.88056

Timestep Collection Time: 2.13086
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.63631

Cumulative Model Updates: 188,212
Cumulative Timesteps: 1,569,691,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1569691060...
Checkpoint 1569691060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.60601
Policy Entropy: 2.35887
Value Function Loss: 0.01609

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.56579

Collected Steps per Second: 23,284.51015
Overall Steps per Second: 10,808.83071

Timestep Collection Time: 2.14744
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.62603

Cumulative Model Updates: 188,218
Cumulative Timesteps: 1,569,741,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.63440
Policy Entropy: 2.38074
Value Function Loss: 0.01569

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.57065

Collected Steps per Second: 22,013.97743
Overall Steps per Second: 9,304.99619

Timestep Collection Time: 2.27192
Timestep Consumption Time: 3.10304
PPO Batch Consumption Time: 0.30362
Total Iteration Time: 5.37496

Cumulative Model Updates: 188,224
Cumulative Timesteps: 1,569,791,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1569791076...
Checkpoint 1569791076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.35226
Policy Entropy: 2.37498
Value Function Loss: 0.01558

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.56197
Value Function Update Magnitude: 0.55868

Collected Steps per Second: 23,015.67131
Overall Steps per Second: 10,884.26872

Timestep Collection Time: 2.17348
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59599

Cumulative Model Updates: 188,230
Cumulative Timesteps: 1,569,841,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.81559
Policy Entropy: 2.37883
Value Function Loss: 0.01548

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.54864

Collected Steps per Second: 22,788.56253
Overall Steps per Second: 10,813.13046

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62604

Cumulative Model Updates: 188,236
Cumulative Timesteps: 1,569,891,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1569891122...
Checkpoint 1569891122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.44337
Policy Entropy: 2.36527
Value Function Loss: 0.01587

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.54963

Collected Steps per Second: 22,204.05551
Overall Steps per Second: 10,634.27743

Timestep Collection Time: 2.25247
Timestep Consumption Time: 2.45062
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.70309

Cumulative Model Updates: 188,242
Cumulative Timesteps: 1,569,941,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.31843
Policy Entropy: 2.35767
Value Function Loss: 0.01579

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 22,616.82897
Overall Steps per Second: 10,637.88177

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.70169

Cumulative Model Updates: 188,248
Cumulative Timesteps: 1,569,991,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1569991152...
Checkpoint 1569991152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.13851
Policy Entropy: 2.34643
Value Function Loss: 0.01673

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.56654
Value Function Update Magnitude: 0.58665

Collected Steps per Second: 22,490.62767
Overall Steps per Second: 10,929.56054

Timestep Collection Time: 2.22359
Timestep Consumption Time: 2.35207
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.57566

Cumulative Model Updates: 188,254
Cumulative Timesteps: 1,570,041,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.69443
Policy Entropy: 2.34593
Value Function Loss: 0.01703

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,889.93352
Overall Steps per Second: 10,691.54728

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67753

Cumulative Model Updates: 188,260
Cumulative Timesteps: 1,570,091,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1570091172...
Checkpoint 1570091172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.05954
Policy Entropy: 2.33568
Value Function Loss: 0.01738

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.61159

Collected Steps per Second: 22,548.09115
Overall Steps per Second: 10,605.43626

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.71720

Cumulative Model Updates: 188,266
Cumulative Timesteps: 1,570,141,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.23034
Policy Entropy: 2.33759
Value Function Loss: 0.01609

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.55765
Value Function Update Magnitude: 0.59648

Collected Steps per Second: 23,202.28564
Overall Steps per Second: 10,841.28333

Timestep Collection Time: 2.15548
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61311

Cumulative Model Updates: 188,272
Cumulative Timesteps: 1,570,191,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1570191212...
Checkpoint 1570191212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.83949
Policy Entropy: 2.33933
Value Function Loss: 0.01576

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.54071
Value Function Update Magnitude: 0.56579

Collected Steps per Second: 23,092.16359
Overall Steps per Second: 10,929.25617

Timestep Collection Time: 2.16619
Timestep Consumption Time: 2.41070
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.57689

Cumulative Model Updates: 188,278
Cumulative Timesteps: 1,570,241,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.32225
Policy Entropy: 2.36661
Value Function Loss: 0.01497

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.53649
Value Function Update Magnitude: 0.54379

Collected Steps per Second: 22,105.62485
Overall Steps per Second: 10,614.55944

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.71240

Cumulative Model Updates: 188,284
Cumulative Timesteps: 1,570,291,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1570291254...
Checkpoint 1570291254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.59204
Policy Entropy: 2.38648
Value Function Loss: 0.01649

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.54048

Collected Steps per Second: 23,194.53947
Overall Steps per Second: 10,789.33589

Timestep Collection Time: 2.15602
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.63495

Cumulative Model Updates: 188,290
Cumulative Timesteps: 1,570,341,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.05057
Policy Entropy: 2.38500
Value Function Loss: 0.01691

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.57002

Collected Steps per Second: 23,702.57944
Overall Steps per Second: 10,902.07073

Timestep Collection Time: 2.11049
Timestep Consumption Time: 2.47800
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.58849

Cumulative Model Updates: 188,296
Cumulative Timesteps: 1,570,391,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1570391286...
Checkpoint 1570391286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.92626
Policy Entropy: 2.39032
Value Function Loss: 0.01747

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.56248
Value Function Update Magnitude: 0.59297

Collected Steps per Second: 23,025.50451
Overall Steps per Second: 10,919.60219

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.40761
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.57929

Cumulative Model Updates: 188,302
Cumulative Timesteps: 1,570,441,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.74540
Policy Entropy: 2.39644
Value Function Loss: 0.01662

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.57091

Collected Steps per Second: 22,985.39291
Overall Steps per Second: 10,939.19657

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.39581
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.57145

Cumulative Model Updates: 188,308
Cumulative Timesteps: 1,570,491,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1570491298...
Checkpoint 1570491298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.07088
Policy Entropy: 2.38476
Value Function Loss: 0.01613

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.55964

Collected Steps per Second: 22,067.85599
Overall Steps per Second: 10,673.44084

Timestep Collection Time: 2.26601
Timestep Consumption Time: 2.41908
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.68509

Cumulative Model Updates: 188,314
Cumulative Timesteps: 1,570,541,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.63006
Policy Entropy: 2.38214
Value Function Loss: 0.01539

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.56001
Value Function Update Magnitude: 0.55644

Collected Steps per Second: 23,013.18710
Overall Steps per Second: 10,849.07774

Timestep Collection Time: 2.17345
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61035

Cumulative Model Updates: 188,320
Cumulative Timesteps: 1,570,591,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1570591322...
Checkpoint 1570591322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.32498
Policy Entropy: 2.38325
Value Function Loss: 0.01499

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.55430

Collected Steps per Second: 22,932.16747
Overall Steps per Second: 10,659.08877

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.69083

Cumulative Model Updates: 188,326
Cumulative Timesteps: 1,570,641,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.73580
Policy Entropy: 2.39045
Value Function Loss: 0.01540

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.55008

Collected Steps per Second: 22,911.49444
Overall Steps per Second: 10,831.53086

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.61671

Cumulative Model Updates: 188,332
Cumulative Timesteps: 1,570,691,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1570691328...
Checkpoint 1570691328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.59760
Policy Entropy: 2.37368
Value Function Loss: 0.01442

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 22,819.31584
Overall Steps per Second: 10,873.23922

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.40761
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.59900

Cumulative Model Updates: 188,338
Cumulative Timesteps: 1,570,741,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.74318
Policy Entropy: 2.34887
Value Function Loss: 0.01356

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.54328
Value Function Update Magnitude: 0.55674

Collected Steps per Second: 23,822.19251
Overall Steps per Second: 10,912.68472

Timestep Collection Time: 2.10023
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.58476

Cumulative Model Updates: 188,344
Cumulative Timesteps: 1,570,791,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1570791366...
Checkpoint 1570791366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.57371
Policy Entropy: 2.35704
Value Function Loss: 0.01296

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.54130

Collected Steps per Second: 23,365.28062
Overall Steps per Second: 10,935.71299

Timestep Collection Time: 2.14053
Timestep Consumption Time: 2.43293
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.57346

Cumulative Model Updates: 188,350
Cumulative Timesteps: 1,570,841,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.37764
Policy Entropy: 2.36136
Value Function Loss: 0.01370

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.53139
Value Function Update Magnitude: 0.54346

Collected Steps per Second: 23,535.06391
Overall Steps per Second: 10,916.29765

Timestep Collection Time: 2.12517
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.58177

Cumulative Model Updates: 188,356
Cumulative Timesteps: 1,570,891,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1570891396...
Checkpoint 1570891396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.21647
Policy Entropy: 2.36643
Value Function Loss: 0.01444

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.54024
Value Function Update Magnitude: 0.56219

Collected Steps per Second: 22,448.74227
Overall Steps per Second: 10,585.42357

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.72518

Cumulative Model Updates: 188,362
Cumulative Timesteps: 1,570,941,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.79118
Policy Entropy: 2.33979
Value Function Loss: 0.01497

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.57527

Collected Steps per Second: 22,803.11323
Overall Steps per Second: 10,853.65569

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.41464
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.60785

Cumulative Model Updates: 188,368
Cumulative Timesteps: 1,570,991,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1570991426...
Checkpoint 1570991426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.64122
Policy Entropy: 2.36236
Value Function Loss: 0.01456

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.58547

Collected Steps per Second: 22,737.75813
Overall Steps per Second: 10,812.94073

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.62446

Cumulative Model Updates: 188,374
Cumulative Timesteps: 1,571,041,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.01509
Policy Entropy: 2.36662
Value Function Loss: 0.01407

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 23,531.00270
Overall Steps per Second: 10,803.96725

Timestep Collection Time: 2.12528
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.62886

Cumulative Model Updates: 188,380
Cumulative Timesteps: 1,571,091,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1571091440...
Checkpoint 1571091440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.69573
Policy Entropy: 2.39793
Value Function Loss: 0.01466

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.55557

Collected Steps per Second: 22,582.91427
Overall Steps per Second: 10,643.75370

Timestep Collection Time: 2.21530
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.70022

Cumulative Model Updates: 188,386
Cumulative Timesteps: 1,571,141,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.50907
Policy Entropy: 2.36648
Value Function Loss: 0.01510

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.55416

Collected Steps per Second: 22,742.94882
Overall Steps per Second: 10,697.65667

Timestep Collection Time: 2.19848
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67392

Cumulative Model Updates: 188,392
Cumulative Timesteps: 1,571,191,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1571191468...
Checkpoint 1571191468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.71608
Policy Entropy: 2.36092
Value Function Loss: 0.01487

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.56038

Collected Steps per Second: 23,100.77851
Overall Steps per Second: 10,875.98389

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.59986

Cumulative Model Updates: 188,398
Cumulative Timesteps: 1,571,241,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.21721
Policy Entropy: 2.37054
Value Function Loss: 0.01467

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 23,433.94008
Overall Steps per Second: 10,966.25712

Timestep Collection Time: 2.13400
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.56017

Cumulative Model Updates: 188,404
Cumulative Timesteps: 1,571,291,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1571291504...
Checkpoint 1571291504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.11878
Policy Entropy: 2.39694
Value Function Loss: 0.01472

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.57084

Collected Steps per Second: 23,163.74472
Overall Steps per Second: 10,910.06211

Timestep Collection Time: 2.15889
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.58366

Cumulative Model Updates: 188,410
Cumulative Timesteps: 1,571,341,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.22866
Policy Entropy: 2.38873
Value Function Loss: 0.01485

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.56212

Collected Steps per Second: 22,424.67530
Overall Steps per Second: 10,562.92389

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.73789

Cumulative Model Updates: 188,416
Cumulative Timesteps: 1,571,391,558

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1571391558...
Checkpoint 1571391558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.20827
Policy Entropy: 2.37447
Value Function Loss: 0.01503

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 22,273.71453
Overall Steps per Second: 10,716.08811

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66719

Cumulative Model Updates: 188,422
Cumulative Timesteps: 1,571,441,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.14464
Policy Entropy: 2.38322
Value Function Loss: 0.01493

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.56894

Collected Steps per Second: 22,888.75445
Overall Steps per Second: 10,775.66732

Timestep Collection Time: 2.18553
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.64231

Cumulative Model Updates: 188,428
Cumulative Timesteps: 1,571,491,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1571491596...
Checkpoint 1571491596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.26610
Policy Entropy: 2.38398
Value Function Loss: 0.01488

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.55923
Value Function Update Magnitude: 0.56445

Collected Steps per Second: 22,850.17684
Overall Steps per Second: 10,691.80386

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.67947

Cumulative Model Updates: 188,434
Cumulative Timesteps: 1,571,541,628

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.19335
Policy Entropy: 2.37168
Value Function Loss: 0.01489

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.58086

Collected Steps per Second: 23,325.21192
Overall Steps per Second: 10,840.84053

Timestep Collection Time: 2.14429
Timestep Consumption Time: 2.46938
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.61366

Cumulative Model Updates: 188,440
Cumulative Timesteps: 1,571,591,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1571591644...
Checkpoint 1571591644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.43888
Policy Entropy: 2.36224
Value Function Loss: 0.01572

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.59471

Collected Steps per Second: 23,101.66529
Overall Steps per Second: 10,714.46971

Timestep Collection Time: 2.16513
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66827

Cumulative Model Updates: 188,446
Cumulative Timesteps: 1,571,641,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.83422
Policy Entropy: 2.36360
Value Function Loss: 0.01552

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.56818
Value Function Update Magnitude: 0.60819

Collected Steps per Second: 23,551.39870
Overall Steps per Second: 10,901.40235

Timestep Collection Time: 2.12319
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.58693

Cumulative Model Updates: 188,452
Cumulative Timesteps: 1,571,691,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1571691666...
Checkpoint 1571691666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.72922
Policy Entropy: 2.37173
Value Function Loss: 0.01570

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.61265

Collected Steps per Second: 22,737.94338
Overall Steps per Second: 10,690.04213

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.67800

Cumulative Model Updates: 188,458
Cumulative Timesteps: 1,571,741,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.18703
Policy Entropy: 2.37112
Value Function Loss: 0.01558

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.59476

Collected Steps per Second: 23,446.23031
Overall Steps per Second: 11,006.97545

Timestep Collection Time: 2.13382
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.54530

Cumulative Model Updates: 188,464
Cumulative Timesteps: 1,571,791,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1571791704...
Checkpoint 1571791704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392.16843
Policy Entropy: 2.38172
Value Function Loss: 0.01595

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.60632

Collected Steps per Second: 22,407.90094
Overall Steps per Second: 10,601.14162

Timestep Collection Time: 2.23216
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.71817

Cumulative Model Updates: 188,470
Cumulative Timesteps: 1,571,841,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.17484
Policy Entropy: 2.37137
Value Function Loss: 0.01600

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.56828
Value Function Update Magnitude: 0.61273

Collected Steps per Second: 22,889.10902
Overall Steps per Second: 10,864.92092

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.60289

Cumulative Model Updates: 188,476
Cumulative Timesteps: 1,571,891,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1571891732...
Checkpoint 1571891732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.51540
Policy Entropy: 2.38009
Value Function Loss: 0.01568

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.61472

Collected Steps per Second: 22,542.88056
Overall Steps per Second: 10,584.11830

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.72538

Cumulative Model Updates: 188,482
Cumulative Timesteps: 1,571,941,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.13021
Policy Entropy: 2.39712
Value Function Loss: 0.01522

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.59506

Collected Steps per Second: 22,668.66796
Overall Steps per Second: 10,846.98364

Timestep Collection Time: 2.20631
Timestep Consumption Time: 2.40456
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61087

Cumulative Model Updates: 188,488
Cumulative Timesteps: 1,571,991,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1571991760...
Checkpoint 1571991760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.35770
Policy Entropy: 2.42376
Value Function Loss: 0.01436

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 22,514.78875
Overall Steps per Second: 10,714.20310

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.66876

Cumulative Model Updates: 188,494
Cumulative Timesteps: 1,572,041,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.68946
Policy Entropy: 2.41921
Value Function Loss: 0.01459

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.53802
Value Function Update Magnitude: 0.55430

Collected Steps per Second: 23,286.91082
Overall Steps per Second: 10,904.19348

Timestep Collection Time: 2.14790
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.58704

Cumulative Model Updates: 188,500
Cumulative Timesteps: 1,572,091,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1572091800...
Checkpoint 1572091800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.59370
Policy Entropy: 2.40924
Value Function Loss: 0.01430

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.57341

Collected Steps per Second: 23,089.08616
Overall Steps per Second: 10,700.71888

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.67445

Cumulative Model Updates: 188,506
Cumulative Timesteps: 1,572,141,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.77468
Policy Entropy: 2.39826
Value Function Loss: 0.01528

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.58598

Collected Steps per Second: 23,467.51548
Overall Steps per Second: 10,856.71072

Timestep Collection Time: 2.13078
Timestep Consumption Time: 2.47504
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.60581

Cumulative Model Updates: 188,512
Cumulative Timesteps: 1,572,191,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1572191824...
Checkpoint 1572191824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.75528
Policy Entropy: 2.40276
Value Function Loss: 0.01509

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 22,093.11118
Overall Steps per Second: 10,654.80603

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.43074
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.69497

Cumulative Model Updates: 188,518
Cumulative Timesteps: 1,572,241,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.42916
Policy Entropy: 2.37738
Value Function Loss: 0.01659

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.60008

Collected Steps per Second: 22,820.12245
Overall Steps per Second: 10,911.50164

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.39146
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.58269

Cumulative Model Updates: 188,524
Cumulative Timesteps: 1,572,291,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1572291852...
Checkpoint 1572291852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.41567
Policy Entropy: 2.37480
Value Function Loss: 0.01517

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.60822

Collected Steps per Second: 21,974.55090
Overall Steps per Second: 10,595.64649

Timestep Collection Time: 2.27627
Timestep Consumption Time: 2.44454
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.72081

Cumulative Model Updates: 188,530
Cumulative Timesteps: 1,572,341,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.48482
Policy Entropy: 2.36959
Value Function Loss: 0.01501

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.59546

Collected Steps per Second: 23,510.33012
Overall Steps per Second: 10,864.03079

Timestep Collection Time: 2.12758
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.60418

Cumulative Model Updates: 188,536
Cumulative Timesteps: 1,572,391,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1572391892...
Checkpoint 1572391892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.53418
Policy Entropy: 2.38974
Value Function Loss: 0.01495

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.55852
Value Function Update Magnitude: 0.57984

Collected Steps per Second: 22,877.47932
Overall Steps per Second: 10,689.67437

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.68022

Cumulative Model Updates: 188,542
Cumulative Timesteps: 1,572,441,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.65552
Policy Entropy: 2.38452
Value Function Loss: 0.01454

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.54230
Value Function Update Magnitude: 0.58031

Collected Steps per Second: 22,627.22123
Overall Steps per Second: 10,809.01431

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62762

Cumulative Model Updates: 188,548
Cumulative Timesteps: 1,572,491,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1572491942...
Checkpoint 1572491942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.45072
Policy Entropy: 2.36948
Value Function Loss: 0.01591

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.58484

Collected Steps per Second: 22,726.90303
Overall Steps per Second: 10,792.52843

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.63450

Cumulative Model Updates: 188,554
Cumulative Timesteps: 1,572,541,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.74120
Policy Entropy: 2.35558
Value Function Loss: 0.01589

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 23,265.78173
Overall Steps per Second: 10,923.32982

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.57773

Cumulative Model Updates: 188,560
Cumulative Timesteps: 1,572,591,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1572591964...
Checkpoint 1572591964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.01866
Policy Entropy: 2.37024
Value Function Loss: 0.01590

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.56564
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 23,034.39761
Overall Steps per Second: 10,780.83765

Timestep Collection Time: 2.17162
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.63990

Cumulative Model Updates: 188,566
Cumulative Timesteps: 1,572,641,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.14764
Policy Entropy: 2.39554
Value Function Loss: 0.01421

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.55104
Value Function Update Magnitude: 0.59518

Collected Steps per Second: 22,457.33253
Overall Steps per Second: 10,720.23560

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.66408

Cumulative Model Updates: 188,572
Cumulative Timesteps: 1,572,691,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1572691986...
Checkpoint 1572691986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.60735
Policy Entropy: 2.40254
Value Function Loss: 0.01443

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.57587

Collected Steps per Second: 22,224.93147
Overall Steps per Second: 10,618.59653

Timestep Collection Time: 2.24991
Timestep Consumption Time: 2.45919
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.70910

Cumulative Model Updates: 188,578
Cumulative Timesteps: 1,572,741,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.52883
Policy Entropy: 2.38978
Value Function Loss: 0.01489

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.58821

Collected Steps per Second: 22,982.23345
Overall Steps per Second: 10,937.22455

Timestep Collection Time: 2.17559
Timestep Consumption Time: 2.39595
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.57154

Cumulative Model Updates: 188,584
Cumulative Timesteps: 1,572,791,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1572791990...
Checkpoint 1572791990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.72531
Policy Entropy: 2.39216
Value Function Loss: 0.01543

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.60514

Collected Steps per Second: 22,921.57583
Overall Steps per Second: 10,610.58389

Timestep Collection Time: 2.18249
Timestep Consumption Time: 2.53224
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.71473

Cumulative Model Updates: 188,590
Cumulative Timesteps: 1,572,842,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.74718
Policy Entropy: 2.39899
Value Function Loss: 0.01537

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.54966
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 23,438.59665
Overall Steps per Second: 10,810.80147

Timestep Collection Time: 2.13434
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.62741

Cumulative Model Updates: 188,596
Cumulative Timesteps: 1,572,892,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1572892042...
Checkpoint 1572892042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.45274
Policy Entropy: 2.40518
Value Function Loss: 0.01514

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.60978

Collected Steps per Second: 22,756.14267
Overall Steps per Second: 10,757.91404

Timestep Collection Time: 2.19747
Timestep Consumption Time: 2.45083
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.64830

Cumulative Model Updates: 188,602
Cumulative Timesteps: 1,572,942,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.44840
Policy Entropy: 2.39588
Value Function Loss: 0.01495

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 23,246.74380
Overall Steps per Second: 10,926.02566

Timestep Collection Time: 2.15222
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.57916

Cumulative Model Updates: 188,608
Cumulative Timesteps: 1,572,992,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1572992080...
Checkpoint 1572992080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.04128
Policy Entropy: 2.39188
Value Function Loss: 0.01543

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.61178

Collected Steps per Second: 22,350.54098
Overall Steps per Second: 10,587.42575

Timestep Collection Time: 2.23717
Timestep Consumption Time: 2.48560
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.72277

Cumulative Model Updates: 188,614
Cumulative Timesteps: 1,573,042,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.94878
Policy Entropy: 2.39296
Value Function Loss: 0.01571

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.63540

Collected Steps per Second: 23,230.66943
Overall Steps per Second: 10,931.81408

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.57454

Cumulative Model Updates: 188,620
Cumulative Timesteps: 1,573,092,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1573092090...
Checkpoint 1573092090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.09500
Policy Entropy: 2.39292
Value Function Loss: 0.01586

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.63893

Collected Steps per Second: 22,429.19904
Overall Steps per Second: 10,637.68285

Timestep Collection Time: 2.22977
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.70140

Cumulative Model Updates: 188,626
Cumulative Timesteps: 1,573,142,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.66230
Policy Entropy: 2.40155
Value Function Loss: 0.01609

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.16242
Policy Update Magnitude: 0.54436
Value Function Update Magnitude: 0.62386

Collected Steps per Second: 22,950.24590
Overall Steps per Second: 10,824.16759

Timestep Collection Time: 2.17941
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62096

Cumulative Model Updates: 188,632
Cumulative Timesteps: 1,573,192,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1573192120...
Checkpoint 1573192120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.97618
Policy Entropy: 2.38531
Value Function Loss: 0.01604

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.16402
Policy Update Magnitude: 0.51763
Value Function Update Magnitude: 0.61343

Collected Steps per Second: 22,585.92745
Overall Steps per Second: 10,791.43871

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.63386

Cumulative Model Updates: 188,638
Cumulative Timesteps: 1,573,242,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.71612
Policy Entropy: 2.39583
Value Function Loss: 0.01557

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.61622

Collected Steps per Second: 23,495.57472
Overall Steps per Second: 10,831.68063

Timestep Collection Time: 2.12917
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.61849

Cumulative Model Updates: 188,644
Cumulative Timesteps: 1,573,292,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1573292152...
Checkpoint 1573292152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.55331
Policy Entropy: 2.38709
Value Function Loss: 0.01610

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.16793
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.61492

Collected Steps per Second: 22,753.44528
Overall Steps per Second: 10,844.02589

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.41423
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.61249

Cumulative Model Updates: 188,650
Cumulative Timesteps: 1,573,342,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.55128
Policy Entropy: 2.40145
Value Function Loss: 0.01560

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 22,866.55767
Overall Steps per Second: 10,877.06517

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.41061
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.59756

Cumulative Model Updates: 188,656
Cumulative Timesteps: 1,573,392,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1573392178...
Checkpoint 1573392178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.55309
Policy Entropy: 2.39736
Value Function Loss: 0.01631

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 23,360.87930
Overall Steps per Second: 10,917.44830

Timestep Collection Time: 2.14102
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.58129

Cumulative Model Updates: 188,662
Cumulative Timesteps: 1,573,442,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.55178
Policy Entropy: 2.39886
Value Function Loss: 0.01650

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.57627
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 23,390.60828
Overall Steps per Second: 10,949.79570

Timestep Collection Time: 2.13804
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.56721

Cumulative Model Updates: 188,668
Cumulative Timesteps: 1,573,492,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1573492204...
Checkpoint 1573492204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.24097
Policy Entropy: 2.40590
Value Function Loss: 0.01528

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.57203
Value Function Update Magnitude: 0.60572

Collected Steps per Second: 22,874.52577
Overall Steps per Second: 10,611.19845

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.52718
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.71389

Cumulative Model Updates: 188,674
Cumulative Timesteps: 1,573,542,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.47235
Policy Entropy: 2.38356
Value Function Loss: 0.01444

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.55630
Value Function Update Magnitude: 0.59961

Collected Steps per Second: 22,869.84913
Overall Steps per Second: 10,867.31973

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.41496
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60150

Cumulative Model Updates: 188,680
Cumulative Timesteps: 1,573,592,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1573592230...
Checkpoint 1573592230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.07810
Policy Entropy: 2.39147
Value Function Loss: 0.01401

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.57594

Collected Steps per Second: 22,464.47347
Overall Steps per Second: 10,715.25322

Timestep Collection Time: 2.22645
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.66774

Cumulative Model Updates: 188,686
Cumulative Timesteps: 1,573,642,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.95374
Policy Entropy: 2.38432
Value Function Loss: 0.01507

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.57899

Collected Steps per Second: 23,163.25117
Overall Steps per Second: 10,880.09996

Timestep Collection Time: 2.15894
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.59628

Cumulative Model Updates: 188,692
Cumulative Timesteps: 1,573,692,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1573692254...
Checkpoint 1573692254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.14811
Policy Entropy: 2.41847
Value Function Loss: 0.01482

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.56799

Collected Steps per Second: 23,089.44575
Overall Steps per Second: 10,639.87091

Timestep Collection Time: 2.16653
Timestep Consumption Time: 2.53503
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70156

Cumulative Model Updates: 188,698
Cumulative Timesteps: 1,573,742,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.49639
Policy Entropy: 2.39832
Value Function Loss: 0.01536

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.56209

Collected Steps per Second: 23,031.06394
Overall Steps per Second: 10,869.94464

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60076

Cumulative Model Updates: 188,704
Cumulative Timesteps: 1,573,792,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1573792288...
Checkpoint 1573792288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.84359
Policy Entropy: 2.38555
Value Function Loss: 0.01545

Mean KL Divergence: 0.02865
SB3 Clip Fraction: 0.18285
Policy Update Magnitude: 0.51010
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 22,895.74039
Overall Steps per Second: 10,923.35808

Timestep Collection Time: 2.18477
Timestep Consumption Time: 2.39459
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.57936

Cumulative Model Updates: 188,710
Cumulative Timesteps: 1,573,842,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.63474
Policy Entropy: 2.35417
Value Function Loss: 0.01522

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.60105

Collected Steps per Second: 23,768.10299
Overall Steps per Second: 10,926.59099

Timestep Collection Time: 2.10442
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.57764

Cumulative Model Updates: 188,716
Cumulative Timesteps: 1,573,892,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1573892328...
Checkpoint 1573892328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.27126
Policy Entropy: 2.36525
Value Function Loss: 0.01454

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.57746
Value Function Update Magnitude: 0.59765

Collected Steps per Second: 22,760.51609
Overall Steps per Second: 10,814.45286

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62437

Cumulative Model Updates: 188,722
Cumulative Timesteps: 1,573,942,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.61153
Policy Entropy: 2.37377
Value Function Loss: 0.01548

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.58932

Collected Steps per Second: 23,183.10631
Overall Steps per Second: 10,895.26943

Timestep Collection Time: 2.15761
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59098

Cumulative Model Updates: 188,728
Cumulative Timesteps: 1,573,992,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1573992358...
Checkpoint 1573992358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.86510
Policy Entropy: 2.38643
Value Function Loss: 0.01578

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.57201
Value Function Update Magnitude: 0.58976

Collected Steps per Second: 22,501.26227
Overall Steps per Second: 10,725.06776

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.66384

Cumulative Model Updates: 188,734
Cumulative Timesteps: 1,574,042,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.13266
Policy Entropy: 2.38948
Value Function Loss: 0.01656

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.56704
Value Function Update Magnitude: 0.59864

Collected Steps per Second: 22,889.00639
Overall Steps per Second: 10,911.72777

Timestep Collection Time: 2.18568
Timestep Consumption Time: 2.39911
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.58479

Cumulative Model Updates: 188,740
Cumulative Timesteps: 1,574,092,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1574092406...
Checkpoint 1574092406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.46201
Policy Entropy: 2.38284
Value Function Loss: 0.01746

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.57245
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 22,502.17812
Overall Steps per Second: 10,588.87436

Timestep Collection Time: 2.22210
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.72213

Cumulative Model Updates: 188,746
Cumulative Timesteps: 1,574,142,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.25736
Policy Entropy: 2.35464
Value Function Loss: 0.01688

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 23,048.87047
Overall Steps per Second: 10,850.74672

Timestep Collection Time: 2.16930
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60798

Cumulative Model Updates: 188,752
Cumulative Timesteps: 1,574,192,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1574192408...
Checkpoint 1574192408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.69708
Policy Entropy: 2.34306
Value Function Loss: 0.01685

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.58040
Value Function Update Magnitude: 0.63264

Collected Steps per Second: 23,050.06644
Overall Steps per Second: 10,721.82434

Timestep Collection Time: 2.17119
Timestep Consumption Time: 2.49649
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.66768

Cumulative Model Updates: 188,758
Cumulative Timesteps: 1,574,242,454

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.59225
Policy Entropy: 2.35709
Value Function Loss: 0.01634

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.60059

Collected Steps per Second: 23,095.80447
Overall Steps per Second: 10,964.69624

Timestep Collection Time: 2.16619
Timestep Consumption Time: 2.39663
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.56283

Cumulative Model Updates: 188,764
Cumulative Timesteps: 1,574,292,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1574292484...
Checkpoint 1574292484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.20938
Policy Entropy: 2.36008
Value Function Loss: 0.01610

Mean KL Divergence: 0.02583
SB3 Clip Fraction: 0.17764
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.58530

Collected Steps per Second: 22,901.17916
Overall Steps per Second: 11,000.48453

Timestep Collection Time: 2.18469
Timestep Consumption Time: 2.36347
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.54816

Cumulative Model Updates: 188,770
Cumulative Timesteps: 1,574,342,516

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.64598
Policy Entropy: 2.37375
Value Function Loss: 0.01561

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.16619
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.57829

Collected Steps per Second: 23,202.05421
Overall Steps per Second: 10,904.95872

Timestep Collection Time: 2.15541
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.58599

Cumulative Model Updates: 188,776
Cumulative Timesteps: 1,574,392,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1574392526...
Checkpoint 1574392526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.32254
Policy Entropy: 2.37853
Value Function Loss: 0.01526

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.17274
Policy Update Magnitude: 0.55206
Value Function Update Magnitude: 0.56177

Collected Steps per Second: 22,876.28887
Overall Steps per Second: 10,705.86326

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.67034

Cumulative Model Updates: 188,782
Cumulative Timesteps: 1,574,442,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.72182
Policy Entropy: 2.39445
Value Function Loss: 0.01518

Mean KL Divergence: 0.02204
SB3 Clip Fraction: 0.16942
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.55772

Collected Steps per Second: 22,740.28425
Overall Steps per Second: 10,817.87695

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62457

Cumulative Model Updates: 188,788
Cumulative Timesteps: 1,574,492,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1574492554...
Checkpoint 1574492554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.37941
Policy Entropy: 2.38533
Value Function Loss: 0.01389

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.53239

Collected Steps per Second: 22,209.52686
Overall Steps per Second: 10,773.33197

Timestep Collection Time: 2.25192
Timestep Consumption Time: 2.39047
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.64239

Cumulative Model Updates: 188,794
Cumulative Timesteps: 1,574,542,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.17284
Policy Entropy: 2.40976
Value Function Loss: 0.01422

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.54926

Collected Steps per Second: 23,023.25425
Overall Steps per Second: 10,881.57985

Timestep Collection Time: 2.17233
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.59621

Cumulative Model Updates: 188,800
Cumulative Timesteps: 1,574,592,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1574592582...
Checkpoint 1574592582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.08326
Policy Entropy: 2.38575
Value Function Loss: 0.01440

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.59441

Collected Steps per Second: 21,728.58674
Overall Steps per Second: 10,609.08522

Timestep Collection Time: 2.30222
Timestep Consumption Time: 2.41298
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.71520

Cumulative Model Updates: 188,806
Cumulative Timesteps: 1,574,642,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.77378
Policy Entropy: 2.37161
Value Function Loss: 0.01540

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.59888

Collected Steps per Second: 23,208.49402
Overall Steps per Second: 10,872.20109

Timestep Collection Time: 2.15490
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59999

Cumulative Model Updates: 188,812
Cumulative Timesteps: 1,574,692,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1574692618...
Checkpoint 1574692618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.84929
Policy Entropy: 2.33604
Value Function Loss: 0.01591

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.58659

Collected Steps per Second: 22,802.43442
Overall Steps per Second: 10,664.92163

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.68958

Cumulative Model Updates: 188,818
Cumulative Timesteps: 1,574,742,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.94448
Policy Entropy: 2.35906
Value Function Loss: 0.01617

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.58259

Collected Steps per Second: 23,197.28739
Overall Steps per Second: 10,876.63981

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59774

Cumulative Model Updates: 188,824
Cumulative Timesteps: 1,574,792,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1574792640...
Checkpoint 1574792640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.32185
Policy Entropy: 2.37174
Value Function Loss: 0.01622

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 23,120.75006
Overall Steps per Second: 10,790.78498

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.63358

Cumulative Model Updates: 188,830
Cumulative Timesteps: 1,574,842,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.71494
Policy Entropy: 2.38771
Value Function Loss: 0.01493

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.59528

Collected Steps per Second: 22,177.33691
Overall Steps per Second: 10,833.68246

Timestep Collection Time: 2.25473
Timestep Consumption Time: 2.36087
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.61561

Cumulative Model Updates: 188,836
Cumulative Timesteps: 1,574,892,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1574892644...
Checkpoint 1574892644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.06796
Policy Entropy: 2.39302
Value Function Loss: 0.01471

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.57348

Collected Steps per Second: 23,175.19119
Overall Steps per Second: 10,784.61236

Timestep Collection Time: 2.15791
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.63716

Cumulative Model Updates: 188,842
Cumulative Timesteps: 1,574,942,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.33384
Policy Entropy: 2.38072
Value Function Loss: 0.01578

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.54886
Value Function Update Magnitude: 0.55803

Collected Steps per Second: 23,419.57444
Overall Steps per Second: 10,774.68290

Timestep Collection Time: 2.13539
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.64144

Cumulative Model Updates: 188,848
Cumulative Timesteps: 1,574,992,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1574992664...
Checkpoint 1574992664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.69042
Policy Entropy: 2.38889
Value Function Loss: 0.01544

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.54867
Value Function Update Magnitude: 0.54746

Collected Steps per Second: 22,141.56265
Overall Steps per Second: 10,586.71757

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.46529
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.72403

Cumulative Model Updates: 188,854
Cumulative Timesteps: 1,575,042,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.73357
Policy Entropy: 2.35633
Value Function Loss: 0.01568

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.53378

Collected Steps per Second: 22,933.03533
Overall Steps per Second: 10,904.40244

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.40514
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58549

Cumulative Model Updates: 188,860
Cumulative Timesteps: 1,575,092,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1575092678...
Checkpoint 1575092678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.78677
Policy Entropy: 2.35577
Value Function Loss: 0.01441

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.52394

Collected Steps per Second: 22,447.89871
Overall Steps per Second: 10,777.75517

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.41325
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.64197

Cumulative Model Updates: 188,866
Cumulative Timesteps: 1,575,142,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.84528
Policy Entropy: 2.33470
Value Function Loss: 0.01433

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.52558

Collected Steps per Second: 22,996.12989
Overall Steps per Second: 10,737.27891

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.65667

Cumulative Model Updates: 188,872
Cumulative Timesteps: 1,575,192,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1575192708...
Checkpoint 1575192708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.39023
Policy Entropy: 2.31641
Value Function Loss: 0.01388

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.53777
Value Function Update Magnitude: 0.52380

Collected Steps per Second: 22,242.82533
Overall Steps per Second: 10,600.40438

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.71944

Cumulative Model Updates: 188,878
Cumulative Timesteps: 1,575,242,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.73982
Policy Entropy: 2.32276
Value Function Loss: 0.01456

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.53453

Collected Steps per Second: 23,091.50501
Overall Steps per Second: 10,759.34389

Timestep Collection Time: 2.16712
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.65103

Cumulative Model Updates: 188,884
Cumulative Timesteps: 1,575,292,778

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1575292778...
Checkpoint 1575292778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.85761
Policy Entropy: 2.31694
Value Function Loss: 0.01503

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,883.83742
Overall Steps per Second: 10,860.78011

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.60611

Cumulative Model Updates: 188,890
Cumulative Timesteps: 1,575,342,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.47376
Policy Entropy: 2.32646
Value Function Loss: 0.01642

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.54790

Collected Steps per Second: 23,025.59336
Overall Steps per Second: 10,921.57924

Timestep Collection Time: 2.17150
Timestep Consumption Time: 2.40660
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.57809

Cumulative Model Updates: 188,896
Cumulative Timesteps: 1,575,392,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1575392804...
Checkpoint 1575392804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.78222
Policy Entropy: 2.31931
Value Function Loss: 0.01584

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.55682

Collected Steps per Second: 23,048.26405
Overall Steps per Second: 10,655.02925

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69318

Cumulative Model Updates: 188,902
Cumulative Timesteps: 1,575,442,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.18550
Policy Entropy: 2.31917
Value Function Loss: 0.01603

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.55389
Value Function Update Magnitude: 0.56091

Collected Steps per Second: 23,672.38681
Overall Steps per Second: 10,936.16819

Timestep Collection Time: 2.11250
Timestep Consumption Time: 2.46021
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.57272

Cumulative Model Updates: 188,908
Cumulative Timesteps: 1,575,492,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1575492818...
Checkpoint 1575492818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.41191
Policy Entropy: 2.34523
Value Function Loss: 0.01471

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.53051
Value Function Update Magnitude: 0.57841

Collected Steps per Second: 22,548.10650
Overall Steps per Second: 10,668.62560

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.46916
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.68664

Cumulative Model Updates: 188,914
Cumulative Timesteps: 1,575,542,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.47284
Policy Entropy: 2.34221
Value Function Loss: 0.01478

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.53076
Value Function Update Magnitude: 0.58312

Collected Steps per Second: 23,123.90725
Overall Steps per Second: 10,810.84937

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.62572

Cumulative Model Updates: 188,920
Cumulative Timesteps: 1,575,592,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1575592826...
Checkpoint 1575592826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.07975
Policy Entropy: 2.36860
Value Function Loss: 0.01466

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.57316

Collected Steps per Second: 22,576.24437
Overall Steps per Second: 10,765.44376

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.64523

Cumulative Model Updates: 188,926
Cumulative Timesteps: 1,575,642,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.75387
Policy Entropy: 2.36779
Value Function Loss: 0.01522

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.58139

Collected Steps per Second: 23,033.15487
Overall Steps per Second: 10,883.25925

Timestep Collection Time: 2.17183
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59642

Cumulative Model Updates: 188,932
Cumulative Timesteps: 1,575,692,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1575692858...
Checkpoint 1575692858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.72719
Policy Entropy: 2.36373
Value Function Loss: 0.01570

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 22,927.60712
Overall Steps per Second: 10,581.08340

Timestep Collection Time: 2.18113
Timestep Consumption Time: 2.54504
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.72617

Cumulative Model Updates: 188,938
Cumulative Timesteps: 1,575,742,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.34660
Policy Entropy: 2.34438
Value Function Loss: 0.01620

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.59445

Collected Steps per Second: 23,410.30922
Overall Steps per Second: 10,917.03557

Timestep Collection Time: 2.13641
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.58128

Cumulative Model Updates: 188,944
Cumulative Timesteps: 1,575,792,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1575792880...
Checkpoint 1575792880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.46653
Policy Entropy: 2.33963
Value Function Loss: 0.01559

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 22,877.98794
Overall Steps per Second: 10,705.49036

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67162

Cumulative Model Updates: 188,950
Cumulative Timesteps: 1,575,842,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.10581
Policy Entropy: 2.35297
Value Function Loss: 0.01569

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.58149

Collected Steps per Second: 23,375.75754
Overall Steps per Second: 10,973.14438

Timestep Collection Time: 2.13982
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.55840

Cumulative Model Updates: 188,956
Cumulative Timesteps: 1,575,892,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1575892912...
Checkpoint 1575892912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.11337
Policy Entropy: 2.35358
Value Function Loss: 0.01545

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.58812

Collected Steps per Second: 22,886.09144
Overall Steps per Second: 10,718.90494

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66876

Cumulative Model Updates: 188,962
Cumulative Timesteps: 1,575,942,956

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.54314
Policy Entropy: 2.34205
Value Function Loss: 0.01655

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.57744

Collected Steps per Second: 23,320.03911
Overall Steps per Second: 10,728.75040

Timestep Collection Time: 2.14416
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.66056

Cumulative Model Updates: 188,968
Cumulative Timesteps: 1,575,992,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1575992958...
Checkpoint 1575992958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.54577
Policy Entropy: 2.33220
Value Function Loss: 0.01707

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.56545

Collected Steps per Second: 22,259.10510
Overall Steps per Second: 10,698.42638

Timestep Collection Time: 2.24663
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.67433

Cumulative Model Updates: 188,974
Cumulative Timesteps: 1,576,042,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.63838
Policy Entropy: 2.33502
Value Function Loss: 0.01694

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.18810
Policy Update Magnitude: 0.52428
Value Function Update Magnitude: 0.56842

Collected Steps per Second: 21,702.42692
Overall Steps per Second: 10,374.25103

Timestep Collection Time: 2.30472
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82136

Cumulative Model Updates: 188,980
Cumulative Timesteps: 1,576,092,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1576092984...
Checkpoint 1576092984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.45885
Policy Entropy: 2.35837
Value Function Loss: 0.01604

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.16965
Policy Update Magnitude: 0.49096
Value Function Update Magnitude: 0.56622

Collected Steps per Second: 22,757.41649
Overall Steps per Second: 10,761.36936

Timestep Collection Time: 2.19840
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.64904

Cumulative Model Updates: 188,986
Cumulative Timesteps: 1,576,143,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.85438
Policy Entropy: 2.38085
Value Function Loss: 0.01663

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16820
Policy Update Magnitude: 0.51438
Value Function Update Magnitude: 0.57588

Collected Steps per Second: 23,365.26867
Overall Steps per Second: 10,780.45493

Timestep Collection Time: 2.14036
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.63895

Cumulative Model Updates: 188,992
Cumulative Timesteps: 1,576,193,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1576193024...
Checkpoint 1576193024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.35882
Policy Entropy: 2.36262
Value Function Loss: 0.01620

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.58225

Collected Steps per Second: 22,989.71178
Overall Steps per Second: 10,664.95186

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.51337
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.68825

Cumulative Model Updates: 188,998
Cumulative Timesteps: 1,576,243,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.27743
Policy Entropy: 2.35709
Value Function Loss: 0.01571

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.56553

Collected Steps per Second: 23,667.51431
Overall Steps per Second: 10,916.16664

Timestep Collection Time: 2.11277
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.58073

Cumulative Model Updates: 189,004
Cumulative Timesteps: 1,576,293,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576293028...
Checkpoint 1576293028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.59570
Policy Entropy: 2.35085
Value Function Loss: 0.01579

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.56066

Collected Steps per Second: 22,754.47299
Overall Steps per Second: 10,713.75510

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.47071
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.66914

Cumulative Model Updates: 189,010
Cumulative Timesteps: 1,576,343,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.62041
Policy Entropy: 2.35241
Value Function Loss: 0.01480

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.55939

Collected Steps per Second: 23,272.30067
Overall Steps per Second: 10,850.41959

Timestep Collection Time: 2.14873
Timestep Consumption Time: 2.45993
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.60867

Cumulative Model Updates: 189,016
Cumulative Timesteps: 1,576,393,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1576393058...
Checkpoint 1576393058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.93588
Policy Entropy: 2.35488
Value Function Loss: 0.01548

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,601.93403
Overall Steps per Second: 10,818.99357

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.41065
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.62409

Cumulative Model Updates: 189,022
Cumulative Timesteps: 1,576,443,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.81756
Policy Entropy: 2.33583
Value Function Loss: 0.01509

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.58344

Collected Steps per Second: 23,018.52789
Overall Steps per Second: 10,757.71823

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.64968

Cumulative Model Updates: 189,028
Cumulative Timesteps: 1,576,493,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1576493106...
Checkpoint 1576493106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.66736
Policy Entropy: 2.34377
Value Function Loss: 0.01564

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.58338

Collected Steps per Second: 22,229.75186
Overall Steps per Second: 10,625.66450

Timestep Collection Time: 2.24978
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.70672

Cumulative Model Updates: 189,034
Cumulative Timesteps: 1,576,543,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.52406
Policy Entropy: 2.31641
Value Function Loss: 0.01585

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.56858

Collected Steps per Second: 23,063.06891
Overall Steps per Second: 10,830.85902

Timestep Collection Time: 2.16797
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.61644

Cumulative Model Updates: 189,040
Cumulative Timesteps: 1,576,593,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1576593118...
Checkpoint 1576593118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.03827
Policy Entropy: 2.32154
Value Function Loss: 0.01509

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.54978

Collected Steps per Second: 22,992.24930
Overall Steps per Second: 10,700.64718

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67355

Cumulative Model Updates: 189,046
Cumulative Timesteps: 1,576,643,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.52919
Policy Entropy: 2.29840
Value Function Loss: 0.01500

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.53101

Collected Steps per Second: 23,200.63969
Overall Steps per Second: 10,832.65895

Timestep Collection Time: 2.15529
Timestep Consumption Time: 2.46076
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.61604

Cumulative Model Updates: 189,052
Cumulative Timesteps: 1,576,693,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576693132...
Checkpoint 1576693132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.95399
Policy Entropy: 2.32178
Value Function Loss: 0.01493

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.52281

Collected Steps per Second: 23,132.28896
Overall Steps per Second: 10,698.44198

Timestep Collection Time: 2.16226
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.67526

Cumulative Model Updates: 189,058
Cumulative Timesteps: 1,576,743,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.52249
Policy Entropy: 2.34008
Value Function Loss: 0.01536

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.52251

Collected Steps per Second: 23,490.90118
Overall Steps per Second: 10,915.07902

Timestep Collection Time: 2.12959
Timestep Consumption Time: 2.45361
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.58320

Cumulative Model Updates: 189,064
Cumulative Timesteps: 1,576,793,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1576793176...
Checkpoint 1576793176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.47041
Policy Entropy: 2.36517
Value Function Loss: 0.01576

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.53142

Collected Steps per Second: 23,291.68071
Overall Steps per Second: 10,789.55328

Timestep Collection Time: 2.14755
Timestep Consumption Time: 2.48842
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.63597

Cumulative Model Updates: 189,070
Cumulative Timesteps: 1,576,843,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.26071
Policy Entropy: 2.35146
Value Function Loss: 0.01542

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.54274

Collected Steps per Second: 23,124.10623
Overall Steps per Second: 10,776.28245

Timestep Collection Time: 2.16337
Timestep Consumption Time: 2.47886
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.64223

Cumulative Model Updates: 189,076
Cumulative Timesteps: 1,576,893,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1576893222...
Checkpoint 1576893222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.63769
Policy Entropy: 2.34229
Value Function Loss: 0.01456

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.54111

Collected Steps per Second: 22,335.27290
Overall Steps per Second: 10,633.32957

Timestep Collection Time: 2.23951
Timestep Consumption Time: 2.46457
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.70408

Cumulative Model Updates: 189,082
Cumulative Timesteps: 1,576,943,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.85638
Policy Entropy: 2.32250
Value Function Loss: 0.01514

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.55199
Value Function Update Magnitude: 0.56416

Collected Steps per Second: 22,975.42506
Overall Steps per Second: 10,903.85676

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.58590

Cumulative Model Updates: 189,088
Cumulative Timesteps: 1,576,993,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576993246...
Checkpoint 1576993246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.64272
Policy Entropy: 2.31674
Value Function Loss: 0.01519

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.55848
Value Function Update Magnitude: 0.57271

Collected Steps per Second: 22,814.47219
Overall Steps per Second: 10,616.15674

Timestep Collection Time: 2.19220
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.71112

Cumulative Model Updates: 189,094
Cumulative Timesteps: 1,577,043,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.65658
Policy Entropy: 2.31356
Value Function Loss: 0.01672

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.55817
Value Function Update Magnitude: 0.57165

Collected Steps per Second: 23,041.43538
Overall Steps per Second: 10,837.13957

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.44474
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61561

Cumulative Model Updates: 189,100
Cumulative Timesteps: 1,577,093,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1577093280...
Checkpoint 1577093280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.55811
Policy Entropy: 2.32392
Value Function Loss: 0.01710

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.56198
Value Function Update Magnitude: 0.56706

Collected Steps per Second: 22,472.95039
Overall Steps per Second: 10,775.75153

Timestep Collection Time: 2.22499
Timestep Consumption Time: 2.41525
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.64023

Cumulative Model Updates: 189,106
Cumulative Timesteps: 1,577,143,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.35763
Policy Entropy: 2.29827
Value Function Loss: 0.01808

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.60677

Collected Steps per Second: 23,370.28576
Overall Steps per Second: 10,936.37993

Timestep Collection Time: 2.14075
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.57464

Cumulative Model Updates: 189,112
Cumulative Timesteps: 1,577,193,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1577193312...
Checkpoint 1577193312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.53263
Policy Entropy: 2.30791
Value Function Loss: 0.01705

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.59997

Collected Steps per Second: 23,328.42314
Overall Steps per Second: 10,942.51974

Timestep Collection Time: 2.14391
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.57061

Cumulative Model Updates: 189,118
Cumulative Timesteps: 1,577,243,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.46619
Policy Entropy: 2.28893
Value Function Loss: 0.01629

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 23,348.39422
Overall Steps per Second: 10,922.71051

Timestep Collection Time: 2.14250
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.57982

Cumulative Model Updates: 189,124
Cumulative Timesteps: 1,577,293,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1577293350...
Checkpoint 1577293350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.17862
Policy Entropy: 2.30411
Value Function Loss: 0.01493

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 22,532.56785
Overall Steps per Second: 10,766.29532

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.64691

Cumulative Model Updates: 189,130
Cumulative Timesteps: 1,577,343,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.02670
Policy Entropy: 2.30720
Value Function Loss: 0.01490

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.55500

Collected Steps per Second: 23,252.58787
Overall Steps per Second: 10,854.50812

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.60804

Cumulative Model Updates: 189,136
Cumulative Timesteps: 1,577,393,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1577393398...
Checkpoint 1577393398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.81278
Policy Entropy: 2.30936
Value Function Loss: 0.01663

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.56611

Collected Steps per Second: 22,578.00793
Overall Steps per Second: 10,843.90831

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.39663
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.61144

Cumulative Model Updates: 189,142
Cumulative Timesteps: 1,577,443,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.18337
Policy Entropy: 2.32877
Value Function Loss: 0.01800

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 23,172.86101
Overall Steps per Second: 10,719.34702

Timestep Collection Time: 2.15821
Timestep Consumption Time: 2.50737
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.66558

Cumulative Model Updates: 189,148
Cumulative Timesteps: 1,577,493,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1577493416...
Checkpoint 1577493416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.92118
Policy Entropy: 2.33908
Value Function Loss: 0.01737

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.63270

Collected Steps per Second: 22,346.27488
Overall Steps per Second: 10,628.31120

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.70649

Cumulative Model Updates: 189,154
Cumulative Timesteps: 1,577,543,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.01358
Policy Entropy: 2.35446
Value Function Loss: 0.01590

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.61295

Collected Steps per Second: 22,821.00827
Overall Steps per Second: 10,849.55495

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60959

Cumulative Model Updates: 189,160
Cumulative Timesteps: 1,577,593,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1577593450...
Checkpoint 1577593450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.05514
Policy Entropy: 2.37172
Value Function Loss: 0.01481

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.56990

Collected Steps per Second: 22,930.25342
Overall Steps per Second: 10,818.81065

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.62158

Cumulative Model Updates: 189,166
Cumulative Timesteps: 1,577,643,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.89001
Policy Entropy: 2.38144
Value Function Loss: 0.01478

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.53083

Collected Steps per Second: 23,447.74173
Overall Steps per Second: 10,773.55541

Timestep Collection Time: 2.13274
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.64174

Cumulative Model Updates: 189,172
Cumulative Timesteps: 1,577,693,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1577693458...
Checkpoint 1577693458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.04480
Policy Entropy: 2.39199
Value Function Loss: 0.01501

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.53191
Value Function Update Magnitude: 0.53566

Collected Steps per Second: 22,863.65731
Overall Steps per Second: 10,643.36002

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69946

Cumulative Model Updates: 189,178
Cumulative Timesteps: 1,577,743,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.79521
Policy Entropy: 2.36846
Value Function Loss: 0.01479

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 23,473.72701
Overall Steps per Second: 10,912.73101

Timestep Collection Time: 2.13217
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.58639

Cumulative Model Updates: 189,184
Cumulative Timesteps: 1,577,793,526

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1577793526...
Checkpoint 1577793526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.36256
Policy Entropy: 2.36486
Value Function Loss: 0.01474

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.55192

Collected Steps per Second: 22,772.26456
Overall Steps per Second: 10,696.66913

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.67510

Cumulative Model Updates: 189,190
Cumulative Timesteps: 1,577,843,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.00558
Policy Entropy: 2.34122
Value Function Loss: 0.01515

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.54966
Value Function Update Magnitude: 0.55543

Collected Steps per Second: 23,188.76766
Overall Steps per Second: 10,882.81712

Timestep Collection Time: 2.15630
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.59458

Cumulative Model Updates: 189,196
Cumulative Timesteps: 1,577,893,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1577893536...
Checkpoint 1577893536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.82045
Policy Entropy: 2.34846
Value Function Loss: 0.01491

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.55586

Collected Steps per Second: 23,307.01579
Overall Steps per Second: 10,817.38635

Timestep Collection Time: 2.14536
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.62237

Cumulative Model Updates: 189,202
Cumulative Timesteps: 1,577,943,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.84266
Policy Entropy: 2.38037
Value Function Loss: 0.01441

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 23,300.56848
Overall Steps per Second: 10,732.21118

Timestep Collection Time: 2.14639
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.65999

Cumulative Model Updates: 189,208
Cumulative Timesteps: 1,577,993,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1577993550...
Checkpoint 1577993550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.43883
Policy Entropy: 2.39110
Value Function Loss: 0.01601

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.53790
Value Function Update Magnitude: 0.52916

Collected Steps per Second: 22,198.18979
Overall Steps per Second: 10,595.99270

Timestep Collection Time: 2.25307
Timestep Consumption Time: 2.46702
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.72009

Cumulative Model Updates: 189,214
Cumulative Timesteps: 1,578,043,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.20833
Policy Entropy: 2.40183
Value Function Loss: 0.01595

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.53488

Collected Steps per Second: 22,794.06895
Overall Steps per Second: 10,846.16836

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.61048

Cumulative Model Updates: 189,220
Cumulative Timesteps: 1,578,093,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1578093570...
Checkpoint 1578093570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.77450
Policy Entropy: 2.37107
Value Function Loss: 0.01588

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.54079

Collected Steps per Second: 22,747.89887
Overall Steps per Second: 10,734.10202

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.65805

Cumulative Model Updates: 189,226
Cumulative Timesteps: 1,578,143,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.60296
Policy Entropy: 2.38061
Value Function Loss: 0.01548

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.53263

Collected Steps per Second: 23,535.49595
Overall Steps per Second: 10,839.37837

Timestep Collection Time: 2.12547
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.61502

Cumulative Model Updates: 189,232
Cumulative Timesteps: 1,578,193,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1578193594...
Checkpoint 1578193594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.98467
Policy Entropy: 2.38872
Value Function Loss: 0.01449

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.55201

Collected Steps per Second: 23,040.05118
Overall Steps per Second: 10,694.54245

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.67640

Cumulative Model Updates: 189,238
Cumulative Timesteps: 1,578,243,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.12236
Policy Entropy: 2.41297
Value Function Loss: 0.01429

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.55300

Collected Steps per Second: 23,322.30997
Overall Steps per Second: 10,947.55233

Timestep Collection Time: 2.14438
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.56833

Cumulative Model Updates: 189,244
Cumulative Timesteps: 1,578,293,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1578293618...
Checkpoint 1578293618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.83201
Policy Entropy: 2.40185
Value Function Loss: 0.01467

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.53264
Value Function Update Magnitude: 0.54001

Collected Steps per Second: 22,959.19843
Overall Steps per Second: 10,759.47684

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.64911

Cumulative Model Updates: 189,250
Cumulative Timesteps: 1,578,343,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.60223
Policy Entropy: 2.41283
Value Function Loss: 0.01568

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.53981

Collected Steps per Second: 23,348.86751
Overall Steps per Second: 11,021.91469

Timestep Collection Time: 2.14280
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.53932

Cumulative Model Updates: 189,256
Cumulative Timesteps: 1,578,393,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1578393672...
Checkpoint 1578393672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.09597
Policy Entropy: 2.39577
Value Function Loss: 0.01548

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.53339

Collected Steps per Second: 22,732.00238
Overall Steps per Second: 10,833.36209

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61703

Cumulative Model Updates: 189,262
Cumulative Timesteps: 1,578,443,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.74457
Policy Entropy: 2.37866
Value Function Loss: 0.01631

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.54670
Value Function Update Magnitude: 0.52974

Collected Steps per Second: 22,695.93584
Overall Steps per Second: 10,688.03328

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68075

Cumulative Model Updates: 189,268
Cumulative Timesteps: 1,578,493,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1578493718...
Checkpoint 1578493718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.87966
Policy Entropy: 2.36930
Value Function Loss: 0.01555

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.53647

Collected Steps per Second: 22,163.31343
Overall Steps per Second: 10,513.53231

Timestep Collection Time: 2.25697
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.75787

Cumulative Model Updates: 189,274
Cumulative Timesteps: 1,578,543,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.95380
Policy Entropy: 2.35621
Value Function Loss: 0.01665

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.54990

Collected Steps per Second: 23,139.05437
Overall Steps per Second: 10,847.56066

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.61154

Cumulative Model Updates: 189,280
Cumulative Timesteps: 1,578,593,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1578593764...
Checkpoint 1578593764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.34416
Policy Entropy: 2.36916
Value Function Loss: 0.01721

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.53752
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 22,576.95160
Overall Steps per Second: 10,713.55364

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.66923

Cumulative Model Updates: 189,286
Cumulative Timesteps: 1,578,643,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.41891
Policy Entropy: 2.36927
Value Function Loss: 0.01782

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 23,596.16125
Overall Steps per Second: 10,813.00278

Timestep Collection Time: 2.11907
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.62425

Cumulative Model Updates: 189,292
Cumulative Timesteps: 1,578,693,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1578693790...
Checkpoint 1578693790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.55029
Policy Entropy: 2.37977
Value Function Loss: 0.01754

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.61330

Collected Steps per Second: 23,019.59408
Overall Steps per Second: 10,686.28640

Timestep Collection Time: 2.17319
Timestep Consumption Time: 2.50813
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.68133

Cumulative Model Updates: 189,298
Cumulative Timesteps: 1,578,743,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.67171
Policy Entropy: 2.38303
Value Function Loss: 0.01681

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.61236

Collected Steps per Second: 23,458.35516
Overall Steps per Second: 10,884.71072

Timestep Collection Time: 2.13272
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.59636

Cumulative Model Updates: 189,304
Cumulative Timesteps: 1,578,793,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1578793846...
Checkpoint 1578793846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.62430
Policy Entropy: 2.38653
Value Function Loss: 0.01607

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.58924

Collected Steps per Second: 23,118.15607
Overall Steps per Second: 10,799.31377

Timestep Collection Time: 2.16315
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.63066

Cumulative Model Updates: 189,310
Cumulative Timesteps: 1,578,843,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.93911
Policy Entropy: 2.39943
Value Function Loss: 0.01623

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.55647

Collected Steps per Second: 23,101.45933
Overall Steps per Second: 10,930.83102

Timestep Collection Time: 2.16584
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.57733

Cumulative Model Updates: 189,316
Cumulative Timesteps: 1,578,893,888

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1578893888...
Checkpoint 1578893888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.03954
Policy Entropy: 2.42301
Value Function Loss: 0.01505

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.53566

Collected Steps per Second: 22,701.19318
Overall Steps per Second: 10,725.59854

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.66174

Cumulative Model Updates: 189,322
Cumulative Timesteps: 1,578,943,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.98141
Policy Entropy: 2.40327
Value Function Loss: 0.01516

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.52899
Value Function Update Magnitude: 0.51494

Collected Steps per Second: 22,996.84137
Overall Steps per Second: 10,671.18834

Timestep Collection Time: 2.17430
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.68570

Cumulative Model Updates: 189,328
Cumulative Timesteps: 1,578,993,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1578993890...
Checkpoint 1578993890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.34249
Policy Entropy: 2.39319
Value Function Loss: 0.01446

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.52731
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 22,562.07764
Overall Steps per Second: 10,591.26859

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.72144

Cumulative Model Updates: 189,334
Cumulative Timesteps: 1,579,043,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.96595
Policy Entropy: 2.36582
Value Function Loss: 0.01480

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.53815

Collected Steps per Second: 23,127.03915
Overall Steps per Second: 10,850.05312

Timestep Collection Time: 2.16206
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60846

Cumulative Model Updates: 189,340
Cumulative Timesteps: 1,579,093,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1579093898...
Checkpoint 1579093898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.09731
Policy Entropy: 2.38948
Value Function Loss: 0.01323

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.53407
Value Function Update Magnitude: 0.52543

Collected Steps per Second: 22,837.09743
Overall Steps per Second: 10,837.05543

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.61694

Cumulative Model Updates: 189,346
Cumulative Timesteps: 1,579,143,932

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.64487
Policy Entropy: 2.39412
Value Function Loss: 0.01414

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.52460
Value Function Update Magnitude: 0.52216

Collected Steps per Second: 23,221.06167
Overall Steps per Second: 10,788.11296

Timestep Collection Time: 2.15365
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.63566

Cumulative Model Updates: 189,352
Cumulative Timesteps: 1,579,193,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1579193942...
Checkpoint 1579193942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.22129
Policy Entropy: 2.36761
Value Function Loss: 0.01403

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.52541

Collected Steps per Second: 23,198.87456
Overall Steps per Second: 10,761.00439

Timestep Collection Time: 2.15554
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.64696

Cumulative Model Updates: 189,358
Cumulative Timesteps: 1,579,243,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.12981
Policy Entropy: 2.35791
Value Function Loss: 0.01495

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.56690

Collected Steps per Second: 23,155.08356
Overall Steps per Second: 10,813.81677

Timestep Collection Time: 2.16048
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.62612

Cumulative Model Updates: 189,364
Cumulative Timesteps: 1,579,293,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1579293974...
Checkpoint 1579293974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.72791
Policy Entropy: 2.35536
Value Function Loss: 0.01454

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.58651

Collected Steps per Second: 22,825.68138
Overall Steps per Second: 10,720.70926

Timestep Collection Time: 2.19174
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.66648

Cumulative Model Updates: 189,370
Cumulative Timesteps: 1,579,344,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.49289
Policy Entropy: 2.37938
Value Function Loss: 0.01443

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.57506

Collected Steps per Second: 23,259.76252
Overall Steps per Second: 10,962.84250

Timestep Collection Time: 2.15032
Timestep Consumption Time: 2.41200
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.56232

Cumulative Model Updates: 189,376
Cumulative Timesteps: 1,579,394,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1579394018...
Checkpoint 1579394018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.52019
Policy Entropy: 2.36597
Value Function Loss: 0.01459

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.53913
Value Function Update Magnitude: 0.56394

Collected Steps per Second: 22,673.13855
Overall Steps per Second: 10,683.74973

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.68000

Cumulative Model Updates: 189,382
Cumulative Timesteps: 1,579,444,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.06827
Policy Entropy: 2.36159
Value Function Loss: 0.01390

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.55984

Collected Steps per Second: 22,996.20075
Overall Steps per Second: 10,745.05849

Timestep Collection Time: 2.17427
Timestep Consumption Time: 2.47903
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.65330

Cumulative Model Updates: 189,388
Cumulative Timesteps: 1,579,494,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1579494018...
Checkpoint 1579494018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.20280
Policy Entropy: 2.33623
Value Function Loss: 0.01478

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 23,049.64220
Overall Steps per Second: 10,654.28001

Timestep Collection Time: 2.17027
Timestep Consumption Time: 2.52493
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.69520

Cumulative Model Updates: 189,394
Cumulative Timesteps: 1,579,544,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.55057
Policy Entropy: 2.32676
Value Function Loss: 0.01519

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.54659

Collected Steps per Second: 23,109.83357
Overall Steps per Second: 10,882.76459

Timestep Collection Time: 2.16471
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.59681

Cumulative Model Updates: 189,400
Cumulative Timesteps: 1,579,594,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1579594068...
Checkpoint 1579594068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.57205
Policy Entropy: 2.30439
Value Function Loss: 0.01576

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.55170

Collected Steps per Second: 22,934.59244
Overall Steps per Second: 11,010.68591

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.36169
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.54250

Cumulative Model Updates: 189,406
Cumulative Timesteps: 1,579,644,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.12187
Policy Entropy: 2.32676
Value Function Loss: 0.01455

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.16120
Policy Update Magnitude: 0.48987
Value Function Update Magnitude: 0.53531

Collected Steps per Second: 23,365.79428
Overall Steps per Second: 10,918.94850

Timestep Collection Time: 2.14125
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.58213

Cumulative Model Updates: 189,412
Cumulative Timesteps: 1,579,694,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1579694116...
Checkpoint 1579694116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.87874
Policy Entropy: 2.33669
Value Function Loss: 0.01382

Mean KL Divergence: 0.02926
SB3 Clip Fraction: 0.19211
Policy Update Magnitude: 0.49977
Value Function Update Magnitude: 0.51975

Collected Steps per Second: 23,152.42856
Overall Steps per Second: 10,698.23798

Timestep Collection Time: 2.16046
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.67554

Cumulative Model Updates: 189,418
Cumulative Timesteps: 1,579,744,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.93271
Policy Entropy: 2.34461
Value Function Loss: 0.01426

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.52955
Value Function Update Magnitude: 0.50740

Collected Steps per Second: 23,210.04553
Overall Steps per Second: 10,880.31000

Timestep Collection Time: 2.15519
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59748

Cumulative Model Updates: 189,424
Cumulative Timesteps: 1,579,794,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1579794158...
Checkpoint 1579794158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.62149
Policy Entropy: 2.34205
Value Function Loss: 0.01471

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.51655

Collected Steps per Second: 22,391.79096
Overall Steps per Second: 10,681.55667

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.68115

Cumulative Model Updates: 189,430
Cumulative Timesteps: 1,579,844,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.19373
Policy Entropy: 2.32631
Value Function Loss: 0.01600

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.54729

Collected Steps per Second: 22,851.03133
Overall Steps per Second: 10,943.71866

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.38217
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.57157

Cumulative Model Updates: 189,436
Cumulative Timesteps: 1,579,894,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1579894190...
Checkpoint 1579894190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.26564
Policy Entropy: 2.31197
Value Function Loss: 0.01606

Mean KL Divergence: 0.02527
SB3 Clip Fraction: 0.18105
Policy Update Magnitude: 0.53091
Value Function Update Magnitude: 0.57625

Collected Steps per Second: 22,324.49584
Overall Steps per Second: 10,584.86422

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.72580

Cumulative Model Updates: 189,442
Cumulative Timesteps: 1,579,944,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.23409
Policy Entropy: 2.31482
Value Function Loss: 0.01658

Mean KL Divergence: 0.02428
SB3 Clip Fraction: 0.17276
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.58404

Collected Steps per Second: 22,899.93293
Overall Steps per Second: 10,812.99188

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62555

Cumulative Model Updates: 189,448
Cumulative Timesteps: 1,579,994,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1579994228...
Checkpoint 1579994228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.19293
Policy Entropy: 2.32942
Value Function Loss: 0.01618

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.57712
Value Function Update Magnitude: 0.57557

Collected Steps per Second: 23,094.88983
Overall Steps per Second: 10,734.29540

Timestep Collection Time: 2.16507
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.65815

Cumulative Model Updates: 189,454
Cumulative Timesteps: 1,580,044,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.07205
Policy Entropy: 2.35137
Value Function Loss: 0.01488

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.56466

Collected Steps per Second: 23,072.62659
Overall Steps per Second: 10,902.29936

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.41931
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.58656

Cumulative Model Updates: 189,460
Cumulative Timesteps: 1,580,094,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1580094234...
Checkpoint 1580094234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.87369
Policy Entropy: 2.36115
Value Function Loss: 0.01451

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.56223

Collected Steps per Second: 23,230.87381
Overall Steps per Second: 11,106.35518

Timestep Collection Time: 2.15334
Timestep Consumption Time: 2.35075
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.50409

Cumulative Model Updates: 189,466
Cumulative Timesteps: 1,580,144,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.11730
Policy Entropy: 2.37187
Value Function Loss: 0.01347

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.55821

Collected Steps per Second: 22,539.72503
Overall Steps per Second: 10,949.77715

Timestep Collection Time: 2.21919
Timestep Consumption Time: 2.34894
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.56813

Cumulative Model Updates: 189,472
Cumulative Timesteps: 1,580,194,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1580194278...
Checkpoint 1580194278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.90466
Policy Entropy: 2.37158
Value Function Loss: 0.01390

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.55306

Collected Steps per Second: 23,214.86193
Overall Steps per Second: 10,817.02569

Timestep Collection Time: 2.15414
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.62308

Cumulative Model Updates: 189,478
Cumulative Timesteps: 1,580,244,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.55837
Policy Entropy: 2.34860
Value Function Loss: 0.01416

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.52669
Value Function Update Magnitude: 0.55525

Collected Steps per Second: 23,186.86201
Overall Steps per Second: 10,713.93688

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66962

Cumulative Model Updates: 189,484
Cumulative Timesteps: 1,580,294,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1580294316...
Checkpoint 1580294316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.94585
Policy Entropy: 2.34784
Value Function Loss: 0.01474

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.54732

Collected Steps per Second: 22,528.66387
Overall Steps per Second: 10,640.89098

Timestep Collection Time: 2.21948
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.69904

Cumulative Model Updates: 189,490
Cumulative Timesteps: 1,580,344,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.56182
Policy Entropy: 2.34871
Value Function Loss: 0.01534

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.53641

Collected Steps per Second: 22,582.75112
Overall Steps per Second: 10,938.68684

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.35742
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57203

Cumulative Model Updates: 189,496
Cumulative Timesteps: 1,580,394,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1580394330...
Checkpoint 1580394330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.21688
Policy Entropy: 2.35695
Value Function Loss: 0.01582

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 22,680.03417
Overall Steps per Second: 10,624.75818

Timestep Collection Time: 2.20467
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70618

Cumulative Model Updates: 189,502
Cumulative Timesteps: 1,580,444,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.99231
Policy Entropy: 2.34774
Value Function Loss: 0.01590

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 22,876.87158
Overall Steps per Second: 10,825.16131

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62016

Cumulative Model Updates: 189,508
Cumulative Timesteps: 1,580,494,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1580494346...
Checkpoint 1580494346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.57488
Policy Entropy: 2.34100
Value Function Loss: 0.01611

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 23,037.17096
Overall Steps per Second: 10,720.53568

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.49484
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.66637

Cumulative Model Updates: 189,514
Cumulative Timesteps: 1,580,544,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.04083
Policy Entropy: 2.33310
Value Function Loss: 0.01553

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.59324

Collected Steps per Second: 23,114.09921
Overall Steps per Second: 10,820.56031

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.45854
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.62250

Cumulative Model Updates: 189,520
Cumulative Timesteps: 1,580,594,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1580594390...
Checkpoint 1580594390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.14835
Policy Entropy: 2.33630
Value Function Loss: 0.01454

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.57043

Collected Steps per Second: 22,869.48230
Overall Steps per Second: 10,935.54690

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.38717
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.57462

Cumulative Model Updates: 189,526
Cumulative Timesteps: 1,580,644,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.91768
Policy Entropy: 2.34096
Value Function Loss: 0.01384

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.53245

Collected Steps per Second: 23,668.31414
Overall Steps per Second: 10,906.69635

Timestep Collection Time: 2.11253
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.58434

Cumulative Model Updates: 189,532
Cumulative Timesteps: 1,580,694,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1580694416...
Checkpoint 1580694416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.12388
Policy Entropy: 2.33734
Value Function Loss: 0.01419

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.51233

Collected Steps per Second: 23,306.41076
Overall Steps per Second: 10,890.02565

Timestep Collection Time: 2.14610
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.59301

Cumulative Model Updates: 189,538
Cumulative Timesteps: 1,580,744,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.80258
Policy Entropy: 2.33801
Value Function Loss: 0.01455

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.51015

Collected Steps per Second: 15,572.40835
Overall Steps per Second: 7,105.32738

Timestep Collection Time: 3.21222
Timestep Consumption Time: 3.82785
PPO Batch Consumption Time: 0.47047
Total Iteration Time: 7.04007

Cumulative Model Updates: 189,544
Cumulative Timesteps: 1,580,794,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1580794456...
Checkpoint 1580794456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.85305
Policy Entropy: 2.32206
Value Function Loss: 0.01457

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.52211

Collected Steps per Second: 14,110.43147
Overall Steps per Second: 8,074.36355

Timestep Collection Time: 3.54546
Timestep Consumption Time: 2.65044
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 6.19591

Cumulative Model Updates: 189,550
Cumulative Timesteps: 1,580,844,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.72433
Policy Entropy: 2.30965
Value Function Loss: 0.01551

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.52134

Collected Steps per Second: 21,861.42372
Overall Steps per Second: 10,776.98012

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.35398
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64267

Cumulative Model Updates: 189,556
Cumulative Timesteps: 1,580,894,518

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1580894518...
Checkpoint 1580894518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.98238
Policy Entropy: 2.28568
Value Function Loss: 0.01579

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.51864

Collected Steps per Second: 22,319.93272
Overall Steps per Second: 10,618.79429

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.71108

Cumulative Model Updates: 189,562
Cumulative Timesteps: 1,580,944,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.27407
Policy Entropy: 2.30052
Value Function Loss: 0.01637

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.52338

Collected Steps per Second: 22,557.02926
Overall Steps per Second: 10,546.66649

Timestep Collection Time: 2.21696
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74159

Cumulative Model Updates: 189,568
Cumulative Timesteps: 1,580,994,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1580994552...
Checkpoint 1580994552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.42380
Policy Entropy: 2.29255
Value Function Loss: 0.01610

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.56315
Value Function Update Magnitude: 0.57507

Collected Steps per Second: 22,837.48099
Overall Steps per Second: 10,665.56080

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68967

Cumulative Model Updates: 189,574
Cumulative Timesteps: 1,581,044,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.95950
Policy Entropy: 2.29178
Value Function Loss: 0.01588

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.60673

Collected Steps per Second: 22,811.93280
Overall Steps per Second: 10,829.39520

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.61928

Cumulative Model Updates: 189,580
Cumulative Timesteps: 1,581,094,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1581094594...
Checkpoint 1581094594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.52272
Policy Entropy: 2.26897
Value Function Loss: 0.01628

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,989.46115
Overall Steps per Second: 10,910.07778

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.58347

Cumulative Model Updates: 189,586
Cumulative Timesteps: 1,581,144,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.64617
Policy Entropy: 2.24716
Value Function Loss: 0.01647

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 23,044.93440
Overall Steps per Second: 10,697.88115

Timestep Collection Time: 2.17046
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.67551

Cumulative Model Updates: 189,592
Cumulative Timesteps: 1,581,194,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1581194618...
Checkpoint 1581194618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.28216
Policy Entropy: 2.24471
Value Function Loss: 0.01653

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 22,890.39556
Overall Steps per Second: 10,636.27761

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.70183

Cumulative Model Updates: 189,598
Cumulative Timesteps: 1,581,244,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.87567
Policy Entropy: 2.26372
Value Function Loss: 0.01516

Mean KL Divergence: 0.02782
SB3 Clip Fraction: 0.18654
Policy Update Magnitude: 0.51496
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 22,746.86730
Overall Steps per Second: 10,671.82203

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68617

Cumulative Model Updates: 189,604
Cumulative Timesteps: 1,581,294,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1581294638...
Checkpoint 1581294638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.93915
Policy Entropy: 2.29350
Value Function Loss: 0.01473

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.53713

Collected Steps per Second: 22,836.07609
Overall Steps per Second: 10,922.44136

Timestep Collection Time: 2.19004
Timestep Consumption Time: 2.38879
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.57883

Cumulative Model Updates: 189,610
Cumulative Timesteps: 1,581,344,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.56127
Policy Entropy: 2.30860
Value Function Loss: 0.01468

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.53057

Collected Steps per Second: 23,159.94007
Overall Steps per Second: 10,858.02146

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.60544

Cumulative Model Updates: 189,616
Cumulative Timesteps: 1,581,394,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1581394656...
Checkpoint 1581394656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.66303
Policy Entropy: 2.30216
Value Function Loss: 0.01558

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.54576

Collected Steps per Second: 22,677.46148
Overall Steps per Second: 10,640.67249

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.69952

Cumulative Model Updates: 189,622
Cumulative Timesteps: 1,581,444,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.19490
Policy Entropy: 2.29900
Value Function Loss: 0.01530

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.54892

Collected Steps per Second: 22,654.55259
Overall Steps per Second: 10,646.52000

Timestep Collection Time: 2.20759
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.69750

Cumulative Model Updates: 189,628
Cumulative Timesteps: 1,581,494,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1581494674...
Checkpoint 1581494674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.05812
Policy Entropy: 2.29877
Value Function Loss: 0.01644

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.55706

Collected Steps per Second: 22,525.30077
Overall Steps per Second: 10,634.51568

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70318

Cumulative Model Updates: 189,634
Cumulative Timesteps: 1,581,544,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.07574
Policy Entropy: 2.30522
Value Function Loss: 0.01601

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.56762
Value Function Update Magnitude: 0.57537

Collected Steps per Second: 22,633.21107
Overall Steps per Second: 10,720.24724

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.45581
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.66575

Cumulative Model Updates: 189,640
Cumulative Timesteps: 1,581,594,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1581594708...
Checkpoint 1581594708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.28754
Policy Entropy: 2.31271
Value Function Loss: 0.01516

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.56620

Collected Steps per Second: 22,704.60955
Overall Steps per Second: 10,856.54620

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.40399
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.60681

Cumulative Model Updates: 189,646
Cumulative Timesteps: 1,581,644,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.07317
Policy Entropy: 2.31890
Value Function Loss: 0.01542

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.55412

Collected Steps per Second: 23,068.63283
Overall Steps per Second: 10,709.67831

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.66942

Cumulative Model Updates: 189,652
Cumulative Timesteps: 1,581,694,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1581694730...
Checkpoint 1581694730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.43930
Policy Entropy: 2.33544
Value Function Loss: 0.01497

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 22,837.47995
Overall Steps per Second: 10,636.28992

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.51241
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.70258

Cumulative Model Updates: 189,658
Cumulative Timesteps: 1,581,744,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.63344
Policy Entropy: 2.34031
Value Function Loss: 0.01635

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.55605

Collected Steps per Second: 22,860.71654
Overall Steps per Second: 10,861.03301

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.41675
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.60417

Cumulative Model Updates: 189,664
Cumulative Timesteps: 1,581,794,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1581794754...
Checkpoint 1581794754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.92448
Policy Entropy: 2.32080
Value Function Loss: 0.01645

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,366.77933
Overall Steps per Second: 10,720.69907

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.66705

Cumulative Model Updates: 189,670
Cumulative Timesteps: 1,581,844,788

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.11229
Policy Entropy: 2.30874
Value Function Loss: 0.01630

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.16715
Policy Update Magnitude: 0.53650
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 22,909.83785
Overall Steps per Second: 10,810.98342

Timestep Collection Time: 2.18413
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.62844

Cumulative Model Updates: 189,676
Cumulative Timesteps: 1,581,894,826

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1581894826...
Checkpoint 1581894826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.54009
Policy Entropy: 2.31264
Value Function Loss: 0.01651

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.61396

Collected Steps per Second: 22,615.15650
Overall Steps per Second: 10,695.77826

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.67549

Cumulative Model Updates: 189,682
Cumulative Timesteps: 1,581,944,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.69733
Policy Entropy: 2.31975
Value Function Loss: 0.01606

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.55653
Value Function Update Magnitude: 0.61248

Collected Steps per Second: 23,037.01695
Overall Steps per Second: 10,889.65527

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.59372

Cumulative Model Updates: 189,688
Cumulative Timesteps: 1,581,994,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1581994858...
Checkpoint 1581994858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.54851
Policy Entropy: 2.27445
Value Function Loss: 0.01753

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.58449
Value Function Update Magnitude: 0.60198

Collected Steps per Second: 22,692.70461
Overall Steps per Second: 10,606.25101

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.71646

Cumulative Model Updates: 189,694
Cumulative Timesteps: 1,582,044,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.67993
Policy Entropy: 2.26601
Value Function Loss: 0.01738

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.59677
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,799.73529
Overall Steps per Second: 10,985.21340

Timestep Collection Time: 2.19380
Timestep Consumption Time: 2.35941
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.55321

Cumulative Model Updates: 189,700
Cumulative Timesteps: 1,582,094,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1582094900...
Checkpoint 1582094900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.70350
Policy Entropy: 2.26342
Value Function Loss: 0.01684

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.59104
Value Function Update Magnitude: 0.60209

Collected Steps per Second: 23,128.66790
Overall Steps per Second: 10,529.47575

Timestep Collection Time: 2.16364
Timestep Consumption Time: 2.58893
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 4.75256

Cumulative Model Updates: 189,706
Cumulative Timesteps: 1,582,144,942

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.68428
Policy Entropy: 2.29840
Value Function Loss: 0.01597

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.57767
Value Function Update Magnitude: 0.57433

Collected Steps per Second: 23,040.74420
Overall Steps per Second: 10,576.45777

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.55762
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.72786

Cumulative Model Updates: 189,712
Cumulative Timesteps: 1,582,194,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1582194946...
Checkpoint 1582194946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.64827
Policy Entropy: 2.29486
Value Function Loss: 0.01570

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.55598

Collected Steps per Second: 22,839.09100
Overall Steps per Second: 10,597.97953

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.52926
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.71901

Cumulative Model Updates: 189,718
Cumulative Timesteps: 1,582,244,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.29122
Policy Entropy: 2.28426
Value Function Loss: 0.01601

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.55394

Collected Steps per Second: 22,516.82863
Overall Steps per Second: 10,662.51283

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.68951

Cumulative Model Updates: 189,724
Cumulative Timesteps: 1,582,294,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1582294960...
Checkpoint 1582294960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.05435
Policy Entropy: 2.30338
Value Function Loss: 0.01560

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.58370

Collected Steps per Second: 22,942.02373
Overall Steps per Second: 10,861.13519

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.60504

Cumulative Model Updates: 189,730
Cumulative Timesteps: 1,582,344,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.24422
Policy Entropy: 2.29592
Value Function Loss: 0.01640

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 22,752.81277
Overall Steps per Second: 10,936.53766

Timestep Collection Time: 2.19762
Timestep Consumption Time: 2.37440
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.57201

Cumulative Model Updates: 189,736
Cumulative Timesteps: 1,582,394,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1582394978...
Checkpoint 1582394978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.54405
Policy Entropy: 2.31410
Value Function Loss: 0.01604

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 22,885.13334
Overall Steps per Second: 10,642.99143

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.69793

Cumulative Model Updates: 189,742
Cumulative Timesteps: 1,582,444,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.44570
Policy Entropy: 2.28039
Value Function Loss: 0.01629

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 22,299.24504
Overall Steps per Second: 10,465.27976

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.53618
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.77904

Cumulative Model Updates: 189,748
Cumulative Timesteps: 1,582,494,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1582494992...
Checkpoint 1582494992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.82616
Policy Entropy: 2.26327
Value Function Loss: 0.01581

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.55616

Collected Steps per Second: 22,838.86905
Overall Steps per Second: 10,668.66243

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.68887

Cumulative Model Updates: 189,754
Cumulative Timesteps: 1,582,545,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.02441
Policy Entropy: 2.25501
Value Function Loss: 0.01549

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.56557

Collected Steps per Second: 23,216.95033
Overall Steps per Second: 10,909.32765

Timestep Collection Time: 2.15369
Timestep Consumption Time: 2.42973
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.58342

Cumulative Model Updates: 189,760
Cumulative Timesteps: 1,582,595,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1582595018...
Checkpoint 1582595018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.19223
Policy Entropy: 2.25270
Value Function Loss: 0.01490

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 22,951.46349
Overall Steps per Second: 10,670.91017

Timestep Collection Time: 2.17912
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.68695

Cumulative Model Updates: 189,766
Cumulative Timesteps: 1,582,645,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.28444
Policy Entropy: 2.27019
Value Function Loss: 0.01500

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.56262
Value Function Update Magnitude: 0.54958

Collected Steps per Second: 22,868.77233
Overall Steps per Second: 10,804.01416

Timestep Collection Time: 2.18735
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.62995

Cumulative Model Updates: 189,772
Cumulative Timesteps: 1,582,695,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1582695054...
Checkpoint 1582695054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.55756
Policy Entropy: 2.26386
Value Function Loss: 0.01545

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.56878
Value Function Update Magnitude: 0.57501

Collected Steps per Second: 22,806.52872
Overall Steps per Second: 10,727.06024

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66372

Cumulative Model Updates: 189,778
Cumulative Timesteps: 1,582,745,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.65473
Policy Entropy: 2.28641
Value Function Loss: 0.01524

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.58859

Collected Steps per Second: 22,644.46077
Overall Steps per Second: 10,784.57131

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.63699

Cumulative Model Updates: 189,784
Cumulative Timesteps: 1,582,795,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1582795090...
Checkpoint 1582795090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.78925
Policy Entropy: 2.28859
Value Function Loss: 0.01591

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.57413

Collected Steps per Second: 22,490.18393
Overall Steps per Second: 10,620.18216

Timestep Collection Time: 2.22373
Timestep Consumption Time: 2.48542
PPO Batch Consumption Time: 0.30349
Total Iteration Time: 4.70915

Cumulative Model Updates: 189,790
Cumulative Timesteps: 1,582,845,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.52597
Policy Entropy: 2.27066
Value Function Loss: 0.01630

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.56567

Collected Steps per Second: 22,772.47899
Overall Steps per Second: 10,625.57810

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.70845

Cumulative Model Updates: 189,796
Cumulative Timesteps: 1,582,895,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1582895132...
Checkpoint 1582895132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.49874
Policy Entropy: 2.26500
Value Function Loss: 0.01603

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.57375

Collected Steps per Second: 22,957.55249
Overall Steps per Second: 10,678.99739

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68302

Cumulative Model Updates: 189,802
Cumulative Timesteps: 1,582,945,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.79486
Policy Entropy: 2.26925
Value Function Loss: 0.01578

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 22,934.97923
Overall Steps per Second: 10,806.45896

Timestep Collection Time: 2.18016
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.62705

Cumulative Model Updates: 189,808
Cumulative Timesteps: 1,582,995,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1582995144...
Checkpoint 1582995144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.53048
Policy Entropy: 2.28221
Value Function Loss: 0.01613

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.15938
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.59924

Collected Steps per Second: 22,753.84919
Overall Steps per Second: 10,844.40108

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.61086

Cumulative Model Updates: 189,814
Cumulative Timesteps: 1,583,045,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.77214
Policy Entropy: 2.27475
Value Function Loss: 0.01639

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.59346

Collected Steps per Second: 23,006.86925
Overall Steps per Second: 10,747.25606

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.65254

Cumulative Model Updates: 189,820
Cumulative Timesteps: 1,583,095,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1583095148...
Checkpoint 1583095148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.67489
Policy Entropy: 2.26670
Value Function Loss: 0.01635

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.57150
Value Function Update Magnitude: 0.62647

Collected Steps per Second: 22,439.24156
Overall Steps per Second: 10,639.43606

Timestep Collection Time: 2.22913
Timestep Consumption Time: 2.47225
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.70138

Cumulative Model Updates: 189,826
Cumulative Timesteps: 1,583,145,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.56947
Policy Entropy: 2.28901
Value Function Loss: 0.01643

Mean KL Divergence: 0.02935
SB3 Clip Fraction: 0.19650
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.64640

Collected Steps per Second: 22,812.48848
Overall Steps per Second: 10,656.32970

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.69223

Cumulative Model Updates: 189,832
Cumulative Timesteps: 1,583,195,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1583195170...
Checkpoint 1583195170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.11903
Policy Entropy: 2.31376
Value Function Loss: 0.01635

Mean KL Divergence: 0.04914
SB3 Clip Fraction: 0.24368
Policy Update Magnitude: 0.50430
Value Function Update Magnitude: 0.66515

Collected Steps per Second: 22,976.60313
Overall Steps per Second: 10,903.23423

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.41005
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.58653

Cumulative Model Updates: 189,838
Cumulative Timesteps: 1,583,245,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.80468
Policy Entropy: 2.32749
Value Function Loss: 0.01651

Mean KL Divergence: 0.04519
SB3 Clip Fraction: 0.23250
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,684.83812
Overall Steps per Second: 10,810.18349

Timestep Collection Time: 2.20500
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62712

Cumulative Model Updates: 189,844
Cumulative Timesteps: 1,583,295,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1583295198...
Checkpoint 1583295198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.13863
Policy Entropy: 2.29884
Value Function Loss: 0.01742

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.63411

Collected Steps per Second: 22,564.37645
Overall Steps per Second: 10,718.18483

Timestep Collection Time: 2.21615
Timestep Consumption Time: 2.44938
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.66553

Cumulative Model Updates: 189,850
Cumulative Timesteps: 1,583,345,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.07480
Policy Entropy: 2.28744
Value Function Loss: 0.01668

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.18060
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.61540

Collected Steps per Second: 22,964.09381
Overall Steps per Second: 10,816.80833

Timestep Collection Time: 2.17766
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.62318

Cumulative Model Updates: 189,856
Cumulative Timesteps: 1,583,395,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1583395212...
Checkpoint 1583395212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.07852
Policy Entropy: 2.27806
Value Function Loss: 0.01537

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16313
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.58291

Collected Steps per Second: 22,576.29475
Overall Steps per Second: 10,747.41644

Timestep Collection Time: 2.21551
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.65396

Cumulative Model Updates: 189,862
Cumulative Timesteps: 1,583,445,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.91237
Policy Entropy: 2.29293
Value Function Loss: 0.01508

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.55289

Collected Steps per Second: 22,512.69479
Overall Steps per Second: 10,524.39474

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.53010
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.75125

Cumulative Model Updates: 189,868
Cumulative Timesteps: 1,583,495,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1583495234...
Checkpoint 1583495234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.38826
Policy Entropy: 2.27918
Value Function Loss: 0.01565

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 22,352.71705
Overall Steps per Second: 10,605.76842

Timestep Collection Time: 2.23874
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.71838

Cumulative Model Updates: 189,874
Cumulative Timesteps: 1,583,545,276

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.82226
Policy Entropy: 2.29114
Value Function Loss: 0.01599

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.57301

Collected Steps per Second: 22,685.37181
Overall Steps per Second: 10,832.54617

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.41166
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.61572

Cumulative Model Updates: 189,880
Cumulative Timesteps: 1,583,595,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1583595276...
Checkpoint 1583595276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.71258
Policy Entropy: 2.30835
Value Function Loss: 0.01592

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.57892

Collected Steps per Second: 22,930.52620
Overall Steps per Second: 10,639.28657

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.51927
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69994

Cumulative Model Updates: 189,886
Cumulative Timesteps: 1,583,645,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.33866
Policy Entropy: 2.32742
Value Function Loss: 0.01571

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.60349
Value Function Update Magnitude: 0.57491

Collected Steps per Second: 22,917.09710
Overall Steps per Second: 10,697.56582

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67527

Cumulative Model Updates: 189,892
Cumulative Timesteps: 1,583,695,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1583695294...
Checkpoint 1583695294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.62583
Policy Entropy: 2.32022
Value Function Loss: 0.01617

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.58498
Value Function Update Magnitude: 0.58355

Collected Steps per Second: 23,022.83359
Overall Steps per Second: 10,838.40715

Timestep Collection Time: 2.17176
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.61322

Cumulative Model Updates: 189,898
Cumulative Timesteps: 1,583,745,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.82612
Policy Entropy: 2.31664
Value Function Loss: 0.01587

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.58166

Collected Steps per Second: 22,971.33845
Overall Steps per Second: 10,873.49158

Timestep Collection Time: 2.17776
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.60073

Cumulative Model Updates: 189,904
Cumulative Timesteps: 1,583,795,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1583795320...
Checkpoint 1583795320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.72290
Policy Entropy: 2.32397
Value Function Loss: 0.01548

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.55799
Value Function Update Magnitude: 0.56838

Collected Steps per Second: 22,688.52287
Overall Steps per Second: 10,704.99658

Timestep Collection Time: 2.20587
Timestep Consumption Time: 2.46933
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67520

Cumulative Model Updates: 189,910
Cumulative Timesteps: 1,583,845,368

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.01348
Policy Entropy: 2.33317
Value Function Loss: 0.01562

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 22,915.90846
Overall Steps per Second: 10,907.76704

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.58517

Cumulative Model Updates: 189,916
Cumulative Timesteps: 1,583,895,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1583895382...
Checkpoint 1583895382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.10296
Policy Entropy: 2.34597
Value Function Loss: 0.01558

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.58988

Collected Steps per Second: 22,666.40686
Overall Steps per Second: 10,650.01885

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69671

Cumulative Model Updates: 189,922
Cumulative Timesteps: 1,583,945,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.32911
Policy Entropy: 2.33440
Value Function Loss: 0.01584

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.56252
Value Function Update Magnitude: 0.60475

Collected Steps per Second: 21,982.86787
Overall Steps per Second: 10,483.37564

Timestep Collection Time: 2.27495
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.77041

Cumulative Model Updates: 189,928
Cumulative Timesteps: 1,583,995,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1583995412...
Checkpoint 1583995412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.01356
Policy Entropy: 2.34217
Value Function Loss: 0.01473

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.58557

Collected Steps per Second: 22,827.05208
Overall Steps per Second: 10,595.53782

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.72048

Cumulative Model Updates: 189,934
Cumulative Timesteps: 1,584,045,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.57452
Policy Entropy: 2.35267
Value Function Loss: 0.01549

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.55155

Collected Steps per Second: 22,185.21138
Overall Steps per Second: 10,519.01151

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.75482

Cumulative Model Updates: 189,940
Cumulative Timesteps: 1,584,095,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1584095444...
Checkpoint 1584095444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.64375
Policy Entropy: 2.35690
Value Function Loss: 0.01505

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.52489

Collected Steps per Second: 22,595.93897
Overall Steps per Second: 10,640.63066

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.69897

Cumulative Model Updates: 189,946
Cumulative Timesteps: 1,584,145,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.17241
Policy Entropy: 2.36110
Value Function Loss: 0.01464

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.52230

Collected Steps per Second: 22,844.15116
Overall Steps per Second: 10,886.59720

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.40531
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.59519

Cumulative Model Updates: 189,952
Cumulative Timesteps: 1,584,195,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1584195470...
Checkpoint 1584195470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.32985
Policy Entropy: 2.33395
Value Function Loss: 0.01463

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,863.46479
Overall Steps per Second: 10,638.33746

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70261

Cumulative Model Updates: 189,958
Cumulative Timesteps: 1,584,245,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.68072
Policy Entropy: 2.35442
Value Function Loss: 0.01513

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.55792

Collected Steps per Second: 23,145.34222
Overall Steps per Second: 10,868.24706

Timestep Collection Time: 2.16061
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60129

Cumulative Model Updates: 189,964
Cumulative Timesteps: 1,584,295,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1584295506...
Checkpoint 1584295506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 637.16213
Policy Entropy: 2.34984
Value Function Loss: 0.01560

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.57699

Collected Steps per Second: 22,742.38805
Overall Steps per Second: 10,696.64905

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.67567

Cumulative Model Updates: 189,970
Cumulative Timesteps: 1,584,345,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.22209
Policy Entropy: 2.35971
Value Function Loss: 0.01480

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 22,440.33935
Overall Steps per Second: 10,645.29095

Timestep Collection Time: 2.22884
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69842

Cumulative Model Updates: 189,976
Cumulative Timesteps: 1,584,395,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1584395536...
Checkpoint 1584395536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.83010
Policy Entropy: 2.33010
Value Function Loss: 0.01413

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.54829

Collected Steps per Second: 22,977.76365
Overall Steps per Second: 10,853.81186

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60889

Cumulative Model Updates: 189,982
Cumulative Timesteps: 1,584,445,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.18574
Policy Entropy: 2.33573
Value Function Loss: 0.01369

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.55546

Collected Steps per Second: 23,012.39861
Overall Steps per Second: 10,971.32454

Timestep Collection Time: 2.17378
Timestep Consumption Time: 2.38574
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.55952

Cumulative Model Updates: 189,988
Cumulative Timesteps: 1,584,495,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1584495584...
Checkpoint 1584495584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.08489
Policy Entropy: 2.34462
Value Function Loss: 0.01447

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.55887

Collected Steps per Second: 22,749.72951
Overall Steps per Second: 10,628.04240

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.70698

Cumulative Model Updates: 189,994
Cumulative Timesteps: 1,584,545,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.81087
Policy Entropy: 2.35663
Value Function Loss: 0.01475

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.55064

Collected Steps per Second: 23,016.31532
Overall Steps per Second: 10,675.72462

Timestep Collection Time: 2.17315
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.68521

Cumulative Model Updates: 190,000
Cumulative Timesteps: 1,584,595,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1584595628...
Checkpoint 1584595628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.31003
Policy Entropy: 2.32000
Value Function Loss: 0.01478

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.54469

Collected Steps per Second: 22,852.34667
Overall Steps per Second: 10,687.13502

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.68152

Cumulative Model Updates: 190,006
Cumulative Timesteps: 1,584,645,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.43703
Policy Entropy: 2.30161
Value Function Loss: 0.01454

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.53822

Collected Steps per Second: 23,256.80205
Overall Steps per Second: 10,863.23575

Timestep Collection Time: 2.15120
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.60544

Cumulative Model Updates: 190,012
Cumulative Timesteps: 1,584,695,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1584695690...
Checkpoint 1584695690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.34027
Policy Entropy: 2.27531
Value Function Loss: 0.01559

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.55753
Value Function Update Magnitude: 0.54897

Collected Steps per Second: 22,588.16415
Overall Steps per Second: 10,884.75176

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.38108
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.59560

Cumulative Model Updates: 190,018
Cumulative Timesteps: 1,584,745,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.13990
Policy Entropy: 2.29078
Value Function Loss: 0.01463

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.55668

Collected Steps per Second: 23,133.59392
Overall Steps per Second: 10,865.08541

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.60447

Cumulative Model Updates: 190,024
Cumulative Timesteps: 1,584,795,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1584795740...
Checkpoint 1584795740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.54950
Policy Entropy: 2.28878
Value Function Loss: 0.01553

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 22,796.51499
Overall Steps per Second: 10,668.06087

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68914

Cumulative Model Updates: 190,030
Cumulative Timesteps: 1,584,845,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.56642
Policy Entropy: 2.31654
Value Function Loss: 0.01592

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.55335

Collected Steps per Second: 23,031.44712
Overall Steps per Second: 10,843.79026

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61296

Cumulative Model Updates: 190,036
Cumulative Timesteps: 1,584,895,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1584895786...
Checkpoint 1584895786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.15565
Policy Entropy: 2.32604
Value Function Loss: 0.01619

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.56117

Collected Steps per Second: 22,673.27471
Overall Steps per Second: 10,726.28069

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.66424

Cumulative Model Updates: 190,042
Cumulative Timesteps: 1,584,945,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.54782
Policy Entropy: 2.31631
Value Function Loss: 0.01609

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.55735

Collected Steps per Second: 22,912.88636
Overall Steps per Second: 10,838.64938

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.61386

Cumulative Model Updates: 190,048
Cumulative Timesteps: 1,584,995,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1584995824...
Checkpoint 1584995824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.84412
Policy Entropy: 2.31160
Value Function Loss: 0.01472

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.53763

Collected Steps per Second: 23,536.36080
Overall Steps per Second: 10,820.49235

Timestep Collection Time: 2.12505
Timestep Consumption Time: 2.49729
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.62234

Cumulative Model Updates: 190,054
Cumulative Timesteps: 1,585,045,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.31922
Policy Entropy: 2.32200
Value Function Loss: 0.01504

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.53798

Collected Steps per Second: 23,270.55627
Overall Steps per Second: 10,777.85278

Timestep Collection Time: 2.14933
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.64063

Cumulative Model Updates: 190,060
Cumulative Timesteps: 1,585,095,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1585095856...
Checkpoint 1585095856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.60650
Policy Entropy: 2.32044
Value Function Loss: 0.01548

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.53613

Collected Steps per Second: 22,963.44502
Overall Steps per Second: 10,672.59201

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.50843
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.68658

Cumulative Model Updates: 190,066
Cumulative Timesteps: 1,585,145,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.20149
Policy Entropy: 2.32389
Value Function Loss: 0.01650

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.53106

Collected Steps per Second: 22,937.48851
Overall Steps per Second: 10,776.90309

Timestep Collection Time: 2.18123
Timestep Consumption Time: 2.46129
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.64252

Cumulative Model Updates: 190,072
Cumulative Timesteps: 1,585,195,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1585195906...
Checkpoint 1585195906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.17877
Policy Entropy: 2.32273
Value Function Loss: 0.01606

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.56574
Value Function Update Magnitude: 0.54206

Collected Steps per Second: 21,724.28756
Overall Steps per Second: 10,667.20364

Timestep Collection Time: 2.30194
Timestep Consumption Time: 2.38607
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.68801

Cumulative Model Updates: 190,078
Cumulative Timesteps: 1,585,245,914

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.91047
Policy Entropy: 2.36125
Value Function Loss: 0.01467

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.54611
Value Function Update Magnitude: 0.53866

Collected Steps per Second: 22,938.28354
Overall Steps per Second: 10,679.93319

Timestep Collection Time: 2.18116
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.68467

Cumulative Model Updates: 190,084
Cumulative Timesteps: 1,585,295,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1585295946...
Checkpoint 1585295946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.92450
Policy Entropy: 2.35241
Value Function Loss: 0.01409

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.51994

Collected Steps per Second: 22,852.49034
Overall Steps per Second: 10,696.14276

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.67720

Cumulative Model Updates: 190,090
Cumulative Timesteps: 1,585,345,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.13895
Policy Entropy: 2.35368
Value Function Loss: 0.01429

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.53630
Value Function Update Magnitude: 0.49852

Collected Steps per Second: 22,543.43003
Overall Steps per Second: 10,741.85507

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.65469

Cumulative Model Updates: 190,096
Cumulative Timesteps: 1,585,395,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1585395974...
Checkpoint 1585395974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.23798
Policy Entropy: 2.32291
Value Function Loss: 0.01557

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.52137

Collected Steps per Second: 22,098.42346
Overall Steps per Second: 10,651.35622

Timestep Collection Time: 2.26378
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.69668

Cumulative Model Updates: 190,102
Cumulative Timesteps: 1,585,446,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.32893
Policy Entropy: 2.31854
Value Function Loss: 0.01588

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.56907
Value Function Update Magnitude: 0.55952

Collected Steps per Second: 22,985.88503
Overall Steps per Second: 10,904.75647

Timestep Collection Time: 2.17629
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.58736

Cumulative Model Updates: 190,108
Cumulative Timesteps: 1,585,496,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1585496024...
Checkpoint 1585496024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.36437
Policy Entropy: 2.34117
Value Function Loss: 0.01612

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.57467

Collected Steps per Second: 22,613.14687
Overall Steps per Second: 10,670.62614

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.68857

Cumulative Model Updates: 190,114
Cumulative Timesteps: 1,585,546,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.68994
Policy Entropy: 2.35846
Value Function Loss: 0.01586

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.56274

Collected Steps per Second: 23,137.43081
Overall Steps per Second: 10,840.78064

Timestep Collection Time: 2.16161
Timestep Consumption Time: 2.45190
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.61351

Cumulative Model Updates: 190,120
Cumulative Timesteps: 1,585,596,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1585596068...
Checkpoint 1585596068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.56649
Policy Entropy: 2.37766
Value Function Loss: 0.01606

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.55429

Collected Steps per Second: 22,619.90908
Overall Steps per Second: 10,652.94923

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.69429

Cumulative Model Updates: 190,126
Cumulative Timesteps: 1,585,646,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.68070
Policy Entropy: 2.36356
Value Function Loss: 0.01550

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.55143

Collected Steps per Second: 23,091.48698
Overall Steps per Second: 10,852.22070

Timestep Collection Time: 2.16573
Timestep Consumption Time: 2.44254
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.60827

Cumulative Model Updates: 190,132
Cumulative Timesteps: 1,585,696,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1585696086...
Checkpoint 1585696086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.39662
Policy Entropy: 2.34237
Value Function Loss: 0.01534

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.55365

Collected Steps per Second: 22,825.60240
Overall Steps per Second: 10,845.49737

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.61205

Cumulative Model Updates: 190,138
Cumulative Timesteps: 1,585,746,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.14734
Policy Entropy: 2.34024
Value Function Loss: 0.01441

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.56207
Value Function Update Magnitude: 0.54628

Collected Steps per Second: 23,188.90452
Overall Steps per Second: 10,759.88679

Timestep Collection Time: 2.15741
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.64949

Cumulative Model Updates: 190,144
Cumulative Timesteps: 1,585,796,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1585796134...
Checkpoint 1585796134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.36211
Policy Entropy: 2.32155
Value Function Loss: 0.01433

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.53205

Collected Steps per Second: 22,672.65052
Overall Steps per Second: 10,667.52265

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.48292
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68919

Cumulative Model Updates: 190,150
Cumulative Timesteps: 1,585,846,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.10824
Policy Entropy: 2.31480
Value Function Loss: 0.01579

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.55890
Value Function Update Magnitude: 0.54640

Collected Steps per Second: 23,146.82733
Overall Steps per Second: 10,655.48669

Timestep Collection Time: 2.16090
Timestep Consumption Time: 2.53321
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.69411

Cumulative Model Updates: 190,156
Cumulative Timesteps: 1,585,896,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1585896174...
Checkpoint 1585896174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.02666
Policy Entropy: 2.33976
Value Function Loss: 0.01449

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.55792
Value Function Update Magnitude: 0.57766

Collected Steps per Second: 22,880.95558
Overall Steps per Second: 10,792.34377

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.63458

Cumulative Model Updates: 190,162
Cumulative Timesteps: 1,585,946,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.74623
Policy Entropy: 2.33833
Value Function Loss: 0.01455

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.58689

Collected Steps per Second: 23,082.31565
Overall Steps per Second: 11,000.51532

Timestep Collection Time: 2.16694
Timestep Consumption Time: 2.37994
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.54688

Cumulative Model Updates: 190,168
Cumulative Timesteps: 1,585,996,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1585996210...
Checkpoint 1585996210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.80044
Policy Entropy: 2.33403
Value Function Loss: 0.01445

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 22,796.80478
Overall Steps per Second: 10,656.67755

Timestep Collection Time: 2.19461
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.69471

Cumulative Model Updates: 190,174
Cumulative Timesteps: 1,586,046,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.26934
Policy Entropy: 2.28436
Value Function Loss: 0.01646

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 23,391.24849
Overall Steps per Second: 10,941.78770

Timestep Collection Time: 2.13866
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.57201

Cumulative Model Updates: 190,180
Cumulative Timesteps: 1,586,096,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1586096266...
Checkpoint 1586096266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.57250
Policy Entropy: 2.29285
Value Function Loss: 0.01656

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.17272
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.57648

Collected Steps per Second: 22,735.35669
Overall Steps per Second: 10,658.48448

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.69260

Cumulative Model Updates: 190,186
Cumulative Timesteps: 1,586,146,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.89247
Policy Entropy: 2.31435
Value Function Loss: 0.01596

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.56864

Collected Steps per Second: 22,985.37042
Overall Steps per Second: 10,874.06244

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.59994

Cumulative Model Updates: 190,192
Cumulative Timesteps: 1,586,196,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1586196302...
Checkpoint 1586196302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.48097
Policy Entropy: 2.33506
Value Function Loss: 0.01566

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.53288
Value Function Update Magnitude: 0.57932

Collected Steps per Second: 22,610.18918
Overall Steps per Second: 10,775.45109

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.64092

Cumulative Model Updates: 190,198
Cumulative Timesteps: 1,586,246,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.13062
Policy Entropy: 2.33714
Value Function Loss: 0.01476

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.17150
Policy Update Magnitude: 0.55610
Value Function Update Magnitude: 0.59564

Collected Steps per Second: 23,047.75996
Overall Steps per Second: 10,793.34333

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.46318
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.63267

Cumulative Model Updates: 190,204
Cumulative Timesteps: 1,586,296,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1586296312...
Checkpoint 1586296312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.39280
Policy Entropy: 2.32425
Value Function Loss: 0.01549

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.15875
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.58808

Collected Steps per Second: 22,636.92472
Overall Steps per Second: 10,633.00368

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.70347

Cumulative Model Updates: 190,210
Cumulative Timesteps: 1,586,346,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.99440
Policy Entropy: 2.30448
Value Function Loss: 0.01619

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 23,045.36545
Overall Steps per Second: 10,815.26291

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.62605

Cumulative Model Updates: 190,216
Cumulative Timesteps: 1,586,396,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1586396356...
Checkpoint 1586396356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.30247
Policy Entropy: 2.30616
Value Function Loss: 0.01650

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.58072
Value Function Update Magnitude: 0.61793

Collected Steps per Second: 22,587.30886
Overall Steps per Second: 10,697.99842

Timestep Collection Time: 2.21469
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.67601

Cumulative Model Updates: 190,222
Cumulative Timesteps: 1,586,446,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.33756
Policy Entropy: 2.30237
Value Function Loss: 0.01643

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 22,946.38778
Overall Steps per Second: 10,871.18668

Timestep Collection Time: 2.17899
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.59931

Cumulative Model Updates: 190,228
Cumulative Timesteps: 1,586,496,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1586496380...
Checkpoint 1586496380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.17366
Policy Entropy: 2.30346
Value Function Loss: 0.01691

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.58315
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 22,098.25351
Overall Steps per Second: 10,727.85362

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.39920
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.66282

Cumulative Model Updates: 190,234
Cumulative Timesteps: 1,586,546,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.88591
Policy Entropy: 2.30946
Value Function Loss: 0.01730

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.15813
Policy Update Magnitude: 0.58093
Value Function Update Magnitude: 0.60780

Collected Steps per Second: 22,721.64114
Overall Steps per Second: 10,597.47294

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.72094

Cumulative Model Updates: 190,240
Cumulative Timesteps: 1,586,596,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1586596432...
Checkpoint 1586596432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.37412
Policy Entropy: 2.32539
Value Function Loss: 0.01612

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.15609
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.62450

Collected Steps per Second: 22,570.26545
Overall Steps per Second: 10,592.94579

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.72277

Cumulative Model Updates: 190,246
Cumulative Timesteps: 1,586,646,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.64708
Policy Entropy: 2.34230
Value Function Loss: 0.01418

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.60267

Collected Steps per Second: 23,203.61841
Overall Steps per Second: 10,831.28991

Timestep Collection Time: 2.15527
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.61718

Cumulative Model Updates: 190,252
Cumulative Timesteps: 1,586,696,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1586696470...
Checkpoint 1586696470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.56995
Policy Entropy: 2.34228
Value Function Loss: 0.01363

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 22,773.70005
Overall Steps per Second: 10,652.85651

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.69452

Cumulative Model Updates: 190,258
Cumulative Timesteps: 1,586,746,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.44490
Policy Entropy: 2.35237
Value Function Loss: 0.01423

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.58628

Collected Steps per Second: 23,183.25360
Overall Steps per Second: 10,878.26165

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.59871

Cumulative Model Updates: 190,264
Cumulative Timesteps: 1,586,796,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1586796506...
Checkpoint 1586796506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.38386
Policy Entropy: 2.35509
Value Function Loss: 0.01509

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.56292

Collected Steps per Second: 22,664.71899
Overall Steps per Second: 10,635.52287

Timestep Collection Time: 2.20748
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.70424

Cumulative Model Updates: 190,270
Cumulative Timesteps: 1,586,846,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.82574
Policy Entropy: 2.33806
Value Function Loss: 0.01593

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.55473
Value Function Update Magnitude: 0.55798

Collected Steps per Second: 22,805.12417
Overall Steps per Second: 10,674.81348

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.68692

Cumulative Model Updates: 190,276
Cumulative Timesteps: 1,586,896,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1586896570...
Checkpoint 1586896570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.95223
Policy Entropy: 2.33611
Value Function Loss: 0.01487

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 23,023.53686
Overall Steps per Second: 10,936.76725

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.40052
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.57265

Cumulative Model Updates: 190,282
Cumulative Timesteps: 1,586,946,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.36082
Policy Entropy: 2.33475
Value Function Loss: 0.01458

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.57392

Collected Steps per Second: 23,029.98259
Overall Steps per Second: 10,900.53759

Timestep Collection Time: 2.17160
Timestep Consumption Time: 2.41643
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.58803

Cumulative Model Updates: 190,288
Cumulative Timesteps: 1,586,996,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1586996592...
Checkpoint 1586996592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.36510
Policy Entropy: 2.33943
Value Function Loss: 0.01569

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.58574

Collected Steps per Second: 22,793.85699
Overall Steps per Second: 10,960.34434

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.36861
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.56245

Cumulative Model Updates: 190,294
Cumulative Timesteps: 1,587,046,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.53864
Policy Entropy: 2.32932
Value Function Loss: 0.01629

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.61053

Collected Steps per Second: 23,036.18100
Overall Steps per Second: 10,733.98695

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.65941

Cumulative Model Updates: 190,300
Cumulative Timesteps: 1,587,096,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1587096612...
Checkpoint 1587096612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.19389
Policy Entropy: 2.33582
Value Function Loss: 0.01645

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 22,827.57502
Overall Steps per Second: 10,827.57776

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.42896
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.62061

Cumulative Model Updates: 190,306
Cumulative Timesteps: 1,587,146,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.45099
Policy Entropy: 2.33980
Value Function Loss: 0.01628

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 22,939.80173
Overall Steps per Second: 10,775.70721

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.46104
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.64118

Cumulative Model Updates: 190,312
Cumulative Timesteps: 1,587,196,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1587196654...
Checkpoint 1587196654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.43263
Policy Entropy: 2.33298
Value Function Loss: 0.01593

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.59276

Collected Steps per Second: 22,747.27378
Overall Steps per Second: 10,781.68395

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.63749

Cumulative Model Updates: 190,318
Cumulative Timesteps: 1,587,246,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.01004
Policy Entropy: 2.32010
Value Function Loss: 0.01689

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.59938

Collected Steps per Second: 22,765.55069
Overall Steps per Second: 10,664.30844

Timestep Collection Time: 2.19744
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.69097

Cumulative Model Updates: 190,324
Cumulative Timesteps: 1,587,296,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1587296680...
Checkpoint 1587296680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.38553
Policy Entropy: 2.31214
Value Function Loss: 0.01749

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.59478

Collected Steps per Second: 22,929.55432
Overall Steps per Second: 10,672.33559

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68595

Cumulative Model Updates: 190,330
Cumulative Timesteps: 1,587,346,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.20309
Policy Entropy: 2.32671
Value Function Loss: 0.01702

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.55955
Value Function Update Magnitude: 0.58408

Collected Steps per Second: 23,272.22590
Overall Steps per Second: 10,751.00046

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.65222

Cumulative Model Updates: 190,336
Cumulative Timesteps: 1,587,396,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1587396706...
Checkpoint 1587396706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.01479
Policy Entropy: 2.34654
Value Function Loss: 0.01552

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.56286
Value Function Update Magnitude: 0.58802

Collected Steps per Second: 22,683.23053
Overall Steps per Second: 10,626.75211

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.70680

Cumulative Model Updates: 190,342
Cumulative Timesteps: 1,587,446,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.92500
Policy Entropy: 2.34232
Value Function Loss: 0.01489

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.59888

Collected Steps per Second: 23,024.33278
Overall Steps per Second: 10,910.01004

Timestep Collection Time: 2.17257
Timestep Consumption Time: 2.41239
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.58496

Cumulative Model Updates: 190,348
Cumulative Timesteps: 1,587,496,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1587496746...
Checkpoint 1587496746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.96667
Policy Entropy: 2.31586
Value Function Loss: 0.01441

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.59259

Collected Steps per Second: 22,538.38899
Overall Steps per Second: 10,653.34721

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69449

Cumulative Model Updates: 190,354
Cumulative Timesteps: 1,587,546,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.53163
Policy Entropy: 2.30008
Value Function Loss: 0.01511

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 23,293.97436
Overall Steps per Second: 10,928.91041

Timestep Collection Time: 2.14742
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.57703

Cumulative Model Updates: 190,360
Cumulative Timesteps: 1,587,596,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1587596780...
Checkpoint 1587596780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.60143
Policy Entropy: 2.30191
Value Function Loss: 0.01515

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.55645

Collected Steps per Second: 22,350.22636
Overall Steps per Second: 10,604.72729

Timestep Collection Time: 2.23774
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.71620

Cumulative Model Updates: 190,366
Cumulative Timesteps: 1,587,646,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.91538
Policy Entropy: 2.30227
Value Function Loss: 0.01597

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.56952
Value Function Update Magnitude: 0.55955

Collected Steps per Second: 22,952.10780
Overall Steps per Second: 10,859.50783

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.60444

Cumulative Model Updates: 190,372
Cumulative Timesteps: 1,587,696,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1587696796...
Checkpoint 1587696796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.43258
Policy Entropy: 2.30860
Value Function Loss: 0.01667

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.58587

Collected Steps per Second: 22,583.61384
Overall Steps per Second: 10,750.21480

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.65126

Cumulative Model Updates: 190,378
Cumulative Timesteps: 1,587,746,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.12858
Policy Entropy: 2.30973
Value Function Loss: 0.01618

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.59644

Collected Steps per Second: 23,192.66673
Overall Steps per Second: 10,888.36841

Timestep Collection Time: 2.15697
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59444

Cumulative Model Updates: 190,384
Cumulative Timesteps: 1,587,796,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1587796824...
Checkpoint 1587796824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.20237
Policy Entropy: 2.32470
Value Function Loss: 0.01577

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.56764
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 22,774.57888
Overall Steps per Second: 10,621.94384

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.70968

Cumulative Model Updates: 190,390
Cumulative Timesteps: 1,587,846,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.01688
Policy Entropy: 2.30877
Value Function Loss: 0.01534

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.56059

Collected Steps per Second: 23,010.21420
Overall Steps per Second: 10,713.68605

Timestep Collection Time: 2.17321
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.66749

Cumulative Model Updates: 190,396
Cumulative Timesteps: 1,587,896,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1587896856...
Checkpoint 1587896856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.38460
Policy Entropy: 2.30216
Value Function Loss: 0.01601

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 22,618.98454
Overall Steps per Second: 10,618.58286

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.71155

Cumulative Model Updates: 190,402
Cumulative Timesteps: 1,587,946,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.71549
Policy Entropy: 2.30985
Value Function Loss: 0.01664

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.55323

Collected Steps per Second: 23,200.59551
Overall Steps per Second: 10,945.44960

Timestep Collection Time: 2.15520
Timestep Consumption Time: 2.41309
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.56829

Cumulative Model Updates: 190,408
Cumulative Timesteps: 1,587,996,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1587996888...
Checkpoint 1587996888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.71148
Policy Entropy: 2.28437
Value Function Loss: 0.01759

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.58371

Collected Steps per Second: 22,797.97679
Overall Steps per Second: 10,842.05061

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61186

Cumulative Model Updates: 190,414
Cumulative Timesteps: 1,588,046,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.09780
Policy Entropy: 2.28815
Value Function Loss: 0.01729

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.60455

Collected Steps per Second: 23,236.61832
Overall Steps per Second: 10,880.98019

Timestep Collection Time: 2.15238
Timestep Consumption Time: 2.44408
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.59646

Cumulative Model Updates: 190,420
Cumulative Timesteps: 1,588,096,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1588096904...
Checkpoint 1588096904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.65954
Policy Entropy: 2.27746
Value Function Loss: 0.01711

Mean KL Divergence: 0.03101
SB3 Clip Fraction: 0.19570
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.60214

Collected Steps per Second: 22,649.21245
Overall Steps per Second: 10,631.41291

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.70436

Cumulative Model Updates: 190,426
Cumulative Timesteps: 1,588,146,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.76256
Policy Entropy: 2.28526
Value Function Loss: 0.01753

Mean KL Divergence: 0.06419
SB3 Clip Fraction: 0.27644
Policy Update Magnitude: 0.49833
Value Function Update Magnitude: 0.59170

Collected Steps per Second: 23,158.06971
Overall Steps per Second: 10,912.15787

Timestep Collection Time: 2.15977
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.58351

Cumulative Model Updates: 190,432
Cumulative Timesteps: 1,588,196,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1588196934...
Checkpoint 1588196934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.78388
Policy Entropy: 2.30463
Value Function Loss: 0.01714

Mean KL Divergence: 0.04996
SB3 Clip Fraction: 0.26623
Policy Update Magnitude: 0.51744
Value Function Update Magnitude: 0.58813

Collected Steps per Second: 22,450.13705
Overall Steps per Second: 10,725.88995

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66292

Cumulative Model Updates: 190,438
Cumulative Timesteps: 1,588,246,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.62514
Policy Entropy: 2.34979
Value Function Loss: 0.01652

Mean KL Divergence: 0.02402
SB3 Clip Fraction: 0.18787
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.59243

Collected Steps per Second: 22,950.58544
Overall Steps per Second: 10,824.22046

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.44165
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.62112

Cumulative Model Updates: 190,444
Cumulative Timesteps: 1,588,296,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1588296968...
Checkpoint 1588296968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.63664
Policy Entropy: 2.37187
Value Function Loss: 0.01527

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.17518
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.60686

Collected Steps per Second: 22,815.46589
Overall Steps per Second: 10,629.08637

Timestep Collection Time: 2.19237
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70595

Cumulative Model Updates: 190,450
Cumulative Timesteps: 1,588,346,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.85876
Policy Entropy: 2.36312
Value Function Loss: 0.01564

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.17368
Policy Update Magnitude: 0.57440
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 22,678.33308
Overall Steps per Second: 10,582.84485

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.72614

Cumulative Model Updates: 190,456
Cumulative Timesteps: 1,588,397,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1588397004...
Checkpoint 1588397004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.74173
Policy Entropy: 2.35251
Value Function Loss: 0.01613

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.57868
Value Function Update Magnitude: 0.62801

Collected Steps per Second: 22,536.83081
Overall Steps per Second: 10,612.82180

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.71147

Cumulative Model Updates: 190,462
Cumulative Timesteps: 1,588,447,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.55256
Policy Entropy: 2.33049
Value Function Loss: 0.01593

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.17376
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 23,066.78859
Overall Steps per Second: 10,816.70633

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.62248

Cumulative Model Updates: 190,468
Cumulative Timesteps: 1,588,497,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1588497006...
Checkpoint 1588497006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.93126
Policy Entropy: 2.33979
Value Function Loss: 0.01599

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.18248
Policy Update Magnitude: 0.52188
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,787.26472
Overall Steps per Second: 10,628.84100

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70456

Cumulative Model Updates: 190,474
Cumulative Timesteps: 1,588,547,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.67670
Policy Entropy: 2.32017
Value Function Loss: 0.01528

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.17801
Policy Update Magnitude: 0.52504
Value Function Update Magnitude: 0.60834

Collected Steps per Second: 22,535.15340
Overall Steps per Second: 10,642.62870

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.70034

Cumulative Model Updates: 190,480
Cumulative Timesteps: 1,588,597,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1588597034...
Checkpoint 1588597034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.55606
Policy Entropy: 2.33474
Value Function Loss: 0.01590

Mean KL Divergence: 0.02847
SB3 Clip Fraction: 0.19240
Policy Update Magnitude: 0.52711
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 22,210.98813
Overall Steps per Second: 10,495.79097

Timestep Collection Time: 2.25168
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.76496

Cumulative Model Updates: 190,486
Cumulative Timesteps: 1,588,647,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.87468
Policy Entropy: 2.34502
Value Function Loss: 0.01521

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.17492
Policy Update Magnitude: 0.56939
Value Function Update Magnitude: 0.61001

Collected Steps per Second: 22,793.60920
Overall Steps per Second: 10,817.37132

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.62423

Cumulative Model Updates: 190,492
Cumulative Timesteps: 1,588,697,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1588697068...
Checkpoint 1588697068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.91771
Policy Entropy: 2.36809
Value Function Loss: 0.01497

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.16807
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.61790

Collected Steps per Second: 22,653.38991
Overall Steps per Second: 10,693.44402

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.46997
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.67838

Cumulative Model Updates: 190,498
Cumulative Timesteps: 1,588,747,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.49169
Policy Entropy: 2.34359
Value Function Loss: 0.01564

Mean KL Divergence: 0.02379
SB3 Clip Fraction: 0.17409
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.61506

Collected Steps per Second: 22,767.85688
Overall Steps per Second: 10,921.60649

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.38210
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.57826

Cumulative Model Updates: 190,504
Cumulative Timesteps: 1,588,797,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1588797098...
Checkpoint 1588797098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.94182
Policy Entropy: 2.34879
Value Function Loss: 0.01569

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 22,440.95114
Overall Steps per Second: 10,645.03473

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.46915
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.69740

Cumulative Model Updates: 190,510
Cumulative Timesteps: 1,588,847,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.25778
Policy Entropy: 2.34088
Value Function Loss: 0.01631

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 23,235.10503
Overall Steps per Second: 10,852.50479

Timestep Collection Time: 2.15209
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.60760

Cumulative Model Updates: 190,516
Cumulative Timesteps: 1,588,897,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1588897106...
Checkpoint 1588897106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.54660
Policy Entropy: 2.36327
Value Function Loss: 0.01590

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,290.79840
Overall Steps per Second: 10,684.26863

Timestep Collection Time: 2.24415
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.68202

Cumulative Model Updates: 190,522
Cumulative Timesteps: 1,588,947,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.07823
Policy Entropy: 2.37674
Value Function Loss: 0.01575

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.61217

Collected Steps per Second: 22,836.66538
Overall Steps per Second: 10,834.57482

Timestep Collection Time: 2.19034
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.61670

Cumulative Model Updates: 190,528
Cumulative Timesteps: 1,588,997,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1588997150...
Checkpoint 1588997150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.48581
Policy Entropy: 2.37377
Value Function Loss: 0.01575

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 22,615.84993
Overall Steps per Second: 10,781.93709

Timestep Collection Time: 2.21119
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.63813

Cumulative Model Updates: 190,534
Cumulative Timesteps: 1,589,047,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.96552
Policy Entropy: 2.37803
Value Function Loss: 0.01552

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.54440
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 23,115.68192
Overall Steps per Second: 10,860.07712

Timestep Collection Time: 2.16407
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60623

Cumulative Model Updates: 190,540
Cumulative Timesteps: 1,589,097,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1589097182...
Checkpoint 1589097182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.09600
Policy Entropy: 2.36676
Value Function Loss: 0.01532

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.53707
Value Function Update Magnitude: 0.56708

Collected Steps per Second: 22,765.44471
Overall Steps per Second: 10,603.79406

Timestep Collection Time: 2.19640
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71548

Cumulative Model Updates: 190,546
Cumulative Timesteps: 1,589,147,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.07136
Policy Entropy: 2.37020
Value Function Loss: 0.01531

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 23,079.21856
Overall Steps per Second: 10,914.11258

Timestep Collection Time: 2.16680
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.58196

Cumulative Model Updates: 190,552
Cumulative Timesteps: 1,589,197,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1589197192...
Checkpoint 1589197192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.23887
Policy Entropy: 2.35668
Value Function Loss: 0.01522

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.55803
Value Function Update Magnitude: 0.58470

Collected Steps per Second: 22,746.50702
Overall Steps per Second: 10,660.71404

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.69162

Cumulative Model Updates: 190,558
Cumulative Timesteps: 1,589,247,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.95848
Policy Entropy: 2.35142
Value Function Loss: 0.01565

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 22,849.62373
Overall Steps per Second: 10,699.02164

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.67501

Cumulative Model Updates: 190,564
Cumulative Timesteps: 1,589,297,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1589297226...
Checkpoint 1589297226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.31798
Policy Entropy: 2.34991
Value Function Loss: 0.01599

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.62015

Collected Steps per Second: 23,091.58991
Overall Steps per Second: 10,888.79453

Timestep Collection Time: 2.16538
Timestep Consumption Time: 2.42668
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59206

Cumulative Model Updates: 190,570
Cumulative Timesteps: 1,589,347,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.86429
Policy Entropy: 2.36810
Value Function Loss: 0.01599

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.61719

Collected Steps per Second: 22,521.64817
Overall Steps per Second: 10,478.71694

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.55190
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.77234

Cumulative Model Updates: 190,576
Cumulative Timesteps: 1,589,397,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1589397236...
Checkpoint 1589397236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.86273
Policy Entropy: 2.36788
Value Function Loss: 0.01625

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.60139

Collected Steps per Second: 22,663.86739
Overall Steps per Second: 10,954.71680

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.35828
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.56461

Cumulative Model Updates: 190,582
Cumulative Timesteps: 1,589,447,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.97353
Policy Entropy: 2.36576
Value Function Loss: 0.01695

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 23,355.27161
Overall Steps per Second: 10,902.40233

Timestep Collection Time: 2.14162
Timestep Consumption Time: 2.44618
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.58780

Cumulative Model Updates: 190,588
Cumulative Timesteps: 1,589,497,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1589497258...
Checkpoint 1589497258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.31863
Policy Entropy: 2.34432
Value Function Loss: 0.01685

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.62819

Collected Steps per Second: 22,868.25602
Overall Steps per Second: 10,747.46854

Timestep Collection Time: 2.18757
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.65468

Cumulative Model Updates: 190,594
Cumulative Timesteps: 1,589,547,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.27662
Policy Entropy: 2.33946
Value Function Loss: 0.01524

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 22,995.00780
Overall Steps per Second: 10,828.52157

Timestep Collection Time: 2.17473
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.61817

Cumulative Model Updates: 190,600
Cumulative Timesteps: 1,589,597,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1589597292...
Checkpoint 1589597292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.96232
Policy Entropy: 2.33710
Value Function Loss: 0.01467

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.59309

Collected Steps per Second: 22,428.47801
Overall Steps per Second: 10,712.04243

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.66932

Cumulative Model Updates: 190,606
Cumulative Timesteps: 1,589,647,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.87602
Policy Entropy: 2.31870
Value Function Loss: 0.01454

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.56582

Collected Steps per Second: 22,973.26199
Overall Steps per Second: 10,947.31044

Timestep Collection Time: 2.17749
Timestep Consumption Time: 2.39204
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.56952

Cumulative Model Updates: 190,612
Cumulative Timesteps: 1,589,697,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1589697334...
Checkpoint 1589697334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.56638
Policy Entropy: 2.29701
Value Function Loss: 0.01423

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.56448

Collected Steps per Second: 22,109.38604
Overall Steps per Second: 10,606.41457

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.71677

Cumulative Model Updates: 190,618
Cumulative Timesteps: 1,589,747,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.19104
Policy Entropy: 2.29420
Value Function Loss: 0.01487

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.54952
Value Function Update Magnitude: 0.56581

Collected Steps per Second: 23,263.95926
Overall Steps per Second: 10,895.70368

Timestep Collection Time: 2.14933
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.58915

Cumulative Model Updates: 190,624
Cumulative Timesteps: 1,589,797,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1589797364...
Checkpoint 1589797364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.82018
Policy Entropy: 2.30245
Value Function Loss: 0.01617

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.58214

Collected Steps per Second: 22,619.72782
Overall Steps per Second: 10,675.32642

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.47462
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68632

Cumulative Model Updates: 190,630
Cumulative Timesteps: 1,589,847,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.61296
Policy Entropy: 2.32497
Value Function Loss: 0.01691

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.61668

Collected Steps per Second: 22,761.49189
Overall Steps per Second: 10,790.86482

Timestep Collection Time: 2.19687
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.63392

Cumulative Model Updates: 190,636
Cumulative Timesteps: 1,589,897,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1589897396...
Checkpoint 1589897396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.00831
Policy Entropy: 2.31385
Value Function Loss: 0.01674

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.57844
Value Function Update Magnitude: 0.62673

Collected Steps per Second: 22,648.46610
Overall Steps per Second: 10,663.28561

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.30530
Total Iteration Time: 4.69124

Cumulative Model Updates: 190,642
Cumulative Timesteps: 1,589,947,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.29845
Policy Entropy: 2.32865
Value Function Loss: 0.01708

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.61071

Collected Steps per Second: 22,522.87139
Overall Steps per Second: 10,892.52837

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.37128
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.59214

Cumulative Model Updates: 190,648
Cumulative Timesteps: 1,589,997,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1589997440...
Checkpoint 1589997440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.67207
Policy Entropy: 2.30723
Value Function Loss: 0.01676

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.61819

Collected Steps per Second: 22,664.90477
Overall Steps per Second: 10,784.56805

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63700

Cumulative Model Updates: 190,654
Cumulative Timesteps: 1,590,047,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.40389
Policy Entropy: 2.30643
Value Function Loss: 0.01715

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.63664

Collected Steps per Second: 23,008.43684
Overall Steps per Second: 10,807.72161

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.45399
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.62780

Cumulative Model Updates: 190,660
Cumulative Timesteps: 1,590,097,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1590097464...
Checkpoint 1590097464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.17379
Policy Entropy: 2.30075
Value Function Loss: 0.01652

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.61986

Collected Steps per Second: 22,751.56745
Overall Steps per Second: 10,672.52828

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68549

Cumulative Model Updates: 190,666
Cumulative Timesteps: 1,590,147,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.68780
Policy Entropy: 2.31250
Value Function Loss: 0.01783

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.60907

Collected Steps per Second: 23,231.60424
Overall Steps per Second: 10,922.00779

Timestep Collection Time: 2.15241
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.57828

Cumulative Model Updates: 190,672
Cumulative Timesteps: 1,590,197,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1590197474...
Checkpoint 1590197474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.48231
Policy Entropy: 2.29913
Value Function Loss: 0.01750

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.61844

Collected Steps per Second: 22,578.33335
Overall Steps per Second: 10,672.12540

Timestep Collection Time: 2.21513
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.68641

Cumulative Model Updates: 190,678
Cumulative Timesteps: 1,590,247,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.61470
Policy Entropy: 2.30123
Value Function Loss: 0.01721

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.63232

Collected Steps per Second: 23,420.74690
Overall Steps per Second: 10,945.63693

Timestep Collection Time: 2.13529
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.56894

Cumulative Model Updates: 190,684
Cumulative Timesteps: 1,590,297,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1590297498...
Checkpoint 1590297498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.09021
Policy Entropy: 2.25376
Value Function Loss: 0.01746

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.62912

Collected Steps per Second: 22,551.78054
Overall Steps per Second: 10,585.45113

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.72516

Cumulative Model Updates: 190,690
Cumulative Timesteps: 1,590,347,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.51237
Policy Entropy: 2.27462
Value Function Loss: 0.01783

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.58078
Value Function Update Magnitude: 0.61311

Collected Steps per Second: 22,861.85709
Overall Steps per Second: 10,939.55497

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.38419
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.57185

Cumulative Model Updates: 190,696
Cumulative Timesteps: 1,590,397,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1590397530...
Checkpoint 1590397530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.49715
Policy Entropy: 2.25238
Value Function Loss: 0.01898

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.55988
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,908.06700
Overall Steps per Second: 10,660.74929

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.69235

Cumulative Model Updates: 190,702
Cumulative Timesteps: 1,590,447,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.28997
Policy Entropy: 2.29913
Value Function Loss: 0.01887

Mean KL Divergence: 0.02441
SB3 Clip Fraction: 0.17282
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.64819

Collected Steps per Second: 23,027.71329
Overall Steps per Second: 10,801.57385

Timestep Collection Time: 2.17164
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62970

Cumulative Model Updates: 190,708
Cumulative Timesteps: 1,590,497,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1590497562...
Checkpoint 1590497562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.83366
Policy Entropy: 2.31043
Value Function Loss: 0.01856

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.17290
Policy Update Magnitude: 0.56532
Value Function Update Magnitude: 0.66963

Collected Steps per Second: 22,526.36114
Overall Steps per Second: 10,673.31110

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.68458

Cumulative Model Updates: 190,714
Cumulative Timesteps: 1,590,547,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.46844
Policy Entropy: 2.33986
Value Function Loss: 0.01772

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.58229
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 23,233.94918
Overall Steps per Second: 10,859.78640

Timestep Collection Time: 2.15383
Timestep Consumption Time: 2.45418
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.60801

Cumulative Model Updates: 190,720
Cumulative Timesteps: 1,590,597,604

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1590597604...
Checkpoint 1590597604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.82284
Policy Entropy: 2.31086
Value Function Loss: 0.01782

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.58648
Value Function Update Magnitude: 0.61975

Collected Steps per Second: 22,159.61864
Overall Steps per Second: 10,737.70438

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.40080
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.65779

Cumulative Model Updates: 190,726
Cumulative Timesteps: 1,590,647,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.97780
Policy Entropy: 2.28449
Value Function Loss: 0.01711

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.60678

Collected Steps per Second: 23,515.97827
Overall Steps per Second: 10,877.43970

Timestep Collection Time: 2.12655
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.59741

Cumulative Model Updates: 190,732
Cumulative Timesteps: 1,590,697,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1590697626...
Checkpoint 1590697626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.34582
Policy Entropy: 2.27061
Value Function Loss: 0.01529

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.60941

Collected Steps per Second: 22,728.57197
Overall Steps per Second: 10,632.32397

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.70415

Cumulative Model Updates: 190,738
Cumulative Timesteps: 1,590,747,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.15257
Policy Entropy: 2.30919
Value Function Loss: 0.01524

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.60981

Collected Steps per Second: 22,827.18378
Overall Steps per Second: 10,693.34363

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.67655

Cumulative Model Updates: 190,744
Cumulative Timesteps: 1,590,797,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1590797650...
Checkpoint 1590797650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.61794
Policy Entropy: 2.31457
Value Function Loss: 0.01525

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.60699

Collected Steps per Second: 22,786.71307
Overall Steps per Second: 10,825.71797

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62103

Cumulative Model Updates: 190,750
Cumulative Timesteps: 1,590,847,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.66422
Policy Entropy: 2.31041
Value Function Loss: 0.01583

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.60380

Collected Steps per Second: 22,885.79540
Overall Steps per Second: 10,997.35476

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.36273
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.54837

Cumulative Model Updates: 190,756
Cumulative Timesteps: 1,590,897,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1590897696...
Checkpoint 1590897696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.77640
Policy Entropy: 2.30185
Value Function Loss: 0.01583

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.61576

Collected Steps per Second: 23,032.48067
Overall Steps per Second: 10,681.50168

Timestep Collection Time: 2.17093
Timestep Consumption Time: 2.51024
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.68118

Cumulative Model Updates: 190,762
Cumulative Timesteps: 1,590,947,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.59192
Policy Entropy: 2.28938
Value Function Loss: 0.01636

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 23,265.68331
Overall Steps per Second: 10,841.64736

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.46374
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.61369

Cumulative Model Updates: 190,768
Cumulative Timesteps: 1,590,997,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1590997718...
Checkpoint 1590997718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.10568
Policy Entropy: 2.29875
Value Function Loss: 0.01599

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.64979

Collected Steps per Second: 22,634.51471
Overall Steps per Second: 10,645.69444

Timestep Collection Time: 2.21008
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.69899

Cumulative Model Updates: 190,774
Cumulative Timesteps: 1,591,047,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.43236
Policy Entropy: 2.28302
Value Function Loss: 0.01649

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 23,208.59445
Overall Steps per Second: 10,931.17943

Timestep Collection Time: 2.15446
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.57425

Cumulative Model Updates: 190,780
Cumulative Timesteps: 1,591,097,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1591097744...
Checkpoint 1591097744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.96497
Policy Entropy: 2.30006
Value Function Loss: 0.01650

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 22,707.54291
Overall Steps per Second: 10,848.64693

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.40821
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.61127

Cumulative Model Updates: 190,786
Cumulative Timesteps: 1,591,147,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.16165
Policy Entropy: 2.29037
Value Function Loss: 0.01681

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.58775

Collected Steps per Second: 23,191.65579
Overall Steps per Second: 10,699.96873

Timestep Collection Time: 2.15724
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.67571

Cumulative Model Updates: 190,792
Cumulative Timesteps: 1,591,197,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1591197800...
Checkpoint 1591197800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.50159
Policy Entropy: 2.28788
Value Function Loss: 0.01609

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.58001

Collected Steps per Second: 22,642.16889
Overall Steps per Second: 10,499.72185

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.55437
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.76317

Cumulative Model Updates: 190,798
Cumulative Timesteps: 1,591,247,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.73570
Policy Entropy: 2.27525
Value Function Loss: 0.01639

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.57676

Collected Steps per Second: 23,225.05483
Overall Steps per Second: 10,783.94554

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.63856

Cumulative Model Updates: 190,804
Cumulative Timesteps: 1,591,297,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1591297834...
Checkpoint 1591297834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.35769
Policy Entropy: 2.29163
Value Function Loss: 0.01633

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.55187
Value Function Update Magnitude: 0.59085

Collected Steps per Second: 23,013.35851
Overall Steps per Second: 10,888.13992

Timestep Collection Time: 2.17326
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.59344

Cumulative Model Updates: 190,810
Cumulative Timesteps: 1,591,347,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.16376
Policy Entropy: 2.27138
Value Function Loss: 0.01684

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 22,789.80920
Overall Steps per Second: 10,878.44628

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.40363
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.59882

Cumulative Model Updates: 190,816
Cumulative Timesteps: 1,591,397,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1591397876...
Checkpoint 1591397876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.71494
Policy Entropy: 2.25475
Value Function Loss: 0.01671

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.17122
Policy Update Magnitude: 0.53506
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,546.20660
Overall Steps per Second: 10,694.89281

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.67625

Cumulative Model Updates: 190,822
Cumulative Timesteps: 1,591,447,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.48550
Policy Entropy: 2.23854
Value Function Loss: 0.01708

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.17249
Policy Update Magnitude: 0.51543
Value Function Update Magnitude: 0.60318

Collected Steps per Second: 23,083.18063
Overall Steps per Second: 10,834.05643

Timestep Collection Time: 2.16686
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61674

Cumulative Model Updates: 190,828
Cumulative Timesteps: 1,591,497,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1591497906...
Checkpoint 1591497906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.74347
Policy Entropy: 2.27069
Value Function Loss: 0.01662

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.17820
Policy Update Magnitude: 0.50851
Value Function Update Magnitude: 0.59492

Collected Steps per Second: 22,704.97822
Overall Steps per Second: 10,712.12770

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.66798

Cumulative Model Updates: 190,834
Cumulative Timesteps: 1,591,547,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.43554
Policy Entropy: 2.28507
Value Function Loss: 0.01677

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.59094

Collected Steps per Second: 22,889.45677
Overall Steps per Second: 10,820.59588

Timestep Collection Time: 2.18598
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.62414

Cumulative Model Updates: 190,840
Cumulative Timesteps: 1,591,597,946

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1591597946...
Checkpoint 1591597946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.65762
Policy Entropy: 2.27674
Value Function Loss: 0.01697

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.16726
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 22,727.21488
Overall Steps per Second: 10,654.72344

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.49305
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69332

Cumulative Model Updates: 190,846
Cumulative Timesteps: 1,591,647,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.87108
Policy Entropy: 2.24836
Value Function Loss: 0.01705

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.61364

Collected Steps per Second: 23,031.77249
Overall Steps per Second: 10,735.09802

Timestep Collection Time: 2.17230
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.66060

Cumulative Model Updates: 190,852
Cumulative Timesteps: 1,591,697,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1591697984...
Checkpoint 1591697984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.78315
Policy Entropy: 2.26485
Value Function Loss: 0.01685

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.56295
Value Function Update Magnitude: 0.60990

Collected Steps per Second: 22,679.45716
Overall Steps per Second: 10,684.16522

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68506

Cumulative Model Updates: 190,858
Cumulative Timesteps: 1,591,748,040

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.82023
Policy Entropy: 2.26391
Value Function Loss: 0.01611

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 22,948.10446
Overall Steps per Second: 10,847.59868

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.61245

Cumulative Model Updates: 190,864
Cumulative Timesteps: 1,591,798,074

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1591798074...
Checkpoint 1591798074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.20307
Policy Entropy: 2.27239
Value Function Loss: 0.01584

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.55333
Value Function Update Magnitude: 0.58510

Collected Steps per Second: 21,558.11282
Overall Steps per Second: 10,608.34602

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.39492
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.71516

Cumulative Model Updates: 190,870
Cumulative Timesteps: 1,591,848,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.49933
Policy Entropy: 2.27104
Value Function Loss: 0.01608

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15383
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 22,767.94441
Overall Steps per Second: 10,599.12237

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.71775

Cumulative Model Updates: 190,876
Cumulative Timesteps: 1,591,898,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1591898098...
Checkpoint 1591898098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.99683
Policy Entropy: 2.26207
Value Function Loss: 0.01637

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.55121
Value Function Update Magnitude: 0.57327

Collected Steps per Second: 22,465.66059
Overall Steps per Second: 10,553.81919

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.74027

Cumulative Model Updates: 190,882
Cumulative Timesteps: 1,591,948,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.48190
Policy Entropy: 2.26316
Value Function Loss: 0.01644

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.56640

Collected Steps per Second: 22,651.98215
Overall Steps per Second: 10,685.07380

Timestep Collection Time: 2.20793
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68074

Cumulative Model Updates: 190,888
Cumulative Timesteps: 1,591,998,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1591998140...
Checkpoint 1591998140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.83252
Policy Entropy: 2.25498
Value Function Loss: 0.01649

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.56762

Collected Steps per Second: 22,736.65677
Overall Steps per Second: 10,847.86206

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61123

Cumulative Model Updates: 190,894
Cumulative Timesteps: 1,592,048,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.61352
Policy Entropy: 2.28277
Value Function Loss: 0.01651

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.57044

Collected Steps per Second: 23,207.03612
Overall Steps per Second: 10,990.69264

Timestep Collection Time: 2.15581
Timestep Consumption Time: 2.39622
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.55203

Cumulative Model Updates: 190,900
Cumulative Timesteps: 1,592,098,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1592098192...
Checkpoint 1592098192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.67968
Policy Entropy: 2.30570
Value Function Loss: 0.01647

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.56539

Collected Steps per Second: 22,907.21159
Overall Steps per Second: 10,657.58928

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.50948
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.69281

Cumulative Model Updates: 190,906
Cumulative Timesteps: 1,592,148,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.70905
Policy Entropy: 2.30137
Value Function Loss: 0.01608

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.58012

Collected Steps per Second: 22,899.56651
Overall Steps per Second: 10,791.87962

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.45084
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.63534

Cumulative Model Updates: 190,912
Cumulative Timesteps: 1,592,198,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1592198230...
Checkpoint 1592198230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.65396
Policy Entropy: 2.26769
Value Function Loss: 0.01587

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.56243
Value Function Update Magnitude: 0.59398

Collected Steps per Second: 22,816.63242
Overall Steps per Second: 10,745.41351

Timestep Collection Time: 2.19287
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.65631

Cumulative Model Updates: 190,918
Cumulative Timesteps: 1,592,248,264

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.66406
Policy Entropy: 2.22183
Value Function Loss: 0.01666

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.57711
Value Function Update Magnitude: 0.60260

Collected Steps per Second: 23,147.08556
Overall Steps per Second: 10,882.51326

Timestep Collection Time: 2.16105
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.59655

Cumulative Model Updates: 190,924
Cumulative Timesteps: 1,592,298,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1592298286...
Checkpoint 1592298286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.44794
Policy Entropy: 2.24604
Value Function Loss: 0.01673

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.60483

Collected Steps per Second: 22,794.91883
Overall Steps per Second: 10,631.58516

Timestep Collection Time: 2.19417
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70447

Cumulative Model Updates: 190,930
Cumulative Timesteps: 1,592,348,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.02917
Policy Entropy: 2.26370
Value Function Loss: 0.01722

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.58449

Collected Steps per Second: 22,833.77333
Overall Steps per Second: 10,661.79313

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.50110
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.69189

Cumulative Model Updates: 190,936
Cumulative Timesteps: 1,592,398,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1592398326...
Checkpoint 1592398326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.92728
Policy Entropy: 2.28232
Value Function Loss: 0.01660

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.58081

Collected Steps per Second: 22,809.81728
Overall Steps per Second: 10,876.31266

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.40617
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.59917

Cumulative Model Updates: 190,942
Cumulative Timesteps: 1,592,448,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.51175
Policy Entropy: 2.28629
Value Function Loss: 0.01733

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.59062

Collected Steps per Second: 22,586.06874
Overall Steps per Second: 10,911.74512

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.36903
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.58332

Cumulative Model Updates: 190,948
Cumulative Timesteps: 1,592,498,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1592498360...
Checkpoint 1592498360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.95826
Policy Entropy: 2.30227
Value Function Loss: 0.01722

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.61188

Collected Steps per Second: 22,697.73137
Overall Steps per Second: 10,696.03855

Timestep Collection Time: 2.20392
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.67687

Cumulative Model Updates: 190,954
Cumulative Timesteps: 1,592,548,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.83276
Policy Entropy: 2.30794
Value Function Loss: 0.01704

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.58722

Collected Steps per Second: 22,940.67545
Overall Steps per Second: 10,654.70012

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.69558

Cumulative Model Updates: 190,960
Cumulative Timesteps: 1,592,598,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1592598414...
Checkpoint 1592598414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.23369
Policy Entropy: 2.30022
Value Function Loss: 0.01663

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.57500

Collected Steps per Second: 22,749.25756
Overall Steps per Second: 10,855.90508

Timestep Collection Time: 2.19831
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.60671

Cumulative Model Updates: 190,966
Cumulative Timesteps: 1,592,648,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.84715
Policy Entropy: 2.29417
Value Function Loss: 0.01657

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 23,139.22098
Overall Steps per Second: 10,881.89134

Timestep Collection Time: 2.16178
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.59681

Cumulative Model Updates: 190,972
Cumulative Timesteps: 1,592,698,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1592698446...
Checkpoint 1592698446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.96257
Policy Entropy: 2.28413
Value Function Loss: 0.01650

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.58092

Collected Steps per Second: 22,698.70762
Overall Steps per Second: 10,802.32380

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.63067

Cumulative Model Updates: 190,978
Cumulative Timesteps: 1,592,748,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.41673
Policy Entropy: 2.28585
Value Function Loss: 0.01605

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 23,093.02264
Overall Steps per Second: 10,779.83470

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.63977

Cumulative Model Updates: 190,984
Cumulative Timesteps: 1,592,798,484

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1592798484...
Checkpoint 1592798484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.39810
Policy Entropy: 2.26630
Value Function Loss: 0.01588

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.54414
Value Function Update Magnitude: 0.57866

Collected Steps per Second: 22,583.82924
Overall Steps per Second: 10,690.23275

Timestep Collection Time: 2.21424
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.67773

Cumulative Model Updates: 190,990
Cumulative Timesteps: 1,592,848,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.57850
Policy Entropy: 2.27673
Value Function Loss: 0.01509

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.58956

Collected Steps per Second: 22,978.17873
Overall Steps per Second: 10,865.58189

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.60261

Cumulative Model Updates: 190,996
Cumulative Timesteps: 1,592,898,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1592898500...
Checkpoint 1592898500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.34311
Policy Entropy: 2.27734
Value Function Loss: 0.01489

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.61061

Collected Steps per Second: 22,953.21376
Overall Steps per Second: 10,896.05973

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.58992

Cumulative Model Updates: 191,002
Cumulative Timesteps: 1,592,948,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.60839
Policy Entropy: 2.26867
Value Function Loss: 0.01478

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.55117
Value Function Update Magnitude: 0.60292

Collected Steps per Second: 23,106.90940
Overall Steps per Second: 10,673.95277

Timestep Collection Time: 2.16411
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.68486

Cumulative Model Updates: 191,008
Cumulative Timesteps: 1,592,998,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1592998518...
Checkpoint 1592998518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.73747
Policy Entropy: 2.26002
Value Function Loss: 0.01550

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.60005

Collected Steps per Second: 22,830.11524
Overall Steps per Second: 10,635.70918

Timestep Collection Time: 2.19035
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.70171

Cumulative Model Updates: 191,014
Cumulative Timesteps: 1,593,048,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.41765
Policy Entropy: 2.28933
Value Function Loss: 0.01538

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,920.41070
Overall Steps per Second: 10,673.33358

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.68495

Cumulative Model Updates: 191,020
Cumulative Timesteps: 1,593,098,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1593098528...
Checkpoint 1593098528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.31835
Policy Entropy: 2.28828
Value Function Loss: 0.01615

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.61110

Collected Steps per Second: 22,578.76504
Overall Steps per Second: 10,800.57736

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.63197

Cumulative Model Updates: 191,026
Cumulative Timesteps: 1,593,148,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.63244
Policy Entropy: 2.30558
Value Function Loss: 0.01634

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.62650

Collected Steps per Second: 22,855.29592
Overall Steps per Second: 10,960.41298

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.37457
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.56260

Cumulative Model Updates: 191,032
Cumulative Timesteps: 1,593,198,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1593198564...
Checkpoint 1593198564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.18148
Policy Entropy: 2.28748
Value Function Loss: 0.01767

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.18024
Policy Update Magnitude: 0.53430
Value Function Update Magnitude: 0.61130

Collected Steps per Second: 22,823.94619
Overall Steps per Second: 10,684.02617

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68026

Cumulative Model Updates: 191,038
Cumulative Timesteps: 1,593,248,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.08610
Policy Entropy: 2.29830
Value Function Loss: 0.01708

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.16778
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 22,873.09438
Overall Steps per Second: 10,521.63175

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.56758
PPO Batch Consumption Time: 0.30120
Total Iteration Time: 4.75478

Cumulative Model Updates: 191,044
Cumulative Timesteps: 1,593,298,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1593298596...
Checkpoint 1593298596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.70612
Policy Entropy: 2.30880
Value Function Loss: 0.01738

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.61136

Collected Steps per Second: 23,091.34918
Overall Steps per Second: 10,718.47659

Timestep Collection Time: 2.16696
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.66839

Cumulative Model Updates: 191,050
Cumulative Timesteps: 1,593,348,634

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.33697
Policy Entropy: 2.32883
Value Function Loss: 0.01617

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.60949

Collected Steps per Second: 23,034.39499
Overall Steps per Second: 10,774.75939

Timestep Collection Time: 2.17180
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.64289

Cumulative Model Updates: 191,056
Cumulative Timesteps: 1,593,398,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1593398660...
Checkpoint 1593398660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.27704
Policy Entropy: 2.31620
Value Function Loss: 0.01630

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 22,869.86292
Overall Steps per Second: 10,884.04701

Timestep Collection Time: 2.18777
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.59700

Cumulative Model Updates: 191,062
Cumulative Timesteps: 1,593,448,694

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.37949
Policy Entropy: 2.30613
Value Function Loss: 0.01583

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.16182
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 23,325.71645
Overall Steps per Second: 10,732.57562

Timestep Collection Time: 2.14501
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.66188

Cumulative Model Updates: 191,068
Cumulative Timesteps: 1,593,498,728

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1593498728...
Checkpoint 1593498728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.06457
Policy Entropy: 2.28242
Value Function Loss: 0.01564

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.51306
Value Function Update Magnitude: 0.62431

Collected Steps per Second: 22,704.55286
Overall Steps per Second: 10,615.28406

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.71151

Cumulative Model Updates: 191,074
Cumulative Timesteps: 1,593,548,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.10361
Policy Entropy: 2.30718
Value Function Loss: 0.01562

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 22,806.54095
Overall Steps per Second: 10,843.81972

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.41866
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.61111

Cumulative Model Updates: 191,080
Cumulative Timesteps: 1,593,598,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1593598744...
Checkpoint 1593598744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.38128
Policy Entropy: 2.30615
Value Function Loss: 0.01484

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.59360

Collected Steps per Second: 22,671.76314
Overall Steps per Second: 10,662.58104

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.68948

Cumulative Model Updates: 191,086
Cumulative Timesteps: 1,593,648,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.48205
Policy Entropy: 2.28937
Value Function Loss: 0.01652

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.60575

Collected Steps per Second: 23,241.90517
Overall Steps per Second: 10,907.31536

Timestep Collection Time: 2.15206
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.58573

Cumulative Model Updates: 191,092
Cumulative Timesteps: 1,593,698,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1593698764...
Checkpoint 1593698764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.10649
Policy Entropy: 2.26211
Value Function Loss: 0.01690

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.63055

Collected Steps per Second: 22,806.69943
Overall Steps per Second: 10,641.40493

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70070

Cumulative Model Updates: 191,098
Cumulative Timesteps: 1,593,748,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.29043
Policy Entropy: 2.26353
Value Function Loss: 0.01748

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.63716

Collected Steps per Second: 22,840.83971
Overall Steps per Second: 10,679.27444

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.68384

Cumulative Model Updates: 191,104
Cumulative Timesteps: 1,593,798,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1593798806...
Checkpoint 1593798806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.98824
Policy Entropy: 2.26029
Value Function Loss: 0.01711

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.64073

Collected Steps per Second: 23,017.41658
Overall Steps per Second: 10,925.77871

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.40416
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.57652

Cumulative Model Updates: 191,110
Cumulative Timesteps: 1,593,848,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.21788
Policy Entropy: 2.25980
Value Function Loss: 0.01659

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.62990

Collected Steps per Second: 22,756.50971
Overall Steps per Second: 10,835.98040

Timestep Collection Time: 2.19849
Timestep Consumption Time: 2.41853
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.61703

Cumulative Model Updates: 191,116
Cumulative Timesteps: 1,593,898,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1593898838...
Checkpoint 1593898838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.19894
Policy Entropy: 2.26169
Value Function Loss: 0.01543

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 22,085.26697
Overall Steps per Second: 10,696.02735

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.67557

Cumulative Model Updates: 191,122
Cumulative Timesteps: 1,593,948,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.13692
Policy Entropy: 2.27730
Value Function Loss: 0.01474

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.53503
Value Function Update Magnitude: 0.57531

Collected Steps per Second: 22,650.96241
Overall Steps per Second: 10,707.37482

Timestep Collection Time: 2.20803
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.67099

Cumulative Model Updates: 191,128
Cumulative Timesteps: 1,593,998,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1593998862...
Checkpoint 1593998862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.78427
Policy Entropy: 2.28430
Value Function Loss: 0.01445

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 22,924.49739
Overall Steps per Second: 10,841.56334

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61188

Cumulative Model Updates: 191,134
Cumulative Timesteps: 1,594,048,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.57503
Policy Entropy: 2.30211
Value Function Loss: 0.01524

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 22,920.03291
Overall Steps per Second: 10,813.52909

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.62495

Cumulative Model Updates: 191,140
Cumulative Timesteps: 1,594,098,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1594098874...
Checkpoint 1594098874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.75247
Policy Entropy: 2.31800
Value Function Loss: 0.01617

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.54211
Value Function Update Magnitude: 0.56373

Collected Steps per Second: 22,953.93190
Overall Steps per Second: 10,731.52246

Timestep Collection Time: 2.17871
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.66010

Cumulative Model Updates: 191,146
Cumulative Timesteps: 1,594,148,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.88324
Policy Entropy: 2.31422
Value Function Loss: 0.01729

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.58527

Collected Steps per Second: 22,868.77837
Overall Steps per Second: 10,903.64497

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.39991
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.58691

Cumulative Model Updates: 191,152
Cumulative Timesteps: 1,594,198,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1594198898...
Checkpoint 1594198898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.83757
Policy Entropy: 2.29562
Value Function Loss: 0.01722

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 22,879.00419
Overall Steps per Second: 10,635.07305

Timestep Collection Time: 2.18593
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.70255

Cumulative Model Updates: 191,158
Cumulative Timesteps: 1,594,248,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.26474
Policy Entropy: 2.26016
Value Function Loss: 0.01638

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.59728

Collected Steps per Second: 23,345.26412
Overall Steps per Second: 10,891.38570

Timestep Collection Time: 2.14210
Timestep Consumption Time: 2.44941
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.59152

Cumulative Model Updates: 191,164
Cumulative Timesteps: 1,594,298,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1594298918...
Checkpoint 1594298918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.98895
Policy Entropy: 2.26118
Value Function Loss: 0.01634

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.57729

Collected Steps per Second: 22,615.14050
Overall Steps per Second: 10,685.28784

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68233

Cumulative Model Updates: 191,170
Cumulative Timesteps: 1,594,348,950

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.85285
Policy Entropy: 2.24794
Value Function Loss: 0.01634

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.57868

Collected Steps per Second: 22,428.91313
Overall Steps per Second: 10,625.02541

Timestep Collection Time: 2.22927
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70587

Cumulative Model Updates: 191,176
Cumulative Timesteps: 1,594,398,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1594398950...
Checkpoint 1594398950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.62563
Policy Entropy: 2.24848
Value Function Loss: 0.01584

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.58987

Collected Steps per Second: 22,683.83195
Overall Steps per Second: 10,910.44993

Timestep Collection Time: 2.20483
Timestep Consumption Time: 2.37922
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.58405

Cumulative Model Updates: 191,182
Cumulative Timesteps: 1,594,448,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.09352
Policy Entropy: 2.26181
Value Function Loss: 0.01625

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.58674

Collected Steps per Second: 22,900.34609
Overall Steps per Second: 10,816.95752

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62441

Cumulative Model Updates: 191,188
Cumulative Timesteps: 1,594,498,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1594498986...
Checkpoint 1594498986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.35827
Policy Entropy: 2.28460
Value Function Loss: 0.01660

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 22,669.54487
Overall Steps per Second: 10,779.37399

Timestep Collection Time: 2.20675
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.64090

Cumulative Model Updates: 191,194
Cumulative Timesteps: 1,594,549,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.04743
Policy Entropy: 2.30182
Value Function Loss: 0.01656

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.57825

Collected Steps per Second: 23,095.05173
Overall Steps per Second: 10,735.78722

Timestep Collection Time: 2.16644
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.66049

Cumulative Model Updates: 191,200
Cumulative Timesteps: 1,594,599,046

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1594599046...
Checkpoint 1594599046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.08559
Policy Entropy: 2.29754
Value Function Loss: 0.01680

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.55969
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 23,004.28534
Overall Steps per Second: 10,746.33785

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.48003
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.65424

Cumulative Model Updates: 191,206
Cumulative Timesteps: 1,594,649,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.81149
Policy Entropy: 2.28834
Value Function Loss: 0.01564

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.55628
Value Function Update Magnitude: 0.58903

Collected Steps per Second: 22,973.68071
Overall Steps per Second: 10,857.03107

Timestep Collection Time: 2.17727
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60715

Cumulative Model Updates: 191,212
Cumulative Timesteps: 1,594,699,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1594699082...
Checkpoint 1594699082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.70792
Policy Entropy: 2.30016
Value Function Loss: 0.01607

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,736.46758
Overall Steps per Second: 10,777.48429

Timestep Collection Time: 2.20034
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.64190

Cumulative Model Updates: 191,218
Cumulative Timesteps: 1,594,749,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.39845
Policy Entropy: 2.29988
Value Function Loss: 0.01592

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.61749

Collected Steps per Second: 22,604.00772
Overall Steps per Second: 10,608.50537

Timestep Collection Time: 2.21297
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71527

Cumulative Model Updates: 191,224
Cumulative Timesteps: 1,594,799,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1594799132...
Checkpoint 1594799132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.08968
Policy Entropy: 2.28028
Value Function Loss: 0.01596

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 22,972.80248
Overall Steps per Second: 10,872.13898

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.59909

Cumulative Model Updates: 191,230
Cumulative Timesteps: 1,594,849,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.99079
Policy Entropy: 2.25724
Value Function Loss: 0.01650

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.62546

Collected Steps per Second: 23,053.97792
Overall Steps per Second: 10,964.64193

Timestep Collection Time: 2.17012
Timestep Consumption Time: 2.39272
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.56285

Cumulative Model Updates: 191,236
Cumulative Timesteps: 1,594,899,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1594899164...
Checkpoint 1594899164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.27145
Policy Entropy: 2.24251
Value Function Loss: 0.01633

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.62851

Collected Steps per Second: 23,039.89428
Overall Steps per Second: 10,741.79091

Timestep Collection Time: 2.17093
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.65639

Cumulative Model Updates: 191,242
Cumulative Timesteps: 1,594,949,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.96850
Policy Entropy: 2.25532
Value Function Loss: 0.01617

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.62457

Collected Steps per Second: 22,789.78719
Overall Steps per Second: 10,763.22433

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.45148
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.64545

Cumulative Model Updates: 191,248
Cumulative Timesteps: 1,594,999,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1594999182...
Checkpoint 1594999182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.63869
Policy Entropy: 2.27457
Value Function Loss: 0.01581

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.61071

Collected Steps per Second: 22,996.09544
Overall Steps per Second: 10,642.26780

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.52417
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.69862

Cumulative Model Updates: 191,254
Cumulative Timesteps: 1,595,049,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.77288
Policy Entropy: 2.29358
Value Function Loss: 0.01734

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.62487

Collected Steps per Second: 23,020.32162
Overall Steps per Second: 10,884.00622

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.42229
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.59463

Cumulative Model Updates: 191,260
Cumulative Timesteps: 1,595,099,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1595099194...
Checkpoint 1595099194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.76288
Policy Entropy: 2.28802
Value Function Loss: 0.01675

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.63872

Collected Steps per Second: 22,847.85099
Overall Steps per Second: 10,878.38677

Timestep Collection Time: 2.18883
Timestep Consumption Time: 2.40836
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.59719

Cumulative Model Updates: 191,266
Cumulative Timesteps: 1,595,149,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.03614
Policy Entropy: 2.29509
Value Function Loss: 0.01610

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.53695
Value Function Update Magnitude: 0.62122

Collected Steps per Second: 23,086.05261
Overall Steps per Second: 10,729.90925

Timestep Collection Time: 2.16676
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.66192

Cumulative Model Updates: 191,272
Cumulative Timesteps: 1,595,199,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1595199226...
Checkpoint 1595199226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.32904
Policy Entropy: 2.28474
Value Function Loss: 0.01475

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.59097

Collected Steps per Second: 22,589.06163
Overall Steps per Second: 10,635.29719

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.70283

Cumulative Model Updates: 191,278
Cumulative Timesteps: 1,595,249,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.35322
Policy Entropy: 2.30410
Value Function Loss: 0.01511

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.56844

Collected Steps per Second: 22,469.09242
Overall Steps per Second: 10,573.95940

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.72992

Cumulative Model Updates: 191,284
Cumulative Timesteps: 1,595,299,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1595299256...
Checkpoint 1595299256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.00749
Policy Entropy: 2.28962
Value Function Loss: 0.01559

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.55037
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 22,810.92979
Overall Steps per Second: 10,774.99727

Timestep Collection Time: 2.19307
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.64279

Cumulative Model Updates: 191,290
Cumulative Timesteps: 1,595,349,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.11970
Policy Entropy: 2.28910
Value Function Loss: 0.01611

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.56517

Collected Steps per Second: 22,855.15877
Overall Steps per Second: 10,860.42098

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.60387

Cumulative Model Updates: 191,296
Cumulative Timesteps: 1,595,399,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1595399282...
Checkpoint 1595399282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.38686
Policy Entropy: 2.27220
Value Function Loss: 0.01649

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.56077

Collected Steps per Second: 23,099.32715
Overall Steps per Second: 10,858.27508

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.60810

Cumulative Model Updates: 191,302
Cumulative Timesteps: 1,595,449,318

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.86094
Policy Entropy: 2.29813
Value Function Loss: 0.01633

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.55825

Collected Steps per Second: 23,178.99021
Overall Steps per Second: 10,869.39400

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60246

Cumulative Model Updates: 191,308
Cumulative Timesteps: 1,595,499,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1595499344...
Checkpoint 1595499344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.07448
Policy Entropy: 2.31607
Value Function Loss: 0.01545

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 22,707.47814
Overall Steps per Second: 10,772.23248

Timestep Collection Time: 2.20262
Timestep Consumption Time: 2.44043
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.64305

Cumulative Model Updates: 191,314
Cumulative Timesteps: 1,595,549,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.54217
Policy Entropy: 2.31637
Value Function Loss: 0.01502

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 22,746.37541
Overall Steps per Second: 10,832.59946

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.41861
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.61773

Cumulative Model Updates: 191,320
Cumulative Timesteps: 1,595,599,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1595599382...
Checkpoint 1595599382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.61108
Policy Entropy: 2.31857
Value Function Loss: 0.01576

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 22,813.39165
Overall Steps per Second: 10,838.33465

Timestep Collection Time: 2.19240
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.61473

Cumulative Model Updates: 191,326
Cumulative Timesteps: 1,595,649,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.56132
Policy Entropy: 2.32707
Value Function Loss: 0.01639

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 23,254.66551
Overall Steps per Second: 10,748.35941

Timestep Collection Time: 2.15054
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.65280

Cumulative Model Updates: 191,332
Cumulative Timesteps: 1,595,699,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1595699408...
Checkpoint 1595699408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.78635
Policy Entropy: 2.35375
Value Function Loss: 0.01614

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 22,899.20756
Overall Steps per Second: 10,660.84656

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.69306

Cumulative Model Updates: 191,338
Cumulative Timesteps: 1,595,749,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.79352
Policy Entropy: 2.33293
Value Function Loss: 0.01510

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.53947
Value Function Update Magnitude: 0.58963

Collected Steps per Second: 23,022.84960
Overall Steps per Second: 10,819.77904

Timestep Collection Time: 2.17202
Timestep Consumption Time: 2.44970
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.62172

Cumulative Model Updates: 191,344
Cumulative Timesteps: 1,595,799,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1595799446...
Checkpoint 1595799446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.12775
Policy Entropy: 2.31128
Value Function Loss: 0.01466

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.53404
Value Function Update Magnitude: 0.56445

Collected Steps per Second: 22,832.37216
Overall Steps per Second: 10,684.61382

Timestep Collection Time: 2.18996
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.67981

Cumulative Model Updates: 191,350
Cumulative Timesteps: 1,595,849,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.79139
Policy Entropy: 2.26202
Value Function Loss: 0.01429

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.55516

Collected Steps per Second: 23,096.39085
Overall Steps per Second: 10,912.74624

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.41696
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.58180

Cumulative Model Updates: 191,356
Cumulative Timesteps: 1,595,899,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1595899448...
Checkpoint 1595899448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.60096
Policy Entropy: 2.25563
Value Function Loss: 0.01468

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.53274

Collected Steps per Second: 23,049.88912
Overall Steps per Second: 10,526.75900

Timestep Collection Time: 2.16929
Timestep Consumption Time: 2.58070
PPO Batch Consumption Time: 0.30357
Total Iteration Time: 4.74999

Cumulative Model Updates: 191,362
Cumulative Timesteps: 1,595,949,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.57792
Policy Entropy: 2.25358
Value Function Loss: 0.01477

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.54083
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 22,547.37961
Overall Steps per Second: 10,569.23706

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.73185

Cumulative Model Updates: 191,368
Cumulative Timesteps: 1,595,999,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1595999462...
Checkpoint 1595999462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.10079
Policy Entropy: 2.26866
Value Function Loss: 0.01575

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.54117

Collected Steps per Second: 22,623.88061
Overall Steps per Second: 10,622.04180

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.70757

Cumulative Model Updates: 191,374
Cumulative Timesteps: 1,596,049,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.41880
Policy Entropy: 2.28428
Value Function Loss: 0.01600

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.55473

Collected Steps per Second: 22,802.05057
Overall Steps per Second: 10,823.23480

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.62061

Cumulative Model Updates: 191,380
Cumulative Timesteps: 1,596,099,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1596099476...
Checkpoint 1596099476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.74682
Policy Entropy: 2.28876
Value Function Loss: 0.01646

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.55478

Collected Steps per Second: 22,654.89092
Overall Steps per Second: 10,769.66994

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.64508

Cumulative Model Updates: 191,386
Cumulative Timesteps: 1,596,149,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.00332
Policy Entropy: 2.28522
Value Function Loss: 0.01579

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 23,016.55163
Overall Steps per Second: 10,843.87526

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.61219

Cumulative Model Updates: 191,392
Cumulative Timesteps: 1,596,199,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1596199516...
Checkpoint 1596199516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.82145
Policy Entropy: 2.28599
Value Function Loss: 0.01571

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 22,833.74199
Overall Steps per Second: 10,631.59060

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.51352
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.70353

Cumulative Model Updates: 191,398
Cumulative Timesteps: 1,596,249,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.55588
Policy Entropy: 2.30431
Value Function Loss: 0.01556

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 22,776.26269
Overall Steps per Second: 10,635.89305

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70332

Cumulative Model Updates: 191,404
Cumulative Timesteps: 1,596,299,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1596299546...
Checkpoint 1596299546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.42457
Policy Entropy: 2.32907
Value Function Loss: 0.01570

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.55389

Collected Steps per Second: 22,996.51811
Overall Steps per Second: 10,935.75392

Timestep Collection Time: 2.17537
Timestep Consumption Time: 2.39916
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.57454

Cumulative Model Updates: 191,410
Cumulative Timesteps: 1,596,349,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.25398
Policy Entropy: 2.33391
Value Function Loss: 0.01593

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.58156

Collected Steps per Second: 23,094.26921
Overall Steps per Second: 10,867.53467

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.43699
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60307

Cumulative Model Updates: 191,416
Cumulative Timesteps: 1,596,399,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1596399596...
Checkpoint 1596399596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.17538
Policy Entropy: 2.33481
Value Function Loss: 0.01581

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.16598
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,674.25020
Overall Steps per Second: 10,669.55615

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.68679

Cumulative Model Updates: 191,422
Cumulative Timesteps: 1,596,449,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.18003
Policy Entropy: 2.30686
Value Function Loss: 0.01617

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.17790
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 22,899.85441
Overall Steps per Second: 10,803.62215

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.63011

Cumulative Model Updates: 191,428
Cumulative Timesteps: 1,596,499,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1596499624...
Checkpoint 1596499624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.80826
Policy Entropy: 2.28970
Value Function Loss: 0.01586

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.17879
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.57164

Collected Steps per Second: 22,733.01235
Overall Steps per Second: 10,754.17437

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.65140

Cumulative Model Updates: 191,434
Cumulative Timesteps: 1,596,549,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.16202
Policy Entropy: 2.26473
Value Function Loss: 0.01706

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.58539

Collected Steps per Second: 22,867.45042
Overall Steps per Second: 10,877.77728

Timestep Collection Time: 2.18669
Timestep Consumption Time: 2.41021
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.59690

Cumulative Model Updates: 191,440
Cumulative Timesteps: 1,596,599,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1596599650...
Checkpoint 1596599650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.29559
Policy Entropy: 2.25495
Value Function Loss: 0.01572

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.58161

Collected Steps per Second: 22,690.41730
Overall Steps per Second: 10,220.21393

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.68869
PPO Batch Consumption Time: 0.32501
Total Iteration Time: 4.89227

Cumulative Model Updates: 191,446
Cumulative Timesteps: 1,596,649,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.15566
Policy Entropy: 2.25968
Value Function Loss: 0.01561

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.57014

Collected Steps per Second: 21,493.46251
Overall Steps per Second: 10,485.08479

Timestep Collection Time: 2.32638
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.76887

Cumulative Model Updates: 191,452
Cumulative Timesteps: 1,596,699,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1596699652...
Checkpoint 1596699652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.20212
Policy Entropy: 2.26589
Value Function Loss: 0.01440

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.55812

Collected Steps per Second: 22,464.97247
Overall Steps per Second: 10,631.69032

Timestep Collection Time: 2.22658
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.70480

Cumulative Model Updates: 191,458
Cumulative Timesteps: 1,596,749,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.47433
Policy Entropy: 2.27957
Value Function Loss: 0.01570

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.56833

Collected Steps per Second: 23,031.83640
Overall Steps per Second: 10,887.41820

Timestep Collection Time: 2.17117
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59301

Cumulative Model Updates: 191,464
Cumulative Timesteps: 1,596,799,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1596799678...
Checkpoint 1596799678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.53314
Policy Entropy: 2.30087
Value Function Loss: 0.01576

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.56918

Collected Steps per Second: 23,200.97576
Overall Steps per Second: 11,089.06940

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.35462
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.51039

Cumulative Model Updates: 191,470
Cumulative Timesteps: 1,596,849,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.11697
Policy Entropy: 2.29684
Value Function Loss: 0.01639

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 23,234.45607
Overall Steps per Second: 10,905.03888

Timestep Collection Time: 2.15301
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.58724

Cumulative Model Updates: 191,476
Cumulative Timesteps: 1,596,899,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1596899718...
Checkpoint 1596899718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.72012
Policy Entropy: 2.31153
Value Function Loss: 0.01566

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.54485
Value Function Update Magnitude: 0.55653

Collected Steps per Second: 23,229.17167
Overall Steps per Second: 10,735.43159

Timestep Collection Time: 2.15272
Timestep Consumption Time: 2.50531
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.65803

Cumulative Model Updates: 191,482
Cumulative Timesteps: 1,596,949,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.04207
Policy Entropy: 2.29019
Value Function Loss: 0.01607

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.55592

Collected Steps per Second: 23,339.57595
Overall Steps per Second: 10,886.50474

Timestep Collection Time: 2.14323
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.59486

Cumulative Model Updates: 191,488
Cumulative Timesteps: 1,596,999,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1596999746...
Checkpoint 1596999746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.82339
Policy Entropy: 2.29946
Value Function Loss: 0.01600

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.53598
Value Function Update Magnitude: 0.56310

Collected Steps per Second: 23,099.96036
Overall Steps per Second: 10,755.96417

Timestep Collection Time: 2.16485
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.64933

Cumulative Model Updates: 191,494
Cumulative Timesteps: 1,597,049,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.27234
Policy Entropy: 2.28327
Value Function Loss: 0.01556

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.56793

Collected Steps per Second: 23,238.14884
Overall Steps per Second: 10,969.45106

Timestep Collection Time: 2.15258
Timestep Consumption Time: 2.40754
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.56012

Cumulative Model Updates: 191,500
Cumulative Timesteps: 1,597,099,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1597099776...
Checkpoint 1597099776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.31968
Policy Entropy: 2.25882
Value Function Loss: 0.01530

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.53180
Value Function Update Magnitude: 0.56090

Collected Steps per Second: 22,820.78038
Overall Steps per Second: 10,808.00277

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62879

Cumulative Model Updates: 191,506
Cumulative Timesteps: 1,597,149,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.62125
Policy Entropy: 2.27213
Value Function Loss: 0.01569

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.56012

Collected Steps per Second: 23,037.33848
Overall Steps per Second: 10,725.45758

Timestep Collection Time: 2.17091
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.66292

Cumulative Model Updates: 191,512
Cumulative Timesteps: 1,597,199,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1597199816...
Checkpoint 1597199816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.69688
Policy Entropy: 2.26033
Value Function Loss: 0.01672

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 23,284.18151
Overall Steps per Second: 10,899.61279

Timestep Collection Time: 2.14764
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58787

Cumulative Model Updates: 191,518
Cumulative Timesteps: 1,597,249,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.82564
Policy Entropy: 2.26610
Value Function Loss: 0.01592

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.58937

Collected Steps per Second: 23,049.60716
Overall Steps per Second: 10,923.11239

Timestep Collection Time: 2.17028
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.57965

Cumulative Model Updates: 191,524
Cumulative Timesteps: 1,597,299,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1597299846...
Checkpoint 1597299846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.49365
Policy Entropy: 2.24233
Value Function Loss: 0.01627

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 23,225.03866
Overall Steps per Second: 11,090.66178

Timestep Collection Time: 2.15380
Timestep Consumption Time: 2.35648
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.51028

Cumulative Model Updates: 191,530
Cumulative Timesteps: 1,597,349,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.72805
Policy Entropy: 2.22657
Value Function Loss: 0.01601

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.62805

Collected Steps per Second: 23,288.74500
Overall Steps per Second: 10,927.49125

Timestep Collection Time: 2.14748
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.57671

Cumulative Model Updates: 191,536
Cumulative Timesteps: 1,597,399,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1597399880...
Checkpoint 1597399880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.62839
Policy Entropy: 2.23149
Value Function Loss: 0.01596

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 23,290.22086
Overall Steps per Second: 10,818.40758

Timestep Collection Time: 2.14708
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.62231

Cumulative Model Updates: 191,542
Cumulative Timesteps: 1,597,449,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.85480
Policy Entropy: 2.26437
Value Function Loss: 0.01537

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.59262

Collected Steps per Second: 23,403.64923
Overall Steps per Second: 10,848.59070

Timestep Collection Time: 2.13753
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.61129

Cumulative Model Updates: 191,548
Cumulative Timesteps: 1,597,499,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1597499912...
Checkpoint 1597499912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.17889
Policy Entropy: 2.30096
Value Function Loss: 0.01445

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.55441

Collected Steps per Second: 23,215.10226
Overall Steps per Second: 10,951.89698

Timestep Collection Time: 2.15411
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.56615

Cumulative Model Updates: 191,554
Cumulative Timesteps: 1,597,549,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.87274
Policy Entropy: 2.30660
Value Function Loss: 0.01470

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.53106
Value Function Update Magnitude: 0.52331

Collected Steps per Second: 23,762.73946
Overall Steps per Second: 10,977.25106

Timestep Collection Time: 2.10439
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.55542

Cumulative Model Updates: 191,560
Cumulative Timesteps: 1,597,599,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1597599926...
Checkpoint 1597599926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.15630
Policy Entropy: 2.26835
Value Function Loss: 0.01532

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.52548

Collected Steps per Second: 22,933.45124
Overall Steps per Second: 10,692.68826

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.67927

Cumulative Model Updates: 191,566
Cumulative Timesteps: 1,597,649,960

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.06185
Policy Entropy: 2.27639
Value Function Loss: 0.01598

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.54279

Collected Steps per Second: 23,223.21017
Overall Steps per Second: 10,817.24498

Timestep Collection Time: 2.15405
Timestep Consumption Time: 2.47042
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.62447

Cumulative Model Updates: 191,572
Cumulative Timesteps: 1,597,699,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1597699984...
Checkpoint 1597699984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.41904
Policy Entropy: 2.27166
Value Function Loss: 0.01590

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 22,883.03240
Overall Steps per Second: 10,767.88933

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.64474

Cumulative Model Updates: 191,578
Cumulative Timesteps: 1,597,749,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.89404
Policy Entropy: 2.28195
Value Function Loss: 0.01501

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15574
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 23,110.69919
Overall Steps per Second: 10,822.24542

Timestep Collection Time: 2.16350
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.62011

Cumulative Model Updates: 191,584
Cumulative Timesteps: 1,597,799,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1597799998...
Checkpoint 1597799998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.52934
Policy Entropy: 2.27049
Value Function Loss: 0.01490

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 24,007.21550
Overall Steps per Second: 11,117.68760

Timestep Collection Time: 2.08396
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.50004

Cumulative Model Updates: 191,590
Cumulative Timesteps: 1,597,850,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.24382
Policy Entropy: 2.26706
Value Function Loss: 0.01584

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.54646
Value Function Update Magnitude: 0.56564

Collected Steps per Second: 23,214.27619
Overall Steps per Second: 10,904.74488

Timestep Collection Time: 2.15523
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.58809

Cumulative Model Updates: 191,596
Cumulative Timesteps: 1,597,900,060

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1597900060...
Checkpoint 1597900060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.91595
Policy Entropy: 2.25658
Value Function Loss: 0.01572

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.56455

Collected Steps per Second: 23,342.02560
Overall Steps per Second: 10,812.96020

Timestep Collection Time: 2.14240
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.62482

Cumulative Model Updates: 191,602
Cumulative Timesteps: 1,597,950,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.61926
Policy Entropy: 2.26016
Value Function Loss: 0.01633

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.16058
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.57526

Collected Steps per Second: 22,868.64536
Overall Steps per Second: 10,736.33684

Timestep Collection Time: 2.18745
Timestep Consumption Time: 2.47187
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.65932

Cumulative Model Updates: 191,608
Cumulative Timesteps: 1,598,000,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1598000092...
Checkpoint 1598000092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.63998
Policy Entropy: 2.22583
Value Function Loss: 0.01591

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15516
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 0.56140

Collected Steps per Second: 23,153.62762
Overall Steps per Second: 11,074.23857

Timestep Collection Time: 2.15958
Timestep Consumption Time: 2.35559
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.51516

Cumulative Model Updates: 191,614
Cumulative Timesteps: 1,598,050,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.01140
Policy Entropy: 2.22298
Value Function Loss: 0.01593

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.54934
Value Function Update Magnitude: 0.54832

Collected Steps per Second: 23,383.80139
Overall Steps per Second: 10,915.52206

Timestep Collection Time: 2.13875
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.58173

Cumulative Model Updates: 191,620
Cumulative Timesteps: 1,598,100,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1598100106...
Checkpoint 1598100106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.03940
Policy Entropy: 2.22151
Value Function Loss: 0.01508

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.53462
Value Function Update Magnitude: 0.52873

Collected Steps per Second: 23,275.75715
Overall Steps per Second: 10,800.84552

Timestep Collection Time: 2.14936
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.63186

Cumulative Model Updates: 191,626
Cumulative Timesteps: 1,598,150,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.39245
Policy Entropy: 2.28171
Value Function Loss: 0.01455

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.49983

Collected Steps per Second: 23,070.55714
Overall Steps per Second: 10,783.40723

Timestep Collection Time: 2.16839
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.63916

Cumulative Model Updates: 191,632
Cumulative Timesteps: 1,598,200,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1598200160...
Checkpoint 1598200160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.13749
Policy Entropy: 2.30171
Value Function Loss: 0.01472

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.52486
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 23,067.54764
Overall Steps per Second: 10,850.64027

Timestep Collection Time: 2.16876
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.61060

Cumulative Model Updates: 191,638
Cumulative Timesteps: 1,598,250,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.96314
Policy Entropy: 2.32807
Value Function Loss: 0.01414

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.52220
Value Function Update Magnitude: 0.54292

Collected Steps per Second: 23,271.82378
Overall Steps per Second: 11,078.63209

Timestep Collection Time: 2.14955
Timestep Consumption Time: 2.36581
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.51536

Cumulative Model Updates: 191,644
Cumulative Timesteps: 1,598,300,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1598300212...
Checkpoint 1598300212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.00512
Policy Entropy: 2.29994
Value Function Loss: 0.01461

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.53223
Value Function Update Magnitude: 0.52177

Collected Steps per Second: 23,079.14444
Overall Steps per Second: 10,671.16657

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68609

Cumulative Model Updates: 191,650
Cumulative Timesteps: 1,598,350,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.62851
Policy Entropy: 2.29789
Value Function Loss: 0.01450

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.51800

Collected Steps per Second: 23,048.44130
Overall Steps per Second: 10,880.76072

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59802

Cumulative Model Updates: 191,656
Cumulative Timesteps: 1,598,400,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1598400248...
Checkpoint 1598400248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.44416
Policy Entropy: 2.25457
Value Function Loss: 0.01532

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.52894

Collected Steps per Second: 22,843.86001
Overall Steps per Second: 10,690.25110

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.67735

Cumulative Model Updates: 191,662
Cumulative Timesteps: 1,598,450,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.24019
Policy Entropy: 2.27229
Value Function Loss: 0.01568

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.51852

Collected Steps per Second: 23,386.52678
Overall Steps per Second: 10,930.14708

Timestep Collection Time: 2.13824
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.57505

Cumulative Model Updates: 191,668
Cumulative Timesteps: 1,598,500,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1598500256...
Checkpoint 1598500256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.12882
Policy Entropy: 2.24458
Value Function Loss: 0.01626

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.52098

Collected Steps per Second: 23,300.38418
Overall Steps per Second: 11,132.20728

Timestep Collection Time: 2.14597
Timestep Consumption Time: 2.34568
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.49165

Cumulative Model Updates: 191,674
Cumulative Timesteps: 1,598,550,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.47611
Policy Entropy: 2.25424
Value Function Loss: 0.01619

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 23,199.83626
Overall Steps per Second: 10,903.91921

Timestep Collection Time: 2.15605
Timestep Consumption Time: 2.43129
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.58734

Cumulative Model Updates: 191,680
Cumulative Timesteps: 1,598,600,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1598600278...
Checkpoint 1598600278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.33204
Policy Entropy: 2.24232
Value Function Loss: 0.01669

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.55722
Value Function Update Magnitude: 0.55522

Collected Steps per Second: 23,012.71920
Overall Steps per Second: 10,716.89446

Timestep Collection Time: 2.17358
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.66740

Cumulative Model Updates: 191,686
Cumulative Timesteps: 1,598,650,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.75267
Policy Entropy: 2.26191
Value Function Loss: 0.01660

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.53525

Collected Steps per Second: 23,183.22830
Overall Steps per Second: 10,817.29030

Timestep Collection Time: 2.15716
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.62315

Cumulative Model Updates: 191,692
Cumulative Timesteps: 1,598,700,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1598700308...
Checkpoint 1598700308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.98728
Policy Entropy: 2.25252
Value Function Loss: 0.01580

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.50903

Collected Steps per Second: 23,128.53914
Overall Steps per Second: 11,066.13300

Timestep Collection Time: 2.16218
Timestep Consumption Time: 2.35684
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.51901

Cumulative Model Updates: 191,698
Cumulative Timesteps: 1,598,750,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.12394
Policy Entropy: 2.25654
Value Function Loss: 0.01623

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.50474

Collected Steps per Second: 23,061.22362
Overall Steps per Second: 10,872.63260

Timestep Collection Time: 2.16823
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.59889

Cumulative Model Updates: 191,704
Cumulative Timesteps: 1,598,800,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1598800318...
Checkpoint 1598800318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.77825
Policy Entropy: 2.25910
Value Function Loss: 0.01553

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.54033
Value Function Update Magnitude: 0.51828

Collected Steps per Second: 23,133.33268
Overall Steps per Second: 10,729.57139

Timestep Collection Time: 2.16225
Timestep Consumption Time: 2.49963
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.66188

Cumulative Model Updates: 191,710
Cumulative Timesteps: 1,598,850,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.61460
Policy Entropy: 2.26106
Value Function Loss: 0.01592

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.54210

Collected Steps per Second: 23,318.47145
Overall Steps per Second: 10,896.20728

Timestep Collection Time: 2.14499
Timestep Consumption Time: 2.44541
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.59040

Cumulative Model Updates: 191,716
Cumulative Timesteps: 1,598,900,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1598900356...
Checkpoint 1598900356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.83881
Policy Entropy: 2.25302
Value Function Loss: 0.01578

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.55650

Collected Steps per Second: 23,418.55585
Overall Steps per Second: 11,095.44473

Timestep Collection Time: 2.13625
Timestep Consumption Time: 2.37262
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.50888

Cumulative Model Updates: 191,722
Cumulative Timesteps: 1,598,950,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.69650
Policy Entropy: 2.23565
Value Function Loss: 0.01553

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.57621

Collected Steps per Second: 23,351.90013
Overall Steps per Second: 10,952.18916

Timestep Collection Time: 2.14304
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.56931

Cumulative Model Updates: 191,728
Cumulative Timesteps: 1,599,000,428

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1599000428...
Checkpoint 1599000428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.73185
Policy Entropy: 2.26059
Value Function Loss: 0.01570

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.54720
Value Function Update Magnitude: 0.55959

Collected Steps per Second: 23,342.89372
Overall Steps per Second: 10,859.11608

Timestep Collection Time: 2.14284
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.60627

Cumulative Model Updates: 191,734
Cumulative Timesteps: 1,599,050,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.37357
Policy Entropy: 2.26760
Value Function Loss: 0.01623

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.54048

Collected Steps per Second: 23,514.53091
Overall Steps per Second: 11,020.85483

Timestep Collection Time: 2.12686
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.53794

Cumulative Model Updates: 191,740
Cumulative Timesteps: 1,599,100,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1599100460...
Checkpoint 1599100460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.24779
Policy Entropy: 2.26764
Value Function Loss: 0.01784

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.15280
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.53048

Collected Steps per Second: 23,327.00799
Overall Steps per Second: 10,797.89802

Timestep Collection Time: 2.14481
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.63349

Cumulative Model Updates: 191,746
Cumulative Timesteps: 1,599,150,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.24599
Policy Entropy: 2.25566
Value Function Loss: 0.01737

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.19511
Policy Update Magnitude: 0.50634
Value Function Update Magnitude: 0.53842

Collected Steps per Second: 23,070.49282
Overall Steps per Second: 10,860.18394

Timestep Collection Time: 2.16788
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.60526

Cumulative Model Updates: 191,752
Cumulative Timesteps: 1,599,200,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1599200506...
Checkpoint 1599200506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.76540
Policy Entropy: 2.24705
Value Function Loss: 0.01752

Mean KL Divergence: 0.02762
SB3 Clip Fraction: 0.18376
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.56598

Collected Steps per Second: 23,121.90139
Overall Steps per Second: 10,751.17638

Timestep Collection Time: 2.16323
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.65233

Cumulative Model Updates: 191,758
Cumulative Timesteps: 1,599,250,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.29146
Policy Entropy: 2.24207
Value Function Loss: 0.01671

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.18861
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.58180

Collected Steps per Second: 23,455.57255
Overall Steps per Second: 10,795.51126

Timestep Collection Time: 2.13195
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.63211

Cumulative Model Updates: 191,764
Cumulative Timesteps: 1,599,300,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1599300530...
Checkpoint 1599300530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.14221
Policy Entropy: 2.26151
Value Function Loss: 0.01720

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.18288
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.60147

Collected Steps per Second: 23,244.29435
Overall Steps per Second: 10,833.09757

Timestep Collection Time: 2.15124
Timestep Consumption Time: 2.46462
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.61585

Cumulative Model Updates: 191,770
Cumulative Timesteps: 1,599,350,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.02771
Policy Entropy: 2.28686
Value Function Loss: 0.01627

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 23,354.45573
Overall Steps per Second: 10,817.14295

Timestep Collection Time: 2.14212
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.62488

Cumulative Model Updates: 191,776
Cumulative Timesteps: 1,599,400,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1599400562...
Checkpoint 1599400562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.54266
Policy Entropy: 2.30504
Value Function Loss: 0.01584

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.55988
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 23,331.89890
Overall Steps per Second: 11,020.96767

Timestep Collection Time: 2.14393
Timestep Consumption Time: 2.39487
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.53880

Cumulative Model Updates: 191,782
Cumulative Timesteps: 1,599,450,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.22137
Policy Entropy: 2.29581
Value Function Loss: 0.01472

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 23,314.01684
Overall Steps per Second: 10,965.13100

Timestep Collection Time: 2.14566
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.56210

Cumulative Model Updates: 191,788
Cumulative Timesteps: 1,599,500,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1599500608...
Checkpoint 1599500608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.48575
Policy Entropy: 2.29477
Value Function Loss: 0.01461

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.54291
Value Function Update Magnitude: 0.56389

Collected Steps per Second: 23,202.01113
Overall Steps per Second: 10,795.48385

Timestep Collection Time: 2.15585
Timestep Consumption Time: 2.47757
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.63342

Cumulative Model Updates: 191,794
Cumulative Timesteps: 1,599,550,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.00038
Policy Entropy: 2.30094
Value Function Loss: 0.01478

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.58514

Collected Steps per Second: 23,252.71821
Overall Steps per Second: 10,864.60665

Timestep Collection Time: 2.15149
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.60468

Cumulative Model Updates: 191,800
Cumulative Timesteps: 1,599,600,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1599600656...
Checkpoint 1599600656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.05600
Policy Entropy: 2.31705
Value Function Loss: 0.01516

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.60037

Collected Steps per Second: 23,046.29584
Overall Steps per Second: 10,942.05215

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.40075
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.57099

Cumulative Model Updates: 191,806
Cumulative Timesteps: 1,599,650,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.90381
Policy Entropy: 2.32334
Value Function Loss: 0.01592

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 23,476.31984
Overall Steps per Second: 10,909.81823

Timestep Collection Time: 2.12989
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.58321

Cumulative Model Updates: 191,812
Cumulative Timesteps: 1,599,700,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1599700674...
Checkpoint 1599700674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.20822
Policy Entropy: 2.30684
Value Function Loss: 0.01636

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.60051

Collected Steps per Second: 23,271.99719
Overall Steps per Second: 10,803.92760

Timestep Collection Time: 2.14850
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.62795

Cumulative Model Updates: 191,818
Cumulative Timesteps: 1,599,750,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.24853
Policy Entropy: 2.28810
Value Function Loss: 0.01688

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 23,188.09413
Overall Steps per Second: 10,744.90322

Timestep Collection Time: 2.15766
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.65635

Cumulative Model Updates: 191,824
Cumulative Timesteps: 1,599,800,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1599800706...
Checkpoint 1599800706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.33923
Policy Entropy: 2.27215
Value Function Loss: 0.01636

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14702
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.59838

Collected Steps per Second: 23,279.80396
Overall Steps per Second: 10,786.04023

Timestep Collection Time: 2.14847
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.63710

Cumulative Model Updates: 191,830
Cumulative Timesteps: 1,599,850,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.62553
Policy Entropy: 2.28863
Value Function Loss: 0.01566

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 23,329.80920
Overall Steps per Second: 10,977.54570

Timestep Collection Time: 2.14370
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.55585

Cumulative Model Updates: 191,836
Cumulative Timesteps: 1,599,900,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1599900734...
Checkpoint 1599900734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.98620
Policy Entropy: 2.27486
Value Function Loss: 0.01570

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 23,582.20437
Overall Steps per Second: 10,891.09198

Timestep Collection Time: 2.12075
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.59201

Cumulative Model Updates: 191,842
Cumulative Timesteps: 1,599,950,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.64263
Policy Entropy: 2.28317
Value Function Loss: 0.01484

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.56019
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 23,320.96534
Overall Steps per Second: 10,902.02069

Timestep Collection Time: 2.14459
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.58759

Cumulative Model Updates: 191,848
Cumulative Timesteps: 1,600,000,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1600000760...
Checkpoint 1600000760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.01161
Policy Entropy: 2.28439
Value Function Loss: 0.01521

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.57245

Collected Steps per Second: 23,233.06818
Overall Steps per Second: 10,811.96832

Timestep Collection Time: 2.15322
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.62691

Cumulative Model Updates: 191,854
Cumulative Timesteps: 1,600,050,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.85826
Policy Entropy: 2.28633
Value Function Loss: 0.01490

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.56884

Collected Steps per Second: 23,276.65267
Overall Steps per Second: 10,812.95520

Timestep Collection Time: 2.14850
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.62501

Cumulative Model Updates: 191,860
Cumulative Timesteps: 1,600,100,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1600100796...
Checkpoint 1600100796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 678.39962
Policy Entropy: 2.28785
Value Function Loss: 0.01495

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.55625

Collected Steps per Second: 22,967.28888
Overall Steps per Second: 11,019.47162

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.36155
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.53960

Cumulative Model Updates: 191,866
Cumulative Timesteps: 1,600,150,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.77096
Policy Entropy: 2.28844
Value Function Loss: 0.01506

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.54675

Collected Steps per Second: 23,182.61619
Overall Steps per Second: 10,966.20947

Timestep Collection Time: 2.15679
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.55946

Cumulative Model Updates: 191,872
Cumulative Timesteps: 1,600,200,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1600200820...
Checkpoint 1600200820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.35111
Policy Entropy: 2.28784
Value Function Loss: 0.01597

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.53649

Collected Steps per Second: 23,182.24693
Overall Steps per Second: 10,767.14161

Timestep Collection Time: 2.15700
Timestep Consumption Time: 2.48713
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.64413

Cumulative Model Updates: 191,878
Cumulative Timesteps: 1,600,250,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.54103
Policy Entropy: 2.28860
Value Function Loss: 0.01587

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.53000

Collected Steps per Second: 22,790.18577
Overall Steps per Second: 10,705.17024

Timestep Collection Time: 2.19480
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.67251

Cumulative Model Updates: 191,884
Cumulative Timesteps: 1,600,300,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1600300844...
Checkpoint 1600300844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.63962
Policy Entropy: 2.30056
Value Function Loss: 0.01542

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.54578

Collected Steps per Second: 23,303.05340
Overall Steps per Second: 11,066.74547

Timestep Collection Time: 2.14676
Timestep Consumption Time: 2.37363
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.52039

Cumulative Model Updates: 191,890
Cumulative Timesteps: 1,600,350,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.34447
Policy Entropy: 2.31064
Value Function Loss: 0.01482

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.55429

Collected Steps per Second: 23,136.93926
Overall Steps per Second: 10,927.58468

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.57850

Cumulative Model Updates: 191,896
Cumulative Timesteps: 1,600,400,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1600400902...
Checkpoint 1600400902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.91081
Policy Entropy: 2.28602
Value Function Loss: 0.01509

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.55209

Collected Steps per Second: 22,991.07335
Overall Steps per Second: 10,675.48581

Timestep Collection Time: 2.17476
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68363

Cumulative Model Updates: 191,902
Cumulative Timesteps: 1,600,450,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.07322
Policy Entropy: 2.27175
Value Function Loss: 0.01485

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.54985

Collected Steps per Second: 23,113.59982
Overall Steps per Second: 10,858.18490

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.60740

Cumulative Model Updates: 191,908
Cumulative Timesteps: 1,600,500,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1600500930...
Checkpoint 1600500930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.96194
Policy Entropy: 2.25142
Value Function Loss: 0.01578

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.54700

Collected Steps per Second: 23,275.87182
Overall Steps per Second: 10,873.94139

Timestep Collection Time: 2.14832
Timestep Consumption Time: 2.45020
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.59852

Cumulative Model Updates: 191,914
Cumulative Timesteps: 1,600,550,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.38058
Policy Entropy: 2.28480
Value Function Loss: 0.01614

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.53818

Collected Steps per Second: 23,143.09946
Overall Steps per Second: 10,960.11675

Timestep Collection Time: 2.16090
Timestep Consumption Time: 2.40200
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.56291

Cumulative Model Updates: 191,920
Cumulative Timesteps: 1,600,600,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1600600944...
Checkpoint 1600600944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.69430
Policy Entropy: 2.27928
Value Function Loss: 0.01641

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.53708

Collected Steps per Second: 23,668.39822
Overall Steps per Second: 10,902.44492

Timestep Collection Time: 2.11294
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.58704

Cumulative Model Updates: 191,926
Cumulative Timesteps: 1,600,650,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.00470
Policy Entropy: 2.28410
Value Function Loss: 0.01583

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.54146

Collected Steps per Second: 23,485.98031
Overall Steps per Second: 10,892.98812

Timestep Collection Time: 2.13004
Timestep Consumption Time: 2.46246
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.59250

Cumulative Model Updates: 191,932
Cumulative Timesteps: 1,600,700,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1600700980...
Checkpoint 1600700980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.08867
Policy Entropy: 2.25852
Value Function Loss: 0.01557

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 23,086.25926
Overall Steps per Second: 10,698.50722

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.50916
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.67617

Cumulative Model Updates: 191,938
Cumulative Timesteps: 1,600,751,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.08505
Policy Entropy: 2.25177
Value Function Loss: 0.01570

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.54471

Collected Steps per Second: 22,881.91396
Overall Steps per Second: 10,852.22005

Timestep Collection Time: 2.18522
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.60754

Cumulative Model Updates: 191,944
Cumulative Timesteps: 1,600,801,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1600801010...
Checkpoint 1600801010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.68110
Policy Entropy: 2.26783
Value Function Loss: 0.01623

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.55258

Collected Steps per Second: 23,165.31570
Overall Steps per Second: 11,110.69988

Timestep Collection Time: 2.15900
Timestep Consumption Time: 2.34242
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.50143

Cumulative Model Updates: 191,950
Cumulative Timesteps: 1,600,851,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.49815
Policy Entropy: 2.28497
Value Function Loss: 0.01622

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.54467

Collected Steps per Second: 23,629.64012
Overall Steps per Second: 10,923.83619

Timestep Collection Time: 2.11616
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.57751

Cumulative Model Updates: 191,956
Cumulative Timesteps: 1,600,901,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1600901028...
Checkpoint 1600901028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.16714
Policy Entropy: 2.29973
Value Function Loss: 0.01747

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.55076
Value Function Update Magnitude: 0.52211

Collected Steps per Second: 22,997.78145
Overall Steps per Second: 10,684.50456

Timestep Collection Time: 2.17525
Timestep Consumption Time: 2.50685
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.68211

Cumulative Model Updates: 191,962
Cumulative Timesteps: 1,600,951,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.16060
Policy Entropy: 2.29120
Value Function Loss: 0.01677

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.52992

Collected Steps per Second: 22,985.32817
Overall Steps per Second: 10,811.36530

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.62661

Cumulative Model Updates: 191,968
Cumulative Timesteps: 1,601,001,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1601001074...
Checkpoint 1601001074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.26925
Policy Entropy: 2.25592
Value Function Loss: 0.01600

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.53455

Collected Steps per Second: 23,168.48486
Overall Steps per Second: 10,815.85278

Timestep Collection Time: 2.15879
Timestep Consumption Time: 2.46553
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.62432

Cumulative Model Updates: 191,974
Cumulative Timesteps: 1,601,051,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.29761
Policy Entropy: 2.23669
Value Function Loss: 0.01475

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.54581
Value Function Update Magnitude: 0.53381

Collected Steps per Second: 23,010.95190
Overall Steps per Second: 10,921.62462

Timestep Collection Time: 2.17297
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.57826

Cumulative Model Updates: 191,980
Cumulative Timesteps: 1,601,101,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1601101092...
Checkpoint 1601101092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.00273
Policy Entropy: 2.24324
Value Function Loss: 0.01413

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.53441

Collected Steps per Second: 23,466.12240
Overall Steps per Second: 11,014.02731

Timestep Collection Time: 2.13150
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.54130

Cumulative Model Updates: 191,986
Cumulative Timesteps: 1,601,151,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.28606
Policy Entropy: 2.25708
Value Function Loss: 0.01523

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.54290
Value Function Update Magnitude: 0.54218

Collected Steps per Second: 22,968.60021
Overall Steps per Second: 10,842.03339

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61426

Cumulative Model Updates: 191,992
Cumulative Timesteps: 1,601,201,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1601201138...
Checkpoint 1601201138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.97763
Policy Entropy: 2.25865
Value Function Loss: 0.01473

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.55909

Collected Steps per Second: 23,068.18485
Overall Steps per Second: 10,831.84215

Timestep Collection Time: 2.16749
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.61602

Cumulative Model Updates: 191,998
Cumulative Timesteps: 1,601,251,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.55097
Policy Entropy: 2.26528
Value Function Loss: 0.01511

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.54918

Collected Steps per Second: 23,563.31546
Overall Steps per Second: 10,917.39015

Timestep Collection Time: 2.12262
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.58131

Cumulative Model Updates: 192,004
Cumulative Timesteps: 1,601,301,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1601301154...
Checkpoint 1601301154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.99036
Policy Entropy: 2.28787
Value Function Loss: 0.01474

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 23,347.49793
Overall Steps per Second: 10,959.06163

Timestep Collection Time: 2.14224
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.56389

Cumulative Model Updates: 192,010
Cumulative Timesteps: 1,601,351,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.33186
Policy Entropy: 2.28166
Value Function Loss: 0.01526

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.54094

Collected Steps per Second: 23,159.05133
Overall Steps per Second: 10,870.29819

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.60006

Cumulative Model Updates: 192,016
Cumulative Timesteps: 1,601,401,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1601401174...
Checkpoint 1601401174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.03989
Policy Entropy: 2.27860
Value Function Loss: 0.01594

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.56958

Collected Steps per Second: 22,974.34801
Overall Steps per Second: 10,690.25411

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.67847

Cumulative Model Updates: 192,022
Cumulative Timesteps: 1,601,451,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.63236
Policy Entropy: 2.27683
Value Function Loss: 0.01662

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.51961
Value Function Update Magnitude: 0.59124

Collected Steps per Second: 23,030.01382
Overall Steps per Second: 10,827.64124

Timestep Collection Time: 2.17230
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.62040

Cumulative Model Updates: 192,028
Cumulative Timesteps: 1,601,501,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1601501216...
Checkpoint 1601501216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.44042
Policy Entropy: 2.28064
Value Function Loss: 0.01632

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.17019
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.57875

Collected Steps per Second: 23,336.48341
Overall Steps per Second: 11,136.90525

Timestep Collection Time: 2.14291
Timestep Consumption Time: 2.34739
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.49030

Cumulative Model Updates: 192,034
Cumulative Timesteps: 1,601,551,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.11575
Policy Entropy: 2.27126
Value Function Loss: 0.01727

Mean KL Divergence: 0.02206
SB3 Clip Fraction: 0.16959
Policy Update Magnitude: 0.52057
Value Function Update Magnitude: 0.55010

Collected Steps per Second: 22,989.85443
Overall Steps per Second: 10,831.08485

Timestep Collection Time: 2.17496
Timestep Consumption Time: 2.44157
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61653

Cumulative Model Updates: 192,040
Cumulative Timesteps: 1,601,601,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1601601226...
Checkpoint 1601601226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.58626
Policy Entropy: 2.27019
Value Function Loss: 0.01691

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.16018
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 23,277.40741
Overall Steps per Second: 10,783.60504

Timestep Collection Time: 2.14912
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.63908

Cumulative Model Updates: 192,046
Cumulative Timesteps: 1,601,651,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.48064
Policy Entropy: 2.27069
Value Function Loss: 0.01698

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.56362
Value Function Update Magnitude: 0.56811

Collected Steps per Second: 23,347.19405
Overall Steps per Second: 10,841.47847

Timestep Collection Time: 2.14270
Timestep Consumption Time: 2.47162
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.61432

Cumulative Model Updates: 192,052
Cumulative Timesteps: 1,601,701,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1601701278...
Checkpoint 1601701278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.19276
Policy Entropy: 2.28559
Value Function Loss: 0.01561

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.56356
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 23,172.08559
Overall Steps per Second: 10,807.98179

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.62695

Cumulative Model Updates: 192,058
Cumulative Timesteps: 1,601,751,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.41554
Policy Entropy: 2.26997
Value Function Loss: 0.01559

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.59653

Collected Steps per Second: 23,339.00227
Overall Steps per Second: 11,131.69470

Timestep Collection Time: 2.14302
Timestep Consumption Time: 2.35009
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.49312

Cumulative Model Updates: 192,064
Cumulative Timesteps: 1,601,801,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1601801302...
Checkpoint 1601801302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.79678
Policy Entropy: 2.25880
Value Function Loss: 0.01488

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.59201

Collected Steps per Second: 23,211.85773
Overall Steps per Second: 10,750.93709

Timestep Collection Time: 2.15442
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.65150

Cumulative Model Updates: 192,070
Cumulative Timesteps: 1,601,851,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.45171
Policy Entropy: 2.26161
Value Function Loss: 0.01600

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.55850
Value Function Update Magnitude: 0.60061

Collected Steps per Second: 23,316.31449
Overall Steps per Second: 10,838.87712

Timestep Collection Time: 2.14494
Timestep Consumption Time: 2.46920
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.61413

Cumulative Model Updates: 192,076
Cumulative Timesteps: 1,601,901,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1601901322...
Checkpoint 1601901322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.14629
Policy Entropy: 2.27903
Value Function Loss: 0.01482

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 22,701.49929
Overall Steps per Second: 10,645.79525

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69838

Cumulative Model Updates: 192,082
Cumulative Timesteps: 1,601,951,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.36931
Policy Entropy: 2.28848
Value Function Loss: 0.01522

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.58272

Collected Steps per Second: 23,267.64373
Overall Steps per Second: 10,974.91174

Timestep Collection Time: 2.14968
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.55749

Cumulative Model Updates: 192,088
Cumulative Timesteps: 1,602,001,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1602001358...
Checkpoint 1602001358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.29465
Policy Entropy: 2.29952
Value Function Loss: 0.01515

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 23,141.11063
Overall Steps per Second: 11,099.36031

Timestep Collection Time: 2.16169
Timestep Consumption Time: 2.34523
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.50693

Cumulative Model Updates: 192,094
Cumulative Timesteps: 1,602,051,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.46803
Policy Entropy: 2.29848
Value Function Loss: 0.01518

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.56486

Collected Steps per Second: 23,314.43985
Overall Steps per Second: 10,939.58711

Timestep Collection Time: 2.14494
Timestep Consumption Time: 2.42635
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.57129

Cumulative Model Updates: 192,100
Cumulative Timesteps: 1,602,101,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1602101390...
Checkpoint 1602101390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 442.79398
Policy Entropy: 2.30006
Value Function Loss: 0.01560

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 23,323.64289
Overall Steps per Second: 10,785.91714

Timestep Collection Time: 2.14469
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.63771

Cumulative Model Updates: 192,106
Cumulative Timesteps: 1,602,151,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.85914
Policy Entropy: 2.28482
Value Function Loss: 0.01647

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.56018
Value Function Update Magnitude: 0.58421

Collected Steps per Second: 23,064.91021
Overall Steps per Second: 10,721.72113

Timestep Collection Time: 2.16832
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.66455

Cumulative Model Updates: 192,112
Cumulative Timesteps: 1,602,201,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1602201424...
Checkpoint 1602201424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.29954
Policy Entropy: 2.29156
Value Function Loss: 0.01610

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.56080
Value Function Update Magnitude: 0.60202

Collected Steps per Second: 22,851.98242
Overall Steps per Second: 10,743.29870

Timestep Collection Time: 2.18852
Timestep Consumption Time: 2.46666
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.65518

Cumulative Model Updates: 192,118
Cumulative Timesteps: 1,602,251,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.70360
Policy Entropy: 2.32830
Value Function Loss: 0.01535

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.60776

Collected Steps per Second: 23,389.58888
Overall Steps per Second: 11,003.60397

Timestep Collection Time: 2.13830
Timestep Consumption Time: 2.40694
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.54524

Cumulative Model Updates: 192,124
Cumulative Timesteps: 1,602,301,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1602301450...
Checkpoint 1602301450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.09545
Policy Entropy: 2.32524
Value Function Loss: 0.01577

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.59129

Collected Steps per Second: 23,503.82628
Overall Steps per Second: 10,904.73344

Timestep Collection Time: 2.12850
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.58773

Cumulative Model Updates: 192,130
Cumulative Timesteps: 1,602,351,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.20278
Policy Entropy: 2.31109
Value Function Loss: 0.01528

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.60452

Collected Steps per Second: 23,204.30002
Overall Steps per Second: 10,854.69855

Timestep Collection Time: 2.15512
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.60704

Cumulative Model Updates: 192,136
Cumulative Timesteps: 1,602,401,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1602401486...
Checkpoint 1602401486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.14746
Policy Entropy: 2.26847
Value Function Loss: 0.01554

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.62436

Collected Steps per Second: 23,141.05320
Overall Steps per Second: 10,834.46553

Timestep Collection Time: 2.16084
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.61527

Cumulative Model Updates: 192,142
Cumulative Timesteps: 1,602,451,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.84729
Policy Entropy: 2.26368
Value Function Loss: 0.01477

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.62988

Collected Steps per Second: 23,263.81206
Overall Steps per Second: 11,011.71090

Timestep Collection Time: 2.14935
Timestep Consumption Time: 2.39146
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.54080

Cumulative Model Updates: 192,148
Cumulative Timesteps: 1,602,501,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1602501492...
Checkpoint 1602501492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.21068
Policy Entropy: 2.25547
Value Function Loss: 0.01525

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.55061
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 23,342.45970
Overall Steps per Second: 10,845.68452

Timestep Collection Time: 2.14262
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.61142

Cumulative Model Updates: 192,154
Cumulative Timesteps: 1,602,551,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.94926
Policy Entropy: 2.27918
Value Function Loss: 0.01498

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.59463

Collected Steps per Second: 23,246.22698
Overall Steps per Second: 10,942.19429

Timestep Collection Time: 2.15166
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.57111

Cumulative Model Updates: 192,160
Cumulative Timesteps: 1,602,601,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1602601524...
Checkpoint 1602601524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.07445
Policy Entropy: 2.27237
Value Function Loss: 0.01618

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.55544
Value Function Update Magnitude: 0.57999

Collected Steps per Second: 23,033.33354
Overall Steps per Second: 10,748.27914

Timestep Collection Time: 2.17137
Timestep Consumption Time: 2.48184
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65321

Cumulative Model Updates: 192,166
Cumulative Timesteps: 1,602,651,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.37385
Policy Entropy: 2.28042
Value Function Loss: 0.01564

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 23,145.79310
Overall Steps per Second: 10,736.64599

Timestep Collection Time: 2.16143
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.65956

Cumulative Model Updates: 192,172
Cumulative Timesteps: 1,602,701,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1602701566...
Checkpoint 1602701566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.05728
Policy Entropy: 2.26749
Value Function Loss: 0.01595

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,989.85934
Overall Steps per Second: 11,041.22291

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.35437
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.52993

Cumulative Model Updates: 192,178
Cumulative Timesteps: 1,602,751,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.18573
Policy Entropy: 2.28103
Value Function Loss: 0.01614

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 23,078.61956
Overall Steps per Second: 10,777.27974

Timestep Collection Time: 2.16737
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.64125

Cumulative Model Updates: 192,184
Cumulative Timesteps: 1,602,801,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1602801602...
Checkpoint 1602801602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.16208
Policy Entropy: 2.26349
Value Function Loss: 0.01655

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.56849
Value Function Update Magnitude: 0.59518

Collected Steps per Second: 23,110.03259
Overall Steps per Second: 10,863.62897

Timestep Collection Time: 2.16477
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.60509

Cumulative Model Updates: 192,190
Cumulative Timesteps: 1,602,851,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.48682
Policy Entropy: 2.26294
Value Function Loss: 0.01651

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.60258

Collected Steps per Second: 23,177.16541
Overall Steps per Second: 10,865.63036

Timestep Collection Time: 2.15868
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60461

Cumulative Model Updates: 192,196
Cumulative Timesteps: 1,602,901,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1602901662...
Checkpoint 1602901662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.76707
Policy Entropy: 2.25742
Value Function Loss: 0.01610

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.59060

Collected Steps per Second: 23,042.83906
Overall Steps per Second: 10,777.01958

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.63987

Cumulative Model Updates: 192,202
Cumulative Timesteps: 1,602,951,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.72412
Policy Entropy: 2.27367
Value Function Loss: 0.01613

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.57758

Collected Steps per Second: 23,228.67753
Overall Steps per Second: 10,983.77695

Timestep Collection Time: 2.15372
Timestep Consumption Time: 2.40100
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.55472

Cumulative Model Updates: 192,208
Cumulative Timesteps: 1,603,001,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1603001694...
Checkpoint 1603001694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467.01766
Policy Entropy: 2.27176
Value Function Loss: 0.01660

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.56996
Value Function Update Magnitude: 0.60747

Collected Steps per Second: 23,218.85619
Overall Steps per Second: 10,962.45936

Timestep Collection Time: 2.15463
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.56357

Cumulative Model Updates: 192,214
Cumulative Timesteps: 1,603,051,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.91543
Policy Entropy: 2.26968
Value Function Loss: 0.01645

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.62236

Collected Steps per Second: 23,385.92408
Overall Steps per Second: 10,890.71976

Timestep Collection Time: 2.13906
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.59327

Cumulative Model Updates: 192,220
Cumulative Timesteps: 1,603,101,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1603101746...
Checkpoint 1603101746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.55146
Policy Entropy: 2.27241
Value Function Loss: 0.01537

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.59876

Collected Steps per Second: 23,330.99719
Overall Steps per Second: 10,826.54013

Timestep Collection Time: 2.14341
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.61902

Cumulative Model Updates: 192,226
Cumulative Timesteps: 1,603,151,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.90610
Policy Entropy: 2.28920
Value Function Loss: 0.01453

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.58040

Collected Steps per Second: 23,351.36496
Overall Steps per Second: 10,869.72824

Timestep Collection Time: 2.14146
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.60048

Cumulative Model Updates: 192,232
Cumulative Timesteps: 1,603,201,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1603201760...
Checkpoint 1603201760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.72438
Policy Entropy: 2.31757
Value Function Loss: 0.01407

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.56456

Collected Steps per Second: 23,415.81323
Overall Steps per Second: 10,961.91950

Timestep Collection Time: 2.13642
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.56362

Cumulative Model Updates: 192,238
Cumulative Timesteps: 1,603,251,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.78780
Policy Entropy: 2.32367
Value Function Loss: 0.01480

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.53662
Value Function Update Magnitude: 0.56258

Collected Steps per Second: 23,138.56746
Overall Steps per Second: 10,902.66125

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.42660
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.58879

Cumulative Model Updates: 192,244
Cumulative Timesteps: 1,603,301,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1603301816...
Checkpoint 1603301816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.48851
Policy Entropy: 2.34034
Value Function Loss: 0.01445

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.53438
Value Function Update Magnitude: 0.54442

Collected Steps per Second: 23,296.46791
Overall Steps per Second: 10,807.05083

Timestep Collection Time: 2.14728
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.62883

Cumulative Model Updates: 192,250
Cumulative Timesteps: 1,603,351,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.69896
Policy Entropy: 2.32695
Value Function Loss: 0.01456

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.51948
Value Function Update Magnitude: 0.53579

Collected Steps per Second: 22,698.22727
Overall Steps per Second: 10,735.31362

Timestep Collection Time: 2.20423
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.66051

Cumulative Model Updates: 192,256
Cumulative Timesteps: 1,603,401,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1603401872...
Checkpoint 1603401872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.23175
Policy Entropy: 2.33426
Value Function Loss: 0.01504

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.51626
Value Function Update Magnitude: 0.53507

Collected Steps per Second: 23,150.49921
Overall Steps per Second: 10,875.81788

Timestep Collection Time: 2.16116
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.60030

Cumulative Model Updates: 192,262
Cumulative Timesteps: 1,603,451,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.91788
Policy Entropy: 2.31512
Value Function Loss: 0.01503

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.54928

Collected Steps per Second: 23,387.17758
Overall Steps per Second: 10,866.11458

Timestep Collection Time: 2.13869
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.60312

Cumulative Model Updates: 192,268
Cumulative Timesteps: 1,603,501,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1603501922...
Checkpoint 1603501922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.98124
Policy Entropy: 2.31347
Value Function Loss: 0.01460

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.52720
Value Function Update Magnitude: 0.54351

Collected Steps per Second: 22,967.55694
Overall Steps per Second: 10,917.92840

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.40370
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.58164

Cumulative Model Updates: 192,274
Cumulative Timesteps: 1,603,551,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.18669
Policy Entropy: 2.29990
Value Function Loss: 0.01460

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.52832

Collected Steps per Second: 22,631.26903
Overall Steps per Second: 10,687.33220

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.47088
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.68180

Cumulative Model Updates: 192,280
Cumulative Timesteps: 1,603,601,980

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1603601980...
Checkpoint 1603601980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.66724
Policy Entropy: 2.30189
Value Function Loss: 0.01440

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.52759
Value Function Update Magnitude: 0.51699

Collected Steps per Second: 23,292.68202
Overall Steps per Second: 10,887.81171

Timestep Collection Time: 2.14788
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.59505

Cumulative Model Updates: 192,286
Cumulative Timesteps: 1,603,652,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.66923
Policy Entropy: 2.30278
Value Function Loss: 0.01485

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.52137
Value Function Update Magnitude: 0.51022

Collected Steps per Second: 22,987.68466
Overall Steps per Second: 10,823.96480

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.62012

Cumulative Model Updates: 192,292
Cumulative Timesteps: 1,603,702,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1603702018...
Checkpoint 1603702018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.19440
Policy Entropy: 2.31894
Value Function Loss: 0.01501

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.52520
Value Function Update Magnitude: 0.50794

Collected Steps per Second: 23,045.66575
Overall Steps per Second: 10,740.45179

Timestep Collection Time: 2.16995
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.65604

Cumulative Model Updates: 192,298
Cumulative Timesteps: 1,603,752,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.74683
Policy Entropy: 2.31666
Value Function Loss: 0.01471

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.52442
Value Function Update Magnitude: 0.52375

Collected Steps per Second: 23,188.31225
Overall Steps per Second: 10,888.71114

Timestep Collection Time: 2.15660
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.59265

Cumulative Model Updates: 192,304
Cumulative Timesteps: 1,603,802,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1603802034...
Checkpoint 1603802034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.28385
Policy Entropy: 2.30397
Value Function Loss: 0.01513

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.53467
Value Function Update Magnitude: 0.52273

Collected Steps per Second: 23,389.44625
Overall Steps per Second: 10,999.84739

Timestep Collection Time: 2.13891
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.54806

Cumulative Model Updates: 192,310
Cumulative Timesteps: 1,603,852,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.66788
Policy Entropy: 2.31745
Value Function Loss: 0.01669

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.53645

Collected Steps per Second: 23,804.09611
Overall Steps per Second: 11,026.95543

Timestep Collection Time: 2.10166
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.53688

Cumulative Model Updates: 192,316
Cumulative Timesteps: 1,603,902,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1603902090...
Checkpoint 1603902090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.38657
Policy Entropy: 2.33523
Value Function Loss: 0.01698

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 23,339.67069
Overall Steps per Second: 10,803.27659

Timestep Collection Time: 2.14322
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.63026

Cumulative Model Updates: 192,322
Cumulative Timesteps: 1,603,952,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.05756
Policy Entropy: 2.33675
Value Function Loss: 0.01576

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.62710

Collected Steps per Second: 23,339.02181
Overall Steps per Second: 10,875.24998

Timestep Collection Time: 2.14311
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.59925

Cumulative Model Updates: 192,328
Cumulative Timesteps: 1,604,002,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1604002130...
Checkpoint 1604002130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.60597
Policy Entropy: 2.33976
Value Function Loss: 0.01578

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.60017

Collected Steps per Second: 23,494.31840
Overall Steps per Second: 10,986.50451

Timestep Collection Time: 2.12911
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.55304

Cumulative Model Updates: 192,334
Cumulative Timesteps: 1,604,052,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.88718
Policy Entropy: 2.32754
Value Function Loss: 0.01698

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15915
Policy Update Magnitude: 0.53289
Value Function Update Magnitude: 0.58922

Collected Steps per Second: 23,024.61748
Overall Steps per Second: 10,849.53880

Timestep Collection Time: 2.17263
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.61070

Cumulative Model Updates: 192,340
Cumulative Timesteps: 1,604,102,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1604102176...
Checkpoint 1604102176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.37871
Policy Entropy: 2.36282
Value Function Loss: 0.01767

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.61631

Collected Steps per Second: 23,376.72158
Overall Steps per Second: 10,810.73137

Timestep Collection Time: 2.13965
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.62670

Cumulative Model Updates: 192,346
Cumulative Timesteps: 1,604,152,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.16263
Policy Entropy: 2.37257
Value Function Loss: 0.01643

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 22,929.50536
Overall Steps per Second: 10,790.13923

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.45434
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.63590

Cumulative Model Updates: 192,352
Cumulative Timesteps: 1,604,202,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1604202216...
Checkpoint 1604202216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.58720
Policy Entropy: 2.37418
Value Function Loss: 0.01553

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.54656
Value Function Update Magnitude: 0.59080

Collected Steps per Second: 23,235.83537
Overall Steps per Second: 10,999.99030

Timestep Collection Time: 2.15254
Timestep Consumption Time: 2.39438
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.54691

Cumulative Model Updates: 192,358
Cumulative Timesteps: 1,604,252,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.13939
Policy Entropy: 2.38078
Value Function Loss: 0.01497

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.53517
Value Function Update Magnitude: 0.55680

Collected Steps per Second: 23,261.30661
Overall Steps per Second: 10,992.35796

Timestep Collection Time: 2.15044
Timestep Consumption Time: 2.40018
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.55062

Cumulative Model Updates: 192,364
Cumulative Timesteps: 1,604,302,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1604302254...
Checkpoint 1604302254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.18565
Policy Entropy: 2.37324
Value Function Loss: 0.01413

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.52728
Value Function Update Magnitude: 0.56421

Collected Steps per Second: 22,203.44787
Overall Steps per Second: 10,688.00011

Timestep Collection Time: 2.25307
Timestep Consumption Time: 2.42750
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.68058

Cumulative Model Updates: 192,370
Cumulative Timesteps: 1,604,352,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.71767
Policy Entropy: 2.37429
Value Function Loss: 0.01463

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.53271
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 23,196.36852
Overall Steps per Second: 10,915.05600

Timestep Collection Time: 2.15672
Timestep Consumption Time: 2.42668
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.58339

Cumulative Model Updates: 192,376
Cumulative Timesteps: 1,604,402,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604402308...
Checkpoint 1604402308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.91593
Policy Entropy: 2.36856
Value Function Loss: 0.01428

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 23,242.54512
Overall Steps per Second: 10,794.53036

Timestep Collection Time: 2.15157
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.63272

Cumulative Model Updates: 192,382
Cumulative Timesteps: 1,604,452,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.39758
Policy Entropy: 2.36642
Value Function Loss: 0.01459

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 23,216.04790
Overall Steps per Second: 10,753.69689

Timestep Collection Time: 2.15429
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.65087

Cumulative Model Updates: 192,388
Cumulative Timesteps: 1,604,502,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1604502330...
Checkpoint 1604502330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.64254
Policy Entropy: 2.36588
Value Function Loss: 0.01510

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 23,230.96999
Overall Steps per Second: 11,063.46581

Timestep Collection Time: 2.15316
Timestep Consumption Time: 2.36803
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.52119

Cumulative Model Updates: 192,394
Cumulative Timesteps: 1,604,552,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.24491
Policy Entropy: 2.34471
Value Function Loss: 0.01579

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 23,057.38788
Overall Steps per Second: 10,845.47058

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61225

Cumulative Model Updates: 192,400
Cumulative Timesteps: 1,604,602,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1604602372...
Checkpoint 1604602372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.71343
Policy Entropy: 2.34045
Value Function Loss: 0.01707

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 23,287.65561
Overall Steps per Second: 10,749.70201

Timestep Collection Time: 2.14835
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.65408

Cumulative Model Updates: 192,406
Cumulative Timesteps: 1,604,652,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.72601
Policy Entropy: 2.34110
Value Function Loss: 0.01728

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.60186

Collected Steps per Second: 23,375.23803
Overall Steps per Second: 10,875.35783

Timestep Collection Time: 2.14021
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.60012

Cumulative Model Updates: 192,412
Cumulative Timesteps: 1,604,702,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604702430...
Checkpoint 1604702430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.65619
Policy Entropy: 2.34858
Value Function Loss: 0.01640

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 23,135.36873
Overall Steps per Second: 10,818.17498

Timestep Collection Time: 2.16240
Timestep Consumption Time: 2.46204
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.62444

Cumulative Model Updates: 192,418
Cumulative Timesteps: 1,604,752,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.56998
Policy Entropy: 2.34203
Value Function Loss: 0.01577

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 23,077.60721
Overall Steps per Second: 10,939.57020

Timestep Collection Time: 2.16669
Timestep Consumption Time: 2.40406
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.57075

Cumulative Model Updates: 192,424
Cumulative Timesteps: 1,604,802,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1604802460...
Checkpoint 1604802460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.52887
Policy Entropy: 2.36792
Value Function Loss: 0.01512

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.59418

Collected Steps per Second: 23,447.27197
Overall Steps per Second: 10,909.35493

Timestep Collection Time: 2.13389
Timestep Consumption Time: 2.45244
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.58634

Cumulative Model Updates: 192,430
Cumulative Timesteps: 1,604,852,494

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.40241
Policy Entropy: 2.36771
Value Function Loss: 0.01541

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.53501
Value Function Update Magnitude: 0.58769

Collected Steps per Second: 23,108.90161
Overall Steps per Second: 10,856.29369

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.44322
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60802

Cumulative Model Updates: 192,436
Cumulative Timesteps: 1,604,902,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1604902520...
Checkpoint 1604902520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.91343
Policy Entropy: 2.35783
Value Function Loss: 0.01525

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.58695

Collected Steps per Second: 23,148.95577
Overall Steps per Second: 10,807.37867

Timestep Collection Time: 2.16113
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.62906

Cumulative Model Updates: 192,442
Cumulative Timesteps: 1,604,952,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.02012
Policy Entropy: 2.32199
Value Function Loss: 0.01563

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54978
Value Function Update Magnitude: 0.57342

Collected Steps per Second: 23,283.79010
Overall Steps per Second: 10,988.62222

Timestep Collection Time: 2.14776
Timestep Consumption Time: 2.40313
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.55089

Cumulative Model Updates: 192,448
Cumulative Timesteps: 1,605,002,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1605002556...
Checkpoint 1605002556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.58874
Policy Entropy: 2.33817
Value Function Loss: 0.01520

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.54841
Value Function Update Magnitude: 0.57554

Collected Steps per Second: 23,127.64335
Overall Steps per Second: 10,929.60280

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.41340
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.57583

Cumulative Model Updates: 192,454
Cumulative Timesteps: 1,605,052,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.32804
Policy Entropy: 2.35851
Value Function Loss: 0.01504

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.57619

Collected Steps per Second: 23,300.19149
Overall Steps per Second: 10,856.61270

Timestep Collection Time: 2.14659
Timestep Consumption Time: 2.46037
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.60696

Cumulative Model Updates: 192,460
Cumulative Timesteps: 1,605,102,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1605102584...
Checkpoint 1605102584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.17308
Policy Entropy: 2.36788
Value Function Loss: 0.01444

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 23,101.59511
Overall Steps per Second: 10,818.11871

Timestep Collection Time: 2.16539
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.62409

Cumulative Model Updates: 192,466
Cumulative Timesteps: 1,605,152,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.77455
Policy Entropy: 2.36132
Value Function Loss: 0.01552

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.53804
Value Function Update Magnitude: 0.56446

Collected Steps per Second: 23,049.76268
Overall Steps per Second: 10,736.74740

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.65709

Cumulative Model Updates: 192,472
Cumulative Timesteps: 1,605,202,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1605202610...
Checkpoint 1605202610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.93142
Policy Entropy: 2.34529
Value Function Loss: 0.01631

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.57415

Collected Steps per Second: 23,329.94901
Overall Steps per Second: 11,154.11400

Timestep Collection Time: 2.14351
Timestep Consumption Time: 2.33986
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.48337

Cumulative Model Updates: 192,478
Cumulative Timesteps: 1,605,252,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.00933
Policy Entropy: 2.32974
Value Function Loss: 0.01569

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.53880
Value Function Update Magnitude: 0.55484

Collected Steps per Second: 23,188.98882
Overall Steps per Second: 10,910.62553

Timestep Collection Time: 2.15766
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.58580

Cumulative Model Updates: 192,484
Cumulative Timesteps: 1,605,302,652

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1605302652...
Checkpoint 1605302652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.54093
Policy Entropy: 2.30588
Value Function Loss: 0.01545

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.52953

Collected Steps per Second: 23,342.44776
Overall Steps per Second: 10,828.98706

Timestep Collection Time: 2.14305
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.61945

Cumulative Model Updates: 192,490
Cumulative Timesteps: 1,605,352,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.27218
Policy Entropy: 2.29848
Value Function Loss: 0.01448

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.52407

Collected Steps per Second: 23,366.78343
Overall Steps per Second: 10,812.48186

Timestep Collection Time: 2.14073
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.62632

Cumulative Model Updates: 192,496
Cumulative Timesteps: 1,605,402,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1605402698...
Checkpoint 1605402698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.13528
Policy Entropy: 2.29613
Value Function Loss: 0.01534

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.53075

Collected Steps per Second: 23,158.80485
Overall Steps per Second: 10,986.09905

Timestep Collection Time: 2.15935
Timestep Consumption Time: 2.39258
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.55193

Cumulative Model Updates: 192,502
Cumulative Timesteps: 1,605,452,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.62701
Policy Entropy: 2.30897
Value Function Loss: 0.01499

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.16053
Policy Update Magnitude: 0.53175
Value Function Update Magnitude: 0.54364

Collected Steps per Second: 23,333.28016
Overall Steps per Second: 10,986.61078

Timestep Collection Time: 2.14389
Timestep Consumption Time: 2.40929
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.55318

Cumulative Model Updates: 192,508
Cumulative Timesteps: 1,605,502,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1605502730...
Checkpoint 1605502730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.06059
Policy Entropy: 2.31073
Value Function Loss: 0.01570

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.15280
Policy Update Magnitude: 0.54198
Value Function Update Magnitude: 0.55381

Collected Steps per Second: 23,246.07984
Overall Steps per Second: 10,996.82717

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.39721
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.54931

Cumulative Model Updates: 192,514
Cumulative Timesteps: 1,605,552,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.09036
Policy Entropy: 2.33331
Value Function Loss: 0.01543

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 23,388.75966
Overall Steps per Second: 10,944.71477

Timestep Collection Time: 2.13829
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.56951

Cumulative Model Updates: 192,520
Cumulative Timesteps: 1,605,602,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1605602770...
Checkpoint 1605602770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.63865
Policy Entropy: 2.36453
Value Function Loss: 0.01478

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.59906

Collected Steps per Second: 23,054.53609
Overall Steps per Second: 10,711.86063

Timestep Collection Time: 2.16912
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.66847

Cumulative Model Updates: 192,526
Cumulative Timesteps: 1,605,652,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.23894
Policy Entropy: 2.37479
Value Function Loss: 0.01344

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.51792
Value Function Update Magnitude: 0.56920

Collected Steps per Second: 23,201.47084
Overall Steps per Second: 10,847.29836

Timestep Collection Time: 2.15573
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.61092

Cumulative Model Updates: 192,532
Cumulative Timesteps: 1,605,702,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1605702794...
Checkpoint 1605702794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.80547
Policy Entropy: 2.35688
Value Function Loss: 0.01408

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.54201

Collected Steps per Second: 23,189.73185
Overall Steps per Second: 11,076.72330

Timestep Collection Time: 2.15613
Timestep Consumption Time: 2.35784
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.51397

Cumulative Model Updates: 192,538
Cumulative Timesteps: 1,605,752,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.98219
Policy Entropy: 2.32906
Value Function Loss: 0.01469

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.53785
Value Function Update Magnitude: 0.55401

Collected Steps per Second: 23,063.83914
Overall Steps per Second: 10,879.01861

Timestep Collection Time: 2.16790
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59600

Cumulative Model Updates: 192,544
Cumulative Timesteps: 1,605,802,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1605802794...
Checkpoint 1605802794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.88437
Policy Entropy: 2.30574
Value Function Loss: 0.01611

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.54788
Value Function Update Magnitude: 0.58612

Collected Steps per Second: 23,079.44863
Overall Steps per Second: 10,729.09915

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66227

Cumulative Model Updates: 192,550
Cumulative Timesteps: 1,605,852,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.56538
Policy Entropy: 2.28188
Value Function Loss: 0.01543

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 23,472.86863
Overall Steps per Second: 10,856.85527

Timestep Collection Time: 2.13097
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.60723

Cumulative Model Updates: 192,556
Cumulative Timesteps: 1,605,902,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1605902836...
Checkpoint 1605902836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.87963
Policy Entropy: 2.29131
Value Function Loss: 0.01599

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.54262
Value Function Update Magnitude: 0.60054

Collected Steps per Second: 23,081.04496
Overall Steps per Second: 10,762.42886

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.64784

Cumulative Model Updates: 192,562
Cumulative Timesteps: 1,605,952,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.94749
Policy Entropy: 2.29426
Value Function Loss: 0.01436

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.59186

Collected Steps per Second: 23,429.20152
Overall Steps per Second: 11,029.57208

Timestep Collection Time: 2.13537
Timestep Consumption Time: 2.40062
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.53599

Cumulative Model Updates: 192,568
Cumulative Timesteps: 1,606,002,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1606002888...
Checkpoint 1606002888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.38522
Policy Entropy: 2.32182
Value Function Loss: 0.01455

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.57294

Collected Steps per Second: 23,307.64908
Overall Steps per Second: 10,882.69472

Timestep Collection Time: 2.14522
Timestep Consumption Time: 2.44923
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.59445

Cumulative Model Updates: 192,574
Cumulative Timesteps: 1,606,052,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.64465
Policy Entropy: 2.32509
Value Function Loss: 0.01368

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.55523

Collected Steps per Second: 23,152.72526
Overall Steps per Second: 10,889.65593

Timestep Collection Time: 2.16000
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.59243

Cumulative Model Updates: 192,580
Cumulative Timesteps: 1,606,102,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1606102898...
Checkpoint 1606102898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.23418
Policy Entropy: 2.32917
Value Function Loss: 0.01517

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.56730

Collected Steps per Second: 23,309.61275
Overall Steps per Second: 10,952.34859

Timestep Collection Time: 2.14615
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.56760

Cumulative Model Updates: 192,586
Cumulative Timesteps: 1,606,152,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.62188
Policy Entropy: 2.34113
Value Function Loss: 0.01541

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 23,130.02720
Overall Steps per Second: 11,093.75621

Timestep Collection Time: 2.16230
Timestep Consumption Time: 2.34600
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.50830

Cumulative Model Updates: 192,592
Cumulative Timesteps: 1,606,202,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1606202938...
Checkpoint 1606202938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.25125
Policy Entropy: 2.31879
Value Function Loss: 0.01609

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.58794

Collected Steps per Second: 23,088.61330
Overall Steps per Second: 10,731.48155

Timestep Collection Time: 2.16618
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66049

Cumulative Model Updates: 192,598
Cumulative Timesteps: 1,606,252,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.98529
Policy Entropy: 2.32355
Value Function Loss: 0.01557

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.60526

Collected Steps per Second: 23,508.40302
Overall Steps per Second: 10,808.33456

Timestep Collection Time: 2.12707
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.62643

Cumulative Model Updates: 192,604
Cumulative Timesteps: 1,606,302,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1606302956...
Checkpoint 1606302956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 646.84988
Policy Entropy: 2.30359
Value Function Loss: 0.01473

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.60174

Collected Steps per Second: 23,029.32222
Overall Steps per Second: 10,818.27178

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.62384

Cumulative Model Updates: 192,610
Cumulative Timesteps: 1,606,352,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.28309
Policy Entropy: 2.31376
Value Function Loss: 0.01459

Mean KL Divergence: 0.02449
SB3 Clip Fraction: 0.16874
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 23,294.87486
Overall Steps per Second: 10,812.35133

Timestep Collection Time: 2.14751
Timestep Consumption Time: 2.47923
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.62675

Cumulative Model Updates: 192,616
Cumulative Timesteps: 1,606,403,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1606403004...
Checkpoint 1606403004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.70402
Policy Entropy: 2.30517
Value Function Loss: 0.01452

Mean KL Divergence: 0.02687
SB3 Clip Fraction: 0.18464
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.58862

Collected Steps per Second: 23,476.88543
Overall Steps per Second: 11,037.95798

Timestep Collection Time: 2.13061
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.53164

Cumulative Model Updates: 192,622
Cumulative Timesteps: 1,606,453,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.31741
Policy Entropy: 2.32103
Value Function Loss: 0.01494

Mean KL Divergence: 0.02307
SB3 Clip Fraction: 0.17221
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.58267

Collected Steps per Second: 23,249.29993
Overall Steps per Second: 10,917.15300

Timestep Collection Time: 2.15206
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.58306

Cumulative Model Updates: 192,628
Cumulative Timesteps: 1,606,503,058

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1606503058...
Checkpoint 1606503058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.72916
Policy Entropy: 2.32096
Value Function Loss: 0.01459

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.57818

Collected Steps per Second: 23,162.51362
Overall Steps per Second: 10,745.93661

Timestep Collection Time: 2.15892
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.65348

Cumulative Model Updates: 192,634
Cumulative Timesteps: 1,606,553,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.76589
Policy Entropy: 2.34704
Value Function Loss: 0.01458

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.54042
Value Function Update Magnitude: 0.58471

Collected Steps per Second: 23,205.34072
Overall Steps per Second: 10,786.51980

Timestep Collection Time: 2.15468
Timestep Consumption Time: 2.48074
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.63542

Cumulative Model Updates: 192,640
Cumulative Timesteps: 1,606,603,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1606603064...
Checkpoint 1606603064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.50428
Policy Entropy: 2.33564
Value Function Loss: 0.01458

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.59426

Collected Steps per Second: 23,169.64850
Overall Steps per Second: 11,106.16941

Timestep Collection Time: 2.15834
Timestep Consumption Time: 2.34438
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.50272

Cumulative Model Updates: 192,646
Cumulative Timesteps: 1,606,653,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.76919
Policy Entropy: 2.33920
Value Function Loss: 0.01510

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.59906

Collected Steps per Second: 23,386.00475
Overall Steps per Second: 10,903.19555

Timestep Collection Time: 2.13897
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.58783

Cumulative Model Updates: 192,652
Cumulative Timesteps: 1,606,703,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1606703094...
Checkpoint 1606703094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.11341
Policy Entropy: 2.32093
Value Function Loss: 0.01482

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.57149

Collected Steps per Second: 23,144.45996
Overall Steps per Second: 10,773.43871

Timestep Collection Time: 2.16155
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.64364

Cumulative Model Updates: 192,658
Cumulative Timesteps: 1,606,753,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.29336
Policy Entropy: 2.31655
Value Function Loss: 0.01499

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.15938
Policy Update Magnitude: 0.53031
Value Function Update Magnitude: 0.56338

Collected Steps per Second: 23,020.94529
Overall Steps per Second: 10,821.19948

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.62333

Cumulative Model Updates: 192,664
Cumulative Timesteps: 1,606,803,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1606803152...
Checkpoint 1606803152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.12394
Policy Entropy: 2.30460
Value Function Loss: 0.01499

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.52567
Value Function Update Magnitude: 0.56723

Collected Steps per Second: 23,103.75008
Overall Steps per Second: 10,979.91154

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.38972
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.55395

Cumulative Model Updates: 192,670
Cumulative Timesteps: 1,606,853,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.63468
Policy Entropy: 2.32694
Value Function Loss: 0.01437

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 23,140.72383
Overall Steps per Second: 11,011.08204

Timestep Collection Time: 2.16069
Timestep Consumption Time: 2.38019
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.54088

Cumulative Model Updates: 192,676
Cumulative Timesteps: 1,606,903,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1606903154...
Checkpoint 1606903154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.13604
Policy Entropy: 2.32814
Value Function Loss: 0.01389

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.53019
Value Function Update Magnitude: 0.54479

Collected Steps per Second: 23,280.64500
Overall Steps per Second: 10,803.98519

Timestep Collection Time: 2.14960
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.63199

Cumulative Model Updates: 192,682
Cumulative Timesteps: 1,606,953,198

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.12067
Policy Entropy: 2.32396
Value Function Loss: 0.01405

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.53104
Value Function Update Magnitude: 0.51506

Collected Steps per Second: 23,201.41272
Overall Steps per Second: 10,715.36226

Timestep Collection Time: 2.15573
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.66769

Cumulative Model Updates: 192,688
Cumulative Timesteps: 1,607,003,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1607003214...
Checkpoint 1607003214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.78218
Policy Entropy: 2.31489
Value Function Loss: 0.01528

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.52850

Collected Steps per Second: 23,215.24292
Overall Steps per Second: 10,749.77846

Timestep Collection Time: 2.15471
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.65331

Cumulative Model Updates: 192,694
Cumulative Timesteps: 1,607,053,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.09744
Policy Entropy: 2.32334
Value Function Loss: 0.01601

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 23,349.32916
Overall Steps per Second: 10,802.79511

Timestep Collection Time: 2.14147
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.62862

Cumulative Model Updates: 192,700
Cumulative Timesteps: 1,607,103,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1607103238...
Checkpoint 1607103238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.10735
Policy Entropy: 2.33072
Value Function Loss: 0.01523

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.55143
Value Function Update Magnitude: 0.56342

Collected Steps per Second: 22,748.72099
Overall Steps per Second: 10,891.07313

Timestep Collection Time: 2.19810
Timestep Consumption Time: 2.39318
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.59128

Cumulative Model Updates: 192,706
Cumulative Timesteps: 1,607,153,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.67739
Policy Entropy: 2.32171
Value Function Loss: 0.01543

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.56223

Collected Steps per Second: 23,532.10886
Overall Steps per Second: 10,919.13184

Timestep Collection Time: 2.12603
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.58187

Cumulative Model Updates: 192,712
Cumulative Timesteps: 1,607,203,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1607203272...
Checkpoint 1607203272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.59482
Policy Entropy: 2.30430
Value Function Loss: 0.01601

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.55173

Collected Steps per Second: 23,057.26014
Overall Steps per Second: 10,884.15754

Timestep Collection Time: 2.16964
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.59622

Cumulative Model Updates: 192,718
Cumulative Timesteps: 1,607,253,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.91333
Policy Entropy: 2.31110
Value Function Loss: 0.01667

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.56809

Collected Steps per Second: 23,361.73335
Overall Steps per Second: 10,899.19467

Timestep Collection Time: 2.14154
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.59025

Cumulative Model Updates: 192,724
Cumulative Timesteps: 1,607,303,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1607303328...
Checkpoint 1607303328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.23346
Policy Entropy: 2.31384
Value Function Loss: 0.01644

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.61713

Collected Steps per Second: 23,210.95778
Overall Steps per Second: 10,976.07015

Timestep Collection Time: 2.15433
Timestep Consumption Time: 2.40140
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.55573

Cumulative Model Updates: 192,730
Cumulative Timesteps: 1,607,353,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.66660
Policy Entropy: 2.32063
Value Function Loss: 0.01643

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.61674

Collected Steps per Second: 23,233.29135
Overall Steps per Second: 11,035.92256

Timestep Collection Time: 2.15329
Timestep Consumption Time: 2.37991
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.53320

Cumulative Model Updates: 192,736
Cumulative Timesteps: 1,607,403,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1607403360...
Checkpoint 1607403360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.46376
Policy Entropy: 2.33491
Value Function Loss: 0.01610

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.58709

Collected Steps per Second: 23,288.40468
Overall Steps per Second: 10,834.96300

Timestep Collection Time: 2.14785
Timestep Consumption Time: 2.46869
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.61654

Cumulative Model Updates: 192,742
Cumulative Timesteps: 1,607,453,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.02265
Policy Entropy: 2.34856
Value Function Loss: 0.01475

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.16840
Policy Update Magnitude: 0.50693
Value Function Update Magnitude: 0.55638

Collected Steps per Second: 23,412.66022
Overall Steps per Second: 10,792.58394

Timestep Collection Time: 2.13594
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.63355

Cumulative Model Updates: 192,748
Cumulative Timesteps: 1,607,503,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1607503388...
Checkpoint 1607503388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.74734
Policy Entropy: 2.34587
Value Function Loss: 0.01404

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.51634
Value Function Update Magnitude: 0.56112

Collected Steps per Second: 23,170.32301
Overall Steps per Second: 10,904.50134

Timestep Collection Time: 2.15793
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58526

Cumulative Model Updates: 192,754
Cumulative Timesteps: 1,607,553,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.77617
Policy Entropy: 2.33506
Value Function Loss: 0.01413

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.53483
Value Function Update Magnitude: 0.57437

Collected Steps per Second: 23,440.47049
Overall Steps per Second: 11,017.07980

Timestep Collection Time: 2.13349
Timestep Consumption Time: 2.40583
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.53932

Cumulative Model Updates: 192,760
Cumulative Timesteps: 1,607,603,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1607603398...
Checkpoint 1607603398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.30194
Policy Entropy: 2.32444
Value Function Loss: 0.01533

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.17254
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.56971

Collected Steps per Second: 23,047.86942
Overall Steps per Second: 10,750.19208

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.65201

Cumulative Model Updates: 192,766
Cumulative Timesteps: 1,607,653,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.07169
Policy Entropy: 2.31744
Value Function Loss: 0.01663

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.17593
Policy Update Magnitude: 0.52614
Value Function Update Magnitude: 0.58565

Collected Steps per Second: 23,529.11391
Overall Steps per Second: 10,771.00606

Timestep Collection Time: 2.12503
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.64209

Cumulative Model Updates: 192,772
Cumulative Timesteps: 1,607,703,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1607703408...
Checkpoint 1607703408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.25823
Policy Entropy: 2.34184
Value Function Loss: 0.01644

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.15909
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.62457

Collected Steps per Second: 23,367.45460
Overall Steps per Second: 10,825.61192

Timestep Collection Time: 2.13998
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.61923

Cumulative Model Updates: 192,778
Cumulative Timesteps: 1,607,753,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.52472
Policy Entropy: 2.32206
Value Function Loss: 0.01637

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.61240

Collected Steps per Second: 23,197.43876
Overall Steps per Second: 10,793.47869

Timestep Collection Time: 2.15558
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.63280

Cumulative Model Updates: 192,784
Cumulative Timesteps: 1,607,803,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1607803418...
Checkpoint 1607803418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.89962
Policy Entropy: 2.34004
Value Function Loss: 0.01579

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.58495

Collected Steps per Second: 23,307.26220
Overall Steps per Second: 11,073.46577

Timestep Collection Time: 2.14603
Timestep Consumption Time: 2.37090
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.51692

Cumulative Model Updates: 192,790
Cumulative Timesteps: 1,607,853,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.19625
Policy Entropy: 2.33375
Value Function Loss: 0.01610

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.57542

Collected Steps per Second: 23,304.23737
Overall Steps per Second: 10,873.31645

Timestep Collection Time: 2.14570
Timestep Consumption Time: 2.45308
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.59878

Cumulative Model Updates: 192,796
Cumulative Timesteps: 1,607,903,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1607903440...
Checkpoint 1607903440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.97312
Policy Entropy: 2.32476
Value Function Loss: 0.01486

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.57622

Collected Steps per Second: 22,736.30721
Overall Steps per Second: 10,637.30273

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.70157

Cumulative Model Updates: 192,802
Cumulative Timesteps: 1,607,953,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.41140
Policy Entropy: 2.29510
Value Function Loss: 0.01466

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 23,082.36759
Overall Steps per Second: 10,887.95469

Timestep Collection Time: 2.16633
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.59260

Cumulative Model Updates: 192,808
Cumulative Timesteps: 1,608,003,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1608003456...
Checkpoint 1608003456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.80097
Policy Entropy: 2.28922
Value Function Loss: 0.01393

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 23,053.26499
Overall Steps per Second: 11,081.26812

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.34360
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.51284

Cumulative Model Updates: 192,814
Cumulative Timesteps: 1,608,053,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.72736
Policy Entropy: 2.28140
Value Function Loss: 0.01399

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.55624

Collected Steps per Second: 23,470.43565
Overall Steps per Second: 10,976.46930

Timestep Collection Time: 2.13119
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.55702

Cumulative Model Updates: 192,820
Cumulative Timesteps: 1,608,103,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1608103484...
Checkpoint 1608103484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.64467
Policy Entropy: 2.29166
Value Function Loss: 0.01473

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.58232

Collected Steps per Second: 23,305.53711
Overall Steps per Second: 10,837.87165

Timestep Collection Time: 2.14644
Timestep Consumption Time: 2.46922
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.61567

Cumulative Model Updates: 192,826
Cumulative Timesteps: 1,608,153,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.73384
Policy Entropy: 2.30134
Value Function Loss: 0.01549

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.59360

Collected Steps per Second: 23,489.15714
Overall Steps per Second: 10,814.25909

Timestep Collection Time: 2.12915
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.62463

Cumulative Model Updates: 192,832
Cumulative Timesteps: 1,608,203,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1608203520...
Checkpoint 1608203520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.05315
Policy Entropy: 2.30319
Value Function Loss: 0.01660

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 23,235.77899
Overall Steps per Second: 10,995.05078

Timestep Collection Time: 2.15228
Timestep Consumption Time: 2.39613
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.54841

Cumulative Model Updates: 192,838
Cumulative Timesteps: 1,608,253,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.00294
Policy Entropy: 2.30600
Value Function Loss: 0.01637

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.62034

Collected Steps per Second: 23,487.80304
Overall Steps per Second: 10,979.95856

Timestep Collection Time: 2.12953
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.55539

Cumulative Model Updates: 192,844
Cumulative Timesteps: 1,608,303,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1608303548...
Checkpoint 1608303548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.23278
Policy Entropy: 2.31671
Value Function Loss: 0.01568

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 23,429.67929
Overall Steps per Second: 10,960.58101

Timestep Collection Time: 2.13456
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.56290

Cumulative Model Updates: 192,850
Cumulative Timesteps: 1,608,353,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.75145
Policy Entropy: 2.32062
Value Function Loss: 0.01565

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.53537
Value Function Update Magnitude: 0.55962

Collected Steps per Second: 23,326.89022
Overall Steps per Second: 10,953.47984

Timestep Collection Time: 2.14431
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.56659

Cumulative Model Updates: 192,856
Cumulative Timesteps: 1,608,403,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1608403580...
Checkpoint 1608403580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.11503
Policy Entropy: 2.31140
Value Function Loss: 0.01646

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 22,918.07617
Overall Steps per Second: 10,918.02964

Timestep Collection Time: 2.18221
Timestep Consumption Time: 2.39847
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.58068

Cumulative Model Updates: 192,862
Cumulative Timesteps: 1,608,453,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.81393
Policy Entropy: 2.29942
Value Function Loss: 0.01582

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.58027

Collected Steps per Second: 23,307.46116
Overall Steps per Second: 10,893.06993

Timestep Collection Time: 2.14618
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.59209

Cumulative Model Updates: 192,868
Cumulative Timesteps: 1,608,503,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1608503614...
Checkpoint 1608503614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.17851
Policy Entropy: 2.28711
Value Function Loss: 0.01528

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.53626
Value Function Update Magnitude: 0.57830

Collected Steps per Second: 22,868.42777
Overall Steps per Second: 10,681.77439

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.68274

Cumulative Model Updates: 192,874
Cumulative Timesteps: 1,608,553,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.36618
Policy Entropy: 2.30947
Value Function Loss: 0.01430

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.56513

Collected Steps per Second: 22,842.77201
Overall Steps per Second: 10,843.09040

Timestep Collection Time: 2.18888
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61123

Cumulative Model Updates: 192,880
Cumulative Timesteps: 1,608,603,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1608603634...
Checkpoint 1608603634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.71266
Policy Entropy: 2.33600
Value Function Loss: 0.01409

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.53273
Value Function Update Magnitude: 0.56402

Collected Steps per Second: 22,628.03532
Overall Steps per Second: 10,711.58219

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67195

Cumulative Model Updates: 192,886
Cumulative Timesteps: 1,608,653,678

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.49014
Policy Entropy: 2.34145
Value Function Loss: 0.01429

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.52266
Value Function Update Magnitude: 0.56188

Collected Steps per Second: 23,119.22019
Overall Steps per Second: 10,892.63872

Timestep Collection Time: 2.16374
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.59246

Cumulative Model Updates: 192,892
Cumulative Timesteps: 1,608,703,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1608703702...
Checkpoint 1608703702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.23324
Policy Entropy: 2.32999
Value Function Loss: 0.01547

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.55231

Collected Steps per Second: 23,120.38252
Overall Steps per Second: 10,763.56625

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.64642

Cumulative Model Updates: 192,898
Cumulative Timesteps: 1,608,753,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.64000
Policy Entropy: 2.30374
Value Function Loss: 0.01553

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.57089

Collected Steps per Second: 23,176.48999
Overall Steps per Second: 10,783.22464

Timestep Collection Time: 2.15736
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.63683

Cumulative Model Updates: 192,904
Cumulative Timesteps: 1,608,803,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1608803714...
Checkpoint 1608803714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.90935
Policy Entropy: 2.29244
Value Function Loss: 0.01535

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 23,080.59485
Overall Steps per Second: 10,767.06072

Timestep Collection Time: 2.16684
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.64491

Cumulative Model Updates: 192,910
Cumulative Timesteps: 1,608,853,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.36576
Policy Entropy: 2.28637
Value Function Loss: 0.01550

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.56847

Collected Steps per Second: 23,179.48444
Overall Steps per Second: 10,753.27125

Timestep Collection Time: 2.15760
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.65086

Cumulative Model Updates: 192,916
Cumulative Timesteps: 1,608,903,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1608903738...
Checkpoint 1608903738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.53205
Policy Entropy: 2.28796
Value Function Loss: 0.01661

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 23,355.40393
Overall Steps per Second: 11,081.19229

Timestep Collection Time: 2.14169
Timestep Consumption Time: 2.37227
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.51395

Cumulative Model Updates: 192,922
Cumulative Timesteps: 1,608,953,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.15190
Policy Entropy: 2.30499
Value Function Loss: 0.01596

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.61131

Collected Steps per Second: 23,175.16323
Overall Steps per Second: 10,898.66937

Timestep Collection Time: 2.15835
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.58955

Cumulative Model Updates: 192,928
Cumulative Timesteps: 1,609,003,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1609003778...
Checkpoint 1609003778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.92992
Policy Entropy: 2.32643
Value Function Loss: 0.01593

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.55289
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 23,389.89900
Overall Steps per Second: 10,790.90585

Timestep Collection Time: 2.13767
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.63353

Cumulative Model Updates: 192,934
Cumulative Timesteps: 1,609,053,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.66398
Policy Entropy: 2.32749
Value Function Loss: 0.01572

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.61423

Collected Steps per Second: 22,943.65655
Overall Steps per Second: 10,853.50566

Timestep Collection Time: 2.18038
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.60920

Cumulative Model Updates: 192,940
Cumulative Timesteps: 1,609,103,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1609103804...
Checkpoint 1609103804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.48325
Policy Entropy: 2.35316
Value Function Loss: 0.01566

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.62491

Collected Steps per Second: 23,262.46326
Overall Steps per Second: 10,978.14186

Timestep Collection Time: 2.14990
Timestep Consumption Time: 2.40570
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.55560

Cumulative Model Updates: 192,946
Cumulative Timesteps: 1,609,153,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.43644
Policy Entropy: 2.32536
Value Function Loss: 0.01533

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.60347

Collected Steps per Second: 22,937.65579
Overall Steps per Second: 11,057.03235

Timestep Collection Time: 2.17991
Timestep Consumption Time: 2.34228
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.52219

Cumulative Model Updates: 192,952
Cumulative Timesteps: 1,609,203,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1609203818...
Checkpoint 1609203818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.43219
Policy Entropy: 2.35728
Value Function Loss: 0.01562

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.54797
Value Function Update Magnitude: 0.60403

Collected Steps per Second: 23,352.78029
Overall Steps per Second: 10,965.02212

Timestep Collection Time: 2.14210
Timestep Consumption Time: 2.42004
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.56214

Cumulative Model Updates: 192,958
Cumulative Timesteps: 1,609,253,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.72939
Policy Entropy: 2.33437
Value Function Loss: 0.01528

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.59028

Collected Steps per Second: 23,288.54374
Overall Steps per Second: 10,899.55600

Timestep Collection Time: 2.14732
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.58808

Cumulative Model Updates: 192,964
Cumulative Timesteps: 1,609,303,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1609303850...
Checkpoint 1609303850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.48348
Policy Entropy: 2.34230
Value Function Loss: 0.01557

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.59096

Collected Steps per Second: 23,147.32001
Overall Steps per Second: 10,703.55855

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.51197
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67265

Cumulative Model Updates: 192,970
Cumulative Timesteps: 1,609,353,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.93446
Policy Entropy: 2.33810
Value Function Loss: 0.01510

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.60409

Collected Steps per Second: 23,042.97202
Overall Steps per Second: 10,931.16616

Timestep Collection Time: 2.17125
Timestep Consumption Time: 2.40576
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.57700

Cumulative Model Updates: 192,976
Cumulative Timesteps: 1,609,403,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1609403896...
Checkpoint 1609403896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.36079
Policy Entropy: 2.32527
Value Function Loss: 0.01492

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.60985

Collected Steps per Second: 23,079.87126
Overall Steps per Second: 11,077.50933

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.34726
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.51365

Cumulative Model Updates: 192,982
Cumulative Timesteps: 1,609,453,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.01643
Policy Entropy: 2.33015
Value Function Loss: 0.01543

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.59277

Collected Steps per Second: 23,231.38102
Overall Steps per Second: 10,916.27739

Timestep Collection Time: 2.15226
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.58032

Cumulative Model Updates: 192,988
Cumulative Timesteps: 1,609,503,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1609503896...
Checkpoint 1609503896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.06632
Policy Entropy: 2.33856
Value Function Loss: 0.01604

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.58091

Collected Steps per Second: 23,125.99696
Overall Steps per Second: 10,737.60330

Timestep Collection Time: 2.16233
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.65709

Cumulative Model Updates: 192,994
Cumulative Timesteps: 1,609,553,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.69808
Policy Entropy: 2.33643
Value Function Loss: 0.01638

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.57767

Collected Steps per Second: 23,204.48146
Overall Steps per Second: 10,877.21316

Timestep Collection Time: 2.15553
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.59842

Cumulative Model Updates: 193,000
Cumulative Timesteps: 1,609,603,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1609603920...
Checkpoint 1609603920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.34060
Policy Entropy: 2.33851
Value Function Loss: 0.01516

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.57284

Collected Steps per Second: 23,145.10621
Overall Steps per Second: 10,813.86506

Timestep Collection Time: 2.16115
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.62554

Cumulative Model Updates: 193,006
Cumulative Timesteps: 1,609,653,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.77691
Policy Entropy: 2.33284
Value Function Loss: 0.01472

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.57374

Collected Steps per Second: 23,578.51720
Overall Steps per Second: 11,170.43674

Timestep Collection Time: 2.12168
Timestep Consumption Time: 2.35675
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.47843

Cumulative Model Updates: 193,012
Cumulative Timesteps: 1,609,703,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1609703966...
Checkpoint 1609703966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.07086
Policy Entropy: 2.34284
Value Function Loss: 0.01482

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.55899

Collected Steps per Second: 23,239.13651
Overall Steps per Second: 10,768.63535

Timestep Collection Time: 2.15275
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.64571

Cumulative Model Updates: 193,018
Cumulative Timesteps: 1,609,753,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.67811
Policy Entropy: 2.34170
Value Function Loss: 0.01544

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.54784

Collected Steps per Second: 23,187.74019
Overall Steps per Second: 10,803.18986

Timestep Collection Time: 2.15648
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.62863

Cumulative Model Updates: 193,024
Cumulative Timesteps: 1,609,803,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1609803998...
Checkpoint 1609803998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.68791
Policy Entropy: 2.33943
Value Function Loss: 0.01500

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.53593
Value Function Update Magnitude: 0.56978

Collected Steps per Second: 23,035.26437
Overall Steps per Second: 10,837.40554

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.61420

Cumulative Model Updates: 193,030
Cumulative Timesteps: 1,609,854,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.72351
Policy Entropy: 2.33562
Value Function Loss: 0.01543

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.55680

Collected Steps per Second: 23,453.89070
Overall Steps per Second: 10,894.87789

Timestep Collection Time: 2.13235
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.59041

Cumulative Model Updates: 193,036
Cumulative Timesteps: 1,609,904,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1609904016...
Checkpoint 1609904016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.73178
Policy Entropy: 2.34188
Value Function Loss: 0.01546

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.53678
Value Function Update Magnitude: 0.55240

Collected Steps per Second: 23,305.52971
Overall Steps per Second: 10,959.62976

Timestep Collection Time: 2.14550
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.56238

Cumulative Model Updates: 193,042
Cumulative Timesteps: 1,609,954,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.90499
Policy Entropy: 2.33775
Value Function Loss: 0.01474

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.52182
Value Function Update Magnitude: 0.54824

Collected Steps per Second: 23,293.36283
Overall Steps per Second: 10,877.93285

Timestep Collection Time: 2.14765
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.59885

Cumulative Model Updates: 193,048
Cumulative Timesteps: 1,610,004,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1610004044...
Checkpoint 1610004044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.79104
Policy Entropy: 2.35009
Value Function Loss: 0.01442

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.51571
Value Function Update Magnitude: 0.54670

Collected Steps per Second: 23,065.24080
Overall Steps per Second: 10,731.01430

Timestep Collection Time: 2.16811
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.66014

Cumulative Model Updates: 193,054
Cumulative Timesteps: 1,610,054,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.63675
Policy Entropy: 2.34468
Value Function Loss: 0.01472

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.55113

Collected Steps per Second: 23,059.62398
Overall Steps per Second: 10,792.70467

Timestep Collection Time: 2.16890
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.63406

Cumulative Model Updates: 193,060
Cumulative Timesteps: 1,610,104,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1610104066...
Checkpoint 1610104066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.80899
Policy Entropy: 2.34902
Value Function Loss: 0.01487

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.54856

Collected Steps per Second: 23,157.01681
Overall Steps per Second: 11,082.64840

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.35314
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.51300

Cumulative Model Updates: 193,066
Cumulative Timesteps: 1,610,154,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.57618
Policy Entropy: 2.35320
Value Function Loss: 0.01437

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.54104

Collected Steps per Second: 23,260.31420
Overall Steps per Second: 10,921.21715

Timestep Collection Time: 2.15079
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.58081

Cumulative Model Updates: 193,072
Cumulative Timesteps: 1,610,204,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1610204110...
Checkpoint 1610204110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.49995
Policy Entropy: 2.36331
Value Function Loss: 0.01436

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.52813
Value Function Update Magnitude: 0.56498

Collected Steps per Second: 23,279.60118
Overall Steps per Second: 10,816.53675

Timestep Collection Time: 2.14909
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.62533

Cumulative Model Updates: 193,078
Cumulative Timesteps: 1,610,254,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.41575
Policy Entropy: 2.36322
Value Function Loss: 0.01411

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.53779
Value Function Update Magnitude: 0.57690

Collected Steps per Second: 23,521.08541
Overall Steps per Second: 10,753.41218

Timestep Collection Time: 2.12592
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.65006

Cumulative Model Updates: 193,084
Cumulative Timesteps: 1,610,304,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1610304144...
Checkpoint 1610304144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.98920
Policy Entropy: 2.35303
Value Function Loss: 0.01340

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.58475

Collected Steps per Second: 23,084.79255
Overall Steps per Second: 10,805.12696

Timestep Collection Time: 2.16601
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.62762

Cumulative Model Updates: 193,090
Cumulative Timesteps: 1,610,354,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.44495
Policy Entropy: 2.34044
Value Function Loss: 0.01410

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.53675
Value Function Update Magnitude: 0.58364

Collected Steps per Second: 23,369.49442
Overall Steps per Second: 11,134.01072

Timestep Collection Time: 2.14031
Timestep Consumption Time: 2.35205
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.49236

Cumulative Model Updates: 193,096
Cumulative Timesteps: 1,610,404,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1610404164...
Checkpoint 1610404164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.97538
Policy Entropy: 2.35085
Value Function Loss: 0.01403

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.59518

Collected Steps per Second: 23,081.53700
Overall Steps per Second: 10,723.98911

Timestep Collection Time: 2.16719
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.66450

Cumulative Model Updates: 193,102
Cumulative Timesteps: 1,610,454,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.43357
Policy Entropy: 2.34367
Value Function Loss: 0.01660

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.54942
Value Function Update Magnitude: 0.60500

Collected Steps per Second: 23,363.99474
Overall Steps per Second: 10,963.75978

Timestep Collection Time: 2.14030
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.56103

Cumulative Model Updates: 193,108
Cumulative Timesteps: 1,610,504,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1610504192...
Checkpoint 1610504192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.48535
Policy Entropy: 2.35537
Value Function Loss: 0.01577

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.61930

Collected Steps per Second: 23,100.70291
Overall Steps per Second: 10,805.18269

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.46386
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.62907

Cumulative Model Updates: 193,114
Cumulative Timesteps: 1,610,554,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.73575
Policy Entropy: 2.34812
Value Function Loss: 0.01643

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 23,171.29399
Overall Steps per Second: 11,076.13793

Timestep Collection Time: 2.15801
Timestep Consumption Time: 2.35656
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.51457

Cumulative Model Updates: 193,120
Cumulative Timesteps: 1,610,604,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1610604214...
Checkpoint 1610604214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.33846
Policy Entropy: 2.36415
Value Function Loss: 0.01540

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.57206

Collected Steps per Second: 23,034.53245
Overall Steps per Second: 10,711.70289

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.49714
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.66779

Cumulative Model Updates: 193,126
Cumulative Timesteps: 1,610,654,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.71802
Policy Entropy: 2.33040
Value Function Loss: 0.01624

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.60217

Collected Steps per Second: 23,409.06980
Overall Steps per Second: 10,967.85728

Timestep Collection Time: 2.13695
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.56096

Cumulative Model Updates: 193,132
Cumulative Timesteps: 1,610,704,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1610704238...
Checkpoint 1610704238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.88074
Policy Entropy: 2.33120
Value Function Loss: 0.01449

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.53891
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 22,914.92463
Overall Steps per Second: 10,711.65940

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.67005

Cumulative Model Updates: 193,138
Cumulative Timesteps: 1,610,754,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.29855
Policy Entropy: 2.33173
Value Function Loss: 0.01507

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.58941

Collected Steps per Second: 22,767.70818
Overall Steps per Second: 10,804.07584

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.62788

Cumulative Model Updates: 193,144
Cumulative Timesteps: 1,610,804,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1610804262...
Checkpoint 1610804262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.62397
Policy Entropy: 2.32779
Value Function Loss: 0.01516

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.58056

Collected Steps per Second: 22,847.12708
Overall Steps per Second: 11,031.49217

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.34411
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.53266

Cumulative Model Updates: 193,150
Cumulative Timesteps: 1,610,854,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.81355
Policy Entropy: 2.30177
Value Function Loss: 0.01537

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.56002
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 23,583.02081
Overall Steps per Second: 11,010.48799

Timestep Collection Time: 2.12093
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.54276

Cumulative Model Updates: 193,156
Cumulative Timesteps: 1,610,904,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1610904282...
Checkpoint 1610904282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.40141
Policy Entropy: 2.27515
Value Function Loss: 0.01534

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.59302

Collected Steps per Second: 23,278.07048
Overall Steps per Second: 10,789.62415

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.63668

Cumulative Model Updates: 193,162
Cumulative Timesteps: 1,610,954,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.82065
Policy Entropy: 2.27487
Value Function Loss: 0.01500

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 23,140.75523
Overall Steps per Second: 10,771.77656

Timestep Collection Time: 2.16173
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.64399

Cumulative Model Updates: 193,168
Cumulative Timesteps: 1,611,004,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1611004334...
Checkpoint 1611004334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.80289
Policy Entropy: 2.28841
Value Function Loss: 0.01541

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 23,131.27961
Overall Steps per Second: 10,816.21082

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.46161
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.62362

Cumulative Model Updates: 193,174
Cumulative Timesteps: 1,611,054,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.61958
Policy Entropy: 2.29532
Value Function Loss: 0.01568

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.55401
Value Function Update Magnitude: 0.61031

Collected Steps per Second: 23,446.44340
Overall Steps per Second: 11,096.77604

Timestep Collection Time: 2.13303
Timestep Consumption Time: 2.37386
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.50689

Cumulative Model Updates: 193,180
Cumulative Timesteps: 1,611,104,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1611104356...
Checkpoint 1611104356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.30236
Policy Entropy: 2.29757
Value Function Loss: 0.01668

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.61061

Collected Steps per Second: 23,295.60905
Overall Steps per Second: 10,778.98338

Timestep Collection Time: 2.14693
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.63996

Cumulative Model Updates: 193,186
Cumulative Timesteps: 1,611,154,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.88131
Policy Entropy: 2.27220
Value Function Loss: 0.01667

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.58727

Collected Steps per Second: 23,389.83187
Overall Steps per Second: 10,874.63192

Timestep Collection Time: 2.13845
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.59951

Cumulative Model Updates: 193,192
Cumulative Timesteps: 1,611,204,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1611204388...
Checkpoint 1611204388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.98808
Policy Entropy: 2.27976
Value Function Loss: 0.01596

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.55395
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 23,183.24244
Overall Steps per Second: 10,789.32350

Timestep Collection Time: 2.15768
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.63625

Cumulative Model Updates: 193,198
Cumulative Timesteps: 1,611,254,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.35145
Policy Entropy: 2.28990
Value Function Loss: 0.01548

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.60002

Collected Steps per Second: 23,277.36517
Overall Steps per Second: 10,809.06054

Timestep Collection Time: 2.14913
Timestep Consumption Time: 2.47903
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.62815

Cumulative Model Updates: 193,204
Cumulative Timesteps: 1,611,304,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1611304436...
Checkpoint 1611304436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.94542
Policy Entropy: 2.27514
Value Function Loss: 0.01561

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.60532

Collected Steps per Second: 23,143.90629
Overall Steps per Second: 11,018.44961

Timestep Collection Time: 2.16100
Timestep Consumption Time: 2.37811
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.53911

Cumulative Model Updates: 193,210
Cumulative Timesteps: 1,611,354,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.89401
Policy Entropy: 2.28339
Value Function Loss: 0.01503

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 23,090.11429
Overall Steps per Second: 10,878.14928

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59674

Cumulative Model Updates: 193,216
Cumulative Timesteps: 1,611,404,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1611404454...
Checkpoint 1611404454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.18380
Policy Entropy: 2.28569
Value Function Loss: 0.01539

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.55492
Value Function Update Magnitude: 0.58868

Collected Steps per Second: 23,168.67512
Overall Steps per Second: 10,743.43524

Timestep Collection Time: 2.15999
Timestep Consumption Time: 2.49811
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.65810

Cumulative Model Updates: 193,222
Cumulative Timesteps: 1,611,454,498

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.84856
Policy Entropy: 2.28810
Value Function Loss: 0.01544

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.58005

Collected Steps per Second: 22,927.36821
Overall Steps per Second: 10,883.22887

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.41343
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.59422

Cumulative Model Updates: 193,228
Cumulative Timesteps: 1,611,504,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1611504498...
Checkpoint 1611504498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.92018
Policy Entropy: 2.29372
Value Function Loss: 0.01598

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.56356
Value Function Update Magnitude: 0.58079

Collected Steps per Second: 23,027.05036
Overall Steps per Second: 11,018.78663

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.36739
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.53970

Cumulative Model Updates: 193,234
Cumulative Timesteps: 1,611,554,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.93940
Policy Entropy: 2.29242
Value Function Loss: 0.01546

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.59773

Collected Steps per Second: 23,122.33135
Overall Steps per Second: 10,749.60201

Timestep Collection Time: 2.16258
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.65171

Cumulative Model Updates: 193,240
Cumulative Timesteps: 1,611,604,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1611604524...
Checkpoint 1611604524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.67253
Policy Entropy: 2.30392
Value Function Loss: 0.01390

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.61606

Collected Steps per Second: 22,834.07007
Overall Steps per Second: 10,828.77829

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.61843

Cumulative Model Updates: 193,246
Cumulative Timesteps: 1,611,654,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.23707
Policy Entropy: 2.29862
Value Function Loss: 0.01507

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.61438

Collected Steps per Second: 23,280.33116
Overall Steps per Second: 10,940.07553

Timestep Collection Time: 2.14799
Timestep Consumption Time: 2.42291
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.57090

Cumulative Model Updates: 193,252
Cumulative Timesteps: 1,611,704,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1611704542...
Checkpoint 1611704542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.33834
Policy Entropy: 2.29471
Value Function Loss: 0.01594

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.60621

Collected Steps per Second: 22,916.23657
Overall Steps per Second: 10,753.35187

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.65139

Cumulative Model Updates: 193,258
Cumulative Timesteps: 1,611,754,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.48157
Policy Entropy: 2.30331
Value Function Loss: 0.01655

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.55864
Value Function Update Magnitude: 0.59455

Collected Steps per Second: 23,582.31577
Overall Steps per Second: 10,863.32364

Timestep Collection Time: 2.12091
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.60412

Cumulative Model Updates: 193,264
Cumulative Timesteps: 1,611,804,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1611804576...
Checkpoint 1611804576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.77362
Policy Entropy: 2.30406
Value Function Loss: 0.01521

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 23,191.20084
Overall Steps per Second: 11,038.01737

Timestep Collection Time: 2.15703
Timestep Consumption Time: 2.37495
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.53197

Cumulative Model Updates: 193,270
Cumulative Timesteps: 1,611,854,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.85667
Policy Entropy: 2.29856
Value Function Loss: 0.01393

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.55417

Collected Steps per Second: 23,180.76969
Overall Steps per Second: 10,895.68128

Timestep Collection Time: 2.15817
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59154

Cumulative Model Updates: 193,276
Cumulative Timesteps: 1,611,904,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1611904628...
Checkpoint 1611904628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.49814
Policy Entropy: 2.26647
Value Function Loss: 0.01423

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.16749
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.53600

Collected Steps per Second: 23,142.08966
Overall Steps per Second: 10,722.86481

Timestep Collection Time: 2.16065
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.66312

Cumulative Model Updates: 193,282
Cumulative Timesteps: 1,611,954,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.69970
Policy Entropy: 2.26404
Value Function Loss: 0.01515

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.51786
Value Function Update Magnitude: 0.54959

Collected Steps per Second: 23,218.53055
Overall Steps per Second: 10,859.66923

Timestep Collection Time: 2.15371
Timestep Consumption Time: 2.45103
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.60474

Cumulative Model Updates: 193,288
Cumulative Timesteps: 1,612,004,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1612004636...
Checkpoint 1612004636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.40438
Policy Entropy: 2.27751
Value Function Loss: 0.01525

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.17275
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.58597

Collected Steps per Second: 23,083.87968
Overall Steps per Second: 11,047.79185

Timestep Collection Time: 2.16662
Timestep Consumption Time: 2.36044
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.52706

Cumulative Model Updates: 193,294
Cumulative Timesteps: 1,612,054,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.34565
Policy Entropy: 2.30372
Value Function Loss: 0.01463

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.55630
Value Function Update Magnitude: 0.59035

Collected Steps per Second: 23,575.51962
Overall Steps per Second: 10,965.93388

Timestep Collection Time: 2.12178
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.56158

Cumulative Model Updates: 193,300
Cumulative Timesteps: 1,612,104,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1612104672...
Checkpoint 1612104672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.00173
Policy Entropy: 2.31772
Value Function Loss: 0.01407

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.53863
Value Function Update Magnitude: 0.58091

Collected Steps per Second: 23,213.40407
Overall Steps per Second: 10,775.52286

Timestep Collection Time: 2.15444
Timestep Consumption Time: 2.48681
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.64126

Cumulative Model Updates: 193,306
Cumulative Timesteps: 1,612,154,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.25305
Policy Entropy: 2.32409
Value Function Loss: 0.01507

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.58783

Collected Steps per Second: 23,348.39447
Overall Steps per Second: 10,782.47371

Timestep Collection Time: 2.14225
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.63882

Cumulative Model Updates: 193,312
Cumulative Timesteps: 1,612,204,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1612204702...
Checkpoint 1612204702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.70298
Policy Entropy: 2.30681
Value Function Loss: 0.01550

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.62541

Collected Steps per Second: 23,040.56698
Overall Steps per Second: 10,791.83771

Timestep Collection Time: 2.17043
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.63387

Cumulative Model Updates: 193,318
Cumulative Timesteps: 1,612,254,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.22080
Policy Entropy: 2.29307
Value Function Loss: 0.01571

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.63171

Collected Steps per Second: 23,434.88638
Overall Steps per Second: 11,140.43519

Timestep Collection Time: 2.13485
Timestep Consumption Time: 2.35600
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.49085

Cumulative Model Updates: 193,324
Cumulative Timesteps: 1,612,304,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1612304740...
Checkpoint 1612304740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.03027
Policy Entropy: 2.29156
Value Function Loss: 0.01553

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.61705

Collected Steps per Second: 23,122.53124
Overall Steps per Second: 10,684.15490

Timestep Collection Time: 2.16265
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68039

Cumulative Model Updates: 193,330
Cumulative Timesteps: 1,612,354,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.57083
Policy Entropy: 2.28148
Value Function Loss: 0.01556

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.59629

Collected Steps per Second: 23,366.70319
Overall Steps per Second: 10,899.80376

Timestep Collection Time: 2.14022
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58816

Cumulative Model Updates: 193,336
Cumulative Timesteps: 1,612,404,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1612404756...
Checkpoint 1612404756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.24544
Policy Entropy: 2.27805
Value Function Loss: 0.01459

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.58543

Collected Steps per Second: 22,871.21802
Overall Steps per Second: 10,694.91002

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.67718

Cumulative Model Updates: 193,342
Cumulative Timesteps: 1,612,454,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.77921
Policy Entropy: 2.26650
Value Function Loss: 0.01525

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.58185

Collected Steps per Second: 23,481.00334
Overall Steps per Second: 10,978.65627

Timestep Collection Time: 2.12972
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.55502

Cumulative Model Updates: 193,348
Cumulative Timesteps: 1,612,504,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1612504786...
Checkpoint 1612504786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.56909
Policy Entropy: 2.25347
Value Function Loss: 0.01524

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.55544
Value Function Update Magnitude: 0.61750

Collected Steps per Second: 23,366.66214
Overall Steps per Second: 10,942.19738

Timestep Collection Time: 2.13980
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.56947

Cumulative Model Updates: 193,354
Cumulative Timesteps: 1,612,554,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.99311
Policy Entropy: 2.24471
Value Function Loss: 0.01596

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.62804

Collected Steps per Second: 23,501.61686
Overall Steps per Second: 10,947.25492

Timestep Collection Time: 2.12819
Timestep Consumption Time: 2.44062
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.56882

Cumulative Model Updates: 193,360
Cumulative Timesteps: 1,612,604,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1612604802...
Checkpoint 1612604802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.41226
Policy Entropy: 2.25199
Value Function Loss: 0.01608

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 23,193.38314
Overall Steps per Second: 10,767.61583

Timestep Collection Time: 2.15725
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.64671

Cumulative Model Updates: 193,366
Cumulative Timesteps: 1,612,654,836

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.57245
Policy Entropy: 2.27330
Value Function Loss: 0.01571

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.60321

Collected Steps per Second: 22,934.84255
Overall Steps per Second: 10,826.40669

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.61889

Cumulative Model Updates: 193,372
Cumulative Timesteps: 1,612,704,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1612704842...
Checkpoint 1612704842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.53685
Policy Entropy: 2.26933
Value Function Loss: 0.01553

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 23,266.45062
Overall Steps per Second: 11,137.98357

Timestep Collection Time: 2.15031
Timestep Consumption Time: 2.34153
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.49184

Cumulative Model Updates: 193,378
Cumulative Timesteps: 1,612,754,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.78538
Policy Entropy: 2.28017
Value Function Loss: 0.01583

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.62592

Collected Steps per Second: 23,428.91529
Overall Steps per Second: 10,890.68910

Timestep Collection Time: 2.13488
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.59273

Cumulative Model Updates: 193,384
Cumulative Timesteps: 1,612,804,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1612804890...
Checkpoint 1612804890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.45556
Policy Entropy: 2.26333
Value Function Loss: 0.01569

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.64022

Collected Steps per Second: 22,956.88181
Overall Steps per Second: 10,699.08084

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67479

Cumulative Model Updates: 193,390
Cumulative Timesteps: 1,612,854,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.13119
Policy Entropy: 2.25119
Value Function Loss: 0.01625

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.63526

Collected Steps per Second: 23,262.39918
Overall Steps per Second: 10,840.26251

Timestep Collection Time: 2.15034
Timestep Consumption Time: 2.46413
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.61446

Cumulative Model Updates: 193,396
Cumulative Timesteps: 1,612,904,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1612904928...
Checkpoint 1612904928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.60250
Policy Entropy: 2.24583
Value Function Loss: 0.01487

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15993
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.62025

Collected Steps per Second: 23,282.09896
Overall Steps per Second: 10,990.24590

Timestep Collection Time: 2.14774
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.54985

Cumulative Model Updates: 193,402
Cumulative Timesteps: 1,612,954,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.99950
Policy Entropy: 2.25732
Value Function Loss: 0.01527

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.61115

Collected Steps per Second: 23,175.74095
Overall Steps per Second: 11,038.60036

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.37299
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.53119

Cumulative Model Updates: 193,408
Cumulative Timesteps: 1,613,004,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1613004950...
Checkpoint 1613004950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.84332
Policy Entropy: 2.25113
Value Function Loss: 0.01562

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.61074

Collected Steps per Second: 22,825.08971
Overall Steps per Second: 10,674.10341

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.68592

Cumulative Model Updates: 193,414
Cumulative Timesteps: 1,613,054,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.85471
Policy Entropy: 2.24289
Value Function Loss: 0.01662

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.62319

Collected Steps per Second: 23,480.71285
Overall Steps per Second: 10,860.97035

Timestep Collection Time: 2.12992
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.60475

Cumulative Model Updates: 193,420
Cumulative Timesteps: 1,613,104,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1613104980...
Checkpoint 1613104980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.59927
Policy Entropy: 2.23905
Value Function Loss: 0.01626

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.62492

Collected Steps per Second: 23,269.69332
Overall Steps per Second: 10,850.73488

Timestep Collection Time: 2.14992
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.61056

Cumulative Model Updates: 193,426
Cumulative Timesteps: 1,613,155,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.20919
Policy Entropy: 2.25740
Value Function Loss: 0.01601

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.56159
Value Function Update Magnitude: 0.62293

Collected Steps per Second: 23,008.68123
Overall Steps per Second: 11,034.40829

Timestep Collection Time: 2.17448
Timestep Consumption Time: 2.35970
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.53418

Cumulative Model Updates: 193,432
Cumulative Timesteps: 1,613,205,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1613205040...
Checkpoint 1613205040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.99713
Policy Entropy: 2.25909
Value Function Loss: 0.01608

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.62356

Collected Steps per Second: 22,461.43743
Overall Steps per Second: 10,730.10221

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.66109

Cumulative Model Updates: 193,438
Cumulative Timesteps: 1,613,255,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.33545
Policy Entropy: 2.25465
Value Function Loss: 0.01645

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.63574

Collected Steps per Second: 23,414.27541
Overall Steps per Second: 10,949.66355

Timestep Collection Time: 2.13647
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.56854

Cumulative Model Updates: 193,444
Cumulative Timesteps: 1,613,305,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1613305078...
Checkpoint 1613305078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.34841
Policy Entropy: 2.25422
Value Function Loss: 0.01589

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.57021
Value Function Update Magnitude: 0.64890

Collected Steps per Second: 22,944.82408
Overall Steps per Second: 10,678.93622

Timestep Collection Time: 2.17914
Timestep Consumption Time: 2.50297
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.68211

Cumulative Model Updates: 193,450
Cumulative Timesteps: 1,613,355,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.59643
Policy Entropy: 2.24732
Value Function Loss: 0.01448

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.64264

Collected Steps per Second: 23,181.66793
Overall Steps per Second: 10,863.51500

Timestep Collection Time: 2.15765
Timestep Consumption Time: 2.44657
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.60422

Cumulative Model Updates: 193,456
Cumulative Timesteps: 1,613,405,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1613405096...
Checkpoint 1613405096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.99674
Policy Entropy: 2.28652
Value Function Loss: 0.01402

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.61088

Collected Steps per Second: 23,005.63992
Overall Steps per Second: 11,053.02647

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.35027
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.52365

Cumulative Model Updates: 193,462
Cumulative Timesteps: 1,613,455,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.95198
Policy Entropy: 2.28345
Value Function Loss: 0.01499

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.60096

Collected Steps per Second: 23,197.23863
Overall Steps per Second: 10,907.31854

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.58554

Cumulative Model Updates: 193,468
Cumulative Timesteps: 1,613,505,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1613505112...
Checkpoint 1613505112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.09058
Policy Entropy: 2.29346
Value Function Loss: 0.01528

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.59979

Collected Steps per Second: 23,133.79877
Overall Steps per Second: 10,721.67095

Timestep Collection Time: 2.16134
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.66345

Cumulative Model Updates: 193,474
Cumulative Timesteps: 1,613,555,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.06540
Policy Entropy: 2.25070
Value Function Loss: 0.01632

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 23,110.36825
Overall Steps per Second: 10,876.67926

Timestep Collection Time: 2.16483
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59975

Cumulative Model Updates: 193,480
Cumulative Timesteps: 1,613,605,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1613605142...
Checkpoint 1613605142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.47196
Policy Entropy: 2.24995
Value Function Loss: 0.01564

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 23,014.67374
Overall Steps per Second: 10,810.24924

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.62598

Cumulative Model Updates: 193,486
Cumulative Timesteps: 1,613,655,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.34003
Policy Entropy: 2.25891
Value Function Loss: 0.01633

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.57247

Collected Steps per Second: 24,226.91286
Overall Steps per Second: 11,135.03714

Timestep Collection Time: 2.06456
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.49195

Cumulative Model Updates: 193,492
Cumulative Timesteps: 1,613,705,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1613705168...
Checkpoint 1613705168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.15654
Policy Entropy: 2.28682
Value Function Loss: 0.01640

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.57541

Collected Steps per Second: 23,121.49311
Overall Steps per Second: 10,724.14435

Timestep Collection Time: 2.16301
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66350

Cumulative Model Updates: 193,498
Cumulative Timesteps: 1,613,755,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.71438
Policy Entropy: 2.29601
Value Function Loss: 0.01562

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.54201
Value Function Update Magnitude: 0.56923

Collected Steps per Second: 23,283.01497
Overall Steps per Second: 10,923.74581

Timestep Collection Time: 2.14818
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.57865

Cumulative Model Updates: 193,504
Cumulative Timesteps: 1,613,805,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1613805196...
Checkpoint 1613805196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.28067
Policy Entropy: 2.26186
Value Function Loss: 0.01592

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.56686

Collected Steps per Second: 23,173.47423
Overall Steps per Second: 10,969.91209

Timestep Collection Time: 2.15833
Timestep Consumption Time: 2.40105
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.55938

Cumulative Model Updates: 193,510
Cumulative Timesteps: 1,613,855,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.56777
Policy Entropy: 2.22670
Value Function Loss: 0.01652

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.59149

Collected Steps per Second: 23,117.39393
Overall Steps per Second: 10,917.51369

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58035

Cumulative Model Updates: 193,516
Cumulative Timesteps: 1,613,905,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1613905218...
Checkpoint 1613905218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.08179
Policy Entropy: 2.21998
Value Function Loss: 0.01568

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 23,872.34025
Overall Steps per Second: 10,968.19327

Timestep Collection Time: 2.09514
Timestep Consumption Time: 2.46495
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.56009

Cumulative Model Updates: 193,522
Cumulative Timesteps: 1,613,955,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.80282
Policy Entropy: 2.24023
Value Function Loss: 0.01584

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.58668

Collected Steps per Second: 23,241.62932
Overall Steps per Second: 10,779.98483

Timestep Collection Time: 2.15234
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.64045

Cumulative Model Updates: 193,528
Cumulative Timesteps: 1,614,005,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1614005258...
Checkpoint 1614005258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.80133
Policy Entropy: 2.26261
Value Function Loss: 0.01573

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.54444
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 22,865.14124
Overall Steps per Second: 10,739.07602

Timestep Collection Time: 2.18787
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.65832

Cumulative Model Updates: 193,534
Cumulative Timesteps: 1,614,055,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.25048
Policy Entropy: 2.26840
Value Function Loss: 0.01543

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 23,099.49484
Overall Steps per Second: 10,770.77473

Timestep Collection Time: 2.16455
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.64219

Cumulative Model Updates: 193,540
Cumulative Timesteps: 1,614,105,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1614105284...
Checkpoint 1614105284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.96928
Policy Entropy: 2.26967
Value Function Loss: 0.01573

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.59219

Collected Steps per Second: 23,247.09739
Overall Steps per Second: 11,046.25047

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.37695
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.52896

Cumulative Model Updates: 193,546
Cumulative Timesteps: 1,614,155,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.32350
Policy Entropy: 2.25990
Value Function Loss: 0.01582

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.58324

Collected Steps per Second: 22,324.58490
Overall Steps per Second: 10,890.52514

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.35222
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59262

Cumulative Model Updates: 193,552
Cumulative Timesteps: 1,614,205,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1614205328...
Checkpoint 1614205328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.92473
Policy Entropy: 2.24672
Value Function Loss: 0.01648

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.58717

Collected Steps per Second: 23,212.32228
Overall Steps per Second: 10,823.76792

Timestep Collection Time: 2.15411
Timestep Consumption Time: 2.46553
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.61965

Cumulative Model Updates: 193,558
Cumulative Timesteps: 1,614,255,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.34089
Policy Entropy: 2.24108
Value Function Loss: 0.01624

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 23,424.20636
Overall Steps per Second: 10,785.37964

Timestep Collection Time: 2.13471
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.63628

Cumulative Model Updates: 193,564
Cumulative Timesteps: 1,614,305,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1614305334...
Checkpoint 1614305334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.15478
Policy Entropy: 2.22819
Value Function Loss: 0.01520

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.61201

Collected Steps per Second: 23,041.46192
Overall Steps per Second: 10,955.27622

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.39545
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.56675

Cumulative Model Updates: 193,570
Cumulative Timesteps: 1,614,355,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.43464
Policy Entropy: 2.25252
Value Function Loss: 0.01521

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 23,133.58800
Overall Steps per Second: 11,010.00309

Timestep Collection Time: 2.16153
Timestep Consumption Time: 2.38016
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.54169

Cumulative Model Updates: 193,576
Cumulative Timesteps: 1,614,405,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1614405368...
Checkpoint 1614405368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.95144
Policy Entropy: 2.27001
Value Function Loss: 0.01503

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.58855

Collected Steps per Second: 23,204.27613
Overall Steps per Second: 10,822.80451

Timestep Collection Time: 2.15529
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.62098

Cumulative Model Updates: 193,582
Cumulative Timesteps: 1,614,455,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.89108
Policy Entropy: 2.30156
Value Function Loss: 0.01500

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.58529

Collected Steps per Second: 23,625.00916
Overall Steps per Second: 10,889.90142

Timestep Collection Time: 2.11716
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.59306

Cumulative Model Updates: 193,588
Cumulative Timesteps: 1,614,505,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1614505398...
Checkpoint 1614505398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.34018
Policy Entropy: 2.28445
Value Function Loss: 0.01506

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.53790
Value Function Update Magnitude: 0.57890

Collected Steps per Second: 23,146.43248
Overall Steps per Second: 10,883.28885

Timestep Collection Time: 2.16146
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.59696

Cumulative Model Updates: 193,594
Cumulative Timesteps: 1,614,555,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.20810
Policy Entropy: 2.27946
Value Function Loss: 0.01479

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 23,194.86325
Overall Steps per Second: 10,932.50029

Timestep Collection Time: 2.15565
Timestep Consumption Time: 2.41787
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.57352

Cumulative Model Updates: 193,600
Cumulative Timesteps: 1,614,605,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1614605428...
Checkpoint 1614605428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.17753
Policy Entropy: 2.27436
Value Function Loss: 0.01512

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.56857

Collected Steps per Second: 22,934.57040
Overall Steps per Second: 11,036.69320

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.35107
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.53197

Cumulative Model Updates: 193,606
Cumulative Timesteps: 1,614,655,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.18411
Policy Entropy: 2.28237
Value Function Loss: 0.01583

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 23,255.15104
Overall Steps per Second: 10,913.62491

Timestep Collection Time: 2.15049
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.58235

Cumulative Model Updates: 193,612
Cumulative Timesteps: 1,614,705,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1614705456...
Checkpoint 1614705456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.47791
Policy Entropy: 2.27377
Value Function Loss: 0.01608

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 23,204.70622
Overall Steps per Second: 10,724.44825

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.66430

Cumulative Model Updates: 193,618
Cumulative Timesteps: 1,614,755,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.31265
Policy Entropy: 2.27556
Value Function Loss: 0.01618

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.61858

Collected Steps per Second: 22,954.32886
Overall Steps per Second: 10,905.83035

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.40752
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.58672

Cumulative Model Updates: 193,624
Cumulative Timesteps: 1,614,805,500

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1614805500...
Checkpoint 1614805500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.42569
Policy Entropy: 2.27535
Value Function Loss: 0.01549

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.60078

Collected Steps per Second: 23,116.67969
Overall Steps per Second: 10,809.02208

Timestep Collection Time: 2.16303
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.62595

Cumulative Model Updates: 193,630
Cumulative Timesteps: 1,614,855,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.69789
Policy Entropy: 2.27882
Value Function Loss: 0.01568

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.57324

Collected Steps per Second: 23,277.42668
Overall Steps per Second: 10,989.45093

Timestep Collection Time: 2.14861
Timestep Consumption Time: 2.40249
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.55109

Cumulative Model Updates: 193,636
Cumulative Timesteps: 1,614,905,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1614905516...
Checkpoint 1614905516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.31238
Policy Entropy: 2.27388
Value Function Loss: 0.01548

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.53743
Value Function Update Magnitude: 0.55479

Collected Steps per Second: 23,137.16341
Overall Steps per Second: 10,867.74996

Timestep Collection Time: 2.16146
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.60169

Cumulative Model Updates: 193,642
Cumulative Timesteps: 1,614,955,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.23582
Policy Entropy: 2.28098
Value Function Loss: 0.01585

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.17758
Policy Update Magnitude: 0.51594
Value Function Update Magnitude: 0.57282

Collected Steps per Second: 23,030.54211
Overall Steps per Second: 10,855.15646

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60703

Cumulative Model Updates: 193,648
Cumulative Timesteps: 1,615,005,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1615005536...
Checkpoint 1615005536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.74935
Policy Entropy: 2.26523
Value Function Loss: 0.01550

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.50949
Value Function Update Magnitude: 0.58363

Collected Steps per Second: 23,053.68920
Overall Steps per Second: 10,686.30358

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68038

Cumulative Model Updates: 193,654
Cumulative Timesteps: 1,615,055,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.94538
Policy Entropy: 2.28755
Value Function Loss: 0.01527

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.59301

Collected Steps per Second: 23,128.31095
Overall Steps per Second: 10,942.14119

Timestep Collection Time: 2.16298
Timestep Consumption Time: 2.40889
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.57187

Cumulative Model Updates: 193,660
Cumulative Timesteps: 1,615,105,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1615105578...
Checkpoint 1615105578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.99968
Policy Entropy: 2.29599
Value Function Loss: 0.01512

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.53951
Value Function Update Magnitude: 0.59154

Collected Steps per Second: 23,073.11399
Overall Steps per Second: 11,087.54453

Timestep Collection Time: 2.16728
Timestep Consumption Time: 2.34282
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.51011

Cumulative Model Updates: 193,666
Cumulative Timesteps: 1,615,155,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.58352
Policy Entropy: 2.32012
Value Function Loss: 0.01567

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.53601
Value Function Update Magnitude: 0.58498

Collected Steps per Second: 23,479.33222
Overall Steps per Second: 10,932.09333

Timestep Collection Time: 2.12979
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.57424

Cumulative Model Updates: 193,672
Cumulative Timesteps: 1,615,205,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1615205590...
Checkpoint 1615205590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.87971
Policy Entropy: 2.31317
Value Function Loss: 0.01637

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 22,878.17482
Overall Steps per Second: 10,670.41941

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.50176
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.68848

Cumulative Model Updates: 193,678
Cumulative Timesteps: 1,615,255,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.93857
Policy Entropy: 2.33286
Value Function Loss: 0.01633

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.57475

Collected Steps per Second: 23,311.85927
Overall Steps per Second: 10,869.60206

Timestep Collection Time: 2.14569
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.60182

Cumulative Model Updates: 193,684
Cumulative Timesteps: 1,615,305,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1615305638...
Checkpoint 1615305638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.95053
Policy Entropy: 2.32098
Value Function Loss: 0.01584

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.56520

Collected Steps per Second: 22,926.60055
Overall Steps per Second: 11,025.02683

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.35502
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.53659

Cumulative Model Updates: 193,690
Cumulative Timesteps: 1,615,355,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.43446
Policy Entropy: 2.31873
Value Function Loss: 0.01544

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.56282

Collected Steps per Second: 23,434.09601
Overall Steps per Second: 10,998.71248

Timestep Collection Time: 2.13398
Timestep Consumption Time: 2.41273
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.54671

Cumulative Model Updates: 193,696
Cumulative Timesteps: 1,615,405,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1615405662...
Checkpoint 1615405662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.74455
Policy Entropy: 2.28751
Value Function Loss: 0.01534

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 23,118.56337
Overall Steps per Second: 10,728.93307

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.66123

Cumulative Model Updates: 193,702
Cumulative Timesteps: 1,615,455,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.24019
Policy Entropy: 2.27348
Value Function Loss: 0.01507

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.55444

Collected Steps per Second: 23,299.19097
Overall Steps per Second: 10,813.98066

Timestep Collection Time: 2.14694
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.62568

Cumulative Model Updates: 193,708
Cumulative Timesteps: 1,615,505,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1615505694...
Checkpoint 1615505694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.15584
Policy Entropy: 2.27656
Value Function Loss: 0.01531

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.55999

Collected Steps per Second: 23,123.16443
Overall Steps per Second: 10,841.29372

Timestep Collection Time: 2.16233
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.61200

Cumulative Model Updates: 193,714
Cumulative Timesteps: 1,615,555,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.80371
Policy Entropy: 2.28484
Value Function Loss: 0.01416

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.56543

Collected Steps per Second: 23,456.28000
Overall Steps per Second: 11,154.65564

Timestep Collection Time: 2.13188
Timestep Consumption Time: 2.35109
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.48297

Cumulative Model Updates: 193,720
Cumulative Timesteps: 1,615,605,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1615605700...
Checkpoint 1615605700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.65438
Policy Entropy: 2.30428
Value Function Loss: 0.01444

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.54439

Collected Steps per Second: 22,790.19912
Overall Steps per Second: 10,673.12995

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.68616

Cumulative Model Updates: 193,726
Cumulative Timesteps: 1,615,655,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.61977
Policy Entropy: 2.31404
Value Function Loss: 0.01442

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.53509
Value Function Update Magnitude: 0.52594

Collected Steps per Second: 23,518.50726
Overall Steps per Second: 10,888.97968

Timestep Collection Time: 2.12735
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.59474

Cumulative Model Updates: 193,732
Cumulative Timesteps: 1,615,705,748

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1615705748...
Checkpoint 1615705748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.69133
Policy Entropy: 2.30215
Value Function Loss: 0.01554

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.54461

Collected Steps per Second: 23,051.26968
Overall Steps per Second: 10,716.52735

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.66830

Cumulative Model Updates: 193,738
Cumulative Timesteps: 1,615,755,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.98218
Policy Entropy: 2.27888
Value Function Loss: 0.01595

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 23,130.34098
Overall Steps per Second: 10,831.02699

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.61803

Cumulative Model Updates: 193,744
Cumulative Timesteps: 1,615,805,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1615805794...
Checkpoint 1615805794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.74582
Policy Entropy: 2.26190
Value Function Loss: 0.01572

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 23,243.94077
Overall Steps per Second: 11,130.83071

Timestep Collection Time: 2.15161
Timestep Consumption Time: 2.34149
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.49311

Cumulative Model Updates: 193,750
Cumulative Timesteps: 1,615,855,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.74503
Policy Entropy: 2.28401
Value Function Loss: 0.01451

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 23,586.12661
Overall Steps per Second: 10,891.71170

Timestep Collection Time: 2.12099
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.59303

Cumulative Model Updates: 193,756
Cumulative Timesteps: 1,615,905,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1615905832...
Checkpoint 1615905832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.99567
Policy Entropy: 2.29019
Value Function Loss: 0.01434

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.53840
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 23,090.96254
Overall Steps per Second: 10,761.86107

Timestep Collection Time: 2.16648
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.64845

Cumulative Model Updates: 193,762
Cumulative Timesteps: 1,615,955,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.56436
Policy Entropy: 2.29789
Value Function Loss: 0.01448

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.56713

Collected Steps per Second: 23,492.99871
Overall Steps per Second: 10,758.78954

Timestep Collection Time: 2.12923
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.64941

Cumulative Model Updates: 193,768
Cumulative Timesteps: 1,616,005,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1616005880...
Checkpoint 1616005880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.98552
Policy Entropy: 2.27365
Value Function Loss: 0.01560

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.54180
Value Function Update Magnitude: 0.56094

Collected Steps per Second: 23,043.75327
Overall Steps per Second: 10,784.98056

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.63663

Cumulative Model Updates: 193,774
Cumulative Timesteps: 1,616,055,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.91673
Policy Entropy: 2.28148
Value Function Loss: 0.01570

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.54268
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 23,218.62690
Overall Steps per Second: 10,970.91044

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.40445
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.55824

Cumulative Model Updates: 193,780
Cumulative Timesteps: 1,616,105,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1616105894...
Checkpoint 1616105894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.88235
Policy Entropy: 2.28548
Value Function Loss: 0.01586

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 23,146.21288
Overall Steps per Second: 10,939.87901

Timestep Collection Time: 2.16139
Timestep Consumption Time: 2.41160
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.57299

Cumulative Model Updates: 193,786
Cumulative Timesteps: 1,616,155,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.39753
Policy Entropy: 2.31191
Value Function Loss: 0.01593

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.56289

Collected Steps per Second: 23,508.37053
Overall Steps per Second: 10,867.77053

Timestep Collection Time: 2.12792
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.60297

Cumulative Model Updates: 193,792
Cumulative Timesteps: 1,616,205,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1616205946...
Checkpoint 1616205946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.12400
Policy Entropy: 2.30587
Value Function Loss: 0.01524

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.57319

Collected Steps per Second: 22,988.94520
Overall Steps per Second: 10,694.64827

Timestep Collection Time: 2.17618
Timestep Consumption Time: 2.50168
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.67785

Cumulative Model Updates: 193,798
Cumulative Timesteps: 1,616,255,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.41978
Policy Entropy: 2.28441
Value Function Loss: 0.01561

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.57988

Collected Steps per Second: 23,110.85337
Overall Steps per Second: 10,886.65614

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.59480

Cumulative Model Updates: 193,804
Cumulative Timesteps: 1,616,305,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1616305996...
Checkpoint 1616305996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.25351
Policy Entropy: 2.26985
Value Function Loss: 0.01480

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.54886
Value Function Update Magnitude: 0.58568

Collected Steps per Second: 23,254.35569
Overall Steps per Second: 11,124.37655

Timestep Collection Time: 2.15134
Timestep Consumption Time: 2.34581
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.49715

Cumulative Model Updates: 193,810
Cumulative Timesteps: 1,616,356,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.72647
Policy Entropy: 2.25956
Value Function Loss: 0.01498

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 23,615.98548
Overall Steps per Second: 10,874.74203

Timestep Collection Time: 2.11848
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.60057

Cumulative Model Updates: 193,816
Cumulative Timesteps: 1,616,406,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1616406054...
Checkpoint 1616406054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.55096
Policy Entropy: 2.28364
Value Function Loss: 0.01460

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.56082

Collected Steps per Second: 23,147.22344
Overall Steps per Second: 10,776.09707

Timestep Collection Time: 2.16035
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.64046

Cumulative Model Updates: 193,822
Cumulative Timesteps: 1,616,456,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.07107
Policy Entropy: 2.29276
Value Function Loss: 0.01693

Mean KL Divergence: 0.02906
SB3 Clip Fraction: 0.17762
Policy Update Magnitude: 0.49564
Value Function Update Magnitude: 0.57100

Collected Steps per Second: 23,456.93660
Overall Steps per Second: 10,795.54569

Timestep Collection Time: 2.13233
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.63321

Cumulative Model Updates: 193,828
Cumulative Timesteps: 1,616,506,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1616506078...
Checkpoint 1616506078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.57852
Policy Entropy: 2.30250
Value Function Loss: 0.01677

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.53207
Value Function Update Magnitude: 0.58257

Collected Steps per Second: 23,159.96320
Overall Steps per Second: 10,926.57476

Timestep Collection Time: 2.15924
Timestep Consumption Time: 2.41749
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.57673

Cumulative Model Updates: 193,834
Cumulative Timesteps: 1,616,556,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.74035
Policy Entropy: 2.28183
Value Function Loss: 0.01757

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.58298

Collected Steps per Second: 23,200.67522
Overall Steps per Second: 11,100.51146

Timestep Collection Time: 2.15528
Timestep Consumption Time: 2.34938
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.50466

Cumulative Model Updates: 193,840
Cumulative Timesteps: 1,616,606,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1616606090...
Checkpoint 1616606090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.69039
Policy Entropy: 2.27324
Value Function Loss: 0.01731

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.59914

Collected Steps per Second: 23,230.67006
Overall Steps per Second: 10,814.86506

Timestep Collection Time: 2.15319
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.62512

Cumulative Model Updates: 193,846
Cumulative Timesteps: 1,616,656,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.81460
Policy Entropy: 2.29453
Value Function Loss: 0.01639

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.59454

Collected Steps per Second: 23,595.79215
Overall Steps per Second: 10,855.12759

Timestep Collection Time: 2.12029
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.60888

Cumulative Model Updates: 193,852
Cumulative Timesteps: 1,616,706,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1616706140...
Checkpoint 1616706140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.86596
Policy Entropy: 2.33010
Value Function Loss: 0.01595

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.56967

Collected Steps per Second: 23,349.28364
Overall Steps per Second: 10,940.30605

Timestep Collection Time: 2.14259
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.57282

Cumulative Model Updates: 193,858
Cumulative Timesteps: 1,616,756,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.60884
Policy Entropy: 2.34161
Value Function Loss: 0.01589

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.54111

Collected Steps per Second: 23,115.60622
Overall Steps per Second: 10,949.78505

Timestep Collection Time: 2.16373
Timestep Consumption Time: 2.40403
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.56776

Cumulative Model Updates: 193,864
Cumulative Timesteps: 1,616,806,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1616806184...
Checkpoint 1616806184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.79336
Policy Entropy: 2.31342
Value Function Loss: 0.01668

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.54256
Value Function Update Magnitude: 0.55328

Collected Steps per Second: 22,963.21287
Overall Steps per Second: 11,037.90871

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.35377
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.53238

Cumulative Model Updates: 193,870
Cumulative Timesteps: 1,616,856,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.89270
Policy Entropy: 2.30530
Value Function Loss: 0.01656

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.58373

Collected Steps per Second: 23,512.36498
Overall Steps per Second: 10,996.09690

Timestep Collection Time: 2.12688
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.54780

Cumulative Model Updates: 193,876
Cumulative Timesteps: 1,616,906,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1616906220...
Checkpoint 1616906220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.17310
Policy Entropy: 2.30342
Value Function Loss: 0.01581

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.60046

Collected Steps per Second: 22,917.52263
Overall Steps per Second: 10,717.59698

Timestep Collection Time: 2.18200
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66578

Cumulative Model Updates: 193,882
Cumulative Timesteps: 1,616,956,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.97839
Policy Entropy: 2.34308
Value Function Loss: 0.01586

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.59530

Collected Steps per Second: 23,352.81627
Overall Steps per Second: 10,785.16236

Timestep Collection Time: 2.14210
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.63822

Cumulative Model Updates: 193,888
Cumulative Timesteps: 1,617,006,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1617006250...
Checkpoint 1617006250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.79723
Policy Entropy: 2.34335
Value Function Loss: 0.01432

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.59698

Collected Steps per Second: 22,776.55380
Overall Steps per Second: 10,709.95105

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.67024

Cumulative Model Updates: 193,894
Cumulative Timesteps: 1,617,056,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.66721
Policy Entropy: 2.35903
Value Function Loss: 0.01455

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.57898

Collected Steps per Second: 23,405.03904
Overall Steps per Second: 10,964.16715

Timestep Collection Time: 2.13629
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.56031

Cumulative Model Updates: 193,900
Cumulative Timesteps: 1,617,106,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1617106268...
Checkpoint 1617106268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.03341
Policy Entropy: 2.32464
Value Function Loss: 0.01369

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.53164
Value Function Update Magnitude: 0.55957

Collected Steps per Second: 22,515.06678
Overall Steps per Second: 10,927.27252

Timestep Collection Time: 2.22091
Timestep Consumption Time: 2.35516
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.57607

Cumulative Model Updates: 193,906
Cumulative Timesteps: 1,617,156,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.05775
Policy Entropy: 2.32463
Value Function Loss: 0.01477

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.53662
Value Function Update Magnitude: 0.56893

Collected Steps per Second: 23,157.09972
Overall Steps per Second: 10,898.05681

Timestep Collection Time: 2.15925
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.58816

Cumulative Model Updates: 193,912
Cumulative Timesteps: 1,617,206,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1617206274...
Checkpoint 1617206274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.37930
Policy Entropy: 2.31203
Value Function Loss: 0.01488

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.59417

Collected Steps per Second: 23,089.06097
Overall Steps per Second: 10,690.87658

Timestep Collection Time: 2.16613
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.67819

Cumulative Model Updates: 193,918
Cumulative Timesteps: 1,617,256,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.33269
Policy Entropy: 2.33304
Value Function Loss: 0.01504

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.59718

Collected Steps per Second: 23,150.60838
Overall Steps per Second: 10,901.84162

Timestep Collection Time: 2.16029
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.58748

Cumulative Model Updates: 193,924
Cumulative Timesteps: 1,617,306,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1617306300...
Checkpoint 1617306300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.42550
Policy Entropy: 2.32658
Value Function Loss: 0.01472

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.60065

Collected Steps per Second: 22,862.15428
Overall Steps per Second: 10,747.34076

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.46579
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.65324

Cumulative Model Updates: 193,930
Cumulative Timesteps: 1,617,356,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.76045
Policy Entropy: 2.32710
Value Function Loss: 0.01379

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.58843

Collected Steps per Second: 23,209.78168
Overall Steps per Second: 10,825.62592

Timestep Collection Time: 2.15521
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.62070

Cumulative Model Updates: 193,936
Cumulative Timesteps: 1,617,406,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1617406332...
Checkpoint 1617406332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.23110
Policy Entropy: 2.31877
Value Function Loss: 0.01422

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.53526
Value Function Update Magnitude: 0.58367

Collected Steps per Second: 22,929.12830
Overall Steps per Second: 11,053.56049

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.34392
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.52560

Cumulative Model Updates: 193,942
Cumulative Timesteps: 1,617,456,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.51509
Policy Entropy: 2.30715
Value Function Loss: 0.01588

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.60529

Collected Steps per Second: 23,162.86769
Overall Steps per Second: 10,896.08890

Timestep Collection Time: 2.16061
Timestep Consumption Time: 2.43241
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59302

Cumulative Model Updates: 193,948
Cumulative Timesteps: 1,617,506,402

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1617506402...
Checkpoint 1617506402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.91013
Policy Entropy: 2.29733
Value Function Loss: 0.01597

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.61404

Collected Steps per Second: 22,811.75398
Overall Steps per Second: 10,699.52007

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.67311

Cumulative Model Updates: 193,954
Cumulative Timesteps: 1,617,556,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.71983
Policy Entropy: 2.28440
Value Function Loss: 0.01586

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.59855

Collected Steps per Second: 23,069.07769
Overall Steps per Second: 10,891.82188

Timestep Collection Time: 2.16766
Timestep Consumption Time: 2.42349
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.59115

Cumulative Model Updates: 193,960
Cumulative Timesteps: 1,617,606,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1617606408...
Checkpoint 1617606408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.00544
Policy Entropy: 2.30555
Value Function Loss: 0.01549

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.60370

Collected Steps per Second: 22,947.67970
Overall Steps per Second: 10,757.36357

Timestep Collection Time: 2.17931
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.64891

Cumulative Model Updates: 193,966
Cumulative Timesteps: 1,617,656,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.94420
Policy Entropy: 2.29933
Value Function Loss: 0.01500

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.61480

Collected Steps per Second: 23,666.07299
Overall Steps per Second: 11,057.59299

Timestep Collection Time: 2.11315
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.52268

Cumulative Model Updates: 193,972
Cumulative Timesteps: 1,617,706,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1617706428...
Checkpoint 1617706428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.49915
Policy Entropy: 2.30932
Value Function Loss: 0.01417

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.60131

Collected Steps per Second: 23,376.37312
Overall Steps per Second: 10,882.34646

Timestep Collection Time: 2.13908
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.59496

Cumulative Model Updates: 193,978
Cumulative Timesteps: 1,617,756,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.51817
Policy Entropy: 2.28918
Value Function Loss: 0.01382

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.53318
Value Function Update Magnitude: 0.58208

Collected Steps per Second: 23,504.41749
Overall Steps per Second: 10,871.91923

Timestep Collection Time: 2.12811
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.60084

Cumulative Model Updates: 193,984
Cumulative Timesteps: 1,617,806,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1617806452...
Checkpoint 1617806452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.03167
Policy Entropy: 2.30745
Value Function Loss: 0.01340

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53231
Value Function Update Magnitude: 0.56179

Collected Steps per Second: 22,945.63895
Overall Steps per Second: 10,686.92975

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.68067

Cumulative Model Updates: 193,990
Cumulative Timesteps: 1,617,856,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.22404
Policy Entropy: 2.29246
Value Function Loss: 0.01524

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 22,993.44577
Overall Steps per Second: 10,919.78274

Timestep Collection Time: 2.17505
Timestep Consumption Time: 2.40489
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.57994

Cumulative Model Updates: 193,996
Cumulative Timesteps: 1,617,906,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1617906486...
Checkpoint 1617906486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.48329
Policy Entropy: 2.31126
Value Function Loss: 0.01565

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.18591
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 22,866.62259
Overall Steps per Second: 10,740.99135

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.46857
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.65525

Cumulative Model Updates: 194,002
Cumulative Timesteps: 1,617,956,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.21944
Policy Entropy: 2.32055
Value Function Loss: 0.01459

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.17172
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.59081

Collected Steps per Second: 23,305.91312
Overall Steps per Second: 10,936.47562

Timestep Collection Time: 2.14658
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.57442

Cumulative Model Updates: 194,008
Cumulative Timesteps: 1,618,006,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1618006516...
Checkpoint 1618006516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686.78735
Policy Entropy: 2.31760
Value Function Loss: 0.01477

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.57768

Collected Steps per Second: 23,156.75628
Overall Steps per Second: 10,901.88085

Timestep Collection Time: 2.15989
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.58783

Cumulative Model Updates: 194,014
Cumulative Timesteps: 1,618,056,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.64490
Policy Entropy: 2.30937
Value Function Loss: 0.01448

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.18097
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.58417

Collected Steps per Second: 22,999.23615
Overall Steps per Second: 10,862.26045

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60420

Cumulative Model Updates: 194,020
Cumulative Timesteps: 1,618,106,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1618106544...
Checkpoint 1618106544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.91302
Policy Entropy: 2.28474
Value Function Loss: 0.01387

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.18738
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.57535

Collected Steps per Second: 22,961.01714
Overall Steps per Second: 10,727.99841

Timestep Collection Time: 2.17804
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.66163

Cumulative Model Updates: 194,026
Cumulative Timesteps: 1,618,156,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.27860
Policy Entropy: 2.31174
Value Function Loss: 0.01355

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.50104
Value Function Update Magnitude: 0.55811

Collected Steps per Second: 23,344.70228
Overall Steps per Second: 10,934.66027

Timestep Collection Time: 2.14233
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.57371

Cumulative Model Updates: 194,032
Cumulative Timesteps: 1,618,206,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1618206566...
Checkpoint 1618206566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.78652
Policy Entropy: 2.33826
Value Function Loss: 0.01275

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 22,405.18938
Overall Steps per Second: 10,775.94469

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.40988
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.64293

Cumulative Model Updates: 194,038
Cumulative Timesteps: 1,618,256,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.56329
Policy Entropy: 2.34759
Value Function Loss: 0.01392

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.52721
Value Function Update Magnitude: 0.53445

Collected Steps per Second: 23,698.16489
Overall Steps per Second: 10,870.40359

Timestep Collection Time: 2.11004
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.60001

Cumulative Model Updates: 194,044
Cumulative Timesteps: 1,618,306,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1618306602...
Checkpoint 1618306602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.16303
Policy Entropy: 2.34543
Value Function Loss: 0.01369

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.53457

Collected Steps per Second: 23,353.11107
Overall Steps per Second: 10,944.25008

Timestep Collection Time: 2.14113
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.56879

Cumulative Model Updates: 194,050
Cumulative Timesteps: 1,618,356,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.78609
Policy Entropy: 2.34501
Value Function Loss: 0.01436

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.53124
Value Function Update Magnitude: 0.53310

Collected Steps per Second: 23,396.08344
Overall Steps per Second: 10,947.49844

Timestep Collection Time: 2.13839
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.56999

Cumulative Model Updates: 194,056
Cumulative Timesteps: 1,618,406,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1618406634...
Checkpoint 1618406634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.64135
Policy Entropy: 2.33407
Value Function Loss: 0.01512

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.52625

Collected Steps per Second: 23,182.46749
Overall Steps per Second: 11,079.53188

Timestep Collection Time: 2.15784
Timestep Consumption Time: 2.35715
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.51499

Cumulative Model Updates: 194,062
Cumulative Timesteps: 1,618,456,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.65754
Policy Entropy: 2.31456
Value Function Loss: 0.01486

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.53692
Value Function Update Magnitude: 0.54370

Collected Steps per Second: 23,224.98428
Overall Steps per Second: 10,898.63608

Timestep Collection Time: 2.15354
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.58920

Cumulative Model Updates: 194,068
Cumulative Timesteps: 1,618,506,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1618506674...
Checkpoint 1618506674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.68113
Policy Entropy: 2.29448
Value Function Loss: 0.01463

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.53923

Collected Steps per Second: 22,828.40861
Overall Steps per Second: 10,674.16567

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68571

Cumulative Model Updates: 194,074
Cumulative Timesteps: 1,618,556,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.08331
Policy Entropy: 2.31043
Value Function Loss: 0.01429

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.52847

Collected Steps per Second: 23,282.13161
Overall Steps per Second: 10,890.88042

Timestep Collection Time: 2.14809
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59210

Cumulative Model Updates: 194,080
Cumulative Timesteps: 1,618,606,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1618606702...
Checkpoint 1618606702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.43614
Policy Entropy: 2.31362
Value Function Loss: 0.01438

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.52706
Value Function Update Magnitude: 0.52374

Collected Steps per Second: 22,776.53918
Overall Steps per Second: 10,695.22605

Timestep Collection Time: 2.19594
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.67648

Cumulative Model Updates: 194,086
Cumulative Timesteps: 1,618,656,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.61325
Policy Entropy: 2.31124
Value Function Loss: 0.01465

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.50671

Collected Steps per Second: 23,353.02054
Overall Steps per Second: 10,949.08980

Timestep Collection Time: 2.14114
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.56677

Cumulative Model Updates: 194,092
Cumulative Timesteps: 1,618,706,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1618706720...
Checkpoint 1618706720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.52631
Policy Entropy: 2.33839
Value Function Loss: 0.01437

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.52539
Value Function Update Magnitude: 0.50170

Collected Steps per Second: 23,288.04337
Overall Steps per Second: 10,944.10739

Timestep Collection Time: 2.14754
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.56977

Cumulative Model Updates: 194,098
Cumulative Timesteps: 1,618,756,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.35438
Policy Entropy: 2.34334
Value Function Loss: 0.01471

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.52122
Value Function Update Magnitude: 0.51891

Collected Steps per Second: 23,389.92643
Overall Steps per Second: 10,928.61635

Timestep Collection Time: 2.13776
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.57533

Cumulative Model Updates: 194,104
Cumulative Timesteps: 1,618,806,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1618806734...
Checkpoint 1618806734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.14789
Policy Entropy: 2.36302
Value Function Loss: 0.01408

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.52554
Value Function Update Magnitude: 0.51279

Collected Steps per Second: 22,818.61908
Overall Steps per Second: 10,709.42500

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.67047

Cumulative Model Updates: 194,110
Cumulative Timesteps: 1,618,856,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.71689
Policy Entropy: 2.33130
Value Function Loss: 0.01547

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.52827

Collected Steps per Second: 23,278.96842
Overall Steps per Second: 10,933.65533

Timestep Collection Time: 2.14846
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.57432

Cumulative Model Updates: 194,116
Cumulative Timesteps: 1,618,906,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1618906766...
Checkpoint 1618906766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.63351
Policy Entropy: 2.32682
Value Function Loss: 0.01603

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.55860

Collected Steps per Second: 23,163.19439
Overall Steps per Second: 11,109.81282

Timestep Collection Time: 2.15955
Timestep Consumption Time: 2.34296
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.50251

Cumulative Model Updates: 194,122
Cumulative Timesteps: 1,618,956,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.43797
Policy Entropy: 2.29963
Value Function Loss: 0.01646

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.58967

Collected Steps per Second: 23,664.56359
Overall Steps per Second: 10,911.63497

Timestep Collection Time: 2.11396
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.58465

Cumulative Model Updates: 194,128
Cumulative Timesteps: 1,619,006,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1619006814...
Checkpoint 1619006814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.94687
Policy Entropy: 2.28860
Value Function Loss: 0.01626

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.59696

Collected Steps per Second: 23,174.91948
Overall Steps per Second: 10,727.12825

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.50398
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.66183

Cumulative Model Updates: 194,134
Cumulative Timesteps: 1,619,056,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.42951
Policy Entropy: 2.29488
Value Function Loss: 0.01525

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.60030

Collected Steps per Second: 23,273.18357
Overall Steps per Second: 10,825.78362

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.47110
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.62027

Cumulative Model Updates: 194,140
Cumulative Timesteps: 1,619,106,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1619106840...
Checkpoint 1619106840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.01162
Policy Entropy: 2.29961
Value Function Loss: 0.01483

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.53516
Value Function Update Magnitude: 0.59259

Collected Steps per Second: 22,972.86448
Overall Steps per Second: 10,804.56300

Timestep Collection Time: 2.17726
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.62934

Cumulative Model Updates: 194,146
Cumulative Timesteps: 1,619,156,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.89916
Policy Entropy: 2.31848
Value Function Loss: 0.01430

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.56696

Collected Steps per Second: 23,755.90182
Overall Steps per Second: 11,234.08309

Timestep Collection Time: 2.10583
Timestep Consumption Time: 2.34722
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.45306

Cumulative Model Updates: 194,152
Cumulative Timesteps: 1,619,206,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1619206884...
Checkpoint 1619206884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.85843
Policy Entropy: 2.31388
Value Function Loss: 0.01510

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.53260
Value Function Update Magnitude: 0.54866

Collected Steps per Second: 23,215.59689
Overall Steps per Second: 10,818.75426

Timestep Collection Time: 2.15441
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.62308

Cumulative Model Updates: 194,158
Cumulative Timesteps: 1,619,256,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.50860
Policy Entropy: 2.29685
Value Function Loss: 0.01510

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.54344
Value Function Update Magnitude: 0.55830

Collected Steps per Second: 23,205.75426
Overall Steps per Second: 10,760.20685

Timestep Collection Time: 2.15584
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.64935

Cumulative Model Updates: 194,164
Cumulative Timesteps: 1,619,306,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1619306928...
Checkpoint 1619306928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.70623
Policy Entropy: 2.26779
Value Function Loss: 0.01545

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.57620

Collected Steps per Second: 22,931.09157
Overall Steps per Second: 10,726.75503

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.66124

Cumulative Model Updates: 194,170
Cumulative Timesteps: 1,619,356,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.38742
Policy Entropy: 2.28052
Value Function Loss: 0.01489

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.57874

Collected Steps per Second: 22,827.27056
Overall Steps per Second: 10,778.66966

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.63990

Cumulative Model Updates: 194,176
Cumulative Timesteps: 1,619,406,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1619406940...
Checkpoint 1619406940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.05027
Policy Entropy: 2.31107
Value Function Loss: 0.01481

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.58023

Collected Steps per Second: 22,785.37318
Overall Steps per Second: 11,017.23312

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.34517
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.54070

Cumulative Model Updates: 194,182
Cumulative Timesteps: 1,619,456,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.93643
Policy Entropy: 2.32418
Value Function Loss: 0.01513

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.57101

Collected Steps per Second: 23,307.92706
Overall Steps per Second: 10,909.56913

Timestep Collection Time: 2.14614
Timestep Consumption Time: 2.43901
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58515

Cumulative Model Updates: 194,188
Cumulative Timesteps: 1,619,506,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1619506988...
Checkpoint 1619506988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.20369
Policy Entropy: 2.32630
Value Function Loss: 0.01477

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.58201

Collected Steps per Second: 23,180.21801
Overall Steps per Second: 10,723.97073

Timestep Collection Time: 2.15762
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.66376

Cumulative Model Updates: 194,194
Cumulative Timesteps: 1,619,557,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.62281
Policy Entropy: 2.31925
Value Function Loss: 0.01586

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.54304
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 23,518.87815
Overall Steps per Second: 10,929.33162

Timestep Collection Time: 2.12697
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.57704

Cumulative Model Updates: 194,200
Cumulative Timesteps: 1,619,607,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1619607026...
Checkpoint 1619607026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.95129
Policy Entropy: 2.30971
Value Function Loss: 0.01579

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.54390
Value Function Update Magnitude: 0.58149

Collected Steps per Second: 22,994.19245
Overall Steps per Second: 10,786.12051

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.63559

Cumulative Model Updates: 194,206
Cumulative Timesteps: 1,619,657,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.77055
Policy Entropy: 2.30475
Value Function Loss: 0.01605

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 22,723.01750
Overall Steps per Second: 10,788.78973

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.63463

Cumulative Model Updates: 194,212
Cumulative Timesteps: 1,619,707,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1619707028...
Checkpoint 1619707028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.38390
Policy Entropy: 2.32286
Value Function Loss: 0.01546

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 23,338.65659
Overall Steps per Second: 10,877.47943

Timestep Collection Time: 2.14374
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.59960

Cumulative Model Updates: 194,218
Cumulative Timesteps: 1,619,757,060

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.95814
Policy Entropy: 2.32950
Value Function Loss: 0.01579

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 23,373.38110
Overall Steps per Second: 10,826.96103

Timestep Collection Time: 2.14047
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.62087

Cumulative Model Updates: 194,224
Cumulative Timesteps: 1,619,807,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1619807090...
Checkpoint 1619807090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.59726
Policy Entropy: 2.33921
Value Function Loss: 0.01636

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.56329

Collected Steps per Second: 23,316.83274
Overall Steps per Second: 10,929.90683

Timestep Collection Time: 2.14497
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.57589

Cumulative Model Updates: 194,230
Cumulative Timesteps: 1,619,857,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.15062
Policy Entropy: 2.31723
Value Function Loss: 0.01689

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.55623
Value Function Update Magnitude: 0.58507

Collected Steps per Second: 23,205.18025
Overall Steps per Second: 10,985.76138

Timestep Collection Time: 2.15469
Timestep Consumption Time: 2.39665
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.55135

Cumulative Model Updates: 194,236
Cumulative Timesteps: 1,619,907,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1619907104...
Checkpoint 1619907104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.35033
Policy Entropy: 2.32768
Value Function Loss: 0.01635

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.59648

Collected Steps per Second: 22,975.03553
Overall Steps per Second: 11,044.87270

Timestep Collection Time: 2.17645
Timestep Consumption Time: 2.35090
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.52735

Cumulative Model Updates: 194,242
Cumulative Timesteps: 1,619,957,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.69304
Policy Entropy: 2.30654
Value Function Loss: 0.01672

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.51439
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 23,542.71046
Overall Steps per Second: 10,941.62232

Timestep Collection Time: 2.12422
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.57062

Cumulative Model Updates: 194,248
Cumulative Timesteps: 1,620,007,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1620007118...
Checkpoint 1620007118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.95066
Policy Entropy: 2.30255
Value Function Loss: 0.01623

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.58643

Collected Steps per Second: 22,864.87722
Overall Steps per Second: 10,679.25166

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.68291

Cumulative Model Updates: 194,254
Cumulative Timesteps: 1,620,057,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.13888
Policy Entropy: 2.31742
Value Function Loss: 0.01498

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.16612
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.58129

Collected Steps per Second: 23,393.34117
Overall Steps per Second: 10,856.46929

Timestep Collection Time: 2.13822
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.60739

Cumulative Model Updates: 194,260
Cumulative Timesteps: 1,620,107,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1620107148...
Checkpoint 1620107148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.85438
Policy Entropy: 2.32940
Value Function Loss: 0.01394

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 23,213.60671
Overall Steps per Second: 10,874.21990

Timestep Collection Time: 2.15520
Timestep Consumption Time: 2.44559
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.60079

Cumulative Model Updates: 194,266
Cumulative Timesteps: 1,620,157,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.10213
Policy Entropy: 2.35875
Value Function Loss: 0.01513

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.53404

Collected Steps per Second: 23,195.92445
Overall Steps per Second: 11,052.09931

Timestep Collection Time: 2.15641
Timestep Consumption Time: 2.36942
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.52584

Cumulative Model Updates: 194,272
Cumulative Timesteps: 1,620,207,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1620207198...
Checkpoint 1620207198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.21261
Policy Entropy: 2.33651
Value Function Loss: 0.01532

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.55331

Collected Steps per Second: 22,930.81000
Overall Steps per Second: 10,726.36907

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66365

Cumulative Model Updates: 194,278
Cumulative Timesteps: 1,620,257,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.05696
Policy Entropy: 2.33003
Value Function Loss: 0.01620

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.57514

Collected Steps per Second: 23,518.97076
Overall Steps per Second: 10,934.64769

Timestep Collection Time: 2.12713
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.57518

Cumulative Model Updates: 194,284
Cumulative Timesteps: 1,620,307,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1620307250...
Checkpoint 1620307250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.92962
Policy Entropy: 2.32495
Value Function Loss: 0.01541

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.54228
Value Function Update Magnitude: 0.56858

Collected Steps per Second: 23,133.28905
Overall Steps per Second: 10,833.64755

Timestep Collection Time: 2.16182
Timestep Consumption Time: 2.45435
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.61617

Cumulative Model Updates: 194,290
Cumulative Timesteps: 1,620,357,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.09602
Policy Entropy: 2.30741
Value Function Loss: 0.01696

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.56141

Collected Steps per Second: 23,613.76656
Overall Steps per Second: 11,203.68963

Timestep Collection Time: 2.11792
Timestep Consumption Time: 2.34597
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.46389

Cumulative Model Updates: 194,296
Cumulative Timesteps: 1,620,407,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1620407272...
Checkpoint 1620407272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.72906
Policy Entropy: 2.31680
Value Function Loss: 0.01621

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.55259
Value Function Update Magnitude: 0.57217

Collected Steps per Second: 22,880.69705
Overall Steps per Second: 10,664.16891

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.50425
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69029

Cumulative Model Updates: 194,302
Cumulative Timesteps: 1,620,457,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.00421
Policy Entropy: 2.31656
Value Function Loss: 0.01543

Mean KL Divergence: 0.02606
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.56428

Collected Steps per Second: 23,193.66890
Overall Steps per Second: 10,844.17829

Timestep Collection Time: 2.15688
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.61317

Cumulative Model Updates: 194,308
Cumulative Timesteps: 1,620,507,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1620507316...
Checkpoint 1620507316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.45137
Policy Entropy: 2.34903
Value Function Loss: 0.01546

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.17816
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.55991

Collected Steps per Second: 22,640.62618
Overall Steps per Second: 10,641.96322

Timestep Collection Time: 2.20966
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.70101

Cumulative Model Updates: 194,314
Cumulative Timesteps: 1,620,557,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.58702
Policy Entropy: 2.32435
Value Function Loss: 0.01569

Mean KL Divergence: 0.02517
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.56080

Collected Steps per Second: 23,078.43660
Overall Steps per Second: 10,906.52205

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.58570

Cumulative Model Updates: 194,320
Cumulative Timesteps: 1,620,607,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1620607358...
Checkpoint 1620607358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.27917
Policy Entropy: 2.32193
Value Function Loss: 0.01582

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.54987

Collected Steps per Second: 23,077.89121
Overall Steps per Second: 11,056.81837

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.35571
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.52246

Cumulative Model Updates: 194,326
Cumulative Timesteps: 1,620,657,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.50071
Policy Entropy: 2.30543
Value Function Loss: 0.01551

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.16634
Policy Update Magnitude: 0.52359
Value Function Update Magnitude: 0.54311

Collected Steps per Second: 23,621.58156
Overall Steps per Second: 11,015.03773

Timestep Collection Time: 2.11696
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.53979

Cumulative Model Updates: 194,332
Cumulative Timesteps: 1,620,707,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1620707368...
Checkpoint 1620707368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.14448
Policy Entropy: 2.32310
Value Function Loss: 0.01525

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.17447
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.54483

Collected Steps per Second: 23,356.89257
Overall Steps per Second: 10,955.04492

Timestep Collection Time: 2.14155
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.56593

Cumulative Model Updates: 194,338
Cumulative Timesteps: 1,620,757,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.52423
Policy Entropy: 2.30268
Value Function Loss: 0.01570

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.55475

Collected Steps per Second: 23,268.25520
Overall Steps per Second: 10,887.56016

Timestep Collection Time: 2.14945
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59368

Cumulative Model Updates: 194,344
Cumulative Timesteps: 1,620,807,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1620807402...
Checkpoint 1620807402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.23073
Policy Entropy: 2.30301
Value Function Loss: 0.01527

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.57199

Collected Steps per Second: 22,914.59917
Overall Steps per Second: 10,746.53102

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.65304

Cumulative Model Updates: 194,350
Cumulative Timesteps: 1,620,857,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.63218
Policy Entropy: 2.31156
Value Function Loss: 0.01467

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 23,455.40472
Overall Steps per Second: 10,968.99138

Timestep Collection Time: 2.13264
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.56031

Cumulative Model Updates: 194,356
Cumulative Timesteps: 1,620,907,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1620907428...
Checkpoint 1620907428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.22013
Policy Entropy: 2.31459
Value Function Loss: 0.01562

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.56521

Collected Steps per Second: 23,267.47008
Overall Steps per Second: 10,821.90485

Timestep Collection Time: 2.14978
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.62211

Cumulative Model Updates: 194,362
Cumulative Timesteps: 1,620,957,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.50005
Policy Entropy: 2.32557
Value Function Loss: 0.01520

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.58062

Collected Steps per Second: 23,629.60479
Overall Steps per Second: 10,890.47590

Timestep Collection Time: 2.11709
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.59356

Cumulative Model Updates: 194,368
Cumulative Timesteps: 1,621,007,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1621007474...
Checkpoint 1621007474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.27384
Policy Entropy: 2.30608
Value Function Loss: 0.01622

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.57655

Collected Steps per Second: 23,066.17033
Overall Steps per Second: 10,888.20746

Timestep Collection Time: 2.16889
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59470

Cumulative Model Updates: 194,374
Cumulative Timesteps: 1,621,057,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.84926
Policy Entropy: 2.29704
Value Function Loss: 0.01510

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 23,190.99698
Overall Steps per Second: 10,984.13029

Timestep Collection Time: 2.15670
Timestep Consumption Time: 2.39678
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.55348

Cumulative Model Updates: 194,380
Cumulative Timesteps: 1,621,107,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1621107518...
Checkpoint 1621107518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.88784
Policy Entropy: 2.31765
Value Function Loss: 0.01550

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 22,959.99355
Overall Steps per Second: 11,031.49338

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.35525
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.53338

Cumulative Model Updates: 194,386
Cumulative Timesteps: 1,621,157,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.34605
Policy Entropy: 2.34440
Value Function Loss: 0.01510

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.54238
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 23,266.27966
Overall Steps per Second: 10,906.26507

Timestep Collection Time: 2.15032
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.58727

Cumulative Model Updates: 194,392
Cumulative Timesteps: 1,621,207,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1621207558...
Checkpoint 1621207558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.02444
Policy Entropy: 2.32837
Value Function Loss: 0.01569

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 22,359.27012
Overall Steps per Second: 10,649.30564

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.69533

Cumulative Model Updates: 194,398
Cumulative Timesteps: 1,621,257,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.25201
Policy Entropy: 2.30986
Value Function Loss: 0.01605

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 23,126.41768
Overall Steps per Second: 10,891.09321

Timestep Collection Time: 2.16212
Timestep Consumption Time: 2.42897
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59109

Cumulative Model Updates: 194,404
Cumulative Timesteps: 1,621,307,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1621307562...
Checkpoint 1621307562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.90516
Policy Entropy: 2.31925
Value Function Loss: 0.01539

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.57452

Collected Steps per Second: 23,155.65757
Overall Steps per Second: 10,822.90632

Timestep Collection Time: 2.16025
Timestep Consumption Time: 2.46161
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.62186

Cumulative Model Updates: 194,410
Cumulative Timesteps: 1,621,357,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.07191
Policy Entropy: 2.34055
Value Function Loss: 0.01525

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.57375

Collected Steps per Second: 23,654.26809
Overall Steps per Second: 11,190.76134

Timestep Collection Time: 2.11488
Timestep Consumption Time: 2.35541
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.47029

Cumulative Model Updates: 194,416
Cumulative Timesteps: 1,621,407,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1621407610...
Checkpoint 1621407610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.86646
Policy Entropy: 2.34073
Value Function Loss: 0.01467

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.57565

Collected Steps per Second: 22,732.11422
Overall Steps per Second: 10,698.61878

Timestep Collection Time: 2.20068
Timestep Consumption Time: 2.47526
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.67593

Cumulative Model Updates: 194,422
Cumulative Timesteps: 1,621,457,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.61001
Policy Entropy: 2.30284
Value Function Loss: 0.01577

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.56111
Value Function Update Magnitude: 0.57894

Collected Steps per Second: 23,458.70412
Overall Steps per Second: 10,925.07742

Timestep Collection Time: 2.13166
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.57718

Cumulative Model Updates: 194,428
Cumulative Timesteps: 1,621,507,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1621507642...
Checkpoint 1621507642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.51647
Policy Entropy: 2.29333
Value Function Loss: 0.01634

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.60333

Collected Steps per Second: 23,038.30938
Overall Steps per Second: 10,811.60218

Timestep Collection Time: 2.17073
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.62559

Cumulative Model Updates: 194,434
Cumulative Timesteps: 1,621,557,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.31548
Policy Entropy: 2.29481
Value Function Loss: 0.01592

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.60792

Collected Steps per Second: 23,489.17961
Overall Steps per Second: 11,159.37938

Timestep Collection Time: 2.12941
Timestep Consumption Time: 2.35274
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.48215

Cumulative Model Updates: 194,440
Cumulative Timesteps: 1,621,607,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1621607670...
Checkpoint 1621607670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.92109
Policy Entropy: 2.31490
Value Function Loss: 0.01641

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.55821
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 23,187.90758
Overall Steps per Second: 10,782.53617

Timestep Collection Time: 2.15725
Timestep Consumption Time: 2.48192
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.63917

Cumulative Model Updates: 194,446
Cumulative Timesteps: 1,621,657,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.73742
Policy Entropy: 2.32379
Value Function Loss: 0.01556

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.62119

Collected Steps per Second: 23,626.75231
Overall Steps per Second: 10,822.05832

Timestep Collection Time: 2.11650
Timestep Consumption Time: 2.50425
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.62075

Cumulative Model Updates: 194,452
Cumulative Timesteps: 1,621,707,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1621707698...
Checkpoint 1621707698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.59424
Policy Entropy: 2.31281
Value Function Loss: 0.01569

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.60989

Collected Steps per Second: 23,232.42498
Overall Steps per Second: 10,800.49622

Timestep Collection Time: 2.15337
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.63201

Cumulative Model Updates: 194,458
Cumulative Timesteps: 1,621,757,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.61581
Policy Entropy: 2.29467
Value Function Loss: 0.01509

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 23,634.09927
Overall Steps per Second: 10,849.49286

Timestep Collection Time: 2.11635
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.61017

Cumulative Model Updates: 194,464
Cumulative Timesteps: 1,621,807,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1621807744...
Checkpoint 1621807744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.78103
Policy Entropy: 2.30028
Value Function Loss: 0.01492

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.58666

Collected Steps per Second: 22,780.60046
Overall Steps per Second: 10,883.80927

Timestep Collection Time: 2.19573
Timestep Consumption Time: 2.40009
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59582

Cumulative Model Updates: 194,470
Cumulative Timesteps: 1,621,857,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.32171
Policy Entropy: 2.32723
Value Function Loss: 0.01430

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.57116

Collected Steps per Second: 23,335.52798
Overall Steps per Second: 11,061.55776

Timestep Collection Time: 2.14386
Timestep Consumption Time: 2.37883
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.52269

Cumulative Model Updates: 194,476
Cumulative Timesteps: 1,621,907,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1621907792...
Checkpoint 1621907792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.40313
Policy Entropy: 2.33085
Value Function Loss: 0.01490

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.55877

Collected Steps per Second: 23,205.61878
Overall Steps per Second: 10,813.26771

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.62635

Cumulative Model Updates: 194,482
Cumulative Timesteps: 1,621,957,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.24313
Policy Entropy: 2.31232
Value Function Loss: 0.01480

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.55365

Collected Steps per Second: 23,420.91589
Overall Steps per Second: 10,793.59143

Timestep Collection Time: 2.13519
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.63312

Cumulative Model Updates: 194,488
Cumulative Timesteps: 1,622,007,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1622007826...
Checkpoint 1622007826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686.71905
Policy Entropy: 2.28977
Value Function Loss: 0.01403

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.55622

Collected Steps per Second: 22,821.20458
Overall Steps per Second: 10,770.36952

Timestep Collection Time: 2.19182
Timestep Consumption Time: 2.45240
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.64422

Cumulative Model Updates: 194,494
Cumulative Timesteps: 1,622,057,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.38853
Policy Entropy: 2.29907
Value Function Loss: 0.01441

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.56396

Collected Steps per Second: 23,398.04378
Overall Steps per Second: 11,139.74917

Timestep Collection Time: 2.13761
Timestep Consumption Time: 2.35225
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.48987

Cumulative Model Updates: 194,500
Cumulative Timesteps: 1,622,107,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1622107862...
Checkpoint 1622107862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.29213
Policy Entropy: 2.28720
Value Function Loss: 0.01491

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 22,350.80778
Overall Steps per Second: 10,736.30505

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.65933

Cumulative Model Updates: 194,506
Cumulative Timesteps: 1,622,157,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.32327
Policy Entropy: 2.28490
Value Function Loss: 0.01523

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.56087

Collected Steps per Second: 23,636.60518
Overall Steps per Second: 10,848.92573

Timestep Collection Time: 2.11596
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.61004

Cumulative Model Updates: 194,512
Cumulative Timesteps: 1,622,207,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1622207900...
Checkpoint 1622207900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.77537
Policy Entropy: 2.27955
Value Function Loss: 0.01486

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.56392

Collected Steps per Second: 23,012.51755
Overall Steps per Second: 10,706.13386

Timestep Collection Time: 2.17317
Timestep Consumption Time: 2.49799
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.67115

Cumulative Model Updates: 194,518
Cumulative Timesteps: 1,622,257,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.49986
Policy Entropy: 2.28288
Value Function Loss: 0.01417

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.54558
Value Function Update Magnitude: 0.57514

Collected Steps per Second: 23,242.86963
Overall Steps per Second: 10,848.09419

Timestep Collection Time: 2.15197
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.61076

Cumulative Model Updates: 194,524
Cumulative Timesteps: 1,622,307,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1622307928...
Checkpoint 1622307928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.19640
Policy Entropy: 2.28000
Value Function Loss: 0.01461

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.57537

Collected Steps per Second: 22,964.56575
Overall Steps per Second: 11,065.76885

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.34201
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.52007

Cumulative Model Updates: 194,530
Cumulative Timesteps: 1,622,357,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.30344
Policy Entropy: 2.26734
Value Function Loss: 0.01612

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.57629

Collected Steps per Second: 23,688.08980
Overall Steps per Second: 10,959.44466

Timestep Collection Time: 2.11136
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.56355

Cumulative Model Updates: 194,536
Cumulative Timesteps: 1,622,407,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1622407960...
Checkpoint 1622407960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.00789
Policy Entropy: 2.27229
Value Function Loss: 0.01697

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.58275

Collected Steps per Second: 22,969.15118
Overall Steps per Second: 10,724.48897

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.66241

Cumulative Model Updates: 194,542
Cumulative Timesteps: 1,622,457,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.48586
Policy Entropy: 2.29449
Value Function Loss: 0.01635

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.54210
Value Function Update Magnitude: 0.56970

Collected Steps per Second: 23,394.61910
Overall Steps per Second: 10,839.31677

Timestep Collection Time: 2.13810
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.61468

Cumulative Model Updates: 194,548
Cumulative Timesteps: 1,622,507,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1622507982...
Checkpoint 1622507982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.48413
Policy Entropy: 2.29590
Value Function Loss: 0.01580

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.56030

Collected Steps per Second: 22,965.30399
Overall Steps per Second: 10,837.33910

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.61663

Cumulative Model Updates: 194,554
Cumulative Timesteps: 1,622,558,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.14684
Policy Entropy: 2.29785
Value Function Loss: 0.01502

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.56913

Collected Steps per Second: 23,576.39265
Overall Steps per Second: 11,192.26585

Timestep Collection Time: 2.12161
Timestep Consumption Time: 2.34754
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.46916

Cumulative Model Updates: 194,560
Cumulative Timesteps: 1,622,608,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1622608034...
Checkpoint 1622608034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.81640
Policy Entropy: 2.29845
Value Function Loss: 0.01511

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.60333

Collected Steps per Second: 23,332.40496
Overall Steps per Second: 10,809.35540

Timestep Collection Time: 2.14389
Timestep Consumption Time: 2.48377
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.62766

Cumulative Model Updates: 194,566
Cumulative Timesteps: 1,622,658,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.01365
Policy Entropy: 2.31111
Value Function Loss: 0.01510

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.63513

Collected Steps per Second: 23,711.73038
Overall Steps per Second: 10,904.84192

Timestep Collection Time: 2.10875
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.58530

Cumulative Model Updates: 194,572
Cumulative Timesteps: 1,622,708,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1622708058...
Checkpoint 1622708058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395.54348
Policy Entropy: 2.32337
Value Function Loss: 0.01684

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.64881

Collected Steps per Second: 23,076.97562
Overall Steps per Second: 10,902.68554

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.58621

Cumulative Model Updates: 194,578
Cumulative Timesteps: 1,622,758,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.78507
Policy Entropy: 2.33431
Value Function Loss: 0.01703

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.64559

Collected Steps per Second: 23,345.11464
Overall Steps per Second: 10,916.94479

Timestep Collection Time: 2.14246
Timestep Consumption Time: 2.43904
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.58150

Cumulative Model Updates: 194,584
Cumulative Timesteps: 1,622,808,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1622808076...
Checkpoint 1622808076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.71651
Policy Entropy: 2.34107
Value Function Loss: 0.01632

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.63959

Collected Steps per Second: 22,887.36930
Overall Steps per Second: 11,029.20910

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.34975
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.53523

Cumulative Model Updates: 194,590
Cumulative Timesteps: 1,622,858,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.22228
Policy Entropy: 2.30415
Value Function Loss: 0.01566

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.60225

Collected Steps per Second: 23,356.23493
Overall Steps per Second: 10,936.85153

Timestep Collection Time: 2.14161
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.57353

Cumulative Model Updates: 194,596
Cumulative Timesteps: 1,622,908,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1622908116...
Checkpoint 1622908116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.19527
Policy Entropy: 2.29730
Value Function Loss: 0.01599

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.58932

Collected Steps per Second: 22,998.51049
Overall Steps per Second: 10,703.97048

Timestep Collection Time: 2.17414
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.67135

Cumulative Model Updates: 194,602
Cumulative Timesteps: 1,622,958,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.16318
Policy Entropy: 2.29327
Value Function Loss: 0.01661

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.59895

Collected Steps per Second: 23,515.50941
Overall Steps per Second: 10,886.69695

Timestep Collection Time: 2.12660
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.59350

Cumulative Model Updates: 194,608
Cumulative Timesteps: 1,623,008,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1623008126...
Checkpoint 1623008126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.51392
Policy Entropy: 2.31601
Value Function Loss: 0.01580

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.59063

Collected Steps per Second: 22,900.96193
Overall Steps per Second: 10,736.37430

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.47405
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.65762

Cumulative Model Updates: 194,614
Cumulative Timesteps: 1,623,058,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.22960
Policy Entropy: 2.32117
Value Function Loss: 0.01624

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.56042
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 23,584.27519
Overall Steps per Second: 11,087.14580

Timestep Collection Time: 2.12107
Timestep Consumption Time: 2.39082
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.51189

Cumulative Model Updates: 194,620
Cumulative Timesteps: 1,623,108,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1623108156...
Checkpoint 1623108156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.45264
Policy Entropy: 2.31151
Value Function Loss: 0.01668

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.59975

Collected Steps per Second: 22,884.84707
Overall Steps per Second: 10,899.03030

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.40319
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.58848

Cumulative Model Updates: 194,626
Cumulative Timesteps: 1,623,158,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.30959
Policy Entropy: 2.29397
Value Function Loss: 0.01742

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 23,523.32961
Overall Steps per Second: 10,918.31369

Timestep Collection Time: 2.12657
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.58166

Cumulative Model Updates: 194,632
Cumulative Timesteps: 1,623,208,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1623208190...
Checkpoint 1623208190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.99646
Policy Entropy: 2.27946
Value Function Loss: 0.01797

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.67240

Collected Steps per Second: 22,925.48415
Overall Steps per Second: 10,687.16295

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.67888

Cumulative Model Updates: 194,638
Cumulative Timesteps: 1,623,258,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.66644
Policy Entropy: 2.30089
Value Function Loss: 0.01757

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.66648

Collected Steps per Second: 23,371.75016
Overall Steps per Second: 10,863.96118

Timestep Collection Time: 2.14019
Timestep Consumption Time: 2.46402
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.60421

Cumulative Model Updates: 194,644
Cumulative Timesteps: 1,623,308,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1623308214...
Checkpoint 1623308214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.91327
Policy Entropy: 2.30064
Value Function Loss: 0.01687

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.57958
Value Function Update Magnitude: 0.61984

Collected Steps per Second: 23,137.32288
Overall Steps per Second: 11,108.41942

Timestep Collection Time: 2.16101
Timestep Consumption Time: 2.34008
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.50109

Cumulative Model Updates: 194,650
Cumulative Timesteps: 1,623,358,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.40373
Policy Entropy: 2.32330
Value Function Loss: 0.01601

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.59092

Collected Steps per Second: 23,677.19354
Overall Steps per Second: 10,903.70364

Timestep Collection Time: 2.11191
Timestep Consumption Time: 2.47406
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.58596

Cumulative Model Updates: 194,656
Cumulative Timesteps: 1,623,408,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1623408218...
Checkpoint 1623408218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.04420
Policy Entropy: 2.32019
Value Function Loss: 0.01563

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.60510

Collected Steps per Second: 22,879.04882
Overall Steps per Second: 10,671.11750

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.68742

Cumulative Model Updates: 194,662
Cumulative Timesteps: 1,623,458,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.84821
Policy Entropy: 2.33914
Value Function Loss: 0.01473

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.61422

Collected Steps per Second: 23,292.20827
Overall Steps per Second: 10,837.40225

Timestep Collection Time: 2.14690
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.61421

Cumulative Model Updates: 194,668
Cumulative Timesteps: 1,623,508,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1623508244...
Checkpoint 1623508244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.76296
Policy Entropy: 2.33579
Value Function Loss: 0.01510

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 23,008.64465
Overall Steps per Second: 10,787.20585

Timestep Collection Time: 2.17318
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.63531

Cumulative Model Updates: 194,674
Cumulative Timesteps: 1,623,558,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.88245
Policy Entropy: 2.32080
Value Function Loss: 0.01543

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 23,472.27194
Overall Steps per Second: 11,154.78814

Timestep Collection Time: 2.13137
Timestep Consumption Time: 2.35352
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.48489

Cumulative Model Updates: 194,680
Cumulative Timesteps: 1,623,608,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1623608274...
Checkpoint 1623608274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.10333
Policy Entropy: 2.33453
Value Function Loss: 0.01558

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.53973
Value Function Update Magnitude: 0.58097

Collected Steps per Second: 23,049.86563
Overall Steps per Second: 10,722.47992

Timestep Collection Time: 2.17042
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.66571

Cumulative Model Updates: 194,686
Cumulative Timesteps: 1,623,658,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.49380
Policy Entropy: 2.33574
Value Function Loss: 0.01638

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.55396
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 23,239.71843
Overall Steps per Second: 10,947.40524

Timestep Collection Time: 2.15183
Timestep Consumption Time: 2.41619
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.56802

Cumulative Model Updates: 194,692
Cumulative Timesteps: 1,623,708,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1623708310...
Checkpoint 1623708310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.31811
Policy Entropy: 2.33698
Value Function Loss: 0.01644

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.57078

Collected Steps per Second: 23,043.00578
Overall Steps per Second: 10,743.54926

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.65433

Cumulative Model Updates: 194,698
Cumulative Timesteps: 1,623,758,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.15263
Policy Entropy: 2.32160
Value Function Loss: 0.01656

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 23,310.54037
Overall Steps per Second: 11,025.69515

Timestep Collection Time: 2.14590
Timestep Consumption Time: 2.39096
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.53686

Cumulative Model Updates: 194,704
Cumulative Timesteps: 1,623,808,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1623808336...
Checkpoint 1623808336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.63462
Policy Entropy: 2.32999
Value Function Loss: 0.01574

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 22,717.19307
Overall Steps per Second: 10,812.26281

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62512

Cumulative Model Updates: 194,710
Cumulative Timesteps: 1,623,858,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.63948
Policy Entropy: 2.32907
Value Function Loss: 0.01607

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.56377

Collected Steps per Second: 23,088.57288
Overall Steps per Second: 10,896.26521

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.58928

Cumulative Model Updates: 194,716
Cumulative Timesteps: 1,623,908,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1623908350...
Checkpoint 1623908350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.06780
Policy Entropy: 2.34613
Value Function Loss: 0.01641

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.55814

Collected Steps per Second: 22,853.10506
Overall Steps per Second: 10,735.89761

Timestep Collection Time: 2.19016
Timestep Consumption Time: 2.47195
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.66212

Cumulative Model Updates: 194,722
Cumulative Timesteps: 1,623,958,402

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.61202
Policy Entropy: 2.33850
Value Function Loss: 0.01623

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 23,306.18395
Overall Steps per Second: 10,885.19756

Timestep Collection Time: 2.14561
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.59395

Cumulative Model Updates: 194,728
Cumulative Timesteps: 1,624,008,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1624008408...
Checkpoint 1624008408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.82850
Policy Entropy: 2.35998
Value Function Loss: 0.01558

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,937.06540
Overall Steps per Second: 10,999.49551

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.36607
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.54621

Cumulative Model Updates: 194,734
Cumulative Timesteps: 1,624,058,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.06043
Policy Entropy: 2.35721
Value Function Loss: 0.01454

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 23,462.90740
Overall Steps per Second: 10,981.18346

Timestep Collection Time: 2.13102
Timestep Consumption Time: 2.42222
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.55324

Cumulative Model Updates: 194,740
Cumulative Timesteps: 1,624,108,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1624108414...
Checkpoint 1624108414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.84425
Policy Entropy: 2.36681
Value Function Loss: 0.01485

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.55861

Collected Steps per Second: 23,079.02740
Overall Steps per Second: 10,693.07273

Timestep Collection Time: 2.16734
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.67779

Cumulative Model Updates: 194,746
Cumulative Timesteps: 1,624,158,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.99591
Policy Entropy: 2.36954
Value Function Loss: 0.01493

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.52783
Value Function Update Magnitude: 0.56084

Collected Steps per Second: 23,524.74079
Overall Steps per Second: 10,882.40984

Timestep Collection Time: 2.12627
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.59641

Cumulative Model Updates: 194,752
Cumulative Timesteps: 1,624,208,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1624208454...
Checkpoint 1624208454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.05679
Policy Entropy: 2.37524
Value Function Loss: 0.01572

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.53948
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 22,751.28567
Overall Steps per Second: 10,707.98698

Timestep Collection Time: 2.19891
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.67203

Cumulative Model Updates: 194,758
Cumulative Timesteps: 1,624,258,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.30447
Policy Entropy: 2.35491
Value Function Loss: 0.01567

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.54720
Value Function Update Magnitude: 0.57712

Collected Steps per Second: 23,423.74863
Overall Steps per Second: 11,010.37209

Timestep Collection Time: 2.13587
Timestep Consumption Time: 2.40803
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.54390

Cumulative Model Updates: 194,764
Cumulative Timesteps: 1,624,308,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1624308512...
Checkpoint 1624308512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.83311
Policy Entropy: 2.33594
Value Function Loss: 0.01548

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 23,109.44852
Overall Steps per Second: 10,904.59757

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58651

Cumulative Model Updates: 194,770
Cumulative Timesteps: 1,624,358,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.82219
Policy Entropy: 2.32612
Value Function Loss: 0.01471

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.58241

Collected Steps per Second: 23,518.72767
Overall Steps per Second: 10,983.24414

Timestep Collection Time: 2.12631
Timestep Consumption Time: 2.42681
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.55312

Cumulative Model Updates: 194,776
Cumulative Timesteps: 1,624,408,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1624408534...
Checkpoint 1624408534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.79406
Policy Entropy: 2.31861
Value Function Loss: 0.01498

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.59812

Collected Steps per Second: 22,610.94478
Overall Steps per Second: 10,634.71218

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.70309

Cumulative Model Updates: 194,782
Cumulative Timesteps: 1,624,458,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.65688
Policy Entropy: 2.31174
Value Function Loss: 0.01609

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.60203

Collected Steps per Second: 23,488.44543
Overall Steps per Second: 10,882.45821

Timestep Collection Time: 2.12990
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.59712

Cumulative Model Updates: 194,788
Cumulative Timesteps: 1,624,508,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1624508578...
Checkpoint 1624508578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.00942
Policy Entropy: 2.29735
Value Function Loss: 0.01649

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.55928
Value Function Update Magnitude: 0.59792

Collected Steps per Second: 23,075.18489
Overall Steps per Second: 11,076.67676

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.34847
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.51652

Cumulative Model Updates: 194,794
Cumulative Timesteps: 1,624,558,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.40976
Policy Entropy: 2.29398
Value Function Loss: 0.01633

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.59040

Collected Steps per Second: 23,231.31390
Overall Steps per Second: 10,917.94016

Timestep Collection Time: 2.15244
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.57998

Cumulative Model Updates: 194,800
Cumulative Timesteps: 1,624,608,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1624608610...
Checkpoint 1624608610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.73304
Policy Entropy: 2.30148
Value Function Loss: 0.01548

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.58721

Collected Steps per Second: 22,590.47877
Overall Steps per Second: 10,650.90413

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.69650

Cumulative Model Updates: 194,806
Cumulative Timesteps: 1,624,658,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.88508
Policy Entropy: 2.30455
Value Function Loss: 0.01691

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.58627

Collected Steps per Second: 23,220.82714
Overall Steps per Second: 10,890.85400

Timestep Collection Time: 2.15410
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.59284

Cumulative Model Updates: 194,812
Cumulative Timesteps: 1,624,708,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1624708652...
Checkpoint 1624708652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.96388
Policy Entropy: 2.32035
Value Function Loss: 0.01642

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.56107
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 23,070.75078
Overall Steps per Second: 10,818.52152

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.62411

Cumulative Model Updates: 194,818
Cumulative Timesteps: 1,624,758,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.21569
Policy Entropy: 2.30791
Value Function Loss: 0.01746

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.56919

Collected Steps per Second: 23,404.77639
Overall Steps per Second: 11,144.57429

Timestep Collection Time: 2.13717
Timestep Consumption Time: 2.35111
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.48828

Cumulative Model Updates: 194,824
Cumulative Timesteps: 1,624,808,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1624808698...
Checkpoint 1624808698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.50854
Policy Entropy: 2.33186
Value Function Loss: 0.01718

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.59090

Collected Steps per Second: 23,191.45607
Overall Steps per Second: 10,727.65707

Timestep Collection Time: 2.15709
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.66327

Cumulative Model Updates: 194,830
Cumulative Timesteps: 1,624,858,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.73769
Policy Entropy: 2.34717
Value Function Loss: 0.01669

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.60339

Collected Steps per Second: 23,548.53455
Overall Steps per Second: 10,949.32639

Timestep Collection Time: 2.12361
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.56722

Cumulative Model Updates: 194,836
Cumulative Timesteps: 1,624,908,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1624908732...
Checkpoint 1624908732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.22391
Policy Entropy: 2.37123
Value Function Loss: 0.01646

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.56615

Collected Steps per Second: 23,145.66674
Overall Steps per Second: 11,000.41820

Timestep Collection Time: 2.16144
Timestep Consumption Time: 2.38639
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.54783

Cumulative Model Updates: 194,842
Cumulative Timesteps: 1,624,958,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.14659
Policy Entropy: 2.36593
Value Function Loss: 0.01709

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.55346

Collected Steps per Second: 23,554.17186
Overall Steps per Second: 11,047.30862

Timestep Collection Time: 2.12353
Timestep Consumption Time: 2.40409
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.52762

Cumulative Model Updates: 194,848
Cumulative Timesteps: 1,625,008,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1625008778...
Checkpoint 1625008778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.30228
Policy Entropy: 2.33926
Value Function Loss: 0.01786

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.57934

Collected Steps per Second: 23,092.58763
Overall Steps per Second: 11,083.07964

Timestep Collection Time: 2.16589
Timestep Consumption Time: 2.34694
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.51283

Cumulative Model Updates: 194,854
Cumulative Timesteps: 1,625,058,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.27740
Policy Entropy: 2.31385
Value Function Loss: 0.01765

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.59070

Collected Steps per Second: 22,735.90066
Overall Steps per Second: 10,766.44227

Timestep Collection Time: 2.19925
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.64425

Cumulative Model Updates: 194,860
Cumulative Timesteps: 1,625,108,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1625108796...
Checkpoint 1625108796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.64887
Policy Entropy: 2.30429
Value Function Loss: 0.01707

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.59102

Collected Steps per Second: 23,024.69729
Overall Steps per Second: 10,773.03124

Timestep Collection Time: 2.17184
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.64178

Cumulative Model Updates: 194,866
Cumulative Timesteps: 1,625,158,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.78581
Policy Entropy: 2.30621
Value Function Loss: 0.01690

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.60025

Collected Steps per Second: 23,421.42972
Overall Steps per Second: 10,895.30233

Timestep Collection Time: 2.13574
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.59115

Cumulative Model Updates: 194,872
Cumulative Timesteps: 1,625,208,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1625208824...
Checkpoint 1625208824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.18694
Policy Entropy: 2.29113
Value Function Loss: 0.01773

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.56023
Value Function Update Magnitude: 0.61765

Collected Steps per Second: 22,735.47146
Overall Steps per Second: 10,696.36268

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.67654

Cumulative Model Updates: 194,878
Cumulative Timesteps: 1,625,258,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.15763
Policy Entropy: 2.30066
Value Function Loss: 0.01712

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.63353

Collected Steps per Second: 23,463.35320
Overall Steps per Second: 11,044.36856

Timestep Collection Time: 2.13226
Timestep Consumption Time: 2.39765
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.52991

Cumulative Model Updates: 194,884
Cumulative Timesteps: 1,625,308,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1625308876...
Checkpoint 1625308876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.08375
Policy Entropy: 2.31755
Value Function Loss: 0.01746

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.51666
Value Function Update Magnitude: 0.63102

Collected Steps per Second: 23,397.28307
Overall Steps per Second: 10,916.97623

Timestep Collection Time: 2.13726
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.58057

Cumulative Model Updates: 194,890
Cumulative Timesteps: 1,625,358,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.59330
Policy Entropy: 2.35282
Value Function Loss: 0.01639

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.52172
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 23,491.75069
Overall Steps per Second: 10,903.17583

Timestep Collection Time: 2.12883
Timestep Consumption Time: 2.45790
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.58674

Cumulative Model Updates: 194,896
Cumulative Timesteps: 1,625,408,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1625408892...
Checkpoint 1625408892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.57368
Policy Entropy: 2.33054
Value Function Loss: 0.01627

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.58817

Collected Steps per Second: 22,840.06412
Overall Steps per Second: 10,644.84730

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69880

Cumulative Model Updates: 194,902
Cumulative Timesteps: 1,625,458,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.75644
Policy Entropy: 2.32833
Value Function Loss: 0.01466

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.57299

Collected Steps per Second: 23,271.26499
Overall Steps per Second: 10,916.89140

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.58134

Cumulative Model Updates: 194,908
Cumulative Timesteps: 1,625,508,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1625508924...
Checkpoint 1625508924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.11557
Policy Entropy: 2.34269
Value Function Loss: 0.01488

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.57328

Collected Steps per Second: 23,071.30829
Overall Steps per Second: 11,066.03905

Timestep Collection Time: 2.16763
Timestep Consumption Time: 2.35160
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.51923

Cumulative Model Updates: 194,914
Cumulative Timesteps: 1,625,558,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.24894
Policy Entropy: 2.32231
Value Function Loss: 0.01522

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.57050

Collected Steps per Second: 22,727.94381
Overall Steps per Second: 10,956.59492

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.36504
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.56638

Cumulative Model Updates: 194,920
Cumulative Timesteps: 1,625,608,966

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1625608966...
Checkpoint 1625608966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.98657
Policy Entropy: 2.30484
Value Function Loss: 0.01567

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.58434

Collected Steps per Second: 23,034.11470
Overall Steps per Second: 10,758.84390

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.64957

Cumulative Model Updates: 194,926
Cumulative Timesteps: 1,625,658,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.01366
Policy Entropy: 2.30207
Value Function Loss: 0.01490

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 23,298.14512
Overall Steps per Second: 10,778.04657

Timestep Collection Time: 2.14669
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.64036

Cumulative Model Updates: 194,932
Cumulative Timesteps: 1,625,709,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1625709004...
Checkpoint 1625709004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.45472
Policy Entropy: 2.32076
Value Function Loss: 0.01455

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 22,965.11756
Overall Steps per Second: 10,800.61048

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.63048

Cumulative Model Updates: 194,938
Cumulative Timesteps: 1,625,759,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.53501
Policy Entropy: 2.32277
Value Function Loss: 0.01441

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 23,561.86743
Overall Steps per Second: 11,164.94017

Timestep Collection Time: 2.12250
Timestep Consumption Time: 2.35670
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.47920

Cumulative Model Updates: 194,944
Cumulative Timesteps: 1,625,809,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1625809026...
Checkpoint 1625809026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.48911
Policy Entropy: 2.32192
Value Function Loss: 0.01407

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.55842

Collected Steps per Second: 22,949.88553
Overall Steps per Second: 10,694.16709

Timestep Collection Time: 2.17997
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.67825

Cumulative Model Updates: 194,950
Cumulative Timesteps: 1,625,859,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.77440
Policy Entropy: 2.33680
Value Function Loss: 0.01379

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.52961
Value Function Update Magnitude: 0.54502

Collected Steps per Second: 23,412.17304
Overall Steps per Second: 10,922.12950

Timestep Collection Time: 2.13650
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.57969

Cumulative Model Updates: 194,956
Cumulative Timesteps: 1,625,909,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1625909076...
Checkpoint 1625909076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.97639
Policy Entropy: 2.35078
Value Function Loss: 0.01424

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.52270

Collected Steps per Second: 22,839.03595
Overall Steps per Second: 10,666.51149

Timestep Collection Time: 2.18941
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68794

Cumulative Model Updates: 194,962
Cumulative Timesteps: 1,625,959,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.04923
Policy Entropy: 2.34843
Value Function Loss: 0.01392

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.52420

Collected Steps per Second: 23,332.32166
Overall Steps per Second: 10,861.24321

Timestep Collection Time: 2.14364
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.60500

Cumulative Model Updates: 194,968
Cumulative Timesteps: 1,626,009,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1626009096...
Checkpoint 1626009096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.82948
Policy Entropy: 2.33488
Value Function Loss: 0.01470

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.52987

Collected Steps per Second: 22,966.97906
Overall Steps per Second: 11,043.48163

Timestep Collection Time: 2.17800
Timestep Consumption Time: 2.35155
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.52955

Cumulative Model Updates: 194,974
Cumulative Timesteps: 1,626,059,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.60562
Policy Entropy: 2.31459
Value Function Loss: 0.01516

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.54840

Collected Steps per Second: 23,297.13006
Overall Steps per Second: 10,938.58842

Timestep Collection Time: 2.14619
Timestep Consumption Time: 2.42479
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.57097

Cumulative Model Updates: 194,980
Cumulative Timesteps: 1,626,109,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1626109118...
Checkpoint 1626109118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.65854
Policy Entropy: 2.31092
Value Function Loss: 0.01660

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 22,345.50296
Overall Steps per Second: 10,667.00569

Timestep Collection Time: 2.23786
Timestep Consumption Time: 2.45006
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.68791

Cumulative Model Updates: 194,986
Cumulative Timesteps: 1,626,159,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.01779
Policy Entropy: 2.31037
Value Function Loss: 0.01721

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 23,405.08622
Overall Steps per Second: 10,919.88526

Timestep Collection Time: 2.13663
Timestep Consumption Time: 2.44291
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.57954

Cumulative Model Updates: 194,992
Cumulative Timesteps: 1,626,209,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1626209132...
Checkpoint 1626209132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.35459
Policy Entropy: 2.32010
Value Function Loss: 0.01778

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 22,730.82066
Overall Steps per Second: 10,873.31967

Timestep Collection Time: 2.19974
Timestep Consumption Time: 2.39885
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.59860

Cumulative Model Updates: 194,998
Cumulative Timesteps: 1,626,259,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.97318
Policy Entropy: 2.32624
Value Function Loss: 0.01675

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.63387

Collected Steps per Second: 23,385.73628
Overall Steps per Second: 10,858.23111

Timestep Collection Time: 2.13917
Timestep Consumption Time: 2.46803
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.60720

Cumulative Model Updates: 195,004
Cumulative Timesteps: 1,626,309,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1626309160...
Checkpoint 1626309160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.10744
Policy Entropy: 2.33593
Value Function Loss: 0.01596

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.63085

Collected Steps per Second: 23,361.88919
Overall Steps per Second: 10,936.70066

Timestep Collection Time: 2.14049
Timestep Consumption Time: 2.43182
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.57231

Cumulative Model Updates: 195,010
Cumulative Timesteps: 1,626,359,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.99223
Policy Entropy: 2.33885
Value Function Loss: 0.01670

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,389.95378
Overall Steps per Second: 10,874.77805

Timestep Collection Time: 2.13776
Timestep Consumption Time: 2.46022
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.59798

Cumulative Model Updates: 195,016
Cumulative Timesteps: 1,626,409,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1626409168...
Checkpoint 1626409168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.93149
Policy Entropy: 2.33003
Value Function Loss: 0.01659

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,895.02316
Overall Steps per Second: 10,745.57315

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.46949
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.65364

Cumulative Model Updates: 195,022
Cumulative Timesteps: 1,626,459,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.74819
Policy Entropy: 2.33131
Value Function Loss: 0.01631

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.58032

Collected Steps per Second: 23,401.96278
Overall Steps per Second: 11,037.08646

Timestep Collection Time: 2.13709
Timestep Consumption Time: 2.39418
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.53127

Cumulative Model Updates: 195,028
Cumulative Timesteps: 1,626,509,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1626509186...
Checkpoint 1626509186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465.59820
Policy Entropy: 2.34087
Value Function Loss: 0.01530

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.54913

Collected Steps per Second: 23,301.94378
Overall Steps per Second: 10,897.22181

Timestep Collection Time: 2.14592
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.58869

Cumulative Model Updates: 195,034
Cumulative Timesteps: 1,626,559,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.17348
Policy Entropy: 2.34024
Value Function Loss: 0.01450

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.52880

Collected Steps per Second: 23,317.61509
Overall Steps per Second: 10,931.64927

Timestep Collection Time: 2.14439
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.57406

Cumulative Model Updates: 195,040
Cumulative Timesteps: 1,626,609,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1626609192...
Checkpoint 1626609192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.67455
Policy Entropy: 2.34335
Value Function Loss: 0.01404

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.53460
Value Function Update Magnitude: 0.52446

Collected Steps per Second: 22,589.65206
Overall Steps per Second: 10,564.62849

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.52038
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.73467

Cumulative Model Updates: 195,046
Cumulative Timesteps: 1,626,659,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.01556
Policy Entropy: 2.32249
Value Function Loss: 0.01492

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.54627

Collected Steps per Second: 23,252.72877
Overall Steps per Second: 10,994.71197

Timestep Collection Time: 2.15132
Timestep Consumption Time: 2.39851
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.54982

Cumulative Model Updates: 195,052
Cumulative Timesteps: 1,626,709,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1626709236...
Checkpoint 1626709236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.43119
Policy Entropy: 2.32876
Value Function Loss: 0.01636

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.56622
Value Function Update Magnitude: 0.57495

Collected Steps per Second: 22,680.62747
Overall Steps per Second: 10,979.64142

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.35058
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.55625

Cumulative Model Updates: 195,058
Cumulative Timesteps: 1,626,759,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.82803
Policy Entropy: 2.31275
Value Function Loss: 0.01659

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.58987

Collected Steps per Second: 23,575.44810
Overall Steps per Second: 11,001.85079

Timestep Collection Time: 2.12144
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.54596

Cumulative Model Updates: 195,064
Cumulative Timesteps: 1,626,809,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1626809276...
Checkpoint 1626809276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.93084
Policy Entropy: 2.30508
Value Function Loss: 0.01665

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.57663

Collected Steps per Second: 23,119.48358
Overall Steps per Second: 10,751.60144

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65140

Cumulative Model Updates: 195,070
Cumulative Timesteps: 1,626,859,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.10147
Policy Entropy: 2.28024
Value Function Loss: 0.01724

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.58710

Collected Steps per Second: 23,716.95610
Overall Steps per Second: 10,856.09509

Timestep Collection Time: 2.10929
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.60810

Cumulative Model Updates: 195,076
Cumulative Timesteps: 1,626,909,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1626909312...
Checkpoint 1626909312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.69134
Policy Entropy: 2.30825
Value Function Loss: 0.01634

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 22,956.69593
Overall Steps per Second: 10,804.02634

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.45048
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.62902

Cumulative Model Updates: 195,082
Cumulative Timesteps: 1,626,959,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.07211
Policy Entropy: 2.31961
Value Function Loss: 0.01636

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.59946

Collected Steps per Second: 23,456.15183
Overall Steps per Second: 10,925.97555

Timestep Collection Time: 2.13300
Timestep Consumption Time: 2.44618
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.57918

Cumulative Model Updates: 195,088
Cumulative Timesteps: 1,627,009,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1627009356...
Checkpoint 1627009356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.14352
Policy Entropy: 2.33279
Value Function Loss: 0.01417

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 22,848.69469
Overall Steps per Second: 10,856.11289

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.41884
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.60846

Cumulative Model Updates: 195,094
Cumulative Timesteps: 1,627,059,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.05120
Policy Entropy: 2.31144
Value Function Loss: 0.01360

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.56513

Collected Steps per Second: 23,258.22879
Overall Steps per Second: 10,919.49739

Timestep Collection Time: 2.15046
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58043

Cumulative Model Updates: 195,100
Cumulative Timesteps: 1,627,109,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1627109402...
Checkpoint 1627109402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.76243
Policy Entropy: 2.30769
Value Function Loss: 0.01410

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.55954

Collected Steps per Second: 22,044.15504
Overall Steps per Second: 10,607.45001

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.44608
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.71480

Cumulative Model Updates: 195,106
Cumulative Timesteps: 1,627,159,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.86768
Policy Entropy: 2.29633
Value Function Loss: 0.01501

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.58939

Collected Steps per Second: 20,822.02829
Overall Steps per Second: 10,060.26603

Timestep Collection Time: 2.40140
Timestep Consumption Time: 2.56885
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.97025

Cumulative Model Updates: 195,112
Cumulative Timesteps: 1,627,209,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1627209416...
Checkpoint 1627209416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.22186
Policy Entropy: 2.29508
Value Function Loss: 0.01583

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.58591

Collected Steps per Second: 21,913.38932
Overall Steps per Second: 10,502.67481

Timestep Collection Time: 2.28235
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.76202

Cumulative Model Updates: 195,118
Cumulative Timesteps: 1,627,259,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.15109
Policy Entropy: 2.28790
Value Function Loss: 0.01488

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 21,499.78940
Overall Steps per Second: 10,628.92602

Timestep Collection Time: 2.32570
Timestep Consumption Time: 2.37864
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.70433

Cumulative Model Updates: 195,124
Cumulative Timesteps: 1,627,309,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1627309432...
Checkpoint 1627309432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.84703
Policy Entropy: 2.30874
Value Function Loss: 0.01509

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 21,838.14551
Overall Steps per Second: 10,513.13880

Timestep Collection Time: 2.29012
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.75709

Cumulative Model Updates: 195,130
Cumulative Timesteps: 1,627,359,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.46354
Policy Entropy: 2.29628
Value Function Loss: 0.01466

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.53626

Collected Steps per Second: 22,070.24823
Overall Steps per Second: 10,551.41646

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.74041

Cumulative Model Updates: 195,136
Cumulative Timesteps: 1,627,409,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1627409462...
Checkpoint 1627409462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.54698
Policy Entropy: 2.28711
Value Function Loss: 0.01529

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.54117

Collected Steps per Second: 22,899.37208
Overall Steps per Second: 10,763.05603

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.64608

Cumulative Model Updates: 195,142
Cumulative Timesteps: 1,627,459,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.95840
Policy Entropy: 2.28360
Value Function Loss: 0.01515

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.56283

Collected Steps per Second: 23,520.55511
Overall Steps per Second: 10,870.27648

Timestep Collection Time: 2.12589
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.59988

Cumulative Model Updates: 195,148
Cumulative Timesteps: 1,627,509,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1627509470...
Checkpoint 1627509470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.66503
Policy Entropy: 2.30365
Value Function Loss: 0.01538

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.57618

Collected Steps per Second: 23,106.87872
Overall Steps per Second: 11,056.87773

Timestep Collection Time: 2.16464
Timestep Consumption Time: 2.35906
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.52370

Cumulative Model Updates: 195,154
Cumulative Timesteps: 1,627,559,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.34241
Policy Entropy: 2.31800
Value Function Loss: 0.01506

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.57087

Collected Steps per Second: 23,706.97706
Overall Steps per Second: 10,883.70065

Timestep Collection Time: 2.10942
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.59476

Cumulative Model Updates: 195,160
Cumulative Timesteps: 1,627,609,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1627609496...
Checkpoint 1627609496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.95996
Policy Entropy: 2.29618
Value Function Loss: 0.01566

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.56746

Collected Steps per Second: 22,928.77700
Overall Steps per Second: 10,697.58420

Timestep Collection Time: 2.18163
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.67601

Cumulative Model Updates: 195,166
Cumulative Timesteps: 1,627,659,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.48701
Policy Entropy: 2.29457
Value Function Loss: 0.01553

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.58371

Collected Steps per Second: 23,465.33637
Overall Steps per Second: 10,842.79081

Timestep Collection Time: 2.13157
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.61302

Cumulative Model Updates: 195,172
Cumulative Timesteps: 1,627,709,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1627709536...
Checkpoint 1627709536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.81130
Policy Entropy: 2.27188
Value Function Loss: 0.01622

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.59767

Collected Steps per Second: 22,824.84915
Overall Steps per Second: 10,749.69504

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.65223

Cumulative Model Updates: 195,178
Cumulative Timesteps: 1,627,759,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.67336
Policy Entropy: 2.29610
Value Function Loss: 0.01673

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.55600
Value Function Update Magnitude: 0.61140

Collected Steps per Second: 23,323.17734
Overall Steps per Second: 11,015.61673

Timestep Collection Time: 2.14422
Timestep Consumption Time: 2.39570
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.53992

Cumulative Model Updates: 195,184
Cumulative Timesteps: 1,627,809,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1627809556...
Checkpoint 1627809556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.89228
Policy Entropy: 2.30722
Value Function Loss: 0.01685

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.61716

Collected Steps per Second: 22,890.13682
Overall Steps per Second: 10,869.00147

Timestep Collection Time: 2.18443
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.60042

Cumulative Model Updates: 195,190
Cumulative Timesteps: 1,627,859,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.77938
Policy Entropy: 2.31759
Value Function Loss: 0.01671

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.55057
Value Function Update Magnitude: 0.60103

Collected Steps per Second: 23,313.18711
Overall Steps per Second: 10,961.74029

Timestep Collection Time: 2.14548
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.56296

Cumulative Model Updates: 195,196
Cumulative Timesteps: 1,627,909,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1627909576...
Checkpoint 1627909576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.01221
Policy Entropy: 2.30468
Value Function Loss: 0.01577

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.58644

Collected Steps per Second: 22,315.01631
Overall Steps per Second: 10,539.37747

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.74582

Cumulative Model Updates: 195,202
Cumulative Timesteps: 1,627,959,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.14809
Policy Entropy: 2.29104
Value Function Loss: 0.01610

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.56229
Value Function Update Magnitude: 0.59196

Collected Steps per Second: 22,775.98624
Overall Steps per Second: 10,870.56456

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.40496
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60087

Cumulative Model Updates: 195,208
Cumulative Timesteps: 1,628,009,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1628009608...
Checkpoint 1628009608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.34830
Policy Entropy: 2.28358
Value Function Loss: 0.01586

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.59159

Collected Steps per Second: 22,807.61566
Overall Steps per Second: 10,871.77290

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.40682
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.59907

Cumulative Model Updates: 195,214
Cumulative Timesteps: 1,628,059,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.32234
Policy Entropy: 2.28221
Value Function Loss: 0.01571

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.55100
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 23,625.97667
Overall Steps per Second: 10,830.99392

Timestep Collection Time: 2.11708
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.61804

Cumulative Model Updates: 195,220
Cumulative Timesteps: 1,628,109,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1628109626...
Checkpoint 1628109626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.23104
Policy Entropy: 2.28062
Value Function Loss: 0.01577

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.59687

Collected Steps per Second: 23,169.98698
Overall Steps per Second: 10,797.58195

Timestep Collection Time: 2.15891
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.63270

Cumulative Model Updates: 195,226
Cumulative Timesteps: 1,628,159,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.32943
Policy Entropy: 2.28697
Value Function Loss: 0.01643

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.60115

Collected Steps per Second: 23,461.55295
Overall Steps per Second: 10,832.50903

Timestep Collection Time: 2.13166
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.61684

Cumulative Model Updates: 195,232
Cumulative Timesteps: 1,628,209,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1628209660...
Checkpoint 1628209660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.03208
Policy Entropy: 2.28944
Value Function Loss: 0.01737

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.60111

Collected Steps per Second: 22,733.82547
Overall Steps per Second: 10,868.09135

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.40193
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60191

Cumulative Model Updates: 195,238
Cumulative Timesteps: 1,628,259,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.95103
Policy Entropy: 2.29089
Value Function Loss: 0.01626

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.54311
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 23,482.44356
Overall Steps per Second: 11,013.65349

Timestep Collection Time: 2.12925
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.53982

Cumulative Model Updates: 195,244
Cumulative Timesteps: 1,628,309,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1628309674...
Checkpoint 1628309674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.75427
Policy Entropy: 2.30061
Value Function Loss: 0.01617

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.54944

Collected Steps per Second: 23,271.56602
Overall Steps per Second: 10,858.56197

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.45680
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.60595

Cumulative Model Updates: 195,250
Cumulative Timesteps: 1,628,359,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.92516
Policy Entropy: 2.29140
Value Function Loss: 0.01620

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.55860

Collected Steps per Second: 23,746.92159
Overall Steps per Second: 10,909.52052

Timestep Collection Time: 2.10604
Timestep Consumption Time: 2.47821
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.58425

Cumulative Model Updates: 195,256
Cumulative Timesteps: 1,628,409,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1628409700...
Checkpoint 1628409700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.32445
Policy Entropy: 2.29552
Value Function Loss: 0.01568

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.57102

Collected Steps per Second: 22,606.88923
Overall Steps per Second: 10,840.72341

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.40168
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61445

Cumulative Model Updates: 195,262
Cumulative Timesteps: 1,628,459,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.51071
Policy Entropy: 2.27816
Value Function Loss: 0.01537

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.57676

Collected Steps per Second: 23,269.07635
Overall Steps per Second: 10,921.92178

Timestep Collection Time: 2.14963
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.57978

Cumulative Model Updates: 195,268
Cumulative Timesteps: 1,628,509,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1628509744...
Checkpoint 1628509744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.21248
Policy Entropy: 2.29670
Value Function Loss: 0.01460

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.53212
Value Function Update Magnitude: 0.57228

Collected Steps per Second: 23,019.52359
Overall Steps per Second: 10,729.78650

Timestep Collection Time: 2.17398
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.66403

Cumulative Model Updates: 195,274
Cumulative Timesteps: 1,628,559,788

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.07126
Policy Entropy: 2.29689
Value Function Loss: 0.01566

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.18533
Policy Update Magnitude: 0.49843
Value Function Update Magnitude: 0.58422

Collected Steps per Second: 23,303.78982
Overall Steps per Second: 10,882.66267

Timestep Collection Time: 2.14609
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.59557

Cumulative Model Updates: 195,280
Cumulative Timesteps: 1,628,609,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1628609800...
Checkpoint 1628609800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.02561
Policy Entropy: 2.30210
Value Function Loss: 0.01599

Mean KL Divergence: 0.02686
SB3 Clip Fraction: 0.18022
Policy Update Magnitude: 0.50731
Value Function Update Magnitude: 0.59699

Collected Steps per Second: 22,603.10481
Overall Steps per Second: 10,672.43829

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.68703

Cumulative Model Updates: 195,286
Cumulative Timesteps: 1,628,659,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.77095
Policy Entropy: 2.31707
Value Function Loss: 0.01591

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.17887
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.57937

Collected Steps per Second: 23,296.74350
Overall Steps per Second: 10,885.87591

Timestep Collection Time: 2.14708
Timestep Consumption Time: 2.44786
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.59494

Cumulative Model Updates: 195,292
Cumulative Timesteps: 1,628,709,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1628709842...
Checkpoint 1628709842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.83376
Policy Entropy: 2.31539
Value Function Loss: 0.01515

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.17801
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.56663

Collected Steps per Second: 23,136.65527
Overall Steps per Second: 11,119.17657

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.33706
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.49943

Cumulative Model Updates: 195,298
Cumulative Timesteps: 1,628,759,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.60151
Policy Entropy: 2.31113
Value Function Loss: 0.01540

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.18368
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 23,580.61777
Overall Steps per Second: 10,893.27157

Timestep Collection Time: 2.12149
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.59238

Cumulative Model Updates: 195,304
Cumulative Timesteps: 1,628,809,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1628809898...
Checkpoint 1628809898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.44992
Policy Entropy: 2.31198
Value Function Loss: 0.01527

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.52206
Value Function Update Magnitude: 0.54791

Collected Steps per Second: 22,922.01314
Overall Steps per Second: 10,679.01871

Timestep Collection Time: 2.18201
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.68358

Cumulative Model Updates: 195,310
Cumulative Timesteps: 1,628,859,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.06295
Policy Entropy: 2.30981
Value Function Loss: 0.01521

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14702
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.55347

Collected Steps per Second: 23,483.35897
Overall Steps per Second: 10,879.19223

Timestep Collection Time: 2.13019
Timestep Consumption Time: 2.46795
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.59814

Cumulative Model Updates: 195,316
Cumulative Timesteps: 1,628,909,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1628909938...
Checkpoint 1628909938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.33130
Policy Entropy: 2.30921
Value Function Loss: 0.01513

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.53697

Collected Steps per Second: 23,183.41147
Overall Steps per Second: 10,861.05426

Timestep Collection Time: 2.15758
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.60545

Cumulative Model Updates: 195,322
Cumulative Timesteps: 1,628,959,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.15310
Policy Entropy: 2.29797
Value Function Loss: 0.01644

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.54261

Collected Steps per Second: 23,614.06575
Overall Steps per Second: 11,215.60305

Timestep Collection Time: 2.11908
Timestep Consumption Time: 2.34257
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.46164

Cumulative Model Updates: 195,328
Cumulative Timesteps: 1,629,009,998

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1629009998...
Checkpoint 1629009998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476.56515
Policy Entropy: 2.26184
Value Function Loss: 0.01637

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.54813
Value Function Update Magnitude: 0.56730

Collected Steps per Second: 22,658.89759
Overall Steps per Second: 10,575.80406

Timestep Collection Time: 2.20814
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73099

Cumulative Model Updates: 195,334
Cumulative Timesteps: 1,629,060,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.84584
Policy Entropy: 2.24512
Value Function Loss: 0.01518

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.57668

Collected Steps per Second: 22,115.24710
Overall Steps per Second: 10,444.63900

Timestep Collection Time: 2.26134
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.78810

Cumulative Model Updates: 195,340
Cumulative Timesteps: 1,629,110,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1629110042...
Checkpoint 1629110042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.23998
Policy Entropy: 2.24872
Value Function Loss: 0.01499

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.57421

Collected Steps per Second: 21,771.54023
Overall Steps per Second: 10,577.66761

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.72770

Cumulative Model Updates: 195,346
Cumulative Timesteps: 1,629,160,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.82498
Policy Entropy: 2.27592
Value Function Loss: 0.01416

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 22,990.67913
Overall Steps per Second: 11,062.46798

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.34602
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.52178

Cumulative Model Updates: 195,352
Cumulative Timesteps: 1,629,210,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1629210072...
Checkpoint 1629210072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.22425
Policy Entropy: 2.29120
Value Function Loss: 0.01475

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.57746

Collected Steps per Second: 22,938.08826
Overall Steps per Second: 10,713.83675

Timestep Collection Time: 2.17987
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66705

Cumulative Model Updates: 195,358
Cumulative Timesteps: 1,629,260,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.25158
Policy Entropy: 2.30866
Value Function Loss: 0.01463

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.59061

Collected Steps per Second: 23,625.09807
Overall Steps per Second: 10,826.46949

Timestep Collection Time: 2.11741
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.62053

Cumulative Model Updates: 195,364
Cumulative Timesteps: 1,629,310,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1629310098...
Checkpoint 1629310098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.80891
Policy Entropy: 2.30579
Value Function Loss: 0.01560

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.54353
Value Function Update Magnitude: 0.57642

Collected Steps per Second: 22,266.11574
Overall Steps per Second: 10,583.48223

Timestep Collection Time: 2.24619
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.72567

Cumulative Model Updates: 195,370
Cumulative Timesteps: 1,629,360,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.71681
Policy Entropy: 2.31135
Value Function Loss: 0.01516

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 23,430.31989
Overall Steps per Second: 10,948.26262

Timestep Collection Time: 2.13458
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.56821

Cumulative Model Updates: 195,376
Cumulative Timesteps: 1,629,410,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1629410126...
Checkpoint 1629410126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.15404
Policy Entropy: 2.28107
Value Function Loss: 0.01537

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.53024
Value Function Update Magnitude: 0.55943

Collected Steps per Second: 23,004.07951
Overall Steps per Second: 11,035.66159

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.35856
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.53330

Cumulative Model Updates: 195,382
Cumulative Timesteps: 1,629,460,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.99334
Policy Entropy: 2.27175
Value Function Loss: 0.01557

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 23,458.09704
Overall Steps per Second: 10,934.65741

Timestep Collection Time: 2.13206
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.57390

Cumulative Model Updates: 195,388
Cumulative Timesteps: 1,629,510,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1629510168...
Checkpoint 1629510168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.20813
Policy Entropy: 2.25360
Value Function Loss: 0.01581

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.54630
Value Function Update Magnitude: 0.59832

Collected Steps per Second: 23,072.44898
Overall Steps per Second: 10,685.43016

Timestep Collection Time: 2.16769
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.68058

Cumulative Model Updates: 195,394
Cumulative Timesteps: 1,629,560,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.90738
Policy Entropy: 2.27740
Value Function Loss: 0.01483

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.53696
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 23,486.65250
Overall Steps per Second: 10,894.13487

Timestep Collection Time: 2.12929
Timestep Consumption Time: 2.46125
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.59054

Cumulative Model Updates: 195,400
Cumulative Timesteps: 1,629,610,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1629610192...
Checkpoint 1629610192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.15866
Policy Entropy: 2.29737
Value Function Loss: 0.01346

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.52007
Value Function Update Magnitude: 0.57743

Collected Steps per Second: 22,966.65078
Overall Steps per Second: 11,048.04858

Timestep Collection Time: 2.17768
Timestep Consumption Time: 2.34927
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.52695

Cumulative Model Updates: 195,406
Cumulative Timesteps: 1,629,660,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.66200
Policy Entropy: 2.31270
Value Function Loss: 0.01370

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.53731

Collected Steps per Second: 23,657.64063
Overall Steps per Second: 10,977.04962

Timestep Collection Time: 2.11348
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.55496

Cumulative Model Updates: 195,412
Cumulative Timesteps: 1,629,710,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1629710206...
Checkpoint 1629710206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.77758
Policy Entropy: 2.29536
Value Function Loss: 0.01357

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.53042

Collected Steps per Second: 23,118.49521
Overall Steps per Second: 10,755.95314

Timestep Collection Time: 2.16338
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.64989

Cumulative Model Updates: 195,418
Cumulative Timesteps: 1,629,760,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.72807
Policy Entropy: 2.29596
Value Function Loss: 0.01485

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.55274

Collected Steps per Second: 23,414.77460
Overall Steps per Second: 10,838.39667

Timestep Collection Time: 2.13669
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.61600

Cumulative Model Updates: 195,424
Cumulative Timesteps: 1,629,810,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1629810250...
Checkpoint 1629810250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657.54567
Policy Entropy: 2.26929
Value Function Loss: 0.01411

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 22,719.17741
Overall Steps per Second: 10,719.36808

Timestep Collection Time: 2.20105
Timestep Consumption Time: 2.46397
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.66501

Cumulative Model Updates: 195,430
Cumulative Timesteps: 1,629,860,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.68762
Policy Entropy: 2.27960
Value Function Loss: 0.01402

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.58120

Collected Steps per Second: 23,403.97600
Overall Steps per Second: 11,072.79377

Timestep Collection Time: 2.13741
Timestep Consumption Time: 2.38033
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.51774

Cumulative Model Updates: 195,436
Cumulative Timesteps: 1,629,910,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1629910280...
Checkpoint 1629910280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595.35429
Policy Entropy: 2.27119
Value Function Loss: 0.01431

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.57320

Collected Steps per Second: 22,990.32613
Overall Steps per Second: 10,907.86664

Timestep Collection Time: 2.17587
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.58605

Cumulative Model Updates: 195,442
Cumulative Timesteps: 1,629,960,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.53066
Policy Entropy: 2.30035
Value Function Loss: 0.01417

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.54052
Value Function Update Magnitude: 0.55370

Collected Steps per Second: 23,167.03896
Overall Steps per Second: 10,844.62281

Timestep Collection Time: 2.15971
Timestep Consumption Time: 2.45401
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.61372

Cumulative Model Updates: 195,448
Cumulative Timesteps: 1,630,010,338

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1630010338...
Checkpoint 1630010338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.65699
Policy Entropy: 2.27499
Value Function Loss: 0.01511

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.52406
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 23,128.57345
Overall Steps per Second: 10,862.50152

Timestep Collection Time: 2.16183
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.60299

Cumulative Model Updates: 195,454
Cumulative Timesteps: 1,630,060,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.65952
Policy Entropy: 2.28268
Value Function Loss: 0.01560

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 23,648.79082
Overall Steps per Second: 11,077.51478

Timestep Collection Time: 2.11486
Timestep Consumption Time: 2.40005
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.51491

Cumulative Model Updates: 195,460
Cumulative Timesteps: 1,630,110,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1630110352...
Checkpoint 1630110352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.72862
Policy Entropy: 2.27919
Value Function Loss: 0.01623

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 23,103.33306
Overall Steps per Second: 11,078.87840

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.34918
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.51363

Cumulative Model Updates: 195,466
Cumulative Timesteps: 1,630,160,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.11551
Policy Entropy: 2.28375
Value Function Loss: 0.01577

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.57181

Collected Steps per Second: 23,230.84177
Overall Steps per Second: 10,910.59252

Timestep Collection Time: 2.15300
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58417

Cumulative Model Updates: 195,472
Cumulative Timesteps: 1,630,210,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1630210374...
Checkpoint 1630210374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.03756
Policy Entropy: 2.27293
Value Function Loss: 0.01546

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.57085

Collected Steps per Second: 22,728.65276
Overall Steps per Second: 10,703.23609

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.67223

Cumulative Model Updates: 195,478
Cumulative Timesteps: 1,630,260,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.01392
Policy Entropy: 2.26768
Value Function Loss: 0.01552

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.54605
Value Function Update Magnitude: 0.57849

Collected Steps per Second: 23,374.50272
Overall Steps per Second: 11,000.89883

Timestep Collection Time: 2.14011
Timestep Consumption Time: 2.40716
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.54726

Cumulative Model Updates: 195,484
Cumulative Timesteps: 1,630,310,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1630310406...
Checkpoint 1630310406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.11576
Policy Entropy: 2.27103
Value Function Loss: 0.01513

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 22,401.02456
Overall Steps per Second: 10,652.61981

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.69537

Cumulative Model Updates: 195,490
Cumulative Timesteps: 1,630,360,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.31022
Policy Entropy: 2.27038
Value Function Loss: 0.01488

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 23,561.39411
Overall Steps per Second: 10,835.51902

Timestep Collection Time: 2.12220
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.61464

Cumulative Model Updates: 195,496
Cumulative Timesteps: 1,630,410,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1630410426...
Checkpoint 1630410426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.01242
Policy Entropy: 2.24993
Value Function Loss: 0.01451

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.53678
Value Function Update Magnitude: 0.54412

Collected Steps per Second: 23,230.77440
Overall Steps per Second: 10,791.06384

Timestep Collection Time: 2.15352
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.63606

Cumulative Model Updates: 195,502
Cumulative Timesteps: 1,630,460,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.67062
Policy Entropy: 2.20559
Value Function Loss: 0.01547

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.54122

Collected Steps per Second: 23,136.65312
Overall Steps per Second: 10,773.07302

Timestep Collection Time: 2.16116
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.64139

Cumulative Model Updates: 195,508
Cumulative Timesteps: 1,630,510,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1630510456...
Checkpoint 1630510456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.72758
Policy Entropy: 2.18164
Value Function Loss: 0.01471

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.54860

Collected Steps per Second: 23,251.06736
Overall Steps per Second: 10,998.37393

Timestep Collection Time: 2.15087
Timestep Consumption Time: 2.39617
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.54704

Cumulative Model Updates: 195,514
Cumulative Timesteps: 1,630,560,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.99718
Policy Entropy: 2.20483
Value Function Loss: 0.01564

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.54602

Collected Steps per Second: 23,064.82804
Overall Steps per Second: 11,059.32881

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.35364
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.52179

Cumulative Model Updates: 195,520
Cumulative Timesteps: 1,630,610,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1630610474...
Checkpoint 1630610474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.43671
Policy Entropy: 2.22973
Value Function Loss: 0.01437

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 22,757.75818
Overall Steps per Second: 10,632.55248

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.70423

Cumulative Model Updates: 195,526
Cumulative Timesteps: 1,630,660,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.99347
Policy Entropy: 2.26364
Value Function Loss: 0.01489

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.56850

Collected Steps per Second: 23,405.10368
Overall Steps per Second: 10,893.35085

Timestep Collection Time: 2.13629
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.58996

Cumulative Model Updates: 195,532
Cumulative Timesteps: 1,630,710,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1630710492...
Checkpoint 1630710492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.52371
Policy Entropy: 2.24548
Value Function Loss: 0.01609

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.57843

Collected Steps per Second: 23,111.30476
Overall Steps per Second: 10,866.34423

Timestep Collection Time: 2.16388
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.60228

Cumulative Model Updates: 195,538
Cumulative Timesteps: 1,630,760,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.60633
Policy Entropy: 2.24384
Value Function Loss: 0.01773

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.56496
Value Function Update Magnitude: 0.59139

Collected Steps per Second: 23,485.19682
Overall Steps per Second: 10,926.83854

Timestep Collection Time: 2.13002
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.57809

Cumulative Model Updates: 195,544
Cumulative Timesteps: 1,630,810,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1630810526...
Checkpoint 1630810526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.12528
Policy Entropy: 2.24491
Value Function Loss: 0.01792

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.56120
Value Function Update Magnitude: 0.60785

Collected Steps per Second: 22,858.10811
Overall Steps per Second: 10,819.54541

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.62256

Cumulative Model Updates: 195,550
Cumulative Timesteps: 1,630,860,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.86045
Policy Entropy: 2.22277
Value Function Loss: 0.01750

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.14928
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.59943

Collected Steps per Second: 23,499.02790
Overall Steps per Second: 10,908.96529

Timestep Collection Time: 2.12868
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.58540

Cumulative Model Updates: 195,556
Cumulative Timesteps: 1,630,910,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1630910562...
Checkpoint 1630910562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.11706
Policy Entropy: 2.22062
Value Function Loss: 0.01610

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.59320

Collected Steps per Second: 23,121.92279
Overall Steps per Second: 10,778.91938

Timestep Collection Time: 2.16314
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.64017

Cumulative Model Updates: 195,562
Cumulative Timesteps: 1,630,960,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.80079
Policy Entropy: 2.20275
Value Function Loss: 0.01584

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.14872
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.58553

Collected Steps per Second: 23,556.82648
Overall Steps per Second: 10,778.46213

Timestep Collection Time: 2.12329
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64055

Cumulative Model Updates: 195,568
Cumulative Timesteps: 1,631,010,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1631010596...
Checkpoint 1631010596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.36752
Policy Entropy: 2.18114
Value Function Loss: 0.01651

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.58438

Collected Steps per Second: 22,966.70283
Overall Steps per Second: 10,775.03460

Timestep Collection Time: 2.17750
Timestep Consumption Time: 2.46378
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.64128

Cumulative Model Updates: 195,574
Cumulative Timesteps: 1,631,060,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.35857
Policy Entropy: 2.17956
Value Function Loss: 0.01691

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 23,693.50550
Overall Steps per Second: 10,956.06509

Timestep Collection Time: 2.11087
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.56496

Cumulative Model Updates: 195,580
Cumulative Timesteps: 1,631,110,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1631110620...
Checkpoint 1631110620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.88289
Policy Entropy: 2.18012
Value Function Loss: 0.01697

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.58302
Value Function Update Magnitude: 0.61563

Collected Steps per Second: 23,003.70646
Overall Steps per Second: 10,930.84999

Timestep Collection Time: 2.17382
Timestep Consumption Time: 2.40093
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.57476

Cumulative Model Updates: 195,586
Cumulative Timesteps: 1,631,160,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.95102
Policy Entropy: 2.22143
Value Function Loss: 0.01678

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.60476

Collected Steps per Second: 23,612.04191
Overall Steps per Second: 10,911.50225

Timestep Collection Time: 2.11824
Timestep Consumption Time: 2.46555
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.58379

Cumulative Model Updates: 195,592
Cumulative Timesteps: 1,631,210,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1631210642...
Checkpoint 1631210642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.55363
Policy Entropy: 2.21932
Value Function Loss: 0.01592

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.58860

Collected Steps per Second: 22,689.55230
Overall Steps per Second: 10,605.45271

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.51110
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.71493

Cumulative Model Updates: 195,598
Cumulative Timesteps: 1,631,260,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.32420
Policy Entropy: 2.23283
Value Function Loss: 0.01601

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.56835

Collected Steps per Second: 22,890.47081
Overall Steps per Second: 10,890.22706

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.40715
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59164

Cumulative Model Updates: 195,604
Cumulative Timesteps: 1,631,310,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1631310650...
Checkpoint 1631310650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.69496
Policy Entropy: 2.23296
Value Function Loss: 0.01504

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.55538

Collected Steps per Second: 23,162.64657
Overall Steps per Second: 11,099.62382

Timestep Collection Time: 2.15908
Timestep Consumption Time: 2.34648
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.50556

Cumulative Model Updates: 195,610
Cumulative Timesteps: 1,631,360,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.87408
Policy Entropy: 2.24203
Value Function Loss: 0.01455

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.55530

Collected Steps per Second: 23,527.12327
Overall Steps per Second: 10,985.97813

Timestep Collection Time: 2.12521
Timestep Consumption Time: 2.42605
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.55126

Cumulative Model Updates: 195,616
Cumulative Timesteps: 1,631,410,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1631410660...
Checkpoint 1631410660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.63763
Policy Entropy: 2.21981
Value Function Loss: 0.01427

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.54409

Collected Steps per Second: 22,975.97235
Overall Steps per Second: 10,726.04286

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66248

Cumulative Model Updates: 195,622
Cumulative Timesteps: 1,631,460,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.30687
Policy Entropy: 2.20092
Value Function Loss: 0.01569

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 23,164.19194
Overall Steps per Second: 10,796.23158

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.47334
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.63236

Cumulative Model Updates: 195,628
Cumulative Timesteps: 1,631,510,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1631510682...
Checkpoint 1631510682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.82442
Policy Entropy: 2.20379
Value Function Loss: 0.01678

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.59388

Collected Steps per Second: 23,115.03702
Overall Steps per Second: 11,082.60031

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.34970
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.51392

Cumulative Model Updates: 195,634
Cumulative Timesteps: 1,631,560,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.61845
Policy Entropy: 2.19631
Value Function Loss: 0.01781

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.18872
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.60596

Collected Steps per Second: 23,639.09464
Overall Steps per Second: 10,956.05666

Timestep Collection Time: 2.11624
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.56606

Cumulative Model Updates: 195,640
Cumulative Timesteps: 1,631,610,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1631610734...
Checkpoint 1631610734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.66031
Policy Entropy: 2.20903
Value Function Loss: 0.01664

Mean KL Divergence: 0.02434
SB3 Clip Fraction: 0.17736
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.61707

Collected Steps per Second: 22,915.98906
Overall Steps per Second: 10,673.38489

Timestep Collection Time: 2.18293
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68680

Cumulative Model Updates: 195,646
Cumulative Timesteps: 1,631,660,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.78532
Policy Entropy: 2.20341
Value Function Loss: 0.01591

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.16504
Policy Update Magnitude: 0.57535
Value Function Update Magnitude: 0.61918

Collected Steps per Second: 23,573.92994
Overall Steps per Second: 10,868.65116

Timestep Collection Time: 2.12175
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.60204

Cumulative Model Updates: 195,652
Cumulative Timesteps: 1,631,710,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1631710776...
Checkpoint 1631710776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424.86019
Policy Entropy: 2.21772
Value Function Loss: 0.01517

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 22,872.51645
Overall Steps per Second: 10,773.82955

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.64273

Cumulative Model Updates: 195,658
Cumulative Timesteps: 1,631,760,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.30824
Policy Entropy: 2.23171
Value Function Loss: 0.01477

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.58645

Collected Steps per Second: 23,512.17122
Overall Steps per Second: 11,164.29923

Timestep Collection Time: 2.12809
Timestep Consumption Time: 2.35370
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.48179

Cumulative Model Updates: 195,664
Cumulative Timesteps: 1,631,810,832

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1631810832...
Checkpoint 1631810832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.95216
Policy Entropy: 2.22303
Value Function Loss: 0.01483

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 22,120.96730
Overall Steps per Second: 10,712.47997

Timestep Collection Time: 2.26039
Timestep Consumption Time: 2.40725
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66764

Cumulative Model Updates: 195,670
Cumulative Timesteps: 1,631,860,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.64926
Policy Entropy: 2.22497
Value Function Loss: 0.01458

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.59248

Collected Steps per Second: 23,419.37263
Overall Steps per Second: 10,972.17888

Timestep Collection Time: 2.13550
Timestep Consumption Time: 2.42258
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.55807

Cumulative Model Updates: 195,676
Cumulative Timesteps: 1,631,910,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1631910846...
Checkpoint 1631910846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.74419
Policy Entropy: 2.21620
Value Function Loss: 0.01509

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.61959

Collected Steps per Second: 23,063.78148
Overall Steps per Second: 10,810.42756

Timestep Collection Time: 2.16833
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.62609

Cumulative Model Updates: 195,682
Cumulative Timesteps: 1,631,960,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.16954
Policy Entropy: 2.21167
Value Function Loss: 0.01581

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.59211

Collected Steps per Second: 23,510.57182
Overall Steps per Second: 10,939.83906

Timestep Collection Time: 2.12789
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.57301

Cumulative Model Updates: 195,688
Cumulative Timesteps: 1,632,010,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1632010884...
Checkpoint 1632010884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.00149
Policy Entropy: 2.20262
Value Function Loss: 0.01629

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.56737
Value Function Update Magnitude: 0.55684

Collected Steps per Second: 22,893.28711
Overall Steps per Second: 10,836.22826

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.61581

Cumulative Model Updates: 195,694
Cumulative Timesteps: 1,632,060,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.99158
Policy Entropy: 2.21531
Value Function Loss: 0.01648

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 23,512.61925
Overall Steps per Second: 10,934.34274

Timestep Collection Time: 2.12686
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.57348

Cumulative Model Updates: 195,700
Cumulative Timesteps: 1,632,110,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1632110910...
Checkpoint 1632110910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.44340
Policy Entropy: 2.20852
Value Function Loss: 0.01617

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.57633

Collected Steps per Second: 23,046.88796
Overall Steps per Second: 10,747.03354

Timestep Collection Time: 2.17079
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.65524

Cumulative Model Updates: 195,706
Cumulative Timesteps: 1,632,160,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.60707
Policy Entropy: 2.18850
Value Function Loss: 0.01503

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.15117
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 23,181.09941
Overall Steps per Second: 10,800.45960

Timestep Collection Time: 2.15702
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.62962

Cumulative Model Updates: 195,712
Cumulative Timesteps: 1,632,210,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1632210942...
Checkpoint 1632210942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.37391
Policy Entropy: 2.18700
Value Function Loss: 0.01487

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.55054

Collected Steps per Second: 23,011.55081
Overall Steps per Second: 10,705.20890

Timestep Collection Time: 2.17395
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.67305

Cumulative Model Updates: 195,718
Cumulative Timesteps: 1,632,260,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.90722
Policy Entropy: 2.18880
Value Function Loss: 0.01463

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.54131

Collected Steps per Second: 23,547.13326
Overall Steps per Second: 11,059.31410

Timestep Collection Time: 2.12450
Timestep Consumption Time: 2.39892
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.52343

Cumulative Model Updates: 195,724
Cumulative Timesteps: 1,632,310,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1632310994...
Checkpoint 1632310994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.92831
Policy Entropy: 2.21153
Value Function Loss: 0.01455

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.53228

Collected Steps per Second: 23,241.72693
Overall Steps per Second: 10,849.32957

Timestep Collection Time: 2.15191
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.60987

Cumulative Model Updates: 195,730
Cumulative Timesteps: 1,632,361,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.75810
Policy Entropy: 2.21361
Value Function Loss: 0.01568

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.53385

Collected Steps per Second: 23,692.00357
Overall Steps per Second: 10,938.37640

Timestep Collection Time: 2.11042
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.57106

Cumulative Model Updates: 195,736
Cumulative Timesteps: 1,632,411,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1632411008...
Checkpoint 1632411008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.04319
Policy Entropy: 2.21739
Value Function Loss: 0.01503

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.54402

Collected Steps per Second: 23,109.13401
Overall Steps per Second: 10,750.98775

Timestep Collection Time: 2.16434
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.65222

Cumulative Model Updates: 195,742
Cumulative Timesteps: 1,632,461,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.49276
Policy Entropy: 2.22036
Value Function Loss: 0.01462

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.56633

Collected Steps per Second: 23,371.12848
Overall Steps per Second: 10,778.38725

Timestep Collection Time: 2.13965
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.63947

Cumulative Model Updates: 195,748
Cumulative Timesteps: 1,632,511,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1632511030...
Checkpoint 1632511030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.47994
Policy Entropy: 2.21933
Value Function Loss: 0.01421

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 23,313.93830
Overall Steps per Second: 11,157.95869

Timestep Collection Time: 2.14524
Timestep Consumption Time: 2.33712
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.48236

Cumulative Model Updates: 195,754
Cumulative Timesteps: 1,632,561,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.87691
Policy Entropy: 2.22574
Value Function Loss: 0.01502

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.55257

Collected Steps per Second: 23,729.87313
Overall Steps per Second: 10,898.77441

Timestep Collection Time: 2.10831
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.59042

Cumulative Model Updates: 195,760
Cumulative Timesteps: 1,632,611,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1632611074...
Checkpoint 1632611074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.54699
Policy Entropy: 2.23695
Value Function Loss: 0.01596

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.55640

Collected Steps per Second: 23,108.52772
Overall Steps per Second: 10,763.38026

Timestep Collection Time: 2.16370
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.64538

Cumulative Model Updates: 195,766
Cumulative Timesteps: 1,632,661,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.11265
Policy Entropy: 2.25371
Value Function Loss: 0.01567

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 23,479.31609
Overall Steps per Second: 10,808.43936

Timestep Collection Time: 2.12962
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.62620

Cumulative Model Updates: 195,772
Cumulative Timesteps: 1,632,711,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1632711076...
Checkpoint 1632711076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.21815
Policy Entropy: 2.25296
Value Function Loss: 0.01526

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.58647

Collected Steps per Second: 22,765.46712
Overall Steps per Second: 10,748.54508

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.65291

Cumulative Model Updates: 195,778
Cumulative Timesteps: 1,632,761,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.26261
Policy Entropy: 2.25661
Value Function Loss: 0.01498

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.54459
Value Function Update Magnitude: 0.57840

Collected Steps per Second: 23,675.43547
Overall Steps per Second: 11,153.72090

Timestep Collection Time: 2.11215
Timestep Consumption Time: 2.37120
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.48335

Cumulative Model Updates: 195,784
Cumulative Timesteps: 1,632,811,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1632811094...
Checkpoint 1632811094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.87269
Policy Entropy: 2.26572
Value Function Loss: 0.01450

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.56156

Collected Steps per Second: 22,803.41150
Overall Steps per Second: 10,690.96702

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.48459
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67759

Cumulative Model Updates: 195,790
Cumulative Timesteps: 1,632,861,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.34922
Policy Entropy: 2.26604
Value Function Loss: 0.01478

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.53163

Collected Steps per Second: 23,319.81215
Overall Steps per Second: 10,933.72164

Timestep Collection Time: 2.14530
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.57557

Cumulative Model Updates: 195,796
Cumulative Timesteps: 1,632,911,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1632911130...
Checkpoint 1632911130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.64076
Policy Entropy: 2.23563
Value Function Loss: 0.01568

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.52035

Collected Steps per Second: 23,100.86475
Overall Steps per Second: 10,843.44703

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.61219

Cumulative Model Updates: 195,802
Cumulative Timesteps: 1,632,961,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.62281
Policy Entropy: 2.22396
Value Function Loss: 0.01673

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.52310

Collected Steps per Second: 23,688.86988
Overall Steps per Second: 11,197.01524

Timestep Collection Time: 2.11137
Timestep Consumption Time: 2.35553
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.46690

Cumulative Model Updates: 195,808
Cumulative Timesteps: 1,633,011,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1633011158...
Checkpoint 1633011158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.26033
Policy Entropy: 2.19681
Value Function Loss: 0.01687

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.55280

Collected Steps per Second: 23,190.67421
Overall Steps per Second: 10,797.48306

Timestep Collection Time: 2.15690
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.63256

Cumulative Model Updates: 195,814
Cumulative Timesteps: 1,633,061,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.79554
Policy Entropy: 2.20995
Value Function Loss: 0.01707

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.56222
Value Function Update Magnitude: 0.58638

Collected Steps per Second: 23,460.30492
Overall Steps per Second: 10,819.23706

Timestep Collection Time: 2.13194
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.62288

Cumulative Model Updates: 195,820
Cumulative Timesteps: 1,633,111,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1633111194...
Checkpoint 1633111194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.37885
Policy Entropy: 2.22261
Value Function Loss: 0.01605

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 22,919.94971
Overall Steps per Second: 10,912.81170

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.40065
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.58250

Cumulative Model Updates: 195,826
Cumulative Timesteps: 1,633,161,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.52966
Policy Entropy: 2.23845
Value Function Loss: 0.01612

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.58636

Collected Steps per Second: 23,223.35074
Overall Steps per Second: 11,026.97284

Timestep Collection Time: 2.15335
Timestep Consumption Time: 2.38171
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.53506

Cumulative Model Updates: 195,832
Cumulative Timesteps: 1,633,211,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1633211210...
Checkpoint 1633211210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.76161
Policy Entropy: 2.24346
Value Function Loss: 0.01619

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.55810
Value Function Update Magnitude: 0.57420

Collected Steps per Second: 23,135.53721
Overall Steps per Second: 10,791.79320

Timestep Collection Time: 2.16247
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.63593

Cumulative Model Updates: 195,838
Cumulative Timesteps: 1,633,261,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.11046
Policy Entropy: 2.24168
Value Function Loss: 0.01650

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.55396
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 23,636.24173
Overall Steps per Second: 10,893.24500

Timestep Collection Time: 2.11633
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.59202

Cumulative Model Updates: 195,844
Cumulative Timesteps: 1,633,311,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1633311262...
Checkpoint 1633311262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.82739
Policy Entropy: 2.25982
Value Function Loss: 0.01540

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.56230

Collected Steps per Second: 23,128.27010
Overall Steps per Second: 10,881.69776

Timestep Collection Time: 2.16238
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59597

Cumulative Model Updates: 195,850
Cumulative Timesteps: 1,633,361,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.80694
Policy Entropy: 2.25596
Value Function Loss: 0.01531

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.55171

Collected Steps per Second: 22,036.74559
Overall Steps per Second: 10,505.93422

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.49068
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.75998

Cumulative Model Updates: 195,856
Cumulative Timesteps: 1,633,411,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1633411282...
Checkpoint 1633411282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.84161
Policy Entropy: 2.24520
Value Function Loss: 0.01483

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.55005

Collected Steps per Second: 22,773.24422
Overall Steps per Second: 10,892.12660

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.39645
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.59341

Cumulative Model Updates: 195,862
Cumulative Timesteps: 1,633,461,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.31512
Policy Entropy: 2.24264
Value Function Loss: 0.01434

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.55221

Collected Steps per Second: 23,649.16305
Overall Steps per Second: 10,909.32214

Timestep Collection Time: 2.11542
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.58580

Cumulative Model Updates: 195,868
Cumulative Timesteps: 1,633,511,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1633511342...
Checkpoint 1633511342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.64437
Policy Entropy: 2.27547
Value Function Loss: 0.01483

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.52007
Value Function Update Magnitude: 0.55235

Collected Steps per Second: 23,288.56448
Overall Steps per Second: 10,883.48482

Timestep Collection Time: 2.14809
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.59651

Cumulative Model Updates: 195,874
Cumulative Timesteps: 1,633,561,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.80909
Policy Entropy: 2.26590
Value Function Loss: 0.01509

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.55344

Collected Steps per Second: 23,161.50357
Overall Steps per Second: 10,917.11896

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.42237
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.58216

Cumulative Model Updates: 195,880
Cumulative Timesteps: 1,633,611,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1633611392...
Checkpoint 1633611392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.36926
Policy Entropy: 2.27570
Value Function Loss: 0.01551

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.55349

Collected Steps per Second: 22,752.00789
Overall Steps per Second: 11,007.22028

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.34618
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.54502

Cumulative Model Updates: 195,886
Cumulative Timesteps: 1,633,661,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.13891
Policy Entropy: 2.26618
Value Function Loss: 0.01557

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.55446

Collected Steps per Second: 23,315.57317
Overall Steps per Second: 10,910.33003

Timestep Collection Time: 2.14458
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.58300

Cumulative Model Updates: 195,892
Cumulative Timesteps: 1,633,711,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1633711422...
Checkpoint 1633711422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.67431
Policy Entropy: 2.26627
Value Function Loss: 0.01536

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.52306
Value Function Update Magnitude: 0.57025

Collected Steps per Second: 23,090.19888
Overall Steps per Second: 10,722.37775

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.66389

Cumulative Model Updates: 195,898
Cumulative Timesteps: 1,633,761,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.13163
Policy Entropy: 2.26978
Value Function Loss: 0.01549

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.56055

Collected Steps per Second: 23,557.16375
Overall Steps per Second: 10,936.20390

Timestep Collection Time: 2.12352
Timestep Consumption Time: 2.45065
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.57416

Cumulative Model Updates: 195,904
Cumulative Timesteps: 1,633,811,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1633811454...
Checkpoint 1633811454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.06658
Policy Entropy: 2.25530
Value Function Loss: 0.01626

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 22,780.54815
Overall Steps per Second: 10,764.04273

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.45024
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.64509

Cumulative Model Updates: 195,910
Cumulative Timesteps: 1,633,861,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.66909
Policy Entropy: 2.25406
Value Function Loss: 0.01698

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.56126
Value Function Update Magnitude: 0.55090

Collected Steps per Second: 23,469.26056
Overall Steps per Second: 11,137.65284

Timestep Collection Time: 2.13079
Timestep Consumption Time: 2.35921
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.48999

Cumulative Model Updates: 195,916
Cumulative Timesteps: 1,633,911,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1633911462...
Checkpoint 1633911462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.82750
Policy Entropy: 2.21919
Value Function Loss: 0.01687

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 23,265.45413
Overall Steps per Second: 10,790.92451

Timestep Collection Time: 2.15040
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.63630

Cumulative Model Updates: 195,922
Cumulative Timesteps: 1,633,961,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.72468
Policy Entropy: 2.19833
Value Function Loss: 0.01674

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.57108
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 23,475.80057
Overall Steps per Second: 10,859.76970

Timestep Collection Time: 2.13011
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.60470

Cumulative Model Updates: 195,928
Cumulative Timesteps: 1,634,011,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1634011498...
Checkpoint 1634011498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.10430
Policy Entropy: 2.21405
Value Function Loss: 0.01609

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.58185

Collected Steps per Second: 22,979.23165
Overall Steps per Second: 10,721.98157

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.66332

Cumulative Model Updates: 195,934
Cumulative Timesteps: 1,634,061,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.59356
Policy Entropy: 2.21472
Value Function Loss: 0.01571

Mean KL Divergence: 0.03028
SB3 Clip Fraction: 0.18820
Policy Update Magnitude: 0.52070
Value Function Update Magnitude: 0.57100

Collected Steps per Second: 23,339.69801
Overall Steps per Second: 10,836.14179

Timestep Collection Time: 2.14313
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.61603

Cumulative Model Updates: 195,940
Cumulative Timesteps: 1,634,111,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1634111518...
Checkpoint 1634111518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.02516
Policy Entropy: 2.23668
Value Function Loss: 0.01464

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.17285
Policy Update Magnitude: 0.53805
Value Function Update Magnitude: 0.54104

Collected Steps per Second: 23,109.51104
Overall Steps per Second: 10,968.44755

Timestep Collection Time: 2.16413
Timestep Consumption Time: 2.39549
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.55962

Cumulative Model Updates: 195,946
Cumulative Timesteps: 1,634,161,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.77594
Policy Entropy: 2.24237
Value Function Loss: 0.01473

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.53925
Value Function Update Magnitude: 0.51129

Collected Steps per Second: 23,436.66593
Overall Steps per Second: 11,031.06730

Timestep Collection Time: 2.13375
Timestep Consumption Time: 2.39963
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.53338

Cumulative Model Updates: 195,952
Cumulative Timesteps: 1,634,211,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1634211538...
Checkpoint 1634211538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.95607
Policy Entropy: 2.26602
Value Function Loss: 0.01490

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.49255

Collected Steps per Second: 22,407.67421
Overall Steps per Second: 10,638.46083

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.70030

Cumulative Model Updates: 195,958
Cumulative Timesteps: 1,634,261,542

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.14440
Policy Entropy: 2.27095
Value Function Loss: 0.01475

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.49849

Collected Steps per Second: 23,586.64601
Overall Steps per Second: 10,896.05692

Timestep Collection Time: 2.12086
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.59102

Cumulative Model Updates: 195,964
Cumulative Timesteps: 1,634,311,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1634311566...
Checkpoint 1634311566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.13418
Policy Entropy: 2.25968
Value Function Loss: 0.01483

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.51944

Collected Steps per Second: 23,001.94044
Overall Steps per Second: 10,732.97694

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.65910

Cumulative Model Updates: 195,970
Cumulative Timesteps: 1,634,361,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.98824
Policy Entropy: 2.24658
Value Function Loss: 0.01471

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.55115

Collected Steps per Second: 23,595.69996
Overall Steps per Second: 10,924.78344

Timestep Collection Time: 2.12005
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.57895

Cumulative Model Updates: 195,976
Cumulative Timesteps: 1,634,411,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1634411596...
Checkpoint 1634411596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.81391
Policy Entropy: 2.25270
Value Function Loss: 0.01497

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.56174

Collected Steps per Second: 22,930.60672
Overall Steps per Second: 10,990.52587

Timestep Collection Time: 2.18136
Timestep Consumption Time: 2.36983
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.55119

Cumulative Model Updates: 195,982
Cumulative Timesteps: 1,634,461,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.61170
Policy Entropy: 2.23942
Value Function Loss: 0.01533

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.53735

Collected Steps per Second: 22,707.61584
Overall Steps per Second: 10,922.32636

Timestep Collection Time: 2.20314
Timestep Consumption Time: 2.37721
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.58034

Cumulative Model Updates: 195,988
Cumulative Timesteps: 1,634,511,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1634511644...
Checkpoint 1634511644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.58533
Policy Entropy: 2.26152
Value Function Loss: 0.01538

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.52433

Collected Steps per Second: 23,210.05396
Overall Steps per Second: 10,793.52386

Timestep Collection Time: 2.15467
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.63333

Cumulative Model Updates: 195,994
Cumulative Timesteps: 1,634,561,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.41921
Policy Entropy: 2.26071
Value Function Loss: 0.01469

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 23,747.82081
Overall Steps per Second: 10,909.47891

Timestep Collection Time: 2.10664
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.58574

Cumulative Model Updates: 196,000
Cumulative Timesteps: 1,634,611,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1634611682...
Checkpoint 1634611682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.56760
Policy Entropy: 2.28718
Value Function Loss: 0.01421

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.53751

Collected Steps per Second: 23,181.20340
Overall Steps per Second: 10,948.88857

Timestep Collection Time: 2.15709
Timestep Consumption Time: 2.40995
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.56704

Cumulative Model Updates: 196,006
Cumulative Timesteps: 1,634,661,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.07946
Policy Entropy: 2.27245
Value Function Loss: 0.01421

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 23,391.35011
Overall Steps per Second: 10,915.04933

Timestep Collection Time: 2.13823
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.58230

Cumulative Model Updates: 196,012
Cumulative Timesteps: 1,634,711,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1634711702...
Checkpoint 1634711702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.99114
Policy Entropy: 2.26185
Value Function Loss: 0.01539

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.55255

Collected Steps per Second: 22,977.91204
Overall Steps per Second: 11,063.73087

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.34383
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.52036

Cumulative Model Updates: 196,018
Cumulative Timesteps: 1,634,761,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.39736
Policy Entropy: 2.23958
Value Function Loss: 0.01486

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.54237
Value Function Update Magnitude: 0.55230

Collected Steps per Second: 23,665.87553
Overall Steps per Second: 10,961.68902

Timestep Collection Time: 2.11376
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.56353

Cumulative Model Updates: 196,024
Cumulative Timesteps: 1,634,811,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1634811738...
Checkpoint 1634811738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.01797
Policy Entropy: 2.26097
Value Function Loss: 0.01539

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.54970

Collected Steps per Second: 22,955.01282
Overall Steps per Second: 10,747.00843

Timestep Collection Time: 2.17826
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.65264

Cumulative Model Updates: 196,030
Cumulative Timesteps: 1,634,861,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.94794
Policy Entropy: 2.26546
Value Function Loss: 0.01517

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 23,352.27457
Overall Steps per Second: 10,827.68800

Timestep Collection Time: 2.14198
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.61964

Cumulative Model Updates: 196,036
Cumulative Timesteps: 1,634,911,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1634911760...
Checkpoint 1634911760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.33213
Policy Entropy: 2.26624
Value Function Loss: 0.01567

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.54582
Value Function Update Magnitude: 0.55699

Collected Steps per Second: 23,036.21263
Overall Steps per Second: 10,932.83504

Timestep Collection Time: 2.17058
Timestep Consumption Time: 2.40298
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.57356

Cumulative Model Updates: 196,042
Cumulative Timesteps: 1,634,961,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.13861
Policy Entropy: 2.25903
Value Function Loss: 0.01605

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.54269
Value Function Update Magnitude: 0.55100

Collected Steps per Second: 23,431.02850
Overall Steps per Second: 11,056.31987

Timestep Collection Time: 2.13520
Timestep Consumption Time: 2.38981
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.52501

Cumulative Model Updates: 196,048
Cumulative Timesteps: 1,635,011,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1635011792...
Checkpoint 1635011792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.15249
Policy Entropy: 2.27324
Value Function Loss: 0.01573

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 23,048.83093
Overall Steps per Second: 10,742.77611

Timestep Collection Time: 2.17000
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.65578

Cumulative Model Updates: 196,054
Cumulative Timesteps: 1,635,061,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.67309
Policy Entropy: 2.27250
Value Function Loss: 0.01520

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.56114

Collected Steps per Second: 23,704.25806
Overall Steps per Second: 10,895.02167

Timestep Collection Time: 2.11017
Timestep Consumption Time: 2.48092
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.59109

Cumulative Model Updates: 196,060
Cumulative Timesteps: 1,635,111,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1635111828...
Checkpoint 1635111828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.31484
Policy Entropy: 2.27608
Value Function Loss: 0.01479

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.53244
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 23,035.24545
Overall Steps per Second: 10,747.57304

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.65370

Cumulative Model Updates: 196,066
Cumulative Timesteps: 1,635,161,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.70869
Policy Entropy: 2.24435
Value Function Loss: 0.01529

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.54008

Collected Steps per Second: 23,630.74035
Overall Steps per Second: 10,922.64018

Timestep Collection Time: 2.11707
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.58021

Cumulative Model Updates: 196,072
Cumulative Timesteps: 1,635,211,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1635211872...
Checkpoint 1635211872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.68142
Policy Entropy: 2.23568
Value Function Loss: 0.01539

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.56088

Collected Steps per Second: 23,110.91748
Overall Steps per Second: 10,904.08400

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.58654

Cumulative Model Updates: 196,078
Cumulative Timesteps: 1,635,261,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.22110
Policy Entropy: 2.24870
Value Function Loss: 0.01487

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.55013
Value Function Update Magnitude: 0.57550

Collected Steps per Second: 23,686.49583
Overall Steps per Second: 10,890.62502

Timestep Collection Time: 2.11201
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.59349

Cumulative Model Updates: 196,084
Cumulative Timesteps: 1,635,311,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1635311910...
Checkpoint 1635311910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.91844
Policy Entropy: 2.26132
Value Function Loss: 0.01444

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.55257

Collected Steps per Second: 23,228.12643
Overall Steps per Second: 10,767.57299

Timestep Collection Time: 2.15385
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.64636

Cumulative Model Updates: 196,090
Cumulative Timesteps: 1,635,361,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.93459
Policy Entropy: 2.25887
Value Function Loss: 0.01463

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.53798
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 23,458.03782
Overall Steps per Second: 10,846.78668

Timestep Collection Time: 2.13223
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.61132

Cumulative Model Updates: 196,096
Cumulative Timesteps: 1,635,411,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1635411958...
Checkpoint 1635411958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.84288
Policy Entropy: 2.23046
Value Function Loss: 0.01543

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.54934

Collected Steps per Second: 22,785.36797
Overall Steps per Second: 11,018.08269

Timestep Collection Time: 2.19518
Timestep Consumption Time: 2.34445
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.53963

Cumulative Model Updates: 196,102
Cumulative Timesteps: 1,635,461,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.76902
Policy Entropy: 2.24042
Value Function Loss: 0.01560

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.54429

Collected Steps per Second: 23,664.00593
Overall Steps per Second: 10,938.05402

Timestep Collection Time: 2.11393
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.57339

Cumulative Model Updates: 196,108
Cumulative Timesteps: 1,635,512,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1635512000...
Checkpoint 1635512000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.19931
Policy Entropy: 2.23434
Value Function Loss: 0.01458

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.52851
Value Function Update Magnitude: 0.53584

Collected Steps per Second: 22,735.47375
Overall Steps per Second: 10,625.80325

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70628

Cumulative Model Updates: 196,114
Cumulative Timesteps: 1,635,562,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.12801
Policy Entropy: 2.25128
Value Function Loss: 0.01319

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.53101

Collected Steps per Second: 23,263.10109
Overall Steps per Second: 10,917.73928

Timestep Collection Time: 2.15001
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.58117

Cumulative Model Updates: 196,120
Cumulative Timesteps: 1,635,612,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1635612024...
Checkpoint 1635612024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.18879
Policy Entropy: 2.25683
Value Function Loss: 0.01282

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.51611
Value Function Update Magnitude: 0.52506

Collected Steps per Second: 23,049.48716
Overall Steps per Second: 11,065.31078

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.34957
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.51899

Cumulative Model Updates: 196,126
Cumulative Timesteps: 1,635,662,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.32768
Policy Entropy: 2.24394
Value Function Loss: 0.01412

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.52793
Value Function Update Magnitude: 0.53505

Collected Steps per Second: 23,481.14448
Overall Steps per Second: 10,927.49400

Timestep Collection Time: 2.12937
Timestep Consumption Time: 2.44625
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.57561

Cumulative Model Updates: 196,132
Cumulative Timesteps: 1,635,712,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1635712028...
Checkpoint 1635712028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.70313
Policy Entropy: 2.24594
Value Function Loss: 0.01476

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.53273

Collected Steps per Second: 23,160.52360
Overall Steps per Second: 10,755.97471

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.64914

Cumulative Model Updates: 196,138
Cumulative Timesteps: 1,635,762,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.29065
Policy Entropy: 2.24181
Value Function Loss: 0.01638

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.53949
Value Function Update Magnitude: 0.54417

Collected Steps per Second: 22,721.62124
Overall Steps per Second: 10,850.81995

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.40740
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.60795

Cumulative Model Updates: 196,144
Cumulative Timesteps: 1,635,812,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1635812034...
Checkpoint 1635812034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.21249
Policy Entropy: 2.27084
Value Function Loss: 0.01634

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.55356

Collected Steps per Second: 22,965.79715
Overall Steps per Second: 10,812.91984

Timestep Collection Time: 2.17741
Timestep Consumption Time: 2.44724
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.62465

Cumulative Model Updates: 196,150
Cumulative Timesteps: 1,635,862,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.43251
Policy Entropy: 2.26300
Value Function Loss: 0.01679

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.57862

Collected Steps per Second: 23,435.81253
Overall Steps per Second: 11,107.11763

Timestep Collection Time: 2.13383
Timestep Consumption Time: 2.36851
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.50234

Cumulative Model Updates: 196,156
Cumulative Timesteps: 1,635,912,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1635912048...
Checkpoint 1635912048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.90074
Policy Entropy: 2.24277
Value Function Loss: 0.01692

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.59002

Collected Steps per Second: 23,010.97096
Overall Steps per Second: 10,660.51645

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.69039

Cumulative Model Updates: 196,162
Cumulative Timesteps: 1,635,962,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.97268
Policy Entropy: 2.24681
Value Function Loss: 0.01653

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 23,282.05824
Overall Steps per Second: 10,933.83285

Timestep Collection Time: 2.14895
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.57589

Cumulative Model Updates: 196,168
Cumulative Timesteps: 1,636,012,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1636012082...
Checkpoint 1636012082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.46238
Policy Entropy: 2.22873
Value Function Loss: 0.01683

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.56010

Collected Steps per Second: 22,739.24436
Overall Steps per Second: 10,717.09707

Timestep Collection Time: 2.19990
Timestep Consumption Time: 2.46778
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.66768

Cumulative Model Updates: 196,174
Cumulative Timesteps: 1,636,062,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.85237
Policy Entropy: 2.24199
Value Function Loss: 0.01664

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.16848
Policy Update Magnitude: 0.52343
Value Function Update Magnitude: 0.57417

Collected Steps per Second: 23,562.60326
Overall Steps per Second: 11,036.85874

Timestep Collection Time: 2.12336
Timestep Consumption Time: 2.40981
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.53317

Cumulative Model Updates: 196,180
Cumulative Timesteps: 1,636,112,138

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1636112138...
Checkpoint 1636112138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.83378
Policy Entropy: 2.23442
Value Function Loss: 0.01626

Mean KL Divergence: 0.03066
SB3 Clip Fraction: 0.19742
Policy Update Magnitude: 0.51564
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 23,047.74052
Overall Steps per Second: 10,854.97121

Timestep Collection Time: 2.17071
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60895

Cumulative Model Updates: 196,186
Cumulative Timesteps: 1,636,162,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.36665
Policy Entropy: 2.27671
Value Function Loss: 0.01659

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.18374
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 23,305.17548
Overall Steps per Second: 10,937.68948

Timestep Collection Time: 2.14596
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.57245

Cumulative Model Updates: 196,192
Cumulative Timesteps: 1,636,212,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1636212180...
Checkpoint 1636212180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.24884
Policy Entropy: 2.31121
Value Function Loss: 0.01516

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 23,040.74240
Overall Steps per Second: 10,826.23831

Timestep Collection Time: 2.17120
Timestep Consumption Time: 2.44961
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.62081

Cumulative Model Updates: 196,198
Cumulative Timesteps: 1,636,262,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.22048
Policy Entropy: 2.31544
Value Function Loss: 0.01570

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.53544
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 23,490.23494
Overall Steps per Second: 11,144.32209

Timestep Collection Time: 2.12863
Timestep Consumption Time: 2.35814
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.48677

Cumulative Model Updates: 196,204
Cumulative Timesteps: 1,636,312,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1636312208...
Checkpoint 1636312208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.55606
Policy Entropy: 2.30561
Value Function Loss: 0.01554

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 23,247.93223
Overall Steps per Second: 10,716.22512

Timestep Collection Time: 2.15099
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.66638

Cumulative Model Updates: 196,210
Cumulative Timesteps: 1,636,362,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.29198
Policy Entropy: 2.30211
Value Function Loss: 0.01559

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.54272

Collected Steps per Second: 23,553.98207
Overall Steps per Second: 10,951.48012

Timestep Collection Time: 2.12346
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.56705

Cumulative Model Updates: 196,216
Cumulative Timesteps: 1,636,412,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1636412230...
Checkpoint 1636412230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448.81790
Policy Entropy: 2.27703
Value Function Loss: 0.01630

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 22,925.97592
Overall Steps per Second: 10,691.57020

Timestep Collection Time: 2.18154
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.67789

Cumulative Model Updates: 196,222
Cumulative Timesteps: 1,636,462,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.02973
Policy Entropy: 2.27205
Value Function Loss: 0.01569

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.58530

Collected Steps per Second: 23,417.20183
Overall Steps per Second: 11,000.08743

Timestep Collection Time: 2.13612
Timestep Consumption Time: 2.41130
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.54742

Cumulative Model Updates: 196,228
Cumulative Timesteps: 1,636,512,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1636512266...
Checkpoint 1636512266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.16119
Policy Entropy: 2.24647
Value Function Loss: 0.01598

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.56644

Collected Steps per Second: 22,441.81176
Overall Steps per Second: 10,911.74916

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.35565
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58497

Cumulative Model Updates: 196,234
Cumulative Timesteps: 1,636,562,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.98431
Policy Entropy: 2.25678
Value Function Loss: 0.01501

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.55133

Collected Steps per Second: 23,569.43964
Overall Steps per Second: 10,957.59330

Timestep Collection Time: 2.12182
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.56396

Cumulative Model Updates: 196,240
Cumulative Timesteps: 1,636,612,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1636612306...
Checkpoint 1636612306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.30362
Policy Entropy: 2.22112
Value Function Loss: 0.01513

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.54731

Collected Steps per Second: 22,867.84353
Overall Steps per Second: 10,650.27255

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69697

Cumulative Model Updates: 196,246
Cumulative Timesteps: 1,636,662,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.11841
Policy Entropy: 2.23548
Value Function Loss: 0.01534

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.55185

Collected Steps per Second: 23,380.59139
Overall Steps per Second: 10,908.05906

Timestep Collection Time: 2.13938
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.58560

Cumulative Model Updates: 196,252
Cumulative Timesteps: 1,636,712,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1636712350...
Checkpoint 1636712350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.71702
Policy Entropy: 2.23530
Value Function Loss: 0.01596

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.55129

Collected Steps per Second: 23,907.66308
Overall Steps per Second: 11,076.25234

Timestep Collection Time: 2.09222
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.51597

Cumulative Model Updates: 196,258
Cumulative Timesteps: 1,636,762,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.37159
Policy Entropy: 2.26322
Value Function Loss: 0.01609

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.56853

Collected Steps per Second: 23,483.04132
Overall Steps per Second: 10,942.55228

Timestep Collection Time: 2.12920
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.56932

Cumulative Model Updates: 196,264
Cumulative Timesteps: 1,636,812,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1636812370...
Checkpoint 1636812370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.67254
Policy Entropy: 2.27183
Value Function Loss: 0.01586

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.56762

Collected Steps per Second: 22,769.12860
Overall Steps per Second: 10,630.85446

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.70329

Cumulative Model Updates: 196,270
Cumulative Timesteps: 1,636,862,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.87473
Policy Entropy: 2.26917
Value Function Loss: 0.01700

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 23,465.35574
Overall Steps per Second: 10,875.80798

Timestep Collection Time: 2.13199
Timestep Consumption Time: 2.46794
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.59993

Cumulative Model Updates: 196,276
Cumulative Timesteps: 1,636,912,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1636912398...
Checkpoint 1636912398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.28663
Policy Entropy: 2.26087
Value Function Loss: 0.01665

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 22,987.36793
Overall Steps per Second: 11,043.76275

Timestep Collection Time: 2.17598
Timestep Consumption Time: 2.35328
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.52925

Cumulative Model Updates: 196,282
Cumulative Timesteps: 1,636,962,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.84204
Policy Entropy: 2.26538
Value Function Loss: 0.01638

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 23,583.25249
Overall Steps per Second: 10,977.25597

Timestep Collection Time: 2.12142
Timestep Consumption Time: 2.43618
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.55761

Cumulative Model Updates: 196,288
Cumulative Timesteps: 1,637,012,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1637012448...
Checkpoint 1637012448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.59308
Policy Entropy: 2.26055
Value Function Loss: 0.01560

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 22,748.91086
Overall Steps per Second: 10,682.34384

Timestep Collection Time: 2.19887
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.68268

Cumulative Model Updates: 196,294
Cumulative Timesteps: 1,637,062,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.05173
Policy Entropy: 2.25132
Value Function Loss: 0.01565

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 23,309.78435
Overall Steps per Second: 10,905.91592

Timestep Collection Time: 2.14605
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.58687

Cumulative Model Updates: 196,300
Cumulative Timesteps: 1,637,112,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1637112494...
Checkpoint 1637112494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.67516
Policy Entropy: 2.23882
Value Function Loss: 0.01608

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.60061

Collected Steps per Second: 22,951.11811
Overall Steps per Second: 10,759.26660

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.64716

Cumulative Model Updates: 196,306
Cumulative Timesteps: 1,637,162,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.91187
Policy Entropy: 2.24643
Value Function Loss: 0.01526

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.18860
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 23,168.42908
Overall Steps per Second: 10,977.99760

Timestep Collection Time: 2.15845
Timestep Consumption Time: 2.39684
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.55529

Cumulative Model Updates: 196,312
Cumulative Timesteps: 1,637,212,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1637212502...
Checkpoint 1637212502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.37120
Policy Entropy: 2.27800
Value Function Loss: 0.01563

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.16793
Policy Update Magnitude: 0.54611
Value Function Update Magnitude: 0.58694

Collected Steps per Second: 23,123.87187
Overall Steps per Second: 10,877.93672

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.43468
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59738

Cumulative Model Updates: 196,318
Cumulative Timesteps: 1,637,262,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.95641
Policy Entropy: 2.31428
Value Function Loss: 0.01536

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15441
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.57326

Collected Steps per Second: 23,347.31330
Overall Steps per Second: 10,918.30877

Timestep Collection Time: 2.14166
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.57965

Cumulative Model Updates: 196,324
Cumulative Timesteps: 1,637,312,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1637312514...
Checkpoint 1637312514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.69477
Policy Entropy: 2.31093
Value Function Loss: 0.01596

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.56444

Collected Steps per Second: 23,216.39989
Overall Steps per Second: 10,760.53702

Timestep Collection Time: 2.15399
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.64735

Cumulative Model Updates: 196,330
Cumulative Timesteps: 1,637,362,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.69504
Policy Entropy: 2.27627
Value Function Loss: 0.01507

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 22,649.53239
Overall Steps per Second: 10,829.79451

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.61745

Cumulative Model Updates: 196,336
Cumulative Timesteps: 1,637,412,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1637412528...
Checkpoint 1637412528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.20478
Policy Entropy: 2.26260
Value Function Loss: 0.01467

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 22,900.56864
Overall Steps per Second: 10,991.29642

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.36599
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.54960

Cumulative Model Updates: 196,342
Cumulative Timesteps: 1,637,462,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.87942
Policy Entropy: 2.26332
Value Function Loss: 0.01411

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.57452

Collected Steps per Second: 23,735.66571
Overall Steps per Second: 10,958.30279

Timestep Collection Time: 2.10687
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.56348

Cumulative Model Updates: 196,348
Cumulative Timesteps: 1,637,512,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1637512542...
Checkpoint 1637512542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.69834
Policy Entropy: 2.27621
Value Function Loss: 0.01470

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.55920

Collected Steps per Second: 22,952.83216
Overall Steps per Second: 10,684.15911

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.68188

Cumulative Model Updates: 196,354
Cumulative Timesteps: 1,637,562,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.71504
Policy Entropy: 2.28018
Value Function Loss: 0.01512

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.56734

Collected Steps per Second: 23,505.57743
Overall Steps per Second: 10,884.99689

Timestep Collection Time: 2.12852
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.59642

Cumulative Model Updates: 196,360
Cumulative Timesteps: 1,637,612,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1637612596...
Checkpoint 1637612596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.45425
Policy Entropy: 2.27376
Value Function Loss: 0.01540

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.58103

Collected Steps per Second: 22,698.81514
Overall Steps per Second: 10,706.74012

Timestep Collection Time: 2.20320
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.67089

Cumulative Model Updates: 196,366
Cumulative Timesteps: 1,637,662,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.08441
Policy Entropy: 2.25629
Value Function Loss: 0.01585

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.56378
Value Function Update Magnitude: 0.60732

Collected Steps per Second: 23,594.81065
Overall Steps per Second: 11,051.12720

Timestep Collection Time: 2.12038
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.52714

Cumulative Model Updates: 196,372
Cumulative Timesteps: 1,637,712,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1637712636...
Checkpoint 1637712636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.73857
Policy Entropy: 2.26602
Value Function Loss: 0.01507

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 23,248.52939
Overall Steps per Second: 10,965.87743

Timestep Collection Time: 2.15205
Timestep Consumption Time: 2.41047
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.56252

Cumulative Model Updates: 196,378
Cumulative Timesteps: 1,637,762,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.01342
Policy Entropy: 2.26660
Value Function Loss: 0.01493

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 23,173.77995
Overall Steps per Second: 10,955.81296

Timestep Collection Time: 2.15778
Timestep Consumption Time: 2.40637
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.56415

Cumulative Model Updates: 196,384
Cumulative Timesteps: 1,637,812,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1637812672...
Checkpoint 1637812672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.55015
Policy Entropy: 2.28151
Value Function Loss: 0.01490

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.16460
Policy Update Magnitude: 0.52308
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 23,049.22889
Overall Steps per Second: 10,933.73656

Timestep Collection Time: 2.17066
Timestep Consumption Time: 2.40527
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.57593

Cumulative Model Updates: 196,390
Cumulative Timesteps: 1,637,862,704

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.83206
Policy Entropy: 2.29033
Value Function Loss: 0.01525

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.17253
Policy Update Magnitude: 0.51634
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 23,347.30309
Overall Steps per Second: 10,969.95878

Timestep Collection Time: 2.14175
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.55827

Cumulative Model Updates: 196,396
Cumulative Timesteps: 1,637,912,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1637912708...
Checkpoint 1637912708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.57979
Policy Entropy: 2.28731
Value Function Loss: 0.01490

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.16387
Policy Update Magnitude: 0.52729
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 22,991.10183
Overall Steps per Second: 11,050.28911

Timestep Collection Time: 2.17658
Timestep Consumption Time: 2.35199
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.52857

Cumulative Model Updates: 196,402
Cumulative Timesteps: 1,637,962,750

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.93569
Policy Entropy: 2.25997
Value Function Loss: 0.01491

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.53009
Value Function Update Magnitude: 0.52356

Collected Steps per Second: 23,347.54671
Overall Steps per Second: 10,963.07737

Timestep Collection Time: 2.14207
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.56186

Cumulative Model Updates: 196,408
Cumulative Timesteps: 1,638,012,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1638012762...
Checkpoint 1638012762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.30649
Policy Entropy: 2.22952
Value Function Loss: 0.01552

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.51966

Collected Steps per Second: 22,649.26700
Overall Steps per Second: 10,707.81766

Timestep Collection Time: 2.20872
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.67191

Cumulative Model Updates: 196,414
Cumulative Timesteps: 1,638,062,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.84434
Policy Entropy: 2.26257
Value Function Loss: 0.01514

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 23,271.14881
Overall Steps per Second: 10,895.68534

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.58971

Cumulative Model Updates: 196,420
Cumulative Timesteps: 1,638,112,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1638112796...
Checkpoint 1638112796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.66122
Policy Entropy: 2.28335
Value Function Loss: 0.01604

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.53723

Collected Steps per Second: 23,008.66708
Overall Steps per Second: 11,020.67074

Timestep Collection Time: 2.17362
Timestep Consumption Time: 2.36440
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.53802

Cumulative Model Updates: 196,426
Cumulative Timesteps: 1,638,162,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.36585
Policy Entropy: 2.28271
Value Function Loss: 0.01603

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.56087

Collected Steps per Second: 23,821.26495
Overall Steps per Second: 10,997.79679

Timestep Collection Time: 2.09905
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.54655

Cumulative Model Updates: 196,432
Cumulative Timesteps: 1,638,212,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1638212810...
Checkpoint 1638212810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.40605
Policy Entropy: 2.25795
Value Function Loss: 0.01721

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.59694

Collected Steps per Second: 23,110.09640
Overall Steps per Second: 10,764.42809

Timestep Collection Time: 2.16390
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64567

Cumulative Model Updates: 196,438
Cumulative Timesteps: 1,638,262,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.89742
Policy Entropy: 2.23869
Value Function Loss: 0.01585

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.59201

Collected Steps per Second: 23,520.38174
Overall Steps per Second: 10,756.26224

Timestep Collection Time: 2.12624
Timestep Consumption Time: 2.52314
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.64938

Cumulative Model Updates: 196,444
Cumulative Timesteps: 1,638,312,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1638312828...
Checkpoint 1638312828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.96362
Policy Entropy: 2.24955
Value Function Loss: 0.01563

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.56380

Collected Steps per Second: 23,106.03699
Overall Steps per Second: 10,849.94002

Timestep Collection Time: 2.16524
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.61109

Cumulative Model Updates: 196,450
Cumulative Timesteps: 1,638,362,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.22364
Policy Entropy: 2.22672
Value Function Loss: 0.01587

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.55433

Collected Steps per Second: 23,543.40593
Overall Steps per Second: 10,922.17802

Timestep Collection Time: 2.12425
Timestep Consumption Time: 2.45469
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.57894

Cumulative Model Updates: 196,456
Cumulative Timesteps: 1,638,412,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1638412870...
Checkpoint 1638412870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.92046
Policy Entropy: 2.23141
Value Function Loss: 0.01588

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.56610

Collected Steps per Second: 23,188.71009
Overall Steps per Second: 10,928.49482

Timestep Collection Time: 2.15657
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.57593

Cumulative Model Updates: 196,462
Cumulative Timesteps: 1,638,462,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.89814
Policy Entropy: 2.22740
Value Function Loss: 0.01545

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 23,070.97350
Overall Steps per Second: 10,857.10884

Timestep Collection Time: 2.16809
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60712

Cumulative Model Updates: 196,468
Cumulative Timesteps: 1,638,512,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1638512898...
Checkpoint 1638512898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.73243
Policy Entropy: 2.27597
Value Function Loss: 0.01456

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.58367

Collected Steps per Second: 22,992.77962
Overall Steps per Second: 10,693.16438

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.50199
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.67719

Cumulative Model Updates: 196,474
Cumulative Timesteps: 1,638,562,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.36717
Policy Entropy: 2.26294
Value Function Loss: 0.01527

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.57097

Collected Steps per Second: 23,313.97867
Overall Steps per Second: 10,954.15961

Timestep Collection Time: 2.14515
Timestep Consumption Time: 2.42042
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.56557

Cumulative Model Updates: 196,480
Cumulative Timesteps: 1,638,612,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1638612924...
Checkpoint 1638612924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.27402
Policy Entropy: 2.27189
Value Function Loss: 0.01492

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.58536

Collected Steps per Second: 23,016.39163
Overall Steps per Second: 10,795.15992

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.46013
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.63319

Cumulative Model Updates: 196,486
Cumulative Timesteps: 1,638,662,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.76259
Policy Entropy: 2.25358
Value Function Loss: 0.01536

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 23,522.50804
Overall Steps per Second: 11,132.38170

Timestep Collection Time: 2.12673
Timestep Consumption Time: 2.36701
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.49374

Cumulative Model Updates: 196,492
Cumulative Timesteps: 1,638,712,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1638712966...
Checkpoint 1638712966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.87518
Policy Entropy: 2.26957
Value Function Loss: 0.01526

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.54178
Value Function Update Magnitude: 0.56108

Collected Steps per Second: 23,202.04876
Overall Steps per Second: 10,712.83935

Timestep Collection Time: 2.15628
Timestep Consumption Time: 2.51382
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.67010

Cumulative Model Updates: 196,498
Cumulative Timesteps: 1,638,762,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.59157
Policy Entropy: 2.25429
Value Function Loss: 0.01574

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.57222

Collected Steps per Second: 23,396.61885
Overall Steps per Second: 10,935.67360

Timestep Collection Time: 2.13817
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.57457

Cumulative Model Updates: 196,504
Cumulative Timesteps: 1,638,813,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1638813022...
Checkpoint 1638813022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428.22274
Policy Entropy: 2.26590
Value Function Loss: 0.01548

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.58301

Collected Steps per Second: 23,128.29756
Overall Steps per Second: 10,779.80037

Timestep Collection Time: 2.16315
Timestep Consumption Time: 2.47794
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.64109

Cumulative Model Updates: 196,510
Cumulative Timesteps: 1,638,863,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.68223
Policy Entropy: 2.26853
Value Function Loss: 0.01526

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 23,319.95307
Overall Steps per Second: 10,814.51989

Timestep Collection Time: 2.14537
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.62619

Cumulative Model Updates: 196,516
Cumulative Timesteps: 1,638,913,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1638913082...
Checkpoint 1638913082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.35213
Policy Entropy: 2.29304
Value Function Loss: 0.01551

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.59288

Collected Steps per Second: 23,288.84612
Overall Steps per Second: 11,012.74408

Timestep Collection Time: 2.14815
Timestep Consumption Time: 2.39458
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.54274

Cumulative Model Updates: 196,522
Cumulative Timesteps: 1,638,963,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.23482
Policy Entropy: 2.28448
Value Function Loss: 0.01451

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.59852

Collected Steps per Second: 23,443.69500
Overall Steps per Second: 10,906.07615

Timestep Collection Time: 2.13277
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.58460

Cumulative Model Updates: 196,528
Cumulative Timesteps: 1,639,013,110

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1639013110...
Checkpoint 1639013110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.15783
Policy Entropy: 2.29750
Value Function Loss: 0.01362

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.56374

Collected Steps per Second: 23,096.23766
Overall Steps per Second: 10,770.22388

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.64429

Cumulative Model Updates: 196,534
Cumulative Timesteps: 1,639,063,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.12131
Policy Entropy: 2.30425
Value Function Loss: 0.01404

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.53045
Value Function Update Magnitude: 0.56439

Collected Steps per Second: 23,367.42535
Overall Steps per Second: 10,763.47853

Timestep Collection Time: 2.13982
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.64552

Cumulative Model Updates: 196,540
Cumulative Timesteps: 1,639,113,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1639113132...
Checkpoint 1639113132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.30909
Policy Entropy: 2.29044
Value Function Loss: 0.01422

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 22,931.14705
Overall Steps per Second: 10,754.82279

Timestep Collection Time: 2.18131
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.65094

Cumulative Model Updates: 196,546
Cumulative Timesteps: 1,639,163,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.38883
Policy Entropy: 2.27962
Value Function Loss: 0.01532

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.57743

Collected Steps per Second: 23,352.04959
Overall Steps per Second: 11,030.10176

Timestep Collection Time: 2.14174
Timestep Consumption Time: 2.39258
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.53432

Cumulative Model Updates: 196,552
Cumulative Timesteps: 1,639,213,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1639213166...
Checkpoint 1639213166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.79812
Policy Entropy: 2.28879
Value Function Loss: 0.01556

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.59292

Collected Steps per Second: 23,061.13783
Overall Steps per Second: 10,909.99667

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.58479

Cumulative Model Updates: 196,558
Cumulative Timesteps: 1,639,263,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.58562
Policy Entropy: 2.29317
Value Function Loss: 0.01598

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.60933

Collected Steps per Second: 23,611.61183
Overall Steps per Second: 10,903.12005

Timestep Collection Time: 2.11862
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.58804

Cumulative Model Updates: 196,564
Cumulative Timesteps: 1,639,313,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1639313210...
Checkpoint 1639313210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.35790
Policy Entropy: 2.27659
Value Function Loss: 0.01543

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.60382

Collected Steps per Second: 22,972.96466
Overall Steps per Second: 10,716.32626

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.66839

Cumulative Model Updates: 196,570
Cumulative Timesteps: 1,639,363,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.32359
Policy Entropy: 2.25933
Value Function Loss: 0.01585

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.58814

Collected Steps per Second: 23,466.46734
Overall Steps per Second: 10,792.14788

Timestep Collection Time: 2.13096
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.63355

Cumulative Model Updates: 196,576
Cumulative Timesteps: 1,639,413,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1639413244...
Checkpoint 1639413244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.67958
Policy Entropy: 2.24467
Value Function Loss: 0.01651

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 23,076.98660
Overall Steps per Second: 11,076.80058

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.34840
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.51611

Cumulative Model Updates: 196,582
Cumulative Timesteps: 1,639,463,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.24651
Policy Entropy: 2.24951
Value Function Loss: 0.01692

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.58218

Collected Steps per Second: 23,506.43829
Overall Steps per Second: 10,987.04931

Timestep Collection Time: 2.12818
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.55318

Cumulative Model Updates: 196,588
Cumulative Timesteps: 1,639,513,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1639513294...
Checkpoint 1639513294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.36371
Policy Entropy: 2.23167
Value Function Loss: 0.01668

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.55655
Value Function Update Magnitude: 0.57928

Collected Steps per Second: 23,048.39208
Overall Steps per Second: 10,733.57118

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.65847

Cumulative Model Updates: 196,594
Cumulative Timesteps: 1,639,563,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.73330
Policy Entropy: 2.23400
Value Function Loss: 0.01559

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 23,566.10888
Overall Steps per Second: 10,802.26417

Timestep Collection Time: 2.12288
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.63125

Cumulative Model Updates: 196,600
Cumulative Timesteps: 1,639,613,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1639613324...
Checkpoint 1639613324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.11402
Policy Entropy: 2.23451
Value Function Loss: 0.01483

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.54997
Value Function Update Magnitude: 0.57011

Collected Steps per Second: 22,898.31673
Overall Steps per Second: 10,764.88937

Timestep Collection Time: 2.18496
Timestep Consumption Time: 2.46274
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.64770

Cumulative Model Updates: 196,606
Cumulative Timesteps: 1,639,663,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.25099
Policy Entropy: 2.23098
Value Function Loss: 0.01422

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 23,393.50486
Overall Steps per Second: 11,028.74647

Timestep Collection Time: 2.13735
Timestep Consumption Time: 2.39626
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.53361

Cumulative Model Updates: 196,612
Cumulative Timesteps: 1,639,713,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1639713356...
Checkpoint 1639713356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.41465
Policy Entropy: 2.24367
Value Function Loss: 0.01463

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.56282

Collected Steps per Second: 23,113.94766
Overall Steps per Second: 10,825.22158

Timestep Collection Time: 2.16432
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.62124

Cumulative Model Updates: 196,618
Cumulative Timesteps: 1,639,763,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.47022
Policy Entropy: 2.25343
Value Function Loss: 0.01479

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.57081

Collected Steps per Second: 23,133.90473
Overall Steps per Second: 10,892.30171

Timestep Collection Time: 2.16133
Timestep Consumption Time: 2.42907
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59040

Cumulative Model Updates: 196,624
Cumulative Timesteps: 1,639,813,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1639813382...
Checkpoint 1639813382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.88747
Policy Entropy: 2.27900
Value Function Loss: 0.01532

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.58842

Collected Steps per Second: 22,905.31184
Overall Steps per Second: 10,772.42992

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.64296

Cumulative Model Updates: 196,630
Cumulative Timesteps: 1,639,863,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.08971
Policy Entropy: 2.26261
Value Function Loss: 0.01483

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.53695
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 23,300.76606
Overall Steps per Second: 10,808.10628

Timestep Collection Time: 2.14637
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.62727

Cumulative Model Updates: 196,636
Cumulative Timesteps: 1,639,913,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1639913410...
Checkpoint 1639913410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.28534
Policy Entropy: 2.25578
Value Function Loss: 0.01497

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14872
Policy Update Magnitude: 0.51795
Value Function Update Magnitude: 0.53786

Collected Steps per Second: 23,160.79089
Overall Steps per Second: 11,068.00739

Timestep Collection Time: 2.15960
Timestep Consumption Time: 2.35955
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.51915

Cumulative Model Updates: 196,642
Cumulative Timesteps: 1,639,963,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.71816
Policy Entropy: 2.25326
Value Function Loss: 0.01603

Mean KL Divergence: 0.03167
SB3 Clip Fraction: 0.18380
Policy Update Magnitude: 0.51757
Value Function Update Magnitude: 0.53657

Collected Steps per Second: 23,567.13212
Overall Steps per Second: 10,965.81076

Timestep Collection Time: 2.12262
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.56182

Cumulative Model Updates: 196,648
Cumulative Timesteps: 1,640,013,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1640013452...
Checkpoint 1640013452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.35850
Policy Entropy: 2.26045
Value Function Loss: 0.01687

Mean KL Divergence: 0.02792
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.55593

Collected Steps per Second: 23,025.44385
Overall Steps per Second: 10,720.93300

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.66377

Cumulative Model Updates: 196,654
Cumulative Timesteps: 1,640,063,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.90185
Policy Entropy: 2.25769
Value Function Loss: 0.01666

Mean KL Divergence: 0.02561
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 23,485.16264
Overall Steps per Second: 10,775.27807

Timestep Collection Time: 2.13003
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.64248

Cumulative Model Updates: 196,660
Cumulative Timesteps: 1,640,113,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1640113476...
Checkpoint 1640113476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.76377
Policy Entropy: 2.26640
Value Function Loss: 0.01585

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,986.25066
Overall Steps per Second: 10,744.09586

Timestep Collection Time: 2.17643
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.65632

Cumulative Model Updates: 196,666
Cumulative Timesteps: 1,640,163,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.62363
Policy Entropy: 2.28388
Value Function Loss: 0.01525

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.57393

Collected Steps per Second: 23,371.10717
Overall Steps per Second: 10,999.21665

Timestep Collection Time: 2.13948
Timestep Consumption Time: 2.40648
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.54596

Cumulative Model Updates: 196,672
Cumulative Timesteps: 1,640,213,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1640213506...
Checkpoint 1640213506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.77139
Policy Entropy: 2.28387
Value Function Loss: 0.01485

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 23,237.57092
Overall Steps per Second: 10,944.52919

Timestep Collection Time: 2.15246
Timestep Consumption Time: 2.41767
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.57014

Cumulative Model Updates: 196,678
Cumulative Timesteps: 1,640,263,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.34047
Policy Entropy: 2.27842
Value Function Loss: 0.01390

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.53650
Value Function Update Magnitude: 0.56925

Collected Steps per Second: 23,298.00560
Overall Steps per Second: 10,950.38701

Timestep Collection Time: 2.14679
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.56751

Cumulative Model Updates: 196,684
Cumulative Timesteps: 1,640,313,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1640313540...
Checkpoint 1640313540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.90477
Policy Entropy: 2.25704
Value Function Loss: 0.01319

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.53920
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 23,224.42280
Overall Steps per Second: 10,808.58799

Timestep Collection Time: 2.15325
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.62669

Cumulative Model Updates: 196,690
Cumulative Timesteps: 1,640,363,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.93849
Policy Entropy: 2.25602
Value Function Loss: 0.01449

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.54002

Collected Steps per Second: 23,540.94341
Overall Steps per Second: 10,935.77311

Timestep Collection Time: 2.12489
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.57416

Cumulative Model Updates: 196,696
Cumulative Timesteps: 1,640,413,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1640413570...
Checkpoint 1640413570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452.59533
Policy Entropy: 2.22905
Value Function Loss: 0.01536

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.55193
Value Function Update Magnitude: 0.54828

Collected Steps per Second: 22,686.20093
Overall Steps per Second: 10,877.78355

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.39359
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.59855

Cumulative Model Updates: 196,702
Cumulative Timesteps: 1,640,463,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.80041
Policy Entropy: 2.24052
Value Function Loss: 0.01504

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.55005
Value Function Update Magnitude: 0.54403

Collected Steps per Second: 23,823.25475
Overall Steps per Second: 10,890.05770

Timestep Collection Time: 2.09988
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.59373

Cumulative Model Updates: 196,708
Cumulative Timesteps: 1,640,513,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1640513618...
Checkpoint 1640513618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.38479
Policy Entropy: 2.24558
Value Function Loss: 0.01452

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.54307
Value Function Update Magnitude: 0.55036

Collected Steps per Second: 23,073.54109
Overall Steps per Second: 10,720.12402

Timestep Collection Time: 2.16759
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66543

Cumulative Model Updates: 196,714
Cumulative Timesteps: 1,640,563,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.95023
Policy Entropy: 2.26384
Value Function Loss: 0.01472

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.53549
Value Function Update Magnitude: 0.54670

Collected Steps per Second: 23,433.60817
Overall Steps per Second: 10,833.28438

Timestep Collection Time: 2.13488
Timestep Consumption Time: 2.48311
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.61799

Cumulative Model Updates: 196,720
Cumulative Timesteps: 1,640,613,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1640613660...
Checkpoint 1640613660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.37679
Policy Entropy: 2.24692
Value Function Loss: 0.01465

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.54049

Collected Steps per Second: 22,988.96740
Overall Steps per Second: 10,787.03339

Timestep Collection Time: 2.17609
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.63760

Cumulative Model Updates: 196,726
Cumulative Timesteps: 1,640,663,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.35238
Policy Entropy: 2.26050
Value Function Loss: 0.01441

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.53560

Collected Steps per Second: 23,600.46078
Overall Steps per Second: 11,176.09109

Timestep Collection Time: 2.11937
Timestep Consumption Time: 2.35608
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.47545

Cumulative Model Updates: 196,732
Cumulative Timesteps: 1,640,713,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1640713704...
Checkpoint 1640713704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.49801
Policy Entropy: 2.27028
Value Function Loss: 0.01386

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 22,875.41935
Overall Steps per Second: 10,735.19906

Timestep Collection Time: 2.18610
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.65832

Cumulative Model Updates: 196,738
Cumulative Timesteps: 1,640,763,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.41777
Policy Entropy: 2.27942
Value Function Loss: 0.01454

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.53226
Value Function Update Magnitude: 0.54752

Collected Steps per Second: 23,452.80111
Overall Steps per Second: 10,902.66327

Timestep Collection Time: 2.13271
Timestep Consumption Time: 2.45498
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.58769

Cumulative Model Updates: 196,744
Cumulative Timesteps: 1,640,813,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1640813730...
Checkpoint 1640813730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.35992
Policy Entropy: 2.27684
Value Function Loss: 0.01538

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.56085

Collected Steps per Second: 23,026.84523
Overall Steps per Second: 10,705.19102

Timestep Collection Time: 2.17147
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.67082

Cumulative Model Updates: 196,750
Cumulative Timesteps: 1,640,863,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.22260
Policy Entropy: 2.26155
Value Function Loss: 0.01675

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.56753

Collected Steps per Second: 23,555.85908
Overall Steps per Second: 10,873.01167

Timestep Collection Time: 2.12338
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.60020

Cumulative Model Updates: 196,756
Cumulative Timesteps: 1,640,913,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1640913750...
Checkpoint 1640913750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.50184
Policy Entropy: 2.27748
Value Function Loss: 0.01654

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.54966
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 23,205.92433
Overall Steps per Second: 10,989.28569

Timestep Collection Time: 2.15583
Timestep Consumption Time: 2.39661
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.55243

Cumulative Model Updates: 196,762
Cumulative Timesteps: 1,640,963,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.46928
Policy Entropy: 2.26549
Value Function Loss: 0.01635

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 23,180.60705
Overall Steps per Second: 10,939.94966

Timestep Collection Time: 2.15836
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.57333

Cumulative Model Updates: 196,768
Cumulative Timesteps: 1,641,013,810

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1641013810...
Checkpoint 1641013810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.25827
Policy Entropy: 2.28661
Value Function Loss: 0.01542

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.58747

Collected Steps per Second: 22,946.04670
Overall Steps per Second: 10,940.91856

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.39193
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.57183

Cumulative Model Updates: 196,774
Cumulative Timesteps: 1,641,063,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.13098
Policy Entropy: 2.28321
Value Function Loss: 0.01445

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.18222
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 23,391.41252
Overall Steps per Second: 10,829.58609

Timestep Collection Time: 2.13848
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.61901

Cumulative Model Updates: 196,780
Cumulative Timesteps: 1,641,113,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1641113852...
Checkpoint 1641113852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.71627
Policy Entropy: 2.29940
Value Function Loss: 0.01376

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.17376
Policy Update Magnitude: 0.52195
Value Function Update Magnitude: 0.55861

Collected Steps per Second: 23,274.06039
Overall Steps per Second: 10,929.75035

Timestep Collection Time: 2.14900
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.57613

Cumulative Model Updates: 196,786
Cumulative Timesteps: 1,641,163,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.20968
Policy Entropy: 2.28163
Value Function Loss: 0.01291

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.51671
Value Function Update Magnitude: 0.53316

Collected Steps per Second: 23,491.53167
Overall Steps per Second: 10,969.08181

Timestep Collection Time: 2.12851
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.55845

Cumulative Model Updates: 196,792
Cumulative Timesteps: 1,641,213,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1641213870...
Checkpoint 1641213870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.17668
Policy Entropy: 2.26748
Value Function Loss: 0.01431

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.52000

Collected Steps per Second: 23,092.40790
Overall Steps per Second: 10,847.90967

Timestep Collection Time: 2.16634
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.61158

Cumulative Model Updates: 196,798
Cumulative Timesteps: 1,641,263,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.20540
Policy Entropy: 2.25814
Value Function Loss: 0.01415

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.54188

Collected Steps per Second: 23,453.23501
Overall Steps per Second: 10,879.30534

Timestep Collection Time: 2.13318
Timestep Consumption Time: 2.46546
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.59864

Cumulative Model Updates: 196,804
Cumulative Timesteps: 1,641,313,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1641313926...
Checkpoint 1641313926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.54721
Policy Entropy: 2.29035
Value Function Loss: 0.01472

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.55302

Collected Steps per Second: 23,352.61861
Overall Steps per Second: 10,957.00902

Timestep Collection Time: 2.14186
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.56493

Cumulative Model Updates: 196,810
Cumulative Timesteps: 1,641,363,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.86868
Policy Entropy: 2.29006
Value Function Loss: 0.01467

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.53642
Value Function Update Magnitude: 0.56139

Collected Steps per Second: 22,915.07464
Overall Steps per Second: 10,874.13275

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.59862

Cumulative Model Updates: 196,816
Cumulative Timesteps: 1,641,413,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1641413950...
Checkpoint 1641413950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.11957
Policy Entropy: 2.27776
Value Function Loss: 0.01443

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.55291

Collected Steps per Second: 22,863.03201
Overall Steps per Second: 10,666.55132

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.68868

Cumulative Model Updates: 196,822
Cumulative Timesteps: 1,641,463,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.57993
Policy Entropy: 2.28406
Value Function Loss: 0.01477

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.53445
Value Function Update Magnitude: 0.52623

Collected Steps per Second: 23,306.18767
Overall Steps per Second: 10,854.47216

Timestep Collection Time: 2.14587
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.60750

Cumulative Model Updates: 196,828
Cumulative Timesteps: 1,641,513,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1641513974...
Checkpoint 1641513974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.00048
Policy Entropy: 2.29175
Value Function Loss: 0.01379

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.50608

Collected Steps per Second: 23,098.26267
Overall Steps per Second: 11,070.65792

Timestep Collection Time: 2.16510
Timestep Consumption Time: 2.35225
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.51735

Cumulative Model Updates: 196,834
Cumulative Timesteps: 1,641,563,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.39703
Policy Entropy: 2.31681
Value Function Loss: 0.01375

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.51512
Value Function Update Magnitude: 0.49618

Collected Steps per Second: 23,517.45371
Overall Steps per Second: 10,996.26277

Timestep Collection Time: 2.12685
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.54864

Cumulative Model Updates: 196,840
Cumulative Timesteps: 1,641,614,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1641614002...
Checkpoint 1641614002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.69289
Policy Entropy: 2.31550
Value Function Loss: 0.01282

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.51093
Value Function Update Magnitude: 0.48353

Collected Steps per Second: 23,154.75261
Overall Steps per Second: 10,793.14133

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63257

Cumulative Model Updates: 196,846
Cumulative Timesteps: 1,641,664,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.90037
Policy Entropy: 2.28811
Value Function Loss: 0.01365

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.50230

Collected Steps per Second: 23,414.25440
Overall Steps per Second: 10,767.51400

Timestep Collection Time: 2.13545
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.64360

Cumulative Model Updates: 196,852
Cumulative Timesteps: 1,641,714,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1641714002...
Checkpoint 1641714002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.73772
Policy Entropy: 2.26541
Value Function Loss: 0.01430

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.52597
Value Function Update Magnitude: 0.52439

Collected Steps per Second: 22,807.28845
Overall Steps per Second: 10,761.27685

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.45460
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.64740

Cumulative Model Updates: 196,858
Cumulative Timesteps: 1,641,764,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.37816
Policy Entropy: 2.24354
Value Function Loss: 0.01489

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.53353

Collected Steps per Second: 23,419.39132
Overall Steps per Second: 11,134.79408

Timestep Collection Time: 2.13498
Timestep Consumption Time: 2.35545
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.49043

Cumulative Model Updates: 196,864
Cumulative Timesteps: 1,641,814,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1641814014...
Checkpoint 1641814014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.74761
Policy Entropy: 2.25596
Value Function Loss: 0.01516

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.53098

Collected Steps per Second: 22,978.06851
Overall Steps per Second: 10,684.69408

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.68034

Cumulative Model Updates: 196,870
Cumulative Timesteps: 1,641,864,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.42982
Policy Entropy: 2.25294
Value Function Loss: 0.01501

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.52622

Collected Steps per Second: 23,264.56509
Overall Steps per Second: 10,913.08597

Timestep Collection Time: 2.14962
Timestep Consumption Time: 2.43295
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.58257

Cumulative Model Updates: 196,876
Cumulative Timesteps: 1,641,914,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1641914032...
Checkpoint 1641914032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.95395
Policy Entropy: 2.26126
Value Function Loss: 0.01487

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 23,087.76272
Overall Steps per Second: 10,832.60949

Timestep Collection Time: 2.16591
Timestep Consumption Time: 2.45034
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.61625

Cumulative Model Updates: 196,882
Cumulative Timesteps: 1,641,964,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.01452
Policy Entropy: 2.24822
Value Function Loss: 0.01497

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.52744
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 23,483.75378
Overall Steps per Second: 11,166.22271

Timestep Collection Time: 2.12939
Timestep Consumption Time: 2.34894
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.47833

Cumulative Model Updates: 196,888
Cumulative Timesteps: 1,642,014,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1642014044...
Checkpoint 1642014044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.88449
Policy Entropy: 2.26507
Value Function Loss: 0.01492

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.55265

Collected Steps per Second: 23,186.42387
Overall Steps per Second: 10,767.13815

Timestep Collection Time: 2.15747
Timestep Consumption Time: 2.48852
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.64599

Cumulative Model Updates: 196,894
Cumulative Timesteps: 1,642,064,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.75847
Policy Entropy: 2.25921
Value Function Loss: 0.01499

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 23,210.19500
Overall Steps per Second: 10,793.32422

Timestep Collection Time: 2.15440
Timestep Consumption Time: 2.47847
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.63286

Cumulative Model Updates: 196,900
Cumulative Timesteps: 1,642,114,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1642114072...
Checkpoint 1642114072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.01227
Policy Entropy: 2.26371
Value Function Loss: 0.01490

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 23,097.55373
Overall Steps per Second: 10,741.96367

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.65650

Cumulative Model Updates: 196,906
Cumulative Timesteps: 1,642,164,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.58381
Policy Entropy: 2.25126
Value Function Loss: 0.01496

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.53804

Collected Steps per Second: 23,309.33767
Overall Steps per Second: 10,828.10396

Timestep Collection Time: 2.14523
Timestep Consumption Time: 2.47275
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.61798

Cumulative Model Updates: 196,912
Cumulative Timesteps: 1,642,214,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1642214096...
Checkpoint 1642214096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.76564
Policy Entropy: 2.24341
Value Function Loss: 0.01586

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.52121

Collected Steps per Second: 22,590.01038
Overall Steps per Second: 10,816.53856

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.40938
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.62292

Cumulative Model Updates: 196,918
Cumulative Timesteps: 1,642,264,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.17147
Policy Entropy: 2.24470
Value Function Loss: 0.01642

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.52703

Collected Steps per Second: 23,610.61544
Overall Steps per Second: 10,863.97462

Timestep Collection Time: 2.11862
Timestep Consumption Time: 2.48577
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.60439

Cumulative Model Updates: 196,924
Cumulative Timesteps: 1,642,314,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1642314122...
Checkpoint 1642314122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 447.04787
Policy Entropy: 2.26282
Value Function Loss: 0.01615

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 23,416.33496
Overall Steps per Second: 10,954.12519

Timestep Collection Time: 2.13637
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.56686

Cumulative Model Updates: 196,930
Cumulative Timesteps: 1,642,364,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.98158
Policy Entropy: 2.27301
Value Function Loss: 0.01594

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.56259

Collected Steps per Second: 23,459.66263
Overall Steps per Second: 10,912.06649

Timestep Collection Time: 2.13140
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.58227

Cumulative Model Updates: 196,936
Cumulative Timesteps: 1,642,414,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1642414150...
Checkpoint 1642414150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.67554
Policy Entropy: 2.28473
Value Function Loss: 0.01540

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.55579

Collected Steps per Second: 22,942.91049
Overall Steps per Second: 11,042.56655

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.34880
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.52830

Cumulative Model Updates: 196,942
Cumulative Timesteps: 1,642,464,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.05515
Policy Entropy: 2.28630
Value Function Loss: 0.01529

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.57431

Collected Steps per Second: 23,317.54002
Overall Steps per Second: 10,929.58664

Timestep Collection Time: 2.14534
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.57693

Cumulative Model Updates: 196,948
Cumulative Timesteps: 1,642,514,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1642514178...
Checkpoint 1642514178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.12125
Policy Entropy: 2.28954
Value Function Loss: 0.01439

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.53398
Value Function Update Magnitude: 0.57894

Collected Steps per Second: 23,072.86120
Overall Steps per Second: 10,718.65700

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.66682

Cumulative Model Updates: 196,954
Cumulative Timesteps: 1,642,564,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.00215
Policy Entropy: 2.26838
Value Function Loss: 0.01531

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.53976
Value Function Update Magnitude: 0.55272

Collected Steps per Second: 23,449.35248
Overall Steps per Second: 10,899.25050

Timestep Collection Time: 2.13260
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.58821

Cumulative Model Updates: 196,960
Cumulative Timesteps: 1,642,614,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1642614208...
Checkpoint 1642614208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.85367
Policy Entropy: 2.25806
Value Function Loss: 0.01535

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.54736

Collected Steps per Second: 22,903.13915
Overall Steps per Second: 10,741.59888

Timestep Collection Time: 2.18328
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.65517

Cumulative Model Updates: 196,966
Cumulative Timesteps: 1,642,664,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.10566
Policy Entropy: 2.24910
Value Function Loss: 0.01557

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.55284
Value Function Update Magnitude: 0.55151

Collected Steps per Second: 23,387.87654
Overall Steps per Second: 11,045.79035

Timestep Collection Time: 2.13991
Timestep Consumption Time: 2.39104
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.53096

Cumulative Model Updates: 196,972
Cumulative Timesteps: 1,642,714,260

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1642714260...
Checkpoint 1642714260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.05365
Policy Entropy: 2.23797
Value Function Loss: 0.01531

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.56197

Collected Steps per Second: 22,781.27968
Overall Steps per Second: 10,819.21538

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62400

Cumulative Model Updates: 196,978
Cumulative Timesteps: 1,642,764,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.18269
Policy Entropy: 2.21928
Value Function Loss: 0.01491

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.57230

Collected Steps per Second: 23,134.49401
Overall Steps per Second: 10,894.59159

Timestep Collection Time: 2.16153
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58998

Cumulative Model Updates: 196,984
Cumulative Timesteps: 1,642,814,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1642814294...
Checkpoint 1642814294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.87182
Policy Entropy: 2.22535
Value Function Loss: 0.01506

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.53403
Value Function Update Magnitude: 0.57723

Collected Steps per Second: 22,880.48087
Overall Steps per Second: 10,683.17412

Timestep Collection Time: 2.18562
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.68101

Cumulative Model Updates: 196,990
Cumulative Timesteps: 1,642,864,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.78942
Policy Entropy: 2.22256
Value Function Loss: 0.01526

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 23,192.67929
Overall Steps per Second: 10,959.89273

Timestep Collection Time: 2.15715
Timestep Consumption Time: 2.40768
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.56483

Cumulative Model Updates: 196,996
Cumulative Timesteps: 1,642,914,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1642914332...
Checkpoint 1642914332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.74526
Policy Entropy: 2.25223
Value Function Loss: 0.01548

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.58287

Collected Steps per Second: 23,142.00949
Overall Steps per Second: 11,046.56776

Timestep Collection Time: 2.16109
Timestep Consumption Time: 2.36629
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.52738

Cumulative Model Updates: 197,002
Cumulative Timesteps: 1,642,964,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.36013
Policy Entropy: 2.25328
Value Function Loss: 0.01543

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.56573

Collected Steps per Second: 23,384.25525
Overall Steps per Second: 10,962.21079

Timestep Collection Time: 2.13905
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.56295

Cumulative Model Updates: 197,008
Cumulative Timesteps: 1,643,014,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1643014364...
Checkpoint 1643014364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.28240
Policy Entropy: 2.23546
Value Function Loss: 0.01518

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.15041
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 22,888.32318
Overall Steps per Second: 10,648.32894

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.69764

Cumulative Model Updates: 197,014
Cumulative Timesteps: 1,643,064,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.14010
Policy Entropy: 2.24171
Value Function Loss: 0.01441

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.53720
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 23,185.98336
Overall Steps per Second: 10,871.63728

Timestep Collection Time: 2.15665
Timestep Consumption Time: 2.44284
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59949

Cumulative Model Updates: 197,020
Cumulative Timesteps: 1,643,114,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1643114390...
Checkpoint 1643114390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.02692
Policy Entropy: 2.26326
Value Function Loss: 0.01504

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.56905

Collected Steps per Second: 23,061.77564
Overall Steps per Second: 10,832.13650

Timestep Collection Time: 2.16818
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.61608

Cumulative Model Updates: 197,026
Cumulative Timesteps: 1,643,164,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.23647
Policy Entropy: 2.27465
Value Function Loss: 0.01612

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.56946

Collected Steps per Second: 23,557.48091
Overall Steps per Second: 11,193.79647

Timestep Collection Time: 2.12417
Timestep Consumption Time: 2.34617
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.47033

Cumulative Model Updates: 197,032
Cumulative Timesteps: 1,643,214,432

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1643214432...
Checkpoint 1643214432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.41505
Policy Entropy: 2.26052
Value Function Loss: 0.01579

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.58713

Collected Steps per Second: 23,388.25409
Overall Steps per Second: 10,875.80304

Timestep Collection Time: 2.13885
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.59957

Cumulative Model Updates: 197,038
Cumulative Timesteps: 1,643,264,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.05045
Policy Entropy: 2.24600
Value Function Loss: 0.01656

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.60016

Collected Steps per Second: 23,512.10064
Overall Steps per Second: 10,825.26534

Timestep Collection Time: 2.12716
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.62012

Cumulative Model Updates: 197,044
Cumulative Timesteps: 1,643,314,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1643314470...
Checkpoint 1643314470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.73617
Policy Entropy: 2.26270
Value Function Loss: 0.01625

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.59769

Collected Steps per Second: 23,258.93182
Overall Steps per Second: 11,009.79470

Timestep Collection Time: 2.15040
Timestep Consumption Time: 2.39246
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.54286

Cumulative Model Updates: 197,050
Cumulative Timesteps: 1,643,364,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.32729
Policy Entropy: 2.27336
Value Function Loss: 0.01633

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 23,179.38111
Overall Steps per Second: 10,901.26102

Timestep Collection Time: 2.15718
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.58681

Cumulative Model Updates: 197,056
Cumulative Timesteps: 1,643,414,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1643414488...
Checkpoint 1643414488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.53081
Policy Entropy: 2.27430
Value Function Loss: 0.01605

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.54038

Collected Steps per Second: 23,154.93543
Overall Steps per Second: 10,807.85916

Timestep Collection Time: 2.15954
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.62663

Cumulative Model Updates: 197,062
Cumulative Timesteps: 1,643,464,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.03175
Policy Entropy: 2.27964
Value Function Loss: 0.01612

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.53199

Collected Steps per Second: 23,210.85398
Overall Steps per Second: 10,753.74479

Timestep Collection Time: 2.15468
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.65066

Cumulative Model Updates: 197,068
Cumulative Timesteps: 1,643,514,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1643514504...
Checkpoint 1643514504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.73654
Policy Entropy: 2.25614
Value Function Loss: 0.01496

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.53155
Value Function Update Magnitude: 0.53125

Collected Steps per Second: 23,191.63874
Overall Steps per Second: 10,812.71131

Timestep Collection Time: 2.15750
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.62752

Cumulative Model Updates: 197,074
Cumulative Timesteps: 1,643,564,540

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.89182
Policy Entropy: 2.23176
Value Function Loss: 0.01440

Mean KL Divergence: 0.02363
SB3 Clip Fraction: 0.16429
Policy Update Magnitude: 0.50694
Value Function Update Magnitude: 0.52101

Collected Steps per Second: 23,199.88568
Overall Steps per Second: 11,092.27360

Timestep Collection Time: 2.15596
Timestep Consumption Time: 2.35331
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.50926

Cumulative Model Updates: 197,080
Cumulative Timesteps: 1,643,614,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1643614558...
Checkpoint 1643614558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.63739
Policy Entropy: 2.21085
Value Function Loss: 0.01541

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.18922
Policy Update Magnitude: 0.49678
Value Function Update Magnitude: 0.53700

Collected Steps per Second: 22,521.62597
Overall Steps per Second: 10,813.39946

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.40448
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.62519

Cumulative Model Updates: 197,086
Cumulative Timesteps: 1,643,664,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.70180
Policy Entropy: 2.20772
Value Function Loss: 0.01519

Mean KL Divergence: 0.02454
SB3 Clip Fraction: 0.17195
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.56021

Collected Steps per Second: 23,307.58269
Overall Steps per Second: 10,770.34865

Timestep Collection Time: 2.14608
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.64423

Cumulative Model Updates: 197,092
Cumulative Timesteps: 1,643,714,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1643714592...
Checkpoint 1643714592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.21681
Policy Entropy: 2.23743
Value Function Loss: 0.01471

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.54943

Collected Steps per Second: 23,045.88241
Overall Steps per Second: 10,707.16959

Timestep Collection Time: 2.17045
Timestep Consumption Time: 2.50118
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.67164

Cumulative Model Updates: 197,098
Cumulative Timesteps: 1,643,764,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.71107
Policy Entropy: 2.24344
Value Function Loss: 0.01404

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.51919

Collected Steps per Second: 23,478.61186
Overall Steps per Second: 10,832.77358

Timestep Collection Time: 2.13062
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.61784

Cumulative Model Updates: 197,104
Cumulative Timesteps: 1,643,814,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1643814636...
Checkpoint 1643814636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.48061
Policy Entropy: 2.25819
Value Function Loss: 0.01480

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.50359

Collected Steps per Second: 22,845.17073
Overall Steps per Second: 10,692.34780

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.67718

Cumulative Model Updates: 197,110
Cumulative Timesteps: 1,643,864,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.63629
Policy Entropy: 2.23379
Value Function Loss: 0.01561

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 24,117.10916
Overall Steps per Second: 10,962.65124

Timestep Collection Time: 2.07388
Timestep Consumption Time: 2.48852
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.56240

Cumulative Model Updates: 197,116
Cumulative Timesteps: 1,643,914,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1643914662...
Checkpoint 1643914662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.52543
Policy Entropy: 2.24957
Value Function Loss: 0.01554

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.51364

Collected Steps per Second: 23,491.75651
Overall Steps per Second: 10,971.77796

Timestep Collection Time: 2.12866
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.55769

Cumulative Model Updates: 197,122
Cumulative Timesteps: 1,643,964,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.63939
Policy Entropy: 2.25207
Value Function Loss: 0.01480

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.53072
Value Function Update Magnitude: 0.53049

Collected Steps per Second: 23,158.84260
Overall Steps per Second: 10,913.01769

Timestep Collection Time: 2.15909
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58187

Cumulative Model Updates: 197,128
Cumulative Timesteps: 1,644,014,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1644014670...
Checkpoint 1644014670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.74012
Policy Entropy: 2.26314
Value Function Loss: 0.01440

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.53414
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 22,825.03747
Overall Steps per Second: 10,744.68847

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.46328
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.65421

Cumulative Model Updates: 197,134
Cumulative Timesteps: 1,644,064,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.02915
Policy Entropy: 2.23975
Value Function Loss: 0.01474

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.56663

Collected Steps per Second: 23,238.33370
Overall Steps per Second: 10,947.97177

Timestep Collection Time: 2.15299
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.56998

Cumulative Model Updates: 197,140
Cumulative Timesteps: 1,644,114,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1644114710...
Checkpoint 1644114710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.73739
Policy Entropy: 2.24899
Value Function Loss: 0.01561

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 23,309.07143
Overall Steps per Second: 10,951.69632

Timestep Collection Time: 2.14517
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.56569

Cumulative Model Updates: 197,146
Cumulative Timesteps: 1,644,164,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.83270
Policy Entropy: 2.24189
Value Function Loss: 0.01603

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.52972
Value Function Update Magnitude: 0.56301

Collected Steps per Second: 23,337.63991
Overall Steps per Second: 10,949.34412

Timestep Collection Time: 2.14323
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.56813

Cumulative Model Updates: 197,152
Cumulative Timesteps: 1,644,214,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1644214730...
Checkpoint 1644214730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.07068
Policy Entropy: 2.23385
Value Function Loss: 0.01571

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 22,290.84478
Overall Steps per Second: 10,641.06855

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.70160

Cumulative Model Updates: 197,158
Cumulative Timesteps: 1,644,264,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.86795
Policy Entropy: 2.22494
Value Function Loss: 0.01573

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.52843
Value Function Update Magnitude: 0.54198

Collected Steps per Second: 23,284.66608
Overall Steps per Second: 10,895.15170

Timestep Collection Time: 2.14768
Timestep Consumption Time: 2.44225
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.58993

Cumulative Model Updates: 197,164
Cumulative Timesteps: 1,644,314,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1644314768...
Checkpoint 1644314768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.56363
Policy Entropy: 2.24455
Value Function Loss: 0.01539

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.53278
Value Function Update Magnitude: 0.54988

Collected Steps per Second: 23,003.31540
Overall Steps per Second: 10,725.73238

Timestep Collection Time: 2.17395
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.66243

Cumulative Model Updates: 197,170
Cumulative Timesteps: 1,644,364,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.06368
Policy Entropy: 2.25494
Value Function Loss: 0.01641

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.56419

Collected Steps per Second: 23,532.24336
Overall Steps per Second: 10,829.11793

Timestep Collection Time: 2.12559
Timestep Consumption Time: 2.49343
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.61903

Cumulative Model Updates: 197,176
Cumulative Timesteps: 1,644,414,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1644414796...
Checkpoint 1644414796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.37779
Policy Entropy: 2.26169
Value Function Loss: 0.01570

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.56852

Collected Steps per Second: 23,072.71013
Overall Steps per Second: 10,846.50850

Timestep Collection Time: 2.16750
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.61070

Cumulative Model Updates: 197,182
Cumulative Timesteps: 1,644,464,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.54028
Policy Entropy: 2.25835
Value Function Loss: 0.01567

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.57178

Collected Steps per Second: 23,385.22305
Overall Steps per Second: 10,882.62430

Timestep Collection Time: 2.13904
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.59650

Cumulative Model Updates: 197,188
Cumulative Timesteps: 1,644,514,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1644514828...
Checkpoint 1644514828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.65148
Policy Entropy: 2.26650
Value Function Loss: 0.01513

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.55089
Value Function Update Magnitude: 0.56494

Collected Steps per Second: 23,359.84771
Overall Steps per Second: 10,982.58237

Timestep Collection Time: 2.14137
Timestep Consumption Time: 2.41330
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.55467

Cumulative Model Updates: 197,194
Cumulative Timesteps: 1,644,564,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.11278
Policy Entropy: 2.26304
Value Function Loss: 0.01540

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.55212
Value Function Update Magnitude: 0.54377

Collected Steps per Second: 23,320.67334
Overall Steps per Second: 10,879.96548

Timestep Collection Time: 2.14539
Timestep Consumption Time: 2.45315
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.59854

Cumulative Model Updates: 197,200
Cumulative Timesteps: 1,644,614,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1644614882...
Checkpoint 1644614882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.31739
Policy Entropy: 2.24646
Value Function Loss: 0.01444

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.53022

Collected Steps per Second: 23,182.52913
Overall Steps per Second: 10,800.22146

Timestep Collection Time: 2.15680
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.62953

Cumulative Model Updates: 197,206
Cumulative Timesteps: 1,644,664,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.89514
Policy Entropy: 2.24632
Value Function Loss: 0.01554

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.52475

Collected Steps per Second: 23,003.75299
Overall Steps per Second: 10,756.66053

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.65014

Cumulative Model Updates: 197,212
Cumulative Timesteps: 1,644,714,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1644714902...
Checkpoint 1644714902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.60227
Policy Entropy: 2.24173
Value Function Loss: 0.01483

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.54006
Value Function Update Magnitude: 0.53723

Collected Steps per Second: 23,212.08959
Overall Steps per Second: 10,960.49378

Timestep Collection Time: 2.15526
Timestep Consumption Time: 2.40914
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.56439

Cumulative Model Updates: 197,218
Cumulative Timesteps: 1,644,764,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.67856
Policy Entropy: 2.23638
Value Function Loss: 0.01461

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 23,423.70199
Overall Steps per Second: 11,032.88223

Timestep Collection Time: 2.13510
Timestep Consumption Time: 2.39789
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.53299

Cumulative Model Updates: 197,224
Cumulative Timesteps: 1,644,814,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1644814942...
Checkpoint 1644814942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.62056
Policy Entropy: 2.22923
Value Function Loss: 0.01458

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.54054

Collected Steps per Second: 23,260.46038
Overall Steps per Second: 10,844.90212

Timestep Collection Time: 2.15069
Timestep Consumption Time: 2.46217
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.61286

Cumulative Model Updates: 197,230
Cumulative Timesteps: 1,644,864,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.57265
Policy Entropy: 2.26159
Value Function Loss: 0.01550

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.14726
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.54332

Collected Steps per Second: 23,191.73936
Overall Steps per Second: 10,724.74775

Timestep Collection Time: 2.15603
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.66230

Cumulative Model Updates: 197,236
Cumulative Timesteps: 1,644,914,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1644914970...
Checkpoint 1644914970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.08443
Policy Entropy: 2.27273
Value Function Loss: 0.01551

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.53286
Value Function Update Magnitude: 0.53858

Collected Steps per Second: 23,371.48967
Overall Steps per Second: 11,004.50388

Timestep Collection Time: 2.14073
Timestep Consumption Time: 2.40577
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.54650

Cumulative Model Updates: 197,242
Cumulative Timesteps: 1,644,965,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.36083
Policy Entropy: 2.29621
Value Function Loss: 0.01501

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.52617
Value Function Update Magnitude: 0.53413

Collected Steps per Second: 24,321.06648
Overall Steps per Second: 10,976.37190

Timestep Collection Time: 2.05632
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.55633

Cumulative Model Updates: 197,248
Cumulative Timesteps: 1,645,015,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1645015014...
Checkpoint 1645015014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.75125
Policy Entropy: 2.26813
Value Function Loss: 0.01491

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.52518
Value Function Update Magnitude: 0.51879

Collected Steps per Second: 23,379.42824
Overall Steps per Second: 10,863.19314

Timestep Collection Time: 2.13923
Timestep Consumption Time: 2.46476
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.60399

Cumulative Model Updates: 197,254
Cumulative Timesteps: 1,645,065,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.05198
Policy Entropy: 2.28469
Value Function Loss: 0.01457

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.52676

Collected Steps per Second: 23,416.65509
Overall Steps per Second: 10,821.57470

Timestep Collection Time: 2.13549
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.62095

Cumulative Model Updates: 197,260
Cumulative Timesteps: 1,645,115,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1645115034...
Checkpoint 1645115034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.87245
Policy Entropy: 2.27808
Value Function Loss: 0.01521

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.55110

Collected Steps per Second: 23,296.11028
Overall Steps per Second: 10,998.51744

Timestep Collection Time: 2.14637
Timestep Consumption Time: 2.39988
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.54625

Cumulative Model Updates: 197,266
Cumulative Timesteps: 1,645,165,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.62526
Policy Entropy: 2.29567
Value Function Loss: 0.01523

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.56966

Collected Steps per Second: 23,093.83717
Overall Steps per Second: 10,881.34334

Timestep Collection Time: 2.16551
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.59594

Cumulative Model Updates: 197,272
Cumulative Timesteps: 1,645,215,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1645215046...
Checkpoint 1645215046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.51796
Policy Entropy: 2.28344
Value Function Loss: 0.01580

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.58417

Collected Steps per Second: 23,239.34974
Overall Steps per Second: 10,793.09198

Timestep Collection Time: 2.15195
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.63352

Cumulative Model Updates: 197,278
Cumulative Timesteps: 1,645,265,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.37134
Policy Entropy: 2.28401
Value Function Loss: 0.01499

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.57645

Collected Steps per Second: 23,310.80242
Overall Steps per Second: 10,760.18515

Timestep Collection Time: 2.14519
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.64732

Cumulative Model Updates: 197,284
Cumulative Timesteps: 1,645,315,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1645315062...
Checkpoint 1645315062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.34361
Policy Entropy: 2.24980
Value Function Loss: 0.01466

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 22,666.86812
Overall Steps per Second: 10,651.97804

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.69697

Cumulative Model Updates: 197,290
Cumulative Timesteps: 1,645,365,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.32845
Policy Entropy: 2.23903
Value Function Loss: 0.01529

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.58596

Collected Steps per Second: 23,481.79339
Overall Steps per Second: 10,877.55178

Timestep Collection Time: 2.12948
Timestep Consumption Time: 2.46751
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.59699

Cumulative Model Updates: 197,296
Cumulative Timesteps: 1,645,415,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1645415098...
Checkpoint 1645415098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.17380
Policy Entropy: 2.23920
Value Function Loss: 0.01641

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.61363

Collected Steps per Second: 23,117.21392
Overall Steps per Second: 11,055.71052

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.36089
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.52490

Cumulative Model Updates: 197,302
Cumulative Timesteps: 1,645,465,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.82788
Policy Entropy: 2.25069
Value Function Loss: 0.01652

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.62124

Collected Steps per Second: 23,363.78652
Overall Steps per Second: 10,946.67419

Timestep Collection Time: 2.14118
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.56997

Cumulative Model Updates: 197,308
Cumulative Timesteps: 1,645,515,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1645515150...
Checkpoint 1645515150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.99570
Policy Entropy: 2.26496
Value Function Loss: 0.01669

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.60604

Collected Steps per Second: 23,295.18135
Overall Steps per Second: 10,793.68633

Timestep Collection Time: 2.14757
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.63493

Cumulative Model Updates: 197,314
Cumulative Timesteps: 1,645,565,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.39576
Policy Entropy: 2.27027
Value Function Loss: 0.01640

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.59492

Collected Steps per Second: 23,310.28622
Overall Steps per Second: 10,817.05138

Timestep Collection Time: 2.14558
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.62363

Cumulative Model Updates: 197,320
Cumulative Timesteps: 1,645,615,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1645615192...
Checkpoint 1645615192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.33421
Policy Entropy: 2.27409
Value Function Loss: 0.01625

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.59816

Collected Steps per Second: 23,184.16045
Overall Steps per Second: 11,060.27683

Timestep Collection Time: 2.15725
Timestep Consumption Time: 2.36470
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.52195

Cumulative Model Updates: 197,326
Cumulative Timesteps: 1,645,665,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.09299
Policy Entropy: 2.27749
Value Function Loss: 0.01577

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 23,168.77694
Overall Steps per Second: 10,881.82384

Timestep Collection Time: 2.15920
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.59721

Cumulative Model Updates: 197,332
Cumulative Timesteps: 1,645,715,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1645715232...
Checkpoint 1645715232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.24113
Policy Entropy: 2.27372
Value Function Loss: 0.01531

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.58265

Collected Steps per Second: 23,047.72390
Overall Steps per Second: 10,724.62111

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.66310

Cumulative Model Updates: 197,338
Cumulative Timesteps: 1,645,765,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.63060
Policy Entropy: 2.28752
Value Function Loss: 0.01575

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.57622

Collected Steps per Second: 23,366.07614
Overall Steps per Second: 10,860.57944

Timestep Collection Time: 2.14080
Timestep Consumption Time: 2.46504
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.60583

Cumulative Model Updates: 197,344
Cumulative Timesteps: 1,645,815,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1645815264...
Checkpoint 1645815264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.73536
Policy Entropy: 2.29307
Value Function Loss: 0.01535

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.58330

Collected Steps per Second: 23,175.29423
Overall Steps per Second: 10,841.11232

Timestep Collection Time: 2.15833
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.61392

Cumulative Model Updates: 197,350
Cumulative Timesteps: 1,645,865,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.27602
Policy Entropy: 2.28922
Value Function Loss: 0.01601

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.58044

Collected Steps per Second: 23,415.47791
Overall Steps per Second: 11,144.20890

Timestep Collection Time: 2.13585
Timestep Consumption Time: 2.35186
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.48771

Cumulative Model Updates: 197,356
Cumulative Timesteps: 1,645,915,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1645915296...
Checkpoint 1645915296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.78229
Policy Entropy: 2.28225
Value Function Loss: 0.01538

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.55911

Collected Steps per Second: 23,207.98935
Overall Steps per Second: 10,792.41330

Timestep Collection Time: 2.15555
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.63529

Cumulative Model Updates: 197,362
Cumulative Timesteps: 1,645,965,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.06150
Policy Entropy: 2.26213
Value Function Loss: 0.01483

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.54584

Collected Steps per Second: 23,339.75168
Overall Steps per Second: 10,764.16650

Timestep Collection Time: 2.14287
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64634

Cumulative Model Updates: 197,368
Cumulative Timesteps: 1,646,015,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1646015336...
Checkpoint 1646015336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.93054
Policy Entropy: 2.24407
Value Function Loss: 0.01529

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.53250

Collected Steps per Second: 23,090.59656
Overall Steps per Second: 10,847.44139

Timestep Collection Time: 2.16573
Timestep Consumption Time: 2.44439
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.61012

Cumulative Model Updates: 197,374
Cumulative Timesteps: 1,646,065,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.22259
Policy Entropy: 2.23484
Value Function Loss: 0.01506

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.53506
Value Function Update Magnitude: 0.53881

Collected Steps per Second: 23,579.87491
Overall Steps per Second: 11,192.16617

Timestep Collection Time: 2.12139
Timestep Consumption Time: 2.34799
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.46938

Cumulative Model Updates: 197,380
Cumulative Timesteps: 1,646,115,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1646115366...
Checkpoint 1646115366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.27896
Policy Entropy: 2.23132
Value Function Loss: 0.01499

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.56042

Collected Steps per Second: 23,409.84211
Overall Steps per Second: 10,888.48103

Timestep Collection Time: 2.13688
Timestep Consumption Time: 2.45733
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.59421

Cumulative Model Updates: 197,386
Cumulative Timesteps: 1,646,165,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.56093
Policy Entropy: 2.25821
Value Function Loss: 0.01503

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.58890

Collected Steps per Second: 23,490.03236
Overall Steps per Second: 10,873.06157

Timestep Collection Time: 2.12873
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.59889

Cumulative Model Updates: 197,392
Cumulative Timesteps: 1,646,215,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1646215394...
Checkpoint 1646215394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445.19889
Policy Entropy: 2.28131
Value Function Loss: 0.01391

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 23,509.09469
Overall Steps per Second: 10,903.21384

Timestep Collection Time: 2.12803
Timestep Consumption Time: 2.46034
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.58837

Cumulative Model Updates: 197,398
Cumulative Timesteps: 1,646,265,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.35248
Policy Entropy: 2.28050
Value Function Loss: 0.01381

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.57117

Collected Steps per Second: 22,768.90089
Overall Steps per Second: 10,847.23472

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.41359
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60965

Cumulative Model Updates: 197,404
Cumulative Timesteps: 1,646,315,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1646315424...
Checkpoint 1646315424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.89390
Policy Entropy: 2.28976
Value Function Loss: 0.01427

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.52612
Value Function Update Magnitude: 0.54600

Collected Steps per Second: 23,191.44688
Overall Steps per Second: 11,076.53842

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.35893
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.51567

Cumulative Model Updates: 197,410
Cumulative Timesteps: 1,646,365,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.22175
Policy Entropy: 2.26365
Value Function Loss: 0.01527

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.54573
Value Function Update Magnitude: 0.54926

Collected Steps per Second: 23,609.07748
Overall Steps per Second: 11,017.07903

Timestep Collection Time: 2.11868
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.54022

Cumulative Model Updates: 197,416
Cumulative Timesteps: 1,646,415,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1646415462...
Checkpoint 1646415462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.38984
Policy Entropy: 2.28295
Value Function Loss: 0.01563

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.57732

Collected Steps per Second: 23,195.97548
Overall Steps per Second: 10,813.78908

Timestep Collection Time: 2.15658
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.62595

Cumulative Model Updates: 197,422
Cumulative Timesteps: 1,646,465,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.62243
Policy Entropy: 2.29158
Value Function Loss: 0.01495

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.57046

Collected Steps per Second: 23,268.85445
Overall Steps per Second: 10,859.61306

Timestep Collection Time: 2.14965
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.60606

Cumulative Model Updates: 197,428
Cumulative Timesteps: 1,646,515,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1646515506...
Checkpoint 1646515506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.52425
Policy Entropy: 2.24640
Value Function Loss: 0.01475

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.54273

Collected Steps per Second: 23,046.57391
Overall Steps per Second: 10,861.99157

Timestep Collection Time: 2.17073
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.60579

Cumulative Model Updates: 197,434
Cumulative Timesteps: 1,646,565,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.61919
Policy Entropy: 2.23107
Value Function Loss: 0.01523

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.52717

Collected Steps per Second: 23,254.25773
Overall Steps per Second: 10,996.33173

Timestep Collection Time: 2.15040
Timestep Consumption Time: 2.39711
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.54752

Cumulative Model Updates: 197,440
Cumulative Timesteps: 1,646,615,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1646615540...
Checkpoint 1646615540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.72867
Policy Entropy: 2.21453
Value Function Loss: 0.01500

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.53606

Collected Steps per Second: 23,114.98234
Overall Steps per Second: 10,758.39709

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.64902

Cumulative Model Updates: 197,446
Cumulative Timesteps: 1,646,665,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.33902
Policy Entropy: 2.25449
Value Function Loss: 0.01505

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.53504

Collected Steps per Second: 23,581.17620
Overall Steps per Second: 10,798.19226

Timestep Collection Time: 2.12042
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.63059

Cumulative Model Updates: 197,452
Cumulative Timesteps: 1,646,715,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1646715558...
Checkpoint 1646715558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.38728
Policy Entropy: 2.24668
Value Function Loss: 0.01527

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.52432

Collected Steps per Second: 23,036.17866
Overall Steps per Second: 10,810.77998

Timestep Collection Time: 2.17189
Timestep Consumption Time: 2.45609
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.62797

Cumulative Model Updates: 197,458
Cumulative Timesteps: 1,646,765,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.16973
Policy Entropy: 2.25428
Value Function Loss: 0.01553

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.54934
Value Function Update Magnitude: 0.54799

Collected Steps per Second: 23,379.62121
Overall Steps per Second: 11,135.77517

Timestep Collection Time: 2.13990
Timestep Consumption Time: 2.35283
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.49273

Cumulative Model Updates: 197,464
Cumulative Timesteps: 1,646,815,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1646815620...
Checkpoint 1646815620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.07075
Policy Entropy: 2.23922
Value Function Loss: 0.01499

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.57612

Collected Steps per Second: 23,275.85312
Overall Steps per Second: 10,785.94653

Timestep Collection Time: 2.14823
Timestep Consumption Time: 2.48761
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.63585

Cumulative Model Updates: 197,470
Cumulative Timesteps: 1,646,865,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.90983
Policy Entropy: 2.24877
Value Function Loss: 0.01389

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.57300

Collected Steps per Second: 23,251.77296
Overall Steps per Second: 10,815.77518

Timestep Collection Time: 2.15063
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.62343

Cumulative Model Updates: 197,476
Cumulative Timesteps: 1,646,915,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1646915628...
Checkpoint 1646915628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.42750
Policy Entropy: 2.26793
Value Function Loss: 0.01408

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.50388
Value Function Update Magnitude: 0.57124

Collected Steps per Second: 23,187.50966
Overall Steps per Second: 10,785.16032

Timestep Collection Time: 2.15676
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.63693

Cumulative Model Updates: 197,482
Cumulative Timesteps: 1,646,965,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.15157
Policy Entropy: 2.27641
Value Function Loss: 0.01473

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.16931
Policy Update Magnitude: 0.50716
Value Function Update Magnitude: 0.56119

Collected Steps per Second: 22,958.09063
Overall Steps per Second: 10,793.33400

Timestep Collection Time: 2.17867
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.63416

Cumulative Model Updates: 197,488
Cumulative Timesteps: 1,647,015,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1647015656...
Checkpoint 1647015656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653.72257
Policy Entropy: 2.28282
Value Function Loss: 0.01424

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.16152
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.57855

Collected Steps per Second: 23,170.23875
Overall Steps per Second: 11,131.75408

Timestep Collection Time: 2.15820
Timestep Consumption Time: 2.33399
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.49219

Cumulative Model Updates: 197,494
Cumulative Timesteps: 1,647,065,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.53331
Policy Entropy: 2.26326
Value Function Loss: 0.01341

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.57219

Collected Steps per Second: 23,082.74626
Overall Steps per Second: 10,896.73855

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.59110

Cumulative Model Updates: 197,500
Cumulative Timesteps: 1,647,115,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1647115690...
Checkpoint 1647115690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.42350
Policy Entropy: 2.26220
Value Function Loss: 0.01459

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.54310
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 23,233.04830
Overall Steps per Second: 10,768.35344

Timestep Collection Time: 2.15236
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.64379

Cumulative Model Updates: 197,506
Cumulative Timesteps: 1,647,165,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.76886
Policy Entropy: 2.25581
Value Function Loss: 0.01543

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.14984
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.63289

Collected Steps per Second: 22,879.24291
Overall Steps per Second: 10,744.17812

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.65610

Cumulative Model Updates: 197,512
Cumulative Timesteps: 1,647,215,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1647215722...
Checkpoint 1647215722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.29295
Policy Entropy: 2.24895
Value Function Loss: 0.01547

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.63855

Collected Steps per Second: 23,402.23737
Overall Steps per Second: 11,025.86906

Timestep Collection Time: 2.13689
Timestep Consumption Time: 2.39863
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.53552

Cumulative Model Updates: 197,518
Cumulative Timesteps: 1,647,265,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.37783
Policy Entropy: 2.24899
Value Function Loss: 0.01518

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.60464

Collected Steps per Second: 22,906.33123
Overall Steps per Second: 11,050.33803

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.34251
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.52583

Cumulative Model Updates: 197,524
Cumulative Timesteps: 1,647,315,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1647315742...
Checkpoint 1647315742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.59652
Policy Entropy: 2.23108
Value Function Loss: 0.01592

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.60911

Collected Steps per Second: 23,295.71128
Overall Steps per Second: 10,963.60873

Timestep Collection Time: 2.14761
Timestep Consumption Time: 2.41567
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.56328

Cumulative Model Updates: 197,530
Cumulative Timesteps: 1,647,365,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.42407
Policy Entropy: 2.24626
Value Function Loss: 0.01612

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.61661

Collected Steps per Second: 23,252.45409
Overall Steps per Second: 10,937.27111

Timestep Collection Time: 2.15194
Timestep Consumption Time: 2.42305
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.57500

Cumulative Model Updates: 197,536
Cumulative Timesteps: 1,647,415,810

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1647415810...
Checkpoint 1647415810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.16542
Policy Entropy: 2.24636
Value Function Loss: 0.01666

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.60625

Collected Steps per Second: 23,211.91780
Overall Steps per Second: 10,835.42749

Timestep Collection Time: 2.15493
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.61634

Cumulative Model Updates: 197,542
Cumulative Timesteps: 1,647,465,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.79778
Policy Entropy: 2.26074
Value Function Loss: 0.01581

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 23,025.63532
Overall Steps per Second: 10,922.79136

Timestep Collection Time: 2.17245
Timestep Consumption Time: 2.40715
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.57960

Cumulative Model Updates: 197,548
Cumulative Timesteps: 1,647,515,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1647515852...
Checkpoint 1647515852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.19181
Policy Entropy: 2.26966
Value Function Loss: 0.01521

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.60086

Collected Steps per Second: 23,388.16770
Overall Steps per Second: 10,955.39383

Timestep Collection Time: 2.13886
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.56615

Cumulative Model Updates: 197,554
Cumulative Timesteps: 1,647,565,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.70709
Policy Entropy: 2.29206
Value Function Loss: 0.01585

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.57709

Collected Steps per Second: 23,007.69029
Overall Steps per Second: 10,873.12630

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60107

Cumulative Model Updates: 197,560
Cumulative Timesteps: 1,647,615,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1647615904...
Checkpoint 1647615904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.78282
Policy Entropy: 2.28538
Value Function Loss: 0.01552

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.57622

Collected Steps per Second: 22,812.48744
Overall Steps per Second: 10,719.98316

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.66437

Cumulative Model Updates: 197,566
Cumulative Timesteps: 1,647,665,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.98581
Policy Entropy: 2.25191
Value Function Loss: 0.01595

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.57042

Collected Steps per Second: 23,403.11289
Overall Steps per Second: 10,900.25238

Timestep Collection Time: 2.13672
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.58760

Cumulative Model Updates: 197,572
Cumulative Timesteps: 1,647,715,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1647715912...
Checkpoint 1647715912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.42103
Policy Entropy: 2.25248
Value Function Loss: 0.01530

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.58525

Collected Steps per Second: 23,281.92900
Overall Steps per Second: 10,991.54307

Timestep Collection Time: 2.14828
Timestep Consumption Time: 2.40213
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.55041

Cumulative Model Updates: 197,578
Cumulative Timesteps: 1,647,765,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.01743
Policy Entropy: 2.23355
Value Function Loss: 0.01609

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.58974

Collected Steps per Second: 23,247.22594
Overall Steps per Second: 11,032.42363

Timestep Collection Time: 2.15200
Timestep Consumption Time: 2.38263
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.53463

Cumulative Model Updates: 197,584
Cumulative Timesteps: 1,647,815,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1647815956...
Checkpoint 1647815956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429.05856
Policy Entropy: 2.24723
Value Function Loss: 0.01547

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.55495
Value Function Update Magnitude: 0.57845

Collected Steps per Second: 23,151.73080
Overall Steps per Second: 10,792.60417

Timestep Collection Time: 2.16062
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.63484

Cumulative Model Updates: 197,590
Cumulative Timesteps: 1,647,865,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.55778
Policy Entropy: 2.22901
Value Function Loss: 0.01638

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.58043

Collected Steps per Second: 23,205.70305
Overall Steps per Second: 10,752.90522

Timestep Collection Time: 2.15559
Timestep Consumption Time: 2.49636
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.65195

Cumulative Model Updates: 197,596
Cumulative Timesteps: 1,647,916,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1647916000...
Checkpoint 1647916000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.51770
Policy Entropy: 2.24948
Value Function Loss: 0.01686

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.55963
Value Function Update Magnitude: 0.58363

Collected Steps per Second: 23,034.37979
Overall Steps per Second: 10,822.94688

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.62129

Cumulative Model Updates: 197,602
Cumulative Timesteps: 1,647,966,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.17729
Policy Entropy: 2.27914
Value Function Loss: 0.01713

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.59095

Collected Steps per Second: 23,884.20573
Overall Steps per Second: 11,212.03542

Timestep Collection Time: 2.09377
Timestep Consumption Time: 2.36644
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.46021

Cumulative Model Updates: 197,608
Cumulative Timesteps: 1,648,016,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1648016024...
Checkpoint 1648016024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.50574
Policy Entropy: 2.30514
Value Function Loss: 0.01628

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.57313

Collected Steps per Second: 23,436.01600
Overall Steps per Second: 10,971.85575

Timestep Collection Time: 2.13475
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.55985

Cumulative Model Updates: 197,614
Cumulative Timesteps: 1,648,066,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.41401
Policy Entropy: 2.31222
Value Function Loss: 0.01602

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.55012

Collected Steps per Second: 23,199.68419
Overall Steps per Second: 10,815.85669

Timestep Collection Time: 2.15572
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.62395

Cumulative Model Updates: 197,620
Cumulative Timesteps: 1,648,116,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1648116066...
Checkpoint 1648116066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.37981
Policy Entropy: 2.30556
Value Function Loss: 0.01617

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.57216

Collected Steps per Second: 22,987.65088
Overall Steps per Second: 10,914.74465

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.40636
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.58188

Cumulative Model Updates: 197,626
Cumulative Timesteps: 1,648,166,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.69308
Policy Entropy: 2.29001
Value Function Loss: 0.01620

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.55707
Value Function Update Magnitude: 0.58422

Collected Steps per Second: 23,236.20121
Overall Steps per Second: 10,862.21220

Timestep Collection Time: 2.15285
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.60532

Cumulative Model Updates: 197,632
Cumulative Timesteps: 1,648,216,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1648216100...
Checkpoint 1648216100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.08919
Policy Entropy: 2.27648
Value Function Loss: 0.01618

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.57429

Collected Steps per Second: 23,271.24767
Overall Steps per Second: 11,038.07155

Timestep Collection Time: 2.14918
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.53105

Cumulative Model Updates: 197,638
Cumulative Timesteps: 1,648,266,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.05839
Policy Entropy: 2.24876
Value Function Loss: 0.01617

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.55770
Value Function Update Magnitude: 0.57523

Collected Steps per Second: 22,814.22578
Overall Steps per Second: 10,714.64387

Timestep Collection Time: 2.19267
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.66875

Cumulative Model Updates: 197,644
Cumulative Timesteps: 1,648,316,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1648316138...
Checkpoint 1648316138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503.23780
Policy Entropy: 2.27029
Value Function Loss: 0.01572

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.56096
Value Function Update Magnitude: 0.58684

Collected Steps per Second: 23,276.71276
Overall Steps per Second: 10,884.14873

Timestep Collection Time: 2.14867
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.59512

Cumulative Model Updates: 197,650
Cumulative Timesteps: 1,648,366,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.53768
Policy Entropy: 2.28698
Value Function Loss: 0.01509

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 23,077.57000
Overall Steps per Second: 10,847.48303

Timestep Collection Time: 2.16765
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61158

Cumulative Model Updates: 197,656
Cumulative Timesteps: 1,648,416,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1648416176...
Checkpoint 1648416176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.83733
Policy Entropy: 2.30999
Value Function Loss: 0.01595

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.55552

Collected Steps per Second: 23,159.41338
Overall Steps per Second: 10,840.47176

Timestep Collection Time: 2.16024
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.61511

Cumulative Model Updates: 197,662
Cumulative Timesteps: 1,648,466,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.82839
Policy Entropy: 2.30054
Value Function Loss: 0.01633

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.18190
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.53089

Collected Steps per Second: 23,076.89043
Overall Steps per Second: 10,906.32056

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.58688

Cumulative Model Updates: 197,668
Cumulative Timesteps: 1,648,516,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1648516232...
Checkpoint 1648516232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 560.95767
Policy Entropy: 2.27779
Value Function Loss: 0.01558

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.16499
Policy Update Magnitude: 0.52102
Value Function Update Magnitude: 0.51810

Collected Steps per Second: 21,620.40724
Overall Steps per Second: 10,578.93611

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.72675

Cumulative Model Updates: 197,674
Cumulative Timesteps: 1,648,566,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.42323
Policy Entropy: 2.26813
Value Function Loss: 0.01585

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.51252

Collected Steps per Second: 23,479.80865
Overall Steps per Second: 10,910.34274

Timestep Collection Time: 2.13051
Timestep Consumption Time: 2.45450
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.58501

Cumulative Model Updates: 197,680
Cumulative Timesteps: 1,648,616,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1648616260...
Checkpoint 1648616260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.14821
Policy Entropy: 2.27614
Value Function Loss: 0.01477

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.55009
Value Function Update Magnitude: 0.53774

Collected Steps per Second: 23,519.15090
Overall Steps per Second: 10,985.68623

Timestep Collection Time: 2.12618
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.55192

Cumulative Model Updates: 197,686
Cumulative Timesteps: 1,648,666,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.70509
Policy Entropy: 2.29009
Value Function Loss: 0.01510

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 22,533.26033
Overall Steps per Second: 10,670.10887

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68599

Cumulative Model Updates: 197,692
Cumulative Timesteps: 1,648,716,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1648716266...
Checkpoint 1648716266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.27242
Policy Entropy: 2.29219
Value Function Loss: 0.01477

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.52845

Collected Steps per Second: 23,246.59469
Overall Steps per Second: 11,009.15695

Timestep Collection Time: 2.15171
Timestep Consumption Time: 2.39178
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.54349

Cumulative Model Updates: 197,698
Cumulative Timesteps: 1,648,766,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.72664
Policy Entropy: 2.30386
Value Function Loss: 0.01468

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.54205
Value Function Update Magnitude: 0.54130

Collected Steps per Second: 23,286.92026
Overall Steps per Second: 10,928.00242

Timestep Collection Time: 2.14807
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.57741

Cumulative Model Updates: 197,704
Cumulative Timesteps: 1,648,816,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1648816308...
Checkpoint 1648816308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.08537
Policy Entropy: 2.32410
Value Function Loss: 0.01447

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.53656
Value Function Update Magnitude: 0.54257

Collected Steps per Second: 23,470.40896
Overall Steps per Second: 10,966.34458

Timestep Collection Time: 2.13043
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.55959

Cumulative Model Updates: 197,710
Cumulative Timesteps: 1,648,866,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.29507
Policy Entropy: 2.33389
Value Function Loss: 0.01447

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.53603
Value Function Update Magnitude: 0.53341

Collected Steps per Second: 23,103.70766
Overall Steps per Second: 10,903.73409

Timestep Collection Time: 2.16545
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58834

Cumulative Model Updates: 197,716
Cumulative Timesteps: 1,648,916,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1648916340...
Checkpoint 1648916340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.25788
Policy Entropy: 2.32823
Value Function Loss: 0.01466

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.54456

Collected Steps per Second: 22,764.83651
Overall Steps per Second: 10,740.15380

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.45955
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.65636

Cumulative Model Updates: 197,722
Cumulative Timesteps: 1,648,966,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.22326
Policy Entropy: 2.31047
Value Function Loss: 0.01497

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.56754

Collected Steps per Second: 23,106.45255
Overall Steps per Second: 10,879.74804

Timestep Collection Time: 2.16433
Timestep Consumption Time: 2.43228
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.59661

Cumulative Model Updates: 197,728
Cumulative Timesteps: 1,649,016,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1649016360...
Checkpoint 1649016360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.47188
Policy Entropy: 2.32874
Value Function Loss: 0.01543

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 23,284.70178
Overall Steps per Second: 10,832.46673

Timestep Collection Time: 2.14776
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.61668

Cumulative Model Updates: 197,734
Cumulative Timesteps: 1,649,066,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.93027
Policy Entropy: 2.33500
Value Function Loss: 0.01505

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.55602

Collected Steps per Second: 23,444.60779
Overall Steps per Second: 10,821.38089

Timestep Collection Time: 2.13311
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.62141

Cumulative Model Updates: 197,740
Cumulative Timesteps: 1,649,116,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1649116380...
Checkpoint 1649116380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.71570
Policy Entropy: 2.33619
Value Function Loss: 0.01501

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.54389

Collected Steps per Second: 23,292.08383
Overall Steps per Second: 10,933.79473

Timestep Collection Time: 2.14734
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.57444

Cumulative Model Updates: 197,746
Cumulative Timesteps: 1,649,166,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.45206
Policy Entropy: 2.35374
Value Function Loss: 0.01446

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.51180

Collected Steps per Second: 23,144.33009
Overall Steps per Second: 10,933.24027

Timestep Collection Time: 2.16139
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.57540

Cumulative Model Updates: 197,752
Cumulative Timesteps: 1,649,216,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1649216420...
Checkpoint 1649216420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.32954
Policy Entropy: 2.32102
Value Function Loss: 0.01534

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.51500

Collected Steps per Second: 23,406.60558
Overall Steps per Second: 11,146.11464

Timestep Collection Time: 2.13666
Timestep Consumption Time: 2.35028
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.48694

Cumulative Model Updates: 197,758
Cumulative Timesteps: 1,649,266,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.21122
Policy Entropy: 2.31278
Value Function Loss: 0.01478

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.53547
Value Function Update Magnitude: 0.51734

Collected Steps per Second: 23,255.56314
Overall Steps per Second: 10,910.70660

Timestep Collection Time: 2.15114
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.58504

Cumulative Model Updates: 197,764
Cumulative Timesteps: 1,649,316,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1649316458...
Checkpoint 1649316458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.91261
Policy Entropy: 2.27596
Value Function Loss: 0.01478

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.53437
Value Function Update Magnitude: 0.52703

Collected Steps per Second: 23,065.78727
Overall Steps per Second: 10,739.75335

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65560

Cumulative Model Updates: 197,770
Cumulative Timesteps: 1,649,366,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.13739
Policy Entropy: 2.27211
Value Function Loss: 0.01369

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.53868
Value Function Update Magnitude: 0.53649

Collected Steps per Second: 23,448.20245
Overall Steps per Second: 10,862.78010

Timestep Collection Time: 2.13262
Timestep Consumption Time: 2.47081
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.60343

Cumulative Model Updates: 197,776
Cumulative Timesteps: 1,649,416,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1649416464...
Checkpoint 1649416464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.84536
Policy Entropy: 2.29631
Value Function Loss: 0.01327

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.52411

Collected Steps per Second: 23,220.11993
Overall Steps per Second: 10,985.24365

Timestep Collection Time: 2.15468
Timestep Consumption Time: 2.39979
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.55447

Cumulative Model Updates: 197,782
Cumulative Timesteps: 1,649,466,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.11287
Policy Entropy: 2.30193
Value Function Loss: 0.01412

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.52921
Value Function Update Magnitude: 0.51792

Collected Steps per Second: 22,757.72657
Overall Steps per Second: 10,984.03411

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.35614
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.55425

Cumulative Model Updates: 197,788
Cumulative Timesteps: 1,649,516,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1649516520...
Checkpoint 1649516520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.53238
Policy Entropy: 2.30896
Value Function Loss: 0.01572

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.54611

Collected Steps per Second: 23,296.21834
Overall Steps per Second: 10,818.46433

Timestep Collection Time: 2.14696
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.62321

Cumulative Model Updates: 197,794
Cumulative Timesteps: 1,649,566,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.35360
Policy Entropy: 2.30193
Value Function Loss: 0.01590

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 23,105.36855
Overall Steps per Second: 10,775.43217

Timestep Collection Time: 2.16495
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.64223

Cumulative Model Updates: 197,800
Cumulative Timesteps: 1,649,616,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1649616558...
Checkpoint 1649616558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.11135
Policy Entropy: 2.31313
Value Function Loss: 0.01538

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.60189

Collected Steps per Second: 23,293.69819
Overall Steps per Second: 10,828.23297

Timestep Collection Time: 2.14736
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.61941

Cumulative Model Updates: 197,806
Cumulative Timesteps: 1,649,666,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.25895
Policy Entropy: 2.31202
Value Function Loss: 0.01513

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.55116
Value Function Update Magnitude: 0.58831

Collected Steps per Second: 23,196.25021
Overall Steps per Second: 10,825.24536

Timestep Collection Time: 2.15673
Timestep Consumption Time: 2.46469
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.62142

Cumulative Model Updates: 197,812
Cumulative Timesteps: 1,649,716,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1649716606...
Checkpoint 1649716606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.93596
Policy Entropy: 2.27949
Value Function Loss: 0.01502

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.60482

Collected Steps per Second: 23,183.37265
Overall Steps per Second: 11,013.20980

Timestep Collection Time: 2.15706
Timestep Consumption Time: 2.38367
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.54073

Cumulative Model Updates: 197,818
Cumulative Timesteps: 1,649,766,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.10061
Policy Entropy: 2.29107
Value Function Loss: 0.01459

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.62642

Collected Steps per Second: 23,520.60409
Overall Steps per Second: 10,904.77776

Timestep Collection Time: 2.12622
Timestep Consumption Time: 2.45984
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.58606

Cumulative Model Updates: 197,824
Cumulative Timesteps: 1,649,816,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1649816624...
Checkpoint 1649816624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.12054
Policy Entropy: 2.29707
Value Function Loss: 0.01373

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.54530
Value Function Update Magnitude: 0.61410

Collected Steps per Second: 23,087.41493
Overall Steps per Second: 10,761.52488

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.64655

Cumulative Model Updates: 197,830
Cumulative Timesteps: 1,649,866,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.63047
Policy Entropy: 2.30235
Value Function Loss: 0.01395

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.58810

Collected Steps per Second: 23,346.55449
Overall Steps per Second: 10,790.53621

Timestep Collection Time: 2.14250
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.63554

Cumulative Model Updates: 197,836
Cumulative Timesteps: 1,649,916,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1649916648...
Checkpoint 1649916648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.05935
Policy Entropy: 2.29385
Value Function Loss: 0.01472

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.58284

Collected Steps per Second: 23,040.93873
Overall Steps per Second: 10,817.88098

Timestep Collection Time: 2.17118
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.62438

Cumulative Model Updates: 197,842
Cumulative Timesteps: 1,649,966,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.78398
Policy Entropy: 2.29602
Value Function Loss: 0.01636

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.56315
Value Function Update Magnitude: 0.58930

Collected Steps per Second: 23,648.19401
Overall Steps per Second: 11,213.37900

Timestep Collection Time: 2.11483
Timestep Consumption Time: 2.34520
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.46003

Cumulative Model Updates: 197,848
Cumulative Timesteps: 1,650,016,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1650016686...
Checkpoint 1650016686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.57823
Policy Entropy: 2.28490
Value Function Loss: 0.01578

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.62854

Collected Steps per Second: 22,672.70644
Overall Steps per Second: 10,965.73572

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.35493
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.56075

Cumulative Model Updates: 197,854
Cumulative Timesteps: 1,650,066,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.95646
Policy Entropy: 2.27156
Value Function Loss: 0.01586

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.62375

Collected Steps per Second: 23,086.46282
Overall Steps per Second: 10,783.01313

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.63896

Cumulative Model Updates: 197,860
Cumulative Timesteps: 1,650,116,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1650116720...
Checkpoint 1650116720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.78093
Policy Entropy: 2.27212
Value Function Loss: 0.01514

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 23,614.17158
Overall Steps per Second: 10,873.84438

Timestep Collection Time: 2.11746
Timestep Consumption Time: 2.48092
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.59837

Cumulative Model Updates: 197,866
Cumulative Timesteps: 1,650,166,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.83726
Policy Entropy: 2.30303
Value Function Loss: 0.01502

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.58239

Collected Steps per Second: 23,174.52226
Overall Steps per Second: 10,871.69977

Timestep Collection Time: 2.15858
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.60130

Cumulative Model Updates: 197,872
Cumulative Timesteps: 1,650,216,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1650216746...
Checkpoint 1650216746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.77098
Policy Entropy: 2.31557
Value Function Loss: 0.01367

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.57505

Collected Steps per Second: 23,122.55681
Overall Steps per Second: 10,816.26720

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.62359

Cumulative Model Updates: 197,878
Cumulative Timesteps: 1,650,266,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.46766
Policy Entropy: 2.34061
Value Function Loss: 0.01500

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.53919
Value Function Update Magnitude: 0.57654

Collected Steps per Second: 23,151.30964
Overall Steps per Second: 10,957.36654

Timestep Collection Time: 2.15996
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.56369

Cumulative Model Updates: 197,884
Cumulative Timesteps: 1,650,316,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1650316762...
Checkpoint 1650316762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.55679
Policy Entropy: 2.35740
Value Function Loss: 0.01422

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.53588
Value Function Update Magnitude: 0.57690

Collected Steps per Second: 23,402.28005
Overall Steps per Second: 10,937.46845

Timestep Collection Time: 2.13868
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.57601

Cumulative Model Updates: 197,890
Cumulative Timesteps: 1,650,366,812

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.84022
Policy Entropy: 2.35323
Value Function Loss: 0.01492

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.57385

Collected Steps per Second: 23,322.26201
Overall Steps per Second: 10,919.16161

Timestep Collection Time: 2.14422
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.57984

Cumulative Model Updates: 197,896
Cumulative Timesteps: 1,650,416,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1650416820...
Checkpoint 1650416820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.58431
Policy Entropy: 2.32548
Value Function Loss: 0.01372

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 23,172.81428
Overall Steps per Second: 10,788.02764

Timestep Collection Time: 2.15874
Timestep Consumption Time: 2.47826
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.63699

Cumulative Model Updates: 197,902
Cumulative Timesteps: 1,650,466,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.29902
Policy Entropy: 2.28947
Value Function Loss: 0.01397

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.56569

Collected Steps per Second: 23,442.64848
Overall Steps per Second: 10,870.62077

Timestep Collection Time: 2.13397
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.60195

Cumulative Model Updates: 197,908
Cumulative Timesteps: 1,650,516,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1650516870...
Checkpoint 1650516870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438.98652
Policy Entropy: 2.30024
Value Function Loss: 0.01433

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.53806
Value Function Update Magnitude: 0.56114

Collected Steps per Second: 23,320.73760
Overall Steps per Second: 10,979.01043

Timestep Collection Time: 2.14427
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.55469

Cumulative Model Updates: 197,914
Cumulative Timesteps: 1,650,566,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.02187
Policy Entropy: 2.30802
Value Function Loss: 0.01524

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.53694
Value Function Update Magnitude: 0.57261

Collected Steps per Second: 23,580.70279
Overall Steps per Second: 10,918.15968

Timestep Collection Time: 2.12063
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.58008

Cumulative Model Updates: 197,920
Cumulative Timesteps: 1,650,616,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1650616882...
Checkpoint 1650616882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.14395
Policy Entropy: 2.31017
Value Function Loss: 0.01537

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.59119

Collected Steps per Second: 23,248.58851
Overall Steps per Second: 10,802.08366

Timestep Collection Time: 2.15067
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.62874

Cumulative Model Updates: 197,926
Cumulative Timesteps: 1,650,666,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.08443
Policy Entropy: 2.30285
Value Function Loss: 0.01604

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.58595

Collected Steps per Second: 23,282.13149
Overall Steps per Second: 10,835.88550

Timestep Collection Time: 2.14774
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.61467

Cumulative Model Updates: 197,932
Cumulative Timesteps: 1,650,716,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1650716886...
Checkpoint 1650716886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.14026
Policy Entropy: 2.29560
Value Function Loss: 0.01601

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 23,133.86270
Overall Steps per Second: 11,012.81912

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.37950
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.54143

Cumulative Model Updates: 197,938
Cumulative Timesteps: 1,650,766,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.47441
Policy Entropy: 2.30278
Value Function Loss: 0.01549

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.61498

Collected Steps per Second: 23,556.14720
Overall Steps per Second: 10,899.37595

Timestep Collection Time: 2.12267
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.58760

Cumulative Model Updates: 197,944
Cumulative Timesteps: 1,650,816,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1650816902...
Checkpoint 1650816902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.26719
Policy Entropy: 2.30380
Value Function Loss: 0.01489

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.60433

Collected Steps per Second: 23,357.79433
Overall Steps per Second: 10,859.48420

Timestep Collection Time: 2.14104
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.60519

Cumulative Model Updates: 197,950
Cumulative Timesteps: 1,650,866,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.00555
Policy Entropy: 2.30534
Value Function Loss: 0.01528

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.54224
Value Function Update Magnitude: 0.58338

Collected Steps per Second: 23,147.12956
Overall Steps per Second: 10,690.34233

Timestep Collection Time: 2.16122
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.67955

Cumulative Model Updates: 197,956
Cumulative Timesteps: 1,650,916,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1650916938...
Checkpoint 1650916938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.35457
Policy Entropy: 2.32146
Value Function Loss: 0.01491

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.57216

Collected Steps per Second: 23,365.50896
Overall Steps per Second: 11,034.46182

Timestep Collection Time: 2.14008
Timestep Consumption Time: 2.39154
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.53162

Cumulative Model Updates: 197,962
Cumulative Timesteps: 1,650,966,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.26339
Policy Entropy: 2.30512
Value Function Loss: 0.01590

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.58394

Collected Steps per Second: 22,698.68702
Overall Steps per Second: 10,736.66803

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.65899

Cumulative Model Updates: 197,968
Cumulative Timesteps: 1,651,016,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1651016964...
Checkpoint 1651016964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.31809
Policy Entropy: 2.29142
Value Function Loss: 0.01621

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 22,933.06166
Overall Steps per Second: 10,862.37418

Timestep Collection Time: 2.18122
Timestep Consumption Time: 2.42385
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.60507

Cumulative Model Updates: 197,974
Cumulative Timesteps: 1,651,066,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.82521
Policy Entropy: 2.26341
Value Function Loss: 0.01505

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.17889
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 23,156.36406
Overall Steps per Second: 10,894.09445

Timestep Collection Time: 2.16044
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59221

Cumulative Model Updates: 197,980
Cumulative Timesteps: 1,651,117,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1651117014...
Checkpoint 1651117014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.42355
Policy Entropy: 2.27100
Value Function Loss: 0.01405

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.49527
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 23,087.79897
Overall Steps per Second: 10,752.26507

Timestep Collection Time: 2.16591
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.65074

Cumulative Model Updates: 197,986
Cumulative Timesteps: 1,651,167,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.88371
Policy Entropy: 2.26990
Value Function Loss: 0.01323

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.15635
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.63378

Collected Steps per Second: 23,323.96204
Overall Steps per Second: 10,809.17014

Timestep Collection Time: 2.14492
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.62829

Cumulative Model Updates: 197,992
Cumulative Timesteps: 1,651,217,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1651217048...
Checkpoint 1651217048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.54533
Policy Entropy: 2.28267
Value Function Loss: 0.01376

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.14995
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.63171

Collected Steps per Second: 23,188.79605
Overall Steps per Second: 10,842.33398

Timestep Collection Time: 2.15690
Timestep Consumption Time: 2.45613
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.61303

Cumulative Model Updates: 197,998
Cumulative Timesteps: 1,651,267,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.66443
Policy Entropy: 2.28963
Value Function Loss: 0.01389

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.52840
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 23,249.65840
Overall Steps per Second: 11,124.64101

Timestep Collection Time: 2.15083
Timestep Consumption Time: 2.34424
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.49507

Cumulative Model Updates: 198,004
Cumulative Timesteps: 1,651,317,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1651317070...
Checkpoint 1651317070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.60133
Policy Entropy: 2.28531
Value Function Loss: 0.01483

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.54075
Value Function Update Magnitude: 0.62009

Collected Steps per Second: 23,208.36804
Overall Steps per Second: 10,725.46192

Timestep Collection Time: 2.15526
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.66367

Cumulative Model Updates: 198,010
Cumulative Timesteps: 1,651,367,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.75322
Policy Entropy: 2.27050
Value Function Loss: 0.01548

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.61972

Collected Steps per Second: 23,381.70484
Overall Steps per Second: 10,910.85501

Timestep Collection Time: 2.13877
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.58333

Cumulative Model Updates: 198,016
Cumulative Timesteps: 1,651,417,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1651417098...
Checkpoint 1651417098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.07132
Policy Entropy: 2.29343
Value Function Loss: 0.01666

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.61130

Collected Steps per Second: 23,345.30666
Overall Steps per Second: 11,008.85598

Timestep Collection Time: 2.14296
Timestep Consumption Time: 2.40138
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.54434

Cumulative Model Updates: 198,022
Cumulative Timesteps: 1,651,467,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.65318
Policy Entropy: 2.29850
Value Function Loss: 0.01644

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.60769

Collected Steps per Second: 23,027.24019
Overall Steps per Second: 11,071.55456

Timestep Collection Time: 2.17247
Timestep Consumption Time: 2.34596
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.51843

Cumulative Model Updates: 198,028
Cumulative Timesteps: 1,651,517,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1651517152...
Checkpoint 1651517152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.71541
Policy Entropy: 2.31476
Value Function Loss: 0.01570

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 23,401.11192
Overall Steps per Second: 10,959.92767

Timestep Collection Time: 2.13768
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.56426

Cumulative Model Updates: 198,034
Cumulative Timesteps: 1,651,567,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.90165
Policy Entropy: 2.28415
Value Function Loss: 0.01534

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.60018

Collected Steps per Second: 23,434.38008
Overall Steps per Second: 10,945.03004

Timestep Collection Time: 2.13447
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.57011

Cumulative Model Updates: 198,040
Cumulative Timesteps: 1,651,617,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1651617196...
Checkpoint 1651617196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.19129
Policy Entropy: 2.29491
Value Function Loss: 0.01474

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 23,164.99284
Overall Steps per Second: 10,694.13087

Timestep Collection Time: 2.15998
Timestep Consumption Time: 2.51884
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67883

Cumulative Model Updates: 198,046
Cumulative Timesteps: 1,651,667,232

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.66253
Policy Entropy: 2.26446
Value Function Loss: 0.01470

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.53776
Value Function Update Magnitude: 0.56528

Collected Steps per Second: 23,066.03625
Overall Steps per Second: 10,968.40015

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.56092

Cumulative Model Updates: 198,052
Cumulative Timesteps: 1,651,717,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1651717258...
Checkpoint 1651717258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.43998
Policy Entropy: 2.27032
Value Function Loss: 0.01465

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.58415

Collected Steps per Second: 23,316.39851
Overall Steps per Second: 11,075.68242

Timestep Collection Time: 2.14519
Timestep Consumption Time: 2.37083
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.51602

Cumulative Model Updates: 198,058
Cumulative Timesteps: 1,651,767,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.81640
Policy Entropy: 2.24728
Value Function Loss: 0.01435

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 22,583.55162
Overall Steps per Second: 10,899.43939

Timestep Collection Time: 2.21409
Timestep Consumption Time: 2.37349
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.58758

Cumulative Model Updates: 198,064
Cumulative Timesteps: 1,651,817,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1651817278...
Checkpoint 1651817278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.17818
Policy Entropy: 2.27498
Value Function Loss: 0.01494

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.53395
Value Function Update Magnitude: 0.61337

Collected Steps per Second: 23,378.07097
Overall Steps per Second: 10,828.40690

Timestep Collection Time: 2.13970
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.61952

Cumulative Model Updates: 198,070
Cumulative Timesteps: 1,651,867,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.16228
Policy Entropy: 2.28144
Value Function Loss: 0.01578

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 23,053.57174
Overall Steps per Second: 10,697.73606

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67519

Cumulative Model Updates: 198,076
Cumulative Timesteps: 1,651,917,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1651917314...
Checkpoint 1651917314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.74179
Policy Entropy: 2.28170
Value Function Loss: 0.01620

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.62397

Collected Steps per Second: 23,119.69007
Overall Steps per Second: 10,849.24448

Timestep Collection Time: 2.16335
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.61009

Cumulative Model Updates: 198,082
Cumulative Timesteps: 1,651,967,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.64528
Policy Entropy: 2.26888
Value Function Loss: 0.01628

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 23,658.57641
Overall Steps per Second: 11,230.91169

Timestep Collection Time: 2.11433
Timestep Consumption Time: 2.33963
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.45396

Cumulative Model Updates: 198,088
Cumulative Timesteps: 1,652,017,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1652017352...
Checkpoint 1652017352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.07465
Policy Entropy: 2.28720
Value Function Loss: 0.01561

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 23,488.47635
Overall Steps per Second: 10,981.03727

Timestep Collection Time: 2.12973
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.55549

Cumulative Model Updates: 198,094
Cumulative Timesteps: 1,652,067,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.54863
Policy Entropy: 2.28395
Value Function Loss: 0.01524

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.63484

Collected Steps per Second: 23,111.85199
Overall Steps per Second: 10,892.42293

Timestep Collection Time: 2.16391
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59145

Cumulative Model Updates: 198,100
Cumulative Timesteps: 1,652,117,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1652117388...
Checkpoint 1652117388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.35921
Policy Entropy: 2.30101
Value Function Loss: 0.01489

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.52441
Value Function Update Magnitude: 0.61009

Collected Steps per Second: 22,956.20970
Overall Steps per Second: 10,745.92545

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.65535

Cumulative Model Updates: 198,106
Cumulative Timesteps: 1,652,167,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.25194
Policy Entropy: 2.28888
Value Function Loss: 0.01467

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 23,287.44479
Overall Steps per Second: 10,916.26590

Timestep Collection Time: 2.14760
Timestep Consumption Time: 2.43383
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.58142

Cumulative Model Updates: 198,112
Cumulative Timesteps: 1,652,217,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1652217426...
Checkpoint 1652217426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.26712
Policy Entropy: 2.30302
Value Function Loss: 0.01464

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.58226

Collected Steps per Second: 23,123.34184
Overall Steps per Second: 11,102.34404

Timestep Collection Time: 2.16361
Timestep Consumption Time: 2.34264
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.50626

Cumulative Model Updates: 198,118
Cumulative Timesteps: 1,652,267,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.80767
Policy Entropy: 2.31878
Value Function Loss: 0.01507

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.58144

Collected Steps per Second: 23,237.10588
Overall Steps per Second: 10,957.74360

Timestep Collection Time: 2.15216
Timestep Consumption Time: 2.41173
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.56390

Cumulative Model Updates: 198,124
Cumulative Timesteps: 1,652,317,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1652317466...
Checkpoint 1652317466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.17443
Policy Entropy: 2.32143
Value Function Loss: 0.01540

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.60473

Collected Steps per Second: 23,184.11347
Overall Steps per Second: 10,795.05412

Timestep Collection Time: 2.15794
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.63453

Cumulative Model Updates: 198,130
Cumulative Timesteps: 1,652,367,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.17565
Policy Entropy: 2.31508
Value Function Loss: 0.01502

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.54487
Value Function Update Magnitude: 0.59784

Collected Steps per Second: 23,274.71098
Overall Steps per Second: 10,788.92580

Timestep Collection Time: 2.14886
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.63568

Cumulative Model Updates: 198,136
Cumulative Timesteps: 1,652,417,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1652417510...
Checkpoint 1652417510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.82321
Policy Entropy: 2.31118
Value Function Loss: 0.01591

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 23,143.42757
Overall Steps per Second: 11,020.72751

Timestep Collection Time: 2.16105
Timestep Consumption Time: 2.37713
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.53818

Cumulative Model Updates: 198,142
Cumulative Timesteps: 1,652,467,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.84024
Policy Entropy: 2.31022
Value Function Loss: 0.01599

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14548
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 22,765.32643
Overall Steps per Second: 10,930.07349

Timestep Collection Time: 2.19755
Timestep Consumption Time: 2.37954
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.57710

Cumulative Model Updates: 198,148
Cumulative Timesteps: 1,652,517,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1652517552...
Checkpoint 1652517552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.08522
Policy Entropy: 2.31623
Value Function Loss: 0.01622

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.55240
Value Function Update Magnitude: 0.59514

Collected Steps per Second: 22,918.53861
Overall Steps per Second: 10,705.02486

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67220

Cumulative Model Updates: 198,154
Cumulative Timesteps: 1,652,567,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.73802
Policy Entropy: 2.31750
Value Function Loss: 0.01606

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.58478

Collected Steps per Second: 23,455.42147
Overall Steps per Second: 10,847.93036

Timestep Collection Time: 2.13204
Timestep Consumption Time: 2.47787
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.60991

Cumulative Model Updates: 198,160
Cumulative Timesteps: 1,652,617,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1652617576...
Checkpoint 1652617576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.63982
Policy Entropy: 2.31545
Value Function Loss: 0.01558

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.58037

Collected Steps per Second: 23,311.87463
Overall Steps per Second: 11,007.30775

Timestep Collection Time: 2.14552
Timestep Consumption Time: 2.39837
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.54389

Cumulative Model Updates: 198,166
Cumulative Timesteps: 1,652,667,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.40406
Policy Entropy: 2.31001
Value Function Loss: 0.01487

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.53532
Value Function Update Magnitude: 0.57433

Collected Steps per Second: 23,045.51233
Overall Steps per Second: 11,025.29635

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.36607
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.53630

Cumulative Model Updates: 198,172
Cumulative Timesteps: 1,652,717,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1652717606...
Checkpoint 1652717606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.55080
Policy Entropy: 2.31738
Value Function Loss: 0.01451

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.53382
Value Function Update Magnitude: 0.57086

Collected Steps per Second: 23,024.14802
Overall Steps per Second: 10,710.51062

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.67055

Cumulative Model Updates: 198,178
Cumulative Timesteps: 1,652,767,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.25727
Policy Entropy: 2.31466
Value Function Loss: 0.01533

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.55409

Collected Steps per Second: 23,497.84630
Overall Steps per Second: 10,809.25785

Timestep Collection Time: 2.12794
Timestep Consumption Time: 2.49791
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.62585

Cumulative Model Updates: 198,184
Cumulative Timesteps: 1,652,817,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1652817632...
Checkpoint 1652817632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.11693
Policy Entropy: 2.31784
Value Function Loss: 0.01537

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.54078

Collected Steps per Second: 23,162.51684
Overall Steps per Second: 10,728.52121

Timestep Collection Time: 2.15892
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.66103

Cumulative Model Updates: 198,190
Cumulative Timesteps: 1,652,867,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.16368
Policy Entropy: 2.27694
Value Function Loss: 0.01486

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.55445

Collected Steps per Second: 23,175.35870
Overall Steps per Second: 10,803.91179

Timestep Collection Time: 2.15807
Timestep Consumption Time: 2.47118
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.62925

Cumulative Model Updates: 198,196
Cumulative Timesteps: 1,652,917,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1652917652...
Checkpoint 1652917652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.25996
Policy Entropy: 2.28778
Value Function Loss: 0.01329

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.54984

Collected Steps per Second: 23,167.10434
Overall Steps per Second: 11,135.48039

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.33285
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.49195

Cumulative Model Updates: 198,202
Cumulative Timesteps: 1,652,967,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.06393
Policy Entropy: 2.29083
Value Function Loss: 0.01343

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 23,561.00971
Overall Steps per Second: 10,880.76763

Timestep Collection Time: 2.12359
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.59839

Cumulative Model Updates: 198,208
Cumulative Timesteps: 1,653,017,706

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1653017706...
Checkpoint 1653017706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.70715
Policy Entropy: 2.32379
Value Function Loss: 0.01428

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.52263
Value Function Update Magnitude: 0.53309

Collected Steps per Second: 22,882.62954
Overall Steps per Second: 10,672.25205

Timestep Collection Time: 2.18637
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.68786

Cumulative Model Updates: 198,214
Cumulative Timesteps: 1,653,067,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.41067
Policy Entropy: 2.31105
Value Function Loss: 0.01542

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.54718

Collected Steps per Second: 23,442.49488
Overall Steps per Second: 10,920.53072

Timestep Collection Time: 2.13296
Timestep Consumption Time: 2.44575
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.57872

Cumulative Model Updates: 198,220
Cumulative Timesteps: 1,653,117,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1653117738...
Checkpoint 1653117738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603.18197
Policy Entropy: 2.30655
Value Function Loss: 0.01541

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.55324

Collected Steps per Second: 24,099.81779
Overall Steps per Second: 11,114.30002

Timestep Collection Time: 2.07529
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.49997

Cumulative Model Updates: 198,226
Cumulative Timesteps: 1,653,167,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.21964
Policy Entropy: 2.31184
Value Function Loss: 0.01587

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.56158

Collected Steps per Second: 23,199.40252
Overall Steps per Second: 10,935.63379

Timestep Collection Time: 2.15600
Timestep Consumption Time: 2.41785
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.57385

Cumulative Model Updates: 198,232
Cumulative Timesteps: 1,653,217,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1653217770...
Checkpoint 1653217770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.26035
Policy Entropy: 2.31234
Value Function Loss: 0.01531

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.56520

Collected Steps per Second: 23,398.26856
Overall Steps per Second: 10,967.59965

Timestep Collection Time: 2.13819
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.56162

Cumulative Model Updates: 198,238
Cumulative Timesteps: 1,653,267,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.52460
Policy Entropy: 2.29809
Value Function Loss: 0.01494

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.54064
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 23,123.52583
Overall Steps per Second: 10,956.13128

Timestep Collection Time: 2.16342
Timestep Consumption Time: 2.40260
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.56603

Cumulative Model Updates: 198,244
Cumulative Timesteps: 1,653,317,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1653317826...
Checkpoint 1653317826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.48413
Policy Entropy: 2.30454
Value Function Loss: 0.01484

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.54856

Collected Steps per Second: 23,305.15403
Overall Steps per Second: 11,108.37494

Timestep Collection Time: 2.14656
Timestep Consumption Time: 2.35689
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.50345

Cumulative Model Updates: 198,250
Cumulative Timesteps: 1,653,367,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.47290
Policy Entropy: 2.31487
Value Function Loss: 0.01404

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14742
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.54245

Collected Steps per Second: 23,307.90006
Overall Steps per Second: 10,925.38610

Timestep Collection Time: 2.14520
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.57650

Cumulative Model Updates: 198,256
Cumulative Timesteps: 1,653,417,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1653417852...
Checkpoint 1653417852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.50272
Policy Entropy: 2.31211
Value Function Loss: 0.01510

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.54604

Collected Steps per Second: 23,120.19096
Overall Steps per Second: 10,740.88591

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.49260
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.65530

Cumulative Model Updates: 198,262
Cumulative Timesteps: 1,653,467,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.83672
Policy Entropy: 2.30272
Value Function Loss: 0.01511

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.54352

Collected Steps per Second: 23,222.35207
Overall Steps per Second: 10,839.37661

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.61429

Cumulative Model Updates: 198,268
Cumulative Timesteps: 1,653,517,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1653517870...
Checkpoint 1653517870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.82292
Policy Entropy: 2.30539
Value Function Loss: 0.01582

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.56258

Collected Steps per Second: 23,189.70718
Overall Steps per Second: 10,846.73446

Timestep Collection Time: 2.15691
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.61134

Cumulative Model Updates: 198,274
Cumulative Timesteps: 1,653,567,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.77717
Policy Entropy: 2.33363
Value Function Loss: 0.01451

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.15071
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.56075

Collected Steps per Second: 23,241.50558
Overall Steps per Second: 11,087.82766

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.35897
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.51107

Cumulative Model Updates: 198,280
Cumulative Timesteps: 1,653,617,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1653617906...
Checkpoint 1653617906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.01841
Policy Entropy: 2.34614
Value Function Loss: 0.01414

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.16480
Policy Update Magnitude: 0.48496
Value Function Update Magnitude: 0.53440

Collected Steps per Second: 22,896.44674
Overall Steps per Second: 10,693.36175

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.67786

Cumulative Model Updates: 198,286
Cumulative Timesteps: 1,653,667,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.14856
Policy Entropy: 2.34505
Value Function Loss: 0.01503

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.50137
Value Function Update Magnitude: 0.54242

Collected Steps per Second: 23,183.72161
Overall Steps per Second: 10,899.22247

Timestep Collection Time: 2.15712
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.58840

Cumulative Model Updates: 198,292
Cumulative Timesteps: 1,653,717,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1653717938...
Checkpoint 1653717938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.00200
Policy Entropy: 2.34113
Value Function Loss: 0.01565

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.15932
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.56056

Collected Steps per Second: 22,970.68140
Overall Steps per Second: 10,783.84717

Timestep Collection Time: 2.17860
Timestep Consumption Time: 2.46204
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.64064

Cumulative Model Updates: 198,298
Cumulative Timesteps: 1,653,767,982

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.56320
Policy Entropy: 2.33333
Value Function Loss: 0.01571

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.56718

Collected Steps per Second: 23,383.93556
Overall Steps per Second: 10,826.23365

Timestep Collection Time: 2.13865
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.61934

Cumulative Model Updates: 198,304
Cumulative Timesteps: 1,653,817,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1653817992...
Checkpoint 1653817992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.99309
Policy Entropy: 2.36031
Value Function Loss: 0.01560

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.57191

Collected Steps per Second: 22,973.49381
Overall Steps per Second: 11,035.05098

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.35535
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.53247

Cumulative Model Updates: 198,310
Cumulative Timesteps: 1,653,868,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.90178
Policy Entropy: 2.36787
Value Function Loss: 0.01395

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.53495
Value Function Update Magnitude: 0.57882

Collected Steps per Second: 23,329.75321
Overall Steps per Second: 10,928.63388

Timestep Collection Time: 2.14387
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.57660

Cumulative Model Updates: 198,316
Cumulative Timesteps: 1,653,918,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1653918024...
Checkpoint 1653918024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.72098
Policy Entropy: 2.38107
Value Function Loss: 0.01391

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.52527
Value Function Update Magnitude: 0.57580

Collected Steps per Second: 23,255.66470
Overall Steps per Second: 10,819.32747

Timestep Collection Time: 2.15027
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.62191

Cumulative Model Updates: 198,322
Cumulative Timesteps: 1,653,968,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.65025
Policy Entropy: 2.38370
Value Function Loss: 0.01453

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.53320
Value Function Update Magnitude: 0.57118

Collected Steps per Second: 23,374.75421
Overall Steps per Second: 10,854.58477

Timestep Collection Time: 2.13957
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.60745

Cumulative Model Updates: 198,328
Cumulative Timesteps: 1,654,018,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1654018042...
Checkpoint 1654018042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.93608
Policy Entropy: 2.36469
Value Function Loss: 0.01550

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.54163
Value Function Update Magnitude: 0.56363

Collected Steps per Second: 23,392.90942
Overall Steps per Second: 11,031.51116

Timestep Collection Time: 2.13749
Timestep Consumption Time: 2.39517
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.53265

Cumulative Model Updates: 198,334
Cumulative Timesteps: 1,654,068,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.74165
Policy Entropy: 2.36746
Value Function Loss: 0.01569

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.53920
Value Function Update Magnitude: 0.57814

Collected Steps per Second: 23,059.49776
Overall Steps per Second: 10,889.74877

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.59349

Cumulative Model Updates: 198,340
Cumulative Timesteps: 1,654,118,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1654118066...
Checkpoint 1654118066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.72756
Policy Entropy: 2.34637
Value Function Loss: 0.01461

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.60359

Collected Steps per Second: 23,141.28002
Overall Steps per Second: 10,785.26418

Timestep Collection Time: 2.16142
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.63762

Cumulative Model Updates: 198,346
Cumulative Timesteps: 1,654,168,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.19186
Policy Entropy: 2.36314
Value Function Loss: 0.01392

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.54157
Value Function Update Magnitude: 0.58198

Collected Steps per Second: 23,558.90086
Overall Steps per Second: 10,809.64103

Timestep Collection Time: 2.12234
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.62550

Cumulative Model Updates: 198,352
Cumulative Timesteps: 1,654,218,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1654218084...
Checkpoint 1654218084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.06062
Policy Entropy: 2.35391
Value Function Loss: 0.01433

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.55468

Collected Steps per Second: 23,115.01144
Overall Steps per Second: 10,930.06415

Timestep Collection Time: 2.16388
Timestep Consumption Time: 2.41231
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.57619

Cumulative Model Updates: 198,358
Cumulative Timesteps: 1,654,268,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.91423
Policy Entropy: 2.35302
Value Function Loss: 0.01415

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.54948

Collected Steps per Second: 23,146.97115
Overall Steps per Second: 10,950.09029

Timestep Collection Time: 2.16141
Timestep Consumption Time: 2.40751
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.56891

Cumulative Model Updates: 198,364
Cumulative Timesteps: 1,654,318,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1654318132...
Checkpoint 1654318132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.86886
Policy Entropy: 2.34382
Value Function Loss: 0.01410

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.11962
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.55558

Collected Steps per Second: 22,950.73201
Overall Steps per Second: 10,964.46472

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.38370
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.56420

Cumulative Model Updates: 198,370
Cumulative Timesteps: 1,654,368,176

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.85992
Policy Entropy: 2.33966
Value Function Loss: 0.01436

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.53690
Value Function Update Magnitude: 0.57742

Collected Steps per Second: 23,118.50341
Overall Steps per Second: 10,732.30928

Timestep Collection Time: 2.16312
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.65958

Cumulative Model Updates: 198,376
Cumulative Timesteps: 1,654,418,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1654418184...
Checkpoint 1654418184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.06299
Policy Entropy: 2.34504
Value Function Loss: 0.01481

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.59135

Collected Steps per Second: 23,404.35272
Overall Steps per Second: 10,958.52175

Timestep Collection Time: 2.13644
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.56284

Cumulative Model Updates: 198,382
Cumulative Timesteps: 1,654,468,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.90057
Policy Entropy: 2.33727
Value Function Loss: 0.01458

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.60647

Collected Steps per Second: 23,392.24488
Overall Steps per Second: 10,929.10404

Timestep Collection Time: 2.13874
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.57769

Cumulative Model Updates: 198,388
Cumulative Timesteps: 1,654,518,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1654518216...
Checkpoint 1654518216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.55838
Policy Entropy: 2.34457
Value Function Loss: 0.01416

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.60396

Collected Steps per Second: 23,160.52336
Overall Steps per Second: 10,833.96421

Timestep Collection Time: 2.15971
Timestep Consumption Time: 2.45725
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.61696

Cumulative Model Updates: 198,394
Cumulative Timesteps: 1,654,568,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.57547
Policy Entropy: 2.33035
Value Function Loss: 0.01456

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.53989
Value Function Update Magnitude: 0.58508

Collected Steps per Second: 23,466.27214
Overall Steps per Second: 11,059.99308

Timestep Collection Time: 2.13208
Timestep Consumption Time: 2.39161
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.52369

Cumulative Model Updates: 198,400
Cumulative Timesteps: 1,654,618,268

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1654618268...
Checkpoint 1654618268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.33644
Policy Entropy: 2.32366
Value Function Loss: 0.01522

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.53829
Value Function Update Magnitude: 0.56586

Collected Steps per Second: 23,141.75841
Overall Steps per Second: 10,849.65243

Timestep Collection Time: 2.16276
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.61305

Cumulative Model Updates: 198,406
Cumulative Timesteps: 1,654,668,318

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.71081
Policy Entropy: 2.30510
Value Function Loss: 0.01546

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.14964
Policy Update Magnitude: 0.52727
Value Function Update Magnitude: 0.54694

Collected Steps per Second: 23,338.73915
Overall Steps per Second: 10,940.69616

Timestep Collection Time: 2.14245
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.57028

Cumulative Model Updates: 198,412
Cumulative Timesteps: 1,654,718,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1654718320...
Checkpoint 1654718320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.19839
Policy Entropy: 2.31385
Value Function Loss: 0.01457

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.15960
Policy Update Magnitude: 0.49396
Value Function Update Magnitude: 0.52766

Collected Steps per Second: 23,176.99494
Overall Steps per Second: 10,789.36454

Timestep Collection Time: 2.15843
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.63660

Cumulative Model Updates: 198,418
Cumulative Timesteps: 1,654,768,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.58537
Policy Entropy: 2.33100
Value Function Loss: 0.01454

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.50035
Value Function Update Magnitude: 0.53350

Collected Steps per Second: 23,317.95137
Overall Steps per Second: 10,823.00006

Timestep Collection Time: 2.14487
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.62108

Cumulative Model Updates: 198,424
Cumulative Timesteps: 1,654,818,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1654818360...
Checkpoint 1654818360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.07939
Policy Entropy: 2.33341
Value Function Loss: 0.01498

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.53729
Value Function Update Magnitude: 0.55145

Collected Steps per Second: 23,221.75640
Overall Steps per Second: 11,024.39216

Timestep Collection Time: 2.15401
Timestep Consumption Time: 2.38320
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.53721

Cumulative Model Updates: 198,430
Cumulative Timesteps: 1,654,868,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.48651
Policy Entropy: 2.32308
Value Function Loss: 0.01566

Mean KL Divergence: 0.02584
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 23,375.09501
Overall Steps per Second: 10,958.59548

Timestep Collection Time: 2.13911
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.56281

Cumulative Model Updates: 198,436
Cumulative Timesteps: 1,654,918,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1654918382...
Checkpoint 1654918382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.26865
Policy Entropy: 2.28910
Value Function Loss: 0.01527

Mean KL Divergence: 0.02823
SB3 Clip Fraction: 0.18417
Policy Update Magnitude: 0.53692
Value Function Update Magnitude: 0.62140

Collected Steps per Second: 23,316.18993
Overall Steps per Second: 10,963.27033

Timestep Collection Time: 2.14555
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.56305

Cumulative Model Updates: 198,442
Cumulative Timesteps: 1,654,968,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.18702
Policy Entropy: 2.28744
Value Function Loss: 0.01529

Mean KL Divergence: 0.02471
SB3 Clip Fraction: 0.17196
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 23,212.25280
Overall Steps per Second: 10,769.48532

Timestep Collection Time: 2.15490
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.64460

Cumulative Model Updates: 198,448
Cumulative Timesteps: 1,655,018,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1655018428...
Checkpoint 1655018428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.14884
Policy Entropy: 2.29588
Value Function Loss: 0.01526

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.16948
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.59196

Collected Steps per Second: 22,955.39326
Overall Steps per Second: 10,831.73830

Timestep Collection Time: 2.17822
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.61625

Cumulative Model Updates: 198,454
Cumulative Timesteps: 1,655,068,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.48995
Policy Entropy: 2.32116
Value Function Loss: 0.01470

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.55260
Value Function Update Magnitude: 0.62004

Collected Steps per Second: 23,058.47026
Overall Steps per Second: 10,927.66586

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.57774

Cumulative Model Updates: 198,460
Cumulative Timesteps: 1,655,118,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1655118454...
Checkpoint 1655118454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.18963
Policy Entropy: 2.31198
Value Function Loss: 0.01431

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.54512
Value Function Update Magnitude: 0.60870

Collected Steps per Second: 22,603.44576
Overall Steps per Second: 10,833.76738

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.40430
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.61741

Cumulative Model Updates: 198,466
Cumulative Timesteps: 1,655,168,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.58679
Policy Entropy: 2.30522
Value Function Loss: 0.01446

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.60424

Collected Steps per Second: 23,673.33840
Overall Steps per Second: 10,895.73955

Timestep Collection Time: 2.11335
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.59170

Cumulative Model Updates: 198,472
Cumulative Timesteps: 1,655,218,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1655218508...
Checkpoint 1655218508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.29646
Policy Entropy: 2.28844
Value Function Loss: 0.01426

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.59400

Collected Steps per Second: 23,401.81257
Overall Steps per Second: 10,940.70382

Timestep Collection Time: 2.13667
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.57027

Cumulative Model Updates: 198,478
Cumulative Timesteps: 1,655,268,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.52953
Policy Entropy: 2.28831
Value Function Loss: 0.01431

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 23,168.23024
Overall Steps per Second: 10,864.94088

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.60325

Cumulative Model Updates: 198,484
Cumulative Timesteps: 1,655,318,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1655318524...
Checkpoint 1655318524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.63999
Policy Entropy: 2.28493
Value Function Loss: 0.01397

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.52979
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 23,238.31110
Overall Steps per Second: 10,884.75693

Timestep Collection Time: 2.15274
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.59597

Cumulative Model Updates: 198,490
Cumulative Timesteps: 1,655,368,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.15872
Policy Entropy: 2.30200
Value Function Loss: 0.01476

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.54629

Collected Steps per Second: 23,641.41286
Overall Steps per Second: 11,200.78678

Timestep Collection Time: 2.11561
Timestep Consumption Time: 2.34979
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.46540

Cumulative Model Updates: 198,496
Cumulative Timesteps: 1,655,418,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1655418566...
Checkpoint 1655418566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.07063
Policy Entropy: 2.29219
Value Function Loss: 0.01406

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.52611
Value Function Update Magnitude: 0.56168

Collected Steps per Second: 23,476.28983
Overall Steps per Second: 10,995.05875

Timestep Collection Time: 2.13015
Timestep Consumption Time: 2.41808
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.54822

Cumulative Model Updates: 198,502
Cumulative Timesteps: 1,655,468,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.75003
Policy Entropy: 2.27064
Value Function Loss: 0.01416

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.52684
Value Function Update Magnitude: 0.58610

Collected Steps per Second: 22,995.27714
Overall Steps per Second: 10,780.89266

Timestep Collection Time: 2.17514
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.63950

Cumulative Model Updates: 198,508
Cumulative Timesteps: 1,655,518,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1655518592...
Checkpoint 1655518592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.43388
Policy Entropy: 2.24296
Value Function Loss: 0.01322

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.15679
Policy Update Magnitude: 0.53817
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 23,039.48699
Overall Steps per Second: 10,879.02283

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.59821

Cumulative Model Updates: 198,514
Cumulative Timesteps: 1,655,568,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.70755
Policy Entropy: 2.24103
Value Function Loss: 0.01447

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.60110

Collected Steps per Second: 23,405.39405
Overall Steps per Second: 10,883.70572

Timestep Collection Time: 2.13694
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.59549

Cumulative Model Updates: 198,520
Cumulative Timesteps: 1,655,618,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1655618632...
Checkpoint 1655618632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.54803
Policy Entropy: 2.25349
Value Function Loss: 0.01426

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.60934

Collected Steps per Second: 23,362.85829
Overall Steps per Second: 11,097.60439

Timestep Collection Time: 2.14023
Timestep Consumption Time: 2.36542
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.50566

Cumulative Model Updates: 198,526
Cumulative Timesteps: 1,655,668,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.96041
Policy Entropy: 2.26233
Value Function Loss: 0.01460

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.54753
Value Function Update Magnitude: 0.61951

Collected Steps per Second: 23,227.15156
Overall Steps per Second: 10,894.58739

Timestep Collection Time: 2.15394
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.59219

Cumulative Model Updates: 198,532
Cumulative Timesteps: 1,655,718,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1655718664...
Checkpoint 1655718664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453.44335
Policy Entropy: 2.26672
Value Function Loss: 0.01575

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.61824

Collected Steps per Second: 22,974.04550
Overall Steps per Second: 10,719.85034

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.66499

Cumulative Model Updates: 198,538
Cumulative Timesteps: 1,655,768,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.48358
Policy Entropy: 2.29018
Value Function Loss: 0.01564

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.63755

Collected Steps per Second: 23,275.14686
Overall Steps per Second: 10,844.18691

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.46373
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.61298

Cumulative Model Updates: 198,544
Cumulative Timesteps: 1,655,818,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1655818696...
Checkpoint 1655818696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.56403
Policy Entropy: 2.28850
Value Function Loss: 0.01548

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.63982

Collected Steps per Second: 23,360.98172
Overall Steps per Second: 10,913.44181

Timestep Collection Time: 2.14092
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.58279

Cumulative Model Updates: 198,550
Cumulative Timesteps: 1,655,868,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.01285
Policy Entropy: 2.30581
Value Function Loss: 0.01481

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.61249

Collected Steps per Second: 22,990.15133
Overall Steps per Second: 11,057.87310

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.34710
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.52221

Cumulative Model Updates: 198,556
Cumulative Timesteps: 1,655,918,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1655918716...
Checkpoint 1655918716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.61976
Policy Entropy: 2.29383
Value Function Loss: 0.01422

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 23,255.86802
Overall Steps per Second: 10,749.65231

Timestep Collection Time: 2.15077
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.65299

Cumulative Model Updates: 198,562
Cumulative Timesteps: 1,655,968,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.62527
Policy Entropy: 2.29121
Value Function Loss: 0.01418

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.58486

Collected Steps per Second: 23,191.81841
Overall Steps per Second: 10,833.22701

Timestep Collection Time: 2.15636
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.61635

Cumulative Model Updates: 198,568
Cumulative Timesteps: 1,656,018,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1656018744...
Checkpoint 1656018744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.76467
Policy Entropy: 2.29046
Value Function Loss: 0.01447

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.58396

Collected Steps per Second: 23,211.69376
Overall Steps per Second: 10,719.26091

Timestep Collection Time: 2.15495
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66637

Cumulative Model Updates: 198,574
Cumulative Timesteps: 1,656,068,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.77713
Policy Entropy: 2.29803
Value Function Loss: 0.01515

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.54741
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 23,080.27769
Overall Steps per Second: 10,886.06080

Timestep Collection Time: 2.16739
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.59523

Cumulative Model Updates: 198,580
Cumulative Timesteps: 1,656,118,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1656118788...
Checkpoint 1656118788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.04375
Policy Entropy: 2.30155
Value Function Loss: 0.01525

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.59489

Collected Steps per Second: 22,953.89582
Overall Steps per Second: 10,798.11181

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.63062

Cumulative Model Updates: 198,586
Cumulative Timesteps: 1,656,168,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.76583
Policy Entropy: 2.31250
Value Function Loss: 0.01568

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.59942

Collected Steps per Second: 23,466.07422
Overall Steps per Second: 11,150.06727

Timestep Collection Time: 2.13244
Timestep Consumption Time: 2.35543
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.48787

Cumulative Model Updates: 198,592
Cumulative Timesteps: 1,656,218,830

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1656218830...
Checkpoint 1656218830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.30262
Policy Entropy: 2.30639
Value Function Loss: 0.01561

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.59941

Collected Steps per Second: 23,307.79094
Overall Steps per Second: 10,795.93959

Timestep Collection Time: 2.14684
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.63489

Cumulative Model Updates: 198,598
Cumulative Timesteps: 1,656,268,868

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.12736
Policy Entropy: 2.31504
Value Function Loss: 0.01535

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.54799
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 23,076.42406
Overall Steps per Second: 10,765.95158

Timestep Collection Time: 2.16732
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.64557

Cumulative Model Updates: 198,604
Cumulative Timesteps: 1,656,318,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1656318882...
Checkpoint 1656318882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.74680
Policy Entropy: 2.30759
Value Function Loss: 0.01470

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.57732

Collected Steps per Second: 23,202.95507
Overall Steps per Second: 10,730.12266

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.66146

Cumulative Model Updates: 198,610
Cumulative Timesteps: 1,656,368,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.41010
Policy Entropy: 2.29334
Value Function Loss: 0.01537

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.57357

Collected Steps per Second: 23,406.41693
Overall Steps per Second: 10,851.05159

Timestep Collection Time: 2.13719
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.61006

Cumulative Model Updates: 198,616
Cumulative Timesteps: 1,656,418,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1656418924...
Checkpoint 1656418924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.14082
Policy Entropy: 2.29419
Value Function Loss: 0.01514

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.59068

Collected Steps per Second: 23,007.92344
Overall Steps per Second: 11,063.06821

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.34675
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.52026

Cumulative Model Updates: 198,622
Cumulative Timesteps: 1,656,468,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.57122
Policy Entropy: 2.30939
Value Function Loss: 0.01552

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.60117

Collected Steps per Second: 23,298.59028
Overall Steps per Second: 10,926.41109

Timestep Collection Time: 2.14648
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.57698

Cumulative Model Updates: 198,628
Cumulative Timesteps: 1,656,518,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1656518942...
Checkpoint 1656518942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.50012
Policy Entropy: 2.31298
Value Function Loss: 0.01515

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.63155

Collected Steps per Second: 23,272.40290
Overall Steps per Second: 10,803.82250

Timestep Collection Time: 2.14881
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.62873

Cumulative Model Updates: 198,634
Cumulative Timesteps: 1,656,568,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.97222
Policy Entropy: 2.30071
Value Function Loss: 0.01513

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 23,316.34025
Overall Steps per Second: 10,818.52367

Timestep Collection Time: 2.14468
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.62226

Cumulative Model Updates: 198,640
Cumulative Timesteps: 1,656,618,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1656618956...
Checkpoint 1656618956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.66326
Policy Entropy: 2.29485
Value Function Loss: 0.01462

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.54631
Value Function Update Magnitude: 0.63695

Collected Steps per Second: 23,155.20202
Overall Steps per Second: 10,830.88419

Timestep Collection Time: 2.16029
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.61846

Cumulative Model Updates: 198,646
Cumulative Timesteps: 1,656,668,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.21762
Policy Entropy: 2.27482
Value Function Loss: 0.01554

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.63278

Collected Steps per Second: 23,590.27834
Overall Steps per Second: 11,175.13336

Timestep Collection Time: 2.12070
Timestep Consumption Time: 2.35602
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.47673

Cumulative Model Updates: 198,652
Cumulative Timesteps: 1,656,719,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1656719006...
Checkpoint 1656719006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.77861
Policy Entropy: 2.26815
Value Function Loss: 0.01533

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.60718

Collected Steps per Second: 22,929.09334
Overall Steps per Second: 10,713.64200

Timestep Collection Time: 2.18125
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.66825

Cumulative Model Updates: 198,658
Cumulative Timesteps: 1,656,769,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.40021
Policy Entropy: 2.25455
Value Function Loss: 0.01567

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.58587

Collected Steps per Second: 22,989.45802
Overall Steps per Second: 10,812.00717

Timestep Collection Time: 2.17508
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.62486

Cumulative Model Updates: 198,664
Cumulative Timesteps: 1,656,819,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1656819024...
Checkpoint 1656819024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.04818
Policy Entropy: 2.26184
Value Function Loss: 0.01482

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.57492

Collected Steps per Second: 23,139.93857
Overall Steps per Second: 10,765.59089

Timestep Collection Time: 2.16154
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.64610

Cumulative Model Updates: 198,670
Cumulative Timesteps: 1,656,869,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.65473
Policy Entropy: 2.27680
Value Function Loss: 0.01415

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 23,307.66122
Overall Steps per Second: 10,800.86524

Timestep Collection Time: 2.14539
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.62963

Cumulative Model Updates: 198,676
Cumulative Timesteps: 1,656,919,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1656919046...
Checkpoint 1656919046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.75959
Policy Entropy: 2.29751
Value Function Loss: 0.01400

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.58004

Collected Steps per Second: 23,085.98975
Overall Steps per Second: 11,107.76224

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.33657
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.50334

Cumulative Model Updates: 198,682
Cumulative Timesteps: 1,656,969,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.08690
Policy Entropy: 2.31168
Value Function Loss: 0.01385

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.53299
Value Function Update Magnitude: 0.57024

Collected Steps per Second: 23,347.75177
Overall Steps per Second: 10,897.42466

Timestep Collection Time: 2.14290
Timestep Consumption Time: 2.44827
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.59118

Cumulative Model Updates: 198,688
Cumulative Timesteps: 1,657,019,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1657019100...
Checkpoint 1657019100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.97609
Policy Entropy: 2.30816
Value Function Loss: 0.01372

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.56211

Collected Steps per Second: 23,444.54083
Overall Steps per Second: 10,887.28428

Timestep Collection Time: 2.13320
Timestep Consumption Time: 2.46041
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.59362

Cumulative Model Updates: 198,694
Cumulative Timesteps: 1,657,069,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.49992
Policy Entropy: 2.26324
Value Function Loss: 0.01383

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.53014
Value Function Update Magnitude: 0.56143

Collected Steps per Second: 23,174.99036
Overall Steps per Second: 10,763.38348

Timestep Collection Time: 2.15802
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.64649

Cumulative Model Updates: 198,700
Cumulative Timesteps: 1,657,119,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1657119124...
Checkpoint 1657119124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.08643
Policy Entropy: 2.23622
Value Function Loss: 0.01506

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.54519
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 22,968.70408
Overall Steps per Second: 10,918.08969

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.58175

Cumulative Model Updates: 198,706
Cumulative Timesteps: 1,657,169,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.93354
Policy Entropy: 2.23568
Value Function Loss: 0.01514

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.62302

Collected Steps per Second: 23,376.63236
Overall Steps per Second: 10,989.99261

Timestep Collection Time: 2.13940
Timestep Consumption Time: 2.41128
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.55069

Cumulative Model Updates: 198,712
Cumulative Timesteps: 1,657,219,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1657219160...
Checkpoint 1657219160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.34083
Policy Entropy: 2.23707
Value Function Loss: 0.01465

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 23,164.33550
Overall Steps per Second: 10,788.29688

Timestep Collection Time: 2.15875
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.63521

Cumulative Model Updates: 198,718
Cumulative Timesteps: 1,657,269,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.88776
Policy Entropy: 2.23643
Value Function Loss: 0.01478

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.61053

Collected Steps per Second: 23,345.51858
Overall Steps per Second: 10,777.85061

Timestep Collection Time: 2.14251
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.64081

Cumulative Model Updates: 198,724
Cumulative Timesteps: 1,657,319,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1657319184...
Checkpoint 1657319184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.85494
Policy Entropy: 2.24785
Value Function Loss: 0.01462

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.60837

Collected Steps per Second: 23,235.05452
Overall Steps per Second: 10,806.94677

Timestep Collection Time: 2.15313
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.62924

Cumulative Model Updates: 198,730
Cumulative Timesteps: 1,657,369,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.80395
Policy Entropy: 2.26354
Value Function Loss: 0.01516

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.60551

Collected Steps per Second: 23,290.70278
Overall Steps per Second: 10,824.96899

Timestep Collection Time: 2.14755
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.62061

Cumulative Model Updates: 198,736
Cumulative Timesteps: 1,657,419,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1657419230...
Checkpoint 1657419230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.54274
Policy Entropy: 2.27290
Value Function Loss: 0.01550

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,961.71824
Overall Steps per Second: 11,012.18042

Timestep Collection Time: 2.17815
Timestep Consumption Time: 2.36355
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.54170

Cumulative Model Updates: 198,742
Cumulative Timesteps: 1,657,469,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.76940
Policy Entropy: 2.27830
Value Function Loss: 0.01547

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.60933

Collected Steps per Second: 23,435.87261
Overall Steps per Second: 10,973.68947

Timestep Collection Time: 2.13485
Timestep Consumption Time: 2.42442
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.55927

Cumulative Model Updates: 198,748
Cumulative Timesteps: 1,657,519,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1657519276...
Checkpoint 1657519276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.07570
Policy Entropy: 2.28981
Value Function Loss: 0.01498

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 23,248.16750
Overall Steps per Second: 10,811.18341

Timestep Collection Time: 2.15208
Timestep Consumption Time: 2.47572
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.62780

Cumulative Model Updates: 198,754
Cumulative Timesteps: 1,657,569,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.06462
Policy Entropy: 2.28357
Value Function Loss: 0.01434

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.59374

Collected Steps per Second: 23,488.99820
Overall Steps per Second: 10,929.86356

Timestep Collection Time: 2.12934
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.57609

Cumulative Model Updates: 198,760
Cumulative Timesteps: 1,657,619,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1657619324...
Checkpoint 1657619324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.01054
Policy Entropy: 2.28621
Value Function Loss: 0.01404

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.59619

Collected Steps per Second: 23,193.89110
Overall Steps per Second: 10,954.11503

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.40924
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.56541

Cumulative Model Updates: 198,766
Cumulative Timesteps: 1,657,669,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.44517
Policy Entropy: 2.26124
Value Function Loss: 0.01459

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.60980

Collected Steps per Second: 23,209.05221
Overall Steps per Second: 10,822.15812

Timestep Collection Time: 2.15476
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.62107

Cumulative Model Updates: 198,772
Cumulative Timesteps: 1,657,719,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1657719344...
Checkpoint 1657719344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.67711
Policy Entropy: 2.26557
Value Function Loss: 0.01457

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.60292

Collected Steps per Second: 23,206.76134
Overall Steps per Second: 10,733.28608

Timestep Collection Time: 2.15454
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.65841

Cumulative Model Updates: 198,778
Cumulative Timesteps: 1,657,769,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.26322
Policy Entropy: 2.25014
Value Function Loss: 0.01520

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.58765

Collected Steps per Second: 23,298.13353
Overall Steps per Second: 10,810.53020

Timestep Collection Time: 2.14695
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.62697

Cumulative Model Updates: 198,784
Cumulative Timesteps: 1,657,819,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1657819364...
Checkpoint 1657819364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567.15310
Policy Entropy: 2.25787
Value Function Loss: 0.01481

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.58570

Collected Steps per Second: 23,122.56016
Overall Steps per Second: 10,855.64962

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.60627

Cumulative Model Updates: 198,790
Cumulative Timesteps: 1,657,869,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.03599
Policy Entropy: 2.24508
Value Function Loss: 0.01491

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.63496

Collected Steps per Second: 23,535.81937
Overall Steps per Second: 11,033.87073

Timestep Collection Time: 2.12578
Timestep Consumption Time: 2.40862
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.53440

Cumulative Model Updates: 198,796
Cumulative Timesteps: 1,657,919,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1657919400...
Checkpoint 1657919400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.91726
Policy Entropy: 2.27885
Value Function Loss: 0.01470

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 23,866.14919
Overall Steps per Second: 10,980.48973

Timestep Collection Time: 2.09611
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.55590

Cumulative Model Updates: 198,802
Cumulative Timesteps: 1,657,969,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.11679
Policy Entropy: 2.27939
Value Function Loss: 0.01499

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 23,623.84872
Overall Steps per Second: 10,919.51658

Timestep Collection Time: 2.11769
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.58152

Cumulative Model Updates: 198,808
Cumulative Timesteps: 1,658,019,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1658019454...
Checkpoint 1658019454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.96533
Policy Entropy: 2.30154
Value Function Loss: 0.01494

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.53643
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 23,428.69957
Overall Steps per Second: 10,870.33837

Timestep Collection Time: 2.13431
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.60004

Cumulative Model Updates: 198,814
Cumulative Timesteps: 1,658,069,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.74896
Policy Entropy: 2.27337
Value Function Loss: 0.01410

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.53108
Value Function Update Magnitude: 0.60116

Collected Steps per Second: 22,661.07721
Overall Steps per Second: 10,848.75564

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.40384
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61159

Cumulative Model Updates: 198,820
Cumulative Timesteps: 1,658,119,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1658119488...
Checkpoint 1658119488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.86872
Policy Entropy: 2.30533
Value Function Loss: 0.01459

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.56949

Collected Steps per Second: 23,182.31366
Overall Steps per Second: 11,123.71617

Timestep Collection Time: 2.15759
Timestep Consumption Time: 2.33893
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.49652

Cumulative Model Updates: 198,826
Cumulative Timesteps: 1,658,169,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.99637
Policy Entropy: 2.29135
Value Function Loss: 0.01582

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.57481

Collected Steps per Second: 23,617.00912
Overall Steps per Second: 10,993.93030

Timestep Collection Time: 2.11771
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.54924

Cumulative Model Updates: 198,832
Cumulative Timesteps: 1,658,219,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1658219520...
Checkpoint 1658219520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.85939
Policy Entropy: 2.30060
Value Function Loss: 0.01656

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.59170

Collected Steps per Second: 23,374.27837
Overall Steps per Second: 10,828.21158

Timestep Collection Time: 2.13927
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.61794

Cumulative Model Updates: 198,838
Cumulative Timesteps: 1,658,269,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.42113
Policy Entropy: 2.28824
Value Function Loss: 0.01557

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.60540

Collected Steps per Second: 23,292.16307
Overall Steps per Second: 10,768.36682

Timestep Collection Time: 2.14682
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.64360

Cumulative Model Updates: 198,844
Cumulative Timesteps: 1,658,319,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1658319528...
Checkpoint 1658319528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.74117
Policy Entropy: 2.31970
Value Function Loss: 0.01513

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 23,291.16121
Overall Steps per Second: 10,954.11598

Timestep Collection Time: 2.14760
Timestep Consumption Time: 2.41872
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.56632

Cumulative Model Updates: 198,850
Cumulative Timesteps: 1,658,369,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.75289
Policy Entropy: 2.31280
Value Function Loss: 0.01486

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.60482

Collected Steps per Second: 23,578.04213
Overall Steps per Second: 10,979.89276

Timestep Collection Time: 2.12155
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.55578

Cumulative Model Updates: 198,856
Cumulative Timesteps: 1,658,419,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1658419570...
Checkpoint 1658419570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.86812
Policy Entropy: 2.29655
Value Function Loss: 0.01654

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.61202

Collected Steps per Second: 23,372.84905
Overall Steps per Second: 10,851.25529

Timestep Collection Time: 2.13975
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.60887

Cumulative Model Updates: 198,862
Cumulative Timesteps: 1,658,469,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.71659
Policy Entropy: 2.27097
Value Function Loss: 0.01690

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.15723
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.64057

Collected Steps per Second: 23,493.10808
Overall Steps per Second: 10,803.98172

Timestep Collection Time: 2.12871
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.62885

Cumulative Model Updates: 198,868
Cumulative Timesteps: 1,658,519,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1658519592...
Checkpoint 1658519592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.69832
Policy Entropy: 2.26550
Value Function Loss: 0.01823

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.66216

Collected Steps per Second: 23,118.03744
Overall Steps per Second: 10,782.88516

Timestep Collection Time: 2.16316
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.63772

Cumulative Model Updates: 198,874
Cumulative Timesteps: 1,658,569,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.59469
Policy Entropy: 2.24347
Value Function Loss: 0.01697

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.66513

Collected Steps per Second: 23,243.46711
Overall Steps per Second: 10,877.86218

Timestep Collection Time: 2.15157
Timestep Consumption Time: 2.44584
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.59741

Cumulative Model Updates: 198,880
Cumulative Timesteps: 1,658,619,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1658619610...
Checkpoint 1658619610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.72237
Policy Entropy: 2.24493
Value Function Loss: 0.01666

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.63510

Collected Steps per Second: 23,572.92082
Overall Steps per Second: 11,058.68782

Timestep Collection Time: 2.12159
Timestep Consumption Time: 2.40083
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.52242

Cumulative Model Updates: 198,886
Cumulative Timesteps: 1,658,669,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.66853
Policy Entropy: 2.26486
Value Function Loss: 0.01582

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.17995
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.61999

Collected Steps per Second: 23,316.60852
Overall Steps per Second: 10,745.89092

Timestep Collection Time: 2.14474
Timestep Consumption Time: 2.50895
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.65369

Cumulative Model Updates: 198,892
Cumulative Timesteps: 1,658,719,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1658719630...
Checkpoint 1658719630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.28739
Policy Entropy: 2.29628
Value Function Loss: 0.01670

Mean KL Divergence: 0.02903
SB3 Clip Fraction: 0.17769
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.64012

Collected Steps per Second: 23,149.76327
Overall Steps per Second: 10,710.17545

Timestep Collection Time: 2.15985
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.66846

Cumulative Model Updates: 198,898
Cumulative Timesteps: 1,658,769,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.07991
Policy Entropy: 2.29582
Value Function Loss: 0.01667

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 23,182.01361
Overall Steps per Second: 10,883.96533

Timestep Collection Time: 2.15771
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.59575

Cumulative Model Updates: 198,904
Cumulative Timesteps: 1,658,819,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1658819650...
Checkpoint 1658819650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459.29205
Policy Entropy: 2.27375
Value Function Loss: 0.01779

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.65865

Collected Steps per Second: 23,147.26983
Overall Steps per Second: 10,965.43866

Timestep Collection Time: 2.16112
Timestep Consumption Time: 2.40085
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.56197

Cumulative Model Updates: 198,910
Cumulative Timesteps: 1,658,869,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.96796
Policy Entropy: 2.28269
Value Function Loss: 0.01716

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.57089
Value Function Update Magnitude: 0.66702

Collected Steps per Second: 23,320.59882
Overall Steps per Second: 10,981.46962

Timestep Collection Time: 2.14420
Timestep Consumption Time: 2.40929
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.55349

Cumulative Model Updates: 198,916
Cumulative Timesteps: 1,658,919,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1658919678...
Checkpoint 1658919678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.34234
Policy Entropy: 2.31740
Value Function Loss: 0.01631

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.65593

Collected Steps per Second: 23,847.38740
Overall Steps per Second: 11,092.06729

Timestep Collection Time: 2.09675
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.50791

Cumulative Model Updates: 198,922
Cumulative Timesteps: 1,658,969,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.15134
Policy Entropy: 2.32567
Value Function Loss: 0.01611

Mean KL Divergence: 0.03224
SB3 Clip Fraction: 0.19741
Policy Update Magnitude: 0.52897
Value Function Update Magnitude: 0.63201

Collected Steps per Second: 23,262.54685
Overall Steps per Second: 10,895.43909

Timestep Collection Time: 2.15050
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.59146

Cumulative Model Updates: 198,928
Cumulative Timesteps: 1,659,019,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1659019706...
Checkpoint 1659019706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.75327
Policy Entropy: 2.33200
Value Function Loss: 0.01626

Mean KL Divergence: 0.02557
SB3 Clip Fraction: 0.17152
Policy Update Magnitude: 0.54419
Value Function Update Magnitude: 0.64414

Collected Steps per Second: 23,298.32766
Overall Steps per Second: 10,770.74363

Timestep Collection Time: 2.14831
Timestep Consumption Time: 2.49872
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.64703

Cumulative Model Updates: 198,934
Cumulative Timesteps: 1,659,069,758

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.39382
Policy Entropy: 2.30660
Value Function Loss: 0.01614

Mean KL Divergence: 0.02819
SB3 Clip Fraction: 0.18177
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.67392

Collected Steps per Second: 22,877.51897
Overall Steps per Second: 10,828.23320

Timestep Collection Time: 2.18643
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.61941

Cumulative Model Updates: 198,940
Cumulative Timesteps: 1,659,119,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1659119778...
Checkpoint 1659119778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.69438
Policy Entropy: 2.32799
Value Function Loss: 0.01711

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.18256
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.67277

Collected Steps per Second: 23,149.61092
Overall Steps per Second: 11,094.30650

Timestep Collection Time: 2.16168
Timestep Consumption Time: 2.34892
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.51060

Cumulative Model Updates: 198,946
Cumulative Timesteps: 1,659,169,820

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.50165
Policy Entropy: 2.31199
Value Function Loss: 0.01601

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.17369
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.65389

Collected Steps per Second: 23,115.10010
Overall Steps per Second: 10,875.13648

Timestep Collection Time: 2.16387
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59930

Cumulative Model Updates: 198,952
Cumulative Timesteps: 1,659,219,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1659219838...
Checkpoint 1659219838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.69786
Policy Entropy: 2.33710
Value Function Loss: 0.01565

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.54149
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 23,037.57875
Overall Steps per Second: 10,702.03959

Timestep Collection Time: 2.17054
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.67238

Cumulative Model Updates: 198,958
Cumulative Timesteps: 1,659,269,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.05935
Policy Entropy: 2.35396
Value Function Loss: 0.01449

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.52069
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 23,191.49047
Overall Steps per Second: 10,897.62114

Timestep Collection Time: 2.15596
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58816

Cumulative Model Updates: 198,964
Cumulative Timesteps: 1,659,319,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1659319842...
Checkpoint 1659319842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.66608
Policy Entropy: 2.35480
Value Function Loss: 0.01592

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.52946
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 23,180.96625
Overall Steps per Second: 10,838.46258

Timestep Collection Time: 2.15815
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.61578

Cumulative Model Updates: 198,970
Cumulative Timesteps: 1,659,369,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.86261
Policy Entropy: 2.31449
Value Function Loss: 0.01673

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.53364
Value Function Update Magnitude: 0.64414

Collected Steps per Second: 23,457.26231
Overall Steps per Second: 10,887.88448

Timestep Collection Time: 2.13273
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.59483

Cumulative Model Updates: 198,976
Cumulative Timesteps: 1,659,419,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1659419898...
Checkpoint 1659419898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.56857
Policy Entropy: 2.28041
Value Function Loss: 0.01695

Mean KL Divergence: 0.02878
SB3 Clip Fraction: 0.18688
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.63992

Collected Steps per Second: 23,366.45777
Overall Steps per Second: 10,934.58367

Timestep Collection Time: 2.14119
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.57557

Cumulative Model Updates: 198,982
Cumulative Timesteps: 1,659,469,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.27433
Policy Entropy: 2.26874
Value Function Loss: 0.01552

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.17034
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.64027

Collected Steps per Second: 23,155.48577
Overall Steps per Second: 10,875.94965

Timestep Collection Time: 2.16035
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.59951

Cumulative Model Updates: 198,988
Cumulative Timesteps: 1,659,519,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1659519954...
Checkpoint 1659519954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.00895
Policy Entropy: 2.32720
Value Function Loss: 0.01364

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.53855
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 23,008.94153
Overall Steps per Second: 10,674.65770

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.68699

Cumulative Model Updates: 198,994
Cumulative Timesteps: 1,659,569,986

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.67093
Policy Entropy: 2.34122
Value Function Loss: 0.01363

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.53616
Value Function Update Magnitude: 0.57598

Collected Steps per Second: 23,223.53582
Overall Steps per Second: 10,885.46216

Timestep Collection Time: 2.15316
Timestep Consumption Time: 2.44049
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.59365

Cumulative Model Updates: 199,000
Cumulative Timesteps: 1,659,619,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1659619990...
Checkpoint 1659619990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.16998
Policy Entropy: 2.32962
Value Function Loss: 0.01317

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.58184

Collected Steps per Second: 23,129.65085
Overall Steps per Second: 10,813.95375

Timestep Collection Time: 2.16173
Timestep Consumption Time: 2.46193
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.62366

Cumulative Model Updates: 199,006
Cumulative Timesteps: 1,659,669,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.13232
Policy Entropy: 2.30880
Value Function Loss: 0.01376

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.53382
Value Function Update Magnitude: 0.59581

Collected Steps per Second: 23,468.44121
Overall Steps per Second: 11,135.86242

Timestep Collection Time: 2.13171
Timestep Consumption Time: 2.36080
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.49251

Cumulative Model Updates: 199,012
Cumulative Timesteps: 1,659,720,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1659720018...
Checkpoint 1659720018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716.28734
Policy Entropy: 2.32064
Value Function Loss: 0.01362

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 23,101.47056
Overall Steps per Second: 10,754.57945

Timestep Collection Time: 2.16532
Timestep Consumption Time: 2.48591
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.65123

Cumulative Model Updates: 199,018
Cumulative Timesteps: 1,659,770,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.09751
Policy Entropy: 2.32005
Value Function Loss: 0.01455

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.58116

Collected Steps per Second: 23,355.37012
Overall Steps per Second: 10,912.26501

Timestep Collection Time: 2.14195
Timestep Consumption Time: 2.44243
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.58438

Cumulative Model Updates: 199,024
Cumulative Timesteps: 1,659,820,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1659820066...
Checkpoint 1659820066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 634.85814
Policy Entropy: 2.32533
Value Function Loss: 0.01499

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.58326

Collected Steps per Second: 23,149.69047
Overall Steps per Second: 10,719.67954

Timestep Collection Time: 2.16124
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.66730

Cumulative Model Updates: 199,030
Cumulative Timesteps: 1,659,870,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.43238
Policy Entropy: 2.31581
Value Function Loss: 0.01471

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.57972

Collected Steps per Second: 22,810.04315
Overall Steps per Second: 10,869.73107

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.40839
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.60085

Cumulative Model Updates: 199,036
Cumulative Timesteps: 1,659,920,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1659920108...
Checkpoint 1659920108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.99110
Policy Entropy: 2.32413
Value Function Loss: 0.01399

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.56136

Collected Steps per Second: 22,989.53476
Overall Steps per Second: 11,042.61646

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.35414
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.53009

Cumulative Model Updates: 199,042
Cumulative Timesteps: 1,659,970,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.95794
Policy Entropy: 2.30624
Value Function Loss: 0.01431

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 23,350.18434
Overall Steps per Second: 10,973.18624

Timestep Collection Time: 2.14242
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.55893

Cumulative Model Updates: 199,048
Cumulative Timesteps: 1,660,020,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1660020158...
Checkpoint 1660020158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.14554
Policy Entropy: 2.33432
Value Function Loss: 0.01416

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.58185

Collected Steps per Second: 23,211.38215
Overall Steps per Second: 10,801.44376

Timestep Collection Time: 2.15480
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.63049

Cumulative Model Updates: 199,054
Cumulative Timesteps: 1,660,070,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.38881
Policy Entropy: 2.33551
Value Function Loss: 0.01576

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.58402

Collected Steps per Second: 23,026.36727
Overall Steps per Second: 10,737.68317

Timestep Collection Time: 2.17247
Timestep Consumption Time: 2.48627
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.65873

Cumulative Model Updates: 199,060
Cumulative Timesteps: 1,660,120,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1660120198...
Checkpoint 1660120198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.96421
Policy Entropy: 2.33144
Value Function Loss: 0.01528

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.54418
Value Function Update Magnitude: 0.57174

Collected Steps per Second: 23,089.94415
Overall Steps per Second: 10,836.25635

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.61599

Cumulative Model Updates: 199,066
Cumulative Timesteps: 1,660,170,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.73081
Policy Entropy: 2.29835
Value Function Loss: 0.01524

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.54049
Value Function Update Magnitude: 0.55198

Collected Steps per Second: 23,441.85434
Overall Steps per Second: 11,117.25846

Timestep Collection Time: 2.13311
Timestep Consumption Time: 2.36476
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.49787

Cumulative Model Updates: 199,072
Cumulative Timesteps: 1,660,220,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1660220222...
Checkpoint 1660220222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.15450
Policy Entropy: 2.30388
Value Function Loss: 0.01462

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 23,248.68535
Overall Steps per Second: 10,768.74828

Timestep Collection Time: 2.15118
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.64418

Cumulative Model Updates: 199,078
Cumulative Timesteps: 1,660,270,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.08943
Policy Entropy: 2.31946
Value Function Loss: 0.01493

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.17389
Policy Update Magnitude: 0.50302
Value Function Update Magnitude: 0.57314

Collected Steps per Second: 23,325.00715
Overall Steps per Second: 10,847.41345

Timestep Collection Time: 2.14388
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.60995

Cumulative Model Updates: 199,084
Cumulative Timesteps: 1,660,320,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1660320240...
Checkpoint 1660320240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.97483
Policy Entropy: 2.37135
Value Function Loss: 0.01462

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 23,235.26162
Overall Steps per Second: 10,840.77526

Timestep Collection Time: 2.15242
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.61332

Cumulative Model Updates: 199,090
Cumulative Timesteps: 1,660,370,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.34642
Policy Entropy: 2.36734
Value Function Loss: 0.01539

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.53201
Value Function Update Magnitude: 0.55129

Collected Steps per Second: 23,062.48937
Overall Steps per Second: 10,732.72149

Timestep Collection Time: 2.16811
Timestep Consumption Time: 2.49073
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.65884

Cumulative Model Updates: 199,096
Cumulative Timesteps: 1,660,420,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1660420254...
Checkpoint 1660420254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456.96004
Policy Entropy: 2.35018
Value Function Loss: 0.01473

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.53079
Value Function Update Magnitude: 0.56306

Collected Steps per Second: 23,271.72838
Overall Steps per Second: 11,073.57739

Timestep Collection Time: 2.14870
Timestep Consumption Time: 2.36691
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.51561

Cumulative Model Updates: 199,102
Cumulative Timesteps: 1,660,470,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.44934
Policy Entropy: 2.31132
Value Function Loss: 0.01560

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.59301

Collected Steps per Second: 23,218.01179
Overall Steps per Second: 10,955.94750

Timestep Collection Time: 2.15393
Timestep Consumption Time: 2.41071
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.56464

Cumulative Model Updates: 199,108
Cumulative Timesteps: 1,660,520,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1660520268...
Checkpoint 1660520268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.59488
Policy Entropy: 2.29666
Value Function Loss: 0.01541

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 23,112.10243
Overall Steps per Second: 10,779.27673

Timestep Collection Time: 2.16475
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.64150

Cumulative Model Updates: 199,114
Cumulative Timesteps: 1,660,570,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.03415
Policy Entropy: 2.27520
Value Function Loss: 0.01486

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.60391

Collected Steps per Second: 23,399.39847
Overall Steps per Second: 10,893.85861

Timestep Collection Time: 2.13732
Timestep Consumption Time: 2.45352
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.59084

Cumulative Model Updates: 199,120
Cumulative Timesteps: 1,660,620,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1660620312...
Checkpoint 1660620312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.99693
Policy Entropy: 2.26614
Value Function Loss: 0.01518

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 23,419.73673
Overall Steps per Second: 10,953.69320

Timestep Collection Time: 2.13546
Timestep Consumption Time: 2.43030
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.56577

Cumulative Model Updates: 199,126
Cumulative Timesteps: 1,660,670,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.90235
Policy Entropy: 2.27295
Value Function Loss: 0.01571

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 24,007.94862
Overall Steps per Second: 10,935.78004

Timestep Collection Time: 2.08298
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.57288

Cumulative Model Updates: 199,132
Cumulative Timesteps: 1,660,720,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1660720332...
Checkpoint 1660720332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.94008
Policy Entropy: 2.29877
Value Function Loss: 0.01586

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.61047

Collected Steps per Second: 23,060.44677
Overall Steps per Second: 10,800.15433

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.46233
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.63142

Cumulative Model Updates: 199,138
Cumulative Timesteps: 1,660,770,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.95091
Policy Entropy: 2.31528
Value Function Loss: 0.01549

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.60206

Collected Steps per Second: 23,501.56614
Overall Steps per Second: 10,775.40999

Timestep Collection Time: 2.12896
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.64335

Cumulative Model Updates: 199,144
Cumulative Timesteps: 1,660,820,386

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1660820386...
Checkpoint 1660820386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.61404
Policy Entropy: 2.33669
Value Function Loss: 0.01404

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.52651
Value Function Update Magnitude: 0.58596

Collected Steps per Second: 23,292.91353
Overall Steps per Second: 10,977.18014

Timestep Collection Time: 2.14752
Timestep Consumption Time: 2.40939
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.55691

Cumulative Model Updates: 199,150
Cumulative Timesteps: 1,660,870,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.25232
Policy Entropy: 2.34524
Value Function Loss: 0.01328

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.50991
Value Function Update Magnitude: 0.55743

Collected Steps per Second: 23,413.46526
Overall Steps per Second: 10,980.07029

Timestep Collection Time: 2.13604
Timestep Consumption Time: 2.41876
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.55480

Cumulative Model Updates: 199,156
Cumulative Timesteps: 1,660,920,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1660920420...
Checkpoint 1660920420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.64176
Policy Entropy: 2.32335
Value Function Loss: 0.01328

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.50736
Value Function Update Magnitude: 0.52505

Collected Steps per Second: 23,216.78996
Overall Steps per Second: 10,831.39043

Timestep Collection Time: 2.15413
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.61732

Cumulative Model Updates: 199,162
Cumulative Timesteps: 1,660,970,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.32579
Policy Entropy: 2.30658
Value Function Loss: 0.01483

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.52077
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 23,650.45149
Overall Steps per Second: 10,874.70066

Timestep Collection Time: 2.11472
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.59912

Cumulative Model Updates: 199,168
Cumulative Timesteps: 1,661,020,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1661020446...
Checkpoint 1661020446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.54651
Policy Entropy: 2.30390
Value Function Loss: 0.01505

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.53301
Value Function Update Magnitude: 0.58408

Collected Steps per Second: 22,847.43516
Overall Steps per Second: 10,898.13461

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.39990
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.58868

Cumulative Model Updates: 199,174
Cumulative Timesteps: 1,661,070,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.56850
Policy Entropy: 2.30613
Value Function Loss: 0.01440

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.56184

Collected Steps per Second: 23,205.37270
Overall Steps per Second: 10,971.55584

Timestep Collection Time: 2.15554
Timestep Consumption Time: 2.40353
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.55906

Cumulative Model Updates: 199,180
Cumulative Timesteps: 1,661,120,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1661120474...
Checkpoint 1661120474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.34281
Policy Entropy: 2.31479
Value Function Loss: 0.01429

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.54586

Collected Steps per Second: 23,300.75843
Overall Steps per Second: 10,855.95184

Timestep Collection Time: 2.14611
Timestep Consumption Time: 2.46021
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.60632

Cumulative Model Updates: 199,186
Cumulative Timesteps: 1,661,170,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.19866
Policy Entropy: 2.30222
Value Function Loss: 0.01480

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 23,743.50745
Overall Steps per Second: 10,944.07974

Timestep Collection Time: 2.10626
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.56959

Cumulative Model Updates: 199,192
Cumulative Timesteps: 1,661,220,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1661220490...
Checkpoint 1661220490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.92649
Policy Entropy: 2.30804
Value Function Loss: 0.01563

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.54967

Collected Steps per Second: 23,131.58296
Overall Steps per Second: 10,851.13671

Timestep Collection Time: 2.16163
Timestep Consumption Time: 2.44636
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.60800

Cumulative Model Updates: 199,198
Cumulative Timesteps: 1,661,270,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.21225
Policy Entropy: 2.28992
Value Function Loss: 0.01522

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.53393
Value Function Update Magnitude: 0.54338

Collected Steps per Second: 22,903.77553
Overall Steps per Second: 10,885.36855

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.41163
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59589

Cumulative Model Updates: 199,204
Cumulative Timesteps: 1,661,320,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1661320520...
Checkpoint 1661320520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.53308
Policy Entropy: 2.30050
Value Function Loss: 0.01454

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.52645
Value Function Update Magnitude: 0.54447

Collected Steps per Second: 23,203.09427
Overall Steps per Second: 11,147.71679

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.33052
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.48558

Cumulative Model Updates: 199,210
Cumulative Timesteps: 1,661,370,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.79777
Policy Entropy: 2.28447
Value Function Loss: 0.01398

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.55716

Collected Steps per Second: 23,437.51758
Overall Steps per Second: 10,892.39551

Timestep Collection Time: 2.13350
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.59073

Cumulative Model Updates: 199,216
Cumulative Timesteps: 1,661,420,528

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1661420528...
Checkpoint 1661420528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.06277
Policy Entropy: 2.28887
Value Function Loss: 0.01457

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.56956

Collected Steps per Second: 23,213.84296
Overall Steps per Second: 10,766.85194

Timestep Collection Time: 2.15415
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.64444

Cumulative Model Updates: 199,222
Cumulative Timesteps: 1,661,470,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.53698
Policy Entropy: 2.27399
Value Function Loss: 0.01491

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 23,396.98877
Overall Steps per Second: 10,795.72237

Timestep Collection Time: 2.13857
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.63480

Cumulative Model Updates: 199,228
Cumulative Timesteps: 1,661,520,570

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1661520570...
Checkpoint 1661520570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.79581
Policy Entropy: 2.28156
Value Function Loss: 0.01532

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.57371

Collected Steps per Second: 23,253.37417
Overall Steps per Second: 11,008.25939

Timestep Collection Time: 2.15040
Timestep Consumption Time: 2.39201
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.54241

Cumulative Model Updates: 199,234
Cumulative Timesteps: 1,661,570,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.71566
Policy Entropy: 2.28613
Value Function Loss: 0.01556

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.58837

Collected Steps per Second: 22,717.41166
Overall Steps per Second: 10,947.99102

Timestep Collection Time: 2.20219
Timestep Consumption Time: 2.36742
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.56961

Cumulative Model Updates: 199,240
Cumulative Timesteps: 1,661,620,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1661620602...
Checkpoint 1661620602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.32766
Policy Entropy: 2.29048
Value Function Loss: 0.01564

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 23,189.93594
Overall Steps per Second: 10,743.88369

Timestep Collection Time: 2.15723
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.65623

Cumulative Model Updates: 199,246
Cumulative Timesteps: 1,661,670,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.25042
Policy Entropy: 2.28846
Value Function Loss: 0.01633

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.54463
Value Function Update Magnitude: 0.59416

Collected Steps per Second: 22,969.27915
Overall Steps per Second: 10,902.26426

Timestep Collection Time: 2.17778
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.58822

Cumulative Model Updates: 199,252
Cumulative Timesteps: 1,661,720,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1661720650...
Checkpoint 1661720650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.09961
Policy Entropy: 2.29097
Value Function Loss: 0.01618

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.54145
Value Function Update Magnitude: 0.58466

Collected Steps per Second: 23,067.76242
Overall Steps per Second: 10,832.55462

Timestep Collection Time: 2.16813
Timestep Consumption Time: 2.44887
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.61701

Cumulative Model Updates: 199,258
Cumulative Timesteps: 1,661,770,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.40757
Policy Entropy: 2.31104
Value Function Loss: 0.01584

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.60465

Collected Steps per Second: 23,430.59824
Overall Steps per Second: 11,136.04094

Timestep Collection Time: 2.13464
Timestep Consumption Time: 2.35672
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.49136

Cumulative Model Updates: 199,264
Cumulative Timesteps: 1,661,820,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1661820680...
Checkpoint 1661820680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.04550
Policy Entropy: 2.30467
Value Function Loss: 0.01541

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 23,286.17046
Overall Steps per Second: 10,809.69198

Timestep Collection Time: 2.14720
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.62548

Cumulative Model Updates: 199,270
Cumulative Timesteps: 1,661,870,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.45112
Policy Entropy: 2.29403
Value Function Loss: 0.01544

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 23,691.03571
Overall Steps per Second: 10,902.76712

Timestep Collection Time: 2.11168
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.58856

Cumulative Model Updates: 199,276
Cumulative Timesteps: 1,661,920,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1661920708...
Checkpoint 1661920708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.76212
Policy Entropy: 2.28842
Value Function Loss: 0.01467

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.60901

Collected Steps per Second: 23,244.76394
Overall Steps per Second: 10,903.36120

Timestep Collection Time: 2.15111
Timestep Consumption Time: 2.43482
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.58593

Cumulative Model Updates: 199,282
Cumulative Timesteps: 1,661,970,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.68889
Policy Entropy: 2.29790
Value Function Loss: 0.01510

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.15522
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.57880

Collected Steps per Second: 23,130.91784
Overall Steps per Second: 10,905.35864

Timestep Collection Time: 2.16256
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.58692

Cumulative Model Updates: 199,288
Cumulative Timesteps: 1,662,020,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1662020732...
Checkpoint 1662020732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.00491
Policy Entropy: 2.30378
Value Function Loss: 0.01449

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.56333

Collected Steps per Second: 23,272.42697
Overall Steps per Second: 11,079.83180

Timestep Collection Time: 2.14864
Timestep Consumption Time: 2.36443
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.51306

Cumulative Model Updates: 199,294
Cumulative Timesteps: 1,662,070,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.49237
Policy Entropy: 2.29811
Value Function Loss: 0.01480

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.56044

Collected Steps per Second: 23,469.39020
Overall Steps per Second: 10,938.42674

Timestep Collection Time: 2.13112
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.57250

Cumulative Model Updates: 199,300
Cumulative Timesteps: 1,662,120,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1662120752...
Checkpoint 1662120752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.80196
Policy Entropy: 2.30881
Value Function Loss: 0.01479

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 23,193.57634
Overall Steps per Second: 10,757.23134

Timestep Collection Time: 2.15603
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.64859

Cumulative Model Updates: 199,306
Cumulative Timesteps: 1,662,170,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.74809
Policy Entropy: 2.31903
Value Function Loss: 0.01578

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.56185

Collected Steps per Second: 23,552.92065
Overall Steps per Second: 10,838.60940

Timestep Collection Time: 2.12415
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.61591

Cumulative Model Updates: 199,312
Cumulative Timesteps: 1,662,220,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1662220788...
Checkpoint 1662220788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.05170
Policy Entropy: 2.31765
Value Function Loss: 0.01516

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.55750

Collected Steps per Second: 23,155.07371
Overall Steps per Second: 10,858.86284

Timestep Collection Time: 2.15987
Timestep Consumption Time: 2.44577
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.60564

Cumulative Model Updates: 199,318
Cumulative Timesteps: 1,662,270,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.40247
Policy Entropy: 2.32274
Value Function Loss: 0.01599

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.56249

Collected Steps per Second: 23,400.34607
Overall Steps per Second: 11,144.29038

Timestep Collection Time: 2.13792
Timestep Consumption Time: 2.35120
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.48911

Cumulative Model Updates: 199,324
Cumulative Timesteps: 1,662,320,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1662320828...
Checkpoint 1662320828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.34673
Policy Entropy: 2.29699
Value Function Loss: 0.01619

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.59006

Collected Steps per Second: 23,221.08986
Overall Steps per Second: 10,793.87267

Timestep Collection Time: 2.15339
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.63263

Cumulative Model Updates: 199,330
Cumulative Timesteps: 1,662,370,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.19510
Policy Entropy: 2.28476
Value Function Loss: 0.01754

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.57097
Value Function Update Magnitude: 0.61805

Collected Steps per Second: 23,575.18600
Overall Steps per Second: 10,756.57633

Timestep Collection Time: 2.12223
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.65129

Cumulative Model Updates: 199,336
Cumulative Timesteps: 1,662,420,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1662420864...
Checkpoint 1662420864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502.43374
Policy Entropy: 2.30219
Value Function Loss: 0.01634

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.62780

Collected Steps per Second: 23,091.27880
Overall Steps per Second: 10,807.66166

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.62690

Cumulative Model Updates: 199,342
Cumulative Timesteps: 1,662,470,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.01005
Policy Entropy: 2.31392
Value Function Loss: 0.01524

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.55137
Value Function Update Magnitude: 0.60988

Collected Steps per Second: 23,221.09572
Overall Steps per Second: 10,783.99311

Timestep Collection Time: 2.15382
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.63780

Cumulative Model Updates: 199,348
Cumulative Timesteps: 1,662,520,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1662520884...
Checkpoint 1662520884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.17443
Policy Entropy: 2.31836
Value Function Loss: 0.01543

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.57088

Collected Steps per Second: 23,034.35772
Overall Steps per Second: 11,111.44735

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.32966
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.50076

Cumulative Model Updates: 199,354
Cumulative Timesteps: 1,662,570,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.89988
Policy Entropy: 2.30587
Value Function Loss: 0.01509

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.56741

Collected Steps per Second: 23,501.36067
Overall Steps per Second: 10,870.43127

Timestep Collection Time: 2.12822
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.60111

Cumulative Model Updates: 199,360
Cumulative Timesteps: 1,662,620,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1662620910...
Checkpoint 1662620910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.36179
Policy Entropy: 2.31652
Value Function Loss: 0.01541

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.57106

Collected Steps per Second: 23,108.40798
Overall Steps per Second: 10,736.23882

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.49421
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.65861

Cumulative Model Updates: 199,366
Cumulative Timesteps: 1,662,670,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.32372
Policy Entropy: 2.33168
Value Function Loss: 0.01456

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.54751
Value Function Update Magnitude: 0.56602

Collected Steps per Second: 23,342.05245
Overall Steps per Second: 10,843.39578

Timestep Collection Time: 2.14257
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.61221

Cumulative Model Updates: 199,372
Cumulative Timesteps: 1,662,720,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1662720938...
Checkpoint 1662720938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 616.83373
Policy Entropy: 2.32913
Value Function Loss: 0.01551

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 23,382.35348
Overall Steps per Second: 10,988.06899

Timestep Collection Time: 2.13854
Timestep Consumption Time: 2.41222
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.55075

Cumulative Model Updates: 199,378
Cumulative Timesteps: 1,662,770,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.60147
Policy Entropy: 2.32739
Value Function Loss: 0.01515

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.56110

Collected Steps per Second: 23,164.49999
Overall Steps per Second: 11,069.95197

Timestep Collection Time: 2.15968
Timestep Consumption Time: 2.35958
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.51926

Cumulative Model Updates: 199,384
Cumulative Timesteps: 1,662,820,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1662820970...
Checkpoint 1662820970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.19284
Policy Entropy: 2.31768
Value Function Loss: 0.01557

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.16048
Policy Update Magnitude: 0.52042
Value Function Update Magnitude: 0.56982

Collected Steps per Second: 23,367.35300
Overall Steps per Second: 10,939.64764

Timestep Collection Time: 2.14085
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.57291

Cumulative Model Updates: 199,390
Cumulative Timesteps: 1,662,870,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.66281
Policy Entropy: 2.30327
Value Function Loss: 0.01559

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.18550
Policy Update Magnitude: 0.50100
Value Function Update Magnitude: 0.60304

Collected Steps per Second: 23,236.49154
Overall Steps per Second: 10,798.74268

Timestep Collection Time: 2.15222
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.63109

Cumulative Model Updates: 199,396
Cumulative Timesteps: 1,662,921,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1662921006...
Checkpoint 1662921006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.29554
Policy Entropy: 2.30322
Value Function Loss: 0.01564

Mean KL Divergence: 0.02870
SB3 Clip Fraction: 0.18286
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.60082

Collected Steps per Second: 22,853.25696
Overall Steps per Second: 10,930.58454

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.38674
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.57487

Cumulative Model Updates: 199,402
Cumulative Timesteps: 1,662,971,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.39648
Policy Entropy: 2.31984
Value Function Loss: 0.01541

Mean KL Divergence: 0.02730
SB3 Clip Fraction: 0.18078
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 23,318.02561
Overall Steps per Second: 10,852.05232

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.60853

Cumulative Model Updates: 199,408
Cumulative Timesteps: 1,663,021,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1663021024...
Checkpoint 1663021024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.44892
Policy Entropy: 2.33845
Value Function Loss: 0.01495

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 23,248.92451
Overall Steps per Second: 11,156.30645

Timestep Collection Time: 2.15193
Timestep Consumption Time: 2.33253
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.48446

Cumulative Model Updates: 199,414
Cumulative Timesteps: 1,663,071,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 833.14621
Policy Entropy: 2.34986
Value Function Loss: 0.01533

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.56345

Collected Steps per Second: 23,216.51004
Overall Steps per Second: 10,898.40036

Timestep Collection Time: 2.15459
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.58985

Cumulative Model Updates: 199,420
Cumulative Timesteps: 1,663,121,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1663121076...
Checkpoint 1663121076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.13618
Policy Entropy: 2.34599
Value Function Loss: 0.01534

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 23,239.02599
Overall Steps per Second: 10,819.25576

Timestep Collection Time: 2.15284
Timestep Consumption Time: 2.47132
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.62416

Cumulative Model Updates: 199,426
Cumulative Timesteps: 1,663,171,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.93745
Policy Entropy: 2.32965
Value Function Loss: 0.01508

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 23,206.91260
Overall Steps per Second: 10,809.58860

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.47129
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.62608

Cumulative Model Updates: 199,432
Cumulative Timesteps: 1,663,221,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1663221112...
Checkpoint 1663221112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.17866
Policy Entropy: 2.33519
Value Function Loss: 0.01520

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.56638

Collected Steps per Second: 23,179.19522
Overall Steps per Second: 11,006.20126

Timestep Collection Time: 2.15719
Timestep Consumption Time: 2.38588
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.54308

Cumulative Model Updates: 199,438
Cumulative Timesteps: 1,663,271,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.66453
Policy Entropy: 2.31846
Value Function Loss: 0.01474

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.53387
Value Function Update Magnitude: 0.56143

Collected Steps per Second: 23,463.52331
Overall Steps per Second: 10,893.74742

Timestep Collection Time: 2.13105
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.58997

Cumulative Model Updates: 199,444
Cumulative Timesteps: 1,663,321,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1663321116...
Checkpoint 1663321116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.70360
Policy Entropy: 2.33652
Value Function Loss: 0.01469

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.56062

Collected Steps per Second: 22,850.58174
Overall Steps per Second: 10,619.14974

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.52035
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.70847

Cumulative Model Updates: 199,450
Cumulative Timesteps: 1,663,371,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.95626
Policy Entropy: 2.31210
Value Function Loss: 0.01359

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.52641
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 23,188.58533
Overall Steps per Second: 10,937.25635

Timestep Collection Time: 2.15692
Timestep Consumption Time: 2.41607
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.57299

Cumulative Model Updates: 199,456
Cumulative Timesteps: 1,663,421,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1663421132...
Checkpoint 1663421132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.78981
Policy Entropy: 2.28755
Value Function Loss: 0.01413

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.54584

Collected Steps per Second: 23,102.27257
Overall Steps per Second: 10,817.07715

Timestep Collection Time: 2.16472
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.62325

Cumulative Model Updates: 199,462
Cumulative Timesteps: 1,663,471,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.63338
Policy Entropy: 2.27501
Value Function Loss: 0.01399

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.55346

Collected Steps per Second: 23,435.49893
Overall Steps per Second: 11,132.16251

Timestep Collection Time: 2.13480
Timestep Consumption Time: 2.35939
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.49419

Cumulative Model Updates: 199,468
Cumulative Timesteps: 1,663,521,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1663521172...
Checkpoint 1663521172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.96131
Policy Entropy: 2.27966
Value Function Loss: 0.01434

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.54398

Collected Steps per Second: 22,978.95399
Overall Steps per Second: 10,697.16322

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.67470

Cumulative Model Updates: 199,474
Cumulative Timesteps: 1,663,571,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.68328
Policy Entropy: 2.31331
Value Function Loss: 0.01433

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.53968
Value Function Update Magnitude: 0.54485

Collected Steps per Second: 23,365.78893
Overall Steps per Second: 10,983.73789

Timestep Collection Time: 2.14108
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.55473

Cumulative Model Updates: 199,480
Cumulative Timesteps: 1,663,621,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1663621206...
Checkpoint 1663621206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.30349
Policy Entropy: 2.32464
Value Function Loss: 0.01483

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.55789

Collected Steps per Second: 23,138.17756
Overall Steps per Second: 10,971.50322

Timestep Collection Time: 2.16145
Timestep Consumption Time: 2.39691
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.55835

Cumulative Model Updates: 199,486
Cumulative Timesteps: 1,663,671,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.67355
Policy Entropy: 2.32585
Value Function Loss: 0.01500

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 23,446.52144
Overall Steps per Second: 11,023.06278

Timestep Collection Time: 2.13294
Timestep Consumption Time: 2.40391
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.53685

Cumulative Model Updates: 199,492
Cumulative Timesteps: 1,663,721,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1663721228...
Checkpoint 1663721228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.78002
Policy Entropy: 2.30466
Value Function Loss: 0.01439

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 22,941.20631
Overall Steps per Second: 10,994.23481

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.36902
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.54911

Cumulative Model Updates: 199,498
Cumulative Timesteps: 1,663,771,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.59301
Policy Entropy: 2.30678
Value Function Loss: 0.01386

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 23,230.43525
Overall Steps per Second: 10,941.72553

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.41770
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.57039

Cumulative Model Updates: 199,504
Cumulative Timesteps: 1,663,821,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1663821250...
Checkpoint 1663821250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.02519
Policy Entropy: 2.32830
Value Function Loss: 0.01369

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.60173

Collected Steps per Second: 23,010.77745
Overall Steps per Second: 10,711.42626

Timestep Collection Time: 2.17368
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.66959

Cumulative Model Updates: 199,510
Cumulative Timesteps: 1,663,871,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.17308
Policy Entropy: 2.33029
Value Function Loss: 0.01405

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.60192

Collected Steps per Second: 23,277.85731
Overall Steps per Second: 10,941.82927

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.42311
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.57236

Cumulative Model Updates: 199,516
Cumulative Timesteps: 1,663,921,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1663921298...
Checkpoint 1663921298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.22365
Policy Entropy: 2.30128
Value Function Loss: 0.01448

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.57115

Collected Steps per Second: 22,804.13018
Overall Steps per Second: 10,751.51374

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.65200

Cumulative Model Updates: 199,522
Cumulative Timesteps: 1,663,971,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.20977
Policy Entropy: 2.27383
Value Function Loss: 0.01493

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.53665
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 23,301.41857
Overall Steps per Second: 11,127.55071

Timestep Collection Time: 2.14605
Timestep Consumption Time: 2.34784
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.49389

Cumulative Model Updates: 199,528
Cumulative Timesteps: 1,664,021,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1664021320...
Checkpoint 1664021320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.69675
Policy Entropy: 2.27946
Value Function Loss: 0.01430

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.53134
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 23,004.62186
Overall Steps per Second: 10,725.36461

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.66241

Cumulative Model Updates: 199,534
Cumulative Timesteps: 1,664,071,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.30296
Policy Entropy: 2.25766
Value Function Loss: 0.01418

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.55521

Collected Steps per Second: 23,616.39732
Overall Steps per Second: 10,894.40997

Timestep Collection Time: 2.11751
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.59024

Cumulative Model Updates: 199,540
Cumulative Timesteps: 1,664,121,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1664121334...
Checkpoint 1664121334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.38650
Policy Entropy: 2.28790
Value Function Loss: 0.01449

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.56662

Collected Steps per Second: 23,095.58516
Overall Steps per Second: 10,824.85260

Timestep Collection Time: 2.16544
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.62011

Cumulative Model Updates: 199,546
Cumulative Timesteps: 1,664,171,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.09373
Policy Entropy: 2.29530
Value Function Loss: 0.01452

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.55555

Collected Steps per Second: 23,291.45712
Overall Steps per Second: 10,801.73141

Timestep Collection Time: 2.14680
Timestep Consumption Time: 2.48228
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.62907

Cumulative Model Updates: 199,552
Cumulative Timesteps: 1,664,221,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1664221348...
Checkpoint 1664221348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.61129
Policy Entropy: 2.32813
Value Function Loss: 0.01496

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.52684
Value Function Update Magnitude: 0.55587

Collected Steps per Second: 23,192.88465
Overall Steps per Second: 11,060.12699

Timestep Collection Time: 2.15713
Timestep Consumption Time: 2.36633
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.52346

Cumulative Model Updates: 199,558
Cumulative Timesteps: 1,664,271,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.50527
Policy Entropy: 2.30555
Value Function Loss: 0.01542

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 23,282.51412
Overall Steps per Second: 10,906.98209

Timestep Collection Time: 2.14753
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.58422

Cumulative Model Updates: 199,564
Cumulative Timesteps: 1,664,321,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1664321378...
Checkpoint 1664321378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.99985
Policy Entropy: 2.27626
Value Function Loss: 0.01514

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.53582
Value Function Update Magnitude: 0.56396

Collected Steps per Second: 23,013.13887
Overall Steps per Second: 10,744.54044

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.65371

Cumulative Model Updates: 199,570
Cumulative Timesteps: 1,664,371,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.76911
Policy Entropy: 2.27067
Value Function Loss: 0.01447

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.55306

Collected Steps per Second: 23,565.78854
Overall Steps per Second: 10,807.12818

Timestep Collection Time: 2.12197
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.62713

Cumulative Model Updates: 199,576
Cumulative Timesteps: 1,664,421,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1664421386...
Checkpoint 1664421386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.02467
Policy Entropy: 2.26475
Value Function Loss: 0.01407

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.53465
Value Function Update Magnitude: 0.54391

Collected Steps per Second: 23,135.74829
Overall Steps per Second: 10,175.26090

Timestep Collection Time: 2.16176
Timestep Consumption Time: 2.75349
PPO Batch Consumption Time: 0.34052
Total Iteration Time: 4.91525

Cumulative Model Updates: 199,582
Cumulative Timesteps: 1,664,471,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.91012
Policy Entropy: 2.27853
Value Function Loss: 0.01415

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.54263

Collected Steps per Second: 14,363.12223
Overall Steps per Second: 7,856.55538

Timestep Collection Time: 3.48156
Timestep Consumption Time: 2.88332
PPO Batch Consumption Time: 0.32409
Total Iteration Time: 6.36488

Cumulative Model Updates: 199,588
Cumulative Timesteps: 1,664,521,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1664521406...
Checkpoint 1664521406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.12916
Policy Entropy: 2.27122
Value Function Loss: 0.01496

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.54230

Collected Steps per Second: 14,226.79559
Overall Steps per Second: 8,115.94265

Timestep Collection Time: 3.51492
Timestep Consumption Time: 2.64654
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 6.16145

Cumulative Model Updates: 199,594
Cumulative Timesteps: 1,664,571,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.93311
Policy Entropy: 2.28294
Value Function Loss: 0.01445

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.55074

Collected Steps per Second: 20,544.60537
Overall Steps per Second: 10,147.52353

Timestep Collection Time: 2.43470
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.92928

Cumulative Model Updates: 199,600
Cumulative Timesteps: 1,664,621,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1664621432...
Checkpoint 1664621432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530.67502
Policy Entropy: 2.28892
Value Function Loss: 0.01433

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.55210

Collected Steps per Second: 22,212.73378
Overall Steps per Second: 10,591.56809

Timestep Collection Time: 2.25186
Timestep Consumption Time: 2.47076
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.72262

Cumulative Model Updates: 199,606
Cumulative Timesteps: 1,664,671,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.07641
Policy Entropy: 2.30410
Value Function Loss: 0.01431

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.52469
Value Function Update Magnitude: 0.53235

Collected Steps per Second: 21,755.39217
Overall Steps per Second: 10,289.26288

Timestep Collection Time: 2.29948
Timestep Consumption Time: 2.56249
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.86196

Cumulative Model Updates: 199,612
Cumulative Timesteps: 1,664,721,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1664721478...
Checkpoint 1664721478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.71058
Policy Entropy: 2.30105
Value Function Loss: 0.01440

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.16940
Policy Update Magnitude: 0.51583
Value Function Update Magnitude: 0.53234

Collected Steps per Second: 22,859.44445
Overall Steps per Second: 10,835.57910

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.61554

Cumulative Model Updates: 199,618
Cumulative Timesteps: 1,664,771,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.53870
Policy Entropy: 2.28943
Value Function Loss: 0.01476

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.53049
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 23,246.61660
Overall Steps per Second: 10,967.16903

Timestep Collection Time: 2.15102
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.55943

Cumulative Model Updates: 199,624
Cumulative Timesteps: 1,664,821,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1664821494...
Checkpoint 1664821494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479.50960
Policy Entropy: 2.28739
Value Function Loss: 0.01521

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.53779
Value Function Update Magnitude: 0.58161

Collected Steps per Second: 22,602.33236
Overall Steps per Second: 10,631.25059

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70424

Cumulative Model Updates: 199,630
Cumulative Timesteps: 1,664,871,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.29268
Policy Entropy: 2.31699
Value Function Loss: 0.01510

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 22,672.93335
Overall Steps per Second: 10,612.23085

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71399

Cumulative Model Updates: 199,636
Cumulative Timesteps: 1,664,921,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1664921532...
Checkpoint 1664921532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529.27885
Policy Entropy: 2.32436
Value Function Loss: 0.01551

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.52808
Value Function Update Magnitude: 0.57475

Collected Steps per Second: 22,199.91467
Overall Steps per Second: 10,549.24315

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.73987

Cumulative Model Updates: 199,642
Cumulative Timesteps: 1,664,971,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.66078
Policy Entropy: 2.31446
Value Function Loss: 0.01600

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.53402
Value Function Update Magnitude: 0.58138

Collected Steps per Second: 22,365.68698
Overall Steps per Second: 10,875.12244

Timestep Collection Time: 2.23727
Timestep Consumption Time: 2.36388
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60114

Cumulative Model Updates: 199,648
Cumulative Timesteps: 1,665,021,572

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1665021572...
Checkpoint 1665021572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.30972
Policy Entropy: 2.30644
Value Function Loss: 0.01696

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.59502

Collected Steps per Second: 23,299.83696
Overall Steps per Second: 10,743.74811

Timestep Collection Time: 2.14602
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.65406

Cumulative Model Updates: 199,654
Cumulative Timesteps: 1,665,071,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.20153
Policy Entropy: 2.28163
Value Function Loss: 0.01679

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.59881

Collected Steps per Second: 22,890.08493
Overall Steps per Second: 10,798.86228

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.63067

Cumulative Model Updates: 199,660
Cumulative Timesteps: 1,665,121,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1665121580...
Checkpoint 1665121580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606.02078
Policy Entropy: 2.26694
Value Function Loss: 0.01601

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.54375
Value Function Update Magnitude: 0.59447

Collected Steps per Second: 22,698.02014
Overall Steps per Second: 10,578.80358

Timestep Collection Time: 2.20284
Timestep Consumption Time: 2.52360
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.72643

Cumulative Model Updates: 199,666
Cumulative Timesteps: 1,665,171,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.25028
Policy Entropy: 2.23147
Value Function Loss: 0.01582

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.59367

Collected Steps per Second: 22,639.90570
Overall Steps per Second: 10,888.20970

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.38468
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.59414

Cumulative Model Updates: 199,672
Cumulative Timesteps: 1,665,221,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1665221602...
Checkpoint 1665221602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.84485
Policy Entropy: 2.24244
Value Function Loss: 0.01611

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.60105

Collected Steps per Second: 22,464.62468
Overall Steps per Second: 10,683.65709

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.45540
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.68210

Cumulative Model Updates: 199,678
Cumulative Timesteps: 1,665,271,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.41978
Policy Entropy: 2.25558
Value Function Loss: 0.01666

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.61287

Collected Steps per Second: 22,483.79148
Overall Steps per Second: 10,565.66235

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.73439

Cumulative Model Updates: 199,684
Cumulative Timesteps: 1,665,321,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1665321646...
Checkpoint 1665321646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.54637
Policy Entropy: 2.27313
Value Function Loss: 0.01554

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.59471

Collected Steps per Second: 22,245.28930
Overall Steps per Second: 10,504.01016

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.51272
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.76066

Cumulative Model Updates: 199,690
Cumulative Timesteps: 1,665,371,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.39384
Policy Entropy: 2.27521
Value Function Loss: 0.01492

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 20,878.87083
Overall Steps per Second: 9,835.45596

Timestep Collection Time: 2.39601
Timestep Consumption Time: 2.69028
PPO Batch Consumption Time: 0.32604
Total Iteration Time: 5.08629

Cumulative Model Updates: 199,696
Cumulative Timesteps: 1,665,421,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1665421678...
Checkpoint 1665421678 saved!
