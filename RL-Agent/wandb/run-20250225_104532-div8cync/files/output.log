Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.65538
Policy Entropy: 3.74785
Value Function Loss: 0.06981

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00690
Policy Update Magnitude: 0.20999
Value Function Update Magnitude: 0.20903

Collected Steps per Second: 16,754.52639
Overall Steps per Second: 11,226.57427

Timestep Collection Time: 2.98582
Timestep Consumption Time: 1.47021
PPO Batch Consumption Time: 0.36710
Total Iteration Time: 4.45603

Cumulative Model Updates: 79,546
Cumulative Timesteps: 663,364,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.13264
Policy Entropy: 3.74028
Value Function Loss: 0.06919

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.51633
Value Function Update Magnitude: 0.43043

Collected Steps per Second: 20,207.64394
Overall Steps per Second: 11,562.10538

Timestep Collection Time: 2.47580
Timestep Consumption Time: 1.85127
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.32707

Cumulative Model Updates: 79,550
Cumulative Timesteps: 663,414,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 663414036...
Checkpoint 663414036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.38236
Policy Entropy: 3.72959
Value Function Loss: 0.06768

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.82578
Value Function Update Magnitude: 0.63198

Collected Steps per Second: 20,441.90915
Overall Steps per Second: 10,356.66232

Timestep Collection Time: 2.44674
Timestep Consumption Time: 2.38262
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.82936

Cumulative Model Updates: 79,556
Cumulative Timesteps: 663,464,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.00348
Policy Entropy: 3.72389
Value Function Loss: 0.06933

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.73046
Value Function Update Magnitude: 0.65612

Collected Steps per Second: 21,618.97034
Overall Steps per Second: 10,335.91923

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.52562
PPO Batch Consumption Time: 0.30739
Total Iteration Time: 4.83924

Cumulative Model Updates: 79,562
Cumulative Timesteps: 663,514,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 663514070...
Checkpoint 663514070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.44391
Policy Entropy: 3.71973
Value Function Loss: 0.07028

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 21,032.58279
Overall Steps per Second: 10,360.01562

Timestep Collection Time: 2.37736
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.82644

Cumulative Model Updates: 79,568
Cumulative Timesteps: 663,564,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.92258
Policy Entropy: 3.71545
Value Function Loss: 0.07043

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.53066
Value Function Update Magnitude: 0.57621

Collected Steps per Second: 21,610.41104
Overall Steps per Second: 10,466.59314

Timestep Collection Time: 2.31500
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.77978

Cumulative Model Updates: 79,574
Cumulative Timesteps: 663,614,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 663614100...
Checkpoint 663614100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,475.75686
Policy Entropy: 3.70967
Value Function Loss: 0.07349

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.60191

Collected Steps per Second: 21,357.23600
Overall Steps per Second: 10,362.80378

Timestep Collection Time: 2.34234
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.82746

Cumulative Model Updates: 79,580
Cumulative Timesteps: 663,664,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,565.29457
Policy Entropy: 3.71665
Value Function Loss: 0.07355

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.63758

Collected Steps per Second: 22,491.49712
Overall Steps per Second: 10,788.32265

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.63687

Cumulative Model Updates: 79,586
Cumulative Timesteps: 663,714,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 663714150...
Checkpoint 663714150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,395.70779
Policy Entropy: 3.72456
Value Function Loss: 0.07491

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 22,057.77664
Overall Steps per Second: 10,544.50531

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.47553
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.74275

Cumulative Model Updates: 79,592
Cumulative Timesteps: 663,764,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,666.72902
Policy Entropy: 3.73442
Value Function Loss: 0.07480

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.64222

Collected Steps per Second: 22,362.98479
Overall Steps per Second: 10,561.23661

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.73486

Cumulative Model Updates: 79,598
Cumulative Timesteps: 663,814,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 663814166...
Checkpoint 663814166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.14956
Policy Entropy: 3.73931
Value Function Loss: 0.07348

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.59981
Value Function Update Magnitude: 0.61590

Collected Steps per Second: 22,124.79729
Overall Steps per Second: 10,504.04524

Timestep Collection Time: 2.26018
Timestep Consumption Time: 2.50046
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.76064

Cumulative Model Updates: 79,604
Cumulative Timesteps: 663,864,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,329.04611
Policy Entropy: 3.73616
Value Function Loss: 0.07118

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.63205
Value Function Update Magnitude: 0.63794

Collected Steps per Second: 22,430.17942
Overall Steps per Second: 10,557.84891

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.73828

Cumulative Model Updates: 79,610
Cumulative Timesteps: 663,914,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 663914198...
Checkpoint 663914198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.37214
Policy Entropy: 3.73035
Value Function Loss: 0.06862

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.65360
Value Function Update Magnitude: 0.64131

Collected Steps per Second: 22,163.06833
Overall Steps per Second: 10,572.11692

Timestep Collection Time: 2.25709
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.73169

Cumulative Model Updates: 79,616
Cumulative Timesteps: 663,964,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,204.92160
Policy Entropy: 3.72774
Value Function Loss: 0.06619

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.65390
Value Function Update Magnitude: 0.72862

Collected Steps per Second: 22,469.92656
Overall Steps per Second: 10,541.03236

Timestep Collection Time: 2.22618
Timestep Consumption Time: 2.51928
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.74546

Cumulative Model Updates: 79,622
Cumulative Timesteps: 664,014,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 664014244...
Checkpoint 664014244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,603.90172
Policy Entropy: 3.71609
Value Function Loss: 0.06524

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.61962
Value Function Update Magnitude: 0.77967

Collected Steps per Second: 22,386.39288
Overall Steps per Second: 10,566.37761

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.49919
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.73332

Cumulative Model Updates: 79,628
Cumulative Timesteps: 664,064,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,717.54747
Policy Entropy: 3.71798
Value Function Loss: 0.06518

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.77213

Collected Steps per Second: 22,166.45212
Overall Steps per Second: 10,437.47386

Timestep Collection Time: 2.25692
Timestep Consumption Time: 2.53619
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.79311

Cumulative Model Updates: 79,634
Cumulative Timesteps: 664,114,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 664114286...
Checkpoint 664114286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.26244
Policy Entropy: 3.71392
Value Function Loss: 0.06716

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.58620
Value Function Update Magnitude: 0.76778

Collected Steps per Second: 22,203.41647
Overall Steps per Second: 10,433.01824

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.54098
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.79324

Cumulative Model Updates: 79,640
Cumulative Timesteps: 664,164,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,900.49165
Policy Entropy: 3.71632
Value Function Loss: 0.06567

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.60358
Value Function Update Magnitude: 0.73195

Collected Steps per Second: 22,652.64471
Overall Steps per Second: 10,649.93315

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.69656

Cumulative Model Updates: 79,646
Cumulative Timesteps: 664,214,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 664214312...
Checkpoint 664214312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,785.07737
Policy Entropy: 3.72155
Value Function Loss: 0.06330

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.64465
Value Function Update Magnitude: 0.73233

Collected Steps per Second: 21,843.48631
Overall Steps per Second: 10,565.09084

Timestep Collection Time: 2.28993
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.73446

Cumulative Model Updates: 79,652
Cumulative Timesteps: 664,264,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.28323
Policy Entropy: 3.73890
Value Function Loss: 0.06064

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.69738
Value Function Update Magnitude: 0.79963

Collected Steps per Second: 22,262.30359
Overall Steps per Second: 10,538.51788

Timestep Collection Time: 2.24721
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.74716

Cumulative Model Updates: 79,658
Cumulative Timesteps: 664,314,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 664314360...
Checkpoint 664314360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.23194
Policy Entropy: 3.72665
Value Function Loss: 0.06255

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.75281
Value Function Update Magnitude: 0.79609

Collected Steps per Second: 21,941.96620
Overall Steps per Second: 10,556.34402

Timestep Collection Time: 2.28011
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.73933

Cumulative Model Updates: 79,664
Cumulative Timesteps: 664,364,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,735.93206
Policy Entropy: 3.72477
Value Function Loss: 0.06351

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.74674
Value Function Update Magnitude: 0.79470

Collected Steps per Second: 21,905.96143
Overall Steps per Second: 10,528.59443

Timestep Collection Time: 2.28312
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.75030

Cumulative Model Updates: 79,670
Cumulative Timesteps: 664,414,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 664414404...
Checkpoint 664414404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.26126
Policy Entropy: 3.72851
Value Function Loss: 0.06418

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.71076
Value Function Update Magnitude: 0.76068

Collected Steps per Second: 22,268.42342
Overall Steps per Second: 10,623.96381

Timestep Collection Time: 2.24578
Timestep Consumption Time: 2.46150
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.70728

Cumulative Model Updates: 79,676
Cumulative Timesteps: 664,464,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.10636
Policy Entropy: 3.72392
Value Function Loss: 0.06387

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.73166
Value Function Update Magnitude: 0.73578

Collected Steps per Second: 22,230.76146
Overall Steps per Second: 10,523.63027

Timestep Collection Time: 2.24923
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.75140

Cumulative Model Updates: 79,682
Cumulative Timesteps: 664,514,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 664514416...
Checkpoint 664514416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.55816
Policy Entropy: 3.70635
Value Function Loss: 0.06635

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.74882
Value Function Update Magnitude: 0.76057

Collected Steps per Second: 22,160.15980
Overall Steps per Second: 10,646.86527

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.69904

Cumulative Model Updates: 79,688
Cumulative Timesteps: 664,564,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,433.06098
Policy Entropy: 3.68933
Value Function Loss: 0.06918

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.68963
Value Function Update Magnitude: 0.77056

Collected Steps per Second: 22,385.95234
Overall Steps per Second: 10,500.56639

Timestep Collection Time: 2.23488
Timestep Consumption Time: 2.52962
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.76450

Cumulative Model Updates: 79,694
Cumulative Timesteps: 664,614,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 664614476...
Checkpoint 664614476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.10114
Policy Entropy: 3.69504
Value Function Loss: 0.06842

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.59146
Value Function Update Magnitude: 0.74730

Collected Steps per Second: 22,354.14553
Overall Steps per Second: 10,516.35390

Timestep Collection Time: 2.23699
Timestep Consumption Time: 2.51808
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.75507

Cumulative Model Updates: 79,700
Cumulative Timesteps: 664,664,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,966.86984
Policy Entropy: 3.69233
Value Function Loss: 0.06792

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.75152

Collected Steps per Second: 22,558.26123
Overall Steps per Second: 10,528.99973

Timestep Collection Time: 2.21755
Timestep Consumption Time: 2.53352
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75107

Cumulative Model Updates: 79,706
Cumulative Timesteps: 664,714,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 664714506...
Checkpoint 664714506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,470.97534
Policy Entropy: 3.69344
Value Function Loss: 0.06937

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.54006
Value Function Update Magnitude: 0.80949

Collected Steps per Second: 22,074.00566
Overall Steps per Second: 10,631.09984

Timestep Collection Time: 2.26529
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.70356

Cumulative Model Updates: 79,712
Cumulative Timesteps: 664,764,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,307.81945
Policy Entropy: 3.69809
Value Function Loss: 0.06946

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.50395
Value Function Update Magnitude: 0.81346

Collected Steps per Second: 22,751.74169
Overall Steps per Second: 10,623.94128

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.70805

Cumulative Model Updates: 79,718
Cumulative Timesteps: 664,814,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 664814528...
Checkpoint 664814528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.33830
Policy Entropy: 3.72035
Value Function Loss: 0.06573

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.50196
Value Function Update Magnitude: 0.72255

Collected Steps per Second: 22,164.64248
Overall Steps per Second: 10,433.84144

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.53747
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.79440

Cumulative Model Updates: 79,724
Cumulative Timesteps: 664,864,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.29142
Policy Entropy: 3.71998
Value Function Loss: 0.06327

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.59567
Value Function Update Magnitude: 0.75060

Collected Steps per Second: 22,423.37295
Overall Steps per Second: 10,512.34771

Timestep Collection Time: 2.23089
Timestep Consumption Time: 2.52771
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.75859

Cumulative Model Updates: 79,730
Cumulative Timesteps: 664,914,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 664914576...
Checkpoint 664914576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.34463
Policy Entropy: 3.71411
Value Function Loss: 0.06302

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.66569
Value Function Update Magnitude: 0.76194

Collected Steps per Second: 22,267.10979
Overall Steps per Second: 10,573.48863

Timestep Collection Time: 2.24645
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.73089

Cumulative Model Updates: 79,736
Cumulative Timesteps: 664,964,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.93710
Policy Entropy: 3.69136
Value Function Loss: 0.06224

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.66613
Value Function Update Magnitude: 0.79066

Collected Steps per Second: 22,474.92634
Overall Steps per Second: 10,473.03019

Timestep Collection Time: 2.22541
Timestep Consumption Time: 2.55028
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.77570

Cumulative Model Updates: 79,742
Cumulative Timesteps: 665,014,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 665014614...
Checkpoint 665014614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,589.07012
Policy Entropy: 3.68668
Value Function Loss: 0.06264

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.52096
Value Function Update Magnitude: 0.80551

Collected Steps per Second: 21,971.76450
Overall Steps per Second: 10,568.20014

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.45700
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.73401

Cumulative Model Updates: 79,748
Cumulative Timesteps: 665,064,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.73726
Policy Entropy: 3.68452
Value Function Loss: 0.06386

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.47716
Value Function Update Magnitude: 0.83154

Collected Steps per Second: 22,501.60850
Overall Steps per Second: 10,547.30779

Timestep Collection Time: 2.22242
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.74130

Cumulative Model Updates: 79,754
Cumulative Timesteps: 665,114,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 665114652...
Checkpoint 665114652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.00474
Policy Entropy: 3.67790
Value Function Loss: 0.06647

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.46040
Value Function Update Magnitude: 0.83746

Collected Steps per Second: 22,160.41254
Overall Steps per Second: 10,605.15884

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.71733

Cumulative Model Updates: 79,760
Cumulative Timesteps: 665,164,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.12817
Policy Entropy: 3.67986
Value Function Loss: 0.06741

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.47288
Value Function Update Magnitude: 0.83108

Collected Steps per Second: 22,379.90138
Overall Steps per Second: 10,472.19321

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.54060
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.77493

Cumulative Model Updates: 79,766
Cumulative Timesteps: 665,214,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 665214684...
Checkpoint 665214684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,240.83690
Policy Entropy: 3.68065
Value Function Loss: 0.06852

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.47220
Value Function Update Magnitude: 0.82974

Collected Steps per Second: 22,044.60225
Overall Steps per Second: 10,594.96314

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.71979

Cumulative Model Updates: 79,772
Cumulative Timesteps: 665,264,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,423.52009
Policy Entropy: 3.68980
Value Function Loss: 0.06967

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.46706
Value Function Update Magnitude: 0.83440

Collected Steps per Second: 22,200.54576
Overall Steps per Second: 10,495.06141

Timestep Collection Time: 2.25283
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.76548

Cumulative Model Updates: 79,778
Cumulative Timesteps: 665,314,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 665314704...
Checkpoint 665314704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.31861
Policy Entropy: 3.69539
Value Function Loss: 0.07150

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.77187

Collected Steps per Second: 22,141.43043
Overall Steps per Second: 10,634.89702

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70470

Cumulative Model Updates: 79,784
Cumulative Timesteps: 665,364,738

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,759.85896
Policy Entropy: 3.68572
Value Function Loss: 0.07327

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.63961
Value Function Update Magnitude: 0.62470

Collected Steps per Second: 23,126.70328
Overall Steps per Second: 10,849.21891

Timestep Collection Time: 2.16295
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.61065

Cumulative Model Updates: 79,790
Cumulative Timesteps: 665,414,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 665414760...
Checkpoint 665414760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,502.40685
Policy Entropy: 3.68536
Value Function Loss: 0.07427

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.70459
Value Function Update Magnitude: 0.54845

Collected Steps per Second: 22,363.67663
Overall Steps per Second: 10,667.60357

Timestep Collection Time: 2.23800
Timestep Consumption Time: 2.45377
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.69178

Cumulative Model Updates: 79,796
Cumulative Timesteps: 665,464,810

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,643.06686
Policy Entropy: 3.68327
Value Function Loss: 0.07396

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.72175
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 22,402.26103
Overall Steps per Second: 10,350.73672

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.59897
PPO Batch Consumption Time: 0.30671
Total Iteration Time: 4.83115

Cumulative Model Updates: 79,802
Cumulative Timesteps: 665,514,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 665514816...
Checkpoint 665514816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.98697
Policy Entropy: 3.67198
Value Function Loss: 0.07474

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.73270
Value Function Update Magnitude: 0.72139

Collected Steps per Second: 22,205.52045
Overall Steps per Second: 10,532.41246

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74858

Cumulative Model Updates: 79,808
Cumulative Timesteps: 665,564,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,906.17158
Policy Entropy: 3.66672
Value Function Loss: 0.07134

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.63315
Value Function Update Magnitude: 0.76807

Collected Steps per Second: 22,128.13907
Overall Steps per Second: 10,791.50258

Timestep Collection Time: 2.26020
Timestep Consumption Time: 2.37437
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63457

Cumulative Model Updates: 79,814
Cumulative Timesteps: 665,614,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 665614844...
Checkpoint 665614844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,196.24423
Policy Entropy: 3.66762
Value Function Loss: 0.07069

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.77365

Collected Steps per Second: 21,683.94826
Overall Steps per Second: 10,584.94030

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.72407

Cumulative Model Updates: 79,820
Cumulative Timesteps: 665,664,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,001.84427
Policy Entropy: 3.67173
Value Function Loss: 0.07036

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.52130
Value Function Update Magnitude: 0.77318

Collected Steps per Second: 22,237.94431
Overall Steps per Second: 10,836.61863

Timestep Collection Time: 2.24949
Timestep Consumption Time: 2.36671
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.61620

Cumulative Model Updates: 79,826
Cumulative Timesteps: 665,714,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 665714872...
Checkpoint 665714872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,983.37811
Policy Entropy: 3.67560
Value Function Loss: 0.07070

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.50240
Value Function Update Magnitude: 0.81233

Collected Steps per Second: 21,382.76496
Overall Steps per Second: 10,507.83676

Timestep Collection Time: 2.33908
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.75988

Cumulative Model Updates: 79,832
Cumulative Timesteps: 665,764,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,639.81214
Policy Entropy: 3.68148
Value Function Loss: 0.06918

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.16905
Policy Update Magnitude: 0.42891
Value Function Update Magnitude: 0.74746

Collected Steps per Second: 22,018.40224
Overall Steps per Second: 10,710.78118

Timestep Collection Time: 2.27219
Timestep Consumption Time: 2.39880
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.67099

Cumulative Model Updates: 79,838
Cumulative Timesteps: 665,814,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 665814918...
Checkpoint 665814918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,551.04691
Policy Entropy: 3.69424
Value Function Loss: 0.06626

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.44478
Value Function Update Magnitude: 0.70243

Collected Steps per Second: 21,259.00826
Overall Steps per Second: 10,573.43593

Timestep Collection Time: 2.35213
Timestep Consumption Time: 2.37708
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.72921

Cumulative Model Updates: 79,844
Cumulative Timesteps: 665,864,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.27197
Policy Entropy: 3.69067
Value Function Loss: 0.06692

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.48383
Value Function Update Magnitude: 0.67419

Collected Steps per Second: 21,924.57426
Overall Steps per Second: 10,608.69182

Timestep Collection Time: 2.28182
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.71576

Cumulative Model Updates: 79,850
Cumulative Timesteps: 665,914,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 665914950...
Checkpoint 665914950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,735.51712
Policy Entropy: 3.68143
Value Function Loss: 0.07002

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.50500
Value Function Update Magnitude: 0.63483

Collected Steps per Second: 21,482.08791
Overall Steps per Second: 10,566.26718

Timestep Collection Time: 2.32752
Timestep Consumption Time: 2.40452
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.73204

Cumulative Model Updates: 79,856
Cumulative Timesteps: 665,964,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,945.98953
Policy Entropy: 3.67014
Value Function Loss: 0.07039

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.59561
Value Function Update Magnitude: 0.66136

Collected Steps per Second: 21,986.66387
Overall Steps per Second: 10,637.12971

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70371

Cumulative Model Updates: 79,862
Cumulative Timesteps: 666,014,984

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 666014984...
Checkpoint 666014984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,159.72852
Policy Entropy: 3.67611
Value Function Loss: 0.07154

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 21,903.04598
Overall Steps per Second: 10,654.27095

Timestep Collection Time: 2.28343
Timestep Consumption Time: 2.41084
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.69427

Cumulative Model Updates: 79,868
Cumulative Timesteps: 666,064,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,693.38014
Policy Entropy: 3.67013
Value Function Loss: 0.07014

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.59864

Collected Steps per Second: 22,171.45666
Overall Steps per Second: 10,737.44975

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.40174
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.65716

Cumulative Model Updates: 79,874
Cumulative Timesteps: 666,115,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 666115004...
Checkpoint 666115004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.29199
Policy Entropy: 3.68699
Value Function Loss: 0.07041

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 21,338.57267
Overall Steps per Second: 10,651.88833

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.35177
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.69588

Cumulative Model Updates: 79,880
Cumulative Timesteps: 666,165,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.48724
Policy Entropy: 3.68167
Value Function Loss: 0.06927

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.70776

Collected Steps per Second: 21,552.11412
Overall Steps per Second: 10,537.06287

Timestep Collection Time: 2.32107
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.74743

Cumulative Model Updates: 79,886
Cumulative Timesteps: 666,215,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 666215048...
Checkpoint 666215048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,012.58778
Policy Entropy: 3.68744
Value Function Loss: 0.06791

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.76969

Collected Steps per Second: 21,698.30001
Overall Steps per Second: 10,490.77923

Timestep Collection Time: 2.30497
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.76742

Cumulative Model Updates: 79,892
Cumulative Timesteps: 666,265,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,492.52028
Policy Entropy: 3.68393
Value Function Loss: 0.06484

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.75797

Collected Steps per Second: 22,434.23564
Overall Steps per Second: 10,590.56969

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.72383

Cumulative Model Updates: 79,898
Cumulative Timesteps: 666,315,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 666315090...
Checkpoint 666315090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,190.48141
Policy Entropy: 3.66922
Value Function Loss: 0.06660

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.57593
Value Function Update Magnitude: 0.71126

Collected Steps per Second: 22,060.01282
Overall Steps per Second: 10,551.96031

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.73978

Cumulative Model Updates: 79,904
Cumulative Timesteps: 666,365,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367.82441
Policy Entropy: 3.67384
Value Function Loss: 0.06741

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.76008

Collected Steps per Second: 22,298.63187
Overall Steps per Second: 10,550.14086

Timestep Collection Time: 2.24265
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.74003

Cumulative Model Updates: 79,910
Cumulative Timesteps: 666,415,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 666415112...
Checkpoint 666415112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,677.59164
Policy Entropy: 3.66915
Value Function Loss: 0.06931

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.78471

Collected Steps per Second: 22,152.03789
Overall Steps per Second: 10,544.66469

Timestep Collection Time: 2.25821
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.74401

Cumulative Model Updates: 79,916
Cumulative Timesteps: 666,465,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,746.42109
Policy Entropy: 3.67366
Value Function Loss: 0.06766

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.80694

Collected Steps per Second: 22,702.33593
Overall Steps per Second: 10,644.30316

Timestep Collection Time: 2.20330
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69923

Cumulative Model Updates: 79,922
Cumulative Timesteps: 666,515,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 666515156...
Checkpoint 666515156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,838.37012
Policy Entropy: 3.66393
Value Function Loss: 0.06854

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.44345
Value Function Update Magnitude: 0.77809

Collected Steps per Second: 22,469.47885
Overall Steps per Second: 10,602.50443

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.71681

Cumulative Model Updates: 79,928
Cumulative Timesteps: 666,565,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,009.99127
Policy Entropy: 3.68040
Value Function Loss: 0.07087

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.46541
Value Function Update Magnitude: 0.71251

Collected Steps per Second: 22,287.51970
Overall Steps per Second: 10,662.32699

Timestep Collection Time: 2.24440
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.69147

Cumulative Model Updates: 79,934
Cumulative Timesteps: 666,615,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 666615188...
Checkpoint 666615188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,798.55490
Policy Entropy: 3.68076
Value Function Loss: 0.06953

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.76633

Collected Steps per Second: 22,320.58072
Overall Steps per Second: 10,661.46107

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.45010
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.69054

Cumulative Model Updates: 79,940
Cumulative Timesteps: 666,665,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,720.89400
Policy Entropy: 3.68821
Value Function Loss: 0.06799

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.83552

Collected Steps per Second: 22,397.27507
Overall Steps per Second: 10,529.83872

Timestep Collection Time: 2.23313
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.74993

Cumulative Model Updates: 79,946
Cumulative Timesteps: 666,715,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 666715212...
Checkpoint 666715212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,309.47082
Policy Entropy: 3.67974
Value Function Loss: 0.06617

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.60356
Value Function Update Magnitude: 0.81203

Collected Steps per Second: 22,095.09131
Overall Steps per Second: 10,565.95332

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.73464

Cumulative Model Updates: 79,952
Cumulative Timesteps: 666,765,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.76311
Policy Entropy: 3.67920
Value Function Loss: 0.06616

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.73726

Collected Steps per Second: 22,421.08340
Overall Steps per Second: 10,495.64351

Timestep Collection Time: 2.23067
Timestep Consumption Time: 2.53455
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76522

Cumulative Model Updates: 79,958
Cumulative Timesteps: 666,815,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 666815252...
Checkpoint 666815252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,030.30864
Policy Entropy: 3.67964
Value Function Loss: 0.06786

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.49991
Value Function Update Magnitude: 0.75855

Collected Steps per Second: 22,417.16239
Overall Steps per Second: 10,713.05876

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.66776

Cumulative Model Updates: 79,964
Cumulative Timesteps: 666,865,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.59889
Policy Entropy: 3.67357
Value Function Loss: 0.06801

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.48426
Value Function Update Magnitude: 0.79546

Collected Steps per Second: 22,789.22925
Overall Steps per Second: 10,790.72014

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.63509

Cumulative Model Updates: 79,970
Cumulative Timesteps: 666,915,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 666915274...
Checkpoint 666915274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,941.09221
Policy Entropy: 3.68738
Value Function Loss: 0.07381

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.40446
Value Function Update Magnitude: 0.72421

Collected Steps per Second: 22,288.13205
Overall Steps per Second: 10,641.63791

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.69928

Cumulative Model Updates: 79,976
Cumulative Timesteps: 666,965,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,943.14862
Policy Entropy: 3.67335
Value Function Loss: 0.07564

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.44903
Value Function Update Magnitude: 0.66585

Collected Steps per Second: 22,810.71409
Overall Steps per Second: 10,704.76818

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.47896
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.67100

Cumulative Model Updates: 79,982
Cumulative Timesteps: 667,015,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 667015284...
Checkpoint 667015284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.02148
Policy Entropy: 3.68115
Value Function Loss: 0.07689

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.64253

Collected Steps per Second: 22,458.54839
Overall Steps per Second: 10,536.26035

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.74779

Cumulative Model Updates: 79,988
Cumulative Timesteps: 667,065,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.39865
Policy Entropy: 3.68123
Value Function Loss: 0.07424

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.59965

Collected Steps per Second: 22,830.16250
Overall Steps per Second: 10,850.82380

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.41912
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61034

Cumulative Model Updates: 79,994
Cumulative Timesteps: 667,115,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 667115334...
Checkpoint 667115334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,911.88997
Policy Entropy: 3.68617
Value Function Loss: 0.07392

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.45296
Value Function Update Magnitude: 0.65659

Collected Steps per Second: 22,470.97817
Overall Steps per Second: 10,648.59078

Timestep Collection Time: 2.22563
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.69658

Cumulative Model Updates: 80,000
Cumulative Timesteps: 667,165,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,553.06070
Policy Entropy: 3.68457
Value Function Loss: 0.07382

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.44874
Value Function Update Magnitude: 0.61326

Collected Steps per Second: 22,969.69035
Overall Steps per Second: 10,819.86221

Timestep Collection Time: 2.17748
Timestep Consumption Time: 2.44513
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.62261

Cumulative Model Updates: 80,006
Cumulative Timesteps: 667,215,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 667215362...
Checkpoint 667215362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.13505
Policy Entropy: 3.68236
Value Function Loss: 0.07545

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.51211
Value Function Update Magnitude: 0.57311

Collected Steps per Second: 22,106.04752
Overall Steps per Second: 10,624.22176

Timestep Collection Time: 2.26318
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.70905

Cumulative Model Updates: 80,012
Cumulative Timesteps: 667,265,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,675.82196
Policy Entropy: 3.68279
Value Function Loss: 0.07686

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 22,886.60470
Overall Steps per Second: 10,611.41451

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.71398

Cumulative Model Updates: 80,018
Cumulative Timesteps: 667,315,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 667315414...
Checkpoint 667315414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,902.89869
Policy Entropy: 3.67928
Value Function Loss: 0.07705

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.72052

Collected Steps per Second: 22,482.54469
Overall Steps per Second: 10,597.28823

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.71838

Cumulative Model Updates: 80,024
Cumulative Timesteps: 667,365,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,506.37997
Policy Entropy: 3.67799
Value Function Loss: 0.07737

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.78799

Collected Steps per Second: 22,775.90056
Overall Steps per Second: 10,674.22261

Timestep Collection Time: 2.19548
Timestep Consumption Time: 2.48908
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.68456

Cumulative Model Updates: 80,030
Cumulative Timesteps: 667,415,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 667415420...
Checkpoint 667415420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,232.92202
Policy Entropy: 3.68319
Value Function Loss: 0.07546

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.48571
Value Function Update Magnitude: 0.81861

Collected Steps per Second: 22,624.88466
Overall Steps per Second: 10,627.27140

Timestep Collection Time: 2.21084
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70676

Cumulative Model Updates: 80,036
Cumulative Timesteps: 667,465,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,607.69045
Policy Entropy: 3.68786
Value Function Loss: 0.07331

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.75393

Collected Steps per Second: 23,076.42624
Overall Steps per Second: 10,610.00261

Timestep Collection Time: 2.16758
Timestep Consumption Time: 2.54684
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.71442

Cumulative Model Updates: 80,042
Cumulative Timesteps: 667,515,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 667515460...
Checkpoint 667515460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,048.54335
Policy Entropy: 3.68199
Value Function Loss: 0.07067

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.62656
Value Function Update Magnitude: 0.80246

Collected Steps per Second: 21,780.92122
Overall Steps per Second: 10,443.10375

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.79015

Cumulative Model Updates: 80,048
Cumulative Timesteps: 667,565,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,501.63032
Policy Entropy: 3.66687
Value Function Loss: 0.06921

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.55731
Value Function Update Magnitude: 0.81670

Collected Steps per Second: 22,843.46969
Overall Steps per Second: 10,786.46562

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63562

Cumulative Model Updates: 80,054
Cumulative Timesteps: 667,615,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 667615486...
Checkpoint 667615486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,140.15203
Policy Entropy: 3.65605
Value Function Loss: 0.06996

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.47965
Value Function Update Magnitude: 0.76794

Collected Steps per Second: 22,051.09680
Overall Steps per Second: 10,567.67732

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.73254

Cumulative Model Updates: 80,060
Cumulative Timesteps: 667,665,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,874.94613
Policy Entropy: 3.65444
Value Function Loss: 0.07031

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.71837

Collected Steps per Second: 22,666.15586
Overall Steps per Second: 10,578.31454

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.52163
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.72835

Cumulative Model Updates: 80,066
Cumulative Timesteps: 667,715,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667715516...
Checkpoint 667715516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.80484
Policy Entropy: 3.66285
Value Function Loss: 0.06964

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.61508
Value Function Update Magnitude: 0.72662

Collected Steps per Second: 22,207.57719
Overall Steps per Second: 10,554.99494

Timestep Collection Time: 2.25256
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.73937

Cumulative Model Updates: 80,072
Cumulative Timesteps: 667,765,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,117.28223
Policy Entropy: 3.67599
Value Function Loss: 0.06801

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.70781
Value Function Update Magnitude: 0.79897

Collected Steps per Second: 22,549.96241
Overall Steps per Second: 10,583.61225

Timestep Collection Time: 2.21836
Timestep Consumption Time: 2.50819
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.72655

Cumulative Model Updates: 80,078
Cumulative Timesteps: 667,815,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 667815564...
Checkpoint 667815564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.38610
Policy Entropy: 3.68136
Value Function Loss: 0.06699

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.71657
Value Function Update Magnitude: 0.80296

Collected Steps per Second: 22,458.47674
Overall Steps per Second: 10,509.55279

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.53226
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.75948

Cumulative Model Updates: 80,084
Cumulative Timesteps: 667,865,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.74860
Policy Entropy: 3.68182
Value Function Loss: 0.07142

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.69020
Value Function Update Magnitude: 0.74374

Collected Steps per Second: 22,647.04255
Overall Steps per Second: 10,814.29585

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62517

Cumulative Model Updates: 80,090
Cumulative Timesteps: 667,915,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 667915602...
Checkpoint 667915602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,679.31032
Policy Entropy: 3.68311
Value Function Loss: 0.07174

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.69361
Value Function Update Magnitude: 0.68160

Collected Steps per Second: 22,374.62646
Overall Steps per Second: 10,675.94539

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.68455

Cumulative Model Updates: 80,096
Cumulative Timesteps: 667,965,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,921.27768
Policy Entropy: 3.67833
Value Function Loss: 0.07061

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.68815
Value Function Update Magnitude: 0.69215

Collected Steps per Second: 22,590.23254
Overall Steps per Second: 10,649.64427

Timestep Collection Time: 2.21397
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69631

Cumulative Model Updates: 80,102
Cumulative Timesteps: 668,015,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 668015628...
Checkpoint 668015628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,501.27351
Policy Entropy: 3.67854
Value Function Loss: 0.06704

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.65469
Value Function Update Magnitude: 0.69164

Collected Steps per Second: 22,582.54978
Overall Steps per Second: 10,575.67890

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.72972

Cumulative Model Updates: 80,108
Cumulative Timesteps: 668,065,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.58342
Policy Entropy: 3.67625
Value Function Loss: 0.06853

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.72949

Collected Steps per Second: 22,817.54489
Overall Steps per Second: 10,715.47895

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.66857

Cumulative Model Updates: 80,114
Cumulative Timesteps: 668,115,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 668115674...
Checkpoint 668115674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.62611
Policy Entropy: 3.66976
Value Function Loss: 0.06995

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.16769
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.77614

Collected Steps per Second: 21,877.19700
Overall Steps per Second: 10,288.48974

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.57514
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 4.86135

Cumulative Model Updates: 80,120
Cumulative Timesteps: 668,165,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.92379
Policy Entropy: 3.68783
Value Function Loss: 0.06887

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.53806
Value Function Update Magnitude: 0.84172

Collected Steps per Second: 22,810.46923
Overall Steps per Second: 10,829.80877

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.61910

Cumulative Model Updates: 80,126
Cumulative Timesteps: 668,215,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 668215714...
Checkpoint 668215714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,342.55489
Policy Entropy: 3.67980
Value Function Loss: 0.06920

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.61331
Value Function Update Magnitude: 0.86664

Collected Steps per Second: 22,288.49235
Overall Steps per Second: 10,664.21213

Timestep Collection Time: 2.24331
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.68858

Cumulative Model Updates: 80,132
Cumulative Timesteps: 668,265,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,311.94808
Policy Entropy: 3.67788
Value Function Loss: 0.06930

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.86464

Collected Steps per Second: 22,410.22755
Overall Steps per Second: 10,498.21220

Timestep Collection Time: 2.23121
Timestep Consumption Time: 2.53169
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.76291

Cumulative Model Updates: 80,138
Cumulative Timesteps: 668,315,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 668315716...
Checkpoint 668315716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,948.38766
Policy Entropy: 3.66260
Value Function Loss: 0.07269

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.50762
Value Function Update Magnitude: 0.83805

Collected Steps per Second: 22,158.52183
Overall Steps per Second: 10,616.45065

Timestep Collection Time: 2.25692
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.71061

Cumulative Model Updates: 80,144
Cumulative Timesteps: 668,365,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.46913
Policy Entropy: 3.66473
Value Function Loss: 0.07136

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.51996
Value Function Update Magnitude: 0.82786

Collected Steps per Second: 22,618.14121
Overall Steps per Second: 10,535.06115

Timestep Collection Time: 2.21097
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.74682

Cumulative Model Updates: 80,150
Cumulative Timesteps: 668,415,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 668415734...
Checkpoint 668415734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,940.91381
Policy Entropy: 3.66203
Value Function Loss: 0.07059

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.50397
Value Function Update Magnitude: 0.80581

Collected Steps per Second: 22,261.33773
Overall Steps per Second: 10,645.67980

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.45207
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.69937

Cumulative Model Updates: 80,156
Cumulative Timesteps: 668,465,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.99305
Policy Entropy: 3.66889
Value Function Loss: 0.06768

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.46274
Value Function Update Magnitude: 0.82354

Collected Steps per Second: 22,455.78171
Overall Steps per Second: 10,535.96931

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74755

Cumulative Model Updates: 80,162
Cumulative Timesteps: 668,515,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 668515782...
Checkpoint 668515782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,078.51193
Policy Entropy: 3.67256
Value Function Loss: 0.06783

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.44535
Value Function Update Magnitude: 0.84803

Collected Steps per Second: 22,224.13243
Overall Steps per Second: 10,520.87832

Timestep Collection Time: 2.25107
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.75512

Cumulative Model Updates: 80,168
Cumulative Timesteps: 668,565,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,968.85016
Policy Entropy: 3.67707
Value Function Loss: 0.06722

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.46674
Value Function Update Magnitude: 0.85786

Collected Steps per Second: 22,486.08040
Overall Steps per Second: 10,508.02176

Timestep Collection Time: 2.22431
Timestep Consumption Time: 2.53548
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.75979

Cumulative Model Updates: 80,174
Cumulative Timesteps: 668,615,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 668615826...
Checkpoint 668615826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,270.99279
Policy Entropy: 3.66858
Value Function Loss: 0.07005

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.46127
Value Function Update Magnitude: 0.79937

Collected Steps per Second: 22,239.36035
Overall Steps per Second: 10,652.71665

Timestep Collection Time: 2.24944
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.69608

Cumulative Model Updates: 80,180
Cumulative Timesteps: 668,665,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.09429
Policy Entropy: 3.66693
Value Function Loss: 0.07021

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.44483
Value Function Update Magnitude: 0.73440

Collected Steps per Second: 22,271.63063
Overall Steps per Second: 10,494.39132

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.52055
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76655

Cumulative Model Updates: 80,186
Cumulative Timesteps: 668,715,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 668715874...
Checkpoint 668715874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,650.17025
Policy Entropy: 3.67124
Value Function Loss: 0.07173

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.47917
Value Function Update Magnitude: 0.74938

Collected Steps per Second: 22,536.31796
Overall Steps per Second: 10,549.64761

Timestep Collection Time: 2.21953
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.74139

Cumulative Model Updates: 80,192
Cumulative Timesteps: 668,765,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.21194
Policy Entropy: 3.66789
Value Function Loss: 0.07016

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.50751
Value Function Update Magnitude: 0.79535

Collected Steps per Second: 22,306.62747
Overall Steps per Second: 10,422.94181

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.55665
PPO Batch Consumption Time: 0.30278
Total Iteration Time: 4.79903

Cumulative Model Updates: 80,198
Cumulative Timesteps: 668,815,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 668815914...
Checkpoint 668815914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,232.83382
Policy Entropy: 3.67796
Value Function Loss: 0.06933

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.52205
Value Function Update Magnitude: 0.78279

Collected Steps per Second: 22,008.35381
Overall Steps per Second: 10,593.37582

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.72144

Cumulative Model Updates: 80,204
Cumulative Timesteps: 668,865,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,200.33844
Policy Entropy: 3.66751
Value Function Loss: 0.07297

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.49283
Value Function Update Magnitude: 0.69169

Collected Steps per Second: 22,532.19358
Overall Steps per Second: 10,533.19586

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.52825
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.74766

Cumulative Model Updates: 80,210
Cumulative Timesteps: 668,915,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 668915938...
Checkpoint 668915938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,236.28214
Policy Entropy: 3.65744
Value Function Loss: 0.07601

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.47277
Value Function Update Magnitude: 0.74562

Collected Steps per Second: 22,426.93801
Overall Steps per Second: 10,669.50755

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.45738
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.68738

Cumulative Model Updates: 80,216
Cumulative Timesteps: 668,965,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,779.36615
Policy Entropy: 3.65874
Value Function Loss: 0.07547

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.47434
Value Function Update Magnitude: 0.78551

Collected Steps per Second: 21,882.30252
Overall Steps per Second: 10,626.84982

Timestep Collection Time: 2.28504
Timestep Consumption Time: 2.42021
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.70525

Cumulative Model Updates: 80,222
Cumulative Timesteps: 669,015,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 669015952...
Checkpoint 669015952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,937.98893
Policy Entropy: 3.66350
Value Function Loss: 0.07603

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.50224
Value Function Update Magnitude: 0.72255

Collected Steps per Second: 22,028.95987
Overall Steps per Second: 10,802.93431

Timestep Collection Time: 2.27047
Timestep Consumption Time: 2.35939
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.62985

Cumulative Model Updates: 80,228
Cumulative Timesteps: 669,065,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,094.05828
Policy Entropy: 3.66374
Value Function Loss: 0.07347

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.51424
Value Function Update Magnitude: 0.71933

Collected Steps per Second: 21,489.43859
Overall Steps per Second: 10,552.47934

Timestep Collection Time: 2.32747
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.73974

Cumulative Model Updates: 80,234
Cumulative Timesteps: 669,115,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 669115984...
Checkpoint 669115984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,651.96149
Policy Entropy: 3.66988
Value Function Loss: 0.07284

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.51413
Value Function Update Magnitude: 0.75792

Collected Steps per Second: 21,790.45485
Overall Steps per Second: 10,653.29035

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.39976
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.69526

Cumulative Model Updates: 80,240
Cumulative Timesteps: 669,166,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,862.30320
Policy Entropy: 3.67116
Value Function Loss: 0.07296

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.76673

Collected Steps per Second: 21,840.21421
Overall Steps per Second: 10,604.26123

Timestep Collection Time: 2.29055
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71754

Cumulative Model Updates: 80,246
Cumulative Timesteps: 669,216,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 669216030...
Checkpoint 669216030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.02752
Policy Entropy: 3.67463
Value Function Loss: 0.07195

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.51585
Value Function Update Magnitude: 0.74305

Collected Steps per Second: 21,931.41332
Overall Steps per Second: 10,590.11265

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.44350
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72516

Cumulative Model Updates: 80,252
Cumulative Timesteps: 669,266,070

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.83799
Policy Entropy: 3.66845
Value Function Loss: 0.07249

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.58811
Value Function Update Magnitude: 0.81602

Collected Steps per Second: 22,055.68998
Overall Steps per Second: 10,542.52206

Timestep Collection Time: 2.26744
Timestep Consumption Time: 2.47620
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.74365

Cumulative Model Updates: 80,258
Cumulative Timesteps: 669,316,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 669316080...
Checkpoint 669316080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,027.77855
Policy Entropy: 3.67090
Value Function Loss: 0.07136

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.79804

Collected Steps per Second: 22,661.77185
Overall Steps per Second: 10,824.70824

Timestep Collection Time: 2.20715
Timestep Consumption Time: 2.41357
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62072

Cumulative Model Updates: 80,264
Cumulative Timesteps: 669,366,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,368.02256
Policy Entropy: 3.66238
Value Function Loss: 0.07532

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.76117

Collected Steps per Second: 22,564.20743
Overall Steps per Second: 10,608.95522

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.71356

Cumulative Model Updates: 80,270
Cumulative Timesteps: 669,416,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 669416104...
Checkpoint 669416104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,017.99066
Policy Entropy: 3.66277
Value Function Loss: 0.07502

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.45223
Value Function Update Magnitude: 0.69118

Collected Steps per Second: 22,209.69999
Overall Steps per Second: 10,562.24531

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.73611

Cumulative Model Updates: 80,276
Cumulative Timesteps: 669,466,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,050.92371
Policy Entropy: 3.66340
Value Function Loss: 0.07592

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.47835
Value Function Update Magnitude: 0.69803

Collected Steps per Second: 21,920.09187
Overall Steps per Second: 10,485.70816

Timestep Collection Time: 2.28138
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.76916

Cumulative Model Updates: 80,282
Cumulative Timesteps: 669,516,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 669516136...
Checkpoint 669516136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,512.64406
Policy Entropy: 3.65534
Value Function Loss: 0.07777

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.45534
Value Function Update Magnitude: 0.67895

Collected Steps per Second: 22,322.09592
Overall Steps per Second: 10,583.97344

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.72639

Cumulative Model Updates: 80,288
Cumulative Timesteps: 669,566,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,435.44969
Policy Entropy: 3.65811
Value Function Loss: 0.07831

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.49953
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 22,601.23572
Overall Steps per Second: 10,548.95314

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.74019

Cumulative Model Updates: 80,294
Cumulative Timesteps: 669,616,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 669616164...
Checkpoint 669616164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,649.98020
Policy Entropy: 3.65678
Value Function Loss: 0.08089

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.47251
Value Function Update Magnitude: 0.60540

Collected Steps per Second: 22,144.19939
Overall Steps per Second: 10,541.37677

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.74492

Cumulative Model Updates: 80,300
Cumulative Timesteps: 669,666,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,605.46230
Policy Entropy: 3.65022
Value Function Loss: 0.07996

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.45081
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 22,587.96860
Overall Steps per Second: 10,546.82621

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.52861
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.74342

Cumulative Model Updates: 80,306
Cumulative Timesteps: 669,716,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 669716210...
Checkpoint 669716210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,587.64987
Policy Entropy: 3.64789
Value Function Loss: 0.08003

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.48761
Value Function Update Magnitude: 0.65495

Collected Steps per Second: 22,088.87460
Overall Steps per Second: 10,612.66970

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71286

Cumulative Model Updates: 80,312
Cumulative Timesteps: 669,766,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,597.47937
Policy Entropy: 3.64869
Value Function Loss: 0.07774

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 22,534.60768
Overall Steps per Second: 10,589.12077

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.72353

Cumulative Model Updates: 80,318
Cumulative Timesteps: 669,816,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 669816244...
Checkpoint 669816244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,798.20160
Policy Entropy: 3.64528
Value Function Loss: 0.08085

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 22,629.37705
Overall Steps per Second: 10,641.38801

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.69957

Cumulative Model Updates: 80,324
Cumulative Timesteps: 669,866,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.56914
Policy Entropy: 3.65210
Value Function Loss: 0.08027

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 22,604.69029
Overall Steps per Second: 10,701.30907

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.46138
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.67419

Cumulative Model Updates: 80,330
Cumulative Timesteps: 669,916,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 669916274...
Checkpoint 669916274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,178.99671
Policy Entropy: 3.66152
Value Function Loss: 0.07925

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.65073

Collected Steps per Second: 22,292.07657
Overall Steps per Second: 10,688.29134

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.67895

Cumulative Model Updates: 80,336
Cumulative Timesteps: 669,966,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,436.96597
Policy Entropy: 3.66417
Value Function Loss: 0.07640

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.49203
Value Function Update Magnitude: 0.72450

Collected Steps per Second: 22,646.73271
Overall Steps per Second: 10,768.30198

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.64326

Cumulative Model Updates: 80,342
Cumulative Timesteps: 670,016,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 670016284...
Checkpoint 670016284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,744.04971
Policy Entropy: 3.64938
Value Function Loss: 0.07649

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.71379

Collected Steps per Second: 21,396.92790
Overall Steps per Second: 10,648.18507

Timestep Collection Time: 2.33828
Timestep Consumption Time: 2.36036
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.69864

Cumulative Model Updates: 80,348
Cumulative Timesteps: 670,066,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,066.99063
Policy Entropy: 3.63470
Value Function Loss: 0.07663

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.58670
Value Function Update Magnitude: 0.71107

Collected Steps per Second: 21,884.33354
Overall Steps per Second: 10,498.30725

Timestep Collection Time: 2.28510
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.76343

Cumulative Model Updates: 80,354
Cumulative Timesteps: 670,116,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 670116324...
Checkpoint 670116324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,001.41642
Policy Entropy: 3.64261
Value Function Loss: 0.07518

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.72358

Collected Steps per Second: 21,507.43275
Overall Steps per Second: 10,669.04547

Timestep Collection Time: 2.32580
Timestep Consumption Time: 2.36272
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.68852

Cumulative Model Updates: 80,360
Cumulative Timesteps: 670,166,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.85213
Policy Entropy: 3.65544
Value Function Loss: 0.06962

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.75029

Collected Steps per Second: 21,758.65433
Overall Steps per Second: 10,544.20470

Timestep Collection Time: 2.29886
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.74384

Cumulative Model Updates: 80,366
Cumulative Timesteps: 670,216,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 670216366...
Checkpoint 670216366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,122.02318
Policy Entropy: 3.67461
Value Function Loss: 0.06514

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.60525
Value Function Update Magnitude: 0.84055

Collected Steps per Second: 21,674.36554
Overall Steps per Second: 10,564.35844

Timestep Collection Time: 2.30761
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.73441

Cumulative Model Updates: 80,372
Cumulative Timesteps: 670,266,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,891.64232
Policy Entropy: 3.69147
Value Function Loss: 0.06287

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.67055
Value Function Update Magnitude: 0.87591

Collected Steps per Second: 21,931.62250
Overall Steps per Second: 10,608.73673

Timestep Collection Time: 2.28209
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.71781

Cumulative Model Updates: 80,378
Cumulative Timesteps: 670,316,432

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 670316432...
Checkpoint 670316432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,139.46968
Policy Entropy: 3.68257
Value Function Loss: 0.06574

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.60467
Value Function Update Magnitude: 0.78643

Collected Steps per Second: 21,750.49558
Overall Steps per Second: 10,488.01068

Timestep Collection Time: 2.29898
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.76773

Cumulative Model Updates: 80,384
Cumulative Timesteps: 670,366,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,213.57220
Policy Entropy: 3.68899
Value Function Loss: 0.06999

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.77560

Collected Steps per Second: 22,239.85540
Overall Steps per Second: 10,506.05877

Timestep Collection Time: 2.24930
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.76144

Cumulative Model Updates: 80,390
Cumulative Timesteps: 670,416,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 670416460...
Checkpoint 670416460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.48921
Policy Entropy: 3.68199
Value Function Loss: 0.06961

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.54146
Value Function Update Magnitude: 0.82709

Collected Steps per Second: 22,458.54792
Overall Steps per Second: 10,591.48150

Timestep Collection Time: 2.22748
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72323

Cumulative Model Updates: 80,396
Cumulative Timesteps: 670,466,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.76571
Policy Entropy: 3.69193
Value Function Loss: 0.06911

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.82334

Collected Steps per Second: 22,300.36461
Overall Steps per Second: 10,556.11569

Timestep Collection Time: 2.24274
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.73792

Cumulative Model Updates: 80,402
Cumulative Timesteps: 670,516,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 670516500...
Checkpoint 670516500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.16295
Policy Entropy: 3.69490
Value Function Loss: 0.06722

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.46984
Value Function Update Magnitude: 0.77361

Collected Steps per Second: 22,288.19464
Overall Steps per Second: 10,566.77387

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.73314

Cumulative Model Updates: 80,408
Cumulative Timesteps: 670,566,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,255.31275
Policy Entropy: 3.69823
Value Function Loss: 0.06572

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.81360

Collected Steps per Second: 22,577.84867
Overall Steps per Second: 10,569.45730

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.51706
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.73250

Cumulative Model Updates: 80,414
Cumulative Timesteps: 670,616,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 670616534...
Checkpoint 670616534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,141.63405
Policy Entropy: 3.68955
Value Function Loss: 0.06792

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.50915
Value Function Update Magnitude: 0.82294

Collected Steps per Second: 22,698.74194
Overall Steps per Second: 10,615.92953

Timestep Collection Time: 2.20400
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.71254

Cumulative Model Updates: 80,420
Cumulative Timesteps: 670,666,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,430.14796
Policy Entropy: 3.67564
Value Function Loss: 0.06828

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.49992
Value Function Update Magnitude: 0.78625

Collected Steps per Second: 22,709.74118
Overall Steps per Second: 10,746.78554

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.45105
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.65293

Cumulative Model Updates: 80,426
Cumulative Timesteps: 670,716,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 670716566...
Checkpoint 670716566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,813.75104
Policy Entropy: 3.67394
Value Function Loss: 0.07105

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.44860
Value Function Update Magnitude: 0.79562

Collected Steps per Second: 22,186.98731
Overall Steps per Second: 10,503.17828

Timestep Collection Time: 2.25357
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.76046

Cumulative Model Updates: 80,432
Cumulative Timesteps: 670,766,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,943.19632
Policy Entropy: 3.67201
Value Function Loss: 0.07147

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.42508
Value Function Update Magnitude: 0.76770

Collected Steps per Second: 22,367.06340
Overall Steps per Second: 10,622.65378

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.70805

Cumulative Model Updates: 80,438
Cumulative Timesteps: 670,816,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 670816578...
Checkpoint 670816578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.20603
Policy Entropy: 3.67556
Value Function Loss: 0.07471

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.47244
Value Function Update Magnitude: 0.69320

Collected Steps per Second: 22,260.79954
Overall Steps per Second: 10,626.97021

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.70708

Cumulative Model Updates: 80,444
Cumulative Timesteps: 670,866,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.64930
Policy Entropy: 3.67850
Value Function Loss: 0.07512

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.51167
Value Function Update Magnitude: 0.73196

Collected Steps per Second: 22,227.85071
Overall Steps per Second: 10,512.06365

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.50771
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.75777

Cumulative Model Updates: 80,450
Cumulative Timesteps: 670,916,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 670916614...
Checkpoint 670916614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.97472
Policy Entropy: 3.68516
Value Function Loss: 0.07366

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.52413
Value Function Update Magnitude: 0.73706

Collected Steps per Second: 22,267.21720
Overall Steps per Second: 10,651.32175

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.69669

Cumulative Model Updates: 80,456
Cumulative Timesteps: 670,966,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,331.61532
Policy Entropy: 3.69104
Value Function Loss: 0.06979

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.50159
Value Function Update Magnitude: 0.81908

Collected Steps per Second: 22,487.93806
Overall Steps per Second: 10,565.15196

Timestep Collection Time: 2.22350
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.73273

Cumulative Model Updates: 80,462
Cumulative Timesteps: 671,016,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 671016642...
Checkpoint 671016642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,235.94575
Policy Entropy: 3.67860
Value Function Loss: 0.07098

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.85968

Collected Steps per Second: 22,660.02168
Overall Steps per Second: 10,565.57324

Timestep Collection Time: 2.20794
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.73538

Cumulative Model Updates: 80,468
Cumulative Timesteps: 671,066,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,668.53050
Policy Entropy: 3.67986
Value Function Loss: 0.07095

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.52607
Value Function Update Magnitude: 0.89110

Collected Steps per Second: 22,394.11283
Overall Steps per Second: 10,564.54844

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.73357

Cumulative Model Updates: 80,474
Cumulative Timesteps: 671,116,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 671116682...
Checkpoint 671116682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.69571
Policy Entropy: 3.67795
Value Function Loss: 0.07370

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.79109

Collected Steps per Second: 22,531.01358
Overall Steps per Second: 10,550.55850

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.52133
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.74174

Cumulative Model Updates: 80,480
Cumulative Timesteps: 671,166,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,257.96512
Policy Entropy: 3.68005
Value Function Loss: 0.07129

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.61468
Value Function Update Magnitude: 0.71531

Collected Steps per Second: 22,583.04967
Overall Steps per Second: 10,616.34287

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.71443

Cumulative Model Updates: 80,486
Cumulative Timesteps: 671,216,760

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 671216760...
Checkpoint 671216760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,823.99968
Policy Entropy: 3.66060
Value Function Loss: 0.07490

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.65678
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 22,399.50887
Overall Steps per Second: 10,563.26739

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.50199
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.73490

Cumulative Model Updates: 80,492
Cumulative Timesteps: 671,266,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,918.92588
Policy Entropy: 3.64022
Value Function Loss: 0.07648

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.73774

Collected Steps per Second: 22,406.58058
Overall Steps per Second: 10,694.05348

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.67550

Cumulative Model Updates: 80,498
Cumulative Timesteps: 671,316,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671316776...
Checkpoint 671316776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.39039
Policy Entropy: 3.64095
Value Function Loss: 0.07696

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.49779
Value Function Update Magnitude: 0.76314

Collected Steps per Second: 22,407.07963
Overall Steps per Second: 10,702.66048

Timestep Collection Time: 2.23144
Timestep Consumption Time: 2.44030
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.67174

Cumulative Model Updates: 80,504
Cumulative Timesteps: 671,366,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,202.73425
Policy Entropy: 3.63912
Value Function Loss: 0.07628

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.45216
Value Function Update Magnitude: 0.74969

Collected Steps per Second: 22,467.99429
Overall Steps per Second: 10,435.27190

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.56749
PPO Batch Consumption Time: 0.30171
Total Iteration Time: 4.79413

Cumulative Model Updates: 80,510
Cumulative Timesteps: 671,416,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 671416804...
Checkpoint 671416804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.39824
Policy Entropy: 3.64365
Value Function Loss: 0.07511

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.52013
Value Function Update Magnitude: 0.69779

Collected Steps per Second: 22,209.69606
Overall Steps per Second: 10,452.04707

Timestep Collection Time: 2.25253
Timestep Consumption Time: 2.53390
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78643

Cumulative Model Updates: 80,516
Cumulative Timesteps: 671,466,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.47997
Policy Entropy: 3.62372
Value Function Loss: 0.07968

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.65649
Value Function Update Magnitude: 0.71354

Collected Steps per Second: 22,657.22585
Overall Steps per Second: 10,664.86018

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.68829

Cumulative Model Updates: 80,522
Cumulative Timesteps: 671,516,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 671516832...
Checkpoint 671516832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,326.33015
Policy Entropy: 3.62842
Value Function Loss: 0.07804

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.68304
Value Function Update Magnitude: 0.75085

Collected Steps per Second: 22,224.12134
Overall Steps per Second: 10,679.06333

Timestep Collection Time: 2.25017
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.68281

Cumulative Model Updates: 80,528
Cumulative Timesteps: 671,566,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.95090
Policy Entropy: 3.62843
Value Function Loss: 0.08090

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.66303
Value Function Update Magnitude: 0.68153

Collected Steps per Second: 22,643.75118
Overall Steps per Second: 10,746.31495

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.44621
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.65574

Cumulative Model Updates: 80,534
Cumulative Timesteps: 671,616,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 671616872...
Checkpoint 671616872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.07531
Policy Entropy: 3.64158
Value Function Loss: 0.08179

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.67789

Collected Steps per Second: 22,278.89434
Overall Steps per Second: 10,673.44599

Timestep Collection Time: 2.24473
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.68546

Cumulative Model Updates: 80,540
Cumulative Timesteps: 671,666,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,528.72664
Policy Entropy: 3.63452
Value Function Loss: 0.08243

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.69023

Collected Steps per Second: 22,454.70898
Overall Steps per Second: 10,519.19712

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.52661
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.75340

Cumulative Model Updates: 80,546
Cumulative Timesteps: 671,716,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 671716884...
Checkpoint 671716884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,755.02475
Policy Entropy: 3.62325
Value Function Loss: 0.07954

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.48675
Value Function Update Magnitude: 0.69281

Collected Steps per Second: 22,257.94441
Overall Steps per Second: 10,678.21780

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.68299

Cumulative Model Updates: 80,552
Cumulative Timesteps: 671,766,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,770.37495
Policy Entropy: 3.61863
Value Function Loss: 0.07857

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.53107
Value Function Update Magnitude: 0.69697

Collected Steps per Second: 22,480.75611
Overall Steps per Second: 10,588.05135

Timestep Collection Time: 2.22484
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.72382

Cumulative Model Updates: 80,558
Cumulative Timesteps: 671,816,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 671816906...
Checkpoint 671816906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,907.44851
Policy Entropy: 3.63960
Value Function Loss: 0.07744

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.66512

Collected Steps per Second: 22,016.97494
Overall Steps per Second: 10,487.16519

Timestep Collection Time: 2.27234
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.77059

Cumulative Model Updates: 80,564
Cumulative Timesteps: 671,866,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,688.06837
Policy Entropy: 3.66040
Value Function Loss: 0.07800

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.56317
Value Function Update Magnitude: 0.63765

Collected Steps per Second: 22,530.17800
Overall Steps per Second: 10,551.21347

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.52045
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.74050

Cumulative Model Updates: 80,570
Cumulative Timesteps: 671,916,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 671916954...
Checkpoint 671916954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.83811
Policy Entropy: 3.65988
Value Function Loss: 0.07700

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.56859
Value Function Update Magnitude: 0.75800

Collected Steps per Second: 22,434.30556
Overall Steps per Second: 10,548.92689

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.74266

Cumulative Model Updates: 80,576
Cumulative Timesteps: 671,966,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.05307
Policy Entropy: 3.65413
Value Function Loss: 0.07709

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.52186
Value Function Update Magnitude: 0.82242

Collected Steps per Second: 22,755.07309
Overall Steps per Second: 10,645.07359

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69983

Cumulative Model Updates: 80,582
Cumulative Timesteps: 672,017,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 672017014...
Checkpoint 672017014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,379.07839
Policy Entropy: 3.65789
Value Function Loss: 0.07369

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.48613
Value Function Update Magnitude: 0.88185

Collected Steps per Second: 22,353.92259
Overall Steps per Second: 10,529.25622

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.74867

Cumulative Model Updates: 80,588
Cumulative Timesteps: 672,067,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,450.17913
Policy Entropy: 3.65836
Value Function Loss: 0.07285

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.48342
Value Function Update Magnitude: 0.86744

Collected Steps per Second: 22,096.07621
Overall Steps per Second: 10,341.83402

Timestep Collection Time: 2.26285
Timestep Consumption Time: 2.57189
PPO Batch Consumption Time: 0.30462
Total Iteration Time: 4.83473

Cumulative Model Updates: 80,594
Cumulative Timesteps: 672,117,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 672117014...
Checkpoint 672117014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,368.51509
Policy Entropy: 3.66263
Value Function Loss: 0.07363

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.46629
Value Function Update Magnitude: 0.80424

Collected Steps per Second: 22,258.73130
Overall Steps per Second: 10,642.57668

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.45308
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.70055

Cumulative Model Updates: 80,600
Cumulative Timesteps: 672,167,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.08396
Policy Entropy: 3.65308
Value Function Loss: 0.07619

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.48691
Value Function Update Magnitude: 0.76155

Collected Steps per Second: 22,645.16748
Overall Steps per Second: 10,624.71768

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.70695

Cumulative Model Updates: 80,606
Cumulative Timesteps: 672,217,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 672217050...
Checkpoint 672217050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,912.47920
Policy Entropy: 3.65233
Value Function Loss: 0.07489

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.48657
Value Function Update Magnitude: 0.77899

Collected Steps per Second: 22,196.97024
Overall Steps per Second: 10,471.82431

Timestep Collection Time: 2.25364
Timestep Consumption Time: 2.52337
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.77701

Cumulative Model Updates: 80,612
Cumulative Timesteps: 672,267,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,345.96521
Policy Entropy: 3.66199
Value Function Loss: 0.07715

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.46043
Value Function Update Magnitude: 0.77452

Collected Steps per Second: 22,563.50315
Overall Steps per Second: 10,574.06155

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.73120

Cumulative Model Updates: 80,618
Cumulative Timesteps: 672,317,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 672317102...
Checkpoint 672317102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,768.66102
Policy Entropy: 3.67470
Value Function Loss: 0.07346

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.41960
Value Function Update Magnitude: 0.82708

Collected Steps per Second: 22,420.78790
Overall Steps per Second: 10,538.46845

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.74585

Cumulative Model Updates: 80,624
Cumulative Timesteps: 672,367,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,198.24826
Policy Entropy: 3.66841
Value Function Loss: 0.07112

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.38425
Value Function Update Magnitude: 0.87992

Collected Steps per Second: 21,796.77526
Overall Steps per Second: 10,566.41100

Timestep Collection Time: 2.29520
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73463

Cumulative Model Updates: 80,630
Cumulative Timesteps: 672,417,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 672417144...
Checkpoint 672417144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,879.59248
Policy Entropy: 3.66551
Value Function Loss: 0.07188

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.46399
Value Function Update Magnitude: 0.79346

Collected Steps per Second: 21,523.46274
Overall Steps per Second: 10,528.44821

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.74923

Cumulative Model Updates: 80,636
Cumulative Timesteps: 672,467,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.71021
Policy Entropy: 3.66411
Value Function Loss: 0.07415

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.51274
Value Function Update Magnitude: 0.71353

Collected Steps per Second: 21,737.27841
Overall Steps per Second: 10,554.82144

Timestep Collection Time: 2.30066
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.73812

Cumulative Model Updates: 80,642
Cumulative Timesteps: 672,517,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 672517156...
Checkpoint 672517156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.42258
Policy Entropy: 3.67379
Value Function Loss: 0.07466

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.65125
Value Function Update Magnitude: 0.78128

Collected Steps per Second: 21,648.07499
Overall Steps per Second: 10,557.76871

Timestep Collection Time: 2.31171
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74002

Cumulative Model Updates: 80,648
Cumulative Timesteps: 672,567,200

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,770.71375
Policy Entropy: 3.67790
Value Function Loss: 0.07165

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.85231

Collected Steps per Second: 22,199.21397
Overall Steps per Second: 10,806.21262

Timestep Collection Time: 2.25233
Timestep Consumption Time: 2.37464
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62697

Cumulative Model Updates: 80,654
Cumulative Timesteps: 672,617,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 672617200...
Checkpoint 672617200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,443.81415
Policy Entropy: 3.67193
Value Function Loss: 0.06917

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.51323
Value Function Update Magnitude: 0.86266

Collected Steps per Second: 21,452.03816
Overall Steps per Second: 10,660.16437

Timestep Collection Time: 2.33209
Timestep Consumption Time: 2.36090
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.69299

Cumulative Model Updates: 80,660
Cumulative Timesteps: 672,667,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,098.43092
Policy Entropy: 3.67187
Value Function Loss: 0.07157

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.48841
Value Function Update Magnitude: 0.86982

Collected Steps per Second: 21,753.61071
Overall Steps per Second: 10,601.74181

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71715

Cumulative Model Updates: 80,666
Cumulative Timesteps: 672,717,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 672717238...
Checkpoint 672717238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,571.83755
Policy Entropy: 3.67104
Value Function Loss: 0.07493

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.80105

Collected Steps per Second: 22,095.58809
Overall Steps per Second: 10,574.16328

Timestep Collection Time: 2.26353
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.72983

Cumulative Model Updates: 80,672
Cumulative Timesteps: 672,767,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,407.66028
Policy Entropy: 3.67687
Value Function Loss: 0.07565

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.73946

Collected Steps per Second: 22,367.06209
Overall Steps per Second: 10,604.33022

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.71694

Cumulative Model Updates: 80,678
Cumulative Timesteps: 672,817,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 672817272...
Checkpoint 672817272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.89127
Policy Entropy: 3.67165
Value Function Loss: 0.07452

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.79346

Collected Steps per Second: 22,153.89357
Overall Steps per Second: 10,518.20869

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.75632

Cumulative Model Updates: 80,684
Cumulative Timesteps: 672,867,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.96977
Policy Entropy: 3.67139
Value Function Loss: 0.07208

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.65073
Value Function Update Magnitude: 0.87629

Collected Steps per Second: 22,981.84445
Overall Steps per Second: 10,875.23597

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.59815

Cumulative Model Updates: 80,690
Cumulative Timesteps: 672,917,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 672917306...
Checkpoint 672917306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,883.87158
Policy Entropy: 3.66414
Value Function Loss: 0.07638

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.71859
Value Function Update Magnitude: 0.78178

Collected Steps per Second: 22,463.21736
Overall Steps per Second: 10,669.28177

Timestep Collection Time: 2.22657
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.68785

Cumulative Model Updates: 80,696
Cumulative Timesteps: 672,967,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.68419
Policy Entropy: 3.66843
Value Function Loss: 0.07464

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.16310
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.78957

Collected Steps per Second: 22,878.05303
Overall Steps per Second: 10,793.96890

Timestep Collection Time: 2.18568
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.63259

Cumulative Model Updates: 80,702
Cumulative Timesteps: 673,017,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 673017326...
Checkpoint 673017326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,019.96052
Policy Entropy: 3.68512
Value Function Loss: 0.07146

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.48224
Value Function Update Magnitude: 0.81972

Collected Steps per Second: 22,151.34924
Overall Steps per Second: 10,614.05000

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.71149

Cumulative Model Updates: 80,708
Cumulative Timesteps: 673,067,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.38784
Policy Entropy: 3.68940
Value Function Loss: 0.06587

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.54202
Value Function Update Magnitude: 0.79782

Collected Steps per Second: 22,663.88035
Overall Steps per Second: 10,575.89472

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73000

Cumulative Model Updates: 80,714
Cumulative Timesteps: 673,117,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 673117358...
Checkpoint 673117358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,662.56476
Policy Entropy: 3.69255
Value Function Loss: 0.06188

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.53583
Value Function Update Magnitude: 0.87189

Collected Steps per Second: 22,336.77590
Overall Steps per Second: 10,610.54832

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.71267

Cumulative Model Updates: 80,720
Cumulative Timesteps: 673,167,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.52909
Policy Entropy: 3.68746
Value Function Loss: 0.06380

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.55398
Value Function Update Magnitude: 0.90621

Collected Steps per Second: 22,493.80200
Overall Steps per Second: 10,533.88458

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.52496
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.74887

Cumulative Model Updates: 80,726
Cumulative Timesteps: 673,217,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 673217386...
Checkpoint 673217386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.19430
Policy Entropy: 3.67953
Value Function Loss: 0.06446

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.63584
Value Function Update Magnitude: 0.90817

Collected Steps per Second: 22,211.86796
Overall Steps per Second: 10,629.39848

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.70412

Cumulative Model Updates: 80,732
Cumulative Timesteps: 673,267,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.44918
Policy Entropy: 3.66394
Value Function Loss: 0.06844

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.62255
Value Function Update Magnitude: 0.88321

Collected Steps per Second: 22,235.89628
Overall Steps per Second: 10,417.36175

Timestep Collection Time: 2.24952
Timestep Consumption Time: 2.55208
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.80160

Cumulative Model Updates: 80,738
Cumulative Timesteps: 673,317,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 673317408...
Checkpoint 673317408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,619.16766
Policy Entropy: 3.65479
Value Function Loss: 0.06920

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.65854
Value Function Update Magnitude: 0.84578

Collected Steps per Second: 21,648.07878
Overall Steps per Second: 10,370.55132

Timestep Collection Time: 2.31097
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.82404

Cumulative Model Updates: 80,744
Cumulative Timesteps: 673,367,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.55217
Policy Entropy: 3.65179
Value Function Loss: 0.07041

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.66180
Value Function Update Magnitude: 0.80160

Collected Steps per Second: 22,451.53971
Overall Steps per Second: 10,633.02807

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.47610
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.70383

Cumulative Model Updates: 80,750
Cumulative Timesteps: 673,417,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 673417452...
Checkpoint 673417452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.70919
Policy Entropy: 3.65192
Value Function Loss: 0.07065

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.65613
Value Function Update Magnitude: 0.71674

Collected Steps per Second: 21,765.77150
Overall Steps per Second: 10,419.06460

Timestep Collection Time: 2.29737
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79928

Cumulative Model Updates: 80,756
Cumulative Timesteps: 673,467,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,950.03859
Policy Entropy: 3.65877
Value Function Loss: 0.07025

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.66476
Value Function Update Magnitude: 0.63654

Collected Steps per Second: 22,764.80221
Overall Steps per Second: 10,771.44375

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.44582
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.64246

Cumulative Model Updates: 80,762
Cumulative Timesteps: 673,517,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 673517462...
Checkpoint 673517462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,586.89429
Policy Entropy: 3.66818
Value Function Loss: 0.06866

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.60368
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,256.08635
Overall Steps per Second: 10,674.11074

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.43785
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.68461

Cumulative Model Updates: 80,768
Cumulative Timesteps: 673,567,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.88613
Policy Entropy: 3.67444
Value Function Loss: 0.06971

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.43817
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 22,810.21107
Overall Steps per Second: 10,648.32746

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.69801

Cumulative Model Updates: 80,774
Cumulative Timesteps: 673,617,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 673617492...
Checkpoint 673617492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,347.75513
Policy Entropy: 3.67965
Value Function Loss: 0.06816

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.38746
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 22,227.32323
Overall Steps per Second: 10,500.23463

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.51252
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.76218

Cumulative Model Updates: 80,780
Cumulative Timesteps: 673,667,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.76365
Policy Entropy: 3.66498
Value Function Loss: 0.06857

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.41588
Value Function Update Magnitude: 0.61547

Collected Steps per Second: 22,827.61684
Overall Steps per Second: 10,796.37389

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.63137

Cumulative Model Updates: 80,786
Cumulative Timesteps: 673,717,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 673717498...
Checkpoint 673717498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,835.58417
Policy Entropy: 3.66086
Value Function Loss: 0.06741

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.42608
Value Function Update Magnitude: 0.60819

Collected Steps per Second: 21,676.05188
Overall Steps per Second: 10,699.49197

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.36652
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.67331

Cumulative Model Updates: 80,792
Cumulative Timesteps: 673,767,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,377.74017
Policy Entropy: 3.67283
Value Function Loss: 0.06901

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.46308
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 22,339.13735
Overall Steps per Second: 10,824.83306

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.38145
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.62030

Cumulative Model Updates: 80,798
Cumulative Timesteps: 673,817,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 673817514...
Checkpoint 673817514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,353.24405
Policy Entropy: 3.68001
Value Function Loss: 0.06605

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.50465
Value Function Update Magnitude: 0.74619

Collected Steps per Second: 21,633.02529
Overall Steps per Second: 10,655.04115

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.38248
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.69487

Cumulative Model Updates: 80,804
Cumulative Timesteps: 673,867,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.69333
Policy Entropy: 3.68054
Value Function Loss: 0.06566

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.64368
Value Function Update Magnitude: 0.79319

Collected Steps per Second: 21,524.23082
Overall Steps per Second: 10,487.58547

Timestep Collection Time: 2.32306
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.76773

Cumulative Model Updates: 80,810
Cumulative Timesteps: 673,917,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 673917540...
Checkpoint 673917540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,848.28209
Policy Entropy: 3.67119
Value Function Loss: 0.06778

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.59333
Value Function Update Magnitude: 0.80162

Collected Steps per Second: 21,787.26198
Overall Steps per Second: 10,658.37203

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.69302

Cumulative Model Updates: 80,816
Cumulative Timesteps: 673,967,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,686.10528
Policy Entropy: 3.66432
Value Function Loss: 0.06923

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.58405
Value Function Update Magnitude: 0.78016

Collected Steps per Second: 21,652.27328
Overall Steps per Second: 10,535.59662

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.74980

Cumulative Model Updates: 80,822
Cumulative Timesteps: 674,017,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 674017602...
Checkpoint 674017602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,201.80052
Policy Entropy: 3.65848
Value Function Loss: 0.07198

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.82492

Collected Steps per Second: 21,644.41876
Overall Steps per Second: 10,403.08439

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.81050

Cumulative Model Updates: 80,828
Cumulative Timesteps: 674,067,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,463.92890
Policy Entropy: 3.66067
Value Function Loss: 0.07194

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.81189

Collected Steps per Second: 22,518.14086
Overall Steps per Second: 10,655.86842

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.69469

Cumulative Model Updates: 80,834
Cumulative Timesteps: 674,117,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 674117672...
Checkpoint 674117672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,513.53824
Policy Entropy: 3.65858
Value Function Loss: 0.07284

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.60574
Value Function Update Magnitude: 0.79747

Collected Steps per Second: 22,305.19539
Overall Steps per Second: 10,627.67394

Timestep Collection Time: 2.24271
Timestep Consumption Time: 2.46425
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.70696

Cumulative Model Updates: 80,840
Cumulative Timesteps: 674,167,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,449.07402
Policy Entropy: 3.66790
Value Function Loss: 0.07331

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.58344
Value Function Update Magnitude: 0.85243

Collected Steps per Second: 22,683.01158
Overall Steps per Second: 10,625.69326

Timestep Collection Time: 2.20535
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70783

Cumulative Model Updates: 80,846
Cumulative Timesteps: 674,217,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 674217720...
Checkpoint 674217720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,494.84785
Policy Entropy: 3.66666
Value Function Loss: 0.06988

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.49694
Value Function Update Magnitude: 0.86693

Collected Steps per Second: 21,919.20037
Overall Steps per Second: 10,436.96516

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.79105

Cumulative Model Updates: 80,852
Cumulative Timesteps: 674,267,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,311.84241
Policy Entropy: 3.66880
Value Function Loss: 0.06749

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.49362
Value Function Update Magnitude: 0.82178

Collected Steps per Second: 22,733.97217
Overall Steps per Second: 10,609.67585

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.51443
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.71475

Cumulative Model Updates: 80,858
Cumulative Timesteps: 674,317,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 674317746...
Checkpoint 674317746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.78565
Policy Entropy: 3.67720
Value Function Loss: 0.06572

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.58801
Value Function Update Magnitude: 0.73910

Collected Steps per Second: 22,432.80395
Overall Steps per Second: 10,525.46213

Timestep Collection Time: 2.22977
Timestep Consumption Time: 2.52252
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.75229

Cumulative Model Updates: 80,864
Cumulative Timesteps: 674,367,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,733.21438
Policy Entropy: 3.67695
Value Function Loss: 0.06617

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.73387

Collected Steps per Second: 22,931.36133
Overall Steps per Second: 10,781.79875

Timestep Collection Time: 2.18121
Timestep Consumption Time: 2.45791
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.63911

Cumulative Model Updates: 80,870
Cumulative Timesteps: 674,417,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 674417784...
Checkpoint 674417784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,878.18868
Policy Entropy: 3.68139
Value Function Loss: 0.06623

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.50595
Value Function Update Magnitude: 0.75518

Collected Steps per Second: 22,148.49722
Overall Steps per Second: 10,677.93031

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.68424

Cumulative Model Updates: 80,876
Cumulative Timesteps: 674,467,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,901.27904
Policy Entropy: 3.69464
Value Function Loss: 0.06348

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.52289
Value Function Update Magnitude: 0.76542

Collected Steps per Second: 22,717.35929
Overall Steps per Second: 10,570.00591

Timestep Collection Time: 2.20202
Timestep Consumption Time: 2.53062
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.73264

Cumulative Model Updates: 80,882
Cumulative Timesteps: 674,517,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 674517826...
Checkpoint 674517826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,788.72635
Policy Entropy: 3.69819
Value Function Loss: 0.06492

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.51392
Value Function Update Magnitude: 0.74228

Collected Steps per Second: 22,450.10118
Overall Steps per Second: 10,587.71516

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.72321

Cumulative Model Updates: 80,888
Cumulative Timesteps: 674,567,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,698.39438
Policy Entropy: 3.69494
Value Function Loss: 0.06333

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.57544
Value Function Update Magnitude: 0.80870

Collected Steps per Second: 22,388.13252
Overall Steps per Second: 10,487.45533

Timestep Collection Time: 2.23422
Timestep Consumption Time: 2.53529
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.76951

Cumulative Model Updates: 80,894
Cumulative Timesteps: 674,617,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 674617854...
Checkpoint 674617854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.22263
Policy Entropy: 3.69322
Value Function Loss: 0.06668

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.58917
Value Function Update Magnitude: 0.79014

Collected Steps per Second: 21,802.39496
Overall Steps per Second: 10,550.39897

Timestep Collection Time: 2.29406
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.74067

Cumulative Model Updates: 80,900
Cumulative Timesteps: 674,667,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,995.68016
Policy Entropy: 3.68230
Value Function Loss: 0.06874

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.16617
Policy Update Magnitude: 0.51511
Value Function Update Magnitude: 0.80462

Collected Steps per Second: 22,577.16935
Overall Steps per Second: 10,398.13608

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.59538
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 4.81125

Cumulative Model Updates: 80,906
Cumulative Timesteps: 674,717,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674717898...
Checkpoint 674717898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,498.88348
Policy Entropy: 3.69480
Value Function Loss: 0.06703

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.45257
Value Function Update Magnitude: 0.86908

Collected Steps per Second: 22,339.91447
Overall Steps per Second: 10,604.24393

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.47833
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.71773

Cumulative Model Updates: 80,912
Cumulative Timesteps: 674,767,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.76457
Policy Entropy: 3.68043
Value Function Loss: 0.06177

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.89926

Collected Steps per Second: 22,427.68073
Overall Steps per Second: 10,606.92220

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.71466

Cumulative Model Updates: 80,918
Cumulative Timesteps: 674,817,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 674817934...
Checkpoint 674817934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,437.54287
Policy Entropy: 3.68505
Value Function Loss: 0.06022

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.87958

Collected Steps per Second: 22,150.08650
Overall Steps per Second: 10,587.29285

Timestep Collection Time: 2.25769
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.72340

Cumulative Model Updates: 80,924
Cumulative Timesteps: 674,867,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,219.56082
Policy Entropy: 3.68187
Value Function Loss: 0.06303

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.84579

Collected Steps per Second: 22,669.13217
Overall Steps per Second: 10,670.55506

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.48154
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68842

Cumulative Model Updates: 80,930
Cumulative Timesteps: 674,917,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 674917970...
Checkpoint 674917970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.72991
Policy Entropy: 3.68820
Value Function Loss: 0.06580

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.77909

Collected Steps per Second: 22,460.34774
Overall Steps per Second: 10,530.64343

Timestep Collection Time: 2.22632
Timestep Consumption Time: 2.52210
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.74843

Cumulative Model Updates: 80,936
Cumulative Timesteps: 674,967,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,697.09916
Policy Entropy: 3.68333
Value Function Loss: 0.06770

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.61463
Value Function Update Magnitude: 0.76834

Collected Steps per Second: 22,611.84382
Overall Steps per Second: 10,584.77305

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.72547

Cumulative Model Updates: 80,942
Cumulative Timesteps: 675,017,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 675017992...
Checkpoint 675017992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,772.87822
Policy Entropy: 3.68367
Value Function Loss: 0.06962

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.60291
Value Function Update Magnitude: 0.71303

Collected Steps per Second: 22,371.68181
Overall Steps per Second: 10,525.53528

Timestep Collection Time: 2.23604
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.75263

Cumulative Model Updates: 80,948
Cumulative Timesteps: 675,068,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,920.21727
Policy Entropy: 3.68586
Value Function Loss: 0.07004

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.57369
Value Function Update Magnitude: 0.75387

Collected Steps per Second: 22,607.78953
Overall Steps per Second: 10,752.47266

Timestep Collection Time: 2.21163
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.65009

Cumulative Model Updates: 80,954
Cumulative Timesteps: 675,118,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 675118016...
Checkpoint 675118016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.78419
Policy Entropy: 3.67297
Value Function Loss: 0.06942

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.49881
Value Function Update Magnitude: 0.71500

Collected Steps per Second: 22,127.25797
Overall Steps per Second: 10,661.30397

Timestep Collection Time: 2.26029
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.69117

Cumulative Model Updates: 80,960
Cumulative Timesteps: 675,168,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.83856
Policy Entropy: 3.67127
Value Function Loss: 0.06957

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.72403

Collected Steps per Second: 22,211.70412
Overall Steps per Second: 10,524.40823

Timestep Collection Time: 2.25305
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.75504

Cumulative Model Updates: 80,966
Cumulative Timesteps: 675,218,074

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 675218074...
Checkpoint 675218074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,002.63715
Policy Entropy: 3.67225
Value Function Loss: 0.07103

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.65848
Value Function Update Magnitude: 0.74361

Collected Steps per Second: 22,209.27720
Overall Steps per Second: 10,619.35258

Timestep Collection Time: 2.25140
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.70857

Cumulative Model Updates: 80,972
Cumulative Timesteps: 675,268,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.93234
Policy Entropy: 3.67231
Value Function Loss: 0.07258

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.72665
Value Function Update Magnitude: 0.71907

Collected Steps per Second: 22,037.13601
Overall Steps per Second: 10,495.48416

Timestep Collection Time: 2.27008
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.76643

Cumulative Model Updates: 80,978
Cumulative Timesteps: 675,318,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 675318102...
Checkpoint 675318102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.00856
Policy Entropy: 3.68194
Value Function Loss: 0.07225

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.69283
Value Function Update Magnitude: 0.64904

Collected Steps per Second: 22,267.13846
Overall Steps per Second: 10,662.48192

Timestep Collection Time: 2.24690
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.69234

Cumulative Model Updates: 80,984
Cumulative Timesteps: 675,368,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,456.04311
Policy Entropy: 3.67623
Value Function Loss: 0.07145

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.67920
Value Function Update Magnitude: 0.58871

Collected Steps per Second: 22,741.05677
Overall Steps per Second: 10,594.36242

Timestep Collection Time: 2.19902
Timestep Consumption Time: 2.52123
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.72025

Cumulative Model Updates: 80,990
Cumulative Timesteps: 675,418,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 675418142...
Checkpoint 675418142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,173.97178
Policy Entropy: 3.67724
Value Function Loss: 0.07296

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.64492
Value Function Update Magnitude: 0.64292

Collected Steps per Second: 22,052.75059
Overall Steps per Second: 10,448.88595

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.51871
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.78673

Cumulative Model Updates: 80,996
Cumulative Timesteps: 675,468,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,958.39592
Policy Entropy: 3.67317
Value Function Loss: 0.06973

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.59669
Value Function Update Magnitude: 0.76773

Collected Steps per Second: 22,690.21245
Overall Steps per Second: 10,615.80544

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.71128

Cumulative Model Updates: 81,002
Cumulative Timesteps: 675,518,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 675518172...
Checkpoint 675518172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,577.78186
Policy Entropy: 3.64120
Value Function Loss: 0.07338

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.60742
Value Function Update Magnitude: 0.78918

Collected Steps per Second: 22,379.96736
Overall Steps per Second: 10,554.04429

Timestep Collection Time: 2.23539
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.74017

Cumulative Model Updates: 81,008
Cumulative Timesteps: 675,568,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,052.79000
Policy Entropy: 3.63857
Value Function Loss: 0.07359

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.59936
Value Function Update Magnitude: 0.71293

Collected Steps per Second: 22,339.49502
Overall Steps per Second: 10,830.96526

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.37868
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.61732

Cumulative Model Updates: 81,014
Cumulative Timesteps: 675,618,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 675618210...
Checkpoint 675618210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.78729
Policy Entropy: 3.64206
Value Function Loss: 0.07496

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.61060
Value Function Update Magnitude: 0.78628

Collected Steps per Second: 21,798.88142
Overall Steps per Second: 10,652.64589

Timestep Collection Time: 2.29470
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.69573

Cumulative Model Updates: 81,020
Cumulative Timesteps: 675,668,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.44740
Policy Entropy: 3.65056
Value Function Loss: 0.07066

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.68495
Value Function Update Magnitude: 0.82520

Collected Steps per Second: 22,146.81203
Overall Steps per Second: 10,708.60258

Timestep Collection Time: 2.25793
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.66970

Cumulative Model Updates: 81,026
Cumulative Timesteps: 675,718,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 675718238...
Checkpoint 675718238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,364.82739
Policy Entropy: 3.65334
Value Function Loss: 0.07474

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.76337
Value Function Update Magnitude: 0.77156

Collected Steps per Second: 21,903.91817
Overall Steps per Second: 10,770.71624

Timestep Collection Time: 2.28361
Timestep Consumption Time: 2.36046
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.64407

Cumulative Model Updates: 81,032
Cumulative Timesteps: 675,768,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,694.89346
Policy Entropy: 3.66503
Value Function Loss: 0.07205

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.68175
Value Function Update Magnitude: 0.72424

Collected Steps per Second: 22,128.08228
Overall Steps per Second: 10,650.95718

Timestep Collection Time: 2.26020
Timestep Consumption Time: 2.43552
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.69573

Cumulative Model Updates: 81,038
Cumulative Timesteps: 675,818,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 675818272...
Checkpoint 675818272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,492.35420
Policy Entropy: 3.65150
Value Function Loss: 0.07477

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.71120

Collected Steps per Second: 21,705.26342
Overall Steps per Second: 10,598.01226

Timestep Collection Time: 2.30460
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71994

Cumulative Model Updates: 81,044
Cumulative Timesteps: 675,868,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.22903
Policy Entropy: 3.64920
Value Function Loss: 0.07290

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.64844

Collected Steps per Second: 22,624.61957
Overall Steps per Second: 10,775.75275

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.64283

Cumulative Model Updates: 81,050
Cumulative Timesteps: 675,918,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 675918324...
Checkpoint 675918324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,822.68804
Policy Entropy: 3.64153
Value Function Loss: 0.07344

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.67070

Collected Steps per Second: 22,137.72738
Overall Steps per Second: 10,680.20608

Timestep Collection Time: 2.26076
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.68605

Cumulative Model Updates: 81,056
Cumulative Timesteps: 675,968,372

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.72053
Policy Entropy: 3.64968
Value Function Loss: 0.07176

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.68236

Collected Steps per Second: 22,840.48339
Overall Steps per Second: 10,845.69818

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.42190
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.61178

Cumulative Model Updates: 81,062
Cumulative Timesteps: 676,018,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 676018390...
Checkpoint 676018390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,931.82785
Policy Entropy: 3.65421
Value Function Loss: 0.07030

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.69984

Collected Steps per Second: 21,810.63688
Overall Steps per Second: 10,461.12250

Timestep Collection Time: 2.29365
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.78209

Cumulative Model Updates: 81,068
Cumulative Timesteps: 676,068,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,702.63970
Policy Entropy: 3.63026
Value Function Loss: 0.06998

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.17286
Policy Update Magnitude: 0.49727
Value Function Update Magnitude: 0.76222

Collected Steps per Second: 22,219.17301
Overall Steps per Second: 10,662.03920

Timestep Collection Time: 2.25049
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.68991

Cumulative Model Updates: 81,074
Cumulative Timesteps: 676,118,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 676118420...
Checkpoint 676118420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,646.83233
Policy Entropy: 3.66377
Value Function Loss: 0.07012

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.41380
Value Function Update Magnitude: 0.76897

Collected Steps per Second: 22,067.05677
Overall Steps per Second: 10,615.49002

Timestep Collection Time: 2.26673
Timestep Consumption Time: 2.44525
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.71198

Cumulative Model Updates: 81,080
Cumulative Timesteps: 676,168,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,076.37793
Policy Entropy: 3.65644
Value Function Loss: 0.06949

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.46897
Value Function Update Magnitude: 0.77367

Collected Steps per Second: 22,646.91860
Overall Steps per Second: 10,552.88555

Timestep Collection Time: 2.20869
Timestep Consumption Time: 2.53125
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73994

Cumulative Model Updates: 81,086
Cumulative Timesteps: 676,218,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 676218460...
Checkpoint 676218460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,680.28338
Policy Entropy: 3.68123
Value Function Loss: 0.06807

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.51931
Value Function Update Magnitude: 0.82862

Collected Steps per Second: 22,060.32188
Overall Steps per Second: 10,597.76918

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.72043

Cumulative Model Updates: 81,092
Cumulative Timesteps: 676,268,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.66373
Policy Entropy: 3.67982
Value Function Loss: 0.06692

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.84910

Collected Steps per Second: 22,661.00815
Overall Steps per Second: 10,602.15588

Timestep Collection Time: 2.20802
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.71942

Cumulative Model Updates: 81,098
Cumulative Timesteps: 676,318,522

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 676318522...
Checkpoint 676318522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.26509
Policy Entropy: 3.67938
Value Function Loss: 0.06863

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.86375

Collected Steps per Second: 22,535.10819
Overall Steps per Second: 10,568.26811

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.73171

Cumulative Model Updates: 81,104
Cumulative Timesteps: 676,368,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.60615
Policy Entropy: 3.67819
Value Function Loss: 0.06934

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.83498

Collected Steps per Second: 22,602.40270
Overall Steps per Second: 10,577.94173

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.72814

Cumulative Model Updates: 81,110
Cumulative Timesteps: 676,418,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 676418542...
Checkpoint 676418542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,814.74640
Policy Entropy: 3.66331
Value Function Loss: 0.07633

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06020
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.69524

Collected Steps per Second: 22,700.42310
Overall Steps per Second: 10,822.78516

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.62358

Cumulative Model Updates: 81,116
Cumulative Timesteps: 676,468,582

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,298.40273
Policy Entropy: 3.66386
Value Function Loss: 0.07692

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.66480
Value Function Update Magnitude: 0.67173

Collected Steps per Second: 21,784.44405
Overall Steps per Second: 10,517.68654

Timestep Collection Time: 2.29531
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.75409

Cumulative Model Updates: 81,122
Cumulative Timesteps: 676,518,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 676518584...
Checkpoint 676518584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,875.34009
Policy Entropy: 3.66415
Value Function Loss: 0.07645

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.70139
Value Function Update Magnitude: 0.62263

Collected Steps per Second: 22,364.21125
Overall Steps per Second: 10,717.47314

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.66733

Cumulative Model Updates: 81,128
Cumulative Timesteps: 676,568,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,180.03397
Policy Entropy: 3.67311
Value Function Loss: 0.07412

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.68362
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 22,466.71663
Overall Steps per Second: 10,555.59661

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.51161
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.73739

Cumulative Model Updates: 81,134
Cumulative Timesteps: 676,618,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 676618612...
Checkpoint 676618612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,000.87802
Policy Entropy: 3.67436
Value Function Loss: 0.07374

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.69946
Value Function Update Magnitude: 0.67009

Collected Steps per Second: 22,287.39996
Overall Steps per Second: 10,476.96680

Timestep Collection Time: 2.24378
Timestep Consumption Time: 2.52936
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.77314

Cumulative Model Updates: 81,140
Cumulative Timesteps: 676,668,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.22325
Policy Entropy: 3.66367
Value Function Loss: 0.07567

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.62834
Value Function Update Magnitude: 0.77935

Collected Steps per Second: 22,775.27638
Overall Steps per Second: 10,542.01582

Timestep Collection Time: 2.19633
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.74501

Cumulative Model Updates: 81,146
Cumulative Timesteps: 676,718,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 676718642...
Checkpoint 676718642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,640.66764
Policy Entropy: 3.66516
Value Function Loss: 0.07497

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.82340

Collected Steps per Second: 22,161.36544
Overall Steps per Second: 10,597.98990

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.71920

Cumulative Model Updates: 81,152
Cumulative Timesteps: 676,768,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,242.48664
Policy Entropy: 3.65671
Value Function Loss: 0.07449

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.59834
Value Function Update Magnitude: 0.81888

Collected Steps per Second: 22,583.71721
Overall Steps per Second: 10,595.26539

Timestep Collection Time: 2.21487
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.72098

Cumulative Model Updates: 81,158
Cumulative Timesteps: 676,818,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 676818676...
Checkpoint 676818676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,237.13982
Policy Entropy: 3.65985
Value Function Loss: 0.07607

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.62714
Value Function Update Magnitude: 0.76218

Collected Steps per Second: 22,288.86548
Overall Steps per Second: 10,475.77356

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.53015
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.77387

Cumulative Model Updates: 81,164
Cumulative Timesteps: 676,868,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.97022
Policy Entropy: 3.66664
Value Function Loss: 0.07556

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.79935

Collected Steps per Second: 22,778.29940
Overall Steps per Second: 10,653.81517

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69428

Cumulative Model Updates: 81,170
Cumulative Timesteps: 676,918,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 676918698...
Checkpoint 676918698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.55521
Policy Entropy: 3.66843
Value Function Loss: 0.07627

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.50575
Value Function Update Magnitude: 0.76272

Collected Steps per Second: 22,511.76217
Overall Steps per Second: 10,563.62366

Timestep Collection Time: 2.22204
Timestep Consumption Time: 2.51327
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.73531

Cumulative Model Updates: 81,176
Cumulative Timesteps: 676,968,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,654.85570
Policy Entropy: 3.67865
Value Function Loss: 0.07616

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.49055
Value Function Update Magnitude: 0.73414

Collected Steps per Second: 22,428.74036
Overall Steps per Second: 10,681.58221

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.68208

Cumulative Model Updates: 81,182
Cumulative Timesteps: 677,018,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 677018732...
Checkpoint 677018732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,698.88464
Policy Entropy: 3.67460
Value Function Loss: 0.08035

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.47764
Value Function Update Magnitude: 0.70462

Collected Steps per Second: 22,048.60199
Overall Steps per Second: 10,476.79473

Timestep Collection Time: 2.26799
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77302

Cumulative Model Updates: 81,188
Cumulative Timesteps: 677,068,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.05799
Policy Entropy: 3.67551
Value Function Loss: 0.07924

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.50937
Value Function Update Magnitude: 0.63122

Collected Steps per Second: 22,761.20730
Overall Steps per Second: 10,726.00824

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.66175

Cumulative Model Updates: 81,194
Cumulative Timesteps: 677,118,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 677118740...
Checkpoint 677118740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,000.12812
Policy Entropy: 3.67091
Value Function Loss: 0.08039

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.49515
Value Function Update Magnitude: 0.62465

Collected Steps per Second: 22,540.03442
Overall Steps per Second: 10,664.15420

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.69085

Cumulative Model Updates: 81,200
Cumulative Timesteps: 677,168,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,446.30409
Policy Entropy: 3.67626
Value Function Loss: 0.08121

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.67748

Collected Steps per Second: 22,685.83198
Overall Steps per Second: 10,601.66078

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.71813

Cumulative Model Updates: 81,206
Cumulative Timesteps: 677,218,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 677218784...
Checkpoint 677218784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,942.22607
Policy Entropy: 3.66606
Value Function Loss: 0.08248

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.51607
Value Function Update Magnitude: 0.71275

Collected Steps per Second: 22,671.55835
Overall Steps per Second: 10,636.61266

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.70300

Cumulative Model Updates: 81,212
Cumulative Timesteps: 677,268,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,537.21239
Policy Entropy: 3.66475
Value Function Loss: 0.08200

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.50621
Value Function Update Magnitude: 0.69802

Collected Steps per Second: 22,651.29874
Overall Steps per Second: 10,757.99356

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.44130
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.64957

Cumulative Model Updates: 81,218
Cumulative Timesteps: 677,318,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 677318828...
Checkpoint 677318828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,605.20947
Policy Entropy: 3.65853
Value Function Loss: 0.07952

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.42349
Value Function Update Magnitude: 0.74680

Collected Steps per Second: 22,290.50099
Overall Steps per Second: 10,428.62430

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.55159
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.79488

Cumulative Model Updates: 81,224
Cumulative Timesteps: 677,368,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,379.73749
Policy Entropy: 3.67903
Value Function Loss: 0.07633

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.46449
Value Function Update Magnitude: 0.73001

Collected Steps per Second: 22,873.80278
Overall Steps per Second: 10,677.97406

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.68329

Cumulative Model Updates: 81,230
Cumulative Timesteps: 677,418,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 677418840...
Checkpoint 677418840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,213.22222
Policy Entropy: 3.67094
Value Function Loss: 0.07544

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.77098

Collected Steps per Second: 22,557.90737
Overall Steps per Second: 10,595.54919

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71972

Cumulative Model Updates: 81,236
Cumulative Timesteps: 677,468,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,472.10347
Policy Entropy: 3.67793
Value Function Loss: 0.07471

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.74849

Collected Steps per Second: 22,501.75522
Overall Steps per Second: 10,555.26898

Timestep Collection Time: 2.22294
Timestep Consumption Time: 2.51593
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.73887

Cumulative Model Updates: 81,242
Cumulative Timesteps: 677,518,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 677518868...
Checkpoint 677518868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.37647
Policy Entropy: 3.68233
Value Function Loss: 0.07524

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.50848
Value Function Update Magnitude: 0.71134

Collected Steps per Second: 22,480.49716
Overall Steps per Second: 10,552.57548

Timestep Collection Time: 2.22415
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73818

Cumulative Model Updates: 81,248
Cumulative Timesteps: 677,568,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.73616
Policy Entropy: 3.67843
Value Function Loss: 0.07684

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.76798

Collected Steps per Second: 22,655.20179
Overall Steps per Second: 10,626.77553

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.70566

Cumulative Model Updates: 81,254
Cumulative Timesteps: 677,618,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 677618874...
Checkpoint 677618874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.87041
Policy Entropy: 3.67294
Value Function Loss: 0.07703

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.73079

Collected Steps per Second: 22,358.25058
Overall Steps per Second: 10,497.99207

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.52762
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.76491

Cumulative Model Updates: 81,260
Cumulative Timesteps: 677,668,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,603.26705
Policy Entropy: 3.66586
Value Function Loss: 0.07846

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.61369
Value Function Update Magnitude: 0.61941

Collected Steps per Second: 22,463.88773
Overall Steps per Second: 10,535.39952

Timestep Collection Time: 2.22579
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.74590

Cumulative Model Updates: 81,266
Cumulative Timesteps: 677,718,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 677718896...
Checkpoint 677718896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.61666
Policy Entropy: 3.66996
Value Function Loss: 0.07546

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06868
Policy Update Magnitude: 0.69147
Value Function Update Magnitude: 0.64136

Collected Steps per Second: 22,273.38970
Overall Steps per Second: 10,561.71551

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.73673

Cumulative Model Updates: 81,272
Cumulative Timesteps: 677,768,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.46802
Policy Entropy: 3.67738
Value Function Loss: 0.07563

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.71357
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 22,845.76610
Overall Steps per Second: 10,798.12255

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.63284

Cumulative Model Updates: 81,278
Cumulative Timesteps: 677,818,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 677818950...
Checkpoint 677818950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,612.55541
Policy Entropy: 3.67695
Value Function Loss: 0.07846

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.73168
Value Function Update Magnitude: 0.62130

Collected Steps per Second: 22,364.91035
Overall Steps per Second: 10,696.42452

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.67446

Cumulative Model Updates: 81,284
Cumulative Timesteps: 677,868,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,606.34999
Policy Entropy: 3.68420
Value Function Loss: 0.08136

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.64503
Value Function Update Magnitude: 0.65117

Collected Steps per Second: 22,739.89705
Overall Steps per Second: 10,601.83148

Timestep Collection Time: 2.19922
Timestep Consumption Time: 2.51789
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.71711

Cumulative Model Updates: 81,290
Cumulative Timesteps: 677,918,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 677918960...
Checkpoint 677918960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,987.48963
Policy Entropy: 3.66960
Value Function Loss: 0.08154

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.57212
Value Function Update Magnitude: 0.69877

Collected Steps per Second: 22,781.45937
Overall Steps per Second: 10,631.78582

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.70307

Cumulative Model Updates: 81,296
Cumulative Timesteps: 677,968,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,836.45716
Policy Entropy: 3.68264
Value Function Loss: 0.07834

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.70359

Collected Steps per Second: 22,860.55350
Overall Steps per Second: 10,653.98568

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69364

Cumulative Model Updates: 81,302
Cumulative Timesteps: 678,018,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 678018968...
Checkpoint 678018968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,062.52606
Policy Entropy: 3.67156
Value Function Loss: 0.07573

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.49357
Value Function Update Magnitude: 0.71766

Collected Steps per Second: 22,642.71089
Overall Steps per Second: 10,536.30429

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.53850
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74777

Cumulative Model Updates: 81,308
Cumulative Timesteps: 678,068,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,089.97466
Policy Entropy: 3.67091
Value Function Loss: 0.07300

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.77337

Collected Steps per Second: 22,708.40562
Overall Steps per Second: 10,717.80646

Timestep Collection Time: 2.20200
Timestep Consumption Time: 2.46350
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.66551

Cumulative Model Updates: 81,314
Cumulative Timesteps: 678,118,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 678118996...
Checkpoint 678118996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,904.34836
Policy Entropy: 3.67017
Value Function Loss: 0.07427

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.60193
Value Function Update Magnitude: 0.74666

Collected Steps per Second: 22,586.50776
Overall Steps per Second: 10,631.58085

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70542

Cumulative Model Updates: 81,320
Cumulative Timesteps: 678,169,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.41878
Policy Entropy: 3.66581
Value Function Loss: 0.07562

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.50741
Value Function Update Magnitude: 0.76747

Collected Steps per Second: 21,711.46943
Overall Steps per Second: 10,548.03424

Timestep Collection Time: 2.30367
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.74174

Cumulative Model Updates: 81,326
Cumulative Timesteps: 678,219,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 678219038...
Checkpoint 678219038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,149.10884
Policy Entropy: 3.66791
Value Function Loss: 0.07733

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.79294

Collected Steps per Second: 21,881.58257
Overall Steps per Second: 10,581.51601

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.72862

Cumulative Model Updates: 81,332
Cumulative Timesteps: 678,269,074

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,941.04484
Policy Entropy: 3.66739
Value Function Loss: 0.07813

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.54093
Value Function Update Magnitude: 0.70526

Collected Steps per Second: 22,011.72624
Overall Steps per Second: 10,780.10402

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.36817
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.64114

Cumulative Model Updates: 81,338
Cumulative Timesteps: 678,319,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 678319106...
Checkpoint 678319106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,929.83545
Policy Entropy: 3.65716
Value Function Loss: 0.07970

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.65037

Collected Steps per Second: 21,627.27201
Overall Steps per Second: 10,691.51046

Timestep Collection Time: 2.31393
Timestep Consumption Time: 2.36679
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.68072

Cumulative Model Updates: 81,344
Cumulative Timesteps: 678,369,150

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,104.80222
Policy Entropy: 3.65783
Value Function Loss: 0.07839

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.70598

Collected Steps per Second: 21,525.79522
Overall Steps per Second: 10,530.98931

Timestep Collection Time: 2.32391
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.75017

Cumulative Model Updates: 81,350
Cumulative Timesteps: 678,419,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678419174...
Checkpoint 678419174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.25280
Policy Entropy: 3.65755
Value Function Loss: 0.07739

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.53600
Value Function Update Magnitude: 0.66910

Collected Steps per Second: 21,833.47687
Overall Steps per Second: 10,645.19670

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.40766
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.69846

Cumulative Model Updates: 81,356
Cumulative Timesteps: 678,469,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.06675
Policy Entropy: 3.67677
Value Function Loss: 0.07621

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.67515

Collected Steps per Second: 22,639.78950
Overall Steps per Second: 10,785.01286

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.63699

Cumulative Model Updates: 81,362
Cumulative Timesteps: 678,519,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 678519200...
Checkpoint 678519200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.09004
Policy Entropy: 3.68367
Value Function Loss: 0.07609

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.16345
Policy Update Magnitude: 0.49131
Value Function Update Magnitude: 0.75432

Collected Steps per Second: 22,312.43332
Overall Steps per Second: 10,752.33583

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.65090

Cumulative Model Updates: 81,368
Cumulative Timesteps: 678,569,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.36083
Policy Entropy: 3.69591
Value Function Loss: 0.07359

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.58822
Value Function Update Magnitude: 0.77581

Collected Steps per Second: 22,574.23168
Overall Steps per Second: 10,767.19911

Timestep Collection Time: 2.21509
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.64410

Cumulative Model Updates: 81,374
Cumulative Timesteps: 678,619,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 678619212...
Checkpoint 678619212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.35966
Policy Entropy: 3.69959
Value Function Loss: 0.07122

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.63555
Value Function Update Magnitude: 0.85465

Collected Steps per Second: 21,727.89886
Overall Steps per Second: 10,359.37516

Timestep Collection Time: 2.30174
Timestep Consumption Time: 2.52596
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.82770

Cumulative Model Updates: 81,380
Cumulative Timesteps: 678,669,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,783.84743
Policy Entropy: 3.70237
Value Function Loss: 0.07108

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.61344
Value Function Update Magnitude: 0.88588

Collected Steps per Second: 22,320.74807
Overall Steps per Second: 10,528.17407

Timestep Collection Time: 2.24034
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.74973

Cumulative Model Updates: 81,386
Cumulative Timesteps: 678,719,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 678719230...
Checkpoint 678719230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,216.04786
Policy Entropy: 3.70205
Value Function Loss: 0.07125

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.62056
Value Function Update Magnitude: 0.90892

Collected Steps per Second: 22,864.29058
Overall Steps per Second: 10,727.19386

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.47443
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.66142

Cumulative Model Updates: 81,392
Cumulative Timesteps: 678,769,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,783.30145
Policy Entropy: 3.69767
Value Function Loss: 0.07018

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.91780

Collected Steps per Second: 22,601.60874
Overall Steps per Second: 10,705.40119

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.67241

Cumulative Model Updates: 81,398
Cumulative Timesteps: 678,819,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 678819254...
Checkpoint 678819254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.94466
Policy Entropy: 3.70278
Value Function Loss: 0.07269

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.61930
Value Function Update Magnitude: 0.83014

Collected Steps per Second: 22,829.91549
Overall Steps per Second: 10,748.53298

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.65384

Cumulative Model Updates: 81,404
Cumulative Timesteps: 678,869,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.92263
Policy Entropy: 3.70635
Value Function Loss: 0.07415

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.68016
Value Function Update Magnitude: 0.77083

Collected Steps per Second: 22,921.33511
Overall Steps per Second: 10,775.32605

Timestep Collection Time: 2.18216
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.64190

Cumulative Model Updates: 81,410
Cumulative Timesteps: 678,919,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 678919294...
Checkpoint 678919294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,986.01941
Policy Entropy: 3.70454
Value Function Loss: 0.07370

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.60212
Value Function Update Magnitude: 0.84478

Collected Steps per Second: 22,747.11987
Overall Steps per Second: 10,649.10660

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.49985
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.70030

Cumulative Model Updates: 81,416
Cumulative Timesteps: 678,969,348

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.89571
Policy Entropy: 3.69559
Value Function Loss: 0.06998

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.91369

Collected Steps per Second: 22,469.42080
Overall Steps per Second: 10,817.49544

Timestep Collection Time: 2.22525
Timestep Consumption Time: 2.39690
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62214

Cumulative Model Updates: 81,422
Cumulative Timesteps: 679,019,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 679019348...
Checkpoint 679019348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,565.35579
Policy Entropy: 3.69454
Value Function Loss: 0.06874

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.61787
Value Function Update Magnitude: 0.90412

Collected Steps per Second: 22,403.64063
Overall Steps per Second: 10,699.61047

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.67456

Cumulative Model Updates: 81,428
Cumulative Timesteps: 679,069,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.55285
Policy Entropy: 3.68685
Value Function Loss: 0.06912

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.70286
Value Function Update Magnitude: 0.88616

Collected Steps per Second: 22,918.28341
Overall Steps per Second: 10,848.36105

Timestep Collection Time: 2.18262
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61102

Cumulative Model Updates: 81,434
Cumulative Timesteps: 679,119,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 679119386...
Checkpoint 679119386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,483.19593
Policy Entropy: 3.68521
Value Function Loss: 0.07519

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.63768
Value Function Update Magnitude: 0.79528

Collected Steps per Second: 22,735.57166
Overall Steps per Second: 10,747.34487

Timestep Collection Time: 2.19990
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.65380

Cumulative Model Updates: 81,440
Cumulative Timesteps: 679,169,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.85315
Policy Entropy: 3.67638
Value Function Loss: 0.07552

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.73308

Collected Steps per Second: 22,607.18137
Overall Steps per Second: 10,628.25026

Timestep Collection Time: 2.21222
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.70557

Cumulative Model Updates: 81,446
Cumulative Timesteps: 679,219,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 679219414...
Checkpoint 679219414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,142.32601
Policy Entropy: 3.66511
Value Function Loss: 0.07942

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.48329
Value Function Update Magnitude: 0.68860

Collected Steps per Second: 22,807.79104
Overall Steps per Second: 10,807.14725

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62731

Cumulative Model Updates: 81,452
Cumulative Timesteps: 679,269,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,627.10676
Policy Entropy: 3.66773
Value Function Loss: 0.08035

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.46305
Value Function Update Magnitude: 0.67843

Collected Steps per Second: 22,732.73331
Overall Steps per Second: 10,619.68937

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.50896
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.70861

Cumulative Model Updates: 81,458
Cumulative Timesteps: 679,319,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 679319426...
Checkpoint 679319426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,053.54920
Policy Entropy: 3.67072
Value Function Loss: 0.08236

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.44386
Value Function Update Magnitude: 0.68664

Collected Steps per Second: 22,483.96790
Overall Steps per Second: 10,555.76611

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.51435
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.73940

Cumulative Model Updates: 81,464
Cumulative Timesteps: 679,369,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,975.62072
Policy Entropy: 3.67201
Value Function Loss: 0.07948

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.44914
Value Function Update Magnitude: 0.68590

Collected Steps per Second: 22,626.91671
Overall Steps per Second: 10,617.66825

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71007

Cumulative Model Updates: 81,470
Cumulative Timesteps: 679,419,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 679419464...
Checkpoint 679419464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,491.29781
Policy Entropy: 3.67422
Value Function Loss: 0.07735

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.44128
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,849.35402
Overall Steps per Second: 10,682.73765

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.68064

Cumulative Model Updates: 81,476
Cumulative Timesteps: 679,469,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,812.06784
Policy Entropy: 3.67493
Value Function Loss: 0.08057

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.51363
Value Function Update Magnitude: 0.62362

Collected Steps per Second: 23,010.57438
Overall Steps per Second: 10,722.79713

Timestep Collection Time: 2.17378
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.66483

Cumulative Model Updates: 81,482
Cumulative Timesteps: 679,519,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 679519486...
Checkpoint 679519486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,294.22709
Policy Entropy: 3.68649
Value Function Loss: 0.08096

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.52641
Value Function Update Magnitude: 0.66156

Collected Steps per Second: 22,738.98086
Overall Steps per Second: 10,634.86390

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70208

Cumulative Model Updates: 81,488
Cumulative Timesteps: 679,569,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,247.05797
Policy Entropy: 3.70508
Value Function Loss: 0.07835

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.43998
Value Function Update Magnitude: 0.79234

Collected Steps per Second: 22,837.44578
Overall Steps per Second: 10,742.68960

Timestep Collection Time: 2.18974
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.65507

Cumulative Model Updates: 81,494
Cumulative Timesteps: 679,619,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 679619500...
Checkpoint 679619500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.82762
Policy Entropy: 3.70857
Value Function Loss: 0.07351

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.85569

Collected Steps per Second: 22,461.71789
Overall Steps per Second: 10,739.61821

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.43082
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.65789

Cumulative Model Updates: 81,500
Cumulative Timesteps: 679,669,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,372.19308
Policy Entropy: 3.69799
Value Function Loss: 0.07220

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.50149
Value Function Update Magnitude: 0.87602

Collected Steps per Second: 22,864.77520
Overall Steps per Second: 10,691.72173

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.49044
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.67782

Cumulative Model Updates: 81,506
Cumulative Timesteps: 679,719,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 679719538...
Checkpoint 679719538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,467.86372
Policy Entropy: 3.68573
Value Function Loss: 0.07309

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.88972

Collected Steps per Second: 22,835.02394
Overall Steps per Second: 10,878.23328

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.40672
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.59633

Cumulative Model Updates: 81,512
Cumulative Timesteps: 679,769,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,371.78437
Policy Entropy: 3.67265
Value Function Loss: 0.07453

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.49953
Value Function Update Magnitude: 0.80111

Collected Steps per Second: 22,787.68842
Overall Steps per Second: 10,704.53272

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.47754
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.67241

Cumulative Model Updates: 81,518
Cumulative Timesteps: 679,819,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 679819554...
Checkpoint 679819554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.63312
Policy Entropy: 3.67264
Value Function Loss: 0.07489

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.46192
Value Function Update Magnitude: 0.74463

Collected Steps per Second: 22,899.14748
Overall Steps per Second: 10,810.84821

Timestep Collection Time: 2.18349
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.62498

Cumulative Model Updates: 81,524
Cumulative Timesteps: 679,869,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,800.45640
Policy Entropy: 3.66888
Value Function Loss: 0.07613

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.69242

Collected Steps per Second: 22,611.87540
Overall Steps per Second: 10,614.40662

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.71454

Cumulative Model Updates: 81,530
Cumulative Timesteps: 679,919,596

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 679919596...
Checkpoint 679919596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,970.48617
Policy Entropy: 3.67746
Value Function Loss: 0.07673

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.70087

Collected Steps per Second: 22,689.02615
Overall Steps per Second: 10,625.37961

Timestep Collection Time: 2.20424
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.70684

Cumulative Model Updates: 81,536
Cumulative Timesteps: 679,969,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,130.39407
Policy Entropy: 3.66974
Value Function Loss: 0.07667

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.52362
Value Function Update Magnitude: 0.70210

Collected Steps per Second: 22,844.84507
Overall Steps per Second: 10,806.77570

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62802

Cumulative Model Updates: 81,542
Cumulative Timesteps: 680,019,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 680019622...
Checkpoint 680019622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,300.29215
Policy Entropy: 3.66511
Value Function Loss: 0.07622

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.50006
Value Function Update Magnitude: 0.67543

Collected Steps per Second: 22,691.05348
Overall Steps per Second: 10,660.44738

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.48692
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69061

Cumulative Model Updates: 81,548
Cumulative Timesteps: 680,069,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,033.28708
Policy Entropy: 3.65336
Value Function Loss: 0.07911

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.50827
Value Function Update Magnitude: 0.75975

Collected Steps per Second: 22,752.68566
Overall Steps per Second: 10,819.72455

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62378

Cumulative Model Updates: 81,554
Cumulative Timesteps: 680,119,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 680119654...
Checkpoint 680119654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,096.70626
Policy Entropy: 3.65581
Value Function Loss: 0.07784

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.76808

Collected Steps per Second: 22,564.77121
Overall Steps per Second: 10,738.79528

Timestep Collection Time: 2.21682
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.65806

Cumulative Model Updates: 81,560
Cumulative Timesteps: 680,169,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,587.04528
Policy Entropy: 3.66212
Value Function Loss: 0.07679

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.50908
Value Function Update Magnitude: 0.74174

Collected Steps per Second: 22,452.95378
Overall Steps per Second: 10,593.31658

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.72222

Cumulative Model Updates: 81,566
Cumulative Timesteps: 680,219,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 680219700...
Checkpoint 680219700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.27114
Policy Entropy: 3.67390
Value Function Loss: 0.07520

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.73643

Collected Steps per Second: 22,780.70504
Overall Steps per Second: 10,696.17665

Timestep Collection Time: 2.19598
Timestep Consumption Time: 2.48102
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.67700

Cumulative Model Updates: 81,572
Cumulative Timesteps: 680,269,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.01752
Policy Entropy: 3.68109
Value Function Loss: 0.07415

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.60335
Value Function Update Magnitude: 0.78546

Collected Steps per Second: 22,138.74199
Overall Steps per Second: 10,734.66619

Timestep Collection Time: 2.25930
Timestep Consumption Time: 2.40019
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.65948

Cumulative Model Updates: 81,578
Cumulative Timesteps: 680,319,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 680319744...
Checkpoint 680319744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.10401
Policy Entropy: 3.68207
Value Function Loss: 0.07289

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.68260
Value Function Update Magnitude: 0.81897

Collected Steps per Second: 22,155.01764
Overall Steps per Second: 10,691.02394

Timestep Collection Time: 2.25818
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.67963

Cumulative Model Updates: 81,584
Cumulative Timesteps: 680,369,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,695.40319
Policy Entropy: 3.67204
Value Function Loss: 0.07346

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.63322
Value Function Update Magnitude: 0.88116

Collected Steps per Second: 22,017.31648
Overall Steps per Second: 10,791.58892

Timestep Collection Time: 2.27121
Timestep Consumption Time: 2.36258
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.63379

Cumulative Model Updates: 81,590
Cumulative Timesteps: 680,419,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 680419780...
Checkpoint 680419780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.76197
Policy Entropy: 3.66395
Value Function Loss: 0.07425

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.57268
Value Function Update Magnitude: 0.84430

Collected Steps per Second: 22,031.27841
Overall Steps per Second: 10,674.48637

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.68519

Cumulative Model Updates: 81,596
Cumulative Timesteps: 680,469,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.50769
Policy Entropy: 3.66463
Value Function Loss: 0.07581

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.76993

Collected Steps per Second: 22,303.39239
Overall Steps per Second: 10,602.61891

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.71808

Cumulative Model Updates: 81,602
Cumulative Timesteps: 680,519,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 680519816...
Checkpoint 680519816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,058.16572
Policy Entropy: 3.67506
Value Function Loss: 0.07587

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.50804
Value Function Update Magnitude: 0.78846

Collected Steps per Second: 22,988.72238
Overall Steps per Second: 10,892.40842

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59127

Cumulative Model Updates: 81,608
Cumulative Timesteps: 680,569,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.05482
Policy Entropy: 3.67711
Value Function Loss: 0.07735

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.46854
Value Function Update Magnitude: 0.75082

Collected Steps per Second: 22,613.54610
Overall Steps per Second: 10,675.61505

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68488

Cumulative Model Updates: 81,614
Cumulative Timesteps: 680,619,840

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 680619840...
Checkpoint 680619840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.40858
Policy Entropy: 3.69919
Value Function Loss: 0.07772

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.46797
Value Function Update Magnitude: 0.69930

Collected Steps per Second: 22,645.64122
Overall Steps per Second: 10,839.71555

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.40522
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.61359

Cumulative Model Updates: 81,620
Cumulative Timesteps: 680,669,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,203.91461
Policy Entropy: 3.68303
Value Function Loss: 0.07640

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.51952
Value Function Update Magnitude: 0.68563

Collected Steps per Second: 22,731.52044
Overall Steps per Second: 10,624.87871

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.70707

Cumulative Model Updates: 81,626
Cumulative Timesteps: 680,719,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 680719862...
Checkpoint 680719862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,561.91560
Policy Entropy: 3.68244
Value Function Loss: 0.07374

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.52393
Value Function Update Magnitude: 0.68967

Collected Steps per Second: 22,563.77727
Overall Steps per Second: 10,592.11072

Timestep Collection Time: 2.21656
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.72182

Cumulative Model Updates: 81,632
Cumulative Timesteps: 680,769,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,188.39102
Policy Entropy: 3.66543
Value Function Loss: 0.07536

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.66507

Collected Steps per Second: 22,656.12388
Overall Steps per Second: 10,778.19610

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.43306
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.64085

Cumulative Model Updates: 81,638
Cumulative Timesteps: 680,819,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 680819896...
Checkpoint 680819896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,542.20259
Policy Entropy: 3.66512
Value Function Loss: 0.07739

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.57102
Value Function Update Magnitude: 0.67631

Collected Steps per Second: 15,897.59972
Overall Steps per Second: 7,391.99816

Timestep Collection Time: 3.14563
Timestep Consumption Time: 3.61952
PPO Batch Consumption Time: 0.35203
Total Iteration Time: 6.76515

Cumulative Model Updates: 81,644
Cumulative Timesteps: 680,869,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,581.32841
Policy Entropy: 3.68022
Value Function Loss: 0.07548

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.67364

Collected Steps per Second: 18,792.36637
Overall Steps per Second: 9,639.41326

Timestep Collection Time: 2.66183
Timestep Consumption Time: 2.52749
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 5.18932

Cumulative Model Updates: 81,650
Cumulative Timesteps: 680,919,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 680919926...
Checkpoint 680919926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.33874
Policy Entropy: 3.70122
Value Function Loss: 0.07202

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.51624
Value Function Update Magnitude: 0.72283

Collected Steps per Second: 22,142.19835
Overall Steps per Second: 10,494.71367

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.50617
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.76430

Cumulative Model Updates: 81,656
Cumulative Timesteps: 680,969,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.71402
Policy Entropy: 3.71078
Value Function Loss: 0.06854

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.44899
Value Function Update Magnitude: 0.68420

Collected Steps per Second: 21,346.54439
Overall Steps per Second: 10,304.31640

Timestep Collection Time: 2.34333
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.85447

Cumulative Model Updates: 81,662
Cumulative Timesteps: 681,019,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 681019948...
Checkpoint 681019948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,514.23744
Policy Entropy: 3.69767
Value Function Loss: 0.06894

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.49111
Value Function Update Magnitude: 0.70714

Collected Steps per Second: 22,194.17932
Overall Steps per Second: 10,677.14833

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.68383

Cumulative Model Updates: 81,668
Cumulative Timesteps: 681,069,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,095.13014
Policy Entropy: 3.67939
Value Function Loss: 0.06814

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.49461
Value Function Update Magnitude: 0.69435

Collected Steps per Second: 22,493.28998
Overall Steps per Second: 10,560.24387

Timestep Collection Time: 2.22324
Timestep Consumption Time: 2.51226
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73550

Cumulative Model Updates: 81,674
Cumulative Timesteps: 681,119,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 681119966...
Checkpoint 681119966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,551.16487
Policy Entropy: 3.68580
Value Function Loss: 0.06726

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.44615
Value Function Update Magnitude: 0.72579

Collected Steps per Second: 22,193.76845
Overall Steps per Second: 10,609.71356

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.71342

Cumulative Model Updates: 81,680
Cumulative Timesteps: 681,169,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.92791
Policy Entropy: 3.70423
Value Function Loss: 0.06227

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.47920
Value Function Update Magnitude: 0.74402

Collected Steps per Second: 22,272.04030
Overall Steps per Second: 10,503.98014

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.76048

Cumulative Model Updates: 81,686
Cumulative Timesteps: 681,219,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 681219978...
Checkpoint 681219978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,037.42883
Policy Entropy: 3.70741
Value Function Loss: 0.06006

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.69006

Collected Steps per Second: 22,484.07749
Overall Steps per Second: 10,605.47168

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71662

Cumulative Model Updates: 81,692
Cumulative Timesteps: 681,270,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,029.93545
Policy Entropy: 3.69980
Value Function Loss: 0.05852

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06942
Policy Update Magnitude: 0.70915
Value Function Update Magnitude: 0.72707

Collected Steps per Second: 22,650.77046
Overall Steps per Second: 10,599.01738

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.51109
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.71949

Cumulative Model Updates: 81,698
Cumulative Timesteps: 681,320,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 681320022...
Checkpoint 681320022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.08003
Policy Entropy: 3.69515
Value Function Loss: 0.05823

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.77490
Value Function Update Magnitude: 0.76983

Collected Steps per Second: 22,387.39351
Overall Steps per Second: 10,515.69710

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.52170
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.75537

Cumulative Model Updates: 81,704
Cumulative Timesteps: 681,370,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.35056
Policy Entropy: 3.70179
Value Function Loss: 0.05887

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.68930
Value Function Update Magnitude: 0.75878

Collected Steps per Second: 22,726.90303
Overall Steps per Second: 10,609.42895

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.71449

Cumulative Model Updates: 81,710
Cumulative Timesteps: 681,420,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 681420046...
Checkpoint 681420046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,569.44413
Policy Entropy: 3.70054
Value Function Loss: 0.05862

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.60312
Value Function Update Magnitude: 0.73268

Collected Steps per Second: 22,403.25692
Overall Steps per Second: 10,508.32074

Timestep Collection Time: 2.23298
Timestep Consumption Time: 2.52763
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.76061

Cumulative Model Updates: 81,716
Cumulative Timesteps: 681,470,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.98592
Policy Entropy: 3.69826
Value Function Loss: 0.05748

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.65688
Value Function Update Magnitude: 0.79067

Collected Steps per Second: 22,674.65024
Overall Steps per Second: 10,533.53703

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.54215
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.74769

Cumulative Model Updates: 81,722
Cumulative Timesteps: 681,520,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 681520082...
Checkpoint 681520082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,756.29158
Policy Entropy: 3.69994
Value Function Loss: 0.05533

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.80691

Collected Steps per Second: 22,052.15748
Overall Steps per Second: 10,544.38930

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.47530
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.74338

Cumulative Model Updates: 81,728
Cumulative Timesteps: 681,570,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.36689
Policy Entropy: 3.70387
Value Function Loss: 0.05826

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.82629

Collected Steps per Second: 22,447.99200
Overall Steps per Second: 10,646.19142

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.69708

Cumulative Model Updates: 81,734
Cumulative Timesteps: 681,620,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 681620104...
Checkpoint 681620104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.76592
Policy Entropy: 3.70523
Value Function Loss: 0.06026

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.84997

Collected Steps per Second: 22,233.05519
Overall Steps per Second: 10,493.86058

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.51830
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.76946

Cumulative Model Updates: 81,740
Cumulative Timesteps: 681,670,154

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.58781
Policy Entropy: 3.70412
Value Function Loss: 0.06496

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.85349

Collected Steps per Second: 22,655.40934
Overall Steps per Second: 10,766.39768

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.64445

Cumulative Model Updates: 81,746
Cumulative Timesteps: 681,720,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 681720158...
Checkpoint 681720158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.20216
Policy Entropy: 3.70022
Value Function Loss: 0.06611

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.78767

Collected Steps per Second: 22,336.74712
Overall Steps per Second: 10,675.67388

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.68448

Cumulative Model Updates: 81,752
Cumulative Timesteps: 681,770,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.86253
Policy Entropy: 3.69984
Value Function Loss: 0.06607

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.53294
Value Function Update Magnitude: 0.71960

Collected Steps per Second: 22,361.65731
Overall Steps per Second: 10,472.46711

Timestep Collection Time: 2.23660
Timestep Consumption Time: 2.53916
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.77576

Cumulative Model Updates: 81,758
Cumulative Timesteps: 681,820,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 681820182...
Checkpoint 681820182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,896.31194
Policy Entropy: 3.69720
Value Function Loss: 0.06444

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.76096

Collected Steps per Second: 22,292.29887
Overall Steps per Second: 10,640.99431

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.70163

Cumulative Model Updates: 81,764
Cumulative Timesteps: 681,870,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,310.37537
Policy Entropy: 3.70508
Value Function Loss: 0.06364

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.77351

Collected Steps per Second: 22,513.00027
Overall Steps per Second: 10,519.81364

Timestep Collection Time: 2.22192
Timestep Consumption Time: 2.53311
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.75503

Cumulative Model Updates: 81,770
Cumulative Timesteps: 681,920,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 681920234...
Checkpoint 681920234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.88898
Policy Entropy: 3.69747
Value Function Loss: 0.06638

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.57561
Value Function Update Magnitude: 0.83918

Collected Steps per Second: 21,891.74349
Overall Steps per Second: 10,573.45157

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.72882

Cumulative Model Updates: 81,776
Cumulative Timesteps: 681,970,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.10557
Policy Entropy: 3.70910
Value Function Loss: 0.06639

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.61341
Value Function Update Magnitude: 0.84363

Collected Steps per Second: 22,748.58443
Overall Steps per Second: 10,595.47767

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.72050

Cumulative Model Updates: 81,782
Cumulative Timesteps: 682,020,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 682020250...
Checkpoint 682020250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.74631
Policy Entropy: 3.70147
Value Function Loss: 0.06727

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.67000
Value Function Update Magnitude: 0.75023

Collected Steps per Second: 22,450.97854
Overall Steps per Second: 10,570.09890

Timestep Collection Time: 2.22770
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.73165

Cumulative Model Updates: 81,788
Cumulative Timesteps: 682,070,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,621.27713
Policy Entropy: 3.70749
Value Function Loss: 0.06855

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.79870

Collected Steps per Second: 22,619.55878
Overall Steps per Second: 10,590.19093

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.51107
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.72173

Cumulative Model Updates: 81,794
Cumulative Timesteps: 682,120,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 682120268...
Checkpoint 682120268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.92055
Policy Entropy: 3.70257
Value Function Loss: 0.06807

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.61491
Value Function Update Magnitude: 0.82870

Collected Steps per Second: 22,289.42364
Overall Steps per Second: 10,372.44085

Timestep Collection Time: 2.24393
Timestep Consumption Time: 2.57807
PPO Batch Consumption Time: 0.30301
Total Iteration Time: 4.82201

Cumulative Model Updates: 81,800
Cumulative Timesteps: 682,170,284

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,895.10795
Policy Entropy: 3.70893
Value Function Loss: 0.07103

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.57528
Value Function Update Magnitude: 0.85932

Collected Steps per Second: 22,759.30852
Overall Steps per Second: 10,472.48545

Timestep Collection Time: 2.19690
Timestep Consumption Time: 2.57751
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 4.77442

Cumulative Model Updates: 81,806
Cumulative Timesteps: 682,220,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 682220284...
Checkpoint 682220284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.30902
Policy Entropy: 3.70282
Value Function Loss: 0.07055

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.64879
Value Function Update Magnitude: 0.81359

Collected Steps per Second: 22,270.62604
Overall Steps per Second: 10,656.30716

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.69356

Cumulative Model Updates: 81,812
Cumulative Timesteps: 682,270,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,279.00722
Policy Entropy: 3.70726
Value Function Loss: 0.07460

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.63175
Value Function Update Magnitude: 0.72379

Collected Steps per Second: 22,677.23348
Overall Steps per Second: 10,663.10693

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.69188

Cumulative Model Updates: 81,818
Cumulative Timesteps: 682,320,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 682320330...
Checkpoint 682320330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,971.60910
Policy Entropy: 3.70947
Value Function Loss: 0.07559

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.62330
Value Function Update Magnitude: 0.73161

Collected Steps per Second: 22,358.50939
Overall Steps per Second: 10,545.20733

Timestep Collection Time: 2.23709
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.74320

Cumulative Model Updates: 81,824
Cumulative Timesteps: 682,370,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,895.44850
Policy Entropy: 3.71543
Value Function Loss: 0.07257

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.61474
Value Function Update Magnitude: 0.86696

Collected Steps per Second: 22,812.40437
Overall Steps per Second: 10,649.72742

Timestep Collection Time: 2.19398
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.69965

Cumulative Model Updates: 81,830
Cumulative Timesteps: 682,420,398

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 682420398...
Checkpoint 682420398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.33660
Policy Entropy: 3.70274
Value Function Loss: 0.07270

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.53513
Value Function Update Magnitude: 0.91027

Collected Steps per Second: 22,293.84170
Overall Steps per Second: 10,475.63299

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.53092
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.77432

Cumulative Model Updates: 81,836
Cumulative Timesteps: 682,470,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,575.36196
Policy Entropy: 3.69356
Value Function Loss: 0.07172

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.90905

Collected Steps per Second: 22,680.77693
Overall Steps per Second: 10,617.40569

Timestep Collection Time: 2.20460
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.70944

Cumulative Model Updates: 81,842
Cumulative Timesteps: 682,520,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 682520414...
Checkpoint 682520414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,463.15366
Policy Entropy: 3.69847
Value Function Loss: 0.07141

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.93141

Collected Steps per Second: 22,298.18418
Overall Steps per Second: 10,634.08224

Timestep Collection Time: 2.24305
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.70337

Cumulative Model Updates: 81,848
Cumulative Timesteps: 682,570,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.44929
Policy Entropy: 3.68532
Value Function Loss: 0.07139

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.91072

Collected Steps per Second: 22,644.55577
Overall Steps per Second: 10,746.67311

Timestep Collection Time: 2.20865
Timestep Consumption Time: 2.44525
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.65391

Cumulative Model Updates: 81,854
Cumulative Timesteps: 682,620,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 682620444...
Checkpoint 682620444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,990.56651
Policy Entropy: 3.69655
Value Function Loss: 0.07299

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.52716
Value Function Update Magnitude: 0.85514

Collected Steps per Second: 22,298.32911
Overall Steps per Second: 10,606.20273

Timestep Collection Time: 2.24331
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.71630

Cumulative Model Updates: 81,860
Cumulative Timesteps: 682,670,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.67092
Policy Entropy: 3.68947
Value Function Loss: 0.07187

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.52298
Value Function Update Magnitude: 0.91251

Collected Steps per Second: 22,963.16991
Overall Steps per Second: 10,812.82872

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.62562

Cumulative Model Updates: 81,866
Cumulative Timesteps: 682,720,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 682720482...
Checkpoint 682720482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,898.70331
Policy Entropy: 3.70878
Value Function Loss: 0.06949

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.50295
Value Function Update Magnitude: 0.91014

Collected Steps per Second: 21,738.28386
Overall Steps per Second: 10,363.80121

Timestep Collection Time: 2.30083
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.82603

Cumulative Model Updates: 81,872
Cumulative Timesteps: 682,770,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.44639
Policy Entropy: 3.69949
Value Function Loss: 0.06522

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.50013
Value Function Update Magnitude: 0.86891

Collected Steps per Second: 22,751.45799
Overall Steps per Second: 10,806.34139

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.62821

Cumulative Model Updates: 81,878
Cumulative Timesteps: 682,820,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 682820512...
Checkpoint 682820512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,995.41306
Policy Entropy: 3.71710
Value Function Loss: 0.06301

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.60135
Value Function Update Magnitude: 0.75125

Collected Steps per Second: 21,264.18596
Overall Steps per Second: 10,150.59579

Timestep Collection Time: 2.35212
Timestep Consumption Time: 2.57527
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.92740

Cumulative Model Updates: 81,884
Cumulative Timesteps: 682,870,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.30601
Policy Entropy: 3.71342
Value Function Loss: 0.06004

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.75129
Value Function Update Magnitude: 0.73726

Collected Steps per Second: 22,453.55242
Overall Steps per Second: 10,568.21366

Timestep Collection Time: 2.22789
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.73344

Cumulative Model Updates: 81,890
Cumulative Timesteps: 682,920,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 682920552...
Checkpoint 682920552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.84878
Policy Entropy: 3.71224
Value Function Loss: 0.05827

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.70425
Value Function Update Magnitude: 0.71391

Collected Steps per Second: 22,334.91627
Overall Steps per Second: 10,602.74192

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.71576

Cumulative Model Updates: 81,896
Cumulative Timesteps: 682,970,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.04456
Policy Entropy: 3.70313
Value Function Loss: 0.05841

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.59846
Value Function Update Magnitude: 0.74070

Collected Steps per Second: 22,581.63530
Overall Steps per Second: 10,693.61040

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.67756

Cumulative Model Updates: 81,902
Cumulative Timesteps: 683,020,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 683020572...
Checkpoint 683020572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.02097
Policy Entropy: 3.69963
Value Function Loss: 0.05786

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.61399
Value Function Update Magnitude: 0.69272

Collected Steps per Second: 22,439.12499
Overall Steps per Second: 10,554.93196

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.73788

Cumulative Model Updates: 81,908
Cumulative Timesteps: 683,070,580

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.48225
Policy Entropy: 3.70514
Value Function Loss: 0.06059

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.59737
Value Function Update Magnitude: 0.67492

Collected Steps per Second: 22,787.94700
Overall Steps per Second: 10,806.17936

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62735

Cumulative Model Updates: 81,914
Cumulative Timesteps: 683,120,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 683120584...
Checkpoint 683120584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,837.36387
Policy Entropy: 3.70776
Value Function Loss: 0.05937

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.73442

Collected Steps per Second: 22,461.46763
Overall Steps per Second: 10,598.13932

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.71819

Cumulative Model Updates: 81,920
Cumulative Timesteps: 683,170,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.96577
Policy Entropy: 3.72559
Value Function Loss: 0.05765

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.55318
Value Function Update Magnitude: 0.79281

Collected Steps per Second: 22,555.36305
Overall Steps per Second: 10,565.01000

Timestep Collection Time: 2.21703
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73317

Cumulative Model Updates: 81,926
Cumulative Timesteps: 683,220,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 683220594...
Checkpoint 683220594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.80443
Policy Entropy: 3.72750
Value Function Loss: 0.05684

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.51516
Value Function Update Magnitude: 0.80453

Collected Steps per Second: 22,348.03044
Overall Steps per Second: 10,509.24885

Timestep Collection Time: 2.23769
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75848

Cumulative Model Updates: 81,932
Cumulative Timesteps: 683,270,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.05210
Policy Entropy: 3.73152
Value Function Loss: 0.05540

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.81140

Collected Steps per Second: 22,796.84541
Overall Steps per Second: 10,628.88543

Timestep Collection Time: 2.19408
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.70586

Cumulative Model Updates: 81,938
Cumulative Timesteps: 683,320,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 683320620...
Checkpoint 683320620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,152.58680
Policy Entropy: 3.72891
Value Function Loss: 0.05638

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.61848
Value Function Update Magnitude: 0.80611

Collected Steps per Second: 22,168.47492
Overall Steps per Second: 10,481.81026

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.77322

Cumulative Model Updates: 81,944
Cumulative Timesteps: 683,370,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.98065
Policy Entropy: 3.73155
Value Function Loss: 0.05797

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.70738
Value Function Update Magnitude: 0.78719

Collected Steps per Second: 22,633.76124
Overall Steps per Second: 10,589.36209

Timestep Collection Time: 2.21033
Timestep Consumption Time: 2.51404
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.72436

Cumulative Model Updates: 81,950
Cumulative Timesteps: 683,420,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 683420680...
Checkpoint 683420680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.14031
Policy Entropy: 3.73718
Value Function Loss: 0.06430

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.65140
Value Function Update Magnitude: 0.79842

Collected Steps per Second: 22,073.63703
Overall Steps per Second: 10,506.06458

Timestep Collection Time: 2.26641
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.76182

Cumulative Model Updates: 81,956
Cumulative Timesteps: 683,470,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.29145
Policy Entropy: 3.74430
Value Function Loss: 0.06586

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.78146

Collected Steps per Second: 22,672.43326
Overall Steps per Second: 10,623.03551

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70675

Cumulative Model Updates: 81,962
Cumulative Timesteps: 683,520,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 683520708...
Checkpoint 683520708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.79354
Policy Entropy: 3.74485
Value Function Loss: 0.06727

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.76376

Collected Steps per Second: 22,454.94670
Overall Steps per Second: 10,586.13563

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.72580

Cumulative Model Updates: 81,968
Cumulative Timesteps: 683,570,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.84599
Policy Entropy: 3.75426
Value Function Loss: 0.06600

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.56016
Value Function Update Magnitude: 0.79030

Collected Steps per Second: 22,924.04908
Overall Steps per Second: 10,839.59442

Timestep Collection Time: 2.18199
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61456

Cumulative Model Updates: 81,974
Cumulative Timesteps: 683,620,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 683620756...
Checkpoint 683620756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.80117
Policy Entropy: 3.74754
Value Function Loss: 0.06906

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.57124
Value Function Update Magnitude: 0.80396

Collected Steps per Second: 22,365.73772
Overall Steps per Second: 10,616.32682

Timestep Collection Time: 2.23637
Timestep Consumption Time: 2.47506
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71142

Cumulative Model Updates: 81,980
Cumulative Timesteps: 683,670,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,462.31367
Policy Entropy: 3.74595
Value Function Loss: 0.06996

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.62942
Value Function Update Magnitude: 0.84588

Collected Steps per Second: 22,773.90889
Overall Steps per Second: 10,423.86879

Timestep Collection Time: 2.19699
Timestep Consumption Time: 2.60296
PPO Batch Consumption Time: 0.30843
Total Iteration Time: 4.79995

Cumulative Model Updates: 81,986
Cumulative Timesteps: 683,720,808

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 683720808...
Checkpoint 683720808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,866.60430
Policy Entropy: 3.74092
Value Function Loss: 0.07008

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.68211
Value Function Update Magnitude: 0.89086

Collected Steps per Second: 19,871.91947
Overall Steps per Second: 9,973.51141

Timestep Collection Time: 2.51621
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 5.01348

Cumulative Model Updates: 81,992
Cumulative Timesteps: 683,770,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.34868
Policy Entropy: 3.72396
Value Function Loss: 0.06595

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.64443
Value Function Update Magnitude: 0.90459

Collected Steps per Second: 23,293.52435
Overall Steps per Second: 10,823.52675

Timestep Collection Time: 2.14678
Timestep Consumption Time: 2.47334
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.62012

Cumulative Model Updates: 81,998
Cumulative Timesteps: 683,820,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 683820816...
Checkpoint 683820816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,798.73703
Policy Entropy: 3.72019
Value Function Loss: 0.06621

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.61891
Value Function Update Magnitude: 0.82793

Collected Steps per Second: 20,965.85020
Overall Steps per Second: 10,422.20604

Timestep Collection Time: 2.38550
Timestep Consumption Time: 2.41329
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.79879

Cumulative Model Updates: 82,004
Cumulative Timesteps: 683,870,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,038.20080
Policy Entropy: 3.71381
Value Function Loss: 0.06929

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12234
Policy Update Magnitude: 0.65302
Value Function Update Magnitude: 0.71503

Collected Steps per Second: 20,104.37148
Overall Steps per Second: 9,798.07636

Timestep Collection Time: 2.48752
Timestep Consumption Time: 2.61654
PPO Batch Consumption Time: 0.31465
Total Iteration Time: 5.10406

Cumulative Model Updates: 82,010
Cumulative Timesteps: 683,920,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 683920840...
Checkpoint 683920840 saved!
