Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.01904
Policy Entropy: 3.17366
Value Function Loss: 0.00712

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00707
Policy Update Magnitude: 0.20948
Value Function Update Magnitude: 0.22790

Collected Steps per Second: 19,604.04176
Overall Steps per Second: 12,672.81698

Timestep Collection Time: 2.55274
Timestep Consumption Time: 1.39619
PPO Batch Consumption Time: 0.34925
Total Iteration Time: 3.94892

Cumulative Model Updates: 120,216
Cumulative Timesteps: 1,002,563,644

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.15978
Policy Entropy: 3.13736
Value Function Loss: 0.00666

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.05787
Policy Update Magnitude: 0.45376
Value Function Update Magnitude: 0.45858

Collected Steps per Second: 22,566.81604
Overall Steps per Second: 12,034.68874

Timestep Collection Time: 2.21617
Timestep Consumption Time: 1.93948
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.15565

Cumulative Model Updates: 120,220
Cumulative Timesteps: 1,002,613,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1002613656...
Checkpoint 1002613656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.02046
Policy Entropy: 3.13442
Value Function Loss: 0.00576

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.65380
Value Function Update Magnitude: 0.60990

Collected Steps per Second: 20,612.37157
Overall Steps per Second: 10,136.08447

Timestep Collection Time: 2.42650
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.93445

Cumulative Model Updates: 120,226
Cumulative Timesteps: 1,002,663,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.78078
Policy Entropy: 3.12135
Value Function Loss: 0.00493

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.59071
Value Function Update Magnitude: 0.53647

Collected Steps per Second: 21,123.23541
Overall Steps per Second: 10,236.25563

Timestep Collection Time: 2.36829
Timestep Consumption Time: 2.51885
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.88714

Cumulative Model Updates: 120,232
Cumulative Timesteps: 1,002,713,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1002713698...
Checkpoint 1002713698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.62693
Policy Entropy: 3.13358
Value Function Loss: 0.00460

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.51541

Collected Steps per Second: 21,282.86148
Overall Steps per Second: 10,224.96810

Timestep Collection Time: 2.35119
Timestep Consumption Time: 2.54272
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.89390

Cumulative Model Updates: 120,238
Cumulative Timesteps: 1,002,763,738

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.63563
Policy Entropy: 3.12637
Value Function Loss: 0.00459

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.52444

Collected Steps per Second: 20,411.13294
Overall Steps per Second: 10,085.63980

Timestep Collection Time: 2.44994
Timestep Consumption Time: 2.50820
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.95814

Cumulative Model Updates: 120,244
Cumulative Timesteps: 1,002,813,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1002813744...
Checkpoint 1002813744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.80137
Policy Entropy: 3.11091
Value Function Loss: 0.00476

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.53426

Collected Steps per Second: 21,484.75810
Overall Steps per Second: 10,233.45342

Timestep Collection Time: 2.32835
Timestep Consumption Time: 2.55993
PPO Batch Consumption Time: 0.30223
Total Iteration Time: 4.88828

Cumulative Model Updates: 120,250
Cumulative Timesteps: 1,002,863,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.31377
Policy Entropy: 3.11124
Value Function Loss: 0.00478

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.54764
Value Function Update Magnitude: 0.53255

Collected Steps per Second: 21,724.23824
Overall Steps per Second: 10,486.09259

Timestep Collection Time: 2.30176
Timestep Consumption Time: 2.46684
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.76860

Cumulative Model Updates: 120,256
Cumulative Timesteps: 1,002,913,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1002913772...
Checkpoint 1002913772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.91184
Policy Entropy: 3.08152
Value Function Loss: 0.00469

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.53784
Value Function Update Magnitude: 0.52822

Collected Steps per Second: 21,803.12925
Overall Steps per Second: 10,509.31835

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.75768

Cumulative Model Updates: 120,262
Cumulative Timesteps: 1,002,963,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.12063
Policy Entropy: 3.09756
Value Function Loss: 0.00425

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.53288
Value Function Update Magnitude: 0.50386

Collected Steps per Second: 20,977.91121
Overall Steps per Second: 10,135.41334

Timestep Collection Time: 2.38441
Timestep Consumption Time: 2.55076
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.93517

Cumulative Model Updates: 120,268
Cumulative Timesteps: 1,003,013,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1003013792...
Checkpoint 1003013792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.07083
Policy Entropy: 3.08646
Value Function Loss: 0.00425

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.52384
Value Function Update Magnitude: 0.51679

Collected Steps per Second: 21,900.19945
Overall Steps per Second: 10,589.85151

Timestep Collection Time: 2.28336
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.72207

Cumulative Model Updates: 120,274
Cumulative Timesteps: 1,003,063,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.93959
Policy Entropy: 3.10359
Value Function Loss: 0.00410

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.51796
Value Function Update Magnitude: 0.51782

Collected Steps per Second: 21,331.76992
Overall Steps per Second: 10,400.00928

Timestep Collection Time: 2.34495
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.80980

Cumulative Model Updates: 120,280
Cumulative Timesteps: 1,003,113,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003113820...
Checkpoint 1003113820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.46881
Policy Entropy: 3.08663
Value Function Loss: 0.00425

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.51805
Value Function Update Magnitude: 0.53621

Collected Steps per Second: 21,901.56336
Overall Steps per Second: 10,325.67571

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.56079
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.84501

Cumulative Model Updates: 120,286
Cumulative Timesteps: 1,003,163,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.33195
Policy Entropy: 3.07261
Value Function Loss: 0.00414

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.51765
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 21,564.20485
Overall Steps per Second: 10,369.28460

Timestep Collection Time: 2.31875
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.82213

Cumulative Model Updates: 120,292
Cumulative Timesteps: 1,003,213,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1003213850...
Checkpoint 1003213850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.86146
Policy Entropy: 3.07280
Value Function Loss: 0.00428

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.53980

Collected Steps per Second: 20,581.52837
Overall Steps per Second: 10,224.67799

Timestep Collection Time: 2.43024
Timestep Consumption Time: 2.46165
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.89189

Cumulative Model Updates: 120,298
Cumulative Timesteps: 1,003,263,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.37451
Policy Entropy: 3.06836
Value Function Loss: 0.00417

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.52790

Collected Steps per Second: 21,381.02991
Overall Steps per Second: 9,978.18879

Timestep Collection Time: 2.33992
Timestep Consumption Time: 2.67401
PPO Batch Consumption Time: 0.31193
Total Iteration Time: 5.01394

Cumulative Model Updates: 120,304
Cumulative Timesteps: 1,003,313,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1003313898...
Checkpoint 1003313898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.45889
Policy Entropy: 3.07706
Value Function Loss: 0.00428

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.51784
Value Function Update Magnitude: 0.53142

Collected Steps per Second: 21,556.91275
Overall Steps per Second: 10,314.33442

Timestep Collection Time: 2.32065
Timestep Consumption Time: 2.52950
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.85014

Cumulative Model Updates: 120,310
Cumulative Timesteps: 1,003,363,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.74701
Policy Entropy: 3.08074
Value Function Loss: 0.00421

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.51412
Value Function Update Magnitude: 0.52342

Collected Steps per Second: 21,194.10788
Overall Steps per Second: 10,365.24701

Timestep Collection Time: 2.36037
Timestep Consumption Time: 2.46595
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.82632

Cumulative Model Updates: 120,316
Cumulative Timesteps: 1,003,413,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1003413950...
Checkpoint 1003413950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.39596
Policy Entropy: 3.10434
Value Function Loss: 0.00401

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.51345

Collected Steps per Second: 20,784.69605
Overall Steps per Second: 10,263.17388

Timestep Collection Time: 2.40590
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.87237

Cumulative Model Updates: 120,322
Cumulative Timesteps: 1,003,463,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.35725
Policy Entropy: 3.11731
Value Function Loss: 0.00389

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.49318
Value Function Update Magnitude: 0.49894

Collected Steps per Second: 21,609.55723
Overall Steps per Second: 10,443.34905

Timestep Collection Time: 2.31407
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.78831

Cumulative Model Updates: 120,328
Cumulative Timesteps: 1,003,513,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1003513962...
Checkpoint 1003513962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.19522
Policy Entropy: 3.12429
Value Function Loss: 0.00428

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.49461
Value Function Update Magnitude: 0.48766

Collected Steps per Second: 21,306.07328
Overall Steps per Second: 10,353.73787

Timestep Collection Time: 2.34741
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.83053

Cumulative Model Updates: 120,334
Cumulative Timesteps: 1,003,563,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.15584
Policy Entropy: 3.10374
Value Function Loss: 0.00434

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.49942
Value Function Update Magnitude: 0.50586

Collected Steps per Second: 20,237.54906
Overall Steps per Second: 10,024.83924

Timestep Collection Time: 2.47174
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.98981

Cumulative Model Updates: 120,340
Cumulative Timesteps: 1,003,613,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003613998...
Checkpoint 1003613998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.66935
Policy Entropy: 3.09727
Value Function Loss: 0.00421

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.49723
Value Function Update Magnitude: 0.50338

Collected Steps per Second: 20,503.70383
Overall Steps per Second: 10,016.55255

Timestep Collection Time: 2.43858
Timestep Consumption Time: 2.55315
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.99174

Cumulative Model Updates: 120,346
Cumulative Timesteps: 1,003,663,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.40016
Policy Entropy: 3.08248
Value Function Loss: 0.00399

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.49240
Value Function Update Magnitude: 0.48757

Collected Steps per Second: 19,705.36741
Overall Steps per Second: 9,923.42617

Timestep Collection Time: 2.53819
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 5.04019

Cumulative Model Updates: 120,352
Cumulative Timesteps: 1,003,714,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1003714014...
Checkpoint 1003714014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.55840
Policy Entropy: 3.07601
Value Function Loss: 0.00404

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.49277
Value Function Update Magnitude: 0.48693

Collected Steps per Second: 20,473.97737
Overall Steps per Second: 9,831.86396

Timestep Collection Time: 2.44222
Timestep Consumption Time: 2.64349
PPO Batch Consumption Time: 0.31330
Total Iteration Time: 5.08571

Cumulative Model Updates: 120,358
Cumulative Timesteps: 1,003,764,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.22454
Policy Entropy: 3.07571
Value Function Loss: 0.00405

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.49562
Value Function Update Magnitude: 0.49934

Collected Steps per Second: 21,662.66030
Overall Steps per Second: 10,528.64118

Timestep Collection Time: 2.30812
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.74895

Cumulative Model Updates: 120,364
Cumulative Timesteps: 1,003,814,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1003814016...
Checkpoint 1003814016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.76564
Policy Entropy: 3.07665
Value Function Loss: 0.00385

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.49393
Value Function Update Magnitude: 0.52041

Collected Steps per Second: 21,467.04551
Overall Steps per Second: 10,317.42041

Timestep Collection Time: 2.33036
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.84869

Cumulative Model Updates: 120,370
Cumulative Timesteps: 1,003,864,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.87553
Policy Entropy: 3.08160
Value Function Loss: 0.00388

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.48687
Value Function Update Magnitude: 0.52249

Collected Steps per Second: 22,265.27693
Overall Steps per Second: 10,545.22903

Timestep Collection Time: 2.24655
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.74338

Cumulative Model Updates: 120,376
Cumulative Timesteps: 1,003,914,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1003914062...
Checkpoint 1003914062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.36058
Policy Entropy: 3.08023
Value Function Loss: 0.00375

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.48986
Value Function Update Magnitude: 0.50910

Collected Steps per Second: 21,889.35277
Overall Steps per Second: 10,568.79208

Timestep Collection Time: 2.28495
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.73242

Cumulative Model Updates: 120,382
Cumulative Timesteps: 1,003,964,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.11254
Policy Entropy: 3.08498
Value Function Loss: 0.00381

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.49665
Value Function Update Magnitude: 0.48737

Collected Steps per Second: 20,933.78892
Overall Steps per Second: 10,288.57321

Timestep Collection Time: 2.38982
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.86248

Cumulative Model Updates: 120,388
Cumulative Timesteps: 1,004,014,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1004014106...
Checkpoint 1004014106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.94764
Policy Entropy: 3.07054
Value Function Loss: 0.00380

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.49209
Value Function Update Magnitude: 0.49506

Collected Steps per Second: 21,442.93199
Overall Steps per Second: 10,414.32899

Timestep Collection Time: 2.33233
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80223

Cumulative Model Updates: 120,394
Cumulative Timesteps: 1,004,064,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.21137
Policy Entropy: 3.06793
Value Function Loss: 0.00392

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.49207
Value Function Update Magnitude: 0.51117

Collected Steps per Second: 20,751.30169
Overall Steps per Second: 10,344.67373

Timestep Collection Time: 2.40997
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.83437

Cumulative Model Updates: 120,400
Cumulative Timesteps: 1,004,114,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1004114128...
Checkpoint 1004114128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.37657
Policy Entropy: 3.05199
Value Function Loss: 0.00382

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.49339
Value Function Update Magnitude: 0.50547

Collected Steps per Second: 21,105.04482
Overall Steps per Second: 10,284.74484

Timestep Collection Time: 2.36967
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.86274

Cumulative Model Updates: 120,406
Cumulative Timesteps: 1,004,164,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.28153
Policy Entropy: 3.05396
Value Function Loss: 0.00402

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.48879

Collected Steps per Second: 21,918.20788
Overall Steps per Second: 10,151.67233

Timestep Collection Time: 2.28139
Timestep Consumption Time: 2.64430
PPO Batch Consumption Time: 0.30930
Total Iteration Time: 4.92569

Cumulative Model Updates: 120,412
Cumulative Timesteps: 1,004,214,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1004214144...
Checkpoint 1004214144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.22363
Policy Entropy: 3.06565
Value Function Loss: 0.00386

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.47767

Collected Steps per Second: 21,982.59224
Overall Steps per Second: 10,505.30536

Timestep Collection Time: 2.27462
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.75969

Cumulative Model Updates: 120,418
Cumulative Timesteps: 1,004,264,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.34452
Policy Entropy: 3.08160
Value Function Loss: 0.00385

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.49615
Value Function Update Magnitude: 0.47866

Collected Steps per Second: 21,962.06545
Overall Steps per Second: 10,519.11828

Timestep Collection Time: 2.27665
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.75325

Cumulative Model Updates: 120,424
Cumulative Timesteps: 1,004,314,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1004314146...
Checkpoint 1004314146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.53858
Policy Entropy: 3.08542
Value Function Loss: 0.00398

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.49376
Value Function Update Magnitude: 0.49393

Collected Steps per Second: 20,866.33954
Overall Steps per Second: 10,119.03015

Timestep Collection Time: 2.39620
Timestep Consumption Time: 2.54498
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.94118

Cumulative Model Updates: 120,430
Cumulative Timesteps: 1,004,364,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.50967
Policy Entropy: 3.06631
Value Function Loss: 0.00421

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.49281
Value Function Update Magnitude: 0.50282

Collected Steps per Second: 21,947.65471
Overall Steps per Second: 10,488.57049

Timestep Collection Time: 2.27906
Timestep Consumption Time: 2.48994
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76900

Cumulative Model Updates: 120,436
Cumulative Timesteps: 1,004,414,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1004414166...
Checkpoint 1004414166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.23813
Policy Entropy: 3.05887
Value Function Loss: 0.00469

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.50822
Value Function Update Magnitude: 0.51433

Collected Steps per Second: 21,826.36472
Overall Steps per Second: 10,510.59018

Timestep Collection Time: 2.29081
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.75711

Cumulative Model Updates: 120,442
Cumulative Timesteps: 1,004,464,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.88275
Policy Entropy: 3.06689
Value Function Loss: 0.00452

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.51152
Value Function Update Magnitude: 0.53083

Collected Steps per Second: 22,426.96587
Overall Steps per Second: 10,705.65605

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.67267

Cumulative Model Updates: 120,448
Cumulative Timesteps: 1,004,514,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1004514190...
Checkpoint 1004514190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.43118
Policy Entropy: 3.08650
Value Function Loss: 0.00438

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.50761
Value Function Update Magnitude: 0.53880

Collected Steps per Second: 21,725.68021
Overall Steps per Second: 10,441.37951

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.78960

Cumulative Model Updates: 120,454
Cumulative Timesteps: 1,004,564,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.18873
Policy Entropy: 3.10278
Value Function Loss: 0.00394

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.51015
Value Function Update Magnitude: 0.51799

Collected Steps per Second: 21,711.71135
Overall Steps per Second: 10,303.56517

Timestep Collection Time: 2.30346
Timestep Consumption Time: 2.55040
PPO Batch Consumption Time: 0.30740
Total Iteration Time: 4.85385

Cumulative Model Updates: 120,460
Cumulative Timesteps: 1,004,614,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004614212...
Checkpoint 1004614212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.69284
Policy Entropy: 3.09617
Value Function Loss: 0.00436

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.50755
Value Function Update Magnitude: 0.51052

Collected Steps per Second: 21,747.09649
Overall Steps per Second: 10,444.35509

Timestep Collection Time: 2.29916
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.78727

Cumulative Model Updates: 120,466
Cumulative Timesteps: 1,004,664,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.78704
Policy Entropy: 3.08326
Value Function Loss: 0.00423

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.51754
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 21,461.87376
Overall Steps per Second: 10,404.83708

Timestep Collection Time: 2.33139
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.80892

Cumulative Model Updates: 120,472
Cumulative Timesteps: 1,004,714,248

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1004714248...
Checkpoint 1004714248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.75900
Policy Entropy: 3.07206
Value Function Loss: 0.00450

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.54634

Collected Steps per Second: 20,667.74586
Overall Steps per Second: 9,999.77869

Timestep Collection Time: 2.42020
Timestep Consumption Time: 2.58191
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 5.00211

Cumulative Model Updates: 120,478
Cumulative Timesteps: 1,004,764,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.73862
Policy Entropy: 3.07160
Value Function Loss: 0.00413

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.52333

Collected Steps per Second: 20,289.92622
Overall Steps per Second: 9,820.12570

Timestep Collection Time: 2.46487
Timestep Consumption Time: 2.62794
PPO Batch Consumption Time: 0.30675
Total Iteration Time: 5.09281

Cumulative Model Updates: 120,484
Cumulative Timesteps: 1,004,814,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1004814280...
Checkpoint 1004814280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.46733
Policy Entropy: 3.07436
Value Function Loss: 0.00407

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.50836
Value Function Update Magnitude: 0.51728

Collected Steps per Second: 20,048.20886
Overall Steps per Second: 9,774.86099

Timestep Collection Time: 2.49469
Timestep Consumption Time: 2.62191
PPO Batch Consumption Time: 0.31176
Total Iteration Time: 5.11659

Cumulative Model Updates: 120,490
Cumulative Timesteps: 1,004,864,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.63942
Policy Entropy: 3.06952
Value Function Loss: 0.00402

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.50232
Value Function Update Magnitude: 0.51766

Collected Steps per Second: 20,744.72192
Overall Steps per Second: 10,013.07411

Timestep Collection Time: 2.41179
Timestep Consumption Time: 2.58487
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.99667

Cumulative Model Updates: 120,496
Cumulative Timesteps: 1,004,914,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1004914326...
Checkpoint 1004914326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.77980
Policy Entropy: 3.07298
Value Function Loss: 0.00414

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.51161
Value Function Update Magnitude: 0.51912

Collected Steps per Second: 17,561.46275
Overall Steps per Second: 9,347.20692

Timestep Collection Time: 2.84828
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 5.35133

Cumulative Model Updates: 120,502
Cumulative Timesteps: 1,004,964,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.33184
Policy Entropy: 3.08823
Value Function Loss: 0.00387

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.50116
Value Function Update Magnitude: 0.51285

Collected Steps per Second: 22,342.34692
Overall Steps per Second: 10,459.68128

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.54256
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.78064

Cumulative Model Updates: 120,508
Cumulative Timesteps: 1,005,014,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1005014350...
Checkpoint 1005014350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.81629
Policy Entropy: 3.10252
Value Function Loss: 0.00367

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.49006
Value Function Update Magnitude: 0.51358

Collected Steps per Second: 22,341.94110
Overall Steps per Second: 10,346.33911

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.59634
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 4.83572

Cumulative Model Updates: 120,514
Cumulative Timesteps: 1,005,064,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.92242
Policy Entropy: 3.11379
Value Function Loss: 0.00340

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.50024

Collected Steps per Second: 22,086.11652
Overall Steps per Second: 10,395.57325

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.54750
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.81282

Cumulative Model Updates: 120,520
Cumulative Timesteps: 1,005,114,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1005114414...
Checkpoint 1005114414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.53667
Policy Entropy: 3.11531
Value Function Loss: 0.00351

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.48864

Collected Steps per Second: 22,358.85720
Overall Steps per Second: 10,433.65991

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.55726
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.79467

Cumulative Model Updates: 120,526
Cumulative Timesteps: 1,005,164,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.43740
Policy Entropy: 3.12179
Value Function Loss: 0.00388

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.48715
Value Function Update Magnitude: 0.50783

Collected Steps per Second: 22,377.48604
Overall Steps per Second: 10,495.02426

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.53190
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.76816

Cumulative Model Updates: 120,532
Cumulative Timesteps: 1,005,214,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1005214482...
Checkpoint 1005214482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.74576
Policy Entropy: 3.11177
Value Function Loss: 0.00392

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.49053
Value Function Update Magnitude: 0.52812

Collected Steps per Second: 21,670.15346
Overall Steps per Second: 10,530.97271

Timestep Collection Time: 2.30852
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.75037

Cumulative Model Updates: 120,538
Cumulative Timesteps: 1,005,264,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.83222
Policy Entropy: 3.10652
Value Function Loss: 0.00424

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.51554

Collected Steps per Second: 22,354.79707
Overall Steps per Second: 10,494.86944

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.52818
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.76538

Cumulative Model Updates: 120,544
Cumulative Timesteps: 1,005,314,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1005314520...
Checkpoint 1005314520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.22811
Policy Entropy: 3.09763
Value Function Loss: 0.00428

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.51473
Value Function Update Magnitude: 0.50712

Collected Steps per Second: 22,538.62196
Overall Steps per Second: 10,622.89244

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.70813

Cumulative Model Updates: 120,550
Cumulative Timesteps: 1,005,364,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.63236
Policy Entropy: 3.09854
Value Function Loss: 0.00454

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.51522
Value Function Update Magnitude: 0.51941

Collected Steps per Second: 22,695.96387
Overall Steps per Second: 10,571.13606

Timestep Collection Time: 2.20312
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.73005

Cumulative Model Updates: 120,556
Cumulative Timesteps: 1,005,414,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1005414536...
Checkpoint 1005414536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.20393
Policy Entropy: 3.11039
Value Function Loss: 0.00415

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.50274
Value Function Update Magnitude: 0.54383

Collected Steps per Second: 22,595.29376
Overall Steps per Second: 10,489.45797

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.55394
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.76688

Cumulative Model Updates: 120,562
Cumulative Timesteps: 1,005,464,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.51266
Policy Entropy: 3.11517
Value Function Loss: 0.00412

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.49879
Value Function Update Magnitude: 0.52146

Collected Steps per Second: 22,607.18510
Overall Steps per Second: 10,501.98603

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.54973
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.76177

Cumulative Model Updates: 120,568
Cumulative Timesteps: 1,005,514,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1005514546...
Checkpoint 1005514546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.42229
Policy Entropy: 3.09805
Value Function Loss: 0.00413

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.50157
Value Function Update Magnitude: 0.52673

Collected Steps per Second: 22,140.37103
Overall Steps per Second: 10,653.39812

Timestep Collection Time: 2.25895
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.69465

Cumulative Model Updates: 120,574
Cumulative Timesteps: 1,005,564,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.90538
Policy Entropy: 3.08514
Value Function Loss: 0.00413

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.50568
Value Function Update Magnitude: 0.53448

Collected Steps per Second: 22,716.07150
Overall Steps per Second: 10,541.90969

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.54209
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.74335

Cumulative Model Updates: 120,580
Cumulative Timesteps: 1,005,614,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1005614564...
Checkpoint 1005614564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 794.21569
Policy Entropy: 3.08335
Value Function Loss: 0.00397

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.49738
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 22,783.89926
Overall Steps per Second: 10,552.73873

Timestep Collection Time: 2.19488
Timestep Consumption Time: 2.54398
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.73886

Cumulative Model Updates: 120,586
Cumulative Timesteps: 1,005,664,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.88784
Policy Entropy: 3.09065
Value Function Loss: 0.00438

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.50872
Value Function Update Magnitude: 0.50739

Collected Steps per Second: 22,178.79212
Overall Steps per Second: 10,371.40799

Timestep Collection Time: 2.25558
Timestep Consumption Time: 2.56787
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.82345

Cumulative Model Updates: 120,592
Cumulative Timesteps: 1,005,714,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1005714598...
Checkpoint 1005714598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.65622
Policy Entropy: 3.09011
Value Function Loss: 0.00456

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.52019
Value Function Update Magnitude: 0.52866

Collected Steps per Second: 22,287.07223
Overall Steps per Second: 10,429.08218

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.55206
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.79659

Cumulative Model Updates: 120,598
Cumulative Timesteps: 1,005,764,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.83406
Policy Entropy: 3.10627
Value Function Loss: 0.00477

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.51467
Value Function Update Magnitude: 0.53556

Collected Steps per Second: 22,729.16534
Overall Steps per Second: 10,728.37289

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.66334

Cumulative Model Updates: 120,604
Cumulative Timesteps: 1,005,814,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1005814652...
Checkpoint 1005814652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.43486
Policy Entropy: 3.11515
Value Function Loss: 0.00472

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.50320
Value Function Update Magnitude: 0.55462

Collected Steps per Second: 22,060.55418
Overall Steps per Second: 10,489.50155

Timestep Collection Time: 2.26794
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.76972

Cumulative Model Updates: 120,610
Cumulative Timesteps: 1,005,864,684

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.27900
Policy Entropy: 3.11588
Value Function Loss: 0.00462

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.56383

Collected Steps per Second: 22,474.67566
Overall Steps per Second: 10,592.49733

Timestep Collection Time: 2.22562
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72221

Cumulative Model Updates: 120,616
Cumulative Timesteps: 1,005,914,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1005914704...
Checkpoint 1005914704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.05028
Policy Entropy: 3.10397
Value Function Loss: 0.00445

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.54806

Collected Steps per Second: 22,227.85884
Overall Steps per Second: 10,634.69109

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.45275
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.70272

Cumulative Model Updates: 120,622
Cumulative Timesteps: 1,005,964,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.41676
Policy Entropy: 3.09999
Value Function Loss: 0.00447

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.51386
Value Function Update Magnitude: 0.55065

Collected Steps per Second: 22,822.10376
Overall Steps per Second: 10,641.92043

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.69840

Cumulative Model Updates: 120,628
Cumulative Timesteps: 1,006,014,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1006014716...
Checkpoint 1006014716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.64231
Policy Entropy: 3.10286
Value Function Loss: 0.00441

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.50989
Value Function Update Magnitude: 0.55272

Collected Steps per Second: 22,327.17161
Overall Steps per Second: 10,564.88917

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.49463
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.73531

Cumulative Model Updates: 120,634
Cumulative Timesteps: 1,006,064,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.62116
Policy Entropy: 3.09811
Value Function Loss: 0.00460

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.50867
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,663.31770
Overall Steps per Second: 10,725.06684

Timestep Collection Time: 2.20709
Timestep Consumption Time: 2.45675
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66384

Cumulative Model Updates: 120,640
Cumulative Timesteps: 1,006,114,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1006114764...
Checkpoint 1006114764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.97147
Policy Entropy: 3.11515
Value Function Loss: 0.00465

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.51388
Value Function Update Magnitude: 0.57190

Collected Steps per Second: 22,487.80681
Overall Steps per Second: 10,734.12403

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.43530
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.65935

Cumulative Model Updates: 120,646
Cumulative Timesteps: 1,006,164,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.17262
Policy Entropy: 3.11817
Value Function Loss: 0.00459

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.50884
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,461.54442
Overall Steps per Second: 10,522.29820

Timestep Collection Time: 2.22710
Timestep Consumption Time: 2.52700
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.75409

Cumulative Model Updates: 120,652
Cumulative Timesteps: 1,006,214,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006214802...
Checkpoint 1006214802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.77010
Policy Entropy: 3.11975
Value Function Loss: 0.00439

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.50176
Value Function Update Magnitude: 0.55519

Collected Steps per Second: 22,253.06424
Overall Steps per Second: 10,607.76359

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.46694
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.71409

Cumulative Model Updates: 120,658
Cumulative Timesteps: 1,006,264,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.78310
Policy Entropy: 3.10158
Value Function Loss: 0.00477

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.50590
Value Function Update Magnitude: 0.54434

Collected Steps per Second: 22,091.39075
Overall Steps per Second: 10,664.15251

Timestep Collection Time: 2.26432
Timestep Consumption Time: 2.42635
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69067

Cumulative Model Updates: 120,664
Cumulative Timesteps: 1,006,314,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1006314830...
Checkpoint 1006314830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.43765
Policy Entropy: 3.10196
Value Function Loss: 0.00511

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.50871
Value Function Update Magnitude: 0.55856

Collected Steps per Second: 22,972.89757
Overall Steps per Second: 10,737.65127

Timestep Collection Time: 2.17761
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.65893

Cumulative Model Updates: 120,670
Cumulative Timesteps: 1,006,364,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.18664
Policy Entropy: 3.10742
Value Function Loss: 0.00481

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.50503
Value Function Update Magnitude: 0.55959

Collected Steps per Second: 21,625.47104
Overall Steps per Second: 10,421.97820

Timestep Collection Time: 2.31246
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.79832

Cumulative Model Updates: 120,676
Cumulative Timesteps: 1,006,414,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1006414864...
Checkpoint 1006414864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.66476
Policy Entropy: 3.11709
Value Function Loss: 0.00439

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.49870
Value Function Update Magnitude: 0.53786

Collected Steps per Second: 22,069.13717
Overall Steps per Second: 10,439.28364

Timestep Collection Time: 2.26606
Timestep Consumption Time: 2.52450
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.79056

Cumulative Model Updates: 120,682
Cumulative Timesteps: 1,006,464,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.95883
Policy Entropy: 3.11896
Value Function Loss: 0.00427

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.49654
Value Function Update Magnitude: 0.52620

Collected Steps per Second: 22,922.67550
Overall Steps per Second: 10,719.88537

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.66591

Cumulative Model Updates: 120,688
Cumulative Timesteps: 1,006,514,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1006514892...
Checkpoint 1006514892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.54764
Policy Entropy: 3.11526
Value Function Loss: 0.00450

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 22,242.14564
Overall Steps per Second: 10,585.09693

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.72400

Cumulative Model Updates: 120,694
Cumulative Timesteps: 1,006,564,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.19610
Policy Entropy: 3.12055
Value Function Loss: 0.00431

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.50546
Value Function Update Magnitude: 0.55870

Collected Steps per Second: 23,019.88883
Overall Steps per Second: 10,599.01891

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.54711
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.72063

Cumulative Model Updates: 120,700
Cumulative Timesteps: 1,006,614,930

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1006614930...
Checkpoint 1006614930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.46553
Policy Entropy: 3.13246
Value Function Loss: 0.00448

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.50551
Value Function Update Magnitude: 0.54657

Collected Steps per Second: 22,118.59870
Overall Steps per Second: 10,581.24838

Timestep Collection Time: 2.26081
Timestep Consumption Time: 2.46510
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.72591

Cumulative Model Updates: 120,706
Cumulative Timesteps: 1,006,664,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.46808
Policy Entropy: 3.13749
Value Function Loss: 0.00447

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.51571
Value Function Update Magnitude: 0.56713

Collected Steps per Second: 22,474.14238
Overall Steps per Second: 10,456.96629

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.55672
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.78150

Cumulative Model Updates: 120,712
Cumulative Timesteps: 1,006,714,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1006714936...
Checkpoint 1006714936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.29139
Policy Entropy: 3.12565
Value Function Loss: 0.00465

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.57673

Collected Steps per Second: 22,565.24462
Overall Steps per Second: 10,677.10138

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.68386

Cumulative Model Updates: 120,718
Cumulative Timesteps: 1,006,764,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.06430
Policy Entropy: 3.11883
Value Function Loss: 0.00435

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.52195
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 22,418.06322
Overall Steps per Second: 10,468.81525

Timestep Collection Time: 2.23150
Timestep Consumption Time: 2.54707
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.77857

Cumulative Model Updates: 120,724
Cumulative Timesteps: 1,006,814,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1006814972...
Checkpoint 1006814972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.96808
Policy Entropy: 3.11744
Value Function Loss: 0.00410

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.50899
Value Function Update Magnitude: 0.55124

Collected Steps per Second: 22,268.51951
Overall Steps per Second: 10,550.39556

Timestep Collection Time: 2.24640
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.74143

Cumulative Model Updates: 120,730
Cumulative Timesteps: 1,006,864,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.99653
Policy Entropy: 3.10776
Value Function Loss: 0.00432

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.50690
Value Function Update Magnitude: 0.53888

Collected Steps per Second: 22,820.41187
Overall Steps per Second: 10,566.10593

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.54251
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.73476

Cumulative Model Updates: 120,736
Cumulative Timesteps: 1,006,915,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1006915024...
Checkpoint 1006915024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.84119
Policy Entropy: 3.11888
Value Function Loss: 0.00450

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,151.87911
Overall Steps per Second: 10,517.23611

Timestep Collection Time: 2.25751
Timestep Consumption Time: 2.49736
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.75486

Cumulative Model Updates: 120,742
Cumulative Timesteps: 1,006,965,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.46610
Policy Entropy: 3.10529
Value Function Loss: 0.00467

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.55042

Collected Steps per Second: 22,768.94358
Overall Steps per Second: 10,549.38327

Timestep Collection Time: 2.19633
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.74037

Cumulative Model Updates: 120,748
Cumulative Timesteps: 1,007,015,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1007015040...
Checkpoint 1007015040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.24156
Policy Entropy: 3.11745
Value Function Loss: 0.00484

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.51881
Value Function Update Magnitude: 0.55497

Collected Steps per Second: 21,703.71988
Overall Steps per Second: 10,383.02394

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.81729

Cumulative Model Updates: 120,754
Cumulative Timesteps: 1,007,065,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.71366
Policy Entropy: 3.13887
Value Function Loss: 0.00440

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.52049
Value Function Update Magnitude: 0.54664

Collected Steps per Second: 22,724.02462
Overall Steps per Second: 10,712.39894

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.46826
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.66954

Cumulative Model Updates: 120,760
Cumulative Timesteps: 1,007,115,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1007115080...
Checkpoint 1007115080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.25924
Policy Entropy: 3.14245
Value Function Loss: 0.00412

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.51370
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 22,220.05441
Overall Steps per Second: 10,705.05637

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67256

Cumulative Model Updates: 120,766
Cumulative Timesteps: 1,007,165,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.22458
Policy Entropy: 3.14716
Value Function Loss: 0.00390

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.56860

Collected Steps per Second: 22,944.09846
Overall Steps per Second: 10,766.61321

Timestep Collection Time: 2.18008
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.64584

Cumulative Model Updates: 120,772
Cumulative Timesteps: 1,007,215,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1007215120...
Checkpoint 1007215120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.56479
Policy Entropy: 3.13569
Value Function Loss: 0.00381

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.50449
Value Function Update Magnitude: 0.54092

Collected Steps per Second: 22,291.67812
Overall Steps per Second: 10,658.93579

Timestep Collection Time: 2.24344
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.69184

Cumulative Model Updates: 120,778
Cumulative Timesteps: 1,007,265,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.19591
Policy Entropy: 3.14662
Value Function Loss: 0.00423

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.50664
Value Function Update Magnitude: 0.52000

Collected Steps per Second: 22,845.68256
Overall Steps per Second: 10,636.96902

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.70172

Cumulative Model Updates: 120,784
Cumulative Timesteps: 1,007,315,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1007315142...
Checkpoint 1007315142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.62536
Policy Entropy: 3.13410
Value Function Loss: 0.00416

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.51253
Value Function Update Magnitude: 0.52614

Collected Steps per Second: 22,620.54219
Overall Steps per Second: 10,573.57088

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.73047

Cumulative Model Updates: 120,790
Cumulative Timesteps: 1,007,365,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.61684
Policy Entropy: 3.13478
Value Function Loss: 0.00431

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.51165
Value Function Update Magnitude: 0.52494

Collected Steps per Second: 22,647.32816
Overall Steps per Second: 10,737.34513

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.45025
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.65925

Cumulative Model Updates: 120,796
Cumulative Timesteps: 1,007,415,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1007415188...
Checkpoint 1007415188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.81988
Policy Entropy: 3.13381
Value Function Loss: 0.00407

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.50455
Value Function Update Magnitude: 0.53230

Collected Steps per Second: 21,977.89739
Overall Steps per Second: 10,456.81679

Timestep Collection Time: 2.27565
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.78291

Cumulative Model Updates: 120,802
Cumulative Timesteps: 1,007,465,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.75777
Policy Entropy: 3.13203
Value Function Loss: 0.00404

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.53501

Collected Steps per Second: 22,293.64623
Overall Steps per Second: 10,664.57274

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.68861

Cumulative Model Updates: 120,808
Cumulative Timesteps: 1,007,515,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1007515204...
Checkpoint 1007515204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.28574
Policy Entropy: 3.11848
Value Function Loss: 0.00402

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.50011
Value Function Update Magnitude: 0.53926

Collected Steps per Second: 22,157.77718
Overall Steps per Second: 10,613.82856

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.45439
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.71102

Cumulative Model Updates: 120,814
Cumulative Timesteps: 1,007,565,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.68035
Policy Entropy: 3.08995
Value Function Loss: 0.00390

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.50373
Value Function Update Magnitude: 0.52887

Collected Steps per Second: 22,801.29224
Overall Steps per Second: 10,620.25919

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.70968

Cumulative Model Updates: 120,820
Cumulative Timesteps: 1,007,615,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007615224...
Checkpoint 1007615224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.77241
Policy Entropy: 3.09279
Value Function Loss: 0.00393

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.50199
Value Function Update Magnitude: 0.52091

Collected Steps per Second: 22,242.43570
Overall Steps per Second: 10,590.63940

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.72172

Cumulative Model Updates: 120,826
Cumulative Timesteps: 1,007,665,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.39729
Policy Entropy: 3.11804
Value Function Loss: 0.00418

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.50794
Value Function Update Magnitude: 0.53581

Collected Steps per Second: 22,741.63097
Overall Steps per Second: 10,509.19970

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.56005
PPO Batch Consumption Time: 0.30256
Total Iteration Time: 4.75945

Cumulative Model Updates: 120,832
Cumulative Timesteps: 1,007,715,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007715248...
Checkpoint 1007715248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.93320
Policy Entropy: 3.13630
Value Function Loss: 0.00420

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.50397
Value Function Update Magnitude: 0.54144

Collected Steps per Second: 22,099.12146
Overall Steps per Second: 10,662.31547

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.42824
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.69204

Cumulative Model Updates: 120,838
Cumulative Timesteps: 1,007,765,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.01983
Policy Entropy: 3.14020
Value Function Loss: 0.00429

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.49382
Value Function Update Magnitude: 0.52717

Collected Steps per Second: 22,543.62266
Overall Steps per Second: 10,821.13151

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.40353
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.62225

Cumulative Model Updates: 120,844
Cumulative Timesteps: 1,007,815,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007815294...
Checkpoint 1007815294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.62150
Policy Entropy: 3.13792
Value Function Loss: 0.00419

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.49026
Value Function Update Magnitude: 0.53232

Collected Steps per Second: 21,665.46529
Overall Steps per Second: 10,624.30516

Timestep Collection Time: 2.30874
Timestep Consumption Time: 2.39933
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.70807

Cumulative Model Updates: 120,850
Cumulative Timesteps: 1,007,865,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.65866
Policy Entropy: 3.13759
Value Function Loss: 0.00398

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.54835

Collected Steps per Second: 21,770.10842
Overall Steps per Second: 10,461.38525

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.48305
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.78006

Cumulative Model Updates: 120,856
Cumulative Timesteps: 1,007,915,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1007915320...
Checkpoint 1007915320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.23075
Policy Entropy: 3.12914
Value Function Loss: 0.00385

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.52278

Collected Steps per Second: 21,908.43267
Overall Steps per Second: 10,689.43911

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.39567
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.67826

Cumulative Model Updates: 120,862
Cumulative Timesteps: 1,007,965,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.15066
Policy Entropy: 3.13113
Value Function Loss: 0.00357

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.50013

Collected Steps per Second: 21,807.55119
Overall Steps per Second: 10,544.47806

Timestep Collection Time: 2.29443
Timestep Consumption Time: 2.45080
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.74523

Cumulative Model Updates: 120,868
Cumulative Timesteps: 1,008,015,364

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1008015364...
Checkpoint 1008015364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.96513
Policy Entropy: 3.13184
Value Function Loss: 0.00360

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.48716
Value Function Update Magnitude: 0.47743

Collected Steps per Second: 21,886.41746
Overall Steps per Second: 10,509.50015

Timestep Collection Time: 2.28452
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.75760

Cumulative Model Updates: 120,874
Cumulative Timesteps: 1,008,065,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.39817
Policy Entropy: 3.13986
Value Function Loss: 0.00365

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.48452
Value Function Update Magnitude: 0.46794

Collected Steps per Second: 21,822.33564
Overall Steps per Second: 10,506.52854

Timestep Collection Time: 2.29169
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.75990

Cumulative Model Updates: 120,880
Cumulative Timesteps: 1,008,115,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1008115374...
Checkpoint 1008115374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.91953
Policy Entropy: 3.13539
Value Function Loss: 0.00397

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.49955
Value Function Update Magnitude: 0.49355

Collected Steps per Second: 21,912.82021
Overall Steps per Second: 10,582.56037

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.72721

Cumulative Model Updates: 120,886
Cumulative Timesteps: 1,008,165,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.72883
Policy Entropy: 3.12665
Value Function Loss: 0.00426

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.51586
Value Function Update Magnitude: 0.52412

Collected Steps per Second: 22,164.10274
Overall Steps per Second: 10,604.17501

Timestep Collection Time: 2.25608
Timestep Consumption Time: 2.45942
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.71550

Cumulative Model Updates: 120,892
Cumulative Timesteps: 1,008,215,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1008215404...
Checkpoint 1008215404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.65452
Policy Entropy: 3.12172
Value Function Loss: 0.00439

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.52295
Value Function Update Magnitude: 0.53194

Collected Steps per Second: 21,798.48721
Overall Steps per Second: 10,517.52737

Timestep Collection Time: 2.29438
Timestep Consumption Time: 2.46092
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.75530

Cumulative Model Updates: 120,898
Cumulative Timesteps: 1,008,265,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.66779
Policy Entropy: 3.11946
Value Function Loss: 0.00453

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.51938
Value Function Update Magnitude: 0.52905

Collected Steps per Second: 22,614.92983
Overall Steps per Second: 10,476.37881

Timestep Collection Time: 2.21137
Timestep Consumption Time: 2.56223
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.77360

Cumulative Model Updates: 120,904
Cumulative Timesteps: 1,008,315,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1008315428...
Checkpoint 1008315428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.82436
Policy Entropy: 3.12093
Value Function Loss: 0.00453

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.51323
Value Function Update Magnitude: 0.53290

Collected Steps per Second: 22,644.59318
Overall Steps per Second: 10,463.39246

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.57197
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 4.78124

Cumulative Model Updates: 120,910
Cumulative Timesteps: 1,008,365,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.37653
Policy Entropy: 3.12903
Value Function Loss: 0.00431

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.52110

Collected Steps per Second: 22,266.26279
Overall Steps per Second: 10,541.70244

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.74383

Cumulative Model Updates: 120,916
Cumulative Timesteps: 1,008,415,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1008415464...
Checkpoint 1008415464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.22721
Policy Entropy: 3.13295
Value Function Loss: 0.00410

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.50896
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 22,643.11731
Overall Steps per Second: 10,697.68205

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.67653

Cumulative Model Updates: 120,922
Cumulative Timesteps: 1,008,465,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.98752
Policy Entropy: 3.14728
Value Function Loss: 0.00403

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.50281
Value Function Update Magnitude: 0.51267

Collected Steps per Second: 22,622.66164
Overall Steps per Second: 10,536.20954

Timestep Collection Time: 2.21044
Timestep Consumption Time: 2.53567
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.74611

Cumulative Model Updates: 120,928
Cumulative Timesteps: 1,008,515,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1008515498...
Checkpoint 1008515498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.52761
Policy Entropy: 3.13565
Value Function Loss: 0.00377

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.50082
Value Function Update Magnitude: 0.48882

Collected Steps per Second: 22,733.05277
Overall Steps per Second: 10,540.22733

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.54490
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.74487

Cumulative Model Updates: 120,934
Cumulative Timesteps: 1,008,565,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.98819
Policy Entropy: 3.12779
Value Function Loss: 0.00369

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.50128
Value Function Update Magnitude: 0.48085

Collected Steps per Second: 22,450.88247
Overall Steps per Second: 10,457.74772

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.78401

Cumulative Model Updates: 120,940
Cumulative Timesteps: 1,008,615,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1008615540...
Checkpoint 1008615540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.83069
Policy Entropy: 3.12645
Value Function Loss: 0.00366

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.50493
Value Function Update Magnitude: 0.47954

Collected Steps per Second: 22,429.75531
Overall Steps per Second: 10,617.78291

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.71021

Cumulative Model Updates: 120,946
Cumulative Timesteps: 1,008,665,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.92621
Policy Entropy: 3.13111
Value Function Loss: 0.00385

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.50305
Value Function Update Magnitude: 0.48690

Collected Steps per Second: 22,703.63334
Overall Steps per Second: 10,514.21309

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.55410
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 4.75718

Cumulative Model Updates: 120,952
Cumulative Timesteps: 1,008,715,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1008715570...
Checkpoint 1008715570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,079.27149
Policy Entropy: 3.14728
Value Function Loss: 0.00392

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.50472
Value Function Update Magnitude: 0.50075

Collected Steps per Second: 22,405.18240
Overall Steps per Second: 10,666.95961

Timestep Collection Time: 2.23279
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.68981

Cumulative Model Updates: 120,958
Cumulative Timesteps: 1,008,765,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.63745
Policy Entropy: 3.14718
Value Function Loss: 0.00385

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.50436
Value Function Update Magnitude: 0.49562

Collected Steps per Second: 22,427.16284
Overall Steps per Second: 10,464.33214

Timestep Collection Time: 2.23015
Timestep Consumption Time: 2.54951
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.77966

Cumulative Model Updates: 120,964
Cumulative Timesteps: 1,008,815,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1008815612...
Checkpoint 1008815612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.22110
Policy Entropy: 3.14834
Value Function Loss: 0.00372

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.48081

Collected Steps per Second: 22,465.31389
Overall Steps per Second: 10,622.99669

Timestep Collection Time: 2.22565
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.70677

Cumulative Model Updates: 120,970
Cumulative Timesteps: 1,008,865,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.57261
Policy Entropy: 3.13912
Value Function Loss: 0.00379

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.50861
Value Function Update Magnitude: 0.48582

Collected Steps per Second: 22,599.01299
Overall Steps per Second: 10,526.57142

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.53852
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.75197

Cumulative Model Updates: 120,976
Cumulative Timesteps: 1,008,915,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1008915634...
Checkpoint 1008915634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.27829
Policy Entropy: 3.12818
Value Function Loss: 0.00381

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.48453

Collected Steps per Second: 22,586.20748
Overall Steps per Second: 10,536.74944

Timestep Collection Time: 2.21392
Timestep Consumption Time: 2.53176
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.74568

Cumulative Model Updates: 120,982
Cumulative Timesteps: 1,008,965,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.08883
Policy Entropy: 3.12047
Value Function Loss: 0.00404

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.51401
Value Function Update Magnitude: 0.50065

Collected Steps per Second: 22,227.77302
Overall Steps per Second: 10,286.55361

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.61138
PPO Batch Consumption Time: 0.30642
Total Iteration Time: 4.86091

Cumulative Model Updates: 120,988
Cumulative Timesteps: 1,009,015,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1009015640...
Checkpoint 1009015640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.70337
Policy Entropy: 3.11780
Value Function Loss: 0.00414

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.51033

Collected Steps per Second: 22,985.40391
Overall Steps per Second: 10,626.93749

Timestep Collection Time: 2.17669
Timestep Consumption Time: 2.53135
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70804

Cumulative Model Updates: 120,994
Cumulative Timesteps: 1,009,065,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.58889
Policy Entropy: 3.13418
Value Function Loss: 0.00405

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.51991
Value Function Update Magnitude: 0.51219

Collected Steps per Second: 22,864.12922
Overall Steps per Second: 10,662.97507

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69044

Cumulative Model Updates: 121,000
Cumulative Timesteps: 1,009,115,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1009115686...
Checkpoint 1009115686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.02858
Policy Entropy: 3.13308
Value Function Loss: 0.00392

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.51141
Value Function Update Magnitude: 0.49033

Collected Steps per Second: 22,547.36428
Overall Steps per Second: 10,585.53119

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.72381

Cumulative Model Updates: 121,006
Cumulative Timesteps: 1,009,165,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.49447
Policy Entropy: 3.13617
Value Function Loss: 0.00378

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.50993
Value Function Update Magnitude: 0.45554

Collected Steps per Second: 22,562.19845
Overall Steps per Second: 10,481.67291

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.55413
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.77023

Cumulative Model Updates: 121,012
Cumulative Timesteps: 1,009,215,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1009215690...
Checkpoint 1009215690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.57130
Policy Entropy: 3.13584
Value Function Loss: 0.00382

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.50842
Value Function Update Magnitude: 0.45598

Collected Steps per Second: 22,420.12087
Overall Steps per Second: 10,632.16969

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.70515

Cumulative Model Updates: 121,018
Cumulative Timesteps: 1,009,265,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.61603
Policy Entropy: 3.15199
Value Function Loss: 0.00383

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.51015
Value Function Update Magnitude: 0.45735

Collected Steps per Second: 22,832.05493
Overall Steps per Second: 10,558.70799

Timestep Collection Time: 2.19060
Timestep Consumption Time: 2.54634
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.73694

Cumulative Model Updates: 121,024
Cumulative Timesteps: 1,009,315,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1009315732...
Checkpoint 1009315732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.89191
Policy Entropy: 3.15155
Value Function Loss: 0.00402

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.50905
Value Function Update Magnitude: 0.46616

Collected Steps per Second: 22,355.91874
Overall Steps per Second: 10,564.04369

Timestep Collection Time: 2.23744
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.73493

Cumulative Model Updates: 121,030
Cumulative Timesteps: 1,009,365,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.94004
Policy Entropy: 3.16683
Value Function Loss: 0.00416

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.51495
Value Function Update Magnitude: 0.51106

Collected Steps per Second: 22,228.10611
Overall Steps per Second: 10,399.71019

Timestep Collection Time: 2.25021
Timestep Consumption Time: 2.55934
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.80956

Cumulative Model Updates: 121,036
Cumulative Timesteps: 1,009,415,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1009415770...
Checkpoint 1009415770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.48610
Policy Entropy: 3.17520
Value Function Loss: 0.00417

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.51690
Value Function Update Magnitude: 0.52966

Collected Steps per Second: 22,253.17961
Overall Steps per Second: 10,597.43961

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.71831

Cumulative Model Updates: 121,042
Cumulative Timesteps: 1,009,465,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.23196
Policy Entropy: 3.17527
Value Function Loss: 0.00385

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.50984
Value Function Update Magnitude: 0.51039

Collected Steps per Second: 22,285.00343
Overall Steps per Second: 10,495.69977

Timestep Collection Time: 2.24519
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.76710

Cumulative Model Updates: 121,048
Cumulative Timesteps: 1,009,515,806

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1009515806...
Checkpoint 1009515806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.42344
Policy Entropy: 3.17400
Value Function Loss: 0.00387

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.50364
Value Function Update Magnitude: 0.50325

Collected Steps per Second: 22,540.24525
Overall Steps per Second: 10,660.02202

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.47256
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.69117

Cumulative Model Updates: 121,054
Cumulative Timesteps: 1,009,565,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.38647
Policy Entropy: 3.16616
Value Function Loss: 0.00372

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.50199
Value Function Update Magnitude: 0.50413

Collected Steps per Second: 22,353.47187
Overall Steps per Second: 10,429.34854

Timestep Collection Time: 2.23679
Timestep Consumption Time: 2.55737
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.79416

Cumulative Model Updates: 121,060
Cumulative Timesteps: 1,009,615,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1009615814...
Checkpoint 1009615814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.76085
Policy Entropy: 3.16266
Value Function Loss: 0.00406

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.50112
Value Function Update Magnitude: 0.49335

Collected Steps per Second: 22,625.79177
Overall Steps per Second: 10,636.41998

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.70139

Cumulative Model Updates: 121,066
Cumulative Timesteps: 1,009,665,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.39779
Policy Entropy: 3.16977
Value Function Loss: 0.00407

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.50796
Value Function Update Magnitude: 0.49191

Collected Steps per Second: 21,992.59683
Overall Steps per Second: 10,326.55169

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.56860
PPO Batch Consumption Time: 0.30707
Total Iteration Time: 4.84227

Cumulative Model Updates: 121,072
Cumulative Timesteps: 1,009,715,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1009715824...
Checkpoint 1009715824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.38457
Policy Entropy: 3.16003
Value Function Loss: 0.00440

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.51187
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 22,208.24554
Overall Steps per Second: 10,570.60867

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.73066

Cumulative Model Updates: 121,078
Cumulative Timesteps: 1,009,765,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.91514
Policy Entropy: 3.16782
Value Function Loss: 0.00416

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 0.51970

Collected Steps per Second: 22,821.91641
Overall Steps per Second: 10,670.98814

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.68729

Cumulative Model Updates: 121,084
Cumulative Timesteps: 1,009,815,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1009815848...
Checkpoint 1009815848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.17586
Policy Entropy: 3.17062
Value Function Loss: 0.00398

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.50871
Value Function Update Magnitude: 0.51467

Collected Steps per Second: 22,292.51332
Overall Steps per Second: 10,666.61138

Timestep Collection Time: 2.24308
Timestep Consumption Time: 2.44481
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.68790

Cumulative Model Updates: 121,090
Cumulative Timesteps: 1,009,865,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.30416
Policy Entropy: 3.17160
Value Function Loss: 0.00383

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.50005
Value Function Update Magnitude: 0.50702

Collected Steps per Second: 22,670.33807
Overall Steps per Second: 10,637.78146

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.70098

Cumulative Model Updates: 121,096
Cumulative Timesteps: 1,009,915,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1009915860...
Checkpoint 1009915860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.55490
Policy Entropy: 3.18795
Value Function Loss: 0.00383

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.49907
Value Function Update Magnitude: 0.52482

Collected Steps per Second: 22,422.38089
Overall Steps per Second: 10,624.22718

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.70867

Cumulative Model Updates: 121,102
Cumulative Timesteps: 1,009,965,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.19926
Policy Entropy: 3.18308
Value Function Loss: 0.00369

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.49029
Value Function Update Magnitude: 0.51216

Collected Steps per Second: 22,325.57924
Overall Steps per Second: 10,609.24715

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.71344

Cumulative Model Updates: 121,108
Cumulative Timesteps: 1,010,015,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010015892...
Checkpoint 1010015892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.09579
Policy Entropy: 3.17508
Value Function Loss: 0.00390

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.49585
Value Function Update Magnitude: 0.49469

Collected Steps per Second: 22,438.88584
Overall Steps per Second: 10,706.86017

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.67214

Cumulative Model Updates: 121,114
Cumulative Timesteps: 1,010,065,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.05759
Policy Entropy: 3.16341
Value Function Loss: 0.00411

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.50308
Value Function Update Magnitude: 0.50272

Collected Steps per Second: 22,392.68568
Overall Steps per Second: 10,476.34802

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.54141
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.77571

Cumulative Model Updates: 121,120
Cumulative Timesteps: 1,010,115,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1010115948...
Checkpoint 1010115948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.59577
Policy Entropy: 3.17221
Value Function Loss: 0.00407

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.51153
Value Function Update Magnitude: 0.52672

Collected Steps per Second: 22,406.73162
Overall Steps per Second: 10,639.79961

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70234

Cumulative Model Updates: 121,126
Cumulative Timesteps: 1,010,165,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.28136
Policy Entropy: 3.17858
Value Function Loss: 0.00426

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.51028
Value Function Update Magnitude: 0.54329

Collected Steps per Second: 22,470.20049
Overall Steps per Second: 10,552.60055

Timestep Collection Time: 2.22535
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.73855

Cumulative Model Updates: 121,132
Cumulative Timesteps: 1,010,215,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1010215984...
Checkpoint 1010215984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.96961
Policy Entropy: 3.18819
Value Function Loss: 0.00401

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.50248
Value Function Update Magnitude: 0.55995

Collected Steps per Second: 22,358.31832
Overall Steps per Second: 10,535.49239

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.74605

Cumulative Model Updates: 121,138
Cumulative Timesteps: 1,010,265,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.06210
Policy Entropy: 3.17270
Value Function Loss: 0.00449

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.51196
Value Function Update Magnitude: 0.54447

Collected Steps per Second: 22,233.20246
Overall Steps per Second: 10,460.77781

Timestep Collection Time: 2.24889
Timestep Consumption Time: 2.53087
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.77976

Cumulative Model Updates: 121,144
Cumulative Timesteps: 1,010,315,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1010315986...
Checkpoint 1010315986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.66332
Policy Entropy: 3.16237
Value Function Loss: 0.00440

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.52513
Value Function Update Magnitude: 0.55078

Collected Steps per Second: 21,750.41497
Overall Steps per Second: 10,410.05569

Timestep Collection Time: 2.30019
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.80593

Cumulative Model Updates: 121,150
Cumulative Timesteps: 1,010,366,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.21198
Policy Entropy: 3.16205
Value Function Loss: 0.00443

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.54912

Collected Steps per Second: 22,518.98077
Overall Steps per Second: 10,652.36252

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.69436

Cumulative Model Updates: 121,156
Cumulative Timesteps: 1,010,416,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010416022...
Checkpoint 1010416022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.77388
Policy Entropy: 3.16620
Value Function Loss: 0.00445

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.54403

Collected Steps per Second: 22,265.22108
Overall Steps per Second: 10,653.78082

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.69336

Cumulative Model Updates: 121,162
Cumulative Timesteps: 1,010,466,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.90944
Policy Entropy: 3.17045
Value Function Loss: 0.00415

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.52219
Value Function Update Magnitude: 0.54773

Collected Steps per Second: 22,521.14814
Overall Steps per Second: 10,519.83041

Timestep Collection Time: 2.22049
Timestep Consumption Time: 2.53320
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.75369

Cumulative Model Updates: 121,168
Cumulative Timesteps: 1,010,516,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1010516032...
Checkpoint 1010516032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.54464
Policy Entropy: 3.15312
Value Function Loss: 0.00453

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.52616
Value Function Update Magnitude: 0.55600

Collected Steps per Second: 20,143.06863
Overall Steps per Second: 9,883.40300

Timestep Collection Time: 2.48264
Timestep Consumption Time: 2.57716
PPO Batch Consumption Time: 0.30235
Total Iteration Time: 5.05980

Cumulative Model Updates: 121,174
Cumulative Timesteps: 1,010,566,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.90769
Policy Entropy: 3.16144
Value Function Loss: 0.00417

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.56435

Collected Steps per Second: 20,520.23053
Overall Steps per Second: 10,059.29775

Timestep Collection Time: 2.43662
Timestep Consumption Time: 2.53391
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.97053

Cumulative Model Updates: 121,180
Cumulative Timesteps: 1,010,616,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1010616040...
Checkpoint 1010616040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.30597
Policy Entropy: 3.17257
Value Function Loss: 0.00397

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.51588
Value Function Update Magnitude: 0.52945

Collected Steps per Second: 20,576.29257
Overall Steps per Second: 10,064.51478

Timestep Collection Time: 2.43008
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.96815

Cumulative Model Updates: 121,186
Cumulative Timesteps: 1,010,666,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.09584
Policy Entropy: 3.18537
Value Function Loss: 0.00400

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.51828
Value Function Update Magnitude: 0.52457

Collected Steps per Second: 21,422.63205
Overall Steps per Second: 10,443.55040

Timestep Collection Time: 2.33454
Timestep Consumption Time: 2.45425
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.78879

Cumulative Model Updates: 121,192
Cumulative Timesteps: 1,010,716,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010716054...
Checkpoint 1010716054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.95880
Policy Entropy: 3.17403
Value Function Loss: 0.00397

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.51255
Value Function Update Magnitude: 0.53342

Collected Steps per Second: 22,216.12388
Overall Steps per Second: 10,433.50576

Timestep Collection Time: 2.25125
Timestep Consumption Time: 2.54235
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.79359

Cumulative Model Updates: 121,198
Cumulative Timesteps: 1,010,766,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.91071
Policy Entropy: 3.18069
Value Function Loss: 0.00405

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 22,545.17433
Overall Steps per Second: 10,513.83863

Timestep Collection Time: 2.21777
Timestep Consumption Time: 2.53787
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.75564

Cumulative Model Updates: 121,204
Cumulative Timesteps: 1,010,816,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1010816068...
Checkpoint 1010816068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.82858
Policy Entropy: 3.18666
Value Function Loss: 0.00371

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.48936
Value Function Update Magnitude: 0.49821

Collected Steps per Second: 21,826.57096
Overall Steps per Second: 10,374.68237

Timestep Collection Time: 2.29179
Timestep Consumption Time: 2.52975
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.82155

Cumulative Model Updates: 121,210
Cumulative Timesteps: 1,010,866,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.15765
Policy Entropy: 3.19948
Value Function Loss: 0.00349

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.47937
Value Function Update Magnitude: 0.45785

Collected Steps per Second: 22,451.59775
Overall Steps per Second: 10,506.18046

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.53260
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 4.76006

Cumulative Model Updates: 121,216
Cumulative Timesteps: 1,010,916,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1010916100...
Checkpoint 1010916100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.29262
Policy Entropy: 3.19273
Value Function Loss: 0.00331

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.47759
Value Function Update Magnitude: 0.45273

Collected Steps per Second: 22,033.20048
Overall Steps per Second: 10,639.74232

Timestep Collection Time: 2.26976
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.70030

Cumulative Model Updates: 121,222
Cumulative Timesteps: 1,010,966,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.75749
Policy Entropy: 3.17088
Value Function Loss: 0.00368

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.48852
Value Function Update Magnitude: 0.49266

Collected Steps per Second: 22,694.58984
Overall Steps per Second: 10,809.55805

Timestep Collection Time: 2.20396
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.62720

Cumulative Model Updates: 121,228
Cumulative Timesteps: 1,011,016,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1011016128...
Checkpoint 1011016128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.53013
Policy Entropy: 3.16576
Value Function Loss: 0.00402

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.50248
Value Function Update Magnitude: 0.53102

Collected Steps per Second: 21,631.80104
Overall Steps per Second: 10,530.13940

Timestep Collection Time: 2.31224
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.74998

Cumulative Model Updates: 121,234
Cumulative Timesteps: 1,011,066,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.59926
Policy Entropy: 3.16145
Value Function Loss: 0.00407

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.51201
Value Function Update Magnitude: 0.53700

Collected Steps per Second: 21,587.33918
Overall Steps per Second: 10,466.28685

Timestep Collection Time: 2.31728
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.77954

Cumulative Model Updates: 121,240
Cumulative Timesteps: 1,011,116,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1011116170...
Checkpoint 1011116170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.95225
Policy Entropy: 3.17551
Value Function Loss: 0.00413

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.51052
Value Function Update Magnitude: 0.51864

Collected Steps per Second: 21,618.61843
Overall Steps per Second: 10,362.63978

Timestep Collection Time: 2.31393
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.82734

Cumulative Model Updates: 121,246
Cumulative Timesteps: 1,011,166,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.27847
Policy Entropy: 3.17107
Value Function Loss: 0.00408

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.51696
Value Function Update Magnitude: 0.53885

Collected Steps per Second: 21,213.25605
Overall Steps per Second: 10,278.28932

Timestep Collection Time: 2.35730
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 4.86521

Cumulative Model Updates: 121,252
Cumulative Timesteps: 1,011,216,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1011216200...
Checkpoint 1011216200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.27174
Policy Entropy: 3.16395
Value Function Loss: 0.00419

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.52330
Value Function Update Magnitude: 0.57691

Collected Steps per Second: 21,404.18747
Overall Steps per Second: 10,399.37554

Timestep Collection Time: 2.33599
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.80798

Cumulative Model Updates: 121,258
Cumulative Timesteps: 1,011,266,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.85380
Policy Entropy: 3.16705
Value Function Loss: 0.00391

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.52661
Value Function Update Magnitude: 0.58724

Collected Steps per Second: 21,863.94956
Overall Steps per Second: 10,563.30995

Timestep Collection Time: 2.28806
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.73583

Cumulative Model Updates: 121,264
Cumulative Timesteps: 1,011,316,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1011316226...
Checkpoint 1011316226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.08918
Policy Entropy: 3.17045
Value Function Loss: 0.00382

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.51958
Value Function Update Magnitude: 0.58585

Collected Steps per Second: 21,078.91861
Overall Steps per Second: 10,491.91273

Timestep Collection Time: 2.37251
Timestep Consumption Time: 2.39402
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.76653

Cumulative Model Updates: 121,270
Cumulative Timesteps: 1,011,366,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.86378
Policy Entropy: 3.17394
Value Function Loss: 0.00379

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.51755
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 21,400.14366
Overall Steps per Second: 10,275.29300

Timestep Collection Time: 2.33690
Timestep Consumption Time: 2.53011
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.86701

Cumulative Model Updates: 121,276
Cumulative Timesteps: 1,011,416,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1011416246...
Checkpoint 1011416246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.28575
Policy Entropy: 3.18206
Value Function Loss: 0.00363

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.51483
Value Function Update Magnitude: 0.58233

Collected Steps per Second: 21,269.33204
Overall Steps per Second: 10,351.00539

Timestep Collection Time: 2.35212
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.83315

Cumulative Model Updates: 121,282
Cumulative Timesteps: 1,011,466,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.55848
Policy Entropy: 3.16554
Value Function Loss: 0.00361

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.51213
Value Function Update Magnitude: 0.56017

Collected Steps per Second: 21,560.34579
Overall Steps per Second: 10,513.20210

Timestep Collection Time: 2.32074
Timestep Consumption Time: 2.43861
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.75935

Cumulative Model Updates: 121,288
Cumulative Timesteps: 1,011,516,310

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1011516310...
Checkpoint 1011516310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.13917
Policy Entropy: 3.16020
Value Function Loss: 0.00364

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.51417
Value Function Update Magnitude: 0.52326

Collected Steps per Second: 17,815.63751
Overall Steps per Second: 9,451.94897

Timestep Collection Time: 2.80652
Timestep Consumption Time: 2.48339
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 5.28991

Cumulative Model Updates: 121,294
Cumulative Timesteps: 1,011,566,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.97011
Policy Entropy: 3.15892
Value Function Loss: 0.00403

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.51967
Value Function Update Magnitude: 0.54495

Collected Steps per Second: 20,707.02502
Overall Steps per Second: 10,148.74797

Timestep Collection Time: 2.41647
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.93046

Cumulative Model Updates: 121,300
Cumulative Timesteps: 1,011,616,348

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1011616348...
Checkpoint 1011616348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.67334
Policy Entropy: 3.17669
Value Function Loss: 0.00398

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.54808

Collected Steps per Second: 22,377.65092
Overall Steps per Second: 10,521.05126

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.51821
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.75276

Cumulative Model Updates: 121,306
Cumulative Timesteps: 1,011,666,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.77769
Policy Entropy: 3.16987
Value Function Loss: 0.00397

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.51688
Value Function Update Magnitude: 0.52871

Collected Steps per Second: 21,082.44371
Overall Steps per Second: 10,414.15614

Timestep Collection Time: 2.37240
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.80269

Cumulative Model Updates: 121,312
Cumulative Timesteps: 1,011,716,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1011716368...
Checkpoint 1011716368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.24293
Policy Entropy: 3.16517
Value Function Loss: 0.00417

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.52210
Value Function Update Magnitude: 0.53992

Collected Steps per Second: 22,062.90792
Overall Steps per Second: 10,435.78206

Timestep Collection Time: 2.26688
Timestep Consumption Time: 2.52567
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.79255

Cumulative Model Updates: 121,318
Cumulative Timesteps: 1,011,766,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.80832
Policy Entropy: 3.18876
Value Function Loss: 0.00390

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.51837
Value Function Update Magnitude: 0.52987

Collected Steps per Second: 22,744.73434
Overall Steps per Second: 10,638.33090

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.70281

Cumulative Model Updates: 121,324
Cumulative Timesteps: 1,011,816,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1011816412...
Checkpoint 1011816412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.04629
Policy Entropy: 3.18816
Value Function Loss: 0.00389

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.50588
Value Function Update Magnitude: 0.50048

Collected Steps per Second: 21,987.60879
Overall Steps per Second: 10,239.74902

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.60965
PPO Batch Consumption Time: 0.30719
Total Iteration Time: 4.88430

Cumulative Model Updates: 121,330
Cumulative Timesteps: 1,011,866,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.80274
Policy Entropy: 3.20006
Value Function Loss: 0.00386

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.50059
Value Function Update Magnitude: 0.49936

Collected Steps per Second: 22,722.07951
Overall Steps per Second: 10,456.86868

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.58249
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.78422

Cumulative Model Updates: 121,336
Cumulative Timesteps: 1,011,916,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1011916454...
Checkpoint 1011916454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.74830
Policy Entropy: 3.18557
Value Function Loss: 0.00396

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.49954
Value Function Update Magnitude: 0.49495

Collected Steps per Second: 22,188.78350
Overall Steps per Second: 10,612.15867

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.71384

Cumulative Model Updates: 121,342
Cumulative Timesteps: 1,011,966,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.12269
Policy Entropy: 3.18403
Value Function Loss: 0.00415

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.50622
Value Function Update Magnitude: 0.48856

Collected Steps per Second: 22,577.11565
Overall Steps per Second: 10,503.69439

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.54682
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.76251

Cumulative Model Updates: 121,348
Cumulative Timesteps: 1,012,016,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012016502...
Checkpoint 1012016502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.84200
Policy Entropy: 3.17912
Value Function Loss: 0.00424

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.50709
Value Function Update Magnitude: 0.51248

Collected Steps per Second: 22,609.78845
Overall Steps per Second: 10,595.70522

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.71965

Cumulative Model Updates: 121,354
Cumulative Timesteps: 1,012,066,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.69312
Policy Entropy: 3.18114
Value Function Loss: 0.00425

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.51460
Value Function Update Magnitude: 0.51970

Collected Steps per Second: 22,293.69416
Overall Steps per Second: 10,516.94665

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.75480

Cumulative Model Updates: 121,360
Cumulative Timesteps: 1,012,116,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1012116516...
Checkpoint 1012116516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.76088
Policy Entropy: 3.17931
Value Function Loss: 0.00432

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.54768

Collected Steps per Second: 22,475.62164
Overall Steps per Second: 10,615.81063

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.71090

Cumulative Model Updates: 121,366
Cumulative Timesteps: 1,012,166,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.70246
Policy Entropy: 3.18796
Value Function Loss: 0.00421

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.52041
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 21,586.45331
Overall Steps per Second: 10,235.50855

Timestep Collection Time: 2.31775
Timestep Consumption Time: 2.57033
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.88808

Cumulative Model Updates: 121,372
Cumulative Timesteps: 1,012,216,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1012216558...
Checkpoint 1012216558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.74218
Policy Entropy: 3.17834
Value Function Loss: 0.00438

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.51086
Value Function Update Magnitude: 0.52376

Collected Steps per Second: 22,517.74891
Overall Steps per Second: 10,421.17050

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.57787
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.79869

Cumulative Model Updates: 121,378
Cumulative Timesteps: 1,012,266,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.83416
Policy Entropy: 3.18391
Value Function Loss: 0.00458

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.54080

Collected Steps per Second: 22,075.32802
Overall Steps per Second: 10,501.09049

Timestep Collection Time: 2.26552
Timestep Consumption Time: 2.49704
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.76255

Cumulative Model Updates: 121,384
Cumulative Timesteps: 1,012,316,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1012316578...
Checkpoint 1012316578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.73028
Policy Entropy: 3.18572
Value Function Loss: 0.00425

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.51962
Value Function Update Magnitude: 0.53421

Collected Steps per Second: 22,329.81218
Overall Steps per Second: 10,657.07910

Timestep Collection Time: 2.24023
Timestep Consumption Time: 2.45374
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.69397

Cumulative Model Updates: 121,390
Cumulative Timesteps: 1,012,366,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.40737
Policy Entropy: 3.19899
Value Function Loss: 0.00399

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.51130
Value Function Update Magnitude: 0.50803

Collected Steps per Second: 22,732.71232
Overall Steps per Second: 10,602.79831

Timestep Collection Time: 2.20062
Timestep Consumption Time: 2.51757
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.71819

Cumulative Model Updates: 121,396
Cumulative Timesteps: 1,012,416,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1012416628...
Checkpoint 1012416628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.45217
Policy Entropy: 3.19833
Value Function Loss: 0.00389

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.50694
Value Function Update Magnitude: 0.48747

Collected Steps per Second: 22,456.62755
Overall Steps per Second: 10,512.50037

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.53074
PPO Batch Consumption Time: 0.30144
Total Iteration Time: 4.75814

Cumulative Model Updates: 121,402
Cumulative Timesteps: 1,012,466,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.77911
Policy Entropy: 3.19102
Value Function Loss: 0.00406

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.51188
Value Function Update Magnitude: 0.49605

Collected Steps per Second: 22,036.75880
Overall Steps per Second: 10,263.85013

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.60378
PPO Batch Consumption Time: 0.30856
Total Iteration Time: 4.87380

Cumulative Model Updates: 121,408
Cumulative Timesteps: 1,012,516,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012516672...
Checkpoint 1012516672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.10236
Policy Entropy: 3.18648
Value Function Loss: 0.00413

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.51695
Value Function Update Magnitude: 0.52204

Collected Steps per Second: 22,310.09660
Overall Steps per Second: 10,615.00007

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.71088

Cumulative Model Updates: 121,414
Cumulative Timesteps: 1,012,566,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.18145
Policy Entropy: 3.18140
Value Function Loss: 0.00424

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.52681

Collected Steps per Second: 22,436.19572
Overall Steps per Second: 10,607.13463

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.71607

Cumulative Model Updates: 121,420
Cumulative Timesteps: 1,012,616,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012616702...
Checkpoint 1012616702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.18981
Policy Entropy: 3.17946
Value Function Loss: 0.00415

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.52612

Collected Steps per Second: 22,299.24349
Overall Steps per Second: 10,623.25511

Timestep Collection Time: 2.24250
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.70722

Cumulative Model Updates: 121,426
Cumulative Timesteps: 1,012,666,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.01206
Policy Entropy: 3.16886
Value Function Loss: 0.00407

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.51836
Value Function Update Magnitude: 0.52091

Collected Steps per Second: 22,053.50787
Overall Steps per Second: 10,439.73691

Timestep Collection Time: 2.26730
Timestep Consumption Time: 2.52228
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.78958

Cumulative Model Updates: 121,432
Cumulative Timesteps: 1,012,716,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1012716710...
Checkpoint 1012716710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.98825
Policy Entropy: 3.17388
Value Function Loss: 0.00381

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.50712
Value Function Update Magnitude: 0.52273

Collected Steps per Second: 22,205.65948
Overall Steps per Second: 10,625.89157

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.70737

Cumulative Model Updates: 121,438
Cumulative Timesteps: 1,012,766,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.65219
Policy Entropy: 3.16777
Value Function Loss: 0.00372

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.49999
Value Function Update Magnitude: 0.52624

Collected Steps per Second: 21,148.12719
Overall Steps per Second: 10,362.66103

Timestep Collection Time: 2.36541
Timestep Consumption Time: 2.46192
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.82733

Cumulative Model Updates: 121,444
Cumulative Timesteps: 1,012,816,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012816754...
Checkpoint 1012816754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.05211
Policy Entropy: 3.16926
Value Function Loss: 0.00380

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.50199
Value Function Update Magnitude: 0.52346

Collected Steps per Second: 22,426.17270
Overall Steps per Second: 10,523.36021

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.75247

Cumulative Model Updates: 121,450
Cumulative Timesteps: 1,012,866,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.29511
Policy Entropy: 3.16864
Value Function Loss: 0.00412

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.52773
Value Function Update Magnitude: 0.55236

Collected Steps per Second: 21,058.78843
Overall Steps per Second: 10,257.31142

Timestep Collection Time: 2.37545
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.87691

Cumulative Model Updates: 121,456
Cumulative Timesteps: 1,012,916,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012916790...
Checkpoint 1012916790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.09827
Policy Entropy: 3.17447
Value Function Loss: 0.00422

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.53208
Value Function Update Magnitude: 0.55338

Collected Steps per Second: 21,832.53842
Overall Steps per Second: 10,136.91029

Timestep Collection Time: 2.29135
Timestep Consumption Time: 2.64368
PPO Batch Consumption Time: 0.31792
Total Iteration Time: 4.93503

Cumulative Model Updates: 121,462
Cumulative Timesteps: 1,012,966,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.26841
Policy Entropy: 3.16846
Value Function Loss: 0.00439

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.52133
Value Function Update Magnitude: 0.53888

Collected Steps per Second: 22,226.32899
Overall Steps per Second: 10,472.07165

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.52603
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.77651

Cumulative Model Updates: 121,468
Cumulative Timesteps: 1,013,016,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013016836...
Checkpoint 1013016836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.31163
Policy Entropy: 3.16330
Value Function Loss: 0.00434

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.53684

Collected Steps per Second: 21,970.41394
Overall Steps per Second: 10,437.21472

Timestep Collection Time: 2.27579
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.79055

Cumulative Model Updates: 121,474
Cumulative Timesteps: 1,013,066,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.14350
Policy Entropy: 3.15557
Value Function Loss: 0.00440

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.56113

Collected Steps per Second: 22,214.85458
Overall Steps per Second: 10,418.15437

Timestep Collection Time: 2.25129
Timestep Consumption Time: 2.54918
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 4.80047

Cumulative Model Updates: 121,480
Cumulative Timesteps: 1,013,116,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1013116848...
Checkpoint 1013116848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.01400
Policy Entropy: 3.15194
Value Function Loss: 0.00425

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.56545

Collected Steps per Second: 21,992.57863
Overall Steps per Second: 10,421.86705

Timestep Collection Time: 2.27440
Timestep Consumption Time: 2.52512
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.79952

Cumulative Model Updates: 121,486
Cumulative Timesteps: 1,013,166,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.78177
Policy Entropy: 3.17205
Value Function Loss: 0.00421

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.51610
Value Function Update Magnitude: 0.57765

Collected Steps per Second: 21,943.81762
Overall Steps per Second: 10,570.77873

Timestep Collection Time: 2.27964
Timestep Consumption Time: 2.45265
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.73229

Cumulative Model Updates: 121,492
Cumulative Timesteps: 1,013,216,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1013216892...
Checkpoint 1013216892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.86086
Policy Entropy: 3.17210
Value Function Loss: 0.00421

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.51078
Value Function Update Magnitude: 0.57798

Collected Steps per Second: 22,326.62707
Overall Steps per Second: 10,620.77071

Timestep Collection Time: 2.23966
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.70813

Cumulative Model Updates: 121,498
Cumulative Timesteps: 1,013,266,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.91250
Policy Entropy: 3.16718
Value Function Loss: 0.00478

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.57515

Collected Steps per Second: 21,843.56967
Overall Steps per Second: 10,530.07431

Timestep Collection Time: 2.28937
Timestep Consumption Time: 2.45969
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.74906

Cumulative Model Updates: 121,504
Cumulative Timesteps: 1,013,316,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1013316904...
Checkpoint 1013316904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.79551
Policy Entropy: 3.15275
Value Function Loss: 0.00462

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.59077

Collected Steps per Second: 21,695.11783
Overall Steps per Second: 10,584.25637

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.72513

Cumulative Model Updates: 121,510
Cumulative Timesteps: 1,013,366,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.70888
Policy Entropy: 3.15941
Value Function Loss: 0.00433

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.54114
Value Function Update Magnitude: 0.56441

Collected Steps per Second: 22,008.61851
Overall Steps per Second: 10,558.49221

Timestep Collection Time: 2.27211
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.73609

Cumulative Model Updates: 121,516
Cumulative Timesteps: 1,013,416,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1013416922...
Checkpoint 1013416922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.61253
Policy Entropy: 3.16668
Value Function Loss: 0.00406

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.51841
Value Function Update Magnitude: 0.53354

Collected Steps per Second: 21,855.14210
Overall Steps per Second: 10,547.54639

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74177

Cumulative Model Updates: 121,522
Cumulative Timesteps: 1,013,466,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.18775
Policy Entropy: 3.17547
Value Function Loss: 0.00403

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.51493
Value Function Update Magnitude: 0.53603

Collected Steps per Second: 21,198.30915
Overall Steps per Second: 10,235.70459

Timestep Collection Time: 2.35991
Timestep Consumption Time: 2.52750
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.88740

Cumulative Model Updates: 121,528
Cumulative Timesteps: 1,013,516,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1013516962...
Checkpoint 1013516962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.06623
Policy Entropy: 3.17885
Value Function Loss: 0.00403

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.52046
Value Function Update Magnitude: 0.53616

Collected Steps per Second: 20,781.44812
Overall Steps per Second: 10,483.58602

Timestep Collection Time: 2.40599
Timestep Consumption Time: 2.36337
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.76936

Cumulative Model Updates: 121,534
Cumulative Timesteps: 1,013,566,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.12062
Policy Entropy: 3.18599
Value Function Loss: 0.00402

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.51644
Value Function Update Magnitude: 0.52364

Collected Steps per Second: 22,518.44835
Overall Steps per Second: 10,445.23542

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.56739
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 4.78859

Cumulative Model Updates: 121,540
Cumulative Timesteps: 1,013,616,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1013616980...
Checkpoint 1013616980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.87951
Policy Entropy: 3.17935
Value Function Loss: 0.00379

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.50982
Value Function Update Magnitude: 0.51209

Collected Steps per Second: 22,391.33574
Overall Steps per Second: 10,583.17904

Timestep Collection Time: 2.23354
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72561

Cumulative Model Updates: 121,546
Cumulative Timesteps: 1,013,666,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.18073
Policy Entropy: 3.17636
Value Function Loss: 0.00368

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.51285
Value Function Update Magnitude: 0.51095

Collected Steps per Second: 22,413.43860
Overall Steps per Second: 10,505.85732

Timestep Collection Time: 2.23188
Timestep Consumption Time: 2.52966
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.76153

Cumulative Model Updates: 121,552
Cumulative Timesteps: 1,013,717,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1013717016...
Checkpoint 1013717016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.42909
Policy Entropy: 3.17991
Value Function Loss: 0.00379

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.51516
Value Function Update Magnitude: 0.51343

Collected Steps per Second: 22,304.77403
Overall Steps per Second: 10,650.20432

Timestep Collection Time: 2.24266
Timestep Consumption Time: 2.45415
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.69681

Cumulative Model Updates: 121,558
Cumulative Timesteps: 1,013,767,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.79748
Policy Entropy: 3.17703
Value Function Loss: 0.00395

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.51473
Value Function Update Magnitude: 0.50871

Collected Steps per Second: 22,265.74620
Overall Steps per Second: 10,303.05999

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.60858
PPO Batch Consumption Time: 0.30813
Total Iteration Time: 4.85526

Cumulative Model Updates: 121,564
Cumulative Timesteps: 1,013,817,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1013817062...
Checkpoint 1013817062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.34539
Policy Entropy: 3.18969
Value Function Loss: 0.00386

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.52516

Collected Steps per Second: 22,338.96773
Overall Steps per Second: 10,521.03261

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.51485
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.75372

Cumulative Model Updates: 121,570
Cumulative Timesteps: 1,013,867,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.45823
Policy Entropy: 3.18849
Value Function Loss: 0.00378

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.50247
Value Function Update Magnitude: 0.52454

Collected Steps per Second: 21,810.83952
Overall Steps per Second: 10,652.64114

Timestep Collection Time: 2.29326
Timestep Consumption Time: 2.40210
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.69536

Cumulative Model Updates: 121,576
Cumulative Timesteps: 1,013,917,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1013917094...
Checkpoint 1013917094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.57928
Policy Entropy: 3.18893
Value Function Loss: 0.00387

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.50728
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 21,412.78113
Overall Steps per Second: 10,314.19011

Timestep Collection Time: 2.33552
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.84866

Cumulative Model Updates: 121,582
Cumulative Timesteps: 1,013,967,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.83334
Policy Entropy: 3.17551
Value Function Loss: 0.00399

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.51789
Value Function Update Magnitude: 0.53284

Collected Steps per Second: 23,256.37182
Overall Steps per Second: 10,785.82866

Timestep Collection Time: 2.15107
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.63812

Cumulative Model Updates: 121,588
Cumulative Timesteps: 1,014,017,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1014017130...
Checkpoint 1014017130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.64083
Policy Entropy: 3.17461
Value Function Loss: 0.00393

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.51799
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 22,128.29072
Overall Steps per Second: 10,445.47516

Timestep Collection Time: 2.25973
Timestep Consumption Time: 2.52741
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.78714

Cumulative Model Updates: 121,594
Cumulative Timesteps: 1,014,067,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.62846
Policy Entropy: 3.16462
Value Function Loss: 0.00388

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.51726
Value Function Update Magnitude: 0.56298

Collected Steps per Second: 22,875.59078
Overall Steps per Second: 10,744.90978

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.65337

Cumulative Model Updates: 121,600
Cumulative Timesteps: 1,014,117,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1014117134...
Checkpoint 1014117134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.06817
Policy Entropy: 3.15199
Value Function Loss: 0.00384

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.51845
Value Function Update Magnitude: 0.51890

Collected Steps per Second: 22,287.92444
Overall Steps per Second: 10,641.53555

Timestep Collection Time: 2.24373
Timestep Consumption Time: 2.45560
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.69932

Cumulative Model Updates: 121,606
Cumulative Timesteps: 1,014,167,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.96846
Policy Entropy: 3.15546
Value Function Loss: 0.00384

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.51914
Value Function Update Magnitude: 0.49289

Collected Steps per Second: 22,883.26378
Overall Steps per Second: 10,625.47452

Timestep Collection Time: 2.18535
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.70643

Cumulative Model Updates: 121,612
Cumulative Timesteps: 1,014,217,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1014217150...
Checkpoint 1014217150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.72547
Policy Entropy: 3.16231
Value Function Loss: 0.00377

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.51252
Value Function Update Magnitude: 0.48465

Collected Steps per Second: 22,506.89880
Overall Steps per Second: 10,469.48417

Timestep Collection Time: 2.22216
Timestep Consumption Time: 2.55496
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.77712

Cumulative Model Updates: 121,618
Cumulative Timesteps: 1,014,267,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.53726
Policy Entropy: 3.15722
Value Function Loss: 0.00373

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.51118
Value Function Update Magnitude: 0.49235

Collected Steps per Second: 22,074.65468
Overall Steps per Second: 10,449.57452

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.78546

Cumulative Model Updates: 121,624
Cumulative Timesteps: 1,014,317,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1014317170...
Checkpoint 1014317170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.90773
Policy Entropy: 3.14063
Value Function Loss: 0.00393

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.52003
Value Function Update Magnitude: 0.49842

Collected Steps per Second: 22,190.97497
Overall Steps per Second: 10,261.95543

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.61983
PPO Batch Consumption Time: 0.30835
Total Iteration Time: 4.87354

Cumulative Model Updates: 121,630
Cumulative Timesteps: 1,014,367,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.32827
Policy Entropy: 3.13141
Value Function Loss: 0.00386

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.52202
Value Function Update Magnitude: 0.49940

Collected Steps per Second: 22,076.53074
Overall Steps per Second: 10,436.78958

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.52610
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.79113

Cumulative Model Updates: 121,636
Cumulative Timesteps: 1,014,417,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1014417186...
Checkpoint 1014417186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.47042
Policy Entropy: 3.14606
Value Function Loss: 0.00426

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.51955
Value Function Update Magnitude: 0.50357

Collected Steps per Second: 21,762.14827
Overall Steps per Second: 10,343.32248

Timestep Collection Time: 2.29793
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.83481

Cumulative Model Updates: 121,642
Cumulative Timesteps: 1,014,467,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.51491
Policy Entropy: 3.13677
Value Function Loss: 0.00417

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.52156
Value Function Update Magnitude: 0.49555

Collected Steps per Second: 21,942.93486
Overall Steps per Second: 10,683.30462

Timestep Collection Time: 2.27991
Timestep Consumption Time: 2.40291
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.68282

Cumulative Model Updates: 121,648
Cumulative Timesteps: 1,014,517,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014517222...
Checkpoint 1014517222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.93060
Policy Entropy: 3.13128
Value Function Loss: 0.00421

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.51977
Value Function Update Magnitude: 0.49214

Collected Steps per Second: 19,898.37666
Overall Steps per Second: 9,931.79841

Timestep Collection Time: 2.51377
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 5.03635

Cumulative Model Updates: 121,654
Cumulative Timesteps: 1,014,567,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.93370
Policy Entropy: 3.12997
Value Function Loss: 0.00400

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.51661
Value Function Update Magnitude: 0.49188

Collected Steps per Second: 22,399.67789
Overall Steps per Second: 10,538.11015

Timestep Collection Time: 2.23325
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.74696

Cumulative Model Updates: 121,660
Cumulative Timesteps: 1,014,617,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1014617266...
Checkpoint 1014617266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.91689
Policy Entropy: 3.13815
Value Function Loss: 0.00385

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.51805
Value Function Update Magnitude: 0.49915

Collected Steps per Second: 22,166.44553
Overall Steps per Second: 10,345.41606

Timestep Collection Time: 2.25566
Timestep Consumption Time: 2.57740
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.83306

Cumulative Model Updates: 121,666
Cumulative Timesteps: 1,014,667,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.61396
Policy Entropy: 3.14172
Value Function Loss: 0.00413

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.52874
Value Function Update Magnitude: 0.52188

Collected Steps per Second: 21,121.41592
Overall Steps per Second: 10,202.39622

Timestep Collection Time: 2.36764
Timestep Consumption Time: 2.53395
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.90159

Cumulative Model Updates: 121,672
Cumulative Timesteps: 1,014,717,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1014717274...
Checkpoint 1014717274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.30349
Policy Entropy: 3.14243
Value Function Loss: 0.00386

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.52293

Collected Steps per Second: 22,511.52247
Overall Steps per Second: 10,513.14888

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.53537
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.75690

Cumulative Model Updates: 121,678
Cumulative Timesteps: 1,014,767,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.45925
Policy Entropy: 3.16185
Value Function Loss: 0.00372

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.51476
Value Function Update Magnitude: 0.50672

Collected Steps per Second: 21,431.52931
Overall Steps per Second: 10,478.40180

Timestep Collection Time: 2.33348
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.77267

Cumulative Model Updates: 121,684
Cumulative Timesteps: 1,014,817,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1014817294...
Checkpoint 1014817294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.46420
Policy Entropy: 3.14663
Value Function Loss: 0.00357

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.50935
Value Function Update Magnitude: 0.48903

Collected Steps per Second: 22,182.25186
Overall Steps per Second: 10,530.28819

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.75068

Cumulative Model Updates: 121,690
Cumulative Timesteps: 1,014,867,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,748.76354
Policy Entropy: 3.13260
Value Function Loss: 0.00359

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.50262
Value Function Update Magnitude: 0.46727

Collected Steps per Second: 21,733.95238
Overall Steps per Second: 10,578.60811

Timestep Collection Time: 2.30110
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.72765

Cumulative Model Updates: 121,696
Cumulative Timesteps: 1,014,917,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1014917332...
Checkpoint 1014917332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.58332
Policy Entropy: 3.13085
Value Function Loss: 0.00385

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.50709
Value Function Update Magnitude: 0.45610

Collected Steps per Second: 21,587.52836
Overall Steps per Second: 10,581.31843

Timestep Collection Time: 2.31708
Timestep Consumption Time: 2.41012
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.72720

Cumulative Model Updates: 121,702
Cumulative Timesteps: 1,014,967,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.49101
Policy Entropy: 3.13579
Value Function Loss: 0.00388

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.51621
Value Function Update Magnitude: 0.48327

Collected Steps per Second: 21,874.73761
Overall Steps per Second: 10,501.01912

Timestep Collection Time: 2.28666
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.76335

Cumulative Model Updates: 121,708
Cumulative Timesteps: 1,015,017,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1015017372...
Checkpoint 1015017372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.80225
Policy Entropy: 3.14431
Value Function Loss: 0.00394

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.51445
Value Function Update Magnitude: 0.50610

Collected Steps per Second: 21,622.05720
Overall Steps per Second: 10,592.01162

Timestep Collection Time: 2.31319
Timestep Consumption Time: 2.40886
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.72205

Cumulative Model Updates: 121,714
Cumulative Timesteps: 1,015,067,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.96947
Policy Entropy: 3.13671
Value Function Loss: 0.00398

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.51436
Value Function Update Magnitude: 0.49254

Collected Steps per Second: 22,563.01103
Overall Steps per Second: 10,408.54095

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.58928
PPO Batch Consumption Time: 0.30513
Total Iteration Time: 4.80663

Cumulative Model Updates: 121,720
Cumulative Timesteps: 1,015,117,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1015117418...
Checkpoint 1015117418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.35770
Policy Entropy: 3.12722
Value Function Loss: 0.00409

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.51703
Value Function Update Magnitude: 0.49979

Collected Steps per Second: 21,401.11617
Overall Steps per Second: 10,486.85551

Timestep Collection Time: 2.33661
Timestep Consumption Time: 2.43184
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.76845

Cumulative Model Updates: 121,726
Cumulative Timesteps: 1,015,167,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.06586
Policy Entropy: 3.12077
Value Function Loss: 0.00402

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.52255
Value Function Update Magnitude: 0.50993

Collected Steps per Second: 22,618.95364
Overall Steps per Second: 10,296.09934

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.64567
PPO Batch Consumption Time: 0.30620
Total Iteration Time: 4.85621

Cumulative Model Updates: 121,732
Cumulative Timesteps: 1,015,217,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1015217424...
Checkpoint 1015217424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.82677
Policy Entropy: 3.12011
Value Function Loss: 0.00382

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.52538
Value Function Update Magnitude: 0.50229

Collected Steps per Second: 22,121.07055
Overall Steps per Second: 10,531.95931

Timestep Collection Time: 2.26155
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.75011

Cumulative Model Updates: 121,738
Cumulative Timesteps: 1,015,267,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.84835
Policy Entropy: 3.12351
Value Function Loss: 0.00398

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.50145

Collected Steps per Second: 22,684.99935
Overall Steps per Second: 10,558.99844

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73681

Cumulative Model Updates: 121,744
Cumulative Timesteps: 1,015,317,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1015317468...
Checkpoint 1015317468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.84015
Policy Entropy: 3.11967
Value Function Loss: 0.00399

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.51311

Collected Steps per Second: 22,462.94259
Overall Steps per Second: 10,648.79170

Timestep Collection Time: 2.22651
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.69668

Cumulative Model Updates: 121,750
Cumulative Timesteps: 1,015,367,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.12644
Policy Entropy: 3.13731
Value Function Loss: 0.00399

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.50681

Collected Steps per Second: 22,348.31216
Overall Steps per Second: 10,270.48366

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.63133
PPO Batch Consumption Time: 0.30861
Total Iteration Time: 4.86890

Cumulative Model Updates: 121,756
Cumulative Timesteps: 1,015,417,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1015417488...
Checkpoint 1015417488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.25836
Policy Entropy: 3.13789
Value Function Loss: 0.00444

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.51305

Collected Steps per Second: 22,006.88287
Overall Steps per Second: 10,269.79041

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.59746
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.87021

Cumulative Model Updates: 121,762
Cumulative Timesteps: 1,015,467,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.73205
Policy Entropy: 3.13697
Value Function Loss: 0.00403

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 22,648.53896
Overall Steps per Second: 10,572.79076

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73158

Cumulative Model Updates: 121,768
Cumulative Timesteps: 1,015,517,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1015517530...
Checkpoint 1015517530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.43508
Policy Entropy: 3.13036
Value Function Loss: 0.00396

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.55391

Collected Steps per Second: 22,030.32912
Overall Steps per Second: 10,568.54298

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.73235

Cumulative Model Updates: 121,774
Cumulative Timesteps: 1,015,567,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.41909
Policy Entropy: 3.13264
Value Function Loss: 0.00359

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.53410
Value Function Update Magnitude: 0.53109

Collected Steps per Second: 22,440.60796
Overall Steps per Second: 10,477.47237

Timestep Collection Time: 2.22837
Timestep Consumption Time: 2.54435
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.77272

Cumulative Model Updates: 121,780
Cumulative Timesteps: 1,015,617,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1015617550...
Checkpoint 1015617550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.53097
Policy Entropy: 3.14570
Value Function Loss: 0.00359

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.52800
Value Function Update Magnitude: 0.51842

Collected Steps per Second: 22,255.50657
Overall Steps per Second: 10,613.31323

Timestep Collection Time: 2.24663
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.71106

Cumulative Model Updates: 121,786
Cumulative Timesteps: 1,015,667,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.66773
Policy Entropy: 3.14353
Value Function Loss: 0.00366

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.52064

Collected Steps per Second: 22,680.17319
Overall Steps per Second: 10,467.61888

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.57268
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.77778

Cumulative Model Updates: 121,792
Cumulative Timesteps: 1,015,717,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1015717562...
Checkpoint 1015717562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.07125
Policy Entropy: 3.13751
Value Function Loss: 0.00376

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.52457

Collected Steps per Second: 22,166.34669
Overall Steps per Second: 10,529.90885

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.75009

Cumulative Model Updates: 121,798
Cumulative Timesteps: 1,015,767,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.17736
Policy Entropy: 3.12396
Value Function Loss: 0.00421

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.54523
Value Function Update Magnitude: 0.53536

Collected Steps per Second: 21,704.20720
Overall Steps per Second: 10,315.72546

Timestep Collection Time: 2.30481
Timestep Consumption Time: 2.54449
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.84930

Cumulative Model Updates: 121,804
Cumulative Timesteps: 1,015,817,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1015817604...
Checkpoint 1015817604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.68478
Policy Entropy: 3.11723
Value Function Loss: 0.00435

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 22,198.24904
Overall Steps per Second: 10,440.85772

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.53665
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.78926

Cumulative Model Updates: 121,810
Cumulative Timesteps: 1,015,867,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.84531
Policy Entropy: 3.12407
Value Function Loss: 0.00470

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.51831

Collected Steps per Second: 20,852.03710
Overall Steps per Second: 10,162.83253

Timestep Collection Time: 2.39813
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.92048

Cumulative Model Updates: 121,816
Cumulative Timesteps: 1,015,917,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1015917614...
Checkpoint 1015917614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.94630
Policy Entropy: 3.13528
Value Function Loss: 0.00440

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.54442
Value Function Update Magnitude: 0.50236

Collected Steps per Second: 22,209.89524
Overall Steps per Second: 10,512.22102

Timestep Collection Time: 2.25143
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.75675

Cumulative Model Updates: 121,822
Cumulative Timesteps: 1,015,967,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.54133
Policy Entropy: 3.13184
Value Function Loss: 0.00415

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.52437
Value Function Update Magnitude: 0.50069

Collected Steps per Second: 22,430.92101
Overall Steps per Second: 10,444.34410

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.55862
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.78805

Cumulative Model Updates: 121,828
Cumulative Timesteps: 1,016,017,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1016017626...
Checkpoint 1016017626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.71295
Policy Entropy: 3.11613
Value Function Loss: 0.00381

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.50671

Collected Steps per Second: 20,887.39952
Overall Steps per Second: 10,041.63471

Timestep Collection Time: 2.39398
Timestep Consumption Time: 2.58569
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.97967

Cumulative Model Updates: 121,834
Cumulative Timesteps: 1,016,067,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.19354
Policy Entropy: 3.11745
Value Function Loss: 0.00407

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.53575
Value Function Update Magnitude: 0.48784

Collected Steps per Second: 22,358.07023
Overall Steps per Second: 10,327.81949

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.60621
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.84362

Cumulative Model Updates: 121,840
Cumulative Timesteps: 1,016,117,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1016117654...
Checkpoint 1016117654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.91410
Policy Entropy: 3.13824
Value Function Loss: 0.00423

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.50300

Collected Steps per Second: 21,397.33567
Overall Steps per Second: 9,960.56668

Timestep Collection Time: 2.33805
Timestep Consumption Time: 2.68456
PPO Batch Consumption Time: 0.31597
Total Iteration Time: 5.02261

Cumulative Model Updates: 121,846
Cumulative Timesteps: 1,016,167,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.80003
Policy Entropy: 3.15768
Value Function Loss: 0.00417

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.51864

Collected Steps per Second: 22,073.28620
Overall Steps per Second: 10,517.13538

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.75624

Cumulative Model Updates: 121,852
Cumulative Timesteps: 1,016,217,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1016217704...
Checkpoint 1016217704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.95613
Policy Entropy: 3.15396
Value Function Loss: 0.00414

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.53150
Value Function Update Magnitude: 0.52047

Collected Steps per Second: 22,178.76326
Overall Steps per Second: 10,401.59491

Timestep Collection Time: 2.25495
Timestep Consumption Time: 2.55316
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.80811

Cumulative Model Updates: 121,858
Cumulative Timesteps: 1,016,267,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,278.98539
Policy Entropy: 3.14665
Value Function Loss: 0.00387

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.50827

Collected Steps per Second: 22,241.06546
Overall Steps per Second: 10,416.69769

Timestep Collection Time: 2.24908
Timestep Consumption Time: 2.55301
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.80210

Cumulative Model Updates: 121,864
Cumulative Timesteps: 1,016,317,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1016317738...
Checkpoint 1016317738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.47236
Policy Entropy: 3.13230
Value Function Loss: 0.00411

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.50394

Collected Steps per Second: 22,604.06352
Overall Steps per Second: 10,601.90028

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.71670

Cumulative Model Updates: 121,870
Cumulative Timesteps: 1,016,367,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.44646
Policy Entropy: 3.13435
Value Function Loss: 0.00381

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.50870

Collected Steps per Second: 22,036.60964
Overall Steps per Second: 10,337.05223

Timestep Collection Time: 2.26931
Timestep Consumption Time: 2.56843
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.83774

Cumulative Model Updates: 121,876
Cumulative Timesteps: 1,016,417,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1016417752...
Checkpoint 1016417752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.82732
Policy Entropy: 3.13918
Value Function Loss: 0.00405

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.50801

Collected Steps per Second: 22,172.27766
Overall Steps per Second: 10,450.60678

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.53015
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.78594

Cumulative Model Updates: 121,882
Cumulative Timesteps: 1,016,467,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.33656
Policy Entropy: 3.13906
Value Function Loss: 0.00362

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.52813

Collected Steps per Second: 22,901.44163
Overall Steps per Second: 10,718.86317

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.66729

Cumulative Model Updates: 121,888
Cumulative Timesteps: 1,016,517,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1016517796...
Checkpoint 1016517796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.00515
Policy Entropy: 3.12637
Value Function Loss: 0.00364

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.52993
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 22,434.48523
Overall Steps per Second: 10,627.54556

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.47684
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.70626

Cumulative Model Updates: 121,894
Cumulative Timesteps: 1,016,567,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.81234
Policy Entropy: 3.13799
Value Function Loss: 0.00377

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.53833
Value Function Update Magnitude: 0.54643

Collected Steps per Second: 22,266.88319
Overall Steps per Second: 10,482.91921

Timestep Collection Time: 2.24665
Timestep Consumption Time: 2.52549
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77214

Cumulative Model Updates: 121,900
Cumulative Timesteps: 1,016,617,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1016617838...
Checkpoint 1016617838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,090.04328
Policy Entropy: 3.13853
Value Function Loss: 0.00384

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.53625
Value Function Update Magnitude: 0.54734

Collected Steps per Second: 22,052.21540
Overall Steps per Second: 10,463.29715

Timestep Collection Time: 2.26871
Timestep Consumption Time: 2.51277
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.78148

Cumulative Model Updates: 121,906
Cumulative Timesteps: 1,016,667,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255.38314
Policy Entropy: 3.14342
Value Function Loss: 0.00397

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.53607
Value Function Update Magnitude: 0.55811

Collected Steps per Second: 22,645.14082
Overall Steps per Second: 10,666.79112

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.68838

Cumulative Model Updates: 121,912
Cumulative Timesteps: 1,016,717,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1016717878...
Checkpoint 1016717878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.31041
Policy Entropy: 3.13082
Value Function Loss: 0.00387

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.57196

Collected Steps per Second: 21,585.56230
Overall Steps per Second: 10,159.30254

Timestep Collection Time: 2.31636
Timestep Consumption Time: 2.60523
PPO Batch Consumption Time: 0.31077
Total Iteration Time: 4.92160

Cumulative Model Updates: 121,918
Cumulative Timesteps: 1,016,767,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.85338
Policy Entropy: 3.13683
Value Function Loss: 0.00402

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.55435

Collected Steps per Second: 22,023.13124
Overall Steps per Second: 10,148.33808

Timestep Collection Time: 2.27107
Timestep Consumption Time: 2.65743
PPO Batch Consumption Time: 0.31043
Total Iteration Time: 4.92849

Cumulative Model Updates: 121,924
Cumulative Timesteps: 1,016,817,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1016817894...
Checkpoint 1016817894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.30047
Policy Entropy: 3.13687
Value Function Loss: 0.00415

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.55925

Collected Steps per Second: 22,128.51061
Overall Steps per Second: 10,268.91925

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.61110
PPO Batch Consumption Time: 0.30725
Total Iteration Time: 4.87198

Cumulative Model Updates: 121,930
Cumulative Timesteps: 1,016,867,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.66006
Policy Entropy: 3.15330
Value Function Loss: 0.00411

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.56406

Collected Steps per Second: 21,427.95986
Overall Steps per Second: 10,064.89912

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.63457
PPO Batch Consumption Time: 0.31077
Total Iteration Time: 4.96816

Cumulative Model Updates: 121,936
Cumulative Timesteps: 1,016,917,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1016917928...
Checkpoint 1016917928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.10033
Policy Entropy: 3.14212
Value Function Loss: 0.00404

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.56117

Collected Steps per Second: 21,619.41139
Overall Steps per Second: 10,192.80849

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.59362
PPO Batch Consumption Time: 0.30318
Total Iteration Time: 4.90719

Cumulative Model Updates: 121,942
Cumulative Timesteps: 1,016,967,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.60916
Policy Entropy: 3.13181
Value Function Loss: 0.00412

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.56774

Collected Steps per Second: 21,279.26622
Overall Steps per Second: 10,206.41395

Timestep Collection Time: 2.35196
Timestep Consumption Time: 2.55162
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.90358

Cumulative Model Updates: 121,948
Cumulative Timesteps: 1,017,017,994

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1017017994...
Checkpoint 1017017994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.76501
Policy Entropy: 3.13132
Value Function Loss: 0.00407

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.57521

Collected Steps per Second: 21,847.51880
Overall Steps per Second: 10,268.20851

Timestep Collection Time: 2.29005
Timestep Consumption Time: 2.58246
PPO Batch Consumption Time: 0.30835
Total Iteration Time: 4.87252

Cumulative Model Updates: 121,954
Cumulative Timesteps: 1,017,068,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.52533
Policy Entropy: 3.13839
Value Function Loss: 0.00436

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.58793

Collected Steps per Second: 22,356.24387
Overall Steps per Second: 10,534.61607

Timestep Collection Time: 2.23732
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.74797

Cumulative Model Updates: 121,960
Cumulative Timesteps: 1,017,118,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1017118044...
Checkpoint 1017118044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.11145
Policy Entropy: 3.14042
Value Function Loss: 0.00439

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 21,682.22769
Overall Steps per Second: 10,214.64187

Timestep Collection Time: 2.30668
Timestep Consumption Time: 2.58962
PPO Batch Consumption Time: 0.30892
Total Iteration Time: 4.89630

Cumulative Model Updates: 121,966
Cumulative Timesteps: 1,017,168,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.47640
Policy Entropy: 3.13053
Value Function Loss: 0.00467

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.57450

Collected Steps per Second: 22,035.89648
Overall Steps per Second: 10,425.59293

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.52687
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.79589

Cumulative Model Updates: 121,972
Cumulative Timesteps: 1,017,218,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1017218058...
Checkpoint 1017218058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.72054
Policy Entropy: 3.14259
Value Function Loss: 0.00413

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.56101

Collected Steps per Second: 22,369.38489
Overall Steps per Second: 10,599.72325

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.48310
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.71937

Cumulative Model Updates: 121,978
Cumulative Timesteps: 1,017,268,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.75570
Policy Entropy: 3.14196
Value Function Loss: 0.00419

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.53367

Collected Steps per Second: 22,478.26589
Overall Steps per Second: 10,499.01913

Timestep Collection Time: 2.22499
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.76368

Cumulative Model Updates: 121,984
Cumulative Timesteps: 1,017,318,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1017318096...
Checkpoint 1017318096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.15124
Policy Entropy: 3.13869
Value Function Loss: 0.00396

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.52900
Value Function Update Magnitude: 0.51476

Collected Steps per Second: 22,286.87971
Overall Steps per Second: 10,589.82940

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.72189

Cumulative Model Updates: 121,990
Cumulative Timesteps: 1,017,368,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.28222
Policy Entropy: 3.11773
Value Function Loss: 0.00391

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.50969

Collected Steps per Second: 22,507.80506
Overall Steps per Second: 10,326.15774

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.62167
PPO Batch Consumption Time: 0.31519
Total Iteration Time: 4.84401

Cumulative Model Updates: 121,996
Cumulative Timesteps: 1,017,418,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1017418120...
Checkpoint 1017418120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.27486
Policy Entropy: 3.11689
Value Function Loss: 0.00385

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.53067
Value Function Update Magnitude: 0.49980

Collected Steps per Second: 21,140.12209
Overall Steps per Second: 10,382.14780

Timestep Collection Time: 2.36621
Timestep Consumption Time: 2.45187
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.81808

Cumulative Model Updates: 122,002
Cumulative Timesteps: 1,017,468,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.01695
Policy Entropy: 3.12105
Value Function Loss: 0.00357

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.47836

Collected Steps per Second: 21,451.58898
Overall Steps per Second: 10,419.35454

Timestep Collection Time: 2.33092
Timestep Consumption Time: 2.46803
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.79895

Cumulative Model Updates: 122,008
Cumulative Timesteps: 1,017,518,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1017518144...
Checkpoint 1017518144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.74241
Policy Entropy: 3.11846
Value Function Loss: 0.00388

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.52054
Value Function Update Magnitude: 0.45717

Collected Steps per Second: 21,614.35405
Overall Steps per Second: 10,399.51837

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.80945

Cumulative Model Updates: 122,014
Cumulative Timesteps: 1,017,568,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.38644
Policy Entropy: 3.12192
Value Function Loss: 0.00389

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.46635

Collected Steps per Second: 22,851.36892
Overall Steps per Second: 10,759.52997

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.64853

Cumulative Model Updates: 122,020
Cumulative Timesteps: 1,017,618,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1017618176...
Checkpoint 1017618176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.11074
Policy Entropy: 3.12570
Value Function Loss: 0.00399

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.48042

Collected Steps per Second: 21,412.54912
Overall Steps per Second: 10,021.03323

Timestep Collection Time: 2.33536
Timestep Consumption Time: 2.65474
PPO Batch Consumption Time: 0.31564
Total Iteration Time: 4.99010

Cumulative Model Updates: 122,026
Cumulative Timesteps: 1,017,668,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.23203
Policy Entropy: 3.13375
Value Function Loss: 0.00386

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.48415

Collected Steps per Second: 22,531.69003
Overall Steps per Second: 10,592.04844

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.72128

Cumulative Model Updates: 122,032
Cumulative Timesteps: 1,017,718,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1017718190...
Checkpoint 1017718190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.98632
Policy Entropy: 3.13591
Value Function Loss: 0.00396

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.48445

Collected Steps per Second: 21,334.20662
Overall Steps per Second: 10,219.20445

Timestep Collection Time: 2.34394
Timestep Consumption Time: 2.54940
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 4.89334

Cumulative Model Updates: 122,038
Cumulative Timesteps: 1,017,768,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.21382
Policy Entropy: 3.13796
Value Function Loss: 0.00454

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.49020

Collected Steps per Second: 22,486.81752
Overall Steps per Second: 10,437.84072

Timestep Collection Time: 2.22361
Timestep Consumption Time: 2.56684
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 4.79045

Cumulative Model Updates: 122,044
Cumulative Timesteps: 1,017,818,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1017818198...
Checkpoint 1017818198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.56375
Policy Entropy: 3.13119
Value Function Loss: 0.00501

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.52973

Collected Steps per Second: 21,836.66746
Overall Steps per Second: 10,475.03621

Timestep Collection Time: 2.29037
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.77459

Cumulative Model Updates: 122,050
Cumulative Timesteps: 1,017,868,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.85977
Policy Entropy: 3.12388
Value Function Loss: 0.00457

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 21,624.94375
Overall Steps per Second: 10,263.94572

Timestep Collection Time: 2.31242
Timestep Consumption Time: 2.55958
PPO Batch Consumption Time: 0.30322
Total Iteration Time: 4.87201

Cumulative Model Updates: 122,056
Cumulative Timesteps: 1,017,918,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1017918218...
Checkpoint 1017918218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.71821
Policy Entropy: 3.11578
Value Function Loss: 0.00426

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.55079

Collected Steps per Second: 22,049.72420
Overall Steps per Second: 10,519.27247

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.48657
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.75508

Cumulative Model Updates: 122,062
Cumulative Timesteps: 1,017,968,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.79785
Policy Entropy: 3.12217
Value Function Loss: 0.00381

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.56131

Collected Steps per Second: 22,051.67718
Overall Steps per Second: 10,259.29435

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.60706
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.87519

Cumulative Model Updates: 122,068
Cumulative Timesteps: 1,018,018,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1018018254...
Checkpoint 1018018254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.88751
Policy Entropy: 3.12786
Value Function Loss: 0.00351

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.53671

Collected Steps per Second: 22,115.17033
Overall Steps per Second: 10,255.37112

Timestep Collection Time: 2.26198
Timestep Consumption Time: 2.61586
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.87783

Cumulative Model Updates: 122,074
Cumulative Timesteps: 1,018,068,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,143.10541
Policy Entropy: 3.12262
Value Function Loss: 0.00356

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.50711

Collected Steps per Second: 22,346.09424
Overall Steps per Second: 10,518.94919

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.75618

Cumulative Model Updates: 122,080
Cumulative Timesteps: 1,018,118,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1018118308...
Checkpoint 1018118308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.05101
Policy Entropy: 3.13246
Value Function Loss: 0.00360

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.49802

Collected Steps per Second: 21,922.60020
Overall Steps per Second: 10,446.87451

Timestep Collection Time: 2.28121
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29802
Total Iteration Time: 4.78708

Cumulative Model Updates: 122,086
Cumulative Timesteps: 1,018,168,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.65065
Policy Entropy: 3.13538
Value Function Loss: 0.00388

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.48891

Collected Steps per Second: 22,281.84674
Overall Steps per Second: 10,188.40775

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.66505
PPO Batch Consumption Time: 0.32046
Total Iteration Time: 4.91029

Cumulative Model Updates: 122,092
Cumulative Timesteps: 1,018,218,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1018218346...
Checkpoint 1018218346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.59080
Policy Entropy: 3.13084
Value Function Loss: 0.00404

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.49456

Collected Steps per Second: 21,599.70965
Overall Steps per Second: 10,357.07749

Timestep Collection Time: 2.31531
Timestep Consumption Time: 2.51327
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.82858

Cumulative Model Updates: 122,098
Cumulative Timesteps: 1,018,268,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.48085
Policy Entropy: 3.12641
Value Function Loss: 0.00416

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.52265

Collected Steps per Second: 22,252.21511
Overall Steps per Second: 10,528.53875

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.75090

Cumulative Model Updates: 122,104
Cumulative Timesteps: 1,018,318,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1018318376...
Checkpoint 1018318376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.30400
Policy Entropy: 3.12540
Value Function Loss: 0.00409

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.53031

Collected Steps per Second: 22,326.38943
Overall Steps per Second: 10,620.47562

Timestep Collection Time: 2.24076
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71052

Cumulative Model Updates: 122,110
Cumulative Timesteps: 1,018,368,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.40153
Policy Entropy: 3.12887
Value Function Loss: 0.00404

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.54249

Collected Steps per Second: 22,108.01525
Overall Steps per Second: 10,468.79716

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.77877

Cumulative Model Updates: 122,116
Cumulative Timesteps: 1,018,418,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1018418432...
Checkpoint 1018418432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.54924
Policy Entropy: 3.14101
Value Function Loss: 0.00385

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.52812
Value Function Update Magnitude: 0.53222

Collected Steps per Second: 22,413.09917
Overall Steps per Second: 10,628.29489

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.70668

Cumulative Model Updates: 122,122
Cumulative Timesteps: 1,018,468,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.39581
Policy Entropy: 3.15936
Value Function Loss: 0.00393

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.52061

Collected Steps per Second: 22,505.62506
Overall Steps per Second: 10,541.91386

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.74411

Cumulative Model Updates: 122,128
Cumulative Timesteps: 1,018,518,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1018518468...
Checkpoint 1018518468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.08219
Policy Entropy: 3.17246
Value Function Loss: 0.00402

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.53540
Value Function Update Magnitude: 0.52948

Collected Steps per Second: 22,424.10180
Overall Steps per Second: 10,575.16827

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.73014

Cumulative Model Updates: 122,134
Cumulative Timesteps: 1,018,568,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.90962
Policy Entropy: 3.18876
Value Function Loss: 0.00395

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.51356

Collected Steps per Second: 22,619.87996
Overall Steps per Second: 10,585.34431

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.72483

Cumulative Model Updates: 122,140
Cumulative Timesteps: 1,018,618,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1018618504...
Checkpoint 1018618504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,844.02043
Policy Entropy: 3.18233
Value Function Loss: 0.00401

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.49592

Collected Steps per Second: 22,383.93419
Overall Steps per Second: 10,546.78464

Timestep Collection Time: 2.23473
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.74287

Cumulative Model Updates: 122,146
Cumulative Timesteps: 1,018,668,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.07786
Policy Entropy: 3.19297
Value Function Loss: 0.00404

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.51029

Collected Steps per Second: 22,268.87364
Overall Steps per Second: 10,477.33488

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.52833
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.77488

Cumulative Model Updates: 122,152
Cumulative Timesteps: 1,018,718,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1018718554...
Checkpoint 1018718554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.56461
Policy Entropy: 3.18012
Value Function Loss: 0.00407

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.57658

Collected Steps per Second: 22,453.50165
Overall Steps per Second: 10,548.72345

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.74105

Cumulative Model Updates: 122,158
Cumulative Timesteps: 1,018,768,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.31776
Policy Entropy: 3.16160
Value Function Loss: 0.00394

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.58924

Collected Steps per Second: 22,312.36689
Overall Steps per Second: 10,461.52743

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.53983
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.78190

Cumulative Model Updates: 122,164
Cumulative Timesteps: 1,018,818,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1018818592...
Checkpoint 1018818592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.49687
Policy Entropy: 3.14273
Value Function Loss: 0.00400

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.56968

Collected Steps per Second: 22,539.26902
Overall Steps per Second: 10,633.18732

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.70470

Cumulative Model Updates: 122,170
Cumulative Timesteps: 1,018,868,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.32872
Policy Entropy: 3.12833
Value Function Loss: 0.00418

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.56231

Collected Steps per Second: 22,379.99546
Overall Steps per Second: 10,503.06017

Timestep Collection Time: 2.23485
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.76204

Cumulative Model Updates: 122,176
Cumulative Timesteps: 1,018,918,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1018918634...
Checkpoint 1018918634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.75229
Policy Entropy: 3.13632
Value Function Loss: 0.00424

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.57703

Collected Steps per Second: 22,390.07141
Overall Steps per Second: 10,601.62090

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71796

Cumulative Model Updates: 122,182
Cumulative Timesteps: 1,018,968,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.92879
Policy Entropy: 3.15495
Value Function Loss: 0.00441

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.58085

Collected Steps per Second: 22,592.97581
Overall Steps per Second: 10,528.17791

Timestep Collection Time: 2.21379
Timestep Consumption Time: 2.53689
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.75068

Cumulative Model Updates: 122,188
Cumulative Timesteps: 1,019,018,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1019018668...
Checkpoint 1019018668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.76483
Policy Entropy: 3.16611
Value Function Loss: 0.00415

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.56603

Collected Steps per Second: 21,917.27434
Overall Steps per Second: 10,563.73471

Timestep Collection Time: 2.28258
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.73583

Cumulative Model Updates: 122,194
Cumulative Timesteps: 1,019,068,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.40068
Policy Entropy: 3.17283
Value Function Loss: 0.00421

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.55447

Collected Steps per Second: 22,601.79099
Overall Steps per Second: 10,535.84212

Timestep Collection Time: 2.21275
Timestep Consumption Time: 2.53410
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.74684

Cumulative Model Updates: 122,200
Cumulative Timesteps: 1,019,118,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019118708...
Checkpoint 1019118708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,026.91650
Policy Entropy: 3.16426
Value Function Loss: 0.00389

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.55694

Collected Steps per Second: 22,263.92998
Overall Steps per Second: 10,547.05218

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.74066

Cumulative Model Updates: 122,206
Cumulative Timesteps: 1,019,168,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.26747
Policy Entropy: 3.17274
Value Function Loss: 0.00403

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.55653
Value Function Update Magnitude: 0.55344

Collected Steps per Second: 22,450.93537
Overall Steps per Second: 10,492.61115

Timestep Collection Time: 2.22815
Timestep Consumption Time: 2.53940
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.76755

Cumulative Model Updates: 122,212
Cumulative Timesteps: 1,019,218,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1019218732...
Checkpoint 1019218732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.47294
Policy Entropy: 3.17921
Value Function Loss: 0.00387

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.54137

Collected Steps per Second: 21,948.99994
Overall Steps per Second: 10,550.26125

Timestep Collection Time: 2.27928
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.74187

Cumulative Model Updates: 122,218
Cumulative Timesteps: 1,019,268,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,261.66386
Policy Entropy: 3.17643
Value Function Loss: 0.00394

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.51699

Collected Steps per Second: 22,119.22361
Overall Steps per Second: 10,510.48950

Timestep Collection Time: 2.26156
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.75944

Cumulative Model Updates: 122,224
Cumulative Timesteps: 1,019,318,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1019318784...
Checkpoint 1019318784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.48439
Policy Entropy: 3.16302
Value Function Loss: 0.00397

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.50725

Collected Steps per Second: 20,817.73058
Overall Steps per Second: 10,212.79335

Timestep Collection Time: 2.40209
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.89641

Cumulative Model Updates: 122,230
Cumulative Timesteps: 1,019,368,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.93409
Policy Entropy: 3.14517
Value Function Loss: 0.00390

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.50347

Collected Steps per Second: 20,972.22513
Overall Steps per Second: 10,326.47123

Timestep Collection Time: 2.38525
Timestep Consumption Time: 2.45900
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.84425

Cumulative Model Updates: 122,236
Cumulative Timesteps: 1,019,418,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1019418814...
Checkpoint 1019418814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.13592
Policy Entropy: 3.15401
Value Function Loss: 0.00396

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.53932
Value Function Update Magnitude: 0.49869

Collected Steps per Second: 22,229.84596
Overall Steps per Second: 10,400.86252

Timestep Collection Time: 2.24941
Timestep Consumption Time: 2.55827
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.80768

Cumulative Model Updates: 122,242
Cumulative Timesteps: 1,019,468,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.76673
Policy Entropy: 3.14987
Value Function Loss: 0.00416

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 22,620.99457
Overall Steps per Second: 10,596.84932

Timestep Collection Time: 2.21060
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.71895

Cumulative Model Updates: 122,248
Cumulative Timesteps: 1,019,518,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1019518824...
Checkpoint 1019518824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.11630
Policy Entropy: 3.16737
Value Function Loss: 0.00425

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.54817
Value Function Update Magnitude: 0.52327

Collected Steps per Second: 22,426.99210
Overall Steps per Second: 10,552.48373

Timestep Collection Time: 2.23008
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.73955

Cumulative Model Updates: 122,254
Cumulative Timesteps: 1,019,568,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.87523
Policy Entropy: 3.18581
Value Function Loss: 0.00397

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.51580

Collected Steps per Second: 22,660.24394
Overall Steps per Second: 10,704.13007

Timestep Collection Time: 2.20668
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.67147

Cumulative Model Updates: 122,260
Cumulative Timesteps: 1,019,618,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1019618842...
Checkpoint 1019618842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.03796
Policy Entropy: 3.19060
Value Function Loss: 0.00423

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.55629

Collected Steps per Second: 22,431.72328
Overall Steps per Second: 10,585.21607

Timestep Collection Time: 2.23015
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.72603

Cumulative Model Updates: 122,266
Cumulative Timesteps: 1,019,668,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.22779
Policy Entropy: 3.16866
Value Function Loss: 0.00427

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 21,810.00258
Overall Steps per Second: 10,497.85689

Timestep Collection Time: 2.29317
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.76421

Cumulative Model Updates: 122,272
Cumulative Timesteps: 1,019,718,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1019718882...
Checkpoint 1019718882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.25845
Policy Entropy: 3.14153
Value Function Loss: 0.00466

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.54978
Value Function Update Magnitude: 0.54110

Collected Steps per Second: 22,163.90998
Overall Steps per Second: 10,655.10789

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.69540

Cumulative Model Updates: 122,278
Cumulative Timesteps: 1,019,768,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.77538
Policy Entropy: 3.14064
Value Function Loss: 0.00427

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.54874
Value Function Update Magnitude: 0.53030

Collected Steps per Second: 22,310.93536
Overall Steps per Second: 10,487.13879

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.52811
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.77041

Cumulative Model Updates: 122,284
Cumulative Timesteps: 1,019,818,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019818940...
Checkpoint 1019818940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.21182
Policy Entropy: 3.14718
Value Function Loss: 0.00429

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.53794

Collected Steps per Second: 22,455.81122
Overall Steps per Second: 10,684.94893

Timestep Collection Time: 2.22766
Timestep Consumption Time: 2.45406
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.68173

Cumulative Model Updates: 122,290
Cumulative Timesteps: 1,019,868,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.31666
Policy Entropy: 3.14405
Value Function Loss: 0.00466

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.55007

Collected Steps per Second: 22,237.47545
Overall Steps per Second: 10,481.11332

Timestep Collection Time: 2.24900
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.77163

Cumulative Model Updates: 122,296
Cumulative Timesteps: 1,019,918,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019918976...
Checkpoint 1019918976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.57641
Policy Entropy: 3.12901
Value Function Loss: 0.00419

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.54716

Collected Steps per Second: 22,441.01013
Overall Steps per Second: 10,593.25781

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.72168

Cumulative Model Updates: 122,302
Cumulative Timesteps: 1,019,968,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.32203
Policy Entropy: 3.14556
Value Function Loss: 0.00382

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.50652

Collected Steps per Second: 22,457.33145
Overall Steps per Second: 10,577.99086

Timestep Collection Time: 2.22751
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.72906

Cumulative Model Updates: 122,308
Cumulative Timesteps: 1,020,019,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1020019018...
Checkpoint 1020019018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.77067
Policy Entropy: 3.15842
Value Function Loss: 0.00363

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.54230
Value Function Update Magnitude: 0.48141

Collected Steps per Second: 22,339.57086
Overall Steps per Second: 10,469.27516

Timestep Collection Time: 2.23863
Timestep Consumption Time: 2.53821
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.77683

Cumulative Model Updates: 122,314
Cumulative Timesteps: 1,020,069,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,966.46018
Policy Entropy: 3.16793
Value Function Loss: 0.00397

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.46586

Collected Steps per Second: 22,672.76277
Overall Steps per Second: 10,618.94350

Timestep Collection Time: 2.20644
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.71101

Cumulative Model Updates: 122,320
Cumulative Timesteps: 1,020,119,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020119054...
Checkpoint 1020119054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,405.67768
Policy Entropy: 3.16623
Value Function Loss: 0.00417

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.49729

Collected Steps per Second: 22,192.07979
Overall Steps per Second: 10,507.09536

Timestep Collection Time: 2.25441
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.76154

Cumulative Model Updates: 122,326
Cumulative Timesteps: 1,020,169,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.94035
Policy Entropy: 3.16221
Value Function Loss: 0.00415

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.53547

Collected Steps per Second: 22,701.22312
Overall Steps per Second: 10,595.31945

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.72001

Cumulative Model Updates: 122,332
Cumulative Timesteps: 1,020,219,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1020219094...
Checkpoint 1020219094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.74013
Policy Entropy: 3.14913
Value Function Loss: 0.00398

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.53564

Collected Steps per Second: 22,224.62398
Overall Steps per Second: 10,535.22059

Timestep Collection Time: 2.25021
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.74693

Cumulative Model Updates: 122,338
Cumulative Timesteps: 1,020,269,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,836.31339
Policy Entropy: 3.13811
Value Function Loss: 0.00399

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.51527

Collected Steps per Second: 22,374.53888
Overall Steps per Second: 10,328.64823

Timestep Collection Time: 2.23486
Timestep Consumption Time: 2.60643
PPO Batch Consumption Time: 0.31133
Total Iteration Time: 4.84129

Cumulative Model Updates: 122,344
Cumulative Timesteps: 1,020,319,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1020319108...
Checkpoint 1020319108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.96152
Policy Entropy: 3.13518
Value Function Loss: 0.00444

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.53785

Collected Steps per Second: 21,872.75615
Overall Steps per Second: 10,398.87614

Timestep Collection Time: 2.28723
Timestep Consumption Time: 2.52368
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.81090

Cumulative Model Updates: 122,350
Cumulative Timesteps: 1,020,369,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.37573
Policy Entropy: 3.12857
Value Function Loss: 0.00433

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.54832

Collected Steps per Second: 22,515.07065
Overall Steps per Second: 10,686.06206

Timestep Collection Time: 2.22207
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.68180

Cumulative Model Updates: 122,356
Cumulative Timesteps: 1,020,419,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1020419166...
Checkpoint 1020419166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.47435
Policy Entropy: 3.14314
Value Function Loss: 0.00423

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.54311
Value Function Update Magnitude: 0.52243

Collected Steps per Second: 22,277.54929
Overall Steps per Second: 10,644.16936

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.69778

Cumulative Model Updates: 122,362
Cumulative Timesteps: 1,020,469,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.74009
Policy Entropy: 3.15241
Value Function Loss: 0.00390

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.53195
Value Function Update Magnitude: 0.50488

Collected Steps per Second: 22,446.01204
Overall Steps per Second: 10,621.28958

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.70809

Cumulative Model Updates: 122,368
Cumulative Timesteps: 1,020,519,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1020519176...
Checkpoint 1020519176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.11060
Policy Entropy: 3.17043
Value Function Loss: 0.00411

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.51192

Collected Steps per Second: 22,374.98882
Overall Steps per Second: 10,595.00193

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.72166

Cumulative Model Updates: 122,374
Cumulative Timesteps: 1,020,569,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.55969
Policy Entropy: 3.15538
Value Function Loss: 0.00436

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.52851

Collected Steps per Second: 22,268.88616
Overall Steps per Second: 10,489.41543

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.52163
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.76709

Cumulative Model Updates: 122,380
Cumulative Timesteps: 1,020,619,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1020619206...
Checkpoint 1020619206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.19437
Policy Entropy: 3.16283
Value Function Loss: 0.00455

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.54845

Collected Steps per Second: 21,957.64156
Overall Steps per Second: 10,581.91343

Timestep Collection Time: 2.27820
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.72731

Cumulative Model Updates: 122,386
Cumulative Timesteps: 1,020,669,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.63888
Policy Entropy: 3.16503
Value Function Loss: 0.00438

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.55084

Collected Steps per Second: 22,181.91530
Overall Steps per Second: 10,587.26511

Timestep Collection Time: 2.25481
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.72417

Cumulative Model Updates: 122,392
Cumulative Timesteps: 1,020,719,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1020719246...
Checkpoint 1020719246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.68930
Policy Entropy: 3.17633
Value Function Loss: 0.00435

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.56467

Collected Steps per Second: 19,434.50252
Overall Steps per Second: 9,948.76321

Timestep Collection Time: 2.57367
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 5.02756

Cumulative Model Updates: 122,398
Cumulative Timesteps: 1,020,769,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.04109
Policy Entropy: 3.16074
Value Function Loss: 0.00418

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.57202

Collected Steps per Second: 18,958.72245
Overall Steps per Second: 9,531.33688

Timestep Collection Time: 2.63879
Timestep Consumption Time: 2.61001
PPO Batch Consumption Time: 0.31120
Total Iteration Time: 5.24879

Cumulative Model Updates: 122,404
Cumulative Timesteps: 1,020,819,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1020819292...
Checkpoint 1020819292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.17010
Policy Entropy: 3.15883
Value Function Loss: 0.00415

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.57052

Collected Steps per Second: 19,245.22642
Overall Steps per Second: 9,916.87999

Timestep Collection Time: 2.59825
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 5.04231

Cumulative Model Updates: 122,410
Cumulative Timesteps: 1,020,869,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.63287
Policy Entropy: 3.15653
Value Function Loss: 0.00427

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.56512

Collected Steps per Second: 19,233.53960
Overall Steps per Second: 9,501.92740

Timestep Collection Time: 2.59963
Timestep Consumption Time: 2.66246
PPO Batch Consumption Time: 0.31816
Total Iteration Time: 5.26209

Cumulative Model Updates: 122,416
Cumulative Timesteps: 1,020,919,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1020919296...
Checkpoint 1020919296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.52418
Policy Entropy: 3.15717
Value Function Loss: 0.00418

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.54462

Collected Steps per Second: 16,886.26211
Overall Steps per Second: 9,048.31505

Timestep Collection Time: 2.96265
Timestep Consumption Time: 2.56634
PPO Batch Consumption Time: 0.30429
Total Iteration Time: 5.52899

Cumulative Model Updates: 122,422
Cumulative Timesteps: 1,020,969,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.74008
Policy Entropy: 3.14481
Value Function Loss: 0.00420

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.54174

Collected Steps per Second: 14,072.12011
Overall Steps per Second: 7,151.98729

Timestep Collection Time: 3.55554
Timestep Consumption Time: 3.44028
PPO Batch Consumption Time: 0.43750
Total Iteration Time: 6.99582

Cumulative Model Updates: 122,428
Cumulative Timesteps: 1,021,019,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1021019358...
Checkpoint 1021019358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.62833
Policy Entropy: 3.14466
Value Function Loss: 0.00425

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.54010
Value Function Update Magnitude: 0.55212

Collected Steps per Second: 6,437.45686
Overall Steps per Second: 4,340.20909

Timestep Collection Time: 7.77108
Timestep Consumption Time: 3.75509
PPO Batch Consumption Time: 0.41868
Total Iteration Time: 11.52617

Cumulative Model Updates: 122,434
Cumulative Timesteps: 1,021,069,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,856.23846
Policy Entropy: 3.14039
Value Function Loss: 0.00439

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.57635

Collected Steps per Second: 11,041.91486
Overall Steps per Second: 5,368.71952

Timestep Collection Time: 4.52947
Timestep Consumption Time: 4.78635
PPO Batch Consumption Time: 0.65667
Total Iteration Time: 9.31582

Cumulative Model Updates: 122,440
Cumulative Timesteps: 1,021,119,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1021119398...
Checkpoint 1021119398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.72694
Policy Entropy: 3.14618
Value Function Loss: 0.00444

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 15,296.29787
Overall Steps per Second: 6,004.78118

Timestep Collection Time: 3.26955
Timestep Consumption Time: 5.05915
PPO Batch Consumption Time: 0.70007
Total Iteration Time: 8.32870

Cumulative Model Updates: 122,446
Cumulative Timesteps: 1,021,169,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.12030
Policy Entropy: 3.14027
Value Function Loss: 0.00474

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.55976

Collected Steps per Second: 14,837.46903
Overall Steps per Second: 6,509.94694

Timestep Collection Time: 3.37133
Timestep Consumption Time: 4.31260
PPO Batch Consumption Time: 0.59504
Total Iteration Time: 7.68393

Cumulative Model Updates: 122,452
Cumulative Timesteps: 1,021,219,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1021219432...
Checkpoint 1021219432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.81485
Policy Entropy: 3.15049
Value Function Loss: 0.00486

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.57814
Value Function Update Magnitude: 0.59051

Collected Steps per Second: 6,015.06798
Overall Steps per Second: 2,282.84734

Timestep Collection Time: 8.31312
Timestep Consumption Time: 13.59110
PPO Batch Consumption Time: 2.09744
Total Iteration Time: 21.90422

Cumulative Model Updates: 122,458
Cumulative Timesteps: 1,021,269,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------
