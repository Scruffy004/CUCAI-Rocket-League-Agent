{"Timestep Collection Time":2.490437100001145,"x_vel":8.444067002068048,"Timestep Consumption Time":2.749560399999609,"SB3 Clip Fraction":0.025823332369327545,"Policy Update Magnitude":0.6947429180145264,"Value Function Loss":0.0037204399704933167,"y_vel":-186.5594775648891,"Cumulative Timesteps":954635880,"Policy Reward":88.93395064437254,"_timestamp":1.7410389340054004e+09,"Total Iteration Time":5.239997500000754,"PPO Batch Consumption Time":0.3350188732147217,"_runtime":772705.2885663,"Mean KL Divergence":0.002365643255567799,"Policy Entropy":4.428728898366292,"Overall Steps per Second":9543.134324013094,"Collected Steps per Second":20079.20617628809,"_wandb":{"runtime":772705},"z_vel":-27.798145264635057,"Timesteps Collected":50006,"Value Function Update Magnitude":0.48237746953964233,"Cumulative Model Updates":114472,"_step":320722}