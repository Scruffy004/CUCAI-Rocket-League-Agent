{"Total Iteration Time":23.97282150000001,"Policy Entropy":1.8661792079607646,"Value Function Update Magnitude":0.4653388261795044,"z_vel":5.071391504812922,"PPO Batch Consumption Time":2.0301244258880615,"Policy Update Magnitude":0.5112167000770569,"Collected Steps per Second":4737.084161987031,"SB3 Clip Fraction":0.167796661456426,"_wandb":{"runtime":79282},"Cumulative Timesteps":720463566,"Timestep Collection Time":10.564726800000017,"Cumulative Model Updates":86378,"x_vel":-1.864753262628012,"Mean KL Divergence":0.017324134707450867,"Overall Steps per Second":2087.6140924838564,"_step":28798,"Timestep Consumption Time":13.408094699999992,"Value Function Loss":0.09562734141945839,"_runtime":79282.5643476,"_timestamp":1.7372344826143703e+09,"y_vel":7.664177615921109,"Policy Reward":15575.579543600707,"Timesteps Collected":50046}