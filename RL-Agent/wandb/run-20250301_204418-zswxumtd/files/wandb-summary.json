{"_runtime":703607.2178547,"Policy Update Magnitude":0.2650206685066223,"PPO Batch Consumption Time":0.28380028406778973,"Mean KL Divergence":0.0003885242234294613,"Total Iteration Time":4.881581099994946,"_timestamp":1.740943956891533e+09,"Timesteps Collected":50022,"Cumulative Timesteps":2603024322,"Policy Reward":27.104011631178693,"SB3 Clip Fraction":0.003903333175306519,"Overall Steps per Second":10247.089820970461,"z_vel":-32.68905330624283,"_step":294538,"Cumulative Model Updates":312136,"Collected Steps per Second":20619.893642346215,"Value Function Loss":0.0021060871658846736,"Timestep Collection Time":2.4259097000031034,"_wandb":{"runtime":703607},"y_vel":63.278661830042125,"Timestep Consumption Time":2.455671399991843,"x_vel":61.885537193572915,"Value Function Update Magnitude":0.47044846415519714,"Policy Entropy":4.45936115582784}