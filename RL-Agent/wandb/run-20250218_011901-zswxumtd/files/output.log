Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.40827
Policy Entropy: 3.98881
Value Function Loss: 0.00842

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00485
Policy Update Magnitude: 0.09017
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 6,314.58650
Overall Steps per Second: 3,348.34437

Timestep Collection Time: 7.92229
Timestep Consumption Time: 7.01823
PPO Batch Consumption Time: 2.82597
Total Iteration Time: 14.94052

Cumulative Model Updates: 374,022
Cumulative Timesteps: 3,119,386,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.23423
Policy Entropy: 3.94071
Value Function Loss: 0.00871

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01712
Policy Update Magnitude: 0.19807
Value Function Update Magnitude: 0.22363

Collected Steps per Second: 21,781.66836
Overall Steps per Second: 11,754.10088

Timestep Collection Time: 2.29652
Timestep Consumption Time: 1.95919
PPO Batch Consumption Time: 0.30410
Total Iteration Time: 4.25571

Cumulative Model Updates: 374,026
Cumulative Timesteps: 3,119,437,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3119437002...
Checkpoint 3119437002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.02611
Policy Entropy: 3.96733
Value Function Loss: 0.00778

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.28792
Value Function Update Magnitude: 0.33831

Collected Steps per Second: 21,911.73061
Overall Steps per Second: 10,587.29208

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.72529

Cumulative Model Updates: 374,032
Cumulative Timesteps: 3,119,487,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.53539
Policy Entropy: 3.95935
Value Function Loss: 0.00778

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03061
Policy Update Magnitude: 0.26938
Value Function Update Magnitude: 0.34512

Collected Steps per Second: 22,477.03259
Overall Steps per Second: 10,616.71528

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.71351

Cumulative Model Updates: 374,038
Cumulative Timesteps: 3,119,537,072

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3119537072...
Checkpoint 3119537072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.96129
Policy Entropy: 3.98099
Value Function Loss: 0.00758

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.26266
Value Function Update Magnitude: 0.34667

Collected Steps per Second: 22,224.96133
Overall Steps per Second: 10,557.20461

Timestep Collection Time: 2.24972
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.73610

Cumulative Model Updates: 374,044
Cumulative Timesteps: 3,119,587,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.79492
Policy Entropy: 3.99677
Value Function Loss: 0.00667

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.24839
Value Function Update Magnitude: 0.34276

Collected Steps per Second: 21,195.86345
Overall Steps per Second: 10,426.60739

Timestep Collection Time: 2.36018
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.79792

Cumulative Model Updates: 374,050
Cumulative Timesteps: 3,119,637,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3119637098...
Checkpoint 3119637098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.96218
Policy Entropy: 3.99040
Value Function Loss: 0.00760

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.23997
Value Function Update Magnitude: 0.32091

Collected Steps per Second: 22,327.52759
Overall Steps per Second: 10,681.06991

Timestep Collection Time: 2.24055
Timestep Consumption Time: 2.44306
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.68361

Cumulative Model Updates: 374,056
Cumulative Timesteps: 3,119,687,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.70851
Policy Entropy: 4.01093
Value Function Loss: 0.00731

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.23784
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 22,237.85310
Overall Steps per Second: 10,755.37551

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.40176
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.65144

Cumulative Model Updates: 374,062
Cumulative Timesteps: 3,119,737,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3119737152...
Checkpoint 3119737152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.77211
Policy Entropy: 3.95514
Value Function Loss: 0.00849

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.25300
Value Function Update Magnitude: 0.33260

Collected Steps per Second: 22,326.45917
Overall Steps per Second: 10,570.08749

Timestep Collection Time: 2.24075
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.73298

Cumulative Model Updates: 374,068
Cumulative Timesteps: 3,119,787,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.09322
Policy Entropy: 3.94458
Value Function Loss: 0.00790

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.26332
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 22,313.05256
Overall Steps per Second: 10,745.26816

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.41305
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.65451

Cumulative Model Updates: 374,074
Cumulative Timesteps: 3,119,837,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3119837194...
Checkpoint 3119837194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.53813
Policy Entropy: 3.92198
Value Function Loss: 0.00805

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.26631
Value Function Update Magnitude: 0.36244

Collected Steps per Second: 22,282.75870
Overall Steps per Second: 10,789.19326

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.39067
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.63482

Cumulative Model Updates: 374,080
Cumulative Timesteps: 3,119,887,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.79855
Policy Entropy: 3.95145
Value Function Loss: 0.00686

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.26549
Value Function Update Magnitude: 0.35356

Collected Steps per Second: 22,584.86963
Overall Steps per Second: 10,663.56431

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.47529
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.68943

Cumulative Model Updates: 374,086
Cumulative Timesteps: 3,119,937,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3119937206...
Checkpoint 3119937206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.56799
Policy Entropy: 3.95905
Value Function Loss: 0.00694

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.25689
Value Function Update Magnitude: 0.34148

Collected Steps per Second: 22,202.66740
Overall Steps per Second: 10,628.13542

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.70694

Cumulative Model Updates: 374,092
Cumulative Timesteps: 3,119,987,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.92808
Policy Entropy: 3.94215
Value Function Loss: 0.00631

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.24934
Value Function Update Magnitude: 0.33306

Collected Steps per Second: 22,409.39878
Overall Steps per Second: 10,689.45511

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.67957

Cumulative Model Updates: 374,098
Cumulative Timesteps: 3,120,037,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3120037254...
Checkpoint 3120037254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.22420
Policy Entropy: 3.91736
Value Function Loss: 0.00682

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.25694
Value Function Update Magnitude: 0.33189

Collected Steps per Second: 22,325.02135
Overall Steps per Second: 10,690.68731

Timestep Collection Time: 2.24036
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.67846

Cumulative Model Updates: 374,104
Cumulative Timesteps: 3,120,087,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38567
Policy Entropy: 3.93436
Value Function Loss: 0.00729

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.25422
Value Function Update Magnitude: 0.34676

Collected Steps per Second: 22,157.73655
Overall Steps per Second: 10,635.17885

Timestep Collection Time: 2.25673
Timestep Consumption Time: 2.44503
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.70175

Cumulative Model Updates: 374,110
Cumulative Timesteps: 3,120,137,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3120137274...
Checkpoint 3120137274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.91053
Policy Entropy: 3.96436
Value Function Loss: 0.00702

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.25622
Value Function Update Magnitude: 0.35749

Collected Steps per Second: 22,074.71505
Overall Steps per Second: 10,844.16253

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.34574
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.61078

Cumulative Model Updates: 374,116
Cumulative Timesteps: 3,120,187,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.74206
Policy Entropy: 3.99441
Value Function Loss: 0.00663

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02142
Policy Update Magnitude: 0.24692
Value Function Update Magnitude: 0.36346

Collected Steps per Second: 22,358.93616
Overall Steps per Second: 10,506.59151

Timestep Collection Time: 2.23705
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.76063

Cumulative Model Updates: 374,122
Cumulative Timesteps: 3,120,237,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3120237292...
Checkpoint 3120237292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.31644
Policy Entropy: 3.99774
Value Function Loss: 0.00593

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.24686
Value Function Update Magnitude: 0.34588

Collected Steps per Second: 22,321.83116
Overall Steps per Second: 10,657.91978

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.69135

Cumulative Model Updates: 374,128
Cumulative Timesteps: 3,120,287,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97252
Policy Entropy: 4.01616
Value Function Loss: 0.00531

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02725
Policy Update Magnitude: 0.23568
Value Function Update Magnitude: 0.32791

Collected Steps per Second: 23,332.27258
Overall Steps per Second: 10,947.75627

Timestep Collection Time: 2.14407
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.56952

Cumulative Model Updates: 374,134
Cumulative Timesteps: 3,120,337,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3120337318...
Checkpoint 3120337318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.93983
Policy Entropy: 3.98392
Value Function Loss: 0.00622

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02165
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.30998

Collected Steps per Second: 22,080.59408
Overall Steps per Second: 10,624.32727

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.70806

Cumulative Model Updates: 374,140
Cumulative Timesteps: 3,120,387,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.06468
Policy Entropy: 3.97227
Value Function Loss: 0.00618

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.23972
Value Function Update Magnitude: 0.31075

Collected Steps per Second: 22,330.46426
Overall Steps per Second: 10,584.92191

Timestep Collection Time: 2.23963
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.72483

Cumulative Model Updates: 374,146
Cumulative Timesteps: 3,120,437,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3120437350...
Checkpoint 3120437350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.55529
Policy Entropy: 3.97004
Value Function Loss: 0.00616

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.23826
Value Function Update Magnitude: 0.32205

Collected Steps per Second: 23,092.32475
Overall Steps per Second: 10,750.57430

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.48699
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.65333

Cumulative Model Updates: 374,152
Cumulative Timesteps: 3,120,487,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.34361
Policy Entropy: 4.01335
Value Function Loss: 0.00565

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.23971
Value Function Update Magnitude: 0.32248

Collected Steps per Second: 22,637.56095
Overall Steps per Second: 10,740.88856

Timestep Collection Time: 2.20978
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.65734

Cumulative Model Updates: 374,158
Cumulative Timesteps: 3,120,537,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3120537400...
Checkpoint 3120537400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.44343
Policy Entropy: 4.04020
Value Function Loss: 0.00594

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.24076
Value Function Update Magnitude: 0.31252

Collected Steps per Second: 22,066.83608
Overall Steps per Second: 10,693.89089

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.41021
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67650

Cumulative Model Updates: 374,164
Cumulative Timesteps: 3,120,587,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.71033
Policy Entropy: 4.00981
Value Function Loss: 0.00583

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.22826
Value Function Update Magnitude: 0.30305

Collected Steps per Second: 22,554.93913
Overall Steps per Second: 10,734.55643

Timestep Collection Time: 2.21858
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.66158

Cumulative Model Updates: 374,170
Cumulative Timesteps: 3,120,637,450

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 3120637450...
Checkpoint 3120637450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.91850
Policy Entropy: 3.99290
Value Function Loss: 0.00600

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.23108
Value Function Update Magnitude: 0.30490

Collected Steps per Second: 21,665.33004
Overall Steps per Second: 10,341.22849

Timestep Collection Time: 2.30867
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.83676

Cumulative Model Updates: 374,176
Cumulative Timesteps: 3,120,687,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01204
Policy Entropy: 4.00499
Value Function Loss: 0.00502

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.22914
Value Function Update Magnitude: 0.30756

Collected Steps per Second: 22,482.74643
Overall Steps per Second: 10,914.13069

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.35748
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.58158

Cumulative Model Updates: 374,182
Cumulative Timesteps: 3,120,737,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3120737472...
Checkpoint 3120737472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.40434
Policy Entropy: 4.01705
Value Function Loss: 0.00546

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.22777
Value Function Update Magnitude: 0.29256

Collected Steps per Second: 22,133.28540
Overall Steps per Second: 10,665.64220

Timestep Collection Time: 2.26031
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.69058

Cumulative Model Updates: 374,188
Cumulative Timesteps: 3,120,787,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.22892
Policy Entropy: 3.99902
Value Function Loss: 0.00586

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.23929
Value Function Update Magnitude: 0.28284

Collected Steps per Second: 22,398.46024
Overall Steps per Second: 10,747.83039

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.65675

Cumulative Model Updates: 374,194
Cumulative Timesteps: 3,120,837,550

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 3120837550...
Checkpoint 3120837550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.73371
Policy Entropy: 3.92477
Value Function Loss: 0.00735

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.25670
Value Function Update Magnitude: 0.30602

Collected Steps per Second: 22,217.09981
Overall Steps per Second: 10,732.69829

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.66257

Cumulative Model Updates: 374,200
Cumulative Timesteps: 3,120,887,592

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.45081
Policy Entropy: 3.94616
Value Function Loss: 0.00692

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.26334
Value Function Update Magnitude: 0.33651

Collected Steps per Second: 22,634.69354
Overall Steps per Second: 10,629.05871

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70465

Cumulative Model Updates: 374,206
Cumulative Timesteps: 3,120,937,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3120937598...
Checkpoint 3120937598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.53515
Policy Entropy: 3.95870
Value Function Loss: 0.00627

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02973
Policy Update Magnitude: 0.26384
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 22,141.87712
Overall Steps per Second: 10,577.10010

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72890

Cumulative Model Updates: 374,212
Cumulative Timesteps: 3,120,987,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.94826
Policy Entropy: 4.00190
Value Function Loss: 0.00653

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02355
Policy Update Magnitude: 0.24815
Value Function Update Magnitude: 0.31937

Collected Steps per Second: 22,558.09460
Overall Steps per Second: 10,812.33809

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.62509

Cumulative Model Updates: 374,218
Cumulative Timesteps: 3,121,037,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3121037624...
Checkpoint 3121037624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.88387
Policy Entropy: 3.99286
Value Function Loss: 0.00566

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.24440
Value Function Update Magnitude: 0.32106

Collected Steps per Second: 22,059.30957
Overall Steps per Second: 10,605.40711

Timestep Collection Time: 2.26770
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71684

Cumulative Model Updates: 374,224
Cumulative Timesteps: 3,121,087,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.01284
Policy Entropy: 4.01012
Value Function Loss: 0.00627

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.24214
Value Function Update Magnitude: 0.31621

Collected Steps per Second: 22,356.87210
Overall Steps per Second: 10,542.88811

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.74348

Cumulative Model Updates: 374,230
Cumulative Timesteps: 3,121,137,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3121137658...
Checkpoint 3121137658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.00381
Policy Entropy: 4.03363
Value Function Loss: 0.00566

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.23645
Value Function Update Magnitude: 0.31285

Collected Steps per Second: 22,538.38175
Overall Steps per Second: 10,662.04893

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.69009

Cumulative Model Updates: 374,236
Cumulative Timesteps: 3,121,187,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.66274
Policy Entropy: 4.01822
Value Function Loss: 0.00715

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.25064
Value Function Update Magnitude: 0.31122

Collected Steps per Second: 22,448.29757
Overall Steps per Second: 10,539.79753

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.51809
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.74677

Cumulative Model Updates: 374,242
Cumulative Timesteps: 3,121,237,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3121237694...
Checkpoint 3121237694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.89864
Policy Entropy: 4.00201
Value Function Loss: 0.00672

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.25605
Value Function Update Magnitude: 0.30950

Collected Steps per Second: 21,974.53091
Overall Steps per Second: 10,524.65413

Timestep Collection Time: 2.27645
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.75303

Cumulative Model Updates: 374,248
Cumulative Timesteps: 3,121,287,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.69898
Policy Entropy: 4.00381
Value Function Loss: 0.00614

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.24020
Value Function Update Magnitude: 0.31178

Collected Steps per Second: 22,782.11518
Overall Steps per Second: 10,636.57573

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.70283

Cumulative Model Updates: 374,254
Cumulative Timesteps: 3,121,337,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3121337740...
Checkpoint 3121337740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.22336
Policy Entropy: 4.01136
Value Function Loss: 0.00538

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.23472
Value Function Update Magnitude: 0.31115

Collected Steps per Second: 21,909.28295
Overall Steps per Second: 10,591.91210

Timestep Collection Time: 2.28259
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.72153

Cumulative Model Updates: 374,260
Cumulative Timesteps: 3,121,387,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.82499
Policy Entropy: 4.00895
Value Function Loss: 0.00611

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.22935
Value Function Update Magnitude: 0.30280

Collected Steps per Second: 22,122.11629
Overall Steps per Second: 10,792.61406

Timestep Collection Time: 2.26154
Timestep Consumption Time: 2.37404
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63558

Cumulative Model Updates: 374,266
Cumulative Timesteps: 3,121,437,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3121437780...
Checkpoint 3121437780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.48930
Policy Entropy: 3.97548
Value Function Loss: 0.00650

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.23055
Value Function Update Magnitude: 0.31036

Collected Steps per Second: 22,077.57540
Overall Steps per Second: 10,633.13216

Timestep Collection Time: 2.26601
Timestep Consumption Time: 2.43891
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70492

Cumulative Model Updates: 374,272
Cumulative Timesteps: 3,121,487,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.48780
Policy Entropy: 3.96956
Value Function Loss: 0.00656

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.23564
Value Function Update Magnitude: 0.32488

Collected Steps per Second: 22,385.54377
Overall Steps per Second: 10,587.96306

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.72348

Cumulative Model Updates: 374,278
Cumulative Timesteps: 3,121,537,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3121537820...
Checkpoint 3121537820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.99082
Policy Entropy: 3.93292
Value Function Loss: 0.00693

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03107
Policy Update Magnitude: 0.24654
Value Function Update Magnitude: 0.33168

Collected Steps per Second: 21,709.28963
Overall Steps per Second: 10,624.50577

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.40477
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.70968

Cumulative Model Updates: 374,284
Cumulative Timesteps: 3,121,587,858

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.12931
Policy Entropy: 3.91401
Value Function Loss: 0.00723

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.26764
Value Function Update Magnitude: 0.34305

Collected Steps per Second: 22,050.61263
Overall Steps per Second: 10,439.30158

Timestep Collection Time: 2.26833
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.79132

Cumulative Model Updates: 374,290
Cumulative Timesteps: 3,121,637,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3121637876...
Checkpoint 3121637876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.83555
Policy Entropy: 3.90317
Value Function Loss: 0.00744

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 0.26210
Value Function Update Magnitude: 0.34887

Collected Steps per Second: 22,175.57348
Overall Steps per Second: 10,704.82669

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.67116

Cumulative Model Updates: 374,296
Cumulative Timesteps: 3,121,687,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97685
Policy Entropy: 3.94924
Value Function Loss: 0.00615

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.25579
Value Function Update Magnitude: 0.34273

Collected Steps per Second: 23,387.76421
Overall Steps per Second: 10,927.54364

Timestep Collection Time: 2.13890
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.57779

Cumulative Model Updates: 374,302
Cumulative Timesteps: 3,121,737,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3121737904...
Checkpoint 3121737904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.81703
Policy Entropy: 3.98374
Value Function Loss: 0.00578

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.24075
Value Function Update Magnitude: 0.32014

Collected Steps per Second: 21,980.32702
Overall Steps per Second: 10,635.69733

Timestep Collection Time: 2.27594
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.70359

Cumulative Model Updates: 374,308
Cumulative Timesteps: 3,121,787,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.74210
Policy Entropy: 3.99684
Value Function Loss: 0.00551

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.23639
Value Function Update Magnitude: 0.30625

Collected Steps per Second: 22,384.27032
Overall Steps per Second: 10,906.31970

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.35135
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.58560

Cumulative Model Updates: 374,314
Cumulative Timesteps: 3,121,837,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3121837942...
Checkpoint 3121837942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.52514
Policy Entropy: 3.99568
Value Function Loss: 0.00523

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.23083
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 22,338.88671
Overall Steps per Second: 10,589.34717

Timestep Collection Time: 2.23852
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.72229

Cumulative Model Updates: 374,320
Cumulative Timesteps: 3,121,887,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.59455
Policy Entropy: 3.98305
Value Function Loss: 0.00516

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.31021

Collected Steps per Second: 22,400.81175
Overall Steps per Second: 10,526.93246

Timestep Collection Time: 2.23242
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.75048

Cumulative Model Updates: 374,326
Cumulative Timesteps: 3,121,937,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3121937956...
Checkpoint 3121937956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.60659
Policy Entropy: 3.99104
Value Function Loss: 0.00531

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.23291
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 21,903.58969
Overall Steps per Second: 10,620.83078

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70867

Cumulative Model Updates: 374,332
Cumulative Timesteps: 3,121,987,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.46690
Policy Entropy: 3.96808
Value Function Loss: 0.00593

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.23614
Value Function Update Magnitude: 0.32645

Collected Steps per Second: 22,328.03284
Overall Steps per Second: 10,539.55435

Timestep Collection Time: 2.24050
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.74650

Cumulative Model Updates: 374,338
Cumulative Timesteps: 3,122,037,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3122037992...
Checkpoint 3122037992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.28130
Policy Entropy: 3.92661
Value Function Loss: 0.00653

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.24594
Value Function Update Magnitude: 0.34521

Collected Steps per Second: 22,167.32214
Overall Steps per Second: 10,494.03063

Timestep Collection Time: 2.25557
Timestep Consumption Time: 2.50904
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.76461

Cumulative Model Updates: 374,344
Cumulative Timesteps: 3,122,087,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36358
Policy Entropy: 3.89606
Value Function Loss: 0.00661

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03056
Policy Update Magnitude: 0.25730
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 22,415.73044
Overall Steps per Second: 10,858.77425

Timestep Collection Time: 2.23200
Timestep Consumption Time: 2.37551
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.60752

Cumulative Model Updates: 374,350
Cumulative Timesteps: 3,122,138,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3122138024...
Checkpoint 3122138024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.76339
Policy Entropy: 3.91888
Value Function Loss: 0.00661

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.24789
Value Function Update Magnitude: 0.34854

Collected Steps per Second: 22,059.96342
Overall Steps per Second: 10,617.97177

Timestep Collection Time: 2.26737
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71069

Cumulative Model Updates: 374,356
Cumulative Timesteps: 3,122,188,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.94904
Policy Entropy: 3.97021
Value Function Loss: 0.00610

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.24128
Value Function Update Magnitude: 0.33946

Collected Steps per Second: 22,280.53599
Overall Steps per Second: 10,526.39864

Timestep Collection Time: 2.24483
Timestep Consumption Time: 2.50665
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.75148

Cumulative Model Updates: 374,362
Cumulative Timesteps: 3,122,238,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3122238058...
Checkpoint 3122238058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32425
Policy Entropy: 4.00322
Value Function Loss: 0.00626

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.23142
Value Function Update Magnitude: 0.31993

Collected Steps per Second: 22,448.19644
Overall Steps per Second: 10,663.01183

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.69004

Cumulative Model Updates: 374,368
Cumulative Timesteps: 3,122,288,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.47219
Policy Entropy: 3.98775
Value Function Loss: 0.00691

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.22255
Value Function Update Magnitude: 0.31725

Collected Steps per Second: 22,436.58114
Overall Steps per Second: 10,543.61033

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.51491
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.74448

Cumulative Model Updates: 374,374
Cumulative Timesteps: 3,122,338,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3122338092...
Checkpoint 3122338092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.72300
Policy Entropy: 4.00162
Value Function Loss: 0.00606

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.22619
Value Function Update Magnitude: 0.32383

Collected Steps per Second: 21,984.01347
Overall Steps per Second: 10,591.41418

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.72137

Cumulative Model Updates: 374,380
Cumulative Timesteps: 3,122,388,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.52869
Policy Entropy: 3.97585
Value Function Loss: 0.00545

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.22648
Value Function Update Magnitude: 0.31587

Collected Steps per Second: 23,184.45107
Overall Steps per Second: 10,866.59332

Timestep Collection Time: 2.15688
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60181

Cumulative Model Updates: 374,386
Cumulative Timesteps: 3,122,438,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3122438104...
Checkpoint 3122438104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.72766
Policy Entropy: 3.98130
Value Function Loss: 0.00514

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.22743
Value Function Update Magnitude: 0.30812

Collected Steps per Second: 22,054.82300
Overall Steps per Second: 10,607.32841

Timestep Collection Time: 2.26771
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.71504

Cumulative Model Updates: 374,392
Cumulative Timesteps: 3,122,488,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.29939
Policy Entropy: 3.94955
Value Function Loss: 0.00601

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.23784
Value Function Update Magnitude: 0.31404

Collected Steps per Second: 22,195.46257
Overall Steps per Second: 10,737.46589

Timestep Collection Time: 2.25397
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.65920

Cumulative Model Updates: 374,398
Cumulative Timesteps: 3,122,538,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3122538146...
Checkpoint 3122538146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.97486
Policy Entropy: 3.96888
Value Function Loss: 0.00685

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.24791
Value Function Update Magnitude: 0.33587

Collected Steps per Second: 22,044.76018
Overall Steps per Second: 10,424.76704

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.79646

Cumulative Model Updates: 374,404
Cumulative Timesteps: 3,122,588,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.72869
Policy Entropy: 3.96155
Value Function Loss: 0.00687

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.25312
Value Function Update Magnitude: 0.34212

Collected Steps per Second: 22,382.14096
Overall Steps per Second: 10,535.98429

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.74792

Cumulative Model Updates: 374,410
Cumulative Timesteps: 3,122,638,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3122638172...
Checkpoint 3122638172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.12241
Policy Entropy: 3.97058
Value Function Loss: 0.00643

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.25376
Value Function Update Magnitude: 0.33607

Collected Steps per Second: 22,140.04234
Overall Steps per Second: 10,694.70636

Timestep Collection Time: 2.25862
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.67577

Cumulative Model Updates: 374,416
Cumulative Timesteps: 3,122,688,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.03427
Policy Entropy: 3.96358
Value Function Loss: 0.00683

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.25127
Value Function Update Magnitude: 0.34464

Collected Steps per Second: 22,605.93639
Overall Steps per Second: 10,710.80042

Timestep Collection Time: 2.21181
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.66819

Cumulative Model Updates: 374,422
Cumulative Timesteps: 3,122,738,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3122738178...
Checkpoint 3122738178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36826
Policy Entropy: 3.98290
Value Function Loss: 0.00630

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.24947
Value Function Update Magnitude: 0.34238

Collected Steps per Second: 21,906.45064
Overall Steps per Second: 10,618.23610

Timestep Collection Time: 2.28353
Timestep Consumption Time: 2.42761
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.71114

Cumulative Model Updates: 374,428
Cumulative Timesteps: 3,122,788,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49257
Policy Entropy: 3.98077
Value Function Loss: 0.00619

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.24175
Value Function Update Magnitude: 0.33633

Collected Steps per Second: 23,045.21107
Overall Steps per Second: 10,744.01764

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.48530
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.65599

Cumulative Model Updates: 374,434
Cumulative Timesteps: 3,122,838,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3122838226...
Checkpoint 3122838226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.22308
Policy Entropy: 3.94564
Value Function Loss: 0.00612

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.24516
Value Function Update Magnitude: 0.33528

Collected Steps per Second: 22,267.79427
Overall Steps per Second: 10,396.11946

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.56491
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.81103

Cumulative Model Updates: 374,440
Cumulative Timesteps: 3,122,888,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.60523
Policy Entropy: 3.94452
Value Function Loss: 0.00657

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.03360
Policy Update Magnitude: 0.25034
Value Function Update Magnitude: 0.34245

Collected Steps per Second: 22,533.43688
Overall Steps per Second: 10,591.31047

Timestep Collection Time: 2.21937
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.72180

Cumulative Model Updates: 374,446
Cumulative Timesteps: 3,122,938,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3122938252...
Checkpoint 3122938252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61012
Policy Entropy: 3.94682
Value Function Loss: 0.00672

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 0.24739
Value Function Update Magnitude: 0.34822

Collected Steps per Second: 22,506.36827
Overall Steps per Second: 10,524.47212

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.53045
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75311

Cumulative Model Updates: 374,452
Cumulative Timesteps: 3,122,988,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.08328
Policy Entropy: 4.01198
Value Function Loss: 0.00617

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.23112
Value Function Update Magnitude: 0.33136

Collected Steps per Second: 22,422.40838
Overall Steps per Second: 10,527.79926

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.74990

Cumulative Model Updates: 374,458
Cumulative Timesteps: 3,123,038,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3123038282...
Checkpoint 3123038282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.44827
Policy Entropy: 3.98582
Value Function Loss: 0.00608

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.23066
Value Function Update Magnitude: 0.32187

Collected Steps per Second: 22,170.07230
Overall Steps per Second: 10,715.01166

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.66635

Cumulative Model Updates: 374,464
Cumulative Timesteps: 3,123,088,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.22033
Policy Entropy: 4.01147
Value Function Loss: 0.00547

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.23984
Value Function Update Magnitude: 0.32394

Collected Steps per Second: 22,632.50966
Overall Steps per Second: 10,721.61620

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.45574
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.66627

Cumulative Model Updates: 374,470
Cumulative Timesteps: 3,123,138,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3123138312...
Checkpoint 3123138312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.38897
Policy Entropy: 3.98898
Value Function Loss: 0.00597

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.23805
Value Function Update Magnitude: 0.31730

Collected Steps per Second: 22,015.72739
Overall Steps per Second: 10,636.02213

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.70270

Cumulative Model Updates: 374,476
Cumulative Timesteps: 3,123,188,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.57347
Policy Entropy: 4.03783
Value Function Loss: 0.00553

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.23484
Value Function Update Magnitude: 0.30983

Collected Steps per Second: 22,171.20262
Overall Steps per Second: 10,654.74996

Timestep Collection Time: 2.25617
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69481

Cumulative Model Updates: 374,482
Cumulative Timesteps: 3,123,238,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3123238352...
Checkpoint 3123238352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.29078
Policy Entropy: 4.00892
Value Function Loss: 0.00657

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.23095
Value Function Update Magnitude: 0.30283

Collected Steps per Second: 22,120.74884
Overall Steps per Second: 10,492.98504

Timestep Collection Time: 2.26095
Timestep Consumption Time: 2.50547
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.76642

Cumulative Model Updates: 374,488
Cumulative Timesteps: 3,123,288,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.63951
Policy Entropy: 3.97509
Value Function Loss: 0.00666

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02111
Policy Update Magnitude: 0.23901
Value Function Update Magnitude: 0.30502

Collected Steps per Second: 22,225.33734
Overall Steps per Second: 10,532.04891

Timestep Collection Time: 2.25067
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74950

Cumulative Model Updates: 374,494
Cumulative Timesteps: 3,123,338,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3123338388...
Checkpoint 3123338388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.48941
Policy Entropy: 3.91344
Value Function Loss: 0.00752

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.24975
Value Function Update Magnitude: 0.33510

Collected Steps per Second: 22,060.15190
Overall Steps per Second: 10,638.48482

Timestep Collection Time: 2.26671
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70029

Cumulative Model Updates: 374,500
Cumulative Timesteps: 3,123,388,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.35989
Policy Entropy: 3.90922
Value Function Loss: 0.00705

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.26340
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 22,591.25151
Overall Steps per Second: 10,754.52249

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.65088

Cumulative Model Updates: 374,506
Cumulative Timesteps: 3,123,438,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3123438410...
Checkpoint 3123438410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.60848
Policy Entropy: 3.92460
Value Function Loss: 0.00698

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.26401
Value Function Update Magnitude: 0.35794

Collected Steps per Second: 21,996.81978
Overall Steps per Second: 10,662.79632

Timestep Collection Time: 2.27406
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.69126

Cumulative Model Updates: 374,512
Cumulative Timesteps: 3,123,488,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.10733
Policy Entropy: 3.93493
Value Function Loss: 0.00737

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.26209
Value Function Update Magnitude: 0.35563

Collected Steps per Second: 22,264.54950
Overall Steps per Second: 10,650.40118

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.44992
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.69654

Cumulative Model Updates: 374,518
Cumulative Timesteps: 3,123,538,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3123538452...
Checkpoint 3123538452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.55022
Policy Entropy: 3.91139
Value Function Loss: 0.00738

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.26970
Value Function Update Magnitude: 0.36119

Collected Steps per Second: 22,304.09105
Overall Steps per Second: 10,543.03588

Timestep Collection Time: 2.24353
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.74626

Cumulative Model Updates: 374,524
Cumulative Timesteps: 3,123,588,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.51530
Policy Entropy: 3.92650
Value Function Loss: 0.00753

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.26785
Value Function Update Magnitude: 0.36114

Collected Steps per Second: 22,362.55182
Overall Steps per Second: 10,613.15727

Timestep Collection Time: 2.23642
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.71226

Cumulative Model Updates: 374,530
Cumulative Timesteps: 3,123,638,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3123638504...
Checkpoint 3123638504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.39355
Policy Entropy: 3.98125
Value Function Loss: 0.00711

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.25172
Value Function Update Magnitude: 0.35927

Collected Steps per Second: 23,158.73562
Overall Steps per Second: 10,862.51415

Timestep Collection Time: 2.16014
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60538

Cumulative Model Updates: 374,536
Cumulative Timesteps: 3,123,688,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.51021
Policy Entropy: 4.03203
Value Function Loss: 0.00649

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.23595
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 22,445.26482
Overall Steps per Second: 10,528.02803

Timestep Collection Time: 2.22844
Timestep Consumption Time: 2.52249
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.75094

Cumulative Model Updates: 374,542
Cumulative Timesteps: 3,123,738,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3123738548...
Checkpoint 3123738548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.25846
Policy Entropy: 4.03622
Value Function Loss: 0.00567

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.22497
Value Function Update Magnitude: 0.34102

Collected Steps per Second: 20,319.34813
Overall Steps per Second: 10,140.90421

Timestep Collection Time: 2.46258
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.93427

Cumulative Model Updates: 374,548
Cumulative Timesteps: 3,123,788,586

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.93874
Policy Entropy: 4.00254
Value Function Loss: 0.00526

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.22824
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 22,542.96328
Overall Steps per Second: 10,507.99212

Timestep Collection Time: 2.21834
Timestep Consumption Time: 2.54070
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.75904

Cumulative Model Updates: 374,554
Cumulative Timesteps: 3,123,838,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3123838594...
Checkpoint 3123838594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01128
Policy Entropy: 3.98358
Value Function Loss: 0.00564

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.22891
Value Function Update Magnitude: 0.32134

Collected Steps per Second: 22,159.37120
Overall Steps per Second: 10,588.84290

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.72497

Cumulative Model Updates: 374,560
Cumulative Timesteps: 3,123,888,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.69472
Policy Entropy: 3.96969
Value Function Loss: 0.00652

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.24006
Value Function Update Magnitude: 0.32875

Collected Steps per Second: 22,381.78220
Overall Steps per Second: 10,746.45390

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.65326

Cumulative Model Updates: 374,566
Cumulative Timesteps: 3,123,938,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3123938632...
Checkpoint 3123938632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.07915
Policy Entropy: 4.01249
Value Function Loss: 0.00597

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.24771
Value Function Update Magnitude: 0.32160

Collected Steps per Second: 22,343.18053
Overall Steps per Second: 10,527.54979

Timestep Collection Time: 2.23871
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.75134

Cumulative Model Updates: 374,572
Cumulative Timesteps: 3,123,988,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.35156
Policy Entropy: 3.98073
Value Function Loss: 0.00607

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.23861
Value Function Update Magnitude: 0.31932

Collected Steps per Second: 22,591.31950
Overall Steps per Second: 10,766.18449

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64436

Cumulative Model Updates: 374,578
Cumulative Timesteps: 3,124,038,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3124038654...
Checkpoint 3124038654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.20332
Policy Entropy: 3.99957
Value Function Loss: 0.00563

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.23432
Value Function Update Magnitude: 0.30924

Collected Steps per Second: 23,011.50686
Overall Steps per Second: 10,658.52637

Timestep Collection Time: 2.17361
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.69277

Cumulative Model Updates: 374,584
Cumulative Timesteps: 3,124,088,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.66000
Policy Entropy: 3.97011
Value Function Loss: 0.00632

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.23908
Value Function Update Magnitude: 0.31207

Collected Steps per Second: 22,310.98418
Overall Steps per Second: 10,471.11606

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.77638

Cumulative Model Updates: 374,590
Cumulative Timesteps: 3,124,138,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3124138686...
Checkpoint 3124138686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.13825
Policy Entropy: 3.96439
Value Function Loss: 0.00759

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.24642
Value Function Update Magnitude: 0.33201

Collected Steps per Second: 21,563.68444
Overall Steps per Second: 10,543.70645

Timestep Collection Time: 2.31946
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.74368

Cumulative Model Updates: 374,596
Cumulative Timesteps: 3,124,188,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.39422
Policy Entropy: 3.94119
Value Function Loss: 0.00743

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.25070
Value Function Update Magnitude: 0.36107

Collected Steps per Second: 23,388.27187
Overall Steps per Second: 10,788.93819

Timestep Collection Time: 2.13902
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.63697

Cumulative Model Updates: 374,602
Cumulative Timesteps: 3,124,238,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3124238730...
Checkpoint 3124238730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.95878
Policy Entropy: 3.94234
Value Function Loss: 0.00803

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03424
Policy Update Magnitude: 0.25194
Value Function Update Magnitude: 0.36442

Collected Steps per Second: 22,127.06796
Overall Steps per Second: 10,429.80540

Timestep Collection Time: 2.25968
Timestep Consumption Time: 2.53428
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.79395

Cumulative Model Updates: 374,608
Cumulative Timesteps: 3,124,288,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.21185
Policy Entropy: 3.99555
Value Function Loss: 0.00631

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.24188
Value Function Update Magnitude: 0.33939

Collected Steps per Second: 22,253.89737
Overall Steps per Second: 10,843.99171

Timestep Collection Time: 2.24698
Timestep Consumption Time: 2.36424
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61122

Cumulative Model Updates: 374,614
Cumulative Timesteps: 3,124,338,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3124338734...
Checkpoint 3124338734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.17962
Policy Entropy: 4.03767
Value Function Loss: 0.00635

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.22395
Value Function Update Magnitude: 0.31938

Collected Steps per Second: 21,615.41413
Overall Steps per Second: 10,401.24394

Timestep Collection Time: 2.31455
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.81000

Cumulative Model Updates: 374,620
Cumulative Timesteps: 3,124,388,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.27466
Policy Entropy: 4.04171
Value Function Loss: 0.00550

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.21197
Value Function Update Magnitude: 0.30132

Collected Steps per Second: 22,336.95315
Overall Steps per Second: 10,709.17094

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.67058

Cumulative Model Updates: 374,626
Cumulative Timesteps: 3,124,438,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3124438782...
Checkpoint 3124438782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.12828
Policy Entropy: 4.04505
Value Function Loss: 0.00547

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.21734
Value Function Update Magnitude: 0.30026

Collected Steps per Second: 22,787.61746
Overall Steps per Second: 10,675.31074

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.68483

Cumulative Model Updates: 374,632
Cumulative Timesteps: 3,124,488,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02703
Policy Entropy: 4.04639
Value Function Loss: 0.00531

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.22023
Value Function Update Magnitude: 0.31017

Collected Steps per Second: 22,400.77244
Overall Steps per Second: 10,496.33982

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.76452

Cumulative Model Updates: 374,638
Cumulative Timesteps: 3,124,538,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3124538804...
Checkpoint 3124538804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.17747
Policy Entropy: 4.04362
Value Function Loss: 0.00530

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.22295
Value Function Update Magnitude: 0.31160

Collected Steps per Second: 21,781.10641
Overall Steps per Second: 10,624.39712

Timestep Collection Time: 2.29759
Timestep Consumption Time: 2.41270
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.71029

Cumulative Model Updates: 374,644
Cumulative Timesteps: 3,124,588,848

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.10199
Policy Entropy: 4.01239
Value Function Loss: 0.00610

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.22924
Value Function Update Magnitude: 0.31773

Collected Steps per Second: 23,022.18309
Overall Steps per Second: 10,666.54950

Timestep Collection Time: 2.17234
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68868

Cumulative Model Updates: 374,650
Cumulative Timesteps: 3,124,638,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3124638860...
Checkpoint 3124638860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.04346
Policy Entropy: 3.98627
Value Function Loss: 0.00657

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.24803
Value Function Update Magnitude: 0.32997

Collected Steps per Second: 21,977.65492
Overall Steps per Second: 10,436.82624

Timestep Collection Time: 2.27531
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.79130

Cumulative Model Updates: 374,656
Cumulative Timesteps: 3,124,688,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.31649
Policy Entropy: 3.97431
Value Function Loss: 0.00658

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.24110
Value Function Update Magnitude: 0.32423

Collected Steps per Second: 22,213.79295
Overall Steps per Second: 10,833.45402

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.36590
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61810

Cumulative Model Updates: 374,662
Cumulative Timesteps: 3,124,738,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3124738896...
Checkpoint 3124738896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.67711
Policy Entropy: 3.99064
Value Function Loss: 0.00581

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.23514
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 22,074.87985
Overall Steps per Second: 10,518.08430

Timestep Collection Time: 2.26620
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.75619

Cumulative Model Updates: 374,668
Cumulative Timesteps: 3,124,788,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.81904
Policy Entropy: 3.99290
Value Function Loss: 0.00576

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.23122
Value Function Update Magnitude: 0.31834

Collected Steps per Second: 22,285.59438
Overall Steps per Second: 10,668.45158

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.68878

Cumulative Model Updates: 374,674
Cumulative Timesteps: 3,124,838,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3124838944...
Checkpoint 3124838944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.11383
Policy Entropy: 3.99692
Value Function Loss: 0.00586

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.23245
Value Function Update Magnitude: 0.31326

Collected Steps per Second: 22,190.51909
Overall Steps per Second: 10,679.47874

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.68300

Cumulative Model Updates: 374,680
Cumulative Timesteps: 3,124,888,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.10868
Policy Entropy: 3.99160
Value Function Loss: 0.00708

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.24528
Value Function Update Magnitude: 0.32511

Collected Steps per Second: 22,461.45813
Overall Steps per Second: 10,531.62130

Timestep Collection Time: 2.22612
Timestep Consumption Time: 2.52167
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74780

Cumulative Model Updates: 374,686
Cumulative Timesteps: 3,124,938,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3124938958...
Checkpoint 3124938958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.38083
Policy Entropy: 4.01957
Value Function Loss: 0.00629

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.24551
Value Function Update Magnitude: 0.33434

Collected Steps per Second: 21,772.84377
Overall Steps per Second: 10,624.64868

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.70849

Cumulative Model Updates: 374,692
Cumulative Timesteps: 3,124,988,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.69053
Policy Entropy: 4.02864
Value Function Loss: 0.00533

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.23802
Value Function Update Magnitude: 0.32336

Collected Steps per Second: 23,045.09612
Overall Steps per Second: 10,824.04665

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.45106
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62193

Cumulative Model Updates: 374,698
Cumulative Timesteps: 3,125,039,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3125039012...
Checkpoint 3125039012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.74695
Policy Entropy: 4.02987
Value Function Loss: 0.00440

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.22035
Value Function Update Magnitude: 0.30709

Collected Steps per Second: 22,044.10028
Overall Steps per Second: 10,600.70566

Timestep Collection Time: 2.26827
Timestep Consumption Time: 2.44858
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.71686

Cumulative Model Updates: 374,704
Cumulative Timesteps: 3,125,089,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.97651
Policy Entropy: 3.99041
Value Function Loss: 0.00569

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.23009
Value Function Update Magnitude: 0.28961

Collected Steps per Second: 21,709.54815
Overall Steps per Second: 10,570.78655

Timestep Collection Time: 2.30433
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73248

Cumulative Model Updates: 374,710
Cumulative Timesteps: 3,125,139,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3125139040...
Checkpoint 3125139040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.98671
Policy Entropy: 3.97778
Value Function Loss: 0.00595

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.24829
Value Function Update Magnitude: 0.30966

Collected Steps per Second: 22,838.87249
Overall Steps per Second: 10,617.60792

Timestep Collection Time: 2.18934
Timestep Consumption Time: 2.52001
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.70935

Cumulative Model Updates: 374,716
Cumulative Timesteps: 3,125,189,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.97730
Policy Entropy: 3.95853
Value Function Loss: 0.00645

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.24565
Value Function Update Magnitude: 0.32637

Collected Steps per Second: 22,296.95446
Overall Steps per Second: 10,454.88051

Timestep Collection Time: 2.24362
Timestep Consumption Time: 2.54132
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.78494

Cumulative Model Updates: 374,722
Cumulative Timesteps: 3,125,239,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3125239068...
Checkpoint 3125239068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.02271
Policy Entropy: 3.98652
Value Function Loss: 0.00621

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.23436
Value Function Update Magnitude: 0.32806

Collected Steps per Second: 22,078.53247
Overall Steps per Second: 10,595.05653

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.45572
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.72145

Cumulative Model Updates: 374,728
Cumulative Timesteps: 3,125,289,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.23597
Policy Entropy: 3.98749
Value Function Loss: 0.00649

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.23777
Value Function Update Magnitude: 0.33496

Collected Steps per Second: 23,030.10257
Overall Steps per Second: 10,849.21158

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60937

Cumulative Model Updates: 374,734
Cumulative Timesteps: 3,125,339,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3125339100...
Checkpoint 3125339100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.40087
Policy Entropy: 4.00789
Value Function Loss: 0.00574

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.23829
Value Function Update Magnitude: 0.34610

Collected Steps per Second: 22,082.52351
Overall Steps per Second: 10,488.84612

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.76868

Cumulative Model Updates: 374,740
Cumulative Timesteps: 3,125,389,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69331
Policy Entropy: 4.02286
Value Function Loss: 0.00471

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.23496
Value Function Update Magnitude: 0.31635

Collected Steps per Second: 22,529.76294
Overall Steps per Second: 10,717.65638

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.66949

Cumulative Model Updates: 374,746
Cumulative Timesteps: 3,125,439,164

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 3125439164...
Checkpoint 3125439164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.72122
Policy Entropy: 4.04172
Value Function Loss: 0.00440

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.22291
Value Function Update Magnitude: 0.28293

Collected Steps per Second: 22,561.17619
Overall Steps per Second: 10,626.20070

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.70648

Cumulative Model Updates: 374,752
Cumulative Timesteps: 3,125,489,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.77946
Policy Entropy: 4.04936
Value Function Loss: 0.00466

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.21951
Value Function Update Magnitude: 0.27240

Collected Steps per Second: 22,365.60933
Overall Steps per Second: 10,485.01267

Timestep Collection Time: 2.23584
Timestep Consumption Time: 2.53344
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76928

Cumulative Model Updates: 374,758
Cumulative Timesteps: 3,125,539,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3125539182...
Checkpoint 3125539182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.86050
Policy Entropy: 4.03392
Value Function Loss: 0.00543

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.22274
Value Function Update Magnitude: 0.28346

Collected Steps per Second: 22,093.99707
Overall Steps per Second: 10,617.27748

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.71062

Cumulative Model Updates: 374,764
Cumulative Timesteps: 3,125,589,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.52582
Policy Entropy: 3.97418
Value Function Loss: 0.00707

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.24019
Value Function Update Magnitude: 0.31652

Collected Steps per Second: 21,897.83514
Overall Steps per Second: 10,443.38132

Timestep Collection Time: 2.28461
Timestep Consumption Time: 2.50579
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.79040

Cumulative Model Updates: 374,770
Cumulative Timesteps: 3,125,639,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3125639224...
Checkpoint 3125639224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.89584
Policy Entropy: 3.94344
Value Function Loss: 0.00657

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.25111
Value Function Update Magnitude: 0.35250

Collected Steps per Second: 22,105.89428
Overall Steps per Second: 10,708.94115

Timestep Collection Time: 2.26247
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.67030

Cumulative Model Updates: 374,776
Cumulative Timesteps: 3,125,689,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.96067
Policy Entropy: 3.91595
Value Function Loss: 0.00615

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.25314
Value Function Update Magnitude: 0.35456

Collected Steps per Second: 23,053.85220
Overall Steps per Second: 10,810.54697

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62604

Cumulative Model Updates: 374,782
Cumulative Timesteps: 3,125,739,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3125739248...
Checkpoint 3125739248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.70797
Policy Entropy: 3.96326
Value Function Loss: 0.00548

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.24783
Value Function Update Magnitude: 0.34120

Collected Steps per Second: 21,839.54575
Overall Steps per Second: 10,449.46946

Timestep Collection Time: 2.29025
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.78665

Cumulative Model Updates: 374,788
Cumulative Timesteps: 3,125,789,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.73397
Policy Entropy: 3.96042
Value Function Loss: 0.00647

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.24282
Value Function Update Magnitude: 0.33612

Collected Steps per Second: 22,470.09433
Overall Steps per Second: 10,691.94482

Timestep Collection Time: 2.22518
Timestep Consumption Time: 2.45124
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.67642

Cumulative Model Updates: 374,794
Cumulative Timesteps: 3,125,839,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3125839266...
Checkpoint 3125839266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.06165
Policy Entropy: 3.94107
Value Function Loss: 0.00721

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.25261
Value Function Update Magnitude: 0.34402

Collected Steps per Second: 22,273.50940
Overall Steps per Second: 10,626.41208

Timestep Collection Time: 2.24644
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.70864

Cumulative Model Updates: 374,800
Cumulative Timesteps: 3,125,889,302

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.65246
Policy Entropy: 3.95369
Value Function Loss: 0.00715

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.25975
Value Function Update Magnitude: 0.35569

Collected Steps per Second: 22,189.30745
Overall Steps per Second: 10,511.69442

Timestep Collection Time: 2.25478
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.75965

Cumulative Model Updates: 374,806
Cumulative Timesteps: 3,125,939,334

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3125939334...
Checkpoint 3125939334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.46650
Policy Entropy: 3.95872
Value Function Loss: 0.00678

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.26574
Value Function Update Magnitude: 0.36045

Collected Steps per Second: 22,221.63108
Overall Steps per Second: 10,645.82690

Timestep Collection Time: 2.25177
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.70025

Cumulative Model Updates: 374,812
Cumulative Timesteps: 3,125,989,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.42590
Policy Entropy: 3.97770
Value Function Loss: 0.00625

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.24833
Value Function Update Magnitude: 0.35492

Collected Steps per Second: 22,348.54592
Overall Steps per Second: 10,447.02308

Timestep Collection Time: 2.23853
Timestep Consumption Time: 2.55020
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.78873

Cumulative Model Updates: 374,818
Cumulative Timesteps: 3,126,039,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3126039400...
Checkpoint 3126039400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.03721
Policy Entropy: 3.96094
Value Function Loss: 0.00547

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.24564
Value Function Update Magnitude: 0.33710

Collected Steps per Second: 21,844.29865
Overall Steps per Second: 10,612.05835

Timestep Collection Time: 2.28993
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.71369

Cumulative Model Updates: 374,824
Cumulative Timesteps: 3,126,089,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.04547
Policy Entropy: 3.98788
Value Function Loss: 0.00592

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.23767
Value Function Update Magnitude: 0.32146

Collected Steps per Second: 22,792.44910
Overall Steps per Second: 10,725.68287

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.46908
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.66376

Cumulative Model Updates: 374,830
Cumulative Timesteps: 3,126,139,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3126139444...
Checkpoint 3126139444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.07103
Policy Entropy: 3.94499
Value Function Loss: 0.00667

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.24351
Value Function Update Magnitude: 0.33222

Collected Steps per Second: 22,166.70893
Overall Steps per Second: 10,374.29711

Timestep Collection Time: 2.25636
Timestep Consumption Time: 2.56479
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.82115

Cumulative Model Updates: 374,836
Cumulative Timesteps: 3,126,189,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.81288
Policy Entropy: 3.93300
Value Function Loss: 0.00778

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.25618
Value Function Update Magnitude: 0.35764

Collected Steps per Second: 22,362.40268
Overall Steps per Second: 10,065.61128

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.73151
PPO Batch Consumption Time: 0.31726
Total Iteration Time: 4.96741

Cumulative Model Updates: 374,842
Cumulative Timesteps: 3,126,239,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3126239460...
Checkpoint 3126239460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.27253
Policy Entropy: 3.95177
Value Function Loss: 0.00671

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.25124
Value Function Update Magnitude: 0.36262

Collected Steps per Second: 16,281.17986
Overall Steps per Second: 8,368.12454

Timestep Collection Time: 3.07250
Timestep Consumption Time: 2.90542
PPO Batch Consumption Time: 0.33309
Total Iteration Time: 5.97792

Cumulative Model Updates: 374,848
Cumulative Timesteps: 3,126,289,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.09577
Policy Entropy: 4.06962
Value Function Loss: 0.00535

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.23085
Value Function Update Magnitude: 0.33288

Collected Steps per Second: 21,719.05688
Overall Steps per Second: 10,244.61051

Timestep Collection Time: 2.30240
Timestep Consumption Time: 2.57880
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.88120

Cumulative Model Updates: 374,854
Cumulative Timesteps: 3,126,339,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3126339490...
Checkpoint 3126339490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.51651
Policy Entropy: 4.08848
Value Function Loss: 0.00484

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01808
Policy Update Magnitude: 0.20926
Value Function Update Magnitude: 0.30125

Collected Steps per Second: 21,045.68158
Overall Steps per Second: 10,220.68638

Timestep Collection Time: 2.37607
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.89263

Cumulative Model Updates: 374,860
Cumulative Timesteps: 3,126,389,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.30586
Policy Entropy: 4.06139
Value Function Loss: 0.00581

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.21142
Value Function Update Magnitude: 0.29859

Collected Steps per Second: 22,266.12201
Overall Steps per Second: 10,442.40394

Timestep Collection Time: 2.24592
Timestep Consumption Time: 2.54301
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.78894

Cumulative Model Updates: 374,866
Cumulative Timesteps: 3,126,439,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3126439504...
Checkpoint 3126439504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.83776
Policy Entropy: 4.03575
Value Function Loss: 0.00605

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.22322
Value Function Update Magnitude: 0.31027

Collected Steps per Second: 21,045.99877
Overall Steps per Second: 10,192.63302

Timestep Collection Time: 2.37575
Timestep Consumption Time: 2.52976
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.90550

Cumulative Model Updates: 374,872
Cumulative Timesteps: 3,126,489,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.12721
Policy Entropy: 4.02246
Value Function Loss: 0.00631

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.22122
Value Function Update Magnitude: 0.32469

Collected Steps per Second: 21,265.69039
Overall Steps per Second: 10,217.58287

Timestep Collection Time: 2.35196
Timestep Consumption Time: 2.54313
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.89509

Cumulative Model Updates: 374,878
Cumulative Timesteps: 3,126,539,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3126539520...
Checkpoint 3126539520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.11024
Policy Entropy: 4.00712
Value Function Loss: 0.00638

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.23756
Value Function Update Magnitude: 0.33501

Collected Steps per Second: 22,183.59438
Overall Steps per Second: 10,343.57962

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.58186
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.83740

Cumulative Model Updates: 374,884
Cumulative Timesteps: 3,126,589,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.85386
Policy Entropy: 3.98242
Value Function Loss: 0.00628

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.24727
Value Function Update Magnitude: 0.33858

Collected Steps per Second: 21,639.24274
Overall Steps per Second: 10,237.19366

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.57395
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.88493

Cumulative Model Updates: 374,890
Cumulative Timesteps: 3,126,639,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3126639564...
Checkpoint 3126639564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.10496
Policy Entropy: 4.00611
Value Function Loss: 0.00616

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.24073
Value Function Update Magnitude: 0.33806

Collected Steps per Second: 21,455.50741
Overall Steps per Second: 10,477.57738

Timestep Collection Time: 2.33106
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.77343

Cumulative Model Updates: 374,896
Cumulative Timesteps: 3,126,689,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.11999
Policy Entropy: 4.01050
Value Function Loss: 0.00565

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 0.22822
Value Function Update Magnitude: 0.33007

Collected Steps per Second: 21,636.55919
Overall Steps per Second: 10,284.44642

Timestep Collection Time: 2.31146
Timestep Consumption Time: 2.55142
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.86288

Cumulative Model Updates: 374,902
Cumulative Timesteps: 3,126,739,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3126739590...
Checkpoint 3126739590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.63369
Policy Entropy: 3.96791
Value Function Loss: 0.00722

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.23136
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 21,192.77815
Overall Steps per Second: 10,343.55250

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.47592
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.83644

Cumulative Model Updates: 374,908
Cumulative Timesteps: 3,126,789,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.44541
Policy Entropy: 3.92502
Value Function Loss: 0.00748

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.24115
Value Function Update Magnitude: 0.33431

Collected Steps per Second: 22,616.14786
Overall Steps per Second: 10,598.48691

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.50765
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.71916

Cumulative Model Updates: 374,914
Cumulative Timesteps: 3,126,839,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3126839632...
Checkpoint 3126839632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.35919
Policy Entropy: 3.88929
Value Function Loss: 0.00771

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02873
Policy Update Magnitude: 0.24582
Value Function Update Magnitude: 0.32507

Collected Steps per Second: 21,189.45041
Overall Steps per Second: 10,195.48375

Timestep Collection Time: 2.36099
Timestep Consumption Time: 2.54589
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.90688

Cumulative Model Updates: 374,920
Cumulative Timesteps: 3,126,889,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.81111
Policy Entropy: 3.93339
Value Function Loss: 0.00616

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.24453
Value Function Update Magnitude: 0.31932

Collected Steps per Second: 21,455.35048
Overall Steps per Second: 10,383.06709

Timestep Collection Time: 2.33135
Timestep Consumption Time: 2.48611
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.81746

Cumulative Model Updates: 374,926
Cumulative Timesteps: 3,126,939,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3126939680...
Checkpoint 3126939680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.87727
Policy Entropy: 3.95064
Value Function Loss: 0.00547

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.23598
Value Function Update Magnitude: 0.31996

Collected Steps per Second: 22,159.95478
Overall Steps per Second: 10,315.93000

Timestep Collection Time: 2.25650
Timestep Consumption Time: 2.59076
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.84726

Cumulative Model Updates: 374,932
Cumulative Timesteps: 3,126,989,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.93400
Policy Entropy: 3.98606
Value Function Loss: 0.00506

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.31125

Collected Steps per Second: 21,751.22445
Overall Steps per Second: 10,360.15014

Timestep Collection Time: 2.29992
Timestep Consumption Time: 2.52878
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.82869

Cumulative Model Updates: 374,938
Cumulative Timesteps: 3,127,039,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3127039710...
Checkpoint 3127039710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.97747
Policy Entropy: 3.99650
Value Function Loss: 0.00524

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.23099
Value Function Update Magnitude: 0.30110

Collected Steps per Second: 21,451.46542
Overall Steps per Second: 10,416.28935

Timestep Collection Time: 2.33252
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.80363

Cumulative Model Updates: 374,944
Cumulative Timesteps: 3,127,089,746

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.31702
Policy Entropy: 3.98519
Value Function Loss: 0.00681

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.23283
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 21,727.18387
Overall Steps per Second: 10,348.16925

Timestep Collection Time: 2.30265
Timestep Consumption Time: 2.53203
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.83467

Cumulative Model Updates: 374,950
Cumulative Timesteps: 3,127,139,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3127139776...
Checkpoint 3127139776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.59533
Policy Entropy: 3.97607
Value Function Loss: 0.00714

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.24179
Value Function Update Magnitude: 0.32884

Collected Steps per Second: 21,468.06971
Overall Steps per Second: 10,259.42383

Timestep Collection Time: 2.33007
Timestep Consumption Time: 2.54565
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.87571

Cumulative Model Updates: 374,956
Cumulative Timesteps: 3,127,189,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16639
Policy Entropy: 3.97072
Value Function Loss: 0.00696

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.24547
Value Function Update Magnitude: 0.33567

Collected Steps per Second: 21,416.04763
Overall Steps per Second: 10,301.17351

Timestep Collection Time: 2.33573
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.85595

Cumulative Model Updates: 374,962
Cumulative Timesteps: 3,127,239,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3127239820...
Checkpoint 3127239820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.64410
Policy Entropy: 4.00314
Value Function Loss: 0.00591

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.23999
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 20,952.89652
Overall Steps per Second: 10,134.00587

Timestep Collection Time: 2.38774
Timestep Consumption Time: 2.54911
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.93684

Cumulative Model Updates: 374,968
Cumulative Timesteps: 3,127,289,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.81500
Policy Entropy: 4.02134
Value Function Loss: 0.00627

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.23450
Value Function Update Magnitude: 0.33754

Collected Steps per Second: 21,587.04812
Overall Steps per Second: 10,328.68823

Timestep Collection Time: 2.31704
Timestep Consumption Time: 2.52559
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.84263

Cumulative Model Updates: 374,974
Cumulative Timesteps: 3,127,339,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3127339868...
Checkpoint 3127339868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02339
Policy Entropy: 4.03432
Value Function Loss: 0.00636

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.23269
Value Function Update Magnitude: 0.33243

Collected Steps per Second: 22,212.11724
Overall Steps per Second: 10,500.30984

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.51124
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.76272

Cumulative Model Updates: 374,980
Cumulative Timesteps: 3,127,389,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.04472
Policy Entropy: 4.03281
Value Function Loss: 0.00636

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.23179
Value Function Update Magnitude: 0.33487

Collected Steps per Second: 21,802.72475
Overall Steps per Second: 10,391.47821

Timestep Collection Time: 2.29403
Timestep Consumption Time: 2.51915
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.81317

Cumulative Model Updates: 374,986
Cumulative Timesteps: 3,127,439,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3127439894...
Checkpoint 3127439894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.56068
Policy Entropy: 4.00825
Value Function Loss: 0.00581

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.23176
Value Function Update Magnitude: 0.33684

Collected Steps per Second: 19,920.63846
Overall Steps per Second: 10,150.55211

Timestep Collection Time: 2.51076
Timestep Consumption Time: 2.41665
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.92742

Cumulative Model Updates: 374,992
Cumulative Timesteps: 3,127,489,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.48148
Policy Entropy: 4.02340
Value Function Loss: 0.00520

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.22953
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,824.52087
Overall Steps per Second: 10,319.70767

Timestep Collection Time: 2.29137
Timestep Consumption Time: 2.55451
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.84587

Cumulative Model Updates: 374,998
Cumulative Timesteps: 3,127,539,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3127539918...
Checkpoint 3127539918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.01440
Policy Entropy: 3.99358
Value Function Loss: 0.00603

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.25435
Value Function Update Magnitude: 0.33513

Collected Steps per Second: 17,122.23659
Overall Steps per Second: 8,567.16841

Timestep Collection Time: 2.92100
Timestep Consumption Time: 2.91687
PPO Batch Consumption Time: 0.35167
Total Iteration Time: 5.83787

Cumulative Model Updates: 375,004
Cumulative Timesteps: 3,127,589,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.98798
Policy Entropy: 4.01521
Value Function Loss: 0.00622

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.25832
Value Function Update Magnitude: 0.33802

Collected Steps per Second: 18,918.55354
Overall Steps per Second: 8,989.00735

Timestep Collection Time: 2.64365
Timestep Consumption Time: 2.92026
PPO Batch Consumption Time: 0.35515
Total Iteration Time: 5.56391

Cumulative Model Updates: 375,010
Cumulative Timesteps: 3,127,639,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3127639946...
Checkpoint 3127639946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.81887
Policy Entropy: 3.95721
Value Function Loss: 0.00662

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.25666
Value Function Update Magnitude: 0.34221

Collected Steps per Second: 17,903.73105
Overall Steps per Second: 9,095.44071

Timestep Collection Time: 2.79428
Timestep Consumption Time: 2.70606
PPO Batch Consumption Time: 0.31102
Total Iteration Time: 5.50034

Cumulative Model Updates: 375,016
Cumulative Timesteps: 3,127,689,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.35914
Policy Entropy: 3.97377
Value Function Loss: 0.00673

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.25300
Value Function Update Magnitude: 0.33606

Collected Steps per Second: 17,491.09203
Overall Steps per Second: 9,271.54171

Timestep Collection Time: 2.85974
Timestep Consumption Time: 2.53526
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 5.39500

Cumulative Model Updates: 375,022
Cumulative Timesteps: 3,127,739,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3127739994...
Checkpoint 3127739994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.99692
Policy Entropy: 3.97091
Value Function Loss: 0.00635

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.03758
Policy Update Magnitude: 0.25199
Value Function Update Magnitude: 0.33534

Collected Steps per Second: 22,083.30934
Overall Steps per Second: 10,049.55815

Timestep Collection Time: 2.26470
Timestep Consumption Time: 2.71184
PPO Batch Consumption Time: 0.32390
Total Iteration Time: 4.97654

Cumulative Model Updates: 375,028
Cumulative Timesteps: 3,127,790,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.75358
Policy Entropy: 4.00047
Value Function Loss: 0.00638

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.25081
Value Function Update Magnitude: 0.33020

Collected Steps per Second: 19,962.55165
Overall Steps per Second: 9,762.68937

Timestep Collection Time: 2.50489
Timestep Consumption Time: 2.61706
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 5.12195

Cumulative Model Updates: 375,034
Cumulative Timesteps: 3,127,840,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3127840010...
Checkpoint 3127840010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.69049
Policy Entropy: 3.97052
Value Function Loss: 0.00735

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.25635
Value Function Update Magnitude: 0.32916

Collected Steps per Second: 21,801.80267
Overall Steps per Second: 10,515.74112

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.75725

Cumulative Model Updates: 375,040
Cumulative Timesteps: 3,127,890,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.03106
Policy Entropy: 3.95808
Value Function Loss: 0.00779

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 0.26231
Value Function Update Magnitude: 0.35212

Collected Steps per Second: 23,028.25038
Overall Steps per Second: 10,700.64121

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.67318

Cumulative Model Updates: 375,046
Cumulative Timesteps: 3,127,940,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3127940042...
Checkpoint 3127940042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.02204
Policy Entropy: 3.91666
Value Function Loss: 0.00763

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.26489
Value Function Update Magnitude: 0.36508

Collected Steps per Second: 22,493.08134
Overall Steps per Second: 10,664.97335

Timestep Collection Time: 2.22424
Timestep Consumption Time: 2.46682
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.69106

Cumulative Model Updates: 375,052
Cumulative Timesteps: 3,127,990,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.66787
Policy Entropy: 3.91264
Value Function Loss: 0.00749

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.25723
Value Function Update Magnitude: 0.35685

Collected Steps per Second: 22,234.84265
Overall Steps per Second: 10,499.02994

Timestep Collection Time: 2.24926
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.76349

Cumulative Model Updates: 375,058
Cumulative Timesteps: 3,128,040,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3128040084...
Checkpoint 3128040084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.28245
Policy Entropy: 3.92810
Value Function Loss: 0.00736

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.25546
Value Function Update Magnitude: 0.35144

Collected Steps per Second: 23,271.57802
Overall Steps per Second: 10,927.14334

Timestep Collection Time: 2.14957
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.57796

Cumulative Model Updates: 375,064
Cumulative Timesteps: 3,128,090,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86168
Policy Entropy: 3.94718
Value Function Loss: 0.00653

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.25172
Value Function Update Magnitude: 0.35162

Collected Steps per Second: 22,625.60131
Overall Steps per Second: 10,625.49101

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.49618
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.70642

Cumulative Model Updates: 375,070
Cumulative Timesteps: 3,128,140,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3128140116...
Checkpoint 3128140116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.11786
Policy Entropy: 3.97989
Value Function Loss: 0.00597

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.24810
Value Function Update Magnitude: 0.34151

Collected Steps per Second: 22,560.23775
Overall Steps per Second: 10,664.72188

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68835

Cumulative Model Updates: 375,076
Cumulative Timesteps: 3,128,190,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.78429
Policy Entropy: 3.93020
Value Function Loss: 0.00654

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.24226
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 23,030.87069
Overall Steps per Second: 10,832.05164

Timestep Collection Time: 2.17117
Timestep Consumption Time: 2.44513
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.61630

Cumulative Model Updates: 375,082
Cumulative Timesteps: 3,128,240,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3128240120...
Checkpoint 3128240120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09539
Policy Entropy: 3.93502
Value Function Loss: 0.00667

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.25127
Value Function Update Magnitude: 0.34069

Collected Steps per Second: 22,621.79594
Overall Steps per Second: 10,621.88787

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.70801

Cumulative Model Updates: 375,088
Cumulative Timesteps: 3,128,290,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.74039
Policy Entropy: 3.90743
Value Function Loss: 0.00685

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.24584
Value Function Update Magnitude: 0.34030

Collected Steps per Second: 22,782.30156
Overall Steps per Second: 10,878.89314

Timestep Collection Time: 2.19592
Timestep Consumption Time: 2.40271
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.59863

Cumulative Model Updates: 375,094
Cumulative Timesteps: 3,128,340,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3128340156...
Checkpoint 3128340156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.36923
Policy Entropy: 3.93801
Value Function Loss: 0.00571

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.23968
Value Function Update Magnitude: 0.33206

Collected Steps per Second: 23,275.48494
Overall Steps per Second: 10,750.14027

Timestep Collection Time: 2.14896
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.65278

Cumulative Model Updates: 375,100
Cumulative Timesteps: 3,128,390,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.93033
Policy Entropy: 3.93513
Value Function Loss: 0.00593

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.23977
Value Function Update Magnitude: 0.32832

Collected Steps per Second: 22,236.84899
Overall Steps per Second: 10,511.81045

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.50874
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.75789

Cumulative Model Updates: 375,106
Cumulative Timesteps: 3,128,440,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3128440188...
Checkpoint 3128440188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.43372
Policy Entropy: 3.90696
Value Function Loss: 0.00635

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.24870
Value Function Update Magnitude: 0.33774

Collected Steps per Second: 22,224.14208
Overall Steps per Second: 10,497.54496

Timestep Collection Time: 2.25017
Timestep Consumption Time: 2.51361
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.76378

Cumulative Model Updates: 375,112
Cumulative Timesteps: 3,128,490,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.25256
Policy Entropy: 3.89774
Value Function Loss: 0.00638

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.26199
Value Function Update Magnitude: 0.36563

Collected Steps per Second: 23,062.40692
Overall Steps per Second: 10,683.40925

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.68165

Cumulative Model Updates: 375,118
Cumulative Timesteps: 3,128,540,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3128540212...
Checkpoint 3128540212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.82251
Policy Entropy: 3.85371
Value Function Loss: 0.00770

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.03625
Policy Update Magnitude: 0.26477
Value Function Update Magnitude: 0.37288

Collected Steps per Second: 22,583.37240
Overall Steps per Second: 10,788.32610

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.63705

Cumulative Model Updates: 375,124
Cumulative Timesteps: 3,128,590,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.80217
Policy Entropy: 3.91454
Value Function Loss: 0.00714

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 0.25725
Value Function Update Magnitude: 0.37175

Collected Steps per Second: 22,157.90577
Overall Steps per Second: 10,543.27075

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.74502

Cumulative Model Updates: 375,130
Cumulative Timesteps: 3,128,640,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3128640266...
Checkpoint 3128640266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.94812
Policy Entropy: 3.92378
Value Function Loss: 0.00702

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.25733
Value Function Update Magnitude: 0.36533

Collected Steps per Second: 22,264.15227
Overall Steps per Second: 10,608.18042

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.71410

Cumulative Model Updates: 375,136
Cumulative Timesteps: 3,128,690,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.19177
Policy Entropy: 3.97544
Value Function Loss: 0.00607

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.24854
Value Function Update Magnitude: 0.35042

Collected Steps per Second: 22,750.80260
Overall Steps per Second: 10,693.55149

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.67646

Cumulative Model Updates: 375,142
Cumulative Timesteps: 3,128,740,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3128740282...
Checkpoint 3128740282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.01317
Policy Entropy: 3.96192
Value Function Loss: 0.00603

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.24996
Value Function Update Magnitude: 0.35081

Collected Steps per Second: 22,749.22604
Overall Steps per Second: 10,895.10960

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.39153
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.58958

Cumulative Model Updates: 375,148
Cumulative Timesteps: 3,128,790,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.32138
Policy Entropy: 3.93930
Value Function Loss: 0.00668

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.24945
Value Function Update Magnitude: 0.34612

Collected Steps per Second: 22,608.66154
Overall Steps per Second: 10,645.16655

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.69941

Cumulative Model Updates: 375,154
Cumulative Timesteps: 3,128,840,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3128840312...
Checkpoint 3128840312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.40248
Policy Entropy: 3.90494
Value Function Loss: 0.00712

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.24883
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 22,804.14079
Overall Steps per Second: 10,849.60840

Timestep Collection Time: 2.19381
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61104

Cumulative Model Updates: 375,160
Cumulative Timesteps: 3,128,890,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.14174
Policy Entropy: 3.88304
Value Function Loss: 0.00778

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.25318
Value Function Update Magnitude: 0.34005

Collected Steps per Second: 22,529.69041
Overall Steps per Second: 10,954.90416

Timestep Collection Time: 2.21929
Timestep Consumption Time: 2.34487
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.56417

Cumulative Model Updates: 375,166
Cumulative Timesteps: 3,128,940,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3128940340...
Checkpoint 3128940340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.22664
Policy Entropy: 3.88017
Value Function Loss: 0.00808

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02949
Policy Update Magnitude: 0.25683
Value Function Update Magnitude: 0.34112

Collected Steps per Second: 22,190.92395
Overall Steps per Second: 10,701.94403

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.27610
Total Iteration Time: 4.67261

Cumulative Model Updates: 375,172
Cumulative Timesteps: 3,128,990,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.07859
Policy Entropy: 3.86005
Value Function Loss: 0.00778

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.26119
Value Function Update Magnitude: 0.35226

Collected Steps per Second: 22,555.44576
Overall Steps per Second: 10,760.34337

Timestep Collection Time: 2.21694
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.64706

Cumulative Model Updates: 375,178
Cumulative Timesteps: 3,129,040,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3129040350...
Checkpoint 3129040350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.45656
Policy Entropy: 3.88195
Value Function Loss: 0.00716

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.26599
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 22,378.28029
Overall Steps per Second: 10,702.19913

Timestep Collection Time: 2.23467
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.67268

Cumulative Model Updates: 375,184
Cumulative Timesteps: 3,129,090,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.00891
Policy Entropy: 3.92512
Value Function Loss: 0.00638

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 0.25654
Value Function Update Magnitude: 0.33030

Collected Steps per Second: 22,769.37704
Overall Steps per Second: 10,675.85045

Timestep Collection Time: 2.19655
Timestep Consumption Time: 2.48823
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.68478

Cumulative Model Updates: 375,190
Cumulative Timesteps: 3,129,140,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3129140372...
Checkpoint 3129140372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.39819
Policy Entropy: 3.99700
Value Function Loss: 0.00554

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.24014
Value Function Update Magnitude: 0.32028

Collected Steps per Second: 21,461.60829
Overall Steps per Second: 10,465.57477

Timestep Collection Time: 2.33086
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.77986

Cumulative Model Updates: 375,196
Cumulative Timesteps: 3,129,190,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.64284
Policy Entropy: 4.00638
Value Function Loss: 0.00565

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.22144
Value Function Update Magnitude: 0.31022

Collected Steps per Second: 23,029.22182
Overall Steps per Second: 10,860.41712

Timestep Collection Time: 2.17142
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60443

Cumulative Model Updates: 375,202
Cumulative Timesteps: 3,129,240,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3129240402...
Checkpoint 3129240402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.30223
Policy Entropy: 4.00306
Value Function Loss: 0.00583

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.21998
Value Function Update Magnitude: 0.31044

Collected Steps per Second: 22,306.37656
Overall Steps per Second: 10,745.47155

Timestep Collection Time: 2.24178
Timestep Consumption Time: 2.41190
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.65368

Cumulative Model Updates: 375,208
Cumulative Timesteps: 3,129,290,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.66112
Policy Entropy: 3.96173
Value Function Loss: 0.00575

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.23200
Value Function Update Magnitude: 0.32509

Collected Steps per Second: 22,009.54727
Overall Steps per Second: 10,506.47097

Timestep Collection Time: 2.27238
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.76030

Cumulative Model Updates: 375,214
Cumulative Timesteps: 3,129,340,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3129340422...
Checkpoint 3129340422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.55747
Policy Entropy: 3.94414
Value Function Loss: 0.00577

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.25555
Value Function Update Magnitude: 0.33203

Collected Steps per Second: 23,236.46518
Overall Steps per Second: 10,801.75194

Timestep Collection Time: 2.15265
Timestep Consumption Time: 2.47808
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.63073

Cumulative Model Updates: 375,220
Cumulative Timesteps: 3,129,390,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.93251
Policy Entropy: 3.94187
Value Function Loss: 0.00603

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.26348
Value Function Update Magnitude: 0.34039

Collected Steps per Second: 22,568.74288
Overall Steps per Second: 10,786.79612

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.63752

Cumulative Model Updates: 375,226
Cumulative Timesteps: 3,129,440,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3129440466...
Checkpoint 3129440466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.77851
Policy Entropy: 3.98313
Value Function Loss: 0.00519

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.25455
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 22,525.14171
Overall Steps per Second: 10,951.24644

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.34651
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.56679

Cumulative Model Updates: 375,232
Cumulative Timesteps: 3,129,490,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.34969
Policy Entropy: 4.01063
Value Function Loss: 0.00536

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.24480
Value Function Update Magnitude: 0.32827

Collected Steps per Second: 22,890.26438
Overall Steps per Second: 10,716.82425

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66593

Cumulative Model Updates: 375,238
Cumulative Timesteps: 3,129,540,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3129540482...
Checkpoint 3129540482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.21236
Policy Entropy: 3.97183
Value Function Loss: 0.00548

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.24201
Value Function Update Magnitude: 0.32851

Collected Steps per Second: 22,535.60464
Overall Steps per Second: 10,861.08641

Timestep Collection Time: 2.21987
Timestep Consumption Time: 2.38612
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.60598

Cumulative Model Updates: 375,244
Cumulative Timesteps: 3,129,590,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.72832
Policy Entropy: 3.90103
Value Function Loss: 0.00682

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.24700
Value Function Update Magnitude: 0.35117

Collected Steps per Second: 22,700.57011
Overall Steps per Second: 10,945.97479

Timestep Collection Time: 2.20373
Timestep Consumption Time: 2.36653
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.57026

Cumulative Model Updates: 375,250
Cumulative Timesteps: 3,129,640,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3129640534...
Checkpoint 3129640534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.08202
Policy Entropy: 3.91044
Value Function Loss: 0.00696

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03176
Policy Update Magnitude: 0.25339
Value Function Update Magnitude: 0.36054

Collected Steps per Second: 22,733.82854
Overall Steps per Second: 10,670.84121

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.68848

Cumulative Model Updates: 375,256
Cumulative Timesteps: 3,129,690,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.21137
Policy Entropy: 3.96113
Value Function Loss: 0.00600

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 0.24446
Value Function Update Magnitude: 0.35463

Collected Steps per Second: 22,971.38355
Overall Steps per Second: 10,915.34471

Timestep Collection Time: 2.17732
Timestep Consumption Time: 2.40486
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.58217

Cumulative Model Updates: 375,262
Cumulative Timesteps: 3,129,740,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3129740580...
Checkpoint 3129740580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.32946
Policy Entropy: 3.99520
Value Function Loss: 0.00587

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.23210
Value Function Update Magnitude: 0.33603

Collected Steps per Second: 22,681.12825
Overall Steps per Second: 10,881.10360

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.39189
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.59751

Cumulative Model Updates: 375,268
Cumulative Timesteps: 3,129,790,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.53195
Policy Entropy: 3.96750
Value Function Loss: 0.00616

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02714
Policy Update Magnitude: 0.24139
Value Function Update Magnitude: 0.32356

Collected Steps per Second: 22,273.09562
Overall Steps per Second: 10,642.13786

Timestep Collection Time: 2.24540
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.69943

Cumulative Model Updates: 375,274
Cumulative Timesteps: 3,129,840,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3129840618...
Checkpoint 3129840618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.65510
Policy Entropy: 3.93114
Value Function Loss: 0.00648

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.24148
Value Function Update Magnitude: 0.32948

Collected Steps per Second: 22,581.14575
Overall Steps per Second: 10,659.31693

Timestep Collection Time: 2.21548
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.69336

Cumulative Model Updates: 375,280
Cumulative Timesteps: 3,129,890,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.16923
Policy Entropy: 3.97894
Value Function Loss: 0.00543

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.23506
Value Function Update Magnitude: 0.33249

Collected Steps per Second: 22,654.43610
Overall Steps per Second: 10,516.26254

Timestep Collection Time: 2.20787
Timestep Consumption Time: 2.54838
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.75625

Cumulative Model Updates: 375,286
Cumulative Timesteps: 3,129,940,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3129940664...
Checkpoint 3129940664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76426
Policy Entropy: 3.97189
Value Function Loss: 0.00574

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.23503
Value Function Update Magnitude: 0.32021

Collected Steps per Second: 22,816.14176
Overall Steps per Second: 10,712.98012

Timestep Collection Time: 2.19222
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.66892

Cumulative Model Updates: 375,292
Cumulative Timesteps: 3,129,990,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.84324
Policy Entropy: 3.99599
Value Function Loss: 0.00566

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.23529
Value Function Update Magnitude: 0.31290

Collected Steps per Second: 21,954.79693
Overall Steps per Second: 10,683.85083

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.40323
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.68127

Cumulative Model Updates: 375,298
Cumulative Timesteps: 3,130,040,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3130040696...
Checkpoint 3130040696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.25561
Policy Entropy: 3.95481
Value Function Loss: 0.00591

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.23667
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 22,459.74839
Overall Steps per Second: 10,775.42887

Timestep Collection Time: 2.22692
Timestep Consumption Time: 2.41475
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.64167

Cumulative Model Updates: 375,304
Cumulative Timesteps: 3,130,090,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.31023
Policy Entropy: 3.91739
Value Function Loss: 0.00579

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.24255
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 22,402.33092
Overall Steps per Second: 10,583.89678

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.72661

Cumulative Model Updates: 375,310
Cumulative Timesteps: 3,130,140,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3130140738...
Checkpoint 3130140738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.17710
Policy Entropy: 3.87866
Value Function Loss: 0.00589

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.25002
Value Function Update Magnitude: 0.33646

Collected Steps per Second: 22,561.65478
Overall Steps per Second: 10,844.57252

Timestep Collection Time: 2.21730
Timestep Consumption Time: 2.39570
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.61300

Cumulative Model Updates: 375,316
Cumulative Timesteps: 3,130,190,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.10171
Policy Entropy: 3.91667
Value Function Loss: 0.00597

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.25559
Value Function Update Magnitude: 0.34218

Collected Steps per Second: 23,228.79077
Overall Steps per Second: 10,895.04986

Timestep Collection Time: 2.15371
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.59181

Cumulative Model Updates: 375,322
Cumulative Timesteps: 3,130,240,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3130240792...
Checkpoint 3130240792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.64847
Policy Entropy: 3.96705
Value Function Loss: 0.00588

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.24751
Value Function Update Magnitude: 0.34853

Collected Steps per Second: 22,612.45103
Overall Steps per Second: 10,734.58187

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.65952

Cumulative Model Updates: 375,328
Cumulative Timesteps: 3,130,290,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.39424
Policy Entropy: 3.96337
Value Function Loss: 0.00704

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.25398
Value Function Update Magnitude: 0.34446

Collected Steps per Second: 22,394.73955
Overall Steps per Second: 10,650.56585

Timestep Collection Time: 2.23294
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.69515

Cumulative Model Updates: 375,334
Cumulative Timesteps: 3,130,340,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3130340816...
Checkpoint 3130340816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71037
Policy Entropy: 3.94869
Value Function Loss: 0.00716

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 0.26289
Value Function Update Magnitude: 0.33635

Collected Steps per Second: 23,596.49039
Overall Steps per Second: 10,944.16622

Timestep Collection Time: 2.12015
Timestep Consumption Time: 2.45106
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.57120

Cumulative Model Updates: 375,340
Cumulative Timesteps: 3,130,390,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49611
Policy Entropy: 3.97684
Value Function Loss: 0.00664

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.25122
Value Function Update Magnitude: 0.34265

Collected Steps per Second: 22,339.97924
Overall Steps per Second: 10,517.60503

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.51600
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.75431

Cumulative Model Updates: 375,346
Cumulative Timesteps: 3,130,440,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3130440848...
Checkpoint 3130440848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.06789
Policy Entropy: 4.02150
Value Function Loss: 0.00590

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.23643
Value Function Update Magnitude: 0.32689

Collected Steps per Second: 22,287.36802
Overall Steps per Second: 10,540.71322

Timestep Collection Time: 2.24423
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.74522

Cumulative Model Updates: 375,352
Cumulative Timesteps: 3,130,490,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.55723
Policy Entropy: 4.01480
Value Function Loss: 0.00593

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.23800
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 23,606.42161
Overall Steps per Second: 10,910.20700

Timestep Collection Time: 2.11942
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.58580

Cumulative Model Updates: 375,358
Cumulative Timesteps: 3,130,540,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3130540898...
Checkpoint 3130540898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02881
Policy Entropy: 3.99371
Value Function Loss: 0.00641

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 0.24378
Value Function Update Magnitude: 0.32340

Collected Steps per Second: 22,505.45696
Overall Steps per Second: 10,652.48664

Timestep Collection Time: 2.22248
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.69543

Cumulative Model Updates: 375,364
Cumulative Timesteps: 3,130,590,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.24251
Policy Entropy: 3.94295
Value Function Loss: 0.00616

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 0.24177
Value Function Update Magnitude: 0.31917

Collected Steps per Second: 22,513.21605
Overall Steps per Second: 10,590.36520

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.72127

Cumulative Model Updates: 375,370
Cumulative Timesteps: 3,130,640,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3130640916...
Checkpoint 3130640916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.16149
Policy Entropy: 3.93652
Value Function Loss: 0.00651

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 0.23407
Value Function Update Magnitude: 0.32500

Collected Steps per Second: 23,516.53022
Overall Steps per Second: 10,877.42204

Timestep Collection Time: 2.12744
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.59944

Cumulative Model Updates: 375,376
Cumulative Timesteps: 3,130,690,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.42429
Policy Entropy: 3.94265
Value Function Loss: 0.00591

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02844
Policy Update Magnitude: 0.24212
Value Function Update Magnitude: 0.35220

Collected Steps per Second: 22,732.62038
Overall Steps per Second: 10,636.80723

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.70310

Cumulative Model Updates: 375,382
Cumulative Timesteps: 3,130,740,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3130740972...
Checkpoint 3130740972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16843
Policy Entropy: 3.93715
Value Function Loss: 0.00698

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 0.24487
Value Function Update Magnitude: 0.37647

Collected Steps per Second: 22,452.21633
Overall Steps per Second: 10,588.73063

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72408

Cumulative Model Updates: 375,388
Cumulative Timesteps: 3,130,790,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.70714
Policy Entropy: 3.87216
Value Function Loss: 0.00772

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.03107
Policy Update Magnitude: 0.25401
Value Function Update Magnitude: 0.37536

Collected Steps per Second: 23,030.32770
Overall Steps per Second: 10,831.28593

Timestep Collection Time: 2.17166
Timestep Consumption Time: 2.44589
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61755

Cumulative Model Updates: 375,394
Cumulative Timesteps: 3,130,841,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3130841008...
Checkpoint 3130841008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.96745
Policy Entropy: 3.89229
Value Function Loss: 0.00739

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 0.25318
Value Function Update Magnitude: 0.38260

Collected Steps per Second: 22,593.84434
Overall Steps per Second: 10,656.82620

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.69333

Cumulative Model Updates: 375,400
Cumulative Timesteps: 3,130,891,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.94449
Policy Entropy: 3.92326
Value Function Loss: 0.00675

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.24629
Value Function Update Magnitude: 0.36515

Collected Steps per Second: 22,638.10411
Overall Steps per Second: 10,693.04053

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.67987

Cumulative Model Updates: 375,406
Cumulative Timesteps: 3,130,941,066

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3130941066...
Checkpoint 3130941066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.21558
Policy Entropy: 3.97606
Value Function Loss: 0.00587

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.24206
Value Function Update Magnitude: 0.32930

Collected Steps per Second: 23,120.42512
Overall Steps per Second: 10,934.35751

Timestep Collection Time: 2.16276
Timestep Consumption Time: 2.41035
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.57311

Cumulative Model Updates: 375,412
Cumulative Timesteps: 3,130,991,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.07079
Policy Entropy: 3.92913
Value Function Loss: 0.00650

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 0.24955
Value Function Update Magnitude: 0.32101

Collected Steps per Second: 22,559.66709
Overall Steps per Second: 10,753.60730

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65146

Cumulative Model Updates: 375,418
Cumulative Timesteps: 3,131,041,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3131041090...
Checkpoint 3131041090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.00345
Policy Entropy: 3.94019
Value Function Loss: 0.00575

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 0.24269
Value Function Update Magnitude: 0.33999

Collected Steps per Second: 22,137.50521
Overall Steps per Second: 10,687.10620

Timestep Collection Time: 2.25978
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.68097

Cumulative Model Updates: 375,424
Cumulative Timesteps: 3,131,091,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.62739
Policy Entropy: 3.93322
Value Function Loss: 0.00537

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.24453
Value Function Update Magnitude: 0.33532

Collected Steps per Second: 23,273.39880
Overall Steps per Second: 10,940.98029

Timestep Collection Time: 2.14958
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.57253

Cumulative Model Updates: 375,430
Cumulative Timesteps: 3,131,141,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3131141144...
Checkpoint 3131141144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.03840
Policy Entropy: 3.94856
Value Function Loss: 0.00565

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.24382
Value Function Update Magnitude: 0.30682

Collected Steps per Second: 22,383.51184
Overall Steps per Second: 10,751.84883

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.65036

Cumulative Model Updates: 375,436
Cumulative Timesteps: 3,131,191,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.68172
Policy Entropy: 3.94709
Value Function Loss: 0.00606

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.24410
Value Function Update Magnitude: 0.30202

Collected Steps per Second: 22,773.24283
Overall Steps per Second: 10,816.95659

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.62422

Cumulative Model Updates: 375,442
Cumulative Timesteps: 3,131,241,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3131241164...
Checkpoint 3131241164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.09831
Policy Entropy: 3.94871
Value Function Loss: 0.00641

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.23838
Value Function Update Magnitude: 0.30218

Collected Steps per Second: 22,556.87317
Overall Steps per Second: 10,671.63197

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.46949
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.68682

Cumulative Model Updates: 375,448
Cumulative Timesteps: 3,131,291,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.82795
Policy Entropy: 3.93383
Value Function Loss: 0.00674

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.23696
Value Function Update Magnitude: 0.30995

Collected Steps per Second: 22,381.89129
Overall Steps per Second: 10,498.24715

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.52956
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.76422

Cumulative Model Updates: 375,454
Cumulative Timesteps: 3,131,341,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3131341196...
Checkpoint 3131341196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.48380
Policy Entropy: 3.93536
Value Function Loss: 0.00655

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.23026
Value Function Update Magnitude: 0.31349

Collected Steps per Second: 22,431.60581
Overall Steps per Second: 10,767.90751

Timestep Collection Time: 2.22900
Timestep Consumption Time: 2.41443
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.64343

Cumulative Model Updates: 375,460
Cumulative Timesteps: 3,131,391,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.43932
Policy Entropy: 3.95011
Value Function Loss: 0.00576

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.22407
Value Function Update Magnitude: 0.31510

Collected Steps per Second: 22,769.30798
Overall Steps per Second: 10,718.43163

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.66785

Cumulative Model Updates: 375,466
Cumulative Timesteps: 3,131,441,228

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3131441228...
Checkpoint 3131441228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.18294
Policy Entropy: 3.98103
Value Function Loss: 0.00503

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.21880
Value Function Update Magnitude: 0.30795

Collected Steps per Second: 22,505.97759
Overall Steps per Second: 10,629.30955

Timestep Collection Time: 2.22163
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.70397

Cumulative Model Updates: 375,472
Cumulative Timesteps: 3,131,491,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.10571
Policy Entropy: 3.99765
Value Function Loss: 0.00549

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.21882
Value Function Update Magnitude: 0.30620

Collected Steps per Second: 22,615.59187
Overall Steps per Second: 10,970.60023

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.34733
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.55873

Cumulative Model Updates: 375,478
Cumulative Timesteps: 3,131,541,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3131541240...
Checkpoint 3131541240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.41837
Policy Entropy: 3.96205
Value Function Loss: 0.00649

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.23779
Value Function Update Magnitude: 0.31095

Collected Steps per Second: 22,356.76257
Overall Steps per Second: 10,614.88473

Timestep Collection Time: 2.23682
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.71112

Cumulative Model Updates: 375,484
Cumulative Timesteps: 3,131,591,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.17802
Policy Entropy: 3.96055
Value Function Loss: 0.00673

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.03252
Policy Update Magnitude: 0.24683
Value Function Update Magnitude: 0.31679

Collected Steps per Second: 21,899.76618
Overall Steps per Second: 10,497.95706

Timestep Collection Time: 2.28349
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.76359

Cumulative Model Updates: 375,490
Cumulative Timesteps: 3,131,641,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3131641256...
Checkpoint 3131641256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.07714
Policy Entropy: 3.94438
Value Function Loss: 0.00690

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.25227
Value Function Update Magnitude: 0.32054

Collected Steps per Second: 22,642.67413
Overall Steps per Second: 10,963.65840

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.35315
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.56216

Cumulative Model Updates: 375,496
Cumulative Timesteps: 3,131,691,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28100
Policy Entropy: 3.93230
Value Function Loss: 0.00692

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.26406
Value Function Update Magnitude: 0.32786

Collected Steps per Second: 22,300.98193
Overall Steps per Second: 10,531.92030

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.74899

Cumulative Model Updates: 375,502
Cumulative Timesteps: 3,131,741,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3131741290...
Checkpoint 3131741290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.50573
Policy Entropy: 3.90050
Value Function Loss: 0.00671

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 0.26441
Value Function Update Magnitude: 0.33636

Collected Steps per Second: 22,348.04988
Overall Steps per Second: 10,636.49913

Timestep Collection Time: 2.23841
Timestep Consumption Time: 2.46465
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.70305

Cumulative Model Updates: 375,508
Cumulative Timesteps: 3,131,791,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.97142
Policy Entropy: 3.90325
Value Function Loss: 0.00665

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 0.26202
Value Function Update Magnitude: 0.32907

Collected Steps per Second: 22,288.35921
Overall Steps per Second: 10,887.94454

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.34891
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.59223

Cumulative Model Updates: 375,514
Cumulative Timesteps: 3,131,841,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3131841314...
Checkpoint 3131841314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.31182
Policy Entropy: 3.90181
Value Function Loss: 0.00693

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.03890
Policy Update Magnitude: 0.26344
Value Function Update Magnitude: 0.32462

Collected Steps per Second: 22,585.13539
Overall Steps per Second: 10,676.61693

Timestep Collection Time: 2.21420
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.68388

Cumulative Model Updates: 375,520
Cumulative Timesteps: 3,131,891,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.95200
Policy Entropy: 3.91479
Value Function Loss: 0.00658

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.26042
Value Function Update Magnitude: 0.31887

Collected Steps per Second: 22,426.98572
Overall Steps per Second: 10,611.33540

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.71270

Cumulative Model Updates: 375,526
Cumulative Timesteps: 3,131,941,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3131941330...
Checkpoint 3131941330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56844
Policy Entropy: 3.93117
Value Function Loss: 0.00671

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 0.25279
Value Function Update Magnitude: 0.33359

Collected Steps per Second: 22,542.63026
Overall Steps per Second: 10,941.63018

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.35309
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.57244

Cumulative Model Updates: 375,532
Cumulative Timesteps: 3,131,991,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.76354
Policy Entropy: 3.93073
Value Function Loss: 0.00630

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03186
Policy Update Magnitude: 0.24221
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 22,307.08152
Overall Steps per Second: 10,541.91332

Timestep Collection Time: 2.24225
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.74468

Cumulative Model Updates: 375,538
Cumulative Timesteps: 3,132,041,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3132041378...
Checkpoint 3132041378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.48003
Policy Entropy: 3.92104
Value Function Loss: 0.00680

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.24474
Value Function Update Magnitude: 0.32518

Collected Steps per Second: 22,446.99939
Overall Steps per Second: 10,620.16443

Timestep Collection Time: 2.22818
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.70953

Cumulative Model Updates: 375,544
Cumulative Timesteps: 3,132,091,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.67574
Policy Entropy: 3.89525
Value Function Loss: 0.00678

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.24401
Value Function Update Magnitude: 0.32258

Collected Steps per Second: 22,484.63435
Overall Steps per Second: 10,690.36410

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67917

Cumulative Model Updates: 375,550
Cumulative Timesteps: 3,132,141,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3132141416...
Checkpoint 3132141416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.13229
Policy Entropy: 3.87396
Value Function Loss: 0.00740

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.25892
Value Function Update Magnitude: 0.32534

Collected Steps per Second: 22,363.81329
Overall Steps per Second: 10,697.51284

Timestep Collection Time: 2.23584
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67417

Cumulative Model Updates: 375,556
Cumulative Timesteps: 3,132,191,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.37878
Policy Entropy: 3.88472
Value Function Loss: 0.00718

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.03837
Policy Update Magnitude: 0.25948
Value Function Update Magnitude: 0.32509

Collected Steps per Second: 22,426.93620
Overall Steps per Second: 10,603.19751

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.48799
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.71914

Cumulative Model Updates: 375,562
Cumulative Timesteps: 3,132,241,456

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3132241456...
Checkpoint 3132241456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.19413
Policy Entropy: 3.88904
Value Function Loss: 0.00749

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.03970
Policy Update Magnitude: 0.26017
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 22,184.80862
Overall Steps per Second: 10,712.09117

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.41566
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.67117

Cumulative Model Updates: 375,568
Cumulative Timesteps: 3,132,291,494

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.83647
Policy Entropy: 3.95716
Value Function Loss: 0.00675

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.03327
Policy Update Magnitude: 0.25945
Value Function Update Magnitude: 0.33719

Collected Steps per Second: 22,572.43219
Overall Steps per Second: 10,725.87240

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.66256

Cumulative Model Updates: 375,574
Cumulative Timesteps: 3,132,341,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3132341504...
Checkpoint 3132341504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.48543
Policy Entropy: 3.96336
Value Function Loss: 0.00656

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.24338
Value Function Update Magnitude: 0.33199

Collected Steps per Second: 22,273.29965
Overall Steps per Second: 10,746.77404

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.40878
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.65461

Cumulative Model Updates: 375,580
Cumulative Timesteps: 3,132,391,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.78276
Policy Entropy: 3.94709
Value Function Loss: 0.00639

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.25039
Value Function Update Magnitude: 0.33616

Collected Steps per Second: 23,375.95027
Overall Steps per Second: 10,892.07387

Timestep Collection Time: 2.13972
Timestep Consumption Time: 2.45243
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.59215

Cumulative Model Updates: 375,586
Cumulative Timesteps: 3,132,441,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3132441544...
Checkpoint 3132441544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.06704
Policy Entropy: 3.92776
Value Function Loss: 0.00685

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.25067
Value Function Update Magnitude: 0.34017

Collected Steps per Second: 22,595.99765
Overall Steps per Second: 10,633.01262

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.70478

Cumulative Model Updates: 375,592
Cumulative Timesteps: 3,132,491,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.32410
Policy Entropy: 3.91187
Value Function Loss: 0.00670

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.24820
Value Function Update Magnitude: 0.33687

Collected Steps per Second: 22,756.15516
Overall Steps per Second: 10,952.52193

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.36899
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.56717

Cumulative Model Updates: 375,598
Cumulative Timesteps: 3,132,541,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3132541592...
Checkpoint 3132541592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.55547
Policy Entropy: 3.93302
Value Function Loss: 0.00653

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.24588
Value Function Update Magnitude: 0.33179

Collected Steps per Second: 22,411.35554
Overall Steps per Second: 10,616.73569

Timestep Collection Time: 2.23110
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.70973

Cumulative Model Updates: 375,604
Cumulative Timesteps: 3,132,591,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.97848
Policy Entropy: 3.90722
Value Function Loss: 0.00636

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.25092
Value Function Update Magnitude: 0.34008

Collected Steps per Second: 22,770.96198
Overall Steps per Second: 10,594.09659

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.52514
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72206

Cumulative Model Updates: 375,610
Cumulative Timesteps: 3,132,641,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3132641620...
Checkpoint 3132641620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.45923
Policy Entropy: 3.95349
Value Function Loss: 0.00638

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.25150
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 22,570.13942
Overall Steps per Second: 10,854.02673

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.39127
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.60659

Cumulative Model Updates: 375,616
Cumulative Timesteps: 3,132,691,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.41429
Policy Entropy: 3.99122
Value Function Loss: 0.00597

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02132
Policy Update Magnitude: 0.24501
Value Function Update Magnitude: 0.32568

Collected Steps per Second: 22,463.87278
Overall Steps per Second: 10,586.79435

Timestep Collection Time: 2.22669
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72475

Cumulative Model Updates: 375,622
Cumulative Timesteps: 3,132,741,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3132741640...
Checkpoint 3132741640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.09492
Policy Entropy: 3.95884
Value Function Loss: 0.00668

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.24423
Value Function Update Magnitude: 0.31414

Collected Steps per Second: 22,457.07976
Overall Steps per Second: 10,646.66215

Timestep Collection Time: 2.22789
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69931

Cumulative Model Updates: 375,628
Cumulative Timesteps: 3,132,791,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.69398
Policy Entropy: 3.93751
Value Function Loss: 0.00630

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.24837
Value Function Update Magnitude: 0.32825

Collected Steps per Second: 23,507.73430
Overall Steps per Second: 10,859.86134

Timestep Collection Time: 2.12756
Timestep Consumption Time: 2.47784
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.60540

Cumulative Model Updates: 375,634
Cumulative Timesteps: 3,132,841,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3132841686...
Checkpoint 3132841686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.28194
Policy Entropy: 3.89889
Value Function Loss: 0.00603

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.24872
Value Function Update Magnitude: 0.33787

Collected Steps per Second: 22,102.18172
Overall Steps per Second: 10,659.45523

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.69255

Cumulative Model Updates: 375,640
Cumulative Timesteps: 3,132,891,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.52146
Policy Entropy: 3.97462
Value Function Loss: 0.00517

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.31691

Collected Steps per Second: 22,804.46801
Overall Steps per Second: 10,895.28440

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.39697
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.58988

Cumulative Model Updates: 375,646
Cumulative Timesteps: 3,132,941,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3132941714...
Checkpoint 3132941714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.21557
Policy Entropy: 3.97310
Value Function Loss: 0.00532

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.23402
Value Function Update Magnitude: 0.29285

Collected Steps per Second: 22,689.79023
Overall Steps per Second: 10,617.96943

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.70900

Cumulative Model Updates: 375,652
Cumulative Timesteps: 3,132,991,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.50412
Policy Entropy: 3.95820
Value Function Loss: 0.00603

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.22998
Value Function Update Magnitude: 0.28738

Collected Steps per Second: 22,486.74376
Overall Steps per Second: 10,588.36656

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.72330

Cumulative Model Updates: 375,658
Cumulative Timesteps: 3,133,041,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3133041726...
Checkpoint 3133041726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.16089
Policy Entropy: 3.95684
Value Function Loss: 0.00671

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.24168
Value Function Update Magnitude: 0.31110

Collected Steps per Second: 22,363.29508
Overall Steps per Second: 10,900.00814

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.35229
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.58899

Cumulative Model Updates: 375,664
Cumulative Timesteps: 3,133,091,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12760
Policy Entropy: 3.91515
Value Function Loss: 0.00732

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.24294
Value Function Update Magnitude: 0.33781

Collected Steps per Second: 22,668.87667
Overall Steps per Second: 10,622.75368

Timestep Collection Time: 2.20699
Timestep Consumption Time: 2.50271
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.70970

Cumulative Model Updates: 375,670
Cumulative Timesteps: 3,133,141,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3133141776...
Checkpoint 3133141776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.71481
Policy Entropy: 3.91469
Value Function Loss: 0.00782

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.25049
Value Function Update Magnitude: 0.37151

Collected Steps per Second: 22,572.66069
Overall Steps per Second: 10,617.65395

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71196

Cumulative Model Updates: 375,676
Cumulative Timesteps: 3,133,191,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.68797
Policy Entropy: 3.90992
Value Function Loss: 0.00712

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.25580
Value Function Update Magnitude: 0.38997

Collected Steps per Second: 22,619.12213
Overall Steps per Second: 10,853.43439

Timestep Collection Time: 2.21123
Timestep Consumption Time: 2.39708
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.60831

Cumulative Model Updates: 375,682
Cumulative Timesteps: 3,133,241,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3133241822...
Checkpoint 3133241822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.02421
Policy Entropy: 3.97070
Value Function Loss: 0.00696

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.25239
Value Function Update Magnitude: 0.36536

Collected Steps per Second: 22,492.69046
Overall Steps per Second: 10,655.31894

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.47073
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.69474

Cumulative Model Updates: 375,688
Cumulative Timesteps: 3,133,291,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.93087
Policy Entropy: 3.99640
Value Function Loss: 0.00712

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.24250
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,002.77131
Overall Steps per Second: 10,375.90940

Timestep Collection Time: 2.27308
Timestep Consumption Time: 2.54713
PPO Batch Consumption Time: 0.30421
Total Iteration Time: 4.82020

Cumulative Model Updates: 375,694
Cumulative Timesteps: 3,133,341,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3133341860...
Checkpoint 3133341860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78029
Policy Entropy: 4.00412
Value Function Loss: 0.00652

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.24178
Value Function Update Magnitude: 0.35391

Collected Steps per Second: 22,055.80492
Overall Steps per Second: 10,705.22838

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.40450
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.67230

Cumulative Model Updates: 375,700
Cumulative Timesteps: 3,133,391,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.19302
Policy Entropy: 3.95327
Value Function Loss: 0.00688

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.23911
Value Function Update Magnitude: 0.34562

Collected Steps per Second: 22,507.89356
Overall Steps per Second: 10,623.89528

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.70675

Cumulative Model Updates: 375,706
Cumulative Timesteps: 3,133,441,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3133441882...
Checkpoint 3133441882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.01509
Policy Entropy: 3.94344
Value Function Loss: 0.00681

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.24412
Value Function Update Magnitude: 0.33366

Collected Steps per Second: 22,513.85202
Overall Steps per Second: 10,689.18892

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.45716
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67837

Cumulative Model Updates: 375,712
Cumulative Timesteps: 3,133,491,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.11898
Policy Entropy: 3.91720
Value Function Loss: 0.00708

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.24516
Value Function Update Magnitude: 0.34452

Collected Steps per Second: 23,293.95814
Overall Steps per Second: 10,769.69790

Timestep Collection Time: 2.14699
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.64377

Cumulative Model Updates: 375,718
Cumulative Timesteps: 3,133,541,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3133541902...
Checkpoint 3133541902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.85538
Policy Entropy: 3.93669
Value Function Loss: 0.00651

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.24325
Value Function Update Magnitude: 0.35427

Collected Steps per Second: 22,082.00473
Overall Steps per Second: 10,525.34248

Timestep Collection Time: 2.26610
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.75424

Cumulative Model Updates: 375,724
Cumulative Timesteps: 3,133,591,942

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.26489
Policy Entropy: 3.95331
Value Function Loss: 0.00640

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.24362
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 22,075.28025
Overall Steps per Second: 10,705.41328

Timestep Collection Time: 2.26579
Timestep Consumption Time: 2.40642
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.67222

Cumulative Model Updates: 375,730
Cumulative Timesteps: 3,133,641,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3133641960...
Checkpoint 3133641960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.09291
Policy Entropy: 3.93600
Value Function Loss: 0.00658

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.24665
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 22,524.15930
Overall Steps per Second: 10,609.92520

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.71483

Cumulative Model Updates: 375,736
Cumulative Timesteps: 3,133,691,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.63839
Policy Entropy: 3.92476
Value Function Loss: 0.00732

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.26749
Value Function Update Magnitude: 0.33703

Collected Steps per Second: 22,899.11098
Overall Steps per Second: 10,770.47423

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.64288

Cumulative Model Updates: 375,742
Cumulative Timesteps: 3,133,741,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3133741990...
Checkpoint 3133741990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.94229
Policy Entropy: 3.90455
Value Function Loss: 0.00759

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.26814
Value Function Update Magnitude: 0.33579

Collected Steps per Second: 22,479.69488
Overall Steps per Second: 10,810.97601

Timestep Collection Time: 2.22503
Timestep Consumption Time: 2.40156
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.62659

Cumulative Model Updates: 375,748
Cumulative Timesteps: 3,133,792,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.92596
Policy Entropy: 3.93148
Value Function Loss: 0.00763

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 0.26182
Value Function Update Magnitude: 0.33067

Collected Steps per Second: 22,862.37439
Overall Steps per Second: 10,725.65451

Timestep Collection Time: 2.18805
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.66396

Cumulative Model Updates: 375,754
Cumulative Timesteps: 3,133,842,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3133842032...
Checkpoint 3133842032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.17119
Policy Entropy: 3.91376
Value Function Loss: 0.00773

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.25387
Value Function Update Magnitude: 0.33060

Collected Steps per Second: 22,117.59474
Overall Steps per Second: 10,711.98870

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.40760
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.66879

Cumulative Model Updates: 375,760
Cumulative Timesteps: 3,133,892,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.07808
Policy Entropy: 3.92285
Value Function Loss: 0.00718

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.26183
Value Function Update Magnitude: 0.32462

Collected Steps per Second: 22,532.95503
Overall Steps per Second: 10,943.55992

Timestep Collection Time: 2.21933
Timestep Consumption Time: 2.35030
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.56963

Cumulative Model Updates: 375,766
Cumulative Timesteps: 3,133,942,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3133942052...
Checkpoint 3133942052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.80839
Policy Entropy: 3.94350
Value Function Loss: 0.00607

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.24935
Value Function Update Magnitude: 0.31074

Collected Steps per Second: 22,444.92389
Overall Steps per Second: 10,594.35286

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.71987

Cumulative Model Updates: 375,772
Cumulative Timesteps: 3,133,992,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.61984
Policy Entropy: 3.98012
Value Function Loss: 0.00577

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.23854
Value Function Update Magnitude: 0.30351

Collected Steps per Second: 22,226.17690
Overall Steps per Second: 10,642.30638

Timestep Collection Time: 2.25050
Timestep Consumption Time: 2.44961
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.70011

Cumulative Model Updates: 375,778
Cumulative Timesteps: 3,134,042,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3134042076...
Checkpoint 3134042076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.92283
Policy Entropy: 3.95635
Value Function Loss: 0.00607

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.24111
Value Function Update Magnitude: 0.30508

Collected Steps per Second: 22,636.07488
Overall Steps per Second: 10,918.91629

Timestep Collection Time: 2.20948
Timestep Consumption Time: 2.37101
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.58049

Cumulative Model Updates: 375,784
Cumulative Timesteps: 3,134,092,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.33146
Policy Entropy: 3.91457
Value Function Loss: 0.00629

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.24652
Value Function Update Magnitude: 0.31867

Collected Steps per Second: 22,702.33586
Overall Steps per Second: 10,806.18238

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.62920

Cumulative Model Updates: 375,790
Cumulative Timesteps: 3,134,142,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3134142114...
Checkpoint 3134142114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.88158
Policy Entropy: 3.91915
Value Function Loss: 0.00617

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.24281
Value Function Update Magnitude: 0.32537

Collected Steps per Second: 22,203.50764
Overall Steps per Second: 10,754.64420

Timestep Collection Time: 2.25208
Timestep Consumption Time: 2.39745
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.64953

Cumulative Model Updates: 375,796
Cumulative Timesteps: 3,134,192,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.92911
Policy Entropy: 3.95302
Value Function Loss: 0.00578

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.23662
Value Function Update Magnitude: 0.32848

Collected Steps per Second: 22,688.93802
Overall Steps per Second: 10,902.65293

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.38375
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.58879

Cumulative Model Updates: 375,802
Cumulative Timesteps: 3,134,242,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3134242148...
Checkpoint 3134242148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.77543
Policy Entropy: 3.98553
Value Function Loss: 0.00549

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02011
Policy Update Magnitude: 0.22887
Value Function Update Magnitude: 0.31974

Collected Steps per Second: 22,525.80925
Overall Steps per Second: 10,615.25242

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.71284

Cumulative Model Updates: 375,808
Cumulative Timesteps: 3,134,292,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.96177
Policy Entropy: 3.96704
Value Function Loss: 0.00577

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01989
Policy Update Magnitude: 0.23196
Value Function Update Magnitude: 0.30434

Collected Steps per Second: 22,202.82035
Overall Steps per Second: 10,611.30213

Timestep Collection Time: 2.25305
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.71422

Cumulative Model Updates: 375,814
Cumulative Timesteps: 3,134,342,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3134342200...
Checkpoint 3134342200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.46115
Policy Entropy: 3.96116
Value Function Loss: 0.00622

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.24003
Value Function Update Magnitude: 0.29448

Collected Steps per Second: 23,221.94481
Overall Steps per Second: 10,896.42420

Timestep Collection Time: 2.15426
Timestep Consumption Time: 2.43679
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59105

Cumulative Model Updates: 375,820
Cumulative Timesteps: 3,134,392,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.79122
Policy Entropy: 3.94799
Value Function Loss: 0.00658

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.24799
Value Function Update Magnitude: 0.29840

Collected Steps per Second: 22,495.42183
Overall Steps per Second: 10,601.66112

Timestep Collection Time: 2.22294
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71681

Cumulative Model Updates: 375,826
Cumulative Timesteps: 3,134,442,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3134442232...
Checkpoint 3134442232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.40753
Policy Entropy: 3.91210
Value Function Loss: 0.00630

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.24997
Value Function Update Magnitude: 0.31218

Collected Steps per Second: 22,388.48366
Overall Steps per Second: 10,529.25142

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74963

Cumulative Model Updates: 375,832
Cumulative Timesteps: 3,134,492,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.75171
Policy Entropy: 3.90954
Value Function Loss: 0.00656

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.25545
Value Function Update Magnitude: 0.31240

Collected Steps per Second: 23,405.08515
Overall Steps per Second: 10,935.99902

Timestep Collection Time: 2.13680
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.57315

Cumulative Model Updates: 375,838
Cumulative Timesteps: 3,134,542,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3134542254...
Checkpoint 3134542254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.43490
Policy Entropy: 3.92207
Value Function Loss: 0.00609

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03232
Policy Update Magnitude: 0.24829
Value Function Update Magnitude: 0.31382

Collected Steps per Second: 22,269.29384
Overall Steps per Second: 10,698.95353

Timestep Collection Time: 2.24641
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.67578

Cumulative Model Updates: 375,844
Cumulative Timesteps: 3,134,592,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.16614
Policy Entropy: 3.95501
Value Function Loss: 0.00650

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 0.25245
Value Function Update Magnitude: 0.31961

Collected Steps per Second: 22,585.45411
Overall Steps per Second: 10,684.73059

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.68369

Cumulative Model Updates: 375,850
Cumulative Timesteps: 3,134,642,324

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3134642324...
Checkpoint 3134642324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.35807
Policy Entropy: 3.95154
Value Function Loss: 0.00623

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03098
Policy Update Magnitude: 0.23748
Value Function Update Magnitude: 0.31795

Collected Steps per Second: 22,415.76058
Overall Steps per Second: 10,674.64112

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.45372
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.68456

Cumulative Model Updates: 375,856
Cumulative Timesteps: 3,134,692,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.98725
Policy Entropy: 3.93344
Value Function Loss: 0.00713

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 0.23867
Value Function Update Magnitude: 0.32015

Collected Steps per Second: 22,355.88439
Overall Steps per Second: 10,582.39474

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.72691

Cumulative Model Updates: 375,862
Cumulative Timesteps: 3,134,742,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3134742352...
Checkpoint 3134742352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.18885
Policy Entropy: 3.96453
Value Function Loss: 0.00555

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 0.23289
Value Function Update Magnitude: 0.31755

Collected Steps per Second: 22,098.52964
Overall Steps per Second: 10,666.44009

Timestep Collection Time: 2.26323
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.68891

Cumulative Model Updates: 375,868
Cumulative Timesteps: 3,134,792,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.04938
Policy Entropy: 3.96682
Value Function Loss: 0.00535

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.22325
Value Function Update Magnitude: 0.29430

Collected Steps per Second: 22,712.17490
Overall Steps per Second: 10,807.19423

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.62673

Cumulative Model Updates: 375,874
Cumulative Timesteps: 3,134,842,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3134842368...
Checkpoint 3134842368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.50293
Policy Entropy: 3.97608
Value Function Loss: 0.00529

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.22631
Value Function Update Magnitude: 0.27340

Collected Steps per Second: 22,350.08209
Overall Steps per Second: 10,787.36694

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.39888
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.63691

Cumulative Model Updates: 375,880
Cumulative Timesteps: 3,134,892,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.24434
Policy Entropy: 3.92923
Value Function Loss: 0.00703

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.24134
Value Function Update Magnitude: 0.29869

Collected Steps per Second: 23,453.16861
Overall Steps per Second: 10,886.77682

Timestep Collection Time: 2.13225
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.59346

Cumulative Model Updates: 375,886
Cumulative Timesteps: 3,134,942,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3134942396...
Checkpoint 3134942396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.45501
Policy Entropy: 3.95188
Value Function Loss: 0.00688

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.25299
Value Function Update Magnitude: 0.31871

Collected Steps per Second: 22,271.30926
Overall Steps per Second: 10,628.80802

Timestep Collection Time: 2.24549
Timestep Consumption Time: 2.45965
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.70514

Cumulative Model Updates: 375,892
Cumulative Timesteps: 3,134,992,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.93476
Policy Entropy: 3.96862
Value Function Loss: 0.00600

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03006
Policy Update Magnitude: 0.24425
Value Function Update Magnitude: 0.31153

Collected Steps per Second: 22,331.28707
Overall Steps per Second: 10,793.21382

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.39430
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.63402

Cumulative Model Updates: 375,898
Cumulative Timesteps: 3,135,042,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3135042422...
Checkpoint 3135042422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.36463
Policy Entropy: 3.98229
Value Function Loss: 0.00556

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.23105
Value Function Update Magnitude: 0.29661

Collected Steps per Second: 21,554.77819
Overall Steps per Second: 10,293.07763

Timestep Collection Time: 2.32097
Timestep Consumption Time: 2.53938
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.86035

Cumulative Model Updates: 375,904
Cumulative Timesteps: 3,135,092,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.46631
Policy Entropy: 3.93610
Value Function Loss: 0.00600

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.22459
Value Function Update Magnitude: 0.30173

Collected Steps per Second: 21,103.20895
Overall Steps per Second: 10,419.91161

Timestep Collection Time: 2.37073
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.80138

Cumulative Model Updates: 375,910
Cumulative Timesteps: 3,135,142,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3135142480...
Checkpoint 3135142480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.54387
Policy Entropy: 3.89360
Value Function Loss: 0.00668

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.23775
Value Function Update Magnitude: 0.31532

Collected Steps per Second: 22,224.13145
Overall Steps per Second: 10,714.23069

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.66688

Cumulative Model Updates: 375,916
Cumulative Timesteps: 3,135,192,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.53397
Policy Entropy: 3.92345
Value Function Loss: 0.00619

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.23679
Value Function Update Magnitude: 0.30685

Collected Steps per Second: 22,706.75323
Overall Steps per Second: 10,646.60271

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.69709

Cumulative Model Updates: 375,922
Cumulative Timesteps: 3,135,242,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3135242490...
Checkpoint 3135242490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.42056
Policy Entropy: 3.97621
Value Function Loss: 0.00523

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.23298
Value Function Update Magnitude: 0.29498

Collected Steps per Second: 22,571.20262
Overall Steps per Second: 10,770.64304

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.64336

Cumulative Model Updates: 375,928
Cumulative Timesteps: 3,135,292,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.02338
Policy Entropy: 3.99331
Value Function Loss: 0.00533

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.22483
Value Function Update Magnitude: 0.27767

Collected Steps per Second: 21,901.31371
Overall Steps per Second: 10,412.45143

Timestep Collection Time: 2.28406
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.30636
Total Iteration Time: 4.80425

Cumulative Model Updates: 375,934
Cumulative Timesteps: 3,135,342,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3135342526...
Checkpoint 3135342526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.06673
Policy Entropy: 3.95208
Value Function Loss: 0.00582

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02242
Policy Update Magnitude: 0.22606
Value Function Update Magnitude: 0.29490

Collected Steps per Second: 22,465.14252
Overall Steps per Second: 10,730.00844

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.66207

Cumulative Model Updates: 375,940
Cumulative Timesteps: 3,135,392,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.43223
Policy Entropy: 3.91482
Value Function Loss: 0.00615

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.23178
Value Function Update Magnitude: 0.31002

Collected Steps per Second: 22,625.87497
Overall Steps per Second: 10,646.07427

Timestep Collection Time: 2.21127
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.69957

Cumulative Model Updates: 375,946
Cumulative Timesteps: 3,135,442,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3135442582...
Checkpoint 3135442582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.26165
Policy Entropy: 3.90819
Value Function Loss: 0.00643

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.24403
Value Function Update Magnitude: 0.31729

Collected Steps per Second: 21,242.05302
Overall Steps per Second: 10,593.37015

Timestep Collection Time: 2.35552
Timestep Consumption Time: 2.36782
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.72333

Cumulative Model Updates: 375,952
Cumulative Timesteps: 3,135,492,618

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.99020
Policy Entropy: 3.91432
Value Function Loss: 0.00679

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.25182
Value Function Update Magnitude: 0.31401

Collected Steps per Second: 22,749.76675
Overall Steps per Second: 10,808.33565

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.62846

Cumulative Model Updates: 375,958
Cumulative Timesteps: 3,135,542,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3135542644...
Checkpoint 3135542644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.51208
Policy Entropy: 3.93433
Value Function Loss: 0.00671

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.03078
Policy Update Magnitude: 0.25708
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 22,339.21746
Overall Steps per Second: 10,709.78534

Timestep Collection Time: 2.23831
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.66881

Cumulative Model Updates: 375,964
Cumulative Timesteps: 3,135,592,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.95882
Policy Entropy: 3.96503
Value Function Loss: 0.00598

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02798
Policy Update Magnitude: 0.24717
Value Function Update Magnitude: 0.32792

Collected Steps per Second: 22,762.68182
Overall Steps per Second: 10,914.79598

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.38522
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.58259

Cumulative Model Updates: 375,970
Cumulative Timesteps: 3,135,642,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3135642664...
Checkpoint 3135642664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.92607
Policy Entropy: 3.98314
Value Function Loss: 0.00590

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.30228

Collected Steps per Second: 22,412.00110
Overall Steps per Second: 10,607.45517

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.71517

Cumulative Model Updates: 375,976
Cumulative Timesteps: 3,135,692,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.00775
Policy Entropy: 3.98815
Value Function Loss: 0.00536

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.23127
Value Function Update Magnitude: 0.29159

Collected Steps per Second: 22,598.12381
Overall Steps per Second: 10,666.73080

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.68991

Cumulative Model Updates: 375,982
Cumulative Timesteps: 3,135,742,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3135742706...
Checkpoint 3135742706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.47156
Policy Entropy: 3.97041
Value Function Loss: 0.00549

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.22637
Value Function Update Magnitude: 0.29165

Collected Steps per Second: 23,119.72667
Overall Steps per Second: 10,941.96054

Timestep Collection Time: 2.16369
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.57176

Cumulative Model Updates: 375,988
Cumulative Timesteps: 3,135,792,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.03116
Policy Entropy: 3.95612
Value Function Loss: 0.00537

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.22877
Value Function Update Magnitude: 0.29332

Collected Steps per Second: 22,574.13965
Overall Steps per Second: 10,614.41246

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.71284

Cumulative Model Updates: 375,994
Cumulative Timesteps: 3,135,842,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3135842754...
Checkpoint 3135842754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.68697
Policy Entropy: 3.92220
Value Function Loss: 0.00633

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03538
Policy Update Magnitude: 0.24321
Value Function Update Magnitude: 0.30143

Collected Steps per Second: 22,327.33317
Overall Steps per Second: 10,619.03743

Timestep Collection Time: 2.23986
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.70947

Cumulative Model Updates: 376,000
Cumulative Timesteps: 3,135,892,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.41756
Policy Entropy: 3.90511
Value Function Loss: 0.00617

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.23801
Value Function Update Magnitude: 0.31430

Collected Steps per Second: 23,303.80995
Overall Steps per Second: 10,742.52114

Timestep Collection Time: 2.14592
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.65515

Cumulative Model Updates: 376,006
Cumulative Timesteps: 3,135,942,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3135942772...
Checkpoint 3135942772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.71466
Policy Entropy: 3.91163
Value Function Loss: 0.00672

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04187
Policy Update Magnitude: 0.24560
Value Function Update Magnitude: 0.32812

Collected Steps per Second: 21,978.28472
Overall Steps per Second: 10,606.11331

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.71483

Cumulative Model Updates: 376,012
Cumulative Timesteps: 3,135,992,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70434
Policy Entropy: 3.97085
Value Function Loss: 0.00622

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 0.24702
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 22,261.28116
Overall Steps per Second: 10,560.72380

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.73623

Cumulative Model Updates: 376,018
Cumulative Timesteps: 3,136,042,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3136042796...
Checkpoint 3136042796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.65152
Policy Entropy: 3.97498
Value Function Loss: 0.00687

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.24482
Value Function Update Magnitude: 0.34218

Collected Steps per Second: 22,658.99316
Overall Steps per Second: 10,647.00026

Timestep Collection Time: 2.20734
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69766

Cumulative Model Updates: 376,024
Cumulative Timesteps: 3,136,092,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.93719
Policy Entropy: 3.96365
Value Function Loss: 0.00690

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.24351
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 22,829.85349
Overall Steps per Second: 10,829.89343

Timestep Collection Time: 2.19011
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.61685

Cumulative Model Updates: 376,030
Cumulative Timesteps: 3,136,142,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3136142812...
Checkpoint 3136142812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.40870
Policy Entropy: 3.89528
Value Function Loss: 0.00769

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.24881
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 22,327.34309
Overall Steps per Second: 10,712.26148

Timestep Collection Time: 2.23950
Timestep Consumption Time: 2.42824
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.66774

Cumulative Model Updates: 376,036
Cumulative Timesteps: 3,136,192,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.89686
Policy Entropy: 3.90849
Value Function Loss: 0.00735

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.25975
Value Function Update Magnitude: 0.32259

Collected Steps per Second: 22,783.57553
Overall Steps per Second: 10,791.68037

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63487

Cumulative Model Updates: 376,042
Cumulative Timesteps: 3,136,242,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3136242832...
Checkpoint 3136242832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.58169
Policy Entropy: 3.89530
Value Function Loss: 0.00733

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.25461
Value Function Update Magnitude: 0.33524

Collected Steps per Second: 22,368.54956
Overall Steps per Second: 10,687.34005

Timestep Collection Time: 2.23626
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.68049

Cumulative Model Updates: 376,048
Cumulative Timesteps: 3,136,292,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.60199
Policy Entropy: 3.88931
Value Function Loss: 0.00622

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.25334
Value Function Update Magnitude: 0.34153

Collected Steps per Second: 22,458.99193
Overall Steps per Second: 10,919.97205

Timestep Collection Time: 2.22646
Timestep Consumption Time: 2.35267
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.57913

Cumulative Model Updates: 376,054
Cumulative Timesteps: 3,136,342,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3136342858...
Checkpoint 3136342858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.40783
Policy Entropy: 3.89726
Value Function Loss: 0.00597

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02667
Policy Update Magnitude: 0.25089
Value Function Update Magnitude: 0.33641

Collected Steps per Second: 22,416.40331
Overall Steps per Second: 10,654.47581

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.69493

Cumulative Model Updates: 376,060
Cumulative Timesteps: 3,136,392,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.78791
Policy Entropy: 3.96227
Value Function Loss: 0.00520

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.24185
Value Function Update Magnitude: 0.32349

Collected Steps per Second: 22,834.39574
Overall Steps per Second: 10,838.74259

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61363

Cumulative Model Updates: 376,066
Cumulative Timesteps: 3,136,442,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3136442886...
Checkpoint 3136442886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.19498
Policy Entropy: 4.00928
Value Function Loss: 0.00545

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.22924
Value Function Update Magnitude: 0.31070

Collected Steps per Second: 22,264.73259
Overall Steps per Second: 10,706.60075

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.67039

Cumulative Model Updates: 376,072
Cumulative Timesteps: 3,136,492,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.95170
Policy Entropy: 3.98145
Value Function Loss: 0.00512

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.22923
Value Function Update Magnitude: 0.29941

Collected Steps per Second: 22,580.51424
Overall Steps per Second: 10,636.89861

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.70231

Cumulative Model Updates: 376,078
Cumulative Timesteps: 3,136,542,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3136542908...
Checkpoint 3136542908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.11156
Policy Entropy: 3.94394
Value Function Loss: 0.00580

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.24087
Value Function Update Magnitude: 0.30421

Collected Steps per Second: 22,362.49576
Overall Steps per Second: 10,691.82290

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.67703

Cumulative Model Updates: 376,084
Cumulative Timesteps: 3,136,592,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.91637
Policy Entropy: 3.93271
Value Function Loss: 0.00614

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.24252
Value Function Update Magnitude: 0.31755

Collected Steps per Second: 22,377.05594
Overall Steps per Second: 10,586.52803

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 4.72431

Cumulative Model Updates: 376,090
Cumulative Timesteps: 3,136,642,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3136642928...
Checkpoint 3136642928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07635
Policy Entropy: 3.98042
Value Function Loss: 0.00568

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.23261
Value Function Update Magnitude: 0.32961

Collected Steps per Second: 22,418.34038
Overall Steps per Second: 10,711.69633

Timestep Collection Time: 2.23139
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.67004

Cumulative Model Updates: 376,096
Cumulative Timesteps: 3,136,692,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.25232
Policy Entropy: 3.99968
Value Function Loss: 0.00529

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.22560
Value Function Update Magnitude: 0.32654

Collected Steps per Second: 22,785.04165
Overall Steps per Second: 10,856.35621

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.41137
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.60597

Cumulative Model Updates: 376,102
Cumulative Timesteps: 3,136,742,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3136742956...
Checkpoint 3136742956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.02858
Policy Entropy: 3.99039
Value Function Loss: 0.00608

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.22122
Value Function Update Magnitude: 0.31423

Collected Steps per Second: 21,983.17572
Overall Steps per Second: 10,716.85461

Timestep Collection Time: 2.27638
Timestep Consumption Time: 2.39309
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.66947

Cumulative Model Updates: 376,108
Cumulative Timesteps: 3,136,792,998

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.55550
Policy Entropy: 4.00203
Value Function Loss: 0.00579

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.21801
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 22,358.94414
Overall Steps per Second: 10,529.73917

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.51352
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.75092

Cumulative Model Updates: 376,114
Cumulative Timesteps: 3,136,843,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3136843024...
Checkpoint 3136843024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.63399
Policy Entropy: 3.97458
Value Function Loss: 0.00622

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.22421
Value Function Update Magnitude: 0.28684

Collected Steps per Second: 21,642.23461
Overall Steps per Second: 10,540.20045

Timestep Collection Time: 2.31048
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.74412

Cumulative Model Updates: 376,120
Cumulative Timesteps: 3,136,893,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42573
Policy Entropy: 3.98094
Value Function Loss: 0.00580

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.22846
Value Function Update Magnitude: 0.29086

Collected Steps per Second: 22,965.71478
Overall Steps per Second: 10,594.98098

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.54318
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.72129

Cumulative Model Updates: 376,126
Cumulative Timesteps: 3,136,943,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3136943050...
Checkpoint 3136943050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.54271
Policy Entropy: 3.90436
Value Function Loss: 0.00651

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.25176
Value Function Update Magnitude: 0.29674

Collected Steps per Second: 22,518.34088
Overall Steps per Second: 10,605.61833

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71731

Cumulative Model Updates: 376,132
Cumulative Timesteps: 3,136,993,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.03635
Policy Entropy: 3.90921
Value Function Loss: 0.00647

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 0.24477
Value Function Update Magnitude: 0.32041

Collected Steps per Second: 22,695.76447
Overall Steps per Second: 10,832.87399

Timestep Collection Time: 2.20411
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.61780

Cumulative Model Updates: 376,138
Cumulative Timesteps: 3,137,043,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3137043104...
Checkpoint 3137043104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.15392
Policy Entropy: 3.95009
Value Function Loss: 0.00614

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.34281

Collected Steps per Second: 22,491.97221
Overall Steps per Second: 10,681.10048

Timestep Collection Time: 2.22399
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.68323

Cumulative Model Updates: 376,144
Cumulative Timesteps: 3,137,093,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.39034
Policy Entropy: 3.98503
Value Function Loss: 0.00596

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02382
Policy Update Magnitude: 0.23267
Value Function Update Magnitude: 0.33451

Collected Steps per Second: 22,649.64639
Overall Steps per Second: 10,626.38822

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.70734

Cumulative Model Updates: 376,150
Cumulative Timesteps: 3,137,143,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3137143148...
Checkpoint 3137143148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.70661
Policy Entropy: 3.96011
Value Function Loss: 0.00621

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.23679
Value Function Update Magnitude: 0.32108

Collected Steps per Second: 16,031.84773
Overall Steps per Second: 8,479.44984

Timestep Collection Time: 3.11904
Timestep Consumption Time: 2.77804
PPO Batch Consumption Time: 0.32270
Total Iteration Time: 5.89708

Cumulative Model Updates: 376,156
Cumulative Timesteps: 3,137,193,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.46218
Policy Entropy: 3.95602
Value Function Loss: 0.00598

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 0.23859
Value Function Update Magnitude: 0.31182

Collected Steps per Second: 21,155.90883
Overall Steps per Second: 10,223.52598

Timestep Collection Time: 2.36520
Timestep Consumption Time: 2.52920
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.89440

Cumulative Model Updates: 376,162
Cumulative Timesteps: 3,137,243,190

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3137243190...
Checkpoint 3137243190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.40299
Policy Entropy: 3.97348
Value Function Loss: 0.00522

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.22730
Value Function Update Magnitude: 0.31296

Collected Steps per Second: 21,017.97676
Overall Steps per Second: 10,161.68690

Timestep Collection Time: 2.37901
Timestep Consumption Time: 2.54163
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.92064

Cumulative Model Updates: 376,168
Cumulative Timesteps: 3,137,293,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.28677
Policy Entropy: 4.01731
Value Function Loss: 0.00430

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.30575

Collected Steps per Second: 22,202.78254
Overall Steps per Second: 10,483.72592

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.77101

Cumulative Model Updates: 376,174
Cumulative Timesteps: 3,137,343,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3137343210...
Checkpoint 3137343210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.94816
Policy Entropy: 3.98413
Value Function Loss: 0.00467

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.21155
Value Function Update Magnitude: 0.30382

Collected Steps per Second: 21,008.40248
Overall Steps per Second: 10,238.47123

Timestep Collection Time: 2.38095
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.88549

Cumulative Model Updates: 376,180
Cumulative Timesteps: 3,137,393,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.55027
Policy Entropy: 3.95406
Value Function Loss: 0.00553

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.22115
Value Function Update Magnitude: 0.30394

Collected Steps per Second: 20,958.52740
Overall Steps per Second: 10,085.85135

Timestep Collection Time: 2.38605
Timestep Consumption Time: 2.57219
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 4.95823

Cumulative Model Updates: 376,186
Cumulative Timesteps: 3,137,443,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3137443238...
Checkpoint 3137443238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.24729
Policy Entropy: 3.95988
Value Function Loss: 0.00565

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.22676
Value Function Update Magnitude: 0.32170

Collected Steps per Second: 20,764.96038
Overall Steps per Second: 10,096.73459

Timestep Collection Time: 2.40790
Timestep Consumption Time: 2.54419
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.95210

Cumulative Model Updates: 376,192
Cumulative Timesteps: 3,137,493,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.42844
Policy Entropy: 3.96350
Value Function Loss: 0.00647

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.23893
Value Function Update Magnitude: 0.33637

Collected Steps per Second: 21,735.56382
Overall Steps per Second: 10,451.63030

Timestep Collection Time: 2.30093
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.78509

Cumulative Model Updates: 376,198
Cumulative Timesteps: 3,137,543,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3137543250...
Checkpoint 3137543250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.94455
Policy Entropy: 3.94376
Value Function Loss: 0.00712

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.25924
Value Function Update Magnitude: 0.34830

Collected Steps per Second: 21,075.86358
Overall Steps per Second: 10,391.95922

Timestep Collection Time: 2.37295
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.81257

Cumulative Model Updates: 376,204
Cumulative Timesteps: 3,137,593,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17253
Policy Entropy: 3.91565
Value Function Loss: 0.00701

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.25384
Value Function Update Magnitude: 0.35485

Collected Steps per Second: 22,492.72806
Overall Steps per Second: 10,441.77434

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.56685
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.79095

Cumulative Model Updates: 376,210
Cumulative Timesteps: 3,137,643,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3137643288...
Checkpoint 3137643288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.70504
Policy Entropy: 3.92820
Value Function Loss: 0.00727

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.23892
Value Function Update Magnitude: 0.34743

Collected Steps per Second: 22,300.18829
Overall Steps per Second: 10,716.79765

Timestep Collection Time: 2.24357
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.66856

Cumulative Model Updates: 376,216
Cumulative Timesteps: 3,137,693,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.44513
Policy Entropy: 3.93750
Value Function Loss: 0.00641

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.24276
Value Function Update Magnitude: 0.33757

Collected Steps per Second: 22,288.58380
Overall Steps per Second: 10,534.65522

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.75042

Cumulative Model Updates: 376,222
Cumulative Timesteps: 3,137,743,364

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3137743364...
Checkpoint 3137743364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.58581
Policy Entropy: 3.91422
Value Function Loss: 0.00699

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.24240
Value Function Update Magnitude: 0.34024

Collected Steps per Second: 21,427.68070
Overall Steps per Second: 10,550.21168

Timestep Collection Time: 2.33436
Timestep Consumption Time: 2.40677
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.74114

Cumulative Model Updates: 376,228
Cumulative Timesteps: 3,137,793,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.06479
Policy Entropy: 3.90784
Value Function Loss: 0.00622

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.24422
Value Function Update Magnitude: 0.34316

Collected Steps per Second: 21,582.75585
Overall Steps per Second: 10,317.59523

Timestep Collection Time: 2.31778
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.84842

Cumulative Model Updates: 376,234
Cumulative Timesteps: 3,137,843,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3137843408...
Checkpoint 3137843408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.05899
Policy Entropy: 3.91349
Value Function Loss: 0.00609

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.24510
Value Function Update Magnitude: 0.33947

Collected Steps per Second: 21,107.78974
Overall Steps per Second: 9,901.20489

Timestep Collection Time: 2.36984
Timestep Consumption Time: 2.68228
PPO Batch Consumption Time: 0.31603
Total Iteration Time: 5.05211

Cumulative Model Updates: 376,240
Cumulative Timesteps: 3,137,893,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.15504
Policy Entropy: 3.95005
Value Function Loss: 0.00548

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.32171

Collected Steps per Second: 22,868.94281
Overall Steps per Second: 10,649.74521

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69532

Cumulative Model Updates: 376,246
Cumulative Timesteps: 3,137,943,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3137943434...
Checkpoint 3137943434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.34714
Policy Entropy: 3.95466
Value Function Loss: 0.00656

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.23061
Value Function Update Magnitude: 0.31964

Collected Steps per Second: 20,067.73181
Overall Steps per Second: 9,978.27888

Timestep Collection Time: 2.49156
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 5.01088

Cumulative Model Updates: 376,252
Cumulative Timesteps: 3,137,993,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.11757
Policy Entropy: 3.97159
Value Function Loss: 0.00638

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.23887
Value Function Update Magnitude: 0.32857

Collected Steps per Second: 22,615.53184
Overall Steps per Second: 10,484.17395

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.55863
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76986

Cumulative Model Updates: 376,258
Cumulative Timesteps: 3,138,043,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3138043442...
Checkpoint 3138043442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.42855
Policy Entropy: 3.96764
Value Function Loss: 0.00665

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.23826
Value Function Update Magnitude: 0.33690

Collected Steps per Second: 21,045.28389
Overall Steps per Second: 10,243.24701

Timestep Collection Time: 2.37640
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.88244

Cumulative Model Updates: 376,264
Cumulative Timesteps: 3,138,093,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.80835
Policy Entropy: 3.94754
Value Function Loss: 0.00645

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.24008
Value Function Update Magnitude: 0.33402

Collected Steps per Second: 21,766.63074
Overall Steps per Second: 10,404.71838

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.50992
PPO Batch Consumption Time: 0.30186
Total Iteration Time: 4.80840

Cumulative Model Updates: 376,270
Cumulative Timesteps: 3,138,143,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3138143484...
Checkpoint 3138143484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.62279
Policy Entropy: 3.93711
Value Function Loss: 0.00650

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.24739
Value Function Update Magnitude: 0.34370

Collected Steps per Second: 21,312.47144
Overall Steps per Second: 10,266.01377

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.87044

Cumulative Model Updates: 376,276
Cumulative Timesteps: 3,138,193,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.37964
Policy Entropy: 3.89552
Value Function Loss: 0.00633

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.25046
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 22,101.86978
Overall Steps per Second: 10,380.89054

Timestep Collection Time: 2.26261
Timestep Consumption Time: 2.55470
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.81731

Cumulative Model Updates: 376,282
Cumulative Timesteps: 3,138,243,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3138243492...
Checkpoint 3138243492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.84199
Policy Entropy: 3.92347
Value Function Loss: 0.00638

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.25030
Value Function Update Magnitude: 0.35444

Collected Steps per Second: 21,183.14322
Overall Steps per Second: 10,315.87495

Timestep Collection Time: 2.36122
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.84864

Cumulative Model Updates: 376,288
Cumulative Timesteps: 3,138,293,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.56086
Policy Entropy: 3.95626
Value Function Loss: 0.00637

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.24739
Value Function Update Magnitude: 0.33956

Collected Steps per Second: 21,891.32925
Overall Steps per Second: 10,389.83489

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.52869
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.81297

Cumulative Model Updates: 376,294
Cumulative Timesteps: 3,138,343,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3138343516...
Checkpoint 3138343516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.38014
Policy Entropy: 3.93610
Value Function Loss: 0.00745

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.25020
Value Function Update Magnitude: 0.34169

Collected Steps per Second: 21,046.90068
Overall Steps per Second: 10,304.05576

Timestep Collection Time: 2.37641
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.85401

Cumulative Model Updates: 376,300
Cumulative Timesteps: 3,138,393,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.70144
Policy Entropy: 3.93221
Value Function Loss: 0.00646

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.24547
Value Function Update Magnitude: 0.34524

Collected Steps per Second: 21,809.59545
Overall Steps per Second: 10,009.69684

Timestep Collection Time: 2.29294
Timestep Consumption Time: 2.70302
PPO Batch Consumption Time: 0.31128
Total Iteration Time: 4.99596

Cumulative Model Updates: 376,306
Cumulative Timesteps: 3,138,443,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3138443540...
Checkpoint 3138443540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.90109
Policy Entropy: 3.91917
Value Function Loss: 0.00616

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 0.23779
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 21,086.06474
Overall Steps per Second: 9,976.38081

Timestep Collection Time: 2.37142
Timestep Consumption Time: 2.64081
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 5.01224

Cumulative Model Updates: 376,312
Cumulative Timesteps: 3,138,493,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.29507
Policy Entropy: 3.97117
Value Function Loss: 0.00554

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.22773
Value Function Update Magnitude: 0.32050

Collected Steps per Second: 22,462.00739
Overall Steps per Second: 10,676.66634

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.68442

Cumulative Model Updates: 376,318
Cumulative Timesteps: 3,138,543,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3138543558...
Checkpoint 3138543558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.63319
Policy Entropy: 3.97420
Value Function Loss: 0.00608

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.23176
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 20,070.12144
Overall Steps per Second: 10,160.66457

Timestep Collection Time: 2.49216
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.92271

Cumulative Model Updates: 376,324
Cumulative Timesteps: 3,138,593,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.46362
Policy Entropy: 3.98080
Value Function Loss: 0.00598

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.23077
Value Function Update Magnitude: 0.30688

Collected Steps per Second: 22,055.01820
Overall Steps per Second: 10,404.45980

Timestep Collection Time: 2.26733
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.80621

Cumulative Model Updates: 376,330
Cumulative Timesteps: 3,138,643,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3138643582...
Checkpoint 3138643582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.00028
Policy Entropy: 3.95643
Value Function Loss: 0.00546

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.23176
Value Function Update Magnitude: 0.30090

Collected Steps per Second: 21,284.96448
Overall Steps per Second: 10,317.36940

Timestep Collection Time: 2.34917
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.84639

Cumulative Model Updates: 376,336
Cumulative Timesteps: 3,138,693,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.19644
Policy Entropy: 3.96225
Value Function Loss: 0.00503

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.22218
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 22,858.88358
Overall Steps per Second: 10,562.66188

Timestep Collection Time: 2.18760
Timestep Consumption Time: 2.54663
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.73422

Cumulative Model Updates: 376,342
Cumulative Timesteps: 3,138,743,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3138743590...
Checkpoint 3138743590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.27261
Policy Entropy: 3.95112
Value Function Loss: 0.00558

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.22354
Value Function Update Magnitude: 0.29838

Collected Steps per Second: 21,476.80978
Overall Steps per Second: 10,375.89122

Timestep Collection Time: 2.32884
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.82041

Cumulative Model Updates: 376,348
Cumulative Timesteps: 3,138,793,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.43671
Policy Entropy: 3.96945
Value Function Loss: 0.00583

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.23246
Value Function Update Magnitude: 0.31206

Collected Steps per Second: 22,212.58964
Overall Steps per Second: 10,617.47663

Timestep Collection Time: 2.25116
Timestep Consumption Time: 2.45844
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70959

Cumulative Model Updates: 376,354
Cumulative Timesteps: 3,138,843,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3138843610...
Checkpoint 3138843610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.62188
Policy Entropy: 3.97853
Value Function Loss: 0.00651

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.23624
Value Function Update Magnitude: 0.32367

Collected Steps per Second: 21,146.12255
Overall Steps per Second: 10,194.05990

Timestep Collection Time: 2.36535
Timestep Consumption Time: 2.54123
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.90658

Cumulative Model Updates: 376,360
Cumulative Timesteps: 3,138,893,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.86371
Policy Entropy: 3.97628
Value Function Loss: 0.00579

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.23060
Value Function Update Magnitude: 0.32074

Collected Steps per Second: 21,906.35491
Overall Steps per Second: 10,440.16161

Timestep Collection Time: 2.28272
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.78977

Cumulative Model Updates: 376,366
Cumulative Timesteps: 3,138,943,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3138943634...
Checkpoint 3138943634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.56372
Policy Entropy: 3.95279
Value Function Loss: 0.00612

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.22723
Value Function Update Magnitude: 0.30261

Collected Steps per Second: 21,146.88485
Overall Steps per Second: 10,304.86612

Timestep Collection Time: 2.36621
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 4.85576

Cumulative Model Updates: 376,372
Cumulative Timesteps: 3,138,993,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.14169
Policy Entropy: 3.95128
Value Function Loss: 0.00548

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.22906
Value Function Update Magnitude: 0.30325

Collected Steps per Second: 21,711.92669
Overall Steps per Second: 10,427.50194

Timestep Collection Time: 2.30371
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.79674

Cumulative Model Updates: 376,378
Cumulative Timesteps: 3,139,043,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3139043690...
Checkpoint 3139043690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.05101
Policy Entropy: 3.96756
Value Function Loss: 0.00559

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.24590
Value Function Update Magnitude: 0.32383

Collected Steps per Second: 21,578.52330
Overall Steps per Second: 10,268.57263

Timestep Collection Time: 2.31777
Timestep Consumption Time: 2.55282
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.87059

Cumulative Model Updates: 376,384
Cumulative Timesteps: 3,139,093,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.51322
Policy Entropy: 3.98397
Value Function Loss: 0.00558

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.23809
Value Function Update Magnitude: 0.32076

Collected Steps per Second: 22,045.96735
Overall Steps per Second: 10,599.91733

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.71721

Cumulative Model Updates: 376,390
Cumulative Timesteps: 3,139,143,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3139143706...
Checkpoint 3139143706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77204
Policy Entropy: 3.97664
Value Function Loss: 0.00544

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.23548
Value Function Update Magnitude: 0.30129

Collected Steps per Second: 21,663.19249
Overall Steps per Second: 10,311.87920

Timestep Collection Time: 2.30889
Timestep Consumption Time: 2.54163
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.85052

Cumulative Model Updates: 376,396
Cumulative Timesteps: 3,139,193,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.14221
Policy Entropy: 3.93809
Value Function Loss: 0.00667

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.23484
Value Function Update Magnitude: 0.30272

Collected Steps per Second: 21,520.33822
Overall Steps per Second: 10,471.68943

Timestep Collection Time: 2.32376
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.77554

Cumulative Model Updates: 376,402
Cumulative Timesteps: 3,139,243,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3139243732...
Checkpoint 3139243732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.73768
Policy Entropy: 3.91629
Value Function Loss: 0.00654

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.23990
Value Function Update Magnitude: 0.31946

Collected Steps per Second: 20,665.98303
Overall Steps per Second: 10,366.10134

Timestep Collection Time: 2.42060
Timestep Consumption Time: 2.40513
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.82573

Cumulative Model Updates: 376,408
Cumulative Timesteps: 3,139,293,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.66115
Policy Entropy: 3.91613
Value Function Loss: 0.00648

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.24390
Value Function Update Magnitude: 0.32278

Collected Steps per Second: 21,484.23431
Overall Steps per Second: 9,871.38132

Timestep Collection Time: 2.32803
Timestep Consumption Time: 2.73874
PPO Batch Consumption Time: 0.31785
Total Iteration Time: 5.06677

Cumulative Model Updates: 376,414
Cumulative Timesteps: 3,139,343,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3139343772...
Checkpoint 3139343772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.44395
Policy Entropy: 3.93274
Value Function Loss: 0.00631

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.24895
Value Function Update Magnitude: 0.31258

Collected Steps per Second: 18,879.17817
Overall Steps per Second: 9,631.95506

Timestep Collection Time: 2.64937
Timestep Consumption Time: 2.54355
PPO Batch Consumption Time: 0.30909
Total Iteration Time: 5.19292

Cumulative Model Updates: 376,420
Cumulative Timesteps: 3,139,393,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.29270
Policy Entropy: 3.94100
Value Function Loss: 0.00631

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.24892
Value Function Update Magnitude: 0.31940

Collected Steps per Second: 18,071.30507
Overall Steps per Second: 9,630.05155

Timestep Collection Time: 2.76815
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 5.19457

Cumulative Model Updates: 376,426
Cumulative Timesteps: 3,139,443,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3139443814...
Checkpoint 3139443814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.95383
Policy Entropy: 3.92630
Value Function Loss: 0.00607

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 0.25163
Value Function Update Magnitude: 0.32833

Collected Steps per Second: 21,056.51325
Overall Steps per Second: 9,932.70844

Timestep Collection Time: 2.37608
Timestep Consumption Time: 2.66101
PPO Batch Consumption Time: 0.31187
Total Iteration Time: 5.03710

Cumulative Model Updates: 376,432
Cumulative Timesteps: 3,139,493,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.53328
Policy Entropy: 3.88751
Value Function Loss: 0.00615

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.25922
Value Function Update Magnitude: 0.33296

Collected Steps per Second: 19,837.51957
Overall Steps per Second: 9,734.96637

Timestep Collection Time: 2.52098
Timestep Consumption Time: 2.61617
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 5.13715

Cumulative Model Updates: 376,438
Cumulative Timesteps: 3,139,543,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3139543856...
Checkpoint 3139543856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.20990
Policy Entropy: 3.86783
Value Function Loss: 0.00726

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.26852
Value Function Update Magnitude: 0.34436

Collected Steps per Second: 19,761.41710
Overall Steps per Second: 9,931.27917

Timestep Collection Time: 2.53130
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.30801
Total Iteration Time: 5.03681

Cumulative Model Updates: 376,444
Cumulative Timesteps: 3,139,593,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.87458
Policy Entropy: 3.88167
Value Function Loss: 0.00675

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.26768
Value Function Update Magnitude: 0.34917

Collected Steps per Second: 21,670.68549
Overall Steps per Second: 10,271.45013

Timestep Collection Time: 2.30773
Timestep Consumption Time: 2.56111
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.86884

Cumulative Model Updates: 376,450
Cumulative Timesteps: 3,139,643,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3139643888...
Checkpoint 3139643888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.14889
Policy Entropy: 3.87957
Value Function Loss: 0.00720

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.26546
Value Function Update Magnitude: 0.34061

Collected Steps per Second: 21,319.94426
Overall Steps per Second: 10,381.56713

Timestep Collection Time: 2.34532
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.81642

Cumulative Model Updates: 376,456
Cumulative Timesteps: 3,139,693,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.71531
Policy Entropy: 3.91035
Value Function Loss: 0.00682

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.26104
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 22,002.05991
Overall Steps per Second: 10,457.20135

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.30412
Total Iteration Time: 4.78407

Cumulative Model Updates: 376,462
Cumulative Timesteps: 3,139,743,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3139743918...
Checkpoint 3139743918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.85630
Policy Entropy: 3.87263
Value Function Loss: 0.00726

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.25894
Value Function Update Magnitude: 0.33441

Collected Steps per Second: 21,477.15951
Overall Steps per Second: 10,234.33618

Timestep Collection Time: 2.32889
Timestep Consumption Time: 2.55838
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.88727

Cumulative Model Updates: 376,468
Cumulative Timesteps: 3,139,793,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.53858
Policy Entropy: 3.92375
Value Function Loss: 0.00721

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.25703
Value Function Update Magnitude: 0.33667

Collected Steps per Second: 21,826.27386
Overall Steps per Second: 10,387.59544

Timestep Collection Time: 2.29128
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.81440

Cumulative Model Updates: 376,474
Cumulative Timesteps: 3,139,843,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3139843946...
Checkpoint 3139843946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.59721
Policy Entropy: 3.91698
Value Function Loss: 0.00640

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 0.24762
Value Function Update Magnitude: 0.33475

Collected Steps per Second: 17,869.14132
Overall Steps per Second: 9,482.11435

Timestep Collection Time: 2.80036
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 5.27730

Cumulative Model Updates: 376,480
Cumulative Timesteps: 3,139,893,986

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.28570
Policy Entropy: 3.96830
Value Function Loss: 0.00607

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.24183
Value Function Update Magnitude: 0.32480

Collected Steps per Second: 20,575.35731
Overall Steps per Second: 10,156.84905

Timestep Collection Time: 2.43126
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.92515

Cumulative Model Updates: 376,486
Cumulative Timesteps: 3,139,944,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3139944010...
Checkpoint 3139944010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.08484
Policy Entropy: 3.98090
Value Function Loss: 0.00511

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.23097
Value Function Update Magnitude: 0.31538

Collected Steps per Second: 21,977.30041
Overall Steps per Second: 10,660.88989

Timestep Collection Time: 2.27526
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.69042

Cumulative Model Updates: 376,492
Cumulative Timesteps: 3,139,994,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.00662
Policy Entropy: 4.00016
Value Function Loss: 0.00579

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.22269
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 22,391.33155
Overall Steps per Second: 10,605.76447

Timestep Collection Time: 2.23435
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.71725

Cumulative Model Updates: 376,498
Cumulative Timesteps: 3,140,044,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3140044044...
Checkpoint 3140044044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.58430
Policy Entropy: 3.99536
Value Function Loss: 0.00536

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.21842
Value Function Update Magnitude: 0.30160

Collected Steps per Second: 22,596.54787
Overall Steps per Second: 10,652.09844

Timestep Collection Time: 2.21397
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.69654

Cumulative Model Updates: 376,504
Cumulative Timesteps: 3,140,094,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.39581
Policy Entropy: 3.99872
Value Function Loss: 0.00486

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.21682
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 22,751.41032
Overall Steps per Second: 10,783.05664

Timestep Collection Time: 2.19819
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.63802

Cumulative Model Updates: 376,510
Cumulative Timesteps: 3,140,144,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3140144084...
Checkpoint 3140144084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.57261
Policy Entropy: 3.97987
Value Function Loss: 0.00428

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.21674
Value Function Update Magnitude: 0.27339

Collected Steps per Second: 22,497.34574
Overall Steps per Second: 10,530.05118

Timestep Collection Time: 2.22275
Timestep Consumption Time: 2.52613
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.74888

Cumulative Model Updates: 376,516
Cumulative Timesteps: 3,140,194,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44322
Policy Entropy: 3.95919
Value Function Loss: 0.00486

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.21939
Value Function Update Magnitude: 0.27256

Collected Steps per Second: 22,563.33410
Overall Steps per Second: 10,683.66869

Timestep Collection Time: 2.21607
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.68023

Cumulative Model Updates: 376,522
Cumulative Timesteps: 3,140,244,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3140244092...
Checkpoint 3140244092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.58250
Policy Entropy: 3.92988
Value Function Loss: 0.00570

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.22335
Value Function Update Magnitude: 0.29360

Collected Steps per Second: 22,406.73870
Overall Steps per Second: 10,867.51051

Timestep Collection Time: 2.23245
Timestep Consumption Time: 2.37044
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60289

Cumulative Model Updates: 376,528
Cumulative Timesteps: 3,140,294,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.31861
Policy Entropy: 3.92604
Value Function Loss: 0.00654

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.23737
Value Function Update Magnitude: 0.30997

Collected Steps per Second: 22,784.72700
Overall Steps per Second: 10,680.02347

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68463

Cumulative Model Updates: 376,534
Cumulative Timesteps: 3,140,344,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3140344146...
Checkpoint 3140344146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.20463
Policy Entropy: 3.91223
Value Function Loss: 0.00646

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 0.23655
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 21,877.44744
Overall Steps per Second: 10,474.01023

Timestep Collection Time: 2.28555
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.77391

Cumulative Model Updates: 376,540
Cumulative Timesteps: 3,140,394,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.82765
Policy Entropy: 3.96508
Value Function Loss: 0.00617

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.22934
Value Function Update Magnitude: 0.32805

Collected Steps per Second: 23,187.77844
Overall Steps per Second: 10,851.88773

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.45168
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60841

Cumulative Model Updates: 376,546
Cumulative Timesteps: 3,140,444,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3140444158...
Checkpoint 3140444158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.22567
Policy Entropy: 3.96165
Value Function Loss: 0.00655

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.24396
Value Function Update Magnitude: 0.33171

Collected Steps per Second: 22,260.95042
Overall Steps per Second: 10,650.48472

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.69725

Cumulative Model Updates: 376,552
Cumulative Timesteps: 3,140,494,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.14980
Policy Entropy: 3.99051
Value Function Loss: 0.00634

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.32568

Collected Steps per Second: 22,381.32740
Overall Steps per Second: 10,564.08353

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73359

Cumulative Model Updates: 376,558
Cumulative Timesteps: 3,140,544,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3140544192...
Checkpoint 3140544192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.27913
Policy Entropy: 3.94924
Value Function Loss: 0.00687

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.03439
Policy Update Magnitude: 0.24900
Value Function Update Magnitude: 0.32884

Collected Steps per Second: 22,777.93562
Overall Steps per Second: 10,636.55830

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.70340

Cumulative Model Updates: 376,564
Cumulative Timesteps: 3,140,594,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.62786
Policy Entropy: 3.99791
Value Function Loss: 0.00642

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.24259
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 22,118.89928
Overall Steps per Second: 10,472.71479

Timestep Collection Time: 2.26132
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.77603

Cumulative Model Updates: 376,570
Cumulative Timesteps: 3,140,644,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3140644238...
Checkpoint 3140644238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.39621
Policy Entropy: 3.96090
Value Function Loss: 0.00613

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.23562
Value Function Update Magnitude: 0.33739

Collected Steps per Second: 22,492.42486
Overall Steps per Second: 10,916.23470

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.35868
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.58290

Cumulative Model Updates: 376,576
Cumulative Timesteps: 3,140,694,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.60866
Policy Entropy: 3.97222
Value Function Loss: 0.00545

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.32885

Collected Steps per Second: 22,671.66597
Overall Steps per Second: 10,544.69592

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.53673
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.74248

Cumulative Model Updates: 376,582
Cumulative Timesteps: 3,140,744,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3140744274...
Checkpoint 3140744274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.67217
Policy Entropy: 3.93812
Value Function Loss: 0.00676

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.24027
Value Function Update Magnitude: 0.32018

Collected Steps per Second: 22,257.71754
Overall Steps per Second: 10,619.68966

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.70880

Cumulative Model Updates: 376,588
Cumulative Timesteps: 3,140,794,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.49414
Policy Entropy: 3.97709
Value Function Loss: 0.00666

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.24109
Value Function Update Magnitude: 0.31901

Collected Steps per Second: 22,766.99160
Overall Steps per Second: 10,910.69888

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.38707
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58376

Cumulative Model Updates: 376,594
Cumulative Timesteps: 3,140,844,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3140844292...
Checkpoint 3140844292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.02834
Policy Entropy: 3.98285
Value Function Loss: 0.00636

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.22871
Value Function Update Magnitude: 0.30411

Collected Steps per Second: 22,553.52301
Overall Steps per Second: 10,640.95609

Timestep Collection Time: 2.21713
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.69920

Cumulative Model Updates: 376,600
Cumulative Timesteps: 3,140,894,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.63149
Policy Entropy: 3.99229
Value Function Loss: 0.00516

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.21752
Value Function Update Magnitude: 0.28799

Collected Steps per Second: 22,768.03513
Overall Steps per Second: 10,158.99631

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.72732
PPO Batch Consumption Time: 0.31953
Total Iteration Time: 4.92470

Cumulative Model Updates: 376,606
Cumulative Timesteps: 3,140,944,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3140944326...
Checkpoint 3140944326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.18728
Policy Entropy: 3.95223
Value Function Loss: 0.00529

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.21974
Value Function Update Magnitude: 0.28826

Collected Steps per Second: 20,170.85847
Overall Steps per Second: 10,045.48414

Timestep Collection Time: 2.47882
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.97736

Cumulative Model Updates: 376,612
Cumulative Timesteps: 3,140,994,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.16221
Policy Entropy: 3.92439
Value Function Loss: 0.00610

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.22957
Value Function Update Magnitude: 0.30731

Collected Steps per Second: 20,433.99858
Overall Steps per Second: 10,055.42506

Timestep Collection Time: 2.44769
Timestep Consumption Time: 2.52635
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.97403

Cumulative Model Updates: 376,618
Cumulative Timesteps: 3,141,044,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3141044342...
Checkpoint 3141044342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98969
Policy Entropy: 3.91693
Value Function Loss: 0.00657

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.24293
Value Function Update Magnitude: 0.32869

Collected Steps per Second: 22,018.28370
Overall Steps per Second: 10,531.35161

Timestep Collection Time: 2.27211
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.75039

Cumulative Model Updates: 376,624
Cumulative Timesteps: 3,141,094,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.49586
Policy Entropy: 3.94688
Value Function Loss: 0.00626

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.24063
Value Function Update Magnitude: 0.34252

Collected Steps per Second: 20,727.62915
Overall Steps per Second: 9,980.00885

Timestep Collection Time: 2.41243
Timestep Consumption Time: 2.59798
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 5.01042

Cumulative Model Updates: 376,630
Cumulative Timesteps: 3,141,144,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3141144374...
Checkpoint 3141144374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.05095
Policy Entropy: 3.94564
Value Function Loss: 0.00667

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.24063
Value Function Update Magnitude: 0.34392

Collected Steps per Second: 20,096.75137
Overall Steps per Second: 10,196.77875

Timestep Collection Time: 2.48956
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.90665

Cumulative Model Updates: 376,636
Cumulative Timesteps: 3,141,194,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.87265
Policy Entropy: 3.95381
Value Function Loss: 0.00647

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.24452
Value Function Update Magnitude: 0.33893

Collected Steps per Second: 21,615.31592
Overall Steps per Second: 10,261.41622

Timestep Collection Time: 2.31382
Timestep Consumption Time: 2.56016
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.87399

Cumulative Model Updates: 376,642
Cumulative Timesteps: 3,141,244,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3141244420...
Checkpoint 3141244420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.25476
Policy Entropy: 3.93390
Value Function Loss: 0.00659

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.23870
Value Function Update Magnitude: 0.32818

Collected Steps per Second: 20,422.11695
Overall Steps per Second: 9,769.46446

Timestep Collection Time: 2.44979
Timestep Consumption Time: 2.67126
PPO Batch Consumption Time: 0.31665
Total Iteration Time: 5.12106

Cumulative Model Updates: 376,648
Cumulative Timesteps: 3,141,294,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.30122
Policy Entropy: 3.92503
Value Function Loss: 0.00651

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.24147
Value Function Update Magnitude: 0.31546

Collected Steps per Second: 22,017.59876
Overall Steps per Second: 10,427.79977

Timestep Collection Time: 2.27173
Timestep Consumption Time: 2.52487
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.79660

Cumulative Model Updates: 376,654
Cumulative Timesteps: 3,141,344,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3141344468...
Checkpoint 3141344468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.05365
Policy Entropy: 3.92225
Value Function Loss: 0.00705

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.03346
Policy Update Magnitude: 0.24562
Value Function Update Magnitude: 0.32985

Collected Steps per Second: 19,770.00238
Overall Steps per Second: 10,165.30757

Timestep Collection Time: 2.53010
Timestep Consumption Time: 2.39056
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.92066

Cumulative Model Updates: 376,660
Cumulative Timesteps: 3,141,394,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.85739
Policy Entropy: 3.94182
Value Function Loss: 0.00713

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.24780
Value Function Update Magnitude: 0.33948

Collected Steps per Second: 20,964.24113
Overall Steps per Second: 10,229.54847

Timestep Collection Time: 2.38683
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.89152

Cumulative Model Updates: 376,666
Cumulative Timesteps: 3,141,444,526

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3141444526...
Checkpoint 3141444526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66872
Policy Entropy: 3.96744
Value Function Loss: 0.00723

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.24183
Value Function Update Magnitude: 0.33780

Collected Steps per Second: 21,996.37123
Overall Steps per Second: 10,591.27235

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72238

Cumulative Model Updates: 376,672
Cumulative Timesteps: 3,141,494,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.89084
Policy Entropy: 3.99126
Value Function Loss: 0.00626

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.23067
Value Function Update Magnitude: 0.32839

Collected Steps per Second: 22,593.27133
Overall Steps per Second: 10,666.35500

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.68876

Cumulative Model Updates: 376,678
Cumulative Timesteps: 3,141,544,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3141544554...
Checkpoint 3141544554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.28283
Policy Entropy: 4.00249
Value Function Loss: 0.00596

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.22387
Value Function Update Magnitude: 0.31044

Collected Steps per Second: 22,598.11324
Overall Steps per Second: 10,540.08081

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.53132
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.74399

Cumulative Model Updates: 376,684
Cumulative Timesteps: 3,141,594,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.05791
Policy Entropy: 4.00406
Value Function Loss: 0.00664

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.22644
Value Function Update Magnitude: 0.31473

Collected Steps per Second: 22,743.67384
Overall Steps per Second: 10,809.27865

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62658

Cumulative Model Updates: 376,690
Cumulative Timesteps: 3,141,644,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3141644566...
Checkpoint 3141644566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.99413
Policy Entropy: 4.01046
Value Function Loss: 0.00624

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.22968
Value Function Update Magnitude: 0.31996

Collected Steps per Second: 20,924.30573
Overall Steps per Second: 9,880.70180

Timestep Collection Time: 2.39090
Timestep Consumption Time: 2.67230
PPO Batch Consumption Time: 0.30613
Total Iteration Time: 5.06320

Cumulative Model Updates: 376,696
Cumulative Timesteps: 3,141,694,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.94975
Policy Entropy: 3.96657
Value Function Loss: 0.00647

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.22726
Value Function Update Magnitude: 0.31659

Collected Steps per Second: 18,700.09517
Overall Steps per Second: 9,535.89906

Timestep Collection Time: 2.67507
Timestep Consumption Time: 2.57079
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 5.24586

Cumulative Model Updates: 376,702
Cumulative Timesteps: 3,141,744,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3141744618...
Checkpoint 3141744618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.65358
Policy Entropy: 3.96991
Value Function Loss: 0.00573

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.23118
Value Function Update Magnitude: 0.31046

Collected Steps per Second: 19,936.88844
Overall Steps per Second: 9,765.46867

Timestep Collection Time: 2.50902
Timestep Consumption Time: 2.61332
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 5.12233

Cumulative Model Updates: 376,708
Cumulative Timesteps: 3,141,794,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.25444
Policy Entropy: 3.92643
Value Function Loss: 0.00609

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.23663
Value Function Update Magnitude: 0.31442

Collected Steps per Second: 21,952.23892
Overall Steps per Second: 10,477.95743

Timestep Collection Time: 2.27895
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.77459

Cumulative Model Updates: 376,714
Cumulative Timesteps: 3,141,844,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3141844668...
Checkpoint 3141844668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.64180
Policy Entropy: 3.95971
Value Function Loss: 0.00558

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.23272
Value Function Update Magnitude: 0.32683

Collected Steps per Second: 21,592.82792
Overall Steps per Second: 10,330.94344

Timestep Collection Time: 2.31605
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.84080

Cumulative Model Updates: 376,720
Cumulative Timesteps: 3,141,894,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.56315
Policy Entropy: 3.91058
Value Function Loss: 0.00588

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.23148
Value Function Update Magnitude: 0.31664

Collected Steps per Second: 22,804.42235
Overall Steps per Second: 10,922.14851

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.38606
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.57932

Cumulative Model Updates: 376,726
Cumulative Timesteps: 3,141,944,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3141944694...
Checkpoint 3141944694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.78827
Policy Entropy: 3.90411
Value Function Loss: 0.00603

Mean KL Divergence: 0.01956
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.30880

Collected Steps per Second: 22,023.54281
Overall Steps per Second: 10,573.24043

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.45892
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.72949

Cumulative Model Updates: 376,732
Cumulative Timesteps: 3,141,994,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.41516
Policy Entropy: 3.92022
Value Function Loss: 0.00629

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.28892
Value Function Update Magnitude: 0.31892

Collected Steps per Second: 22,011.50656
Overall Steps per Second: 10,174.29267

Timestep Collection Time: 2.27272
Timestep Consumption Time: 2.64418
PPO Batch Consumption Time: 0.31444
Total Iteration Time: 4.91690

Cumulative Model Updates: 376,738
Cumulative Timesteps: 3,142,044,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3142044726...
Checkpoint 3142044726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.32832
Policy Entropy: 3.89694
Value Function Loss: 0.00731

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.26631
Value Function Update Magnitude: 0.33109

Collected Steps per Second: 20,056.88385
Overall Steps per Second: 9,851.45932

Timestep Collection Time: 2.49361
Timestep Consumption Time: 2.58320
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 5.07681

Cumulative Model Updates: 376,744
Cumulative Timesteps: 3,142,094,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.79453
Policy Entropy: 3.89645
Value Function Loss: 0.00778

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.26344
Value Function Update Magnitude: 0.35074

Collected Steps per Second: 21,653.30382
Overall Steps per Second: 10,162.08045

Timestep Collection Time: 2.30976
Timestep Consumption Time: 2.61187
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 4.92163

Cumulative Model Updates: 376,750
Cumulative Timesteps: 3,142,144,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3142144754...
Checkpoint 3142144754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.39361
Policy Entropy: 3.91064
Value Function Loss: 0.00702

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.04154
Policy Update Magnitude: 0.25654
Value Function Update Magnitude: 0.36141

Collected Steps per Second: 21,048.75803
Overall Steps per Second: 10,352.31342

Timestep Collection Time: 2.37563
Timestep Consumption Time: 2.45460
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.83022

Cumulative Model Updates: 376,756
Cumulative Timesteps: 3,142,194,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.29935
Policy Entropy: 3.94307
Value Function Loss: 0.00678

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 0.24522
Value Function Update Magnitude: 0.33592

Collected Steps per Second: 21,643.02545
Overall Steps per Second: 10,462.85923

Timestep Collection Time: 2.31068
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.77976

Cumulative Model Updates: 376,762
Cumulative Timesteps: 3,142,244,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3142244768...
Checkpoint 3142244768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.60437
Policy Entropy: 3.94470
Value Function Loss: 0.00585

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03176
Policy Update Magnitude: 0.23361
Value Function Update Magnitude: 0.31688

Collected Steps per Second: 22,620.53030
Overall Steps per Second: 10,474.49311

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.56496
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.77694

Cumulative Model Updates: 376,768
Cumulative Timesteps: 3,142,294,804

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.66413
Policy Entropy: 3.91932
Value Function Loss: 0.00648

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.22972
Value Function Update Magnitude: 0.31375

Collected Steps per Second: 21,846.55292
Overall Steps per Second: 10,506.28337

Timestep Collection Time: 2.29006
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.76191

Cumulative Model Updates: 376,774
Cumulative Timesteps: 3,142,344,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3142344834...
Checkpoint 3142344834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.35107
Policy Entropy: 3.89769
Value Function Loss: 0.00594

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.23418
Value Function Update Magnitude: 0.31701

Collected Steps per Second: 22,301.35559
Overall Steps per Second: 10,442.44886

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.54654
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.78892

Cumulative Model Updates: 376,780
Cumulative Timesteps: 3,142,394,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.64998
Policy Entropy: 3.92269
Value Function Loss: 0.00584

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.24241
Value Function Update Magnitude: 0.31841

Collected Steps per Second: 22,237.20731
Overall Steps per Second: 10,285.41185

Timestep Collection Time: 2.24875
Timestep Consumption Time: 2.61308
PPO Batch Consumption Time: 0.30883
Total Iteration Time: 4.86184

Cumulative Model Updates: 376,786
Cumulative Timesteps: 3,142,444,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3142444848...
Checkpoint 3142444848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.00994
Policy Entropy: 3.96030
Value Function Loss: 0.00494

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03016
Policy Update Magnitude: 0.23174
Value Function Update Magnitude: 0.31601

Collected Steps per Second: 19,565.09972
Overall Steps per Second: 9,706.21169

Timestep Collection Time: 2.55680
Timestep Consumption Time: 2.59702
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 5.15381

Cumulative Model Updates: 376,792
Cumulative Timesteps: 3,142,494,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.01087
Policy Entropy: 4.00824
Value Function Loss: 0.00529

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.22838
Value Function Update Magnitude: 0.32256

Collected Steps per Second: 20,164.73090
Overall Steps per Second: 9,962.37595

Timestep Collection Time: 2.48106
Timestep Consumption Time: 2.54083
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 5.02189

Cumulative Model Updates: 376,798
Cumulative Timesteps: 3,142,544,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3142544902...
Checkpoint 3142544902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10802
Policy Entropy: 3.98702
Value Function Loss: 0.00555

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02165
Policy Update Magnitude: 0.23209
Value Function Update Magnitude: 0.32505

Collected Steps per Second: 22,007.96935
Overall Steps per Second: 10,436.27864

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.79251

Cumulative Model Updates: 376,804
Cumulative Timesteps: 3,142,594,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.05553
Policy Entropy: 3.96609
Value Function Loss: 0.00634

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.23673
Value Function Update Magnitude: 0.32560

Collected Steps per Second: 19,908.23981
Overall Steps per Second: 10,061.34767

Timestep Collection Time: 2.51253
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.97150

Cumulative Model Updates: 376,810
Cumulative Timesteps: 3,142,644,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3142644938...
Checkpoint 3142644938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.44657
Policy Entropy: 3.92778
Value Function Loss: 0.00726

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02972
Policy Update Magnitude: 0.25154
Value Function Update Magnitude: 0.33031

Collected Steps per Second: 21,476.72675
Overall Steps per Second: 10,122.82854

Timestep Collection Time: 2.32922
Timestep Consumption Time: 2.61248
PPO Batch Consumption Time: 0.30456
Total Iteration Time: 4.94170

Cumulative Model Updates: 376,816
Cumulative Timesteps: 3,142,694,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.70230
Policy Entropy: 3.93283
Value Function Loss: 0.00734

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.25695
Value Function Update Magnitude: 0.34134

Collected Steps per Second: 19,178.68163
Overall Steps per Second: 9,645.53228

Timestep Collection Time: 2.60748
Timestep Consumption Time: 2.57710
PPO Batch Consumption Time: 0.30604
Total Iteration Time: 5.18458

Cumulative Model Updates: 376,822
Cumulative Timesteps: 3,142,744,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3142744970...
Checkpoint 3142744970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.93853
Policy Entropy: 3.92561
Value Function Loss: 0.00810

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 0.25809
Value Function Update Magnitude: 0.36278

Collected Steps per Second: 21,600.45330
Overall Steps per Second: 10,419.96753

Timestep Collection Time: 2.31514
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.30134
Total Iteration Time: 4.79925

Cumulative Model Updates: 376,828
Cumulative Timesteps: 3,142,794,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.18483
Policy Entropy: 3.94525
Value Function Loss: 0.00733

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.03878
Policy Update Magnitude: 0.25546
Value Function Update Magnitude: 0.35288

Collected Steps per Second: 21,592.43589
Overall Steps per Second: 9,985.06014

Timestep Collection Time: 2.31627
Timestep Consumption Time: 2.69261
PPO Batch Consumption Time: 0.31966
Total Iteration Time: 5.00888

Cumulative Model Updates: 376,834
Cumulative Timesteps: 3,142,844,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3142844992...
Checkpoint 3142844992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.41458
Policy Entropy: 3.94546
Value Function Loss: 0.00680

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 0.24325
Value Function Update Magnitude: 0.33077

Collected Steps per Second: 21,017.83062
Overall Steps per Second: 10,016.09779

Timestep Collection Time: 2.38045
Timestep Consumption Time: 2.61470
PPO Batch Consumption Time: 0.31076
Total Iteration Time: 4.99516

Cumulative Model Updates: 376,840
Cumulative Timesteps: 3,142,895,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73787
Policy Entropy: 3.95614
Value Function Loss: 0.00716

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.03681
Policy Update Magnitude: 0.25630
Value Function Update Magnitude: 0.32776

Collected Steps per Second: 20,491.89478
Overall Steps per Second: 9,740.60603

Timestep Collection Time: 2.44097
Timestep Consumption Time: 2.69424
PPO Batch Consumption Time: 0.31266
Total Iteration Time: 5.13520

Cumulative Model Updates: 376,846
Cumulative Timesteps: 3,142,945,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3142945044...
Checkpoint 3142945044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.58309
Policy Entropy: 3.96821
Value Function Loss: 0.00720

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 0.25042
Value Function Update Magnitude: 0.33194

Collected Steps per Second: 20,948.13801
Overall Steps per Second: 10,096.84402

Timestep Collection Time: 2.38752
Timestep Consumption Time: 2.56591
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.95343

Cumulative Model Updates: 376,852
Cumulative Timesteps: 3,142,995,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.86073
Policy Entropy: 3.95927
Value Function Loss: 0.00807

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.25844
Value Function Update Magnitude: 0.34688

Collected Steps per Second: 21,378.49398
Overall Steps per Second: 10,418.72805

Timestep Collection Time: 2.33955
Timestep Consumption Time: 2.46104
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.80059

Cumulative Model Updates: 376,858
Cumulative Timesteps: 3,143,045,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3143045074...
Checkpoint 3143045074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.00744
Policy Entropy: 3.92892
Value Function Loss: 0.00750

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.25887
Value Function Update Magnitude: 0.35860

Collected Steps per Second: 21,042.60836
Overall Steps per Second: 10,228.77450

Timestep Collection Time: 2.37680
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.88954

Cumulative Model Updates: 376,864
Cumulative Timesteps: 3,143,095,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.53777
Policy Entropy: 3.89799
Value Function Loss: 0.00757

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.03614
Policy Update Magnitude: 0.25121
Value Function Update Magnitude: 0.35844

Collected Steps per Second: 22,333.61942
Overall Steps per Second: 10,540.35149

Timestep Collection Time: 2.23949
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.74519

Cumulative Model Updates: 376,870
Cumulative Timesteps: 3,143,145,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3143145104...
Checkpoint 3143145104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.69992
Policy Entropy: 3.91445
Value Function Loss: 0.00736

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.24962
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 22,223.25042
Overall Steps per Second: 10,574.90782

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.72817

Cumulative Model Updates: 376,876
Cumulative Timesteps: 3,143,195,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.12451
Policy Entropy: 3.90349
Value Function Loss: 0.00721

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.24807
Value Function Update Magnitude: 0.34017

Collected Steps per Second: 21,052.90543
Overall Steps per Second: 10,306.17267

Timestep Collection Time: 2.37544
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.85243

Cumulative Model Updates: 376,882
Cumulative Timesteps: 3,143,245,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3143245114...
Checkpoint 3143245114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.10634
Policy Entropy: 3.89466
Value Function Loss: 0.00729

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 0.25387
Value Function Update Magnitude: 0.35683

Collected Steps per Second: 22,197.39970
Overall Steps per Second: 10,610.19411

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.71509

Cumulative Model Updates: 376,888
Cumulative Timesteps: 3,143,295,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.45917
Policy Entropy: 3.88795
Value Function Loss: 0.00676

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 0.25176
Value Function Update Magnitude: 0.36680

Collected Steps per Second: 22,893.48073
Overall Steps per Second: 10,856.28533

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.60692

Cumulative Model Updates: 376,894
Cumulative Timesteps: 3,143,345,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3143345156...
Checkpoint 3143345156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39145
Policy Entropy: 3.93753
Value Function Loss: 0.00618

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.24532
Value Function Update Magnitude: 0.35435

Collected Steps per Second: 20,338.40494
Overall Steps per Second: 10,110.51053

Timestep Collection Time: 2.45919
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.94693

Cumulative Model Updates: 376,900
Cumulative Timesteps: 3,143,395,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.89516
Policy Entropy: 3.93325
Value Function Loss: 0.00642

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03071
Policy Update Magnitude: 0.23819
Value Function Update Magnitude: 0.34710

Collected Steps per Second: 19,992.71909
Overall Steps per Second: 9,856.96366

Timestep Collection Time: 2.50161
Timestep Consumption Time: 2.57237
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 5.07398

Cumulative Model Updates: 376,906
Cumulative Timesteps: 3,143,445,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3143445186...
Checkpoint 3143445186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.61083
Policy Entropy: 3.89217
Value Function Loss: 0.00709

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03034
Policy Update Magnitude: 0.24861
Value Function Update Magnitude: 0.36620

Collected Steps per Second: 19,329.28360
Overall Steps per Second: 9,574.83876

Timestep Collection Time: 2.58758
Timestep Consumption Time: 2.63611
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 5.22369

Cumulative Model Updates: 376,912
Cumulative Timesteps: 3,143,495,202

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.66862
Policy Entropy: 3.85801
Value Function Loss: 0.00724

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.25753
Value Function Update Magnitude: 0.38911

Collected Steps per Second: 21,750.94357
Overall Steps per Second: 10,399.54535

Timestep Collection Time: 2.29995
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.81040

Cumulative Model Updates: 376,918
Cumulative Timesteps: 3,143,545,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3143545228...
Checkpoint 3143545228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.30731
Policy Entropy: 3.90105
Value Function Loss: 0.00728

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 0.25321
Value Function Update Magnitude: 0.39069

Collected Steps per Second: 20,790.25069
Overall Steps per Second: 10,368.11773

Timestep Collection Time: 2.40545
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.82344

Cumulative Model Updates: 376,924
Cumulative Timesteps: 3,143,595,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.37667
Policy Entropy: 3.96353
Value Function Loss: 0.00640

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.23985
Value Function Update Magnitude: 0.36098

Collected Steps per Second: 21,409.84611
Overall Steps per Second: 10,245.53580

Timestep Collection Time: 2.33603
Timestep Consumption Time: 2.54551
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.88154

Cumulative Model Updates: 376,930
Cumulative Timesteps: 3,143,645,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3143645252...
Checkpoint 3143645252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.04557
Policy Entropy: 3.99842
Value Function Loss: 0.00642

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.23170
Value Function Update Magnitude: 0.34059

Collected Steps per Second: 21,991.52492
Overall Steps per Second: 10,380.99273

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.54350
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.81765

Cumulative Model Updates: 376,936
Cumulative Timesteps: 3,143,695,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.02151
Policy Entropy: 3.98574
Value Function Loss: 0.00619

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.23332
Value Function Update Magnitude: 0.33911

Collected Steps per Second: 20,051.03718
Overall Steps per Second: 10,069.02287

Timestep Collection Time: 2.49453
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 4.96751

Cumulative Model Updates: 376,942
Cumulative Timesteps: 3,143,745,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3143745282...
Checkpoint 3143745282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.04365
Policy Entropy: 3.95427
Value Function Loss: 0.00752

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.24081
Value Function Update Magnitude: 0.35511

Collected Steps per Second: 21,682.20153
Overall Steps per Second: 10,239.85860

Timestep Collection Time: 2.30650
Timestep Consumption Time: 2.57736
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.88386

Cumulative Model Updates: 376,948
Cumulative Timesteps: 3,143,795,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88036
Policy Entropy: 3.89875
Value Function Loss: 0.00708

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.25316
Value Function Update Magnitude: 0.36826

Collected Steps per Second: 20,315.35758
Overall Steps per Second: 9,914.89261

Timestep Collection Time: 2.46198
Timestep Consumption Time: 2.58255
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 5.04453

Cumulative Model Updates: 376,954
Cumulative Timesteps: 3,143,845,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3143845308...
Checkpoint 3143845308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.32517
Policy Entropy: 3.88669
Value Function Loss: 0.00725

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.25619
Value Function Update Magnitude: 0.37020

Collected Steps per Second: 22,403.93105
Overall Steps per Second: 10,486.71327

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.53720
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.76985

Cumulative Model Updates: 376,960
Cumulative Timesteps: 3,143,895,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.35725
Policy Entropy: 3.89734
Value Function Loss: 0.00649

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.24960
Value Function Update Magnitude: 0.36150

Collected Steps per Second: 19,712.73522
Overall Steps per Second: 9,332.67877

Timestep Collection Time: 2.53755
Timestep Consumption Time: 2.82233
PPO Batch Consumption Time: 0.31632
Total Iteration Time: 5.35988

Cumulative Model Updates: 376,966
Cumulative Timesteps: 3,143,945,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3143945350...
Checkpoint 3143945350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.58712
Policy Entropy: 3.95621
Value Function Loss: 0.00597

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.24566
Value Function Update Magnitude: 0.34838

Collected Steps per Second: 18,728.28070
Overall Steps per Second: 9,414.41843

Timestep Collection Time: 2.67104
Timestep Consumption Time: 2.64251
PPO Batch Consumption Time: 0.31864
Total Iteration Time: 5.31355

Cumulative Model Updates: 376,972
Cumulative Timesteps: 3,143,995,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.37959
Policy Entropy: 3.96357
Value Function Loss: 0.00594

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.32691

Collected Steps per Second: 20,337.91502
Overall Steps per Second: 9,838.36898

Timestep Collection Time: 2.45915
Timestep Consumption Time: 2.62442
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 5.08357

Cumulative Model Updates: 376,978
Cumulative Timesteps: 3,144,045,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3144045388...
Checkpoint 3144045388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.29218
Policy Entropy: 3.96585
Value Function Loss: 0.00495

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.23460
Value Function Update Magnitude: 0.30742

Collected Steps per Second: 21,436.73168
Overall Steps per Second: 10,190.87856

Timestep Collection Time: 2.33291
Timestep Consumption Time: 2.57442
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.90733

Cumulative Model Updates: 376,984
Cumulative Timesteps: 3,144,095,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.30498
Policy Entropy: 3.94042
Value Function Loss: 0.00581

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.22867
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 19,626.37134
Overall Steps per Second: 10,027.67607

Timestep Collection Time: 2.54810
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.98720

Cumulative Model Updates: 376,990
Cumulative Timesteps: 3,144,145,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3144145408...
Checkpoint 3144145408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.87164
Policy Entropy: 3.94497
Value Function Loss: 0.00577

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.23110
Value Function Update Magnitude: 0.33072

Collected Steps per Second: 21,183.25920
Overall Steps per Second: 10,408.85782

Timestep Collection Time: 2.36139
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.80571

Cumulative Model Updates: 376,996
Cumulative Timesteps: 3,144,195,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.39240
Policy Entropy: 3.92190
Value Function Loss: 0.00724

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.24169
Value Function Update Magnitude: 0.35191

Collected Steps per Second: 21,326.38703
Overall Steps per Second: 10,267.46152

Timestep Collection Time: 2.34592
Timestep Consumption Time: 2.52675
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.87267

Cumulative Model Updates: 377,002
Cumulative Timesteps: 3,144,245,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3144245460...
Checkpoint 3144245460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.09218
Policy Entropy: 3.96212
Value Function Loss: 0.00641

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.24060
Value Function Update Magnitude: 0.36156

Collected Steps per Second: 22,210.25617
Overall Steps per Second: 10,848.74655

Timestep Collection Time: 2.25211
Timestep Consumption Time: 2.35856
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61067

Cumulative Model Updates: 377,008
Cumulative Timesteps: 3,144,295,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.09982
Policy Entropy: 3.94143
Value Function Loss: 0.00649

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.24176
Value Function Update Magnitude: 0.36079

Collected Steps per Second: 22,313.59291
Overall Steps per Second: 10,468.38682

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.53550
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77629

Cumulative Model Updates: 377,014
Cumulative Timesteps: 3,144,345,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3144345480...
Checkpoint 3144345480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04483
Policy Entropy: 4.00582
Value Function Loss: 0.00561

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.23265
Value Function Update Magnitude: 0.33994

Collected Steps per Second: 20,414.92501
Overall Steps per Second: 10,357.92655

Timestep Collection Time: 2.45046
Timestep Consumption Time: 2.37927
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.82973

Cumulative Model Updates: 377,020
Cumulative Timesteps: 3,144,395,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.53032
Policy Entropy: 3.98700
Value Function Loss: 0.00540

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.21556
Value Function Update Magnitude: 0.32194

Collected Steps per Second: 20,813.36341
Overall Steps per Second: 9,888.06269

Timestep Collection Time: 2.40403
Timestep Consumption Time: 2.65621
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 5.06024

Cumulative Model Updates: 377,026
Cumulative Timesteps: 3,144,445,542

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3144445542...
Checkpoint 3144445542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.75875
Policy Entropy: 4.01764
Value Function Loss: 0.00584

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.22136
Value Function Update Magnitude: 0.32479

Collected Steps per Second: 21,042.34652
Overall Steps per Second: 10,242.23475

Timestep Collection Time: 2.37749
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.88448

Cumulative Model Updates: 377,032
Cumulative Timesteps: 3,144,495,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.75329
Policy Entropy: 3.96124
Value Function Loss: 0.00613

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.22659
Value Function Update Magnitude: 0.34316

Collected Steps per Second: 21,021.60478
Overall Steps per Second: 10,334.99891

Timestep Collection Time: 2.37974
Timestep Consumption Time: 2.46070
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.84045

Cumulative Model Updates: 377,038
Cumulative Timesteps: 3,144,545,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3144545596...
Checkpoint 3144545596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.35035
Policy Entropy: 3.90494
Value Function Loss: 0.00684

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.24363
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 20,587.57821
Overall Steps per Second: 10,317.24050

Timestep Collection Time: 2.42962
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.84820

Cumulative Model Updates: 377,044
Cumulative Timesteps: 3,144,595,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.96737
Policy Entropy: 3.87170
Value Function Loss: 0.00660

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.03808
Policy Update Magnitude: 0.26049
Value Function Update Magnitude: 0.36672

Collected Steps per Second: 20,618.79467
Overall Steps per Second: 10,118.86419

Timestep Collection Time: 2.42604
Timestep Consumption Time: 2.51740
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.94344

Cumulative Model Updates: 377,050
Cumulative Timesteps: 3,144,645,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3144645638...
Checkpoint 3144645638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.71355
Policy Entropy: 3.90202
Value Function Loss: 0.00639

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.25049
Value Function Update Magnitude: 0.35718

Collected Steps per Second: 18,817.54858
Overall Steps per Second: 9,677.89085

Timestep Collection Time: 2.65869
Timestep Consumption Time: 2.51083
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 5.16951

Cumulative Model Updates: 377,056
Cumulative Timesteps: 3,144,695,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69850
Policy Entropy: 3.93684
Value Function Loss: 0.00640

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02798
Policy Update Magnitude: 0.24184
Value Function Update Magnitude: 0.34223

Collected Steps per Second: 17,902.64139
Overall Steps per Second: 9,542.30003

Timestep Collection Time: 2.79389
Timestep Consumption Time: 2.44782
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 5.24171

Cumulative Model Updates: 377,062
Cumulative Timesteps: 3,144,745,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3144745686...
Checkpoint 3144745686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.86071
Policy Entropy: 3.96583
Value Function Loss: 0.00593

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.24259
Value Function Update Magnitude: 0.34664

Collected Steps per Second: 20,128.48838
Overall Steps per Second: 9,399.23293

Timestep Collection Time: 2.48424
Timestep Consumption Time: 2.83577
PPO Batch Consumption Time: 0.33010
Total Iteration Time: 5.32001

Cumulative Model Updates: 377,068
Cumulative Timesteps: 3,144,795,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82330
Policy Entropy: 3.99236
Value Function Loss: 0.00595

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.24203
Value Function Update Magnitude: 0.34207

Collected Steps per Second: 16,801.67432
Overall Steps per Second: 9,210.31809

Timestep Collection Time: 2.97625
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 5.42935

Cumulative Model Updates: 377,074
Cumulative Timesteps: 3,144,845,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3144845696...
Checkpoint 3144845696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70880
Policy Entropy: 3.97552
Value Function Loss: 0.00677

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.23827
Value Function Update Magnitude: 0.34536

Collected Steps per Second: 21,955.47216
Overall Steps per Second: 10,393.08468

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.53487
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.81339

Cumulative Model Updates: 377,080
Cumulative Timesteps: 3,144,895,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53213
Policy Entropy: 3.98212
Value Function Loss: 0.00656

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.25128
Value Function Update Magnitude: 0.36584

Collected Steps per Second: 21,314.22161
Overall Steps per Second: 10,086.08601

Timestep Collection Time: 2.34679
Timestep Consumption Time: 2.61252
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.95931

Cumulative Model Updates: 377,086
Cumulative Timesteps: 3,144,945,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3144945742...
Checkpoint 3144945742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.76681
Policy Entropy: 4.00972
Value Function Loss: 0.00600

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.24142
Value Function Update Magnitude: 0.34659

Collected Steps per Second: 20,268.14312
Overall Steps per Second: 10,059.73306

Timestep Collection Time: 2.46841
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.97329

Cumulative Model Updates: 377,092
Cumulative Timesteps: 3,144,995,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.09706
Policy Entropy: 4.00621
Value Function Loss: 0.00516

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.22667
Value Function Update Magnitude: 0.31021

Collected Steps per Second: 21,653.84429
Overall Steps per Second: 10,380.46266

Timestep Collection Time: 2.30934
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.81732

Cumulative Model Updates: 377,098
Cumulative Timesteps: 3,145,045,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3145045778...
Checkpoint 3145045778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.41743
Policy Entropy: 3.96945
Value Function Loss: 0.00599

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.22427
Value Function Update Magnitude: 0.30465

Collected Steps per Second: 22,002.80625
Overall Steps per Second: 10,374.78006

Timestep Collection Time: 2.27271
Timestep Consumption Time: 2.54725
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.81996

Cumulative Model Updates: 377,104
Cumulative Timesteps: 3,145,095,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.29256
Policy Entropy: 3.91702
Value Function Loss: 0.00604

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03168
Policy Update Magnitude: 0.22887
Value Function Update Magnitude: 0.32942

Collected Steps per Second: 21,207.81197
Overall Steps per Second: 10,265.15689

Timestep Collection Time: 2.35941
Timestep Consumption Time: 2.51513
PPO Batch Consumption Time: 0.30601
Total Iteration Time: 4.87455

Cumulative Model Updates: 377,110
Cumulative Timesteps: 3,145,145,822

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3145145822...
Checkpoint 3145145822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.94234
Policy Entropy: 3.94629
Value Function Loss: 0.00650

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.23249
Value Function Update Magnitude: 0.33624

Collected Steps per Second: 21,551.51707
Overall Steps per Second: 10,335.54250

Timestep Collection Time: 2.32095
Timestep Consumption Time: 2.51866
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.83961

Cumulative Model Updates: 377,116
Cumulative Timesteps: 3,145,195,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.43507
Policy Entropy: 3.96287
Value Function Loss: 0.00613

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.23655
Value Function Update Magnitude: 0.32546

Collected Steps per Second: 22,611.16209
Overall Steps per Second: 10,506.05451

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.54919
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.76164

Cumulative Model Updates: 377,122
Cumulative Timesteps: 3,145,245,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3145245868...
Checkpoint 3145245868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.40158
Policy Entropy: 3.95086
Value Function Loss: 0.00672

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.24065
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 20,255.43404
Overall Steps per Second: 10,236.23343

Timestep Collection Time: 2.46976
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.88715

Cumulative Model Updates: 377,128
Cumulative Timesteps: 3,145,295,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.76947
Policy Entropy: 3.93210
Value Function Loss: 0.00619

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.24923
Value Function Update Magnitude: 0.34525

Collected Steps per Second: 22,747.92454
Overall Steps per Second: 10,771.79428

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.64249

Cumulative Model Updates: 377,134
Cumulative Timesteps: 3,145,345,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3145345902...
Checkpoint 3145345902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.30593
Policy Entropy: 3.95909
Value Function Loss: 0.00644

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.25002
Value Function Update Magnitude: 0.34954

Collected Steps per Second: 20,924.24084
Overall Steps per Second: 10,223.88443

Timestep Collection Time: 2.39043
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.89227

Cumulative Model Updates: 377,140
Cumulative Timesteps: 3,145,395,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.74956
Policy Entropy: 3.97093
Value Function Loss: 0.00580

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.23209
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 22,540.76369
Overall Steps per Second: 10,917.78155

Timestep Collection Time: 2.21865
Timestep Consumption Time: 2.36195
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58060

Cumulative Model Updates: 377,146
Cumulative Timesteps: 3,145,445,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3145445930...
Checkpoint 3145445930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.53056
Policy Entropy: 3.97957
Value Function Loss: 0.00548

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.22461
Value Function Update Magnitude: 0.32626

Collected Steps per Second: 22,278.22719
Overall Steps per Second: 10,636.32511

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.70125

Cumulative Model Updates: 377,152
Cumulative Timesteps: 3,145,495,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.93523
Policy Entropy: 3.94738
Value Function Loss: 0.00502

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.22109
Value Function Update Magnitude: 0.31357

Collected Steps per Second: 22,236.36807
Overall Steps per Second: 10,553.05221

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.49069
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.74043

Cumulative Model Updates: 377,158
Cumulative Timesteps: 3,145,545,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3145545960...
Checkpoint 3145545960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.22137
Policy Entropy: 3.94667
Value Function Loss: 0.00481

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.22295
Value Function Update Magnitude: 0.31211

Collected Steps per Second: 20,728.06553
Overall Steps per Second: 10,413.66690

Timestep Collection Time: 2.41325
Timestep Consumption Time: 2.39025
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.80350

Cumulative Model Updates: 377,164
Cumulative Timesteps: 3,145,595,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.45544
Policy Entropy: 3.92695
Value Function Loss: 0.00558

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02228
Policy Update Magnitude: 0.22108
Value Function Update Magnitude: 0.31577

Collected Steps per Second: 22,248.77338
Overall Steps per Second: 10,520.92899

Timestep Collection Time: 2.24857
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.75509

Cumulative Model Updates: 377,170
Cumulative Timesteps: 3,145,646,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3145646010...
Checkpoint 3145646010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.16060
Policy Entropy: 3.90423
Value Function Loss: 0.00665

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02366
Policy Update Magnitude: 0.23312
Value Function Update Magnitude: 0.32993

Collected Steps per Second: 20,827.57849
Overall Steps per Second: 10,017.26101

Timestep Collection Time: 2.40124
Timestep Consumption Time: 2.59134
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.99258

Cumulative Model Updates: 377,176
Cumulative Timesteps: 3,145,696,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.44437
Policy Entropy: 3.86084
Value Function Loss: 0.00777

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.24680
Value Function Update Magnitude: 0.35034

Collected Steps per Second: 22,297.33012
Overall Steps per Second: 10,730.64067

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.66198

Cumulative Model Updates: 377,182
Cumulative Timesteps: 3,145,746,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3145746048...
Checkpoint 3145746048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.99182
Policy Entropy: 3.85662
Value Function Loss: 0.00797

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03151
Policy Update Magnitude: 0.26231
Value Function Update Magnitude: 0.36278

Collected Steps per Second: 20,131.65382
Overall Steps per Second: 10,012.66465

Timestep Collection Time: 2.48474
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.99587

Cumulative Model Updates: 377,188
Cumulative Timesteps: 3,145,796,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.25990
Policy Entropy: 3.83792
Value Function Loss: 0.00775

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 0.25860
Value Function Update Magnitude: 0.37664

Collected Steps per Second: 22,745.54906
Overall Steps per Second: 10,683.33297

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.68356

Cumulative Model Updates: 377,194
Cumulative Timesteps: 3,145,846,106

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3145846106...
Checkpoint 3145846106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.94672
Policy Entropy: 3.89975
Value Function Loss: 0.00655

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03144
Policy Update Magnitude: 0.25280
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 22,298.57479
Overall Steps per Second: 10,572.50747

Timestep Collection Time: 2.24310
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.73095

Cumulative Model Updates: 377,200
Cumulative Timesteps: 3,145,896,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86499
Policy Entropy: 3.93054
Value Function Loss: 0.00632

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02966
Policy Update Magnitude: 0.24523
Value Function Update Magnitude: 0.35263

Collected Steps per Second: 20,424.78722
Overall Steps per Second: 10,097.24413

Timestep Collection Time: 2.44840
Timestep Consumption Time: 2.50424
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.95264

Cumulative Model Updates: 377,206
Cumulative Timesteps: 3,145,946,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3145946132...
Checkpoint 3145946132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.57168
Policy Entropy: 3.97460
Value Function Loss: 0.00623

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.23631
Value Function Update Magnitude: 0.34310

Collected Steps per Second: 19,600.69568
Overall Steps per Second: 9,947.47258

Timestep Collection Time: 2.55185
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 5.02821

Cumulative Model Updates: 377,212
Cumulative Timesteps: 3,145,996,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.11832
Policy Entropy: 3.95286
Value Function Loss: 0.00660

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.23681
Value Function Update Magnitude: 0.34093

Collected Steps per Second: 22,919.45969
Overall Steps per Second: 10,794.36277

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.63205

Cumulative Model Updates: 377,218
Cumulative Timesteps: 3,146,046,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3146046150...
Checkpoint 3146046150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.12629
Policy Entropy: 3.94708
Value Function Loss: 0.00700

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.23324
Value Function Update Magnitude: 0.33517

Collected Steps per Second: 21,133.02903
Overall Steps per Second: 10,232.83054

Timestep Collection Time: 2.36776
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.88995

Cumulative Model Updates: 377,224
Cumulative Timesteps: 3,146,096,188

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.10287
Policy Entropy: 3.99541
Value Function Loss: 0.00606

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.22490
Value Function Update Magnitude: 0.32571

Collected Steps per Second: 20,701.60318
Overall Steps per Second: 10,269.16259

Timestep Collection Time: 2.41547
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.86934

Cumulative Model Updates: 377,230
Cumulative Timesteps: 3,146,146,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3146146192...
Checkpoint 3146146192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.16669
Policy Entropy: 4.01971
Value Function Loss: 0.00569

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.22666
Value Function Update Magnitude: 0.30171

Collected Steps per Second: 21,006.57455
Overall Steps per Second: 10,360.69667

Timestep Collection Time: 2.38021
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.82593

Cumulative Model Updates: 377,236
Cumulative Timesteps: 3,146,196,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.95355
Policy Entropy: 4.02124
Value Function Loss: 0.00515

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.22266
Value Function Update Magnitude: 0.29611

Collected Steps per Second: 20,451.25008
Overall Steps per Second: 10,153.13823

Timestep Collection Time: 2.44523
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.92537

Cumulative Model Updates: 377,242
Cumulative Timesteps: 3,146,246,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3146246200...
Checkpoint 3146246200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.97997
Policy Entropy: 4.00640
Value Function Loss: 0.00491

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.21558
Value Function Update Magnitude: 0.30896

Collected Steps per Second: 21,576.72389
Overall Steps per Second: 10,229.08888

Timestep Collection Time: 2.31787
Timestep Consumption Time: 2.57133
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.88919

Cumulative Model Updates: 377,248
Cumulative Timesteps: 3,146,296,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.36690
Policy Entropy: 3.98155
Value Function Loss: 0.00593

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.21358
Value Function Update Magnitude: 0.32079

Collected Steps per Second: 21,172.94402
Overall Steps per Second: 9,866.73244

Timestep Collection Time: 2.36264
Timestep Consumption Time: 2.70733
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 5.06997

Cumulative Model Updates: 377,254
Cumulative Timesteps: 3,146,346,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3146346236...
Checkpoint 3146346236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.72519
Policy Entropy: 3.99159
Value Function Loss: 0.00607

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.22568
Value Function Update Magnitude: 0.33621

Collected Steps per Second: 20,591.92524
Overall Steps per Second: 10,413.48236

Timestep Collection Time: 2.42950
Timestep Consumption Time: 2.37466
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.80416

Cumulative Model Updates: 377,260
Cumulative Timesteps: 3,146,396,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.89305
Policy Entropy: 3.95816
Value Function Loss: 0.00621

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.22718
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 22,755.22039
Overall Steps per Second: 10,736.50695

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.65906

Cumulative Model Updates: 377,266
Cumulative Timesteps: 3,146,446,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3146446286...
Checkpoint 3146446286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.43158
Policy Entropy: 3.96726
Value Function Loss: 0.00629

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01971
Policy Update Magnitude: 0.22315
Value Function Update Magnitude: 0.32928

Collected Steps per Second: 20,770.01930
Overall Steps per Second: 10,185.88849

Timestep Collection Time: 2.40876
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.91170

Cumulative Model Updates: 377,272
Cumulative Timesteps: 3,146,496,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.66895
Policy Entropy: 3.96612
Value Function Loss: 0.00644

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.23017
Value Function Update Magnitude: 0.33659

Collected Steps per Second: 20,972.99972
Overall Steps per Second: 9,875.13886

Timestep Collection Time: 2.38421
Timestep Consumption Time: 2.67942
PPO Batch Consumption Time: 0.30826
Total Iteration Time: 5.06363

Cumulative Model Updates: 377,278
Cumulative Timesteps: 3,146,546,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3146546320...
Checkpoint 3146546320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.20563
Policy Entropy: 3.96060
Value Function Loss: 0.00608

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.23135
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 22,713.93679
Overall Steps per Second: 10,595.35011

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.72169

Cumulative Model Updates: 377,284
Cumulative Timesteps: 3,146,596,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.08038
Policy Entropy: 3.95115
Value Function Loss: 0.00594

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 0.23409
Value Function Update Magnitude: 0.34774

Collected Steps per Second: 21,877.20675
Overall Steps per Second: 10,382.41120

Timestep Collection Time: 2.28631
Timestep Consumption Time: 2.53126
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.81757

Cumulative Model Updates: 377,290
Cumulative Timesteps: 3,146,646,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3146646366...
Checkpoint 3146646366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.69104
Policy Entropy: 3.92390
Value Function Loss: 0.00616

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.23241
Value Function Update Magnitude: 0.34081

Collected Steps per Second: 22,008.52135
Overall Steps per Second: 10,547.64363

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.74191

Cumulative Model Updates: 377,296
Cumulative Timesteps: 3,146,696,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.88614
Policy Entropy: 3.92350
Value Function Loss: 0.00658

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.23858
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 23,216.15920
Overall Steps per Second: 10,738.64181

Timestep Collection Time: 2.15488
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.65869

Cumulative Model Updates: 377,302
Cumulative Timesteps: 3,146,746,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3146746410...
Checkpoint 3146746410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.29889
Policy Entropy: 3.90136
Value Function Loss: 0.00745

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.24558
Value Function Update Magnitude: 0.34586

Collected Steps per Second: 21,804.72701
Overall Steps per Second: 10,428.98860

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.79548

Cumulative Model Updates: 377,308
Cumulative Timesteps: 3,146,796,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.09271
Policy Entropy: 3.94155
Value Function Loss: 0.00742

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.25765
Value Function Update Magnitude: 0.34425

Collected Steps per Second: 21,857.38565
Overall Steps per Second: 10,379.00554

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.53037
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.81838

Cumulative Model Updates: 377,314
Cumulative Timesteps: 3,146,846,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3146846432...
Checkpoint 3146846432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.48792
Policy Entropy: 3.92534
Value Function Loss: 0.00736

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.25185
Value Function Update Magnitude: 0.34446

Collected Steps per Second: 20,308.87795
Overall Steps per Second: 10,039.46731

Timestep Collection Time: 2.46326
Timestep Consumption Time: 2.51968
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.98293

Cumulative Model Updates: 377,320
Cumulative Timesteps: 3,146,896,458

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.80767
Policy Entropy: 3.91717
Value Function Loss: 0.00718

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.24520
Value Function Update Magnitude: 0.35544

Collected Steps per Second: 22,267.52046
Overall Steps per Second: 10,446.48126

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.54098
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.78649

Cumulative Model Updates: 377,326
Cumulative Timesteps: 3,146,946,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3146946460...
Checkpoint 3146946460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.24825
Policy Entropy: 3.92679
Value Function Loss: 0.00608

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.23255
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 22,158.39557
Overall Steps per Second: 10,303.87446

Timestep Collection Time: 2.25684
Timestep Consumption Time: 2.59648
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.85332

Cumulative Model Updates: 377,332
Cumulative Timesteps: 3,146,996,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.98635
Policy Entropy: 3.95220
Value Function Loss: 0.00588

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01973
Policy Update Magnitude: 0.22494
Value Function Update Magnitude: 0.36417

Collected Steps per Second: 21,255.35686
Overall Steps per Second: 10,335.53208

Timestep Collection Time: 2.35357
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.84020

Cumulative Model Updates: 377,338
Cumulative Timesteps: 3,147,046,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3147046494...
Checkpoint 3147046494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.85328
Policy Entropy: 4.00161
Value Function Loss: 0.00595

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.22849
Value Function Update Magnitude: 0.35153

Collected Steps per Second: 21,479.24530
Overall Steps per Second: 10,357.01024

Timestep Collection Time: 2.32904
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.83016

Cumulative Model Updates: 377,344
Cumulative Timesteps: 3,147,096,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.87848
Policy Entropy: 3.98044
Value Function Loss: 0.00703

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.23576
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 21,044.63282
Overall Steps per Second: 10,223.73531

Timestep Collection Time: 2.37695
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.89273

Cumulative Model Updates: 377,350
Cumulative Timesteps: 3,147,146,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3147146542...
Checkpoint 3147146542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.80256
Policy Entropy: 3.97806
Value Function Loss: 0.00728

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.24238
Value Function Update Magnitude: 0.36027

Collected Steps per Second: 22,187.59619
Overall Steps per Second: 10,400.85445

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.55440
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.80845

Cumulative Model Updates: 377,356
Cumulative Timesteps: 3,147,196,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.28443
Policy Entropy: 3.98983
Value Function Loss: 0.00644

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.23122
Value Function Update Magnitude: 0.35819

Collected Steps per Second: 22,187.43296
Overall Steps per Second: 10,611.44077

Timestep Collection Time: 2.25389
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.71265

Cumulative Model Updates: 377,362
Cumulative Timesteps: 3,147,246,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3147246562...
Checkpoint 3147246562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.88714
Policy Entropy: 3.96173
Value Function Loss: 0.00631

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.22606
Value Function Update Magnitude: 0.35043

Collected Steps per Second: 20,146.77270
Overall Steps per Second: 10,240.67196

Timestep Collection Time: 2.48308
Timestep Consumption Time: 2.40195
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.88503

Cumulative Model Updates: 377,368
Cumulative Timesteps: 3,147,296,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.12245
Policy Entropy: 3.97017
Value Function Loss: 0.00611

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02130
Policy Update Magnitude: 0.23056
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 21,586.23345
Overall Steps per Second: 10,235.21349

Timestep Collection Time: 2.31740
Timestep Consumption Time: 2.57004
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.88744

Cumulative Model Updates: 377,374
Cumulative Timesteps: 3,147,346,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3147346612...
Checkpoint 3147346612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.53132
Policy Entropy: 3.94276
Value Function Loss: 0.00670

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.23630
Value Function Update Magnitude: 0.32511

Collected Steps per Second: 21,519.55578
Overall Steps per Second: 10,055.34116

Timestep Collection Time: 2.32458
Timestep Consumption Time: 2.65029
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 4.97487

Cumulative Model Updates: 377,380
Cumulative Timesteps: 3,147,396,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.02478
Policy Entropy: 3.98344
Value Function Loss: 0.00529

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.23411
Value Function Update Magnitude: 0.32143

Collected Steps per Second: 21,707.15929
Overall Steps per Second: 10,584.71535

Timestep Collection Time: 2.30357
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.72417

Cumulative Model Updates: 377,386
Cumulative Timesteps: 3,147,446,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3147446640...
Checkpoint 3147446640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.60936
Policy Entropy: 4.00915
Value Function Loss: 0.00497

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.22165
Value Function Update Magnitude: 0.31022

Collected Steps per Second: 21,957.65291
Overall Steps per Second: 10,175.52299

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.63738
PPO Batch Consumption Time: 0.31066
Total Iteration Time: 4.91513

Cumulative Model Updates: 377,392
Cumulative Timesteps: 3,147,496,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.64402
Policy Entropy: 4.02911
Value Function Loss: 0.00497

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.22067
Value Function Update Magnitude: 0.29947

Collected Steps per Second: 21,673.73689
Overall Steps per Second: 10,229.75967

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.58128
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 4.88868

Cumulative Model Updates: 377,398
Cumulative Timesteps: 3,147,546,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3147546664...
Checkpoint 3147546664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32464
Policy Entropy: 4.04013
Value Function Loss: 0.00561

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.22201
Value Function Update Magnitude: 0.32037

Collected Steps per Second: 20,727.66464
Overall Steps per Second: 10,115.89673

Timestep Collection Time: 2.41397
Timestep Consumption Time: 2.53230
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.94627

Cumulative Model Updates: 377,404
Cumulative Timesteps: 3,147,596,700

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.43678
Policy Entropy: 3.98773
Value Function Loss: 0.00629

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.22874
Value Function Update Magnitude: 0.33074

Collected Steps per Second: 20,892.70747
Overall Steps per Second: 10,237.70488

Timestep Collection Time: 2.39481
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.88723

Cumulative Model Updates: 377,410
Cumulative Timesteps: 3,147,646,734

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3147646734...
Checkpoint 3147646734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.22892
Policy Entropy: 3.95458
Value Function Loss: 0.00619

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.23621
Value Function Update Magnitude: 0.33130

Collected Steps per Second: 20,506.40946
Overall Steps per Second: 10,201.12419

Timestep Collection Time: 2.44002
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.90495

Cumulative Model Updates: 377,416
Cumulative Timesteps: 3,147,696,770

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.82530
Policy Entropy: 3.92793
Value Function Loss: 0.00644

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.24039
Value Function Update Magnitude: 0.33350

Collected Steps per Second: 21,191.54779
Overall Steps per Second: 10,498.18776

Timestep Collection Time: 2.35962
Timestep Consumption Time: 2.40349
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.76311

Cumulative Model Updates: 377,422
Cumulative Timesteps: 3,147,746,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3147746774...
Checkpoint 3147746774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.78547
Policy Entropy: 3.93603
Value Function Loss: 0.00711

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.24272
Value Function Update Magnitude: 0.33743

Collected Steps per Second: 20,772.04138
Overall Steps per Second: 10,478.31936

Timestep Collection Time: 2.40804
Timestep Consumption Time: 2.36562
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.77367

Cumulative Model Updates: 377,428
Cumulative Timesteps: 3,147,796,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.47585
Policy Entropy: 3.93182
Value Function Loss: 0.00723

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03102
Policy Update Magnitude: 0.24842
Value Function Update Magnitude: 0.34713

Collected Steps per Second: 22,550.36157
Overall Steps per Second: 10,657.92721

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.69228

Cumulative Model Updates: 377,434
Cumulative Timesteps: 3,147,846,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3147846804...
Checkpoint 3147846804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.72343
Policy Entropy: 3.92275
Value Function Loss: 0.00698

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.25302
Value Function Update Magnitude: 0.34736

Collected Steps per Second: 21,630.69201
Overall Steps per Second: 10,474.44041

Timestep Collection Time: 2.31153
Timestep Consumption Time: 2.46199
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.77352

Cumulative Model Updates: 377,440
Cumulative Timesteps: 3,147,896,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.78294
Policy Entropy: 3.93360
Value Function Loss: 0.00695

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02792
Policy Update Magnitude: 0.24540
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 21,291.19186
Overall Steps per Second: 10,084.00751

Timestep Collection Time: 2.34848
Timestep Consumption Time: 2.61006
PPO Batch Consumption Time: 0.30732
Total Iteration Time: 4.95854

Cumulative Model Updates: 377,446
Cumulative Timesteps: 3,147,946,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3147946806...
Checkpoint 3147946806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.69381
Policy Entropy: 3.93952
Value Function Loss: 0.00710

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.24797
Value Function Update Magnitude: 0.33609

Collected Steps per Second: 22,809.37923
Overall Steps per Second: 10,910.66760

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.39059
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.58267

Cumulative Model Updates: 377,452
Cumulative Timesteps: 3,147,996,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.18103
Policy Entropy: 3.91840
Value Function Loss: 0.00817

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.25067
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 22,817.88468
Overall Steps per Second: 10,596.94282

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.72023

Cumulative Model Updates: 377,458
Cumulative Timesteps: 3,148,046,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3148046826...
Checkpoint 3148046826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.29904
Policy Entropy: 3.93291
Value Function Loss: 0.00760

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.25560
Value Function Update Magnitude: 0.36060

Collected Steps per Second: 21,516.26785
Overall Steps per Second: 10,164.36482

Timestep Collection Time: 2.32419
Timestep Consumption Time: 2.59574
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 4.91993

Cumulative Model Updates: 377,464
Cumulative Timesteps: 3,148,096,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.76799
Policy Entropy: 3.92594
Value Function Loss: 0.00753

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.25823
Value Function Update Magnitude: 0.35394

Collected Steps per Second: 21,789.84814
Overall Steps per Second: 10,615.69548

Timestep Collection Time: 2.29501
Timestep Consumption Time: 2.41575
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.71076

Cumulative Model Updates: 377,470
Cumulative Timesteps: 3,148,146,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3148146842...
Checkpoint 3148146842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.17644
Policy Entropy: 3.99034
Value Function Loss: 0.00611

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.23966
Value Function Update Magnitude: 0.34802

Collected Steps per Second: 21,078.53154
Overall Steps per Second: 10,051.56062

Timestep Collection Time: 2.37294
Timestep Consumption Time: 2.60321
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.97614

Cumulative Model Updates: 377,476
Cumulative Timesteps: 3,148,196,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.42856
Policy Entropy: 3.96569
Value Function Loss: 0.00633

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.23392
Value Function Update Magnitude: 0.34526

Collected Steps per Second: 21,120.62278
Overall Steps per Second: 10,114.95763

Timestep Collection Time: 2.36792
Timestep Consumption Time: 2.57644
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.94436

Cumulative Model Updates: 377,482
Cumulative Timesteps: 3,148,246,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3148246872...
Checkpoint 3148246872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.99216
Policy Entropy: 3.94013
Value Function Loss: 0.00727

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.24322
Value Function Update Magnitude: 0.34113

Collected Steps per Second: 21,244.04622
Overall Steps per Second: 10,299.04394

Timestep Collection Time: 2.35445
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.30342
Total Iteration Time: 4.85657

Cumulative Model Updates: 377,488
Cumulative Timesteps: 3,148,296,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.30747
Policy Entropy: 3.90784
Value Function Loss: 0.00745

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 0.25680
Value Function Update Magnitude: 0.35400

Collected Steps per Second: 21,407.79107
Overall Steps per Second: 10,328.71758

Timestep Collection Time: 2.33607
Timestep Consumption Time: 2.50577
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.84184

Cumulative Model Updates: 377,494
Cumulative Timesteps: 3,148,346,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3148346900...
Checkpoint 3148346900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.01676
Policy Entropy: 3.91496
Value Function Loss: 0.00721

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.03616
Policy Update Magnitude: 0.25664
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 19,575.60309
Overall Steps per Second: 9,809.42966

Timestep Collection Time: 2.55491
Timestep Consumption Time: 2.54365
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 5.09856

Cumulative Model Updates: 377,500
Cumulative Timesteps: 3,148,396,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.89240
Policy Entropy: 3.96381
Value Function Loss: 0.00586

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 0.24217
Value Function Update Magnitude: 0.34930

Collected Steps per Second: 22,385.94165
Overall Steps per Second: 10,691.14026

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.67883

Cumulative Model Updates: 377,506
Cumulative Timesteps: 3,148,446,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3148446936...
Checkpoint 3148446936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.49518
Policy Entropy: 3.97935
Value Function Loss: 0.00565

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.23315
Value Function Update Magnitude: 0.34690

Collected Steps per Second: 22,228.84100
Overall Steps per Second: 10,657.47566

Timestep Collection Time: 2.25050
Timestep Consumption Time: 2.44348
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.69398

Cumulative Model Updates: 377,512
Cumulative Timesteps: 3,148,496,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.92515
Policy Entropy: 3.96553
Value Function Loss: 0.00643

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.23269
Value Function Update Magnitude: 0.33499

Collected Steps per Second: 22,861.01842
Overall Steps per Second: 10,873.52018

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.41158
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.59906

Cumulative Model Updates: 377,518
Cumulative Timesteps: 3,148,546,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3148546970...
Checkpoint 3148546970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.59825
Policy Entropy: 3.93500
Value Function Loss: 0.00697

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.24279
Value Function Update Magnitude: 0.34627

Collected Steps per Second: 23,034.18759
Overall Steps per Second: 10,679.98373

Timestep Collection Time: 2.17164
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.68372

Cumulative Model Updates: 377,524
Cumulative Timesteps: 3,148,596,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.35377
Policy Entropy: 3.92455
Value Function Loss: 0.00692

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.24931
Value Function Update Magnitude: 0.35216

Collected Steps per Second: 22,263.95149
Overall Steps per Second: 10,506.70236

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76172

Cumulative Model Updates: 377,530
Cumulative Timesteps: 3,148,647,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3148647022...
Checkpoint 3148647022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.82053
Policy Entropy: 3.94685
Value Function Loss: 0.00661

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.24396
Value Function Update Magnitude: 0.33956

Collected Steps per Second: 22,465.62907
Overall Steps per Second: 10,899.84546

Timestep Collection Time: 2.22642
Timestep Consumption Time: 2.36245
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.58887

Cumulative Model Updates: 377,536
Cumulative Timesteps: 3,148,697,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.51763
Policy Entropy: 3.97052
Value Function Loss: 0.00651

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.23605
Value Function Update Magnitude: 0.34164

Collected Steps per Second: 22,593.50700
Overall Steps per Second: 10,591.46370

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.50926
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.72362

Cumulative Model Updates: 377,542
Cumulative Timesteps: 3,148,747,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3148747070...
Checkpoint 3148747070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.02166
Policy Entropy: 3.99498
Value Function Loss: 0.00590

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.24346
Value Function Update Magnitude: 0.34117

Collected Steps per Second: 22,678.60136
Overall Steps per Second: 10,674.34673

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68413

Cumulative Model Updates: 377,548
Cumulative Timesteps: 3,148,797,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.28244
Policy Entropy: 3.98287
Value Function Loss: 0.00565

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02880
Policy Update Magnitude: 0.23364
Value Function Update Magnitude: 0.32073

Collected Steps per Second: 22,865.50096
Overall Steps per Second: 10,804.97963

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62805

Cumulative Model Updates: 377,554
Cumulative Timesteps: 3,148,847,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3148847076...
Checkpoint 3148847076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.61970
Policy Entropy: 3.99287
Value Function Loss: 0.00599

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.23367
Value Function Update Magnitude: 0.32286

Collected Steps per Second: 22,549.80350
Overall Steps per Second: 10,656.69138

Timestep Collection Time: 2.21758
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.69245

Cumulative Model Updates: 377,560
Cumulative Timesteps: 3,148,897,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.25617
Policy Entropy: 3.96455
Value Function Loss: 0.00604

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 0.23629
Value Function Update Magnitude: 0.33887

Collected Steps per Second: 22,545.19110
Overall Steps per Second: 10,915.12863

Timestep Collection Time: 2.21901
Timestep Consumption Time: 2.36435
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.58336

Cumulative Model Updates: 377,566
Cumulative Timesteps: 3,148,947,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3148947110...
Checkpoint 3148947110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.44983
Policy Entropy: 3.95719
Value Function Loss: 0.00616

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.23780
Value Function Update Magnitude: 0.33690

Collected Steps per Second: 22,093.58743
Overall Steps per Second: 10,570.10015

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.73108

Cumulative Model Updates: 377,572
Cumulative Timesteps: 3,148,997,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.94785
Policy Entropy: 3.93239
Value Function Loss: 0.00712

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 0.25090
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 19,722.42709
Overall Steps per Second: 9,860.88285

Timestep Collection Time: 2.53610
Timestep Consumption Time: 2.53627
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 5.07237

Cumulative Model Updates: 377,578
Cumulative Timesteps: 3,149,047,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3149047136...
Checkpoint 3149047136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.27586
Policy Entropy: 3.93396
Value Function Loss: 0.00657

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.24852
Value Function Update Magnitude: 0.33615

Collected Steps per Second: 20,181.73731
Overall Steps per Second: 10,027.77313

Timestep Collection Time: 2.47858
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.98835

Cumulative Model Updates: 377,584
Cumulative Timesteps: 3,149,097,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.62094
Policy Entropy: 4.00305
Value Function Loss: 0.00644

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.24034
Value Function Update Magnitude: 0.33711

Collected Steps per Second: 19,662.90887
Overall Steps per Second: 9,915.98854

Timestep Collection Time: 2.54316
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 5.04297

Cumulative Model Updates: 377,590
Cumulative Timesteps: 3,149,147,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3149147164...
Checkpoint 3149147164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.32951
Policy Entropy: 3.99393
Value Function Loss: 0.00703

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.23733
Value Function Update Magnitude: 0.32951

Collected Steps per Second: 14,203.63498
Overall Steps per Second: 7,941.07530

Timestep Collection Time: 3.52121
Timestep Consumption Time: 2.77693
PPO Batch Consumption Time: 0.33386
Total Iteration Time: 6.29814

Cumulative Model Updates: 377,596
Cumulative Timesteps: 3,149,197,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3149197178...
Checkpoint 3149197178 saved!
