Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.54431
Policy Entropy: 2.16436
Value Function Loss: 0.01886

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.04320
Policy Update Magnitude: 0.21628
Value Function Update Magnitude: 0.18451

Collected Steps per Second: 20,219.76032
Overall Steps per Second: 12,897.50069

Timestep Collection Time: 2.47342
Timestep Consumption Time: 1.40423
PPO Batch Consumption Time: 0.34794
Total Iteration Time: 3.87765

Cumulative Model Updates: 226,020
Cumulative Timesteps: 1,884,992,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.16637
Policy Entropy: 2.12477
Value Function Loss: 0.01969

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.05737
Policy Update Magnitude: 0.23092
Value Function Update Magnitude: 0.18771

Collected Steps per Second: 22,487.90075
Overall Steps per Second: 13,858.17715

Timestep Collection Time: 2.22377
Timestep Consumption Time: 1.38478
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 3.60856

Cumulative Model Updates: 226,022
Cumulative Timesteps: 1,885,042,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1885042028...
Checkpoint 1885042028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.40739
Policy Entropy: 2.14227
Value Function Loss: 0.01852

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.45232
Value Function Update Magnitude: 0.37326

Collected Steps per Second: 22,482.66617
Overall Steps per Second: 11,961.03200

Timestep Collection Time: 2.22483
Timestep Consumption Time: 1.95709
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.18191

Cumulative Model Updates: 226,026
Cumulative Timesteps: 1,885,092,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.48859
Policy Entropy: 2.12788
Value Function Loss: 0.01705

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.63414
Value Function Update Magnitude: 0.57281

Collected Steps per Second: 22,040.50953
Overall Steps per Second: 10,613.24322

Timestep Collection Time: 2.26964
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71336

Cumulative Model Updates: 226,032
Cumulative Timesteps: 1,885,142,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1885142072...
Checkpoint 1885142072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.43736
Policy Entropy: 2.12688
Value Function Loss: 0.01679

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.59484
Value Function Update Magnitude: 0.55696

Collected Steps per Second: 22,312.24129
Overall Steps per Second: 10,600.97417

Timestep Collection Time: 2.24155
Timestep Consumption Time: 2.47632
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71787

Cumulative Model Updates: 226,038
Cumulative Timesteps: 1,885,192,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.10421
Policy Entropy: 2.12234
Value Function Loss: 0.01633

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.57711
Value Function Update Magnitude: 0.56424

Collected Steps per Second: 22,246.43734
Overall Steps per Second: 10,478.47154

Timestep Collection Time: 2.24809
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77283

Cumulative Model Updates: 226,044
Cumulative Timesteps: 1,885,242,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1885242098...
Checkpoint 1885242098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.47524
Policy Entropy: 2.14620
Value Function Loss: 0.01546

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.16444
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.56059

Collected Steps per Second: 22,238.57340
Overall Steps per Second: 10,629.41472

Timestep Collection Time: 2.24951
Timestep Consumption Time: 2.45686
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.70637

Cumulative Model Updates: 226,050
Cumulative Timesteps: 1,885,292,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.69389
Policy Entropy: 2.16408
Value Function Loss: 0.01353

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.54032

Collected Steps per Second: 22,748.44015
Overall Steps per Second: 10,868.65745

Timestep Collection Time: 2.19795
Timestep Consumption Time: 2.40243
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.60038

Cumulative Model Updates: 226,056
Cumulative Timesteps: 1,885,342,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1885342124...
Checkpoint 1885342124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.29291
Policy Entropy: 2.17815
Value Function Loss: 0.01337

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.52454
Value Function Update Magnitude: 0.53032

Collected Steps per Second: 22,830.08316
Overall Steps per Second: 10,640.89558

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.70054

Cumulative Model Updates: 226,062
Cumulative Timesteps: 1,885,392,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.26045
Policy Entropy: 2.18056
Value Function Loss: 0.01383

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.51967
Value Function Update Magnitude: 0.53012

Collected Steps per Second: 22,685.19327
Overall Steps per Second: 10,642.42851

Timestep Collection Time: 2.20443
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.69893

Cumulative Model Updates: 226,068
Cumulative Timesteps: 1,885,442,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1885442150...
Checkpoint 1885442150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.14460
Policy Entropy: 2.19245
Value Function Loss: 0.01494

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.54358

Collected Steps per Second: 22,575.04510
Overall Steps per Second: 10,778.78731

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.42536
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.64152

Cumulative Model Updates: 226,074
Cumulative Timesteps: 1,885,492,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.37653
Policy Entropy: 2.18453
Value Function Loss: 0.01589

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.55448

Collected Steps per Second: 22,495.70519
Overall Steps per Second: 10,578.00888

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.72735

Cumulative Model Updates: 226,080
Cumulative Timesteps: 1,885,542,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1885542186...
Checkpoint 1885542186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.71499
Policy Entropy: 2.19441
Value Function Loss: 0.01618

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.53941
Value Function Update Magnitude: 0.56434

Collected Steps per Second: 23,415.40381
Overall Steps per Second: 10,826.52222

Timestep Collection Time: 2.13612
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.61995

Cumulative Model Updates: 226,086
Cumulative Timesteps: 1,885,592,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.30583
Policy Entropy: 2.20280
Value Function Loss: 0.01521

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.56651

Collected Steps per Second: 22,206.48954
Overall Steps per Second: 10,663.14645

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69092

Cumulative Model Updates: 226,092
Cumulative Timesteps: 1,885,642,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1885642224...
Checkpoint 1885642224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.72445
Policy Entropy: 2.22592
Value Function Loss: 0.01548

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.56928

Collected Steps per Second: 22,056.07041
Overall Steps per Second: 10,425.10536

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.52917
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.79611

Cumulative Model Updates: 226,098
Cumulative Timesteps: 1,885,692,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.59171
Policy Entropy: 2.23846
Value Function Loss: 0.01516

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.52758
Value Function Update Magnitude: 0.57405

Collected Steps per Second: 22,562.20081
Overall Steps per Second: 10,752.75892

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.65053

Cumulative Model Updates: 226,104
Cumulative Timesteps: 1,885,742,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1885742230...
Checkpoint 1885742230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.19526
Policy Entropy: 2.24283
Value Function Loss: 0.01560

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.52137
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 22,272.18809
Overall Steps per Second: 10,649.78671

Timestep Collection Time: 2.24522
Timestep Consumption Time: 2.45027
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.69549

Cumulative Model Updates: 226,110
Cumulative Timesteps: 1,885,792,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.07126
Policy Entropy: 2.25388
Value Function Loss: 0.01424

Mean KL Divergence: 0.02161
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.51236
Value Function Update Magnitude: 0.56507

Collected Steps per Second: 22,268.11576
Overall Steps per Second: 10,429.00661

Timestep Collection Time: 2.24563
Timestep Consumption Time: 2.54926
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.79490

Cumulative Model Updates: 226,116
Cumulative Timesteps: 1,885,842,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1885842242...
Checkpoint 1885842242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.93874
Policy Entropy: 2.26093
Value Function Loss: 0.01482

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.52446
Value Function Update Magnitude: 0.57721

Collected Steps per Second: 22,775.94159
Overall Steps per Second: 10,627.52847

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.51097
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70759

Cumulative Model Updates: 226,122
Cumulative Timesteps: 1,885,892,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.38420
Policy Entropy: 2.26155
Value Function Loss: 0.01448

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.51592
Value Function Update Magnitude: 0.58894

Collected Steps per Second: 22,969.91797
Overall Steps per Second: 10,920.35863

Timestep Collection Time: 2.17693
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.57897

Cumulative Model Updates: 226,128
Cumulative Timesteps: 1,885,942,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1885942276...
Checkpoint 1885942276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.36544
Policy Entropy: 2.24582
Value Function Loss: 0.01501

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.50538
Value Function Update Magnitude: 0.58069

Collected Steps per Second: 22,941.27221
Overall Steps per Second: 10,674.66791

Timestep Collection Time: 2.17983
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.68474

Cumulative Model Updates: 226,134
Cumulative Timesteps: 1,885,992,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.12532
Policy Entropy: 2.26495
Value Function Loss: 0.01462

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.51098
Value Function Update Magnitude: 0.56754

Collected Steps per Second: 22,962.49306
Overall Steps per Second: 10,804.73478

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.45102
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.62927

Cumulative Model Updates: 226,140
Cumulative Timesteps: 1,886,042,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1886042302...
Checkpoint 1886042302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.18018
Policy Entropy: 2.24508
Value Function Loss: 0.01542

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.52172
Value Function Update Magnitude: 0.55962

Collected Steps per Second: 22,570.22384
Overall Steps per Second: 10,674.14798

Timestep Collection Time: 2.21593
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.68553

Cumulative Model Updates: 226,146
Cumulative Timesteps: 1,886,092,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.32194
Policy Entropy: 2.26091
Value Function Loss: 0.01511

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.52002
Value Function Update Magnitude: 0.55509

Collected Steps per Second: 22,443.00166
Overall Steps per Second: 10,282.53613

Timestep Collection Time: 2.22796
Timestep Consumption Time: 2.63485
PPO Batch Consumption Time: 0.30645
Total Iteration Time: 4.86281

Cumulative Model Updates: 226,152
Cumulative Timesteps: 1,886,142,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1886142318...
Checkpoint 1886142318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.42935
Policy Entropy: 2.23910
Value Function Loss: 0.01554

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.51312
Value Function Update Magnitude: 0.55432

Collected Steps per Second: 22,523.52545
Overall Steps per Second: 10,857.66691

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.38628
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.60725

Cumulative Model Updates: 226,158
Cumulative Timesteps: 1,886,192,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.53214
Policy Entropy: 2.23828
Value Function Loss: 0.01489

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.51330
Value Function Update Magnitude: 0.57173

Collected Steps per Second: 22,132.71684
Overall Steps per Second: 10,470.85001

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.51737
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.77764

Cumulative Model Updates: 226,164
Cumulative Timesteps: 1,886,242,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1886242368...
Checkpoint 1886242368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.33655
Policy Entropy: 2.23118
Value Function Loss: 0.01491

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 21,699.43099
Overall Steps per Second: 10,415.73111

Timestep Collection Time: 2.30504
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.80216

Cumulative Model Updates: 226,170
Cumulative Timesteps: 1,886,292,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.75256
Policy Entropy: 2.23534
Value Function Loss: 0.01411

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.54108

Collected Steps per Second: 22,480.78951
Overall Steps per Second: 10,686.81883

Timestep Collection Time: 2.22457
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.67960

Cumulative Model Updates: 226,176
Cumulative Timesteps: 1,886,342,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1886342396...
Checkpoint 1886342396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.41569
Policy Entropy: 2.26614
Value Function Loss: 0.01412

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.50007
Value Function Update Magnitude: 0.52127

Collected Steps per Second: 22,268.60129
Overall Steps per Second: 10,633.90449

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70194

Cumulative Model Updates: 226,182
Cumulative Timesteps: 1,886,392,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.00619
Policy Entropy: 2.25957
Value Function Loss: 0.01571

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.51413
Value Function Update Magnitude: 0.53464

Collected Steps per Second: 22,764.45724
Overall Steps per Second: 10,566.07342

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.73307

Cumulative Model Updates: 226,188
Cumulative Timesteps: 1,886,442,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1886442406...
Checkpoint 1886442406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.23994
Policy Entropy: 2.27106
Value Function Loss: 0.01537

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.51565
Value Function Update Magnitude: 0.55942

Collected Steps per Second: 22,784.35561
Overall Steps per Second: 10,609.30088

Timestep Collection Time: 2.19458
Timestep Consumption Time: 2.51846
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.71303

Cumulative Model Updates: 226,194
Cumulative Timesteps: 1,886,492,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.61625
Policy Entropy: 2.26174
Value Function Loss: 0.01594

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.51453
Value Function Update Magnitude: 0.54826

Collected Steps per Second: 22,807.54804
Overall Steps per Second: 10,864.76205

Timestep Collection Time: 2.19226
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60203

Cumulative Model Updates: 226,200
Cumulative Timesteps: 1,886,542,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1886542408...
Checkpoint 1886542408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.30383
Policy Entropy: 2.28258
Value Function Loss: 0.01455

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.54849

Collected Steps per Second: 22,559.46878
Overall Steps per Second: 10,763.41148

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.64760

Cumulative Model Updates: 226,206
Cumulative Timesteps: 1,886,592,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.76768
Policy Entropy: 2.26865
Value Function Loss: 0.01477

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.50191
Value Function Update Magnitude: 0.55246

Collected Steps per Second: 23,168.98081
Overall Steps per Second: 10,763.17608

Timestep Collection Time: 2.15840
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.64621

Cumulative Model Updates: 226,212
Cumulative Timesteps: 1,886,642,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1886642440...
Checkpoint 1886642440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.72894
Policy Entropy: 2.26729
Value Function Loss: 0.01303

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.49480
Value Function Update Magnitude: 0.54261

Collected Steps per Second: 22,540.05597
Overall Steps per Second: 10,628.54972

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.70488

Cumulative Model Updates: 226,218
Cumulative Timesteps: 1,886,692,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.66719
Policy Entropy: 2.23992
Value Function Loss: 0.01343

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.49177
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 22,490.62310
Overall Steps per Second: 10,622.56187

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70753

Cumulative Model Updates: 226,224
Cumulative Timesteps: 1,886,742,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1886742452...
Checkpoint 1886742452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.06409
Policy Entropy: 2.24554
Value Function Loss: 0.01417

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.50359
Value Function Update Magnitude: 0.52454

Collected Steps per Second: 22,294.18970
Overall Steps per Second: 10,774.21797

Timestep Collection Time: 2.24354
Timestep Consumption Time: 2.39883
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.64238

Cumulative Model Updates: 226,230
Cumulative Timesteps: 1,886,792,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.39822
Policy Entropy: 2.24293
Value Function Loss: 0.01570

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.54015

Collected Steps per Second: 22,414.99997
Overall Steps per Second: 10,425.23583

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.56571
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.79663

Cumulative Model Updates: 226,236
Cumulative Timesteps: 1,886,842,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1886842476...
Checkpoint 1886842476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.13125
Policy Entropy: 2.27328
Value Function Loss: 0.01551

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.51185
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 22,183.69494
Overall Steps per Second: 10,557.42717

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.73714

Cumulative Model Updates: 226,242
Cumulative Timesteps: 1,886,892,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.19210
Policy Entropy: 2.25875
Value Function Loss: 0.01550

Mean KL Divergence: 0.03342
SB3 Clip Fraction: 0.18613
Policy Update Magnitude: 0.49195
Value Function Update Magnitude: 0.55524

Collected Steps per Second: 22,277.66390
Overall Steps per Second: 10,684.58166

Timestep Collection Time: 2.24440
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.67964

Cumulative Model Updates: 226,248
Cumulative Timesteps: 1,886,942,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1886942488...
Checkpoint 1886942488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.76730
Policy Entropy: 2.25414
Value Function Loss: 0.01624

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.16237
Policy Update Magnitude: 0.51234
Value Function Update Magnitude: 0.56598

Collected Steps per Second: 22,215.48658
Overall Steps per Second: 10,652.14095

Timestep Collection Time: 2.25104
Timestep Consumption Time: 2.44360
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.69464

Cumulative Model Updates: 226,254
Cumulative Timesteps: 1,886,992,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.88924
Policy Entropy: 2.23068
Value Function Loss: 0.01586

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.57989

Collected Steps per Second: 23,042.50299
Overall Steps per Second: 10,768.12040

Timestep Collection Time: 2.17121
Timestep Consumption Time: 2.47492
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.64612

Cumulative Model Updates: 226,260
Cumulative Timesteps: 1,887,042,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1887042526...
Checkpoint 1887042526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480.12145
Policy Entropy: 2.21575
Value Function Loss: 0.01462

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.17423
Policy Update Magnitude: 0.51077
Value Function Update Magnitude: 0.57322

Collected Steps per Second: 22,418.17467
Overall Steps per Second: 10,714.05480

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.66770

Cumulative Model Updates: 226,266
Cumulative Timesteps: 1,887,092,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.30187
Policy Entropy: 2.23734
Value Function Loss: 0.01483

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.17444
Policy Update Magnitude: 0.49549
Value Function Update Magnitude: 0.56097

Collected Steps per Second: 22,674.58159
Overall Steps per Second: 10,658.82514

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.69282

Cumulative Model Updates: 226,272
Cumulative Timesteps: 1,887,142,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1887142556...
Checkpoint 1887142556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.71967
Policy Entropy: 2.25003
Value Function Loss: 0.01503

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.51165
Value Function Update Magnitude: 0.57219

Collected Steps per Second: 22,877.34471
Overall Steps per Second: 10,871.28371

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.41486
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60148

Cumulative Model Updates: 226,278
Cumulative Timesteps: 1,887,192,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.05474
Policy Entropy: 2.27733
Value Function Loss: 0.01496

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.51621
Value Function Update Magnitude: 0.56180

Collected Steps per Second: 22,759.88211
Overall Steps per Second: 10,930.67802

Timestep Collection Time: 2.19764
Timestep Consumption Time: 2.37829
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.57593

Cumulative Model Updates: 226,284
Cumulative Timesteps: 1,887,242,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1887242598...
Checkpoint 1887242598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.98798
Policy Entropy: 2.26988
Value Function Loss: 0.01393

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.51540
Value Function Update Magnitude: 0.54036

Collected Steps per Second: 22,403.35875
Overall Steps per Second: 10,712.50887

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.66819

Cumulative Model Updates: 226,290
Cumulative Timesteps: 1,887,292,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.62190
Policy Entropy: 2.26221
Value Function Loss: 0.01332

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.53756

Collected Steps per Second: 22,458.41959
Overall Steps per Second: 10,546.66946

Timestep Collection Time: 2.22678
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.74178

Cumulative Model Updates: 226,296
Cumulative Timesteps: 1,887,342,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1887342616...
Checkpoint 1887342616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.64877
Policy Entropy: 2.22822
Value Function Loss: 0.01435

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.51020
Value Function Update Magnitude: 0.54771

Collected Steps per Second: 21,941.29622
Overall Steps per Second: 10,534.15341

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.46815
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.74742

Cumulative Model Updates: 226,302
Cumulative Timesteps: 1,887,392,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.62261
Policy Entropy: 2.22347
Value Function Loss: 0.01410

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.51495
Value Function Update Magnitude: 0.53730

Collected Steps per Second: 21,493.16810
Overall Steps per Second: 10,460.02752

Timestep Collection Time: 2.32753
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.78259

Cumulative Model Updates: 226,308
Cumulative Timesteps: 1,887,442,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1887442652...
Checkpoint 1887442652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.76052
Policy Entropy: 2.22795
Value Function Loss: 0.01514

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.54669

Collected Steps per Second: 21,915.22739
Overall Steps per Second: 10,514.53813

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.75798

Cumulative Model Updates: 226,314
Cumulative Timesteps: 1,887,492,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.65214
Policy Entropy: 2.23967
Value Function Loss: 0.01425

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.52243
Value Function Update Magnitude: 0.57582

Collected Steps per Second: 22,314.00067
Overall Steps per Second: 10,628.46430

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.70717

Cumulative Model Updates: 226,320
Cumulative Timesteps: 1,887,542,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1887542710...
Checkpoint 1887542710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.95852
Policy Entropy: 2.25916
Value Function Loss: 0.01531

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.52251
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,816.85898
Overall Steps per Second: 10,602.19874

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.71600

Cumulative Model Updates: 226,326
Cumulative Timesteps: 1,887,592,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.76888
Policy Entropy: 2.24880
Value Function Loss: 0.01633

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.58651

Collected Steps per Second: 23,301.66530
Overall Steps per Second: 10,904.43233

Timestep Collection Time: 2.14637
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.58658

Cumulative Model Updates: 226,332
Cumulative Timesteps: 1,887,642,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1887642724...
Checkpoint 1887642724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.21974
Policy Entropy: 2.25158
Value Function Loss: 0.01646

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.51760
Value Function Update Magnitude: 0.61098

Collected Steps per Second: 22,737.62186
Overall Steps per Second: 10,628.23861

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.50585
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.70520

Cumulative Model Updates: 226,338
Cumulative Timesteps: 1,887,692,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.47522
Policy Entropy: 2.22118
Value Function Loss: 0.01625

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.51991
Value Function Update Magnitude: 0.60526

Collected Steps per Second: 23,026.61453
Overall Steps per Second: 10,849.03907

Timestep Collection Time: 2.17140
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.60870

Cumulative Model Updates: 226,344
Cumulative Timesteps: 1,887,742,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1887742732...
Checkpoint 1887742732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.38584
Policy Entropy: 2.25205
Value Function Loss: 0.01528

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.51149
Value Function Update Magnitude: 0.59832

Collected Steps per Second: 22,659.63760
Overall Steps per Second: 10,718.16712

Timestep Collection Time: 2.20780
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.66759

Cumulative Model Updates: 226,350
Cumulative Timesteps: 1,887,792,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.39569
Policy Entropy: 2.26700
Value Function Loss: 0.01586

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.50843
Value Function Update Magnitude: 0.59522

Collected Steps per Second: 22,731.43775
Overall Steps per Second: 10,863.95304

Timestep Collection Time: 2.19960
Timestep Consumption Time: 2.40278
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.60238

Cumulative Model Updates: 226,356
Cumulative Timesteps: 1,887,842,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1887842760...
Checkpoint 1887842760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.13161
Policy Entropy: 2.26633
Value Function Loss: 0.01576

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 22,039.55812
Overall Steps per Second: 10,620.48279

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.70901

Cumulative Model Updates: 226,362
Cumulative Timesteps: 1,887,892,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.99857
Policy Entropy: 2.24821
Value Function Loss: 0.01573

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 22,333.39652
Overall Steps per Second: 10,509.88492

Timestep Collection Time: 2.23943
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.75876

Cumulative Model Updates: 226,368
Cumulative Timesteps: 1,887,942,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1887942786...
Checkpoint 1887942786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.02703
Policy Entropy: 2.21524
Value Function Loss: 0.01551

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 21,960.40464
Overall Steps per Second: 10,688.01364

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.40266
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.68076

Cumulative Model Updates: 226,374
Cumulative Timesteps: 1,887,992,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.60904
Policy Entropy: 2.22241
Value Function Loss: 0.01462

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.51542
Value Function Update Magnitude: 0.60145

Collected Steps per Second: 21,991.37193
Overall Steps per Second: 10,398.86897

Timestep Collection Time: 2.27453
Timestep Consumption Time: 2.53561
PPO Batch Consumption Time: 0.30277
Total Iteration Time: 4.81014

Cumulative Model Updates: 226,380
Cumulative Timesteps: 1,888,042,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1888042834...
Checkpoint 1888042834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.60270
Policy Entropy: 2.21854
Value Function Loss: 0.01455

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.57827

Collected Steps per Second: 22,404.75024
Overall Steps per Second: 10,594.05462

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.71963

Cumulative Model Updates: 226,386
Cumulative Timesteps: 1,888,092,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.81905
Policy Entropy: 2.23877
Value Function Loss: 0.01452

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.51889
Value Function Update Magnitude: 0.57289

Collected Steps per Second: 22,824.98899
Overall Steps per Second: 10,584.10450

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.53409
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.72520

Cumulative Model Updates: 226,392
Cumulative Timesteps: 1,888,142,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1888142846...
Checkpoint 1888142846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.89710
Policy Entropy: 2.20924
Value Function Loss: 0.01444

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.50479
Value Function Update Magnitude: 0.57767

Collected Steps per Second: 22,683.36643
Overall Steps per Second: 10,695.64017

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.47173
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.67705

Cumulative Model Updates: 226,398
Cumulative Timesteps: 1,888,192,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.86141
Policy Entropy: 2.20911
Value Function Loss: 0.01407

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.55112

Collected Steps per Second: 23,118.64408
Overall Steps per Second: 10,885.04087

Timestep Collection Time: 2.16362
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.59530

Cumulative Model Updates: 226,404
Cumulative Timesteps: 1,888,242,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1888242890...
Checkpoint 1888242890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.91527
Policy Entropy: 2.21916
Value Function Loss: 0.01397

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.49326
Value Function Update Magnitude: 0.52290

Collected Steps per Second: 22,910.07527
Overall Steps per Second: 10,749.81589

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.65180

Cumulative Model Updates: 226,410
Cumulative Timesteps: 1,888,292,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.45218
Policy Entropy: 2.23619
Value Function Loss: 0.01445

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.49772
Value Function Update Magnitude: 0.51878

Collected Steps per Second: 23,141.72923
Overall Steps per Second: 10,686.40936

Timestep Collection Time: 2.16086
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.67940

Cumulative Model Updates: 226,416
Cumulative Timesteps: 1,888,342,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1888342902...
Checkpoint 1888342902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.78896
Policy Entropy: 2.24673
Value Function Loss: 0.01436

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.49732
Value Function Update Magnitude: 0.52923

Collected Steps per Second: 22,632.70822
Overall Steps per Second: 10,638.97083

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.70139

Cumulative Model Updates: 226,422
Cumulative Timesteps: 1,888,392,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.53020
Policy Entropy: 2.21633
Value Function Loss: 0.01539

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.50794
Value Function Update Magnitude: 0.54121

Collected Steps per Second: 22,576.12402
Overall Steps per Second: 10,906.15812

Timestep Collection Time: 2.21597
Timestep Consumption Time: 2.37116
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.58713

Cumulative Model Updates: 226,428
Cumulative Timesteps: 1,888,442,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1888442948...
Checkpoint 1888442948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.31483
Policy Entropy: 2.18187
Value Function Loss: 0.01611

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.51086
Value Function Update Magnitude: 0.54384

Collected Steps per Second: 22,142.43416
Overall Steps per Second: 10,690.75023

Timestep Collection Time: 2.25829
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.67731

Cumulative Model Updates: 226,434
Cumulative Timesteps: 1,888,492,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.05948
Policy Entropy: 2.15520
Value Function Loss: 0.01719

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.52585
Value Function Update Magnitude: 0.56777

Collected Steps per Second: 22,726.84211
Overall Steps per Second: 10,801.79357

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63053

Cumulative Model Updates: 226,440
Cumulative Timesteps: 1,888,542,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1888542970...
Checkpoint 1888542970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.46554
Policy Entropy: 2.15789
Value Function Loss: 0.01649

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.58454

Collected Steps per Second: 22,486.64400
Overall Steps per Second: 10,706.92638

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.67249

Cumulative Model Updates: 226,446
Cumulative Timesteps: 1,888,592,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.40021
Policy Entropy: 2.20015
Value Function Loss: 0.01618

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.52519
Value Function Update Magnitude: 0.57346

Collected Steps per Second: 23,201.89919
Overall Steps per Second: 10,868.13231

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.60300

Cumulative Model Updates: 226,452
Cumulative Timesteps: 1,888,643,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1888643024...
Checkpoint 1888643024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.64762
Policy Entropy: 2.23435
Value Function Loss: 0.01501

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.52385
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 22,996.36377
Overall Steps per Second: 10,707.17686

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.67219

Cumulative Model Updates: 226,458
Cumulative Timesteps: 1,888,693,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.23625
Policy Entropy: 2.24250
Value Function Loss: 0.01518

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.55627

Collected Steps per Second: 22,957.99207
Overall Steps per Second: 10,862.00275

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.60541

Cumulative Model Updates: 226,464
Cumulative Timesteps: 1,888,743,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1888743074...
Checkpoint 1888743074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.80682
Policy Entropy: 2.21074
Value Function Loss: 0.01639

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.52722
Value Function Update Magnitude: 0.56809

Collected Steps per Second: 22,586.21718
Overall Steps per Second: 10,678.67232

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.68242

Cumulative Model Updates: 226,470
Cumulative Timesteps: 1,888,793,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.55851
Policy Entropy: 2.20639
Value Function Loss: 0.01608

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.53167
Value Function Update Magnitude: 0.57582

Collected Steps per Second: 23,075.57535
Overall Steps per Second: 10,932.89132

Timestep Collection Time: 2.16775
Timestep Consumption Time: 2.40762
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.57537

Cumulative Model Updates: 226,476
Cumulative Timesteps: 1,888,843,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1888843098...
Checkpoint 1888843098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.35862
Policy Entropy: 2.20725
Value Function Loss: 0.01565

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.57865

Collected Steps per Second: 22,178.46404
Overall Steps per Second: 10,662.05581

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.69084

Cumulative Model Updates: 226,482
Cumulative Timesteps: 1,888,893,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.58662
Policy Entropy: 2.22425
Value Function Loss: 0.01522

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.58819

Collected Steps per Second: 22,744.89438
Overall Steps per Second: 10,790.40819

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.63523

Cumulative Model Updates: 226,488
Cumulative Timesteps: 1,888,943,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1888943128...
Checkpoint 1888943128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.40276
Policy Entropy: 2.22472
Value Function Loss: 0.01469

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.57783

Collected Steps per Second: 21,931.66079
Overall Steps per Second: 10,625.33363

Timestep Collection Time: 2.28109
Timestep Consumption Time: 2.42728
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.70837

Cumulative Model Updates: 226,494
Cumulative Timesteps: 1,888,993,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.78479
Policy Entropy: 2.21298
Value Function Loss: 0.01577

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.55512

Collected Steps per Second: 22,779.94059
Overall Steps per Second: 10,615.65471

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.71210

Cumulative Model Updates: 226,500
Cumulative Timesteps: 1,889,043,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1889043178...
Checkpoint 1889043178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.33643
Policy Entropy: 2.22139
Value Function Loss: 0.01588

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.54652

Collected Steps per Second: 22,722.78071
Overall Steps per Second: 10,896.03160

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.38887
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.58974

Cumulative Model Updates: 226,506
Cumulative Timesteps: 1,889,093,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.00602
Policy Entropy: 2.20701
Value Function Loss: 0.01696

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.57105

Collected Steps per Second: 22,940.93841
Overall Steps per Second: 10,675.74909

Timestep Collection Time: 2.18038
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.68539

Cumulative Model Updates: 226,512
Cumulative Timesteps: 1,889,143,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1889143208...
Checkpoint 1889143208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.80383
Policy Entropy: 2.20998
Value Function Loss: 0.01720

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.53639
Value Function Update Magnitude: 0.59315

Collected Steps per Second: 22,761.85730
Overall Steps per Second: 10,625.92410

Timestep Collection Time: 2.19666
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.70547

Cumulative Model Updates: 226,518
Cumulative Timesteps: 1,889,193,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.02886
Policy Entropy: 2.22396
Value Function Loss: 0.01751

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 23,071.21774
Overall Steps per Second: 10,816.02507

Timestep Collection Time: 2.16842
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.62536

Cumulative Model Updates: 226,524
Cumulative Timesteps: 1,889,243,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1889243236...
Checkpoint 1889243236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.34003
Policy Entropy: 2.21970
Value Function Loss: 0.01671

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.15710
Policy Update Magnitude: 0.52044
Value Function Update Magnitude: 0.56715

Collected Steps per Second: 23,315.07778
Overall Steps per Second: 10,801.99244

Timestep Collection Time: 2.14539
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.63063

Cumulative Model Updates: 226,530
Cumulative Timesteps: 1,889,293,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.89068
Policy Entropy: 2.22731
Value Function Loss: 0.01578

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.49853
Value Function Update Magnitude: 0.56307

Collected Steps per Second: 22,805.99175
Overall Steps per Second: 10,593.79335

Timestep Collection Time: 2.19241
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.71974

Cumulative Model Updates: 226,536
Cumulative Timesteps: 1,889,343,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1889343256...
Checkpoint 1889343256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.47309
Policy Entropy: 2.20078
Value Function Loss: 0.01530

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.16948
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 22,326.24891
Overall Steps per Second: 10,621.72446

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.70903

Cumulative Model Updates: 226,542
Cumulative Timesteps: 1,889,393,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.05634
Policy Entropy: 2.21558
Value Function Loss: 0.01543

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.16430
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.59929

Collected Steps per Second: 22,326.85956
Overall Steps per Second: 10,630.95579

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.70343

Cumulative Model Updates: 226,548
Cumulative Timesteps: 1,889,443,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1889443276...
Checkpoint 1889443276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.28781
Policy Entropy: 2.22909
Value Function Loss: 0.01459

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.59254

Collected Steps per Second: 22,255.26912
Overall Steps per Second: 10,697.07222

Timestep Collection Time: 2.24765
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.67623

Cumulative Model Updates: 226,554
Cumulative Timesteps: 1,889,493,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.20763
Policy Entropy: 2.24790
Value Function Loss: 0.01389

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.51055
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 22,737.36794
Overall Steps per Second: 10,775.13019

Timestep Collection Time: 2.19929
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.64087

Cumulative Model Updates: 226,560
Cumulative Timesteps: 1,889,543,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1889543304...
Checkpoint 1889543304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.26442
Policy Entropy: 2.23571
Value Function Loss: 0.01442

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.54474

Collected Steps per Second: 22,458.06231
Overall Steps per Second: 10,647.91068

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.69764

Cumulative Model Updates: 226,566
Cumulative Timesteps: 1,889,593,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.51249
Policy Entropy: 2.21180
Value Function Loss: 0.01597

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.52395
Value Function Update Magnitude: 0.55547

Collected Steps per Second: 22,792.79409
Overall Steps per Second: 10,669.51016

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.68719

Cumulative Model Updates: 226,572
Cumulative Timesteps: 1,889,643,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1889643334...
Checkpoint 1889643334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.39082
Policy Entropy: 2.19158
Value Function Loss: 0.01674

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.53316
Value Function Update Magnitude: 0.58877

Collected Steps per Second: 22,564.22542
Overall Steps per Second: 10,919.91058

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.36441
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.58172

Cumulative Model Updates: 226,578
Cumulative Timesteps: 1,889,693,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.95204
Policy Entropy: 2.19985
Value Function Loss: 0.01619

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.61332

Collected Steps per Second: 23,117.88546
Overall Steps per Second: 10,877.64100

Timestep Collection Time: 2.16369
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59842

Cumulative Model Updates: 226,584
Cumulative Timesteps: 1,889,743,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1889743386...
Checkpoint 1889743386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.68111
Policy Entropy: 2.23150
Value Function Loss: 0.01482

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.62213

Collected Steps per Second: 22,407.89764
Overall Steps per Second: 10,636.61777

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.70337

Cumulative Model Updates: 226,590
Cumulative Timesteps: 1,889,793,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.38918
Policy Entropy: 2.21530
Value Function Loss: 0.01490

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.52526
Value Function Update Magnitude: 0.59510

Collected Steps per Second: 22,902.02334
Overall Steps per Second: 10,719.75183

Timestep Collection Time: 2.18348
Timestep Consumption Time: 2.48137
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.66485

Cumulative Model Updates: 226,596
Cumulative Timesteps: 1,889,843,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1889843420...
Checkpoint 1889843420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.79311
Policy Entropy: 2.21033
Value Function Loss: 0.01661

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.53464
Value Function Update Magnitude: 0.57721

Collected Steps per Second: 22,582.74666
Overall Steps per Second: 10,978.48689

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.34094
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.55564

Cumulative Model Updates: 226,602
Cumulative Timesteps: 1,889,893,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.82152
Policy Entropy: 2.19562
Value Function Loss: 0.01642

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.53701
Value Function Update Magnitude: 0.59808

Collected Steps per Second: 22,997.67379
Overall Steps per Second: 10,835.69701

Timestep Collection Time: 2.17422
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61456

Cumulative Model Updates: 226,608
Cumulative Timesteps: 1,889,943,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1889943436...
Checkpoint 1889943436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.20441
Policy Entropy: 2.23289
Value Function Loss: 0.01531

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.52934
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 20,961.40209
Overall Steps per Second: 10,233.68078

Timestep Collection Time: 2.38591
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.88700

Cumulative Model Updates: 226,614
Cumulative Timesteps: 1,889,993,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.35914
Policy Entropy: 2.24326
Value Function Loss: 0.01422

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.57433

Collected Steps per Second: 22,071.40244
Overall Steps per Second: 10,414.75307

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.53652
PPO Batch Consumption Time: 0.30462
Total Iteration Time: 4.80280

Cumulative Model Updates: 226,620
Cumulative Timesteps: 1,890,043,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1890043468...
Checkpoint 1890043468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.24937
Policy Entropy: 2.24108
Value Function Loss: 0.01400

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.51306
Value Function Update Magnitude: 0.54852

Collected Steps per Second: 22,206.01662
Overall Steps per Second: 10,668.90221

Timestep Collection Time: 2.25299
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68933

Cumulative Model Updates: 226,626
Cumulative Timesteps: 1,890,093,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.06837
Policy Entropy: 2.23480
Value Function Loss: 0.01469

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.50788
Value Function Update Magnitude: 0.54755

Collected Steps per Second: 23,280.57539
Overall Steps per Second: 10,847.48074

Timestep Collection Time: 2.14831
Timestep Consumption Time: 2.46234
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.61066

Cumulative Model Updates: 226,632
Cumulative Timesteps: 1,890,143,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1890143512...
Checkpoint 1890143512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.13291
Policy Entropy: 2.22373
Value Function Loss: 0.01542

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.53827

Collected Steps per Second: 22,649.42272
Overall Steps per Second: 10,695.75577

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.67606

Cumulative Model Updates: 226,638
Cumulative Timesteps: 1,890,193,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.37499
Policy Entropy: 2.21099
Value Function Loss: 0.01583

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.51179
Value Function Update Magnitude: 0.53905

Collected Steps per Second: 22,786.71618
Overall Steps per Second: 10,757.40255

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.45498
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.65038

Cumulative Model Updates: 226,644
Cumulative Timesteps: 1,890,243,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1890243552...
Checkpoint 1890243552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.55180
Policy Entropy: 2.20066
Value Function Loss: 0.01567

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.51926
Value Function Update Magnitude: 0.55270

Collected Steps per Second: 22,555.44433
Overall Steps per Second: 10,766.46717

Timestep Collection Time: 2.21676
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.64405

Cumulative Model Updates: 226,650
Cumulative Timesteps: 1,890,293,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.87330
Policy Entropy: 2.20663
Value Function Loss: 0.01460

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.51547
Value Function Update Magnitude: 0.56446

Collected Steps per Second: 23,100.11038
Overall Steps per Second: 10,963.97720

Timestep Collection Time: 2.16501
Timestep Consumption Time: 2.39647
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.56148

Cumulative Model Updates: 226,656
Cumulative Timesteps: 1,890,343,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1890343564...
Checkpoint 1890343564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.17675
Policy Entropy: 2.21141
Value Function Loss: 0.01550

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.55725

Collected Steps per Second: 22,546.49776
Overall Steps per Second: 10,648.19606

Timestep Collection Time: 2.21888
Timestep Consumption Time: 2.47938
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.69826

Cumulative Model Updates: 226,662
Cumulative Timesteps: 1,890,393,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.87866
Policy Entropy: 2.20347
Value Function Loss: 0.01527

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.51861
Value Function Update Magnitude: 0.55123

Collected Steps per Second: 22,400.31336
Overall Steps per Second: 10,551.46581

Timestep Collection Time: 2.23229
Timestep Consumption Time: 2.50677
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.73906

Cumulative Model Updates: 226,668
Cumulative Timesteps: 1,890,443,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1890443596...
Checkpoint 1890443596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.62657
Policy Entropy: 2.19866
Value Function Loss: 0.01595

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.56188

Collected Steps per Second: 22,288.10123
Overall Steps per Second: 10,891.94039

Timestep Collection Time: 2.24344
Timestep Consumption Time: 2.34729
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59073

Cumulative Model Updates: 226,674
Cumulative Timesteps: 1,890,493,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.19986
Policy Entropy: 2.20175
Value Function Loss: 0.01609

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.59810

Collected Steps per Second: 22,926.05517
Overall Steps per Second: 10,695.29950

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.67495

Cumulative Model Updates: 226,680
Cumulative Timesteps: 1,890,543,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1890543598...
Checkpoint 1890543598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.10694
Policy Entropy: 2.24673
Value Function Loss: 0.01576

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 21,977.37588
Overall Steps per Second: 10,530.55055

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.47372
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.74942

Cumulative Model Updates: 226,686
Cumulative Timesteps: 1,890,593,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.42360
Policy Entropy: 2.25889
Value Function Loss: 0.01566

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.52455
Value Function Update Magnitude: 0.60983

Collected Steps per Second: 23,009.30630
Overall Steps per Second: 10,762.13586

Timestep Collection Time: 2.17390
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.64778

Cumulative Model Updates: 226,692
Cumulative Timesteps: 1,890,643,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1890643632...
Checkpoint 1890643632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.40166
Policy Entropy: 2.26995
Value Function Loss: 0.01525

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.51932
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 22,545.47989
Overall Steps per Second: 10,768.13013

Timestep Collection Time: 2.21827
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.64445

Cumulative Model Updates: 226,698
Cumulative Timesteps: 1,890,693,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.53848
Policy Entropy: 2.24595
Value Function Loss: 0.01521

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 22,890.33616
Overall Steps per Second: 10,812.72673

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.62696

Cumulative Model Updates: 226,704
Cumulative Timesteps: 1,890,743,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1890743674...
Checkpoint 1890743674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.54675
Policy Entropy: 2.23086
Value Function Loss: 0.01589

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.58279

Collected Steps per Second: 22,383.06554
Overall Steps per Second: 10,678.98218

Timestep Collection Time: 2.23410
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.68266

Cumulative Model Updates: 226,710
Cumulative Timesteps: 1,890,793,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.91920
Policy Entropy: 2.23548
Value Function Loss: 0.01483

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.58743

Collected Steps per Second: 22,911.66005
Overall Steps per Second: 10,856.72786

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.60654

Cumulative Model Updates: 226,716
Cumulative Timesteps: 1,890,843,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1890843692...
Checkpoint 1890843692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.34173
Policy Entropy: 2.27486
Value Function Loss: 0.01393

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.51616
Value Function Update Magnitude: 0.59153

Collected Steps per Second: 22,576.16385
Overall Steps per Second: 10,731.88641

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.65976

Cumulative Model Updates: 226,722
Cumulative Timesteps: 1,890,893,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.88548
Policy Entropy: 2.28919
Value Function Loss: 0.01443

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.51965
Value Function Update Magnitude: 0.60135

Collected Steps per Second: 22,404.46330
Overall Steps per Second: 10,564.86866

Timestep Collection Time: 2.23304
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.73551

Cumulative Model Updates: 226,728
Cumulative Timesteps: 1,890,943,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1890943730...
Checkpoint 1890943730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.45932
Policy Entropy: 2.25843
Value Function Loss: 0.01626

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.53038
Value Function Update Magnitude: 0.59850

Collected Steps per Second: 22,316.97831
Overall Steps per Second: 10,560.18685

Timestep Collection Time: 2.24054
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.73495

Cumulative Model Updates: 226,734
Cumulative Timesteps: 1,890,993,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.29420
Policy Entropy: 2.22392
Value Function Loss: 0.01650

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.60113

Collected Steps per Second: 22,480.91692
Overall Steps per Second: 10,649.38540

Timestep Collection Time: 2.22553
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69811

Cumulative Model Updates: 226,740
Cumulative Timesteps: 1,891,043,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1891043764...
Checkpoint 1891043764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.63040
Policy Entropy: 2.20496
Value Function Loss: 0.01691

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.59402

Collected Steps per Second: 22,511.68923
Overall Steps per Second: 10,887.87388

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.37224
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.59429

Cumulative Model Updates: 226,746
Cumulative Timesteps: 1,891,093,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.15417
Policy Entropy: 2.22005
Value Function Loss: 0.01551

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.58462

Collected Steps per Second: 23,079.78582
Overall Steps per Second: 10,649.73975

Timestep Collection Time: 2.16683
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69589

Cumulative Model Updates: 226,752
Cumulative Timesteps: 1,891,143,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1891143796...
Checkpoint 1891143796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.72365
Policy Entropy: 2.22745
Value Function Loss: 0.01679

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.59157

Collected Steps per Second: 22,856.60085
Overall Steps per Second: 10,803.42231

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63057

Cumulative Model Updates: 226,758
Cumulative Timesteps: 1,891,193,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.61240
Policy Entropy: 2.25839
Value Function Loss: 0.01572

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.59559

Collected Steps per Second: 22,737.25452
Overall Steps per Second: 10,698.79905

Timestep Collection Time: 2.19991
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.67529

Cumulative Model Updates: 226,764
Cumulative Timesteps: 1,891,243,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1891243842...
Checkpoint 1891243842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.15430
Policy Entropy: 2.27087
Value Function Loss: 0.01529

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.52132
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 23,004.95471
Overall Steps per Second: 10,975.96699

Timestep Collection Time: 2.17405
Timestep Consumption Time: 2.38263
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.55668

Cumulative Model Updates: 226,770
Cumulative Timesteps: 1,891,293,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.00798
Policy Entropy: 2.24737
Value Function Loss: 0.01549

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.56728

Collected Steps per Second: 23,110.39895
Overall Steps per Second: 10,656.04527

Timestep Collection Time: 2.16457
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.69442

Cumulative Model Updates: 226,776
Cumulative Timesteps: 1,891,343,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1891343880...
Checkpoint 1891343880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.84181
Policy Entropy: 2.24725
Value Function Loss: 0.01609

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.52796
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 22,714.89385
Overall Steps per Second: 10,705.01012

Timestep Collection Time: 2.20243
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.67333

Cumulative Model Updates: 226,782
Cumulative Timesteps: 1,891,393,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.93115
Policy Entropy: 2.22955
Value Function Loss: 0.01667

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.58599

Collected Steps per Second: 22,423.45127
Overall Steps per Second: 10,678.95812

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.68210

Cumulative Model Updates: 226,788
Cumulative Timesteps: 1,891,443,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1891443908...
Checkpoint 1891443908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.03508
Policy Entropy: 2.25846
Value Function Loss: 0.01596

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.16476
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 22,738.51890
Overall Steps per Second: 10,679.64494

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.68443

Cumulative Model Updates: 226,794
Cumulative Timesteps: 1,891,493,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.57402
Policy Entropy: 2.26850
Value Function Loss: 0.01478

Mean KL Divergence: 0.02810
SB3 Clip Fraction: 0.17253
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.55895

Collected Steps per Second: 23,123.02748
Overall Steps per Second: 10,865.14966

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.60205

Cumulative Model Updates: 226,800
Cumulative Timesteps: 1,891,543,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1891543938...
Checkpoint 1891543938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.38042
Policy Entropy: 2.25521
Value Function Loss: 0.01422

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.16999
Policy Update Magnitude: 0.51887
Value Function Update Magnitude: 0.55730

Collected Steps per Second: 22,511.13584
Overall Steps per Second: 10,647.69595

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.69698

Cumulative Model Updates: 226,806
Cumulative Timesteps: 1,891,593,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.35004
Policy Entropy: 2.21956
Value Function Loss: 0.01483

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.16437
Policy Update Magnitude: 0.52078
Value Function Update Magnitude: 0.57456

Collected Steps per Second: 23,048.22021
Overall Steps per Second: 10,861.50926

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60488

Cumulative Model Updates: 226,812
Cumulative Timesteps: 1,891,643,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1891643966...
Checkpoint 1891643966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.97173
Policy Entropy: 2.22838
Value Function Loss: 0.01491

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.16497
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.58222

Collected Steps per Second: 22,607.97339
Overall Steps per Second: 10,644.97950

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69818

Cumulative Model Updates: 226,818
Cumulative Timesteps: 1,891,693,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.10208
Policy Entropy: 2.25539
Value Function Loss: 0.01493

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.58123

Collected Steps per Second: 22,923.98358
Overall Steps per Second: 10,968.54989

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.37803
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.55976

Cumulative Model Updates: 226,824
Cumulative Timesteps: 1,891,743,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1891743992...
Checkpoint 1891743992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.54210
Policy Entropy: 2.28957
Value Function Loss: 0.01372

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.51623
Value Function Update Magnitude: 0.56616

Collected Steps per Second: 22,791.24379
Overall Steps per Second: 10,617.83386

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.71019

Cumulative Model Updates: 226,830
Cumulative Timesteps: 1,891,794,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.07820
Policy Entropy: 2.25792
Value Function Loss: 0.01322

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.51055
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 23,096.44690
Overall Steps per Second: 10,866.80582

Timestep Collection Time: 2.16544
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60246

Cumulative Model Updates: 226,836
Cumulative Timesteps: 1,891,844,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1891844018...
Checkpoint 1891844018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.86916
Policy Entropy: 2.22456
Value Function Loss: 0.01387

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.51365
Value Function Update Magnitude: 0.54835

Collected Steps per Second: 22,341.31935
Overall Steps per Second: 10,716.56062

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.66754

Cumulative Model Updates: 226,842
Cumulative Timesteps: 1,891,894,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.42757
Policy Entropy: 2.21570
Value Function Loss: 0.01459

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.52532
Value Function Update Magnitude: 0.58136

Collected Steps per Second: 23,256.19251
Overall Steps per Second: 10,889.74230

Timestep Collection Time: 2.15014
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.59184

Cumulative Model Updates: 226,848
Cumulative Timesteps: 1,891,944,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1891944042...
Checkpoint 1891944042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.14955
Policy Entropy: 2.22137
Value Function Loss: 0.01488

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.58355

Collected Steps per Second: 22,919.48806
Overall Steps per Second: 10,681.64033

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.68093

Cumulative Model Updates: 226,854
Cumulative Timesteps: 1,891,994,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.19283
Policy Entropy: 2.20036
Value Function Loss: 0.01543

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.51776
Value Function Update Magnitude: 0.57534

Collected Steps per Second: 22,792.71935
Overall Steps per Second: 10,738.38912

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.65675

Cumulative Model Updates: 226,860
Cumulative Timesteps: 1,892,044,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1892044048...
Checkpoint 1892044048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.30914
Policy Entropy: 2.21171
Value Function Loss: 0.01532

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.15404
Policy Update Magnitude: 0.53059
Value Function Update Magnitude: 0.57055

Collected Steps per Second: 22,379.11464
Overall Steps per Second: 10,714.15911

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.66859

Cumulative Model Updates: 226,866
Cumulative Timesteps: 1,892,094,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.61833
Policy Entropy: 2.19878
Value Function Loss: 0.01476

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.15165
Policy Update Magnitude: 0.53165
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 22,981.34114
Overall Steps per Second: 10,863.84728

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.42684
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60261

Cumulative Model Updates: 226,872
Cumulative Timesteps: 1,892,144,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1892144070...
Checkpoint 1892144070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.17546
Policy Entropy: 2.25361
Value Function Loss: 0.01442

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.52896
Value Function Update Magnitude: 0.58730

Collected Steps per Second: 22,492.44300
Overall Steps per Second: 10,742.99473

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.65773

Cumulative Model Updates: 226,878
Cumulative Timesteps: 1,892,194,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.21654
Policy Entropy: 2.28105
Value Function Loss: 0.01444

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.57938

Collected Steps per Second: 23,172.06603
Overall Steps per Second: 10,874.41033

Timestep Collection Time: 2.15794
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.59832

Cumulative Model Updates: 226,884
Cumulative Timesteps: 1,892,244,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1892244112...
Checkpoint 1892244112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.96897
Policy Entropy: 2.29512
Value Function Loss: 0.01484

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.52640
Value Function Update Magnitude: 0.56016

Collected Steps per Second: 22,071.95868
Overall Steps per Second: 10,904.92120

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.32079
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.58710

Cumulative Model Updates: 226,890
Cumulative Timesteps: 1,892,294,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.17792
Policy Entropy: 2.28364
Value Function Loss: 0.01557

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.52419
Value Function Update Magnitude: 0.56138

Collected Steps per Second: 22,792.02227
Overall Steps per Second: 10,852.57020

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.60960

Cumulative Model Updates: 226,896
Cumulative Timesteps: 1,892,344,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1892344160...
Checkpoint 1892344160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.14395
Policy Entropy: 2.24607
Value Function Loss: 0.01465

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.57065

Collected Steps per Second: 22,981.18475
Overall Steps per Second: 10,859.66036

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.60567

Cumulative Model Updates: 226,902
Cumulative Timesteps: 1,892,394,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.43979
Policy Entropy: 2.24382
Value Function Loss: 0.01517

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.56952

Collected Steps per Second: 23,191.03504
Overall Steps per Second: 10,888.86880

Timestep Collection Time: 2.15635
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59258

Cumulative Model Updates: 226,908
Cumulative Timesteps: 1,892,444,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1892444184...
Checkpoint 1892444184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.07852
Policy Entropy: 2.24146
Value Function Loss: 0.01501

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.59300

Collected Steps per Second: 22,628.78752
Overall Steps per Second: 10,754.84814

Timestep Collection Time: 2.21196
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.65409

Cumulative Model Updates: 226,914
Cumulative Timesteps: 1,892,494,238

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.61036
Policy Entropy: 2.23825
Value Function Loss: 0.01480

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 23,018.11944
Overall Steps per Second: 10,879.81944

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.59842

Cumulative Model Updates: 226,920
Cumulative Timesteps: 1,892,544,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1892544268...
Checkpoint 1892544268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.21591
Policy Entropy: 2.23390
Value Function Loss: 0.01494

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 22,638.28652
Overall Steps per Second: 10,791.75539

Timestep Collection Time: 2.20918
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.63428

Cumulative Model Updates: 226,926
Cumulative Timesteps: 1,892,594,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.69035
Policy Entropy: 2.23975
Value Function Loss: 0.01453

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.51811
Value Function Update Magnitude: 0.54726

Collected Steps per Second: 23,437.75403
Overall Steps per Second: 10,844.76219

Timestep Collection Time: 2.13433
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.61273

Cumulative Model Updates: 226,932
Cumulative Timesteps: 1,892,644,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1892644304...
Checkpoint 1892644304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.07564
Policy Entropy: 2.25740
Value Function Loss: 0.01413

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.51333
Value Function Update Magnitude: 0.54654

Collected Steps per Second: 22,603.13851
Overall Steps per Second: 10,551.38663

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.74080

Cumulative Model Updates: 226,938
Cumulative Timesteps: 1,892,694,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.41255
Policy Entropy: 2.26833
Value Function Loss: 0.01371

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.51217
Value Function Update Magnitude: 0.54434

Collected Steps per Second: 22,893.31654
Overall Steps per Second: 10,773.27236

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.45845
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.64371

Cumulative Model Updates: 226,944
Cumulative Timesteps: 1,892,744,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1892744354...
Checkpoint 1892744354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.66716
Policy Entropy: 2.26620
Value Function Loss: 0.01576

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.54482

Collected Steps per Second: 23,417.96584
Overall Steps per Second: 10,863.53081

Timestep Collection Time: 2.13588
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.60421

Cumulative Model Updates: 226,950
Cumulative Timesteps: 1,892,794,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.16780
Policy Entropy: 2.26532
Value Function Loss: 0.01579

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 22,928.45533
Overall Steps per Second: 10,826.27612

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61839

Cumulative Model Updates: 226,956
Cumulative Timesteps: 1,892,844,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1892844372...
Checkpoint 1892844372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.16587
Policy Entropy: 2.25544
Value Function Loss: 0.01593

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.53102
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 22,549.40944
Overall Steps per Second: 10,744.20155

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.65591

Cumulative Model Updates: 226,962
Cumulative Timesteps: 1,892,894,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.82249
Policy Entropy: 2.24245
Value Function Loss: 0.01414

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.51487
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 22,893.34506
Overall Steps per Second: 10,852.10227

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.42365
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.60796

Cumulative Model Updates: 226,968
Cumulative Timesteps: 1,892,944,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1892944402...
Checkpoint 1892944402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.68305
Policy Entropy: 2.24112
Value Function Loss: 0.01405

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.50580
Value Function Update Magnitude: 0.58443

Collected Steps per Second: 22,507.23545
Overall Steps per Second: 10,762.21293

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.64607

Cumulative Model Updates: 226,974
Cumulative Timesteps: 1,892,994,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.53077
Policy Entropy: 2.24002
Value Function Loss: 0.01442

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.51156
Value Function Update Magnitude: 0.56855

Collected Steps per Second: 22,905.52835
Overall Steps per Second: 10,871.13325

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60007

Cumulative Model Updates: 226,980
Cumulative Timesteps: 1,893,044,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1893044412...
Checkpoint 1893044412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.68157
Policy Entropy: 2.22077
Value Function Loss: 0.01567

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.56424

Collected Steps per Second: 22,968.53720
Overall Steps per Second: 10,695.01248

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.67751

Cumulative Model Updates: 226,986
Cumulative Timesteps: 1,893,094,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.08014
Policy Entropy: 2.20683
Value Function Loss: 0.01547

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.57501

Collected Steps per Second: 23,068.49756
Overall Steps per Second: 10,775.46606

Timestep Collection Time: 2.16841
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.64221

Cumulative Model Updates: 226,992
Cumulative Timesteps: 1,893,144,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1893144460...
Checkpoint 1893144460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.30134
Policy Entropy: 2.22222
Value Function Loss: 0.01593

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.56871

Collected Steps per Second: 23,280.08491
Overall Steps per Second: 10,771.67753

Timestep Collection Time: 2.14784
Timestep Consumption Time: 2.49414
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.64199

Cumulative Model Updates: 226,998
Cumulative Timesteps: 1,893,194,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.54771
Policy Entropy: 2.25538
Value Function Loss: 0.01624

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.59320

Collected Steps per Second: 23,288.99478
Overall Steps per Second: 10,858.37285

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.60640

Cumulative Model Updates: 227,004
Cumulative Timesteps: 1,893,244,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1893244480...
Checkpoint 1893244480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.71712
Policy Entropy: 2.28101
Value Function Loss: 0.01587

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 23,071.72739
Overall Steps per Second: 10,723.83438

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66512

Cumulative Model Updates: 227,010
Cumulative Timesteps: 1,893,294,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.32431
Policy Entropy: 2.25774
Value Function Loss: 0.01615

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.63039

Collected Steps per Second: 23,274.98171
Overall Steps per Second: 10,959.41311

Timestep Collection Time: 2.14823
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.56229

Cumulative Model Updates: 227,016
Cumulative Timesteps: 1,893,344,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1893344508...
Checkpoint 1893344508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398.10111
Policy Entropy: 2.25817
Value Function Loss: 0.01548

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,771.67779
Overall Steps per Second: 10,655.26900

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.69270

Cumulative Model Updates: 227,022
Cumulative Timesteps: 1,893,394,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.34870
Policy Entropy: 2.24121
Value Function Loss: 0.01663

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.61060

Collected Steps per Second: 23,106.17041
Overall Steps per Second: 10,725.35115

Timestep Collection Time: 2.16401
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.66204

Cumulative Model Updates: 227,028
Cumulative Timesteps: 1,893,444,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1893444512...
Checkpoint 1893444512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.39383
Policy Entropy: 2.24083
Value Function Loss: 0.01592

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.54314
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,676.23049
Overall Steps per Second: 10,641.17698

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.69967

Cumulative Model Updates: 227,034
Cumulative Timesteps: 1,893,494,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.80302
Policy Entropy: 2.23409
Value Function Loss: 0.01634

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.53288
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 23,126.05345
Overall Steps per Second: 10,887.83231

Timestep Collection Time: 2.16241
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.59302

Cumulative Model Updates: 227,040
Cumulative Timesteps: 1,893,544,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1893544530...
Checkpoint 1893544530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.48490
Policy Entropy: 2.23362
Value Function Loss: 0.01490

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 22,863.59514
Overall Steps per Second: 10,652.46213

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69657

Cumulative Model Updates: 227,046
Cumulative Timesteps: 1,893,594,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.60394
Policy Entropy: 2.22801
Value Function Loss: 0.01477

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.51271
Value Function Update Magnitude: 0.58361

Collected Steps per Second: 22,867.47282
Overall Steps per Second: 10,690.47328

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.67818

Cumulative Model Updates: 227,052
Cumulative Timesteps: 1,893,644,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1893644572...
Checkpoint 1893644572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.84113
Policy Entropy: 2.21542
Value Function Loss: 0.01490

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.52695
Value Function Update Magnitude: 0.59279

Collected Steps per Second: 22,733.59632
Overall Steps per Second: 10,851.91763

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.40867
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60859

Cumulative Model Updates: 227,058
Cumulative Timesteps: 1,893,694,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.42767
Policy Entropy: 2.21733
Value Function Loss: 0.01582

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 22,863.23533
Overall Steps per Second: 10,919.49763

Timestep Collection Time: 2.18762
Timestep Consumption Time: 2.39281
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.58043

Cumulative Model Updates: 227,064
Cumulative Timesteps: 1,893,744,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1893744600...
Checkpoint 1893744600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.95602
Policy Entropy: 2.23420
Value Function Loss: 0.01541

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.53436
Value Function Update Magnitude: 0.58920

Collected Steps per Second: 22,875.93825
Overall Steps per Second: 10,616.78105

Timestep Collection Time: 2.18570
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.70953

Cumulative Model Updates: 227,070
Cumulative Timesteps: 1,893,794,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.71955
Policy Entropy: 2.23842
Value Function Loss: 0.01498

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.52207
Value Function Update Magnitude: 0.58838

Collected Steps per Second: 22,793.06952
Overall Steps per Second: 10,720.41176

Timestep Collection Time: 2.19488
Timestep Consumption Time: 2.47173
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.66661

Cumulative Model Updates: 227,076
Cumulative Timesteps: 1,893,844,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1893844628...
Checkpoint 1893844628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.33302
Policy Entropy: 2.25099
Value Function Loss: 0.01477

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.60401

Collected Steps per Second: 22,788.65101
Overall Steps per Second: 10,890.51438

Timestep Collection Time: 2.19451
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.59207

Cumulative Model Updates: 227,082
Cumulative Timesteps: 1,893,894,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.18713
Policy Entropy: 2.24081
Value Function Loss: 0.01474

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.59869

Collected Steps per Second: 22,954.06562
Overall Steps per Second: 10,841.04143

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.61358

Cumulative Model Updates: 227,088
Cumulative Timesteps: 1,893,944,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1893944654...
Checkpoint 1893944654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.34448
Policy Entropy: 2.26685
Value Function Loss: 0.01494

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.52465
Value Function Update Magnitude: 0.57661

Collected Steps per Second: 22,874.49368
Overall Steps per Second: 10,646.12279

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.51121
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.69748

Cumulative Model Updates: 227,094
Cumulative Timesteps: 1,893,994,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.72673
Policy Entropy: 2.26394
Value Function Loss: 0.01556

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.57630

Collected Steps per Second: 22,913.74641
Overall Steps per Second: 10,706.68716

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.67166

Cumulative Model Updates: 227,100
Cumulative Timesteps: 1,894,044,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1894044682...
Checkpoint 1894044682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.71125
Policy Entropy: 2.25124
Value Function Loss: 0.01521

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.53790
Value Function Update Magnitude: 0.58284

Collected Steps per Second: 22,331.70555
Overall Steps per Second: 10,711.09631

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.67104

Cumulative Model Updates: 227,106
Cumulative Timesteps: 1,894,094,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.17413
Policy Entropy: 2.22320
Value Function Loss: 0.01582

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.57977

Collected Steps per Second: 23,769.66901
Overall Steps per Second: 11,038.81468

Timestep Collection Time: 2.10478
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.53219

Cumulative Model Updates: 227,112
Cumulative Timesteps: 1,894,144,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1894144744...
Checkpoint 1894144744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.63917
Policy Entropy: 2.22555
Value Function Loss: 0.01599

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,759.96992
Overall Steps per Second: 10,676.43836

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.48697
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.68433

Cumulative Model Updates: 227,118
Cumulative Timesteps: 1,894,194,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.05426
Policy Entropy: 2.23325
Value Function Loss: 0.01566

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.53718
Value Function Update Magnitude: 0.61025

Collected Steps per Second: 22,900.67737
Overall Steps per Second: 10,862.58315

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.42010
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60388

Cumulative Model Updates: 227,124
Cumulative Timesteps: 1,894,244,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1894244766...
Checkpoint 1894244766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.39729
Policy Entropy: 2.24924
Value Function Loss: 0.01638

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.53963
Value Function Update Magnitude: 0.60990

Collected Steps per Second: 22,652.21453
Overall Steps per Second: 10,692.06041

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.67655

Cumulative Model Updates: 227,130
Cumulative Timesteps: 1,894,294,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.93051
Policy Entropy: 2.23008
Value Function Loss: 0.01671

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 23,713.78458
Overall Steps per Second: 10,903.96641

Timestep Collection Time: 2.10957
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.58787

Cumulative Model Updates: 227,136
Cumulative Timesteps: 1,894,344,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1894344794...
Checkpoint 1894344794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.83343
Policy Entropy: 2.22579
Value Function Loss: 0.01715

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.62063

Collected Steps per Second: 22,878.71045
Overall Steps per Second: 10,664.06513

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69014

Cumulative Model Updates: 227,142
Cumulative Timesteps: 1,894,394,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.09086
Policy Entropy: 2.22189
Value Function Loss: 0.01614

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.62234

Collected Steps per Second: 23,072.36363
Overall Steps per Second: 10,877.97700

Timestep Collection Time: 2.16727
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.59681

Cumulative Model Updates: 227,148
Cumulative Timesteps: 1,894,444,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1894444814...
Checkpoint 1894444814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.64941
Policy Entropy: 2.23458
Value Function Loss: 0.01522

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.60881

Collected Steps per Second: 22,750.71359
Overall Steps per Second: 10,832.90476

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.61631

Cumulative Model Updates: 227,154
Cumulative Timesteps: 1,894,494,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.90451
Policy Entropy: 2.25696
Value Function Loss: 0.01450

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.53024
Value Function Update Magnitude: 0.61209

Collected Steps per Second: 23,169.39883
Overall Steps per Second: 10,735.25207

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.50013
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.65867

Cumulative Model Updates: 227,160
Cumulative Timesteps: 1,894,544,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1894544834...
Checkpoint 1894544834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.01728
Policy Entropy: 2.25045
Value Function Loss: 0.01542

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.61984

Collected Steps per Second: 22,923.78844
Overall Steps per Second: 10,666.84112

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68967

Cumulative Model Updates: 227,166
Cumulative Timesteps: 1,894,594,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.15758
Policy Entropy: 2.25874
Value Function Loss: 0.01518

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.60248

Collected Steps per Second: 22,894.99729
Overall Steps per Second: 10,925.86446

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.39328
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.57794

Cumulative Model Updates: 227,172
Cumulative Timesteps: 1,894,644,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1894644876...
Checkpoint 1894644876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.67942
Policy Entropy: 2.24523
Value Function Loss: 0.01546

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 22,930.64100
Overall Steps per Second: 10,892.20595

Timestep Collection Time: 2.18119
Timestep Consumption Time: 2.41072
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.59191

Cumulative Model Updates: 227,178
Cumulative Timesteps: 1,894,694,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.02585
Policy Entropy: 2.25262
Value Function Loss: 0.01638

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.60205

Collected Steps per Second: 23,090.44776
Overall Steps per Second: 10,569.74375

Timestep Collection Time: 2.16652
Timestep Consumption Time: 2.56642
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 4.73294

Cumulative Model Updates: 227,184
Cumulative Timesteps: 1,894,744,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1894744918...
Checkpoint 1894744918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.91196
Policy Entropy: 2.21845
Value Function Loss: 0.01683

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.55519
Value Function Update Magnitude: 0.61130

Collected Steps per Second: 22,909.66799
Overall Steps per Second: 10,676.91304

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68469

Cumulative Model Updates: 227,190
Cumulative Timesteps: 1,894,794,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.32916
Policy Entropy: 2.22418
Value Function Loss: 0.01715

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 23,018.90802
Overall Steps per Second: 10,891.78320

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.59264

Cumulative Model Updates: 227,196
Cumulative Timesteps: 1,894,844,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1894844958...
Checkpoint 1894844958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.53646
Policy Entropy: 2.23389
Value Function Loss: 0.01687

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 22,901.29211
Overall Steps per Second: 11,050.95794

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.34234
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.52667

Cumulative Model Updates: 227,202
Cumulative Timesteps: 1,894,894,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.12583
Policy Entropy: 2.26685
Value Function Loss: 0.01607

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.54305
Value Function Update Magnitude: 0.58411

Collected Steps per Second: 22,940.84473
Overall Steps per Second: 10,692.68729

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.67703

Cumulative Model Updates: 227,208
Cumulative Timesteps: 1,894,944,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1894944992...
Checkpoint 1894944992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.27873
Policy Entropy: 2.27269
Value Function Loss: 0.01480

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.59935

Collected Steps per Second: 22,978.78748
Overall Steps per Second: 10,857.01887

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60753

Cumulative Model Updates: 227,214
Cumulative Timesteps: 1,894,995,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.50884
Policy Entropy: 2.24569
Value Function Loss: 0.01460

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 22,813.76698
Overall Steps per Second: 10,749.65238

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.45965
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.65131

Cumulative Model Updates: 227,220
Cumulative Timesteps: 1,895,045,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1895045016...
Checkpoint 1895045016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.35470
Policy Entropy: 2.21999
Value Function Loss: 0.01504

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.58729

Collected Steps per Second: 22,810.40105
Overall Steps per Second: 10,914.88710

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.38939
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.58182

Cumulative Model Updates: 227,226
Cumulative Timesteps: 1,895,095,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.09463
Policy Entropy: 2.21627
Value Function Loss: 0.01616

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.60094

Collected Steps per Second: 22,858.30210
Overall Steps per Second: 10,805.97478

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62966

Cumulative Model Updates: 227,232
Cumulative Timesteps: 1,895,145,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1895145054...
Checkpoint 1895145054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.75828
Policy Entropy: 2.22015
Value Function Loss: 0.01650

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.61113

Collected Steps per Second: 22,799.15471
Overall Steps per Second: 10,751.35511

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.65337

Cumulative Model Updates: 227,238
Cumulative Timesteps: 1,895,195,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.31547
Policy Entropy: 2.21093
Value Function Loss: 0.01714

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 23,003.57723
Overall Steps per Second: 10,838.00948

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61561

Cumulative Model Updates: 227,244
Cumulative Timesteps: 1,895,245,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1895245108...
Checkpoint 1895245108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.66591
Policy Entropy: 2.19335
Value Function Loss: 0.01689

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.60390

Collected Steps per Second: 22,624.96467
Overall Steps per Second: 10,822.43329

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.62022

Cumulative Model Updates: 227,250
Cumulative Timesteps: 1,895,295,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.21547
Policy Entropy: 2.18675
Value Function Loss: 0.01610

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.56977

Collected Steps per Second: 23,367.00710
Overall Steps per Second: 10,784.40763

Timestep Collection Time: 2.14080
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.63855

Cumulative Model Updates: 227,256
Cumulative Timesteps: 1,895,345,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1895345134...
Checkpoint 1895345134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.39010
Policy Entropy: 2.22364
Value Function Loss: 0.01559

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.55148

Collected Steps per Second: 22,249.91155
Overall Steps per Second: 10,648.50489

Timestep Collection Time: 2.24828
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.69775

Cumulative Model Updates: 227,262
Cumulative Timesteps: 1,895,395,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.06151
Policy Entropy: 2.22887
Value Function Loss: 0.01534

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.55107

Collected Steps per Second: 22,657.59638
Overall Steps per Second: 10,815.39491

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.41763
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62563

Cumulative Model Updates: 227,268
Cumulative Timesteps: 1,895,445,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1895445186...
Checkpoint 1895445186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.69831
Policy Entropy: 2.23000
Value Function Loss: 0.01564

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.55817

Collected Steps per Second: 22,838.91910
Overall Steps per Second: 10,876.44079

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.40900
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.59930

Cumulative Model Updates: 227,274
Cumulative Timesteps: 1,895,495,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.97442
Policy Entropy: 2.19603
Value Function Loss: 0.01592

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.54417
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 21,727.68258
Overall Steps per Second: 10,704.57400

Timestep Collection Time: 2.30250
Timestep Consumption Time: 2.37102
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67352

Cumulative Model Updates: 227,280
Cumulative Timesteps: 1,895,545,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1895545238...
Checkpoint 1895545238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.03946
Policy Entropy: 2.18622
Value Function Loss: 0.01527

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.57456

Collected Steps per Second: 22,906.10079
Overall Steps per Second: 10,675.48637

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68381

Cumulative Model Updates: 227,286
Cumulative Timesteps: 1,895,595,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.75868
Policy Entropy: 2.16334
Value Function Loss: 0.01587

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.55049
Value Function Update Magnitude: 0.58545

Collected Steps per Second: 22,690.80661
Overall Steps per Second: 10,660.62947

Timestep Collection Time: 2.20398
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69109

Cumulative Model Updates: 227,292
Cumulative Timesteps: 1,895,645,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1895645250...
Checkpoint 1895645250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.29503
Policy Entropy: 2.18056
Value Function Loss: 0.01588

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.15847
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.60759

Collected Steps per Second: 22,908.41407
Overall Steps per Second: 10,887.01744

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.59410

Cumulative Model Updates: 227,298
Cumulative Timesteps: 1,895,695,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.90955
Policy Entropy: 2.17978
Value Function Loss: 0.01641

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.16379
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.62187

Collected Steps per Second: 22,602.74161
Overall Steps per Second: 10,914.21291

Timestep Collection Time: 2.21345
Timestep Consumption Time: 2.37048
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.58393

Cumulative Model Updates: 227,304
Cumulative Timesteps: 1,895,745,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1895745296...
Checkpoint 1895745296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.64362
Policy Entropy: 2.19130
Value Function Loss: 0.01618

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.62499

Collected Steps per Second: 22,976.10256
Overall Steps per Second: 10,669.84029

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.68798

Cumulative Model Updates: 227,310
Cumulative Timesteps: 1,895,795,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.72429
Policy Entropy: 2.17865
Value Function Loss: 0.01769

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.18987
Policy Update Magnitude: 0.52158
Value Function Update Magnitude: 0.65108

Collected Steps per Second: 22,999.99963
Overall Steps per Second: 10,849.90535

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61036

Cumulative Model Updates: 227,316
Cumulative Timesteps: 1,895,845,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1895845338...
Checkpoint 1895845338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.41837
Policy Entropy: 2.16455
Value Function Loss: 0.01739

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.65062

Collected Steps per Second: 22,941.21557
Overall Steps per Second: 10,744.63574

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.65497

Cumulative Model Updates: 227,322
Cumulative Timesteps: 1,895,895,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.62647
Policy Entropy: 2.14196
Value Function Loss: 0.01807

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 23,001.30983
Overall Steps per Second: 10,912.20628

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.40833
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.58221

Cumulative Model Updates: 227,328
Cumulative Timesteps: 1,895,945,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1895945356...
Checkpoint 1895945356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.78210
Policy Entropy: 2.16591
Value Function Loss: 0.01641

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.58113
Value Function Update Magnitude: 0.63666

Collected Steps per Second: 22,784.34233
Overall Steps per Second: 10,960.31039

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.36743
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.56191

Cumulative Model Updates: 227,334
Cumulative Timesteps: 1,895,995,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.58691
Policy Entropy: 2.18064
Value Function Loss: 0.01613

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.64452

Collected Steps per Second: 22,799.39306
Overall Steps per Second: 10,463.86590

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.58562
PPO Batch Consumption Time: 0.30680
Total Iteration Time: 4.77892

Cumulative Model Updates: 227,340
Cumulative Timesteps: 1,896,045,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1896045362...
Checkpoint 1896045362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.21789
Policy Entropy: 2.18489
Value Function Loss: 0.01651

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.65229

Collected Steps per Second: 22,880.29263
Overall Steps per Second: 10,759.24759

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.65144

Cumulative Model Updates: 227,346
Cumulative Timesteps: 1,896,095,408

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.00926
Policy Entropy: 2.19036
Value Function Loss: 0.01594

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 22,800.85777
Overall Steps per Second: 10,826.16791

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.62010

Cumulative Model Updates: 227,352
Cumulative Timesteps: 1,896,145,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1896145426...
Checkpoint 1896145426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.13668
Policy Entropy: 2.18355
Value Function Loss: 0.01657

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.60574

Collected Steps per Second: 23,604.52940
Overall Steps per Second: 10,885.02081

Timestep Collection Time: 2.11959
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.59641

Cumulative Model Updates: 227,358
Cumulative Timesteps: 1,896,195,458

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.93660
Policy Entropy: 2.19427
Value Function Loss: 0.01493

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.58583

Collected Steps per Second: 23,207.15535
Overall Steps per Second: 10,737.71716

Timestep Collection Time: 2.15459
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.65667

Cumulative Model Updates: 227,364
Cumulative Timesteps: 1,896,245,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1896245460...
Checkpoint 1896245460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.00542
Policy Entropy: 2.23052
Value Function Loss: 0.01504

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.56613

Collected Steps per Second: 22,647.88691
Overall Steps per Second: 10,628.69053

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.70462

Cumulative Model Updates: 227,370
Cumulative Timesteps: 1,896,295,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.91022
Policy Entropy: 2.23732
Value Function Loss: 0.01514

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.55830

Collected Steps per Second: 22,913.50507
Overall Steps per Second: 10,906.10102

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.40391
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.58734

Cumulative Model Updates: 227,376
Cumulative Timesteps: 1,896,345,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1896345494...
Checkpoint 1896345494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.34660
Policy Entropy: 2.25726
Value Function Loss: 0.01514

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.57156

Collected Steps per Second: 22,963.06218
Overall Steps per Second: 10,686.09306

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.68141

Cumulative Model Updates: 227,382
Cumulative Timesteps: 1,896,395,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.89510
Policy Entropy: 2.22051
Value Function Loss: 0.01569

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.52655
Value Function Update Magnitude: 0.57503

Collected Steps per Second: 22,812.11409
Overall Steps per Second: 10,775.38992

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.64225

Cumulative Model Updates: 227,388
Cumulative Timesteps: 1,896,445,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1896445542...
Checkpoint 1896445542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.44734
Policy Entropy: 2.22765
Value Function Loss: 0.01567

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 22,725.50462
Overall Steps per Second: 10,718.02678

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.66597

Cumulative Model Updates: 227,394
Cumulative Timesteps: 1,896,495,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.42268
Policy Entropy: 2.22024
Value Function Loss: 0.01501

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.53148
Value Function Update Magnitude: 0.58591

Collected Steps per Second: 22,640.96973
Overall Steps per Second: 10,912.26505

Timestep Collection Time: 2.20945
Timestep Consumption Time: 2.37475
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.58420

Cumulative Model Updates: 227,400
Cumulative Timesteps: 1,896,545,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1896545576...
Checkpoint 1896545576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.36203
Policy Entropy: 2.24193
Value Function Loss: 0.01508

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.59392

Collected Steps per Second: 22,980.65828
Overall Steps per Second: 10,673.66281

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.68555

Cumulative Model Updates: 227,406
Cumulative Timesteps: 1,896,595,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.91213
Policy Entropy: 2.23164
Value Function Loss: 0.01556

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.59674

Collected Steps per Second: 22,933.29632
Overall Steps per Second: 10,825.38180

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62118

Cumulative Model Updates: 227,412
Cumulative Timesteps: 1,896,645,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1896645614...
Checkpoint 1896645614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.16890
Policy Entropy: 2.21333
Value Function Loss: 0.01632

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.53812
Value Function Update Magnitude: 0.59899

Collected Steps per Second: 22,390.02729
Overall Steps per Second: 10,678.05728

Timestep Collection Time: 2.23358
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.68344

Cumulative Model Updates: 227,418
Cumulative Timesteps: 1,896,695,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.64156
Policy Entropy: 2.18959
Value Function Loss: 0.01661

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.57424

Collected Steps per Second: 22,616.61202
Overall Steps per Second: 10,810.47634

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.41448
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.62533

Cumulative Model Updates: 227,424
Cumulative Timesteps: 1,896,745,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1896745626...
Checkpoint 1896745626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.92564
Policy Entropy: 2.22316
Value Function Loss: 0.01526

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.52906
Value Function Update Magnitude: 0.55985

Collected Steps per Second: 22,654.71278
Overall Steps per Second: 10,763.02654

Timestep Collection Time: 2.20802
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64758

Cumulative Model Updates: 227,430
Cumulative Timesteps: 1,896,795,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.94614
Policy Entropy: 2.23232
Value Function Loss: 0.01434

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.54258

Collected Steps per Second: 22,910.17800
Overall Steps per Second: 10,799.92657

Timestep Collection Time: 2.18313
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63114

Cumulative Model Updates: 227,436
Cumulative Timesteps: 1,896,845,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1896845664...
Checkpoint 1896845664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.44159
Policy Entropy: 2.24435
Value Function Loss: 0.01430

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.51627
Value Function Update Magnitude: 0.54081

Collected Steps per Second: 22,857.76145
Overall Steps per Second: 10,753.70688

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.64956

Cumulative Model Updates: 227,442
Cumulative Timesteps: 1,896,895,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.37601
Policy Entropy: 2.24367
Value Function Loss: 0.01545

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.57529

Collected Steps per Second: 23,007.15410
Overall Steps per Second: 10,908.15430

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.41290
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.58831

Cumulative Model Updates: 227,448
Cumulative Timesteps: 1,896,945,714

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1896945714...
Checkpoint 1896945714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.65448
Policy Entropy: 2.24664
Value Function Loss: 0.01609

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.53248
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 22,816.34698
Overall Steps per Second: 10,608.76261

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.52208
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.71384

Cumulative Model Updates: 227,454
Cumulative Timesteps: 1,896,995,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.05748
Policy Entropy: 2.24302
Value Function Loss: 0.01588

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.61922

Collected Steps per Second: 22,893.10204
Overall Steps per Second: 10,736.63361

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.65844

Cumulative Model Updates: 227,460
Cumulative Timesteps: 1,897,045,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1897045738...
Checkpoint 1897045738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.10445
Policy Entropy: 2.23902
Value Function Loss: 0.01524

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 22,793.66114
Overall Steps per Second: 10,897.43333

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.39570
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.59026

Cumulative Model Updates: 227,466
Cumulative Timesteps: 1,897,095,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.06740
Policy Entropy: 2.22673
Value Function Loss: 0.01605

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.52918
Value Function Update Magnitude: 0.60266

Collected Steps per Second: 23,729.64825
Overall Steps per Second: 10,844.52027

Timestep Collection Time: 2.10774
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.61210

Cumulative Model Updates: 227,472
Cumulative Timesteps: 1,897,145,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1897145776...
Checkpoint 1897145776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.10789
Policy Entropy: 2.21031
Value Function Loss: 0.01671

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.58615

Collected Steps per Second: 22,875.29666
Overall Steps per Second: 10,659.82429

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69295

Cumulative Model Updates: 227,478
Cumulative Timesteps: 1,897,195,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.35531
Policy Entropy: 2.16264
Value Function Loss: 0.01700

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.58793

Collected Steps per Second: 23,013.57325
Overall Steps per Second: 10,900.00409

Timestep Collection Time: 2.17289
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.58770

Cumulative Model Updates: 227,484
Cumulative Timesteps: 1,897,245,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1897245808...
Checkpoint 1897245808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.78670
Policy Entropy: 2.17460
Value Function Loss: 0.01650

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.60785

Collected Steps per Second: 22,919.79168
Overall Steps per Second: 10,738.69923

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.65606

Cumulative Model Updates: 227,490
Cumulative Timesteps: 1,897,295,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.40688
Policy Entropy: 2.18531
Value Function Loss: 0.01588

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.59769

Collected Steps per Second: 23,950.20755
Overall Steps per Second: 10,865.05015

Timestep Collection Time: 2.08792
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.60246

Cumulative Model Updates: 227,496
Cumulative Timesteps: 1,897,345,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1897345814...
Checkpoint 1897345814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.93915
Policy Entropy: 2.21863
Value Function Loss: 0.01534

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.57779

Collected Steps per Second: 23,019.54199
Overall Steps per Second: 10,636.51036

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.53014
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.70342

Cumulative Model Updates: 227,502
Cumulative Timesteps: 1,897,395,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.61839
Policy Entropy: 2.21638
Value Function Loss: 0.01478

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.53881

Collected Steps per Second: 22,499.74791
Overall Steps per Second: 10,809.11514

Timestep Collection Time: 2.22242
Timestep Consumption Time: 2.40367
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62610

Cumulative Model Updates: 227,508
Cumulative Timesteps: 1,897,445,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1897445846...
Checkpoint 1897445846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.56472
Policy Entropy: 2.18941
Value Function Loss: 0.01536

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.54297

Collected Steps per Second: 22,868.37803
Overall Steps per Second: 10,900.31887

Timestep Collection Time: 2.18721
Timestep Consumption Time: 2.40146
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.58867

Cumulative Model Updates: 227,514
Cumulative Timesteps: 1,897,495,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.84449
Policy Entropy: 2.19506
Value Function Loss: 0.01532

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.53880
Value Function Update Magnitude: 0.56404

Collected Steps per Second: 23,125.81195
Overall Steps per Second: 10,713.68404

Timestep Collection Time: 2.16338
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.66973

Cumulative Model Updates: 227,520
Cumulative Timesteps: 1,897,545,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1897545894...
Checkpoint 1897545894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.41572
Policy Entropy: 2.21485
Value Function Loss: 0.01703

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.58515

Collected Steps per Second: 22,885.82482
Overall Steps per Second: 10,608.98451

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.52914
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.71468

Cumulative Model Updates: 227,526
Cumulative Timesteps: 1,897,595,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.72150
Policy Entropy: 2.24698
Value Function Loss: 0.01667

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,620.71830
Overall Steps per Second: 10,683.93571

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68180

Cumulative Model Updates: 227,532
Cumulative Timesteps: 1,897,645,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1897645932...
Checkpoint 1897645932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.73570
Policy Entropy: 2.24972
Value Function Loss: 0.01681

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.62369

Collected Steps per Second: 22,639.46732
Overall Steps per Second: 10,926.96600

Timestep Collection Time: 2.20933
Timestep Consumption Time: 2.36816
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.57748

Cumulative Model Updates: 227,538
Cumulative Timesteps: 1,897,695,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.82372
Policy Entropy: 2.23693
Value Function Loss: 0.01714

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.62869

Collected Steps per Second: 23,164.23635
Overall Steps per Second: 10,869.11891

Timestep Collection Time: 2.15867
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60056

Cumulative Model Updates: 227,544
Cumulative Timesteps: 1,897,745,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1897745954...
Checkpoint 1897745954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.70723
Policy Entropy: 2.23212
Value Function Loss: 0.01711

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.62769

Collected Steps per Second: 22,747.02913
Overall Steps per Second: 10,636.24010

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70298

Cumulative Model Updates: 227,550
Cumulative Timesteps: 1,897,795,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.11548
Policy Entropy: 2.24596
Value Function Loss: 0.01670

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.62096

Collected Steps per Second: 22,710.12552
Overall Steps per Second: 10,818.74644

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62383

Cumulative Model Updates: 227,556
Cumulative Timesteps: 1,897,846,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1897846000...
Checkpoint 1897846000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.73175
Policy Entropy: 2.22736
Value Function Loss: 0.01547

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.60332

Collected Steps per Second: 22,716.68958
Overall Steps per Second: 10,824.52746

Timestep Collection Time: 2.20226
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.62173

Cumulative Model Updates: 227,562
Cumulative Timesteps: 1,897,896,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.85616
Policy Entropy: 2.21080
Value Function Loss: 0.01556

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.53230
Value Function Update Magnitude: 0.59722

Collected Steps per Second: 23,072.57691
Overall Steps per Second: 10,875.60662

Timestep Collection Time: 2.16707
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.59744

Cumulative Model Updates: 227,568
Cumulative Timesteps: 1,897,946,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1897946028...
Checkpoint 1897946028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.40496
Policy Entropy: 2.15974
Value Function Loss: 0.01705

Mean KL Divergence: 0.03432
SB3 Clip Fraction: 0.19067
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.59103

Collected Steps per Second: 22,811.07228
Overall Steps per Second: 10,636.17672

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.70338

Cumulative Model Updates: 227,574
Cumulative Timesteps: 1,897,996,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.85553
Policy Entropy: 2.16477
Value Function Loss: 0.01697

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.17201
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.61584

Collected Steps per Second: 22,863.99665
Overall Steps per Second: 10,807.20147

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.62914

Cumulative Model Updates: 227,580
Cumulative Timesteps: 1,898,046,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1898046082...
Checkpoint 1898046082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.10051
Policy Entropy: 2.16114
Value Function Loss: 0.01652

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.63670

Collected Steps per Second: 22,729.01163
Overall Steps per Second: 10,695.66027

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.30549
Total Iteration Time: 4.67722

Cumulative Model Updates: 227,586
Cumulative Timesteps: 1,898,096,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.12249
Policy Entropy: 2.19799
Value Function Loss: 0.01505

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.62643

Collected Steps per Second: 22,840.02592
Overall Steps per Second: 10,814.15937

Timestep Collection Time: 2.18958
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62449

Cumulative Model Updates: 227,592
Cumulative Timesteps: 1,898,146,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1898146118...
Checkpoint 1898146118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.26820
Policy Entropy: 2.21237
Value Function Loss: 0.01522

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.61452

Collected Steps per Second: 22,532.47948
Overall Steps per Second: 10,767.54163

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.64451

Cumulative Model Updates: 227,598
Cumulative Timesteps: 1,898,196,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.59547
Policy Entropy: 2.20359
Value Function Loss: 0.01582

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,757.22913
Overall Steps per Second: 10,849.01701

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.41306
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61148

Cumulative Model Updates: 227,604
Cumulative Timesteps: 1,898,246,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1898246158...
Checkpoint 1898246158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.37208
Policy Entropy: 2.18736
Value Function Loss: 0.01573

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.53902
Value Function Update Magnitude: 0.60532

Collected Steps per Second: 22,763.40841
Overall Steps per Second: 10,871.06170

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.40315
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.59992

Cumulative Model Updates: 227,610
Cumulative Timesteps: 1,898,296,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.93371
Policy Entropy: 2.20844
Value Function Loss: 0.01534

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.59307

Collected Steps per Second: 23,372.41086
Overall Steps per Second: 10,765.55122

Timestep Collection Time: 2.14013
Timestep Consumption Time: 2.50617
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.64630

Cumulative Model Updates: 227,616
Cumulative Timesteps: 1,898,346,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1898346184...
Checkpoint 1898346184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.13552
Policy Entropy: 2.21196
Value Function Loss: 0.01514

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.59035

Collected Steps per Second: 22,748.12999
Overall Steps per Second: 10,634.87689

Timestep Collection Time: 2.19904
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.70377

Cumulative Model Updates: 227,622
Cumulative Timesteps: 1,898,396,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.41606
Policy Entropy: 2.19827
Value Function Loss: 0.01582

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.60316

Collected Steps per Second: 22,921.35829
Overall Steps per Second: 10,873.97296

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.41676
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59814

Cumulative Model Updates: 227,628
Cumulative Timesteps: 1,898,446,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1898446208...
Checkpoint 1898446208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.05126
Policy Entropy: 2.17561
Value Function Loss: 0.01721

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.61474

Collected Steps per Second: 23,482.50881
Overall Steps per Second: 10,990.44583

Timestep Collection Time: 2.13061
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.55232

Cumulative Model Updates: 227,634
Cumulative Timesteps: 1,898,496,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.04117
Policy Entropy: 2.19584
Value Function Loss: 0.01697

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.56048
Value Function Update Magnitude: 0.61361

Collected Steps per Second: 22,788.03383
Overall Steps per Second: 10,679.08514

Timestep Collection Time: 2.19466
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.68317

Cumulative Model Updates: 227,640
Cumulative Timesteps: 1,898,546,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1898546252...
Checkpoint 1898546252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.25348
Policy Entropy: 2.20558
Value Function Loss: 0.01679

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.60156

Collected Steps per Second: 22,539.56420
Overall Steps per Second: 10,691.72562

Timestep Collection Time: 2.21939
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.67876

Cumulative Model Updates: 227,646
Cumulative Timesteps: 1,898,596,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.62636
Policy Entropy: 2.19658
Value Function Loss: 0.01620

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.59074

Collected Steps per Second: 22,863.40853
Overall Steps per Second: 10,887.88729

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.40584
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.59318

Cumulative Model Updates: 227,652
Cumulative Timesteps: 1,898,646,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1898646286...
Checkpoint 1898646286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.28514
Policy Entropy: 2.17887
Value Function Loss: 0.01583

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 22,079.59815
Overall Steps per Second: 10,727.99775

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.39703
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.66238

Cumulative Model Updates: 227,658
Cumulative Timesteps: 1,898,696,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.60190
Policy Entropy: 2.18218
Value Function Loss: 0.01633

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.60005

Collected Steps per Second: 22,502.85751
Overall Steps per Second: 10,712.42602

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.44612
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.66860

Cumulative Model Updates: 227,664
Cumulative Timesteps: 1,898,746,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1898746316...
Checkpoint 1898746316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.01764
Policy Entropy: 2.17794
Value Function Loss: 0.01538

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.54755
Value Function Update Magnitude: 0.60568

Collected Steps per Second: 22,451.82797
Overall Steps per Second: 10,634.21618

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.70237

Cumulative Model Updates: 227,670
Cumulative Timesteps: 1,898,796,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.12663
Policy Entropy: 2.18695
Value Function Loss: 0.01564

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.59288

Collected Steps per Second: 23,004.82985
Overall Steps per Second: 10,912.55696

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.40910
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.58316

Cumulative Model Updates: 227,676
Cumulative Timesteps: 1,898,846,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1898846336...
Checkpoint 1898846336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.16513
Policy Entropy: 2.19555
Value Function Loss: 0.01483

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.58421

Collected Steps per Second: 22,980.43102
Overall Steps per Second: 11,032.05414

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.35667
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.53261

Cumulative Model Updates: 227,682
Cumulative Timesteps: 1,898,896,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.21040
Policy Entropy: 2.20872
Value Function Loss: 0.01461

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.59178

Collected Steps per Second: 22,865.18151
Overall Steps per Second: 10,705.74205

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.67189

Cumulative Model Updates: 227,688
Cumulative Timesteps: 1,898,946,356

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1898946356...
Checkpoint 1898946356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.29982
Policy Entropy: 2.19835
Value Function Loss: 0.01408

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.58670

Collected Steps per Second: 22,977.03523
Overall Steps per Second: 10,855.76927

Timestep Collection Time: 2.17670
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.60714

Cumulative Model Updates: 227,694
Cumulative Timesteps: 1,898,996,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.75370
Policy Entropy: 2.18428
Value Function Loss: 0.01386

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.56777

Collected Steps per Second: 22,800.62511
Overall Steps per Second: 10,857.59687

Timestep Collection Time: 2.19327
Timestep Consumption Time: 2.41253
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60581

Cumulative Model Updates: 227,700
Cumulative Timesteps: 1,899,046,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1899046378...
Checkpoint 1899046378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.56070
Policy Entropy: 2.18815
Value Function Loss: 0.01542

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.54340
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 22,754.05270
Overall Steps per Second: 10,830.22573

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.61929

Cumulative Model Updates: 227,706
Cumulative Timesteps: 1,899,096,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.13002
Policy Entropy: 2.18847
Value Function Loss: 0.01649

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.58127

Collected Steps per Second: 23,278.29414
Overall Steps per Second: 10,825.59663

Timestep Collection Time: 2.14887
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.62072

Cumulative Model Updates: 227,712
Cumulative Timesteps: 1,899,146,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1899146428...
Checkpoint 1899146428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.67938
Policy Entropy: 2.17304
Value Function Loss: 0.01829

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.56087
Value Function Update Magnitude: 0.59594

Collected Steps per Second: 22,799.82176
Overall Steps per Second: 10,749.46957

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.65139

Cumulative Model Updates: 227,718
Cumulative Timesteps: 1,899,196,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.44150
Policy Entropy: 2.17350
Value Function Loss: 0.01743

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 22,998.05796
Overall Steps per Second: 10,854.43753

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.60752

Cumulative Model Updates: 227,724
Cumulative Timesteps: 1,899,246,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1899246440...
Checkpoint 1899246440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.35177
Policy Entropy: 2.18611
Value Function Loss: 0.01708

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.64204

Collected Steps per Second: 23,119.76067
Overall Steps per Second: 10,758.98975

Timestep Collection Time: 2.16343
Timestep Consumption Time: 2.48552
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.64895

Cumulative Model Updates: 227,730
Cumulative Timesteps: 1,899,296,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.01323
Policy Entropy: 2.23385
Value Function Loss: 0.01610

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.63239

Collected Steps per Second: 22,716.71246
Overall Steps per Second: 10,727.08580

Timestep Collection Time: 2.20208
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.66334

Cumulative Model Updates: 227,736
Cumulative Timesteps: 1,899,346,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1899346482...
Checkpoint 1899346482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.31273
Policy Entropy: 2.25303
Value Function Loss: 0.01666

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.62267

Collected Steps per Second: 22,733.97871
Overall Steps per Second: 10,526.99345

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.55055
PPO Batch Consumption Time: 0.30761
Total Iteration Time: 4.75007

Cumulative Model Updates: 227,742
Cumulative Timesteps: 1,899,396,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.92557
Policy Entropy: 2.24149
Value Function Loss: 0.01603

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.60536

Collected Steps per Second: 22,990.23046
Overall Steps per Second: 10,867.77570

Timestep Collection Time: 2.17527
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.60168

Cumulative Model Updates: 227,748
Cumulative Timesteps: 1,899,446,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1899446496...
Checkpoint 1899446496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.29689
Policy Entropy: 2.23621
Value Function Loss: 0.01646

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.60534

Collected Steps per Second: 22,847.84480
Overall Steps per Second: 10,790.00757

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.63540

Cumulative Model Updates: 227,754
Cumulative Timesteps: 1,899,496,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.45400
Policy Entropy: 2.20151
Value Function Loss: 0.01619

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.55142
Value Function Update Magnitude: 0.59406

Collected Steps per Second: 22,206.46175
Overall Steps per Second: 10,496.59361

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.51236
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.76440

Cumulative Model Updates: 227,760
Cumulative Timesteps: 1,899,546,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1899546522...
Checkpoint 1899546522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.46349
Policy Entropy: 2.22822
Value Function Loss: 0.01671

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.15792
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.60079

Collected Steps per Second: 22,808.00705
Overall Steps per Second: 10,620.61205

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.70914

Cumulative Model Updates: 227,766
Cumulative Timesteps: 1,899,596,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.83581
Policy Entropy: 2.23407
Value Function Loss: 0.01588

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.59059

Collected Steps per Second: 22,801.40776
Overall Steps per Second: 10,824.09749

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.42745
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.62117

Cumulative Model Updates: 227,772
Cumulative Timesteps: 1,899,646,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1899646556...
Checkpoint 1899646556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.89298
Policy Entropy: 2.28389
Value Function Loss: 0.01525

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.16320
Policy Update Magnitude: 0.51556
Value Function Update Magnitude: 0.56757

Collected Steps per Second: 22,569.20621
Overall Steps per Second: 10,774.56657

Timestep Collection Time: 2.21541
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.64056

Cumulative Model Updates: 227,778
Cumulative Timesteps: 1,899,696,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.99693
Policy Entropy: 2.22541
Value Function Loss: 0.01620

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.55744

Collected Steps per Second: 19,853.07801
Overall Steps per Second: 9,963.93467

Timestep Collection Time: 2.51961
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 5.02031

Cumulative Model Updates: 227,784
Cumulative Timesteps: 1,899,746,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1899746578...
Checkpoint 1899746578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.89033
Policy Entropy: 2.21866
Value Function Loss: 0.01568

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.58365

Collected Steps per Second: 22,439.49135
Overall Steps per Second: 10,683.66777

Timestep Collection Time: 2.22821
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.68004

Cumulative Model Updates: 227,790
Cumulative Timesteps: 1,899,796,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.72658
Policy Entropy: 2.21212
Value Function Loss: 0.01515

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 22,719.00351
Overall Steps per Second: 10,895.93519

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.38940
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.59144

Cumulative Model Updates: 227,796
Cumulative Timesteps: 1,899,846,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1899846606...
Checkpoint 1899846606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.42588
Policy Entropy: 2.21415
Value Function Loss: 0.01485

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.54463
Value Function Update Magnitude: 0.57630

Collected Steps per Second: 22,060.68572
Overall Steps per Second: 10,638.14811

Timestep Collection Time: 2.26765
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.70251

Cumulative Model Updates: 227,802
Cumulative Timesteps: 1,899,896,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.13120
Policy Entropy: 2.20403
Value Function Loss: 0.01532

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.56224

Collected Steps per Second: 22,708.41089
Overall Steps per Second: 10,624.85143

Timestep Collection Time: 2.20262
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70764

Cumulative Model Updates: 227,808
Cumulative Timesteps: 1,899,946,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1899946650...
Checkpoint 1899946650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.51899
Policy Entropy: 2.19268
Value Function Loss: 0.01559

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.54080
Value Function Update Magnitude: 0.54990

Collected Steps per Second: 22,756.79111
Overall Steps per Second: 10,803.83860

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62965

Cumulative Model Updates: 227,814
Cumulative Timesteps: 1,899,996,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.84316
Policy Entropy: 2.21904
Value Function Loss: 0.01587

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.54643

Collected Steps per Second: 22,644.91360
Overall Steps per Second: 10,946.91013

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.36157
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.57152

Cumulative Model Updates: 227,820
Cumulative Timesteps: 1,900,046,712

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1900046712...
Checkpoint 1900046712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.57102
Policy Entropy: 2.25585
Value Function Loss: 0.01581

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.58102

Collected Steps per Second: 22,797.53105
Overall Steps per Second: 10,563.46534

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.54129
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.73557

Cumulative Model Updates: 227,826
Cumulative Timesteps: 1,900,096,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.07912
Policy Entropy: 2.25010
Value Function Loss: 0.01538

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.59788

Collected Steps per Second: 22,783.28825
Overall Steps per Second: 10,604.02815

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.71783

Cumulative Model Updates: 227,832
Cumulative Timesteps: 1,900,146,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1900146764...
Checkpoint 1900146764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.64208
Policy Entropy: 2.23252
Value Function Loss: 0.01571

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 22,073.81564
Overall Steps per Second: 10,639.90007

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.69967

Cumulative Model Updates: 227,838
Cumulative Timesteps: 1,900,196,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.02648
Policy Entropy: 2.20654
Value Function Loss: 0.01641

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.60278

Collected Steps per Second: 22,913.61326
Overall Steps per Second: 10,874.66144

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59932

Cumulative Model Updates: 227,844
Cumulative Timesteps: 1,900,246,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1900246784...
Checkpoint 1900246784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.07211
Policy Entropy: 2.22436
Value Function Loss: 0.01654

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.60078

Collected Steps per Second: 22,358.42829
Overall Steps per Second: 10,686.78483

Timestep Collection Time: 2.23638
Timestep Consumption Time: 2.44248
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.67886

Cumulative Model Updates: 227,850
Cumulative Timesteps: 1,900,296,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.91587
Policy Entropy: 2.24706
Value Function Loss: 0.01534

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.58703

Collected Steps per Second: 22,421.10155
Overall Steps per Second: 10,643.61959

Timestep Collection Time: 2.23093
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69953

Cumulative Model Updates: 227,856
Cumulative Timesteps: 1,900,346,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900346806...
Checkpoint 1900346806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.30390
Policy Entropy: 2.24842
Value Function Loss: 0.01383

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.52614
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 22,639.93482
Overall Steps per Second: 10,708.98449

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.67028

Cumulative Model Updates: 227,862
Cumulative Timesteps: 1,900,396,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.57993
Policy Entropy: 2.24480
Value Function Loss: 0.01344

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.52595
Value Function Update Magnitude: 0.57552

Collected Steps per Second: 22,532.98585
Overall Steps per Second: 10,639.53664

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.70096

Cumulative Model Updates: 227,868
Cumulative Timesteps: 1,900,446,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1900446836...
Checkpoint 1900446836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.52170
Policy Entropy: 2.23286
Value Function Loss: 0.01422

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.53089
Value Function Update Magnitude: 0.57927

Collected Steps per Second: 22,765.20515
Overall Steps per Second: 10,648.32718

Timestep Collection Time: 2.19739
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.69783

Cumulative Model Updates: 227,874
Cumulative Timesteps: 1,900,496,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.96366
Policy Entropy: 2.24137
Value Function Loss: 0.01526

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.57646

Collected Steps per Second: 23,487.90342
Overall Steps per Second: 10,882.70906

Timestep Collection Time: 2.12969
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.59647

Cumulative Model Updates: 227,880
Cumulative Timesteps: 1,900,546,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1900546882...
Checkpoint 1900546882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.05631
Policy Entropy: 2.24698
Value Function Loss: 0.01580

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.57379

Collected Steps per Second: 22,893.69156
Overall Steps per Second: 10,667.99350

Timestep Collection Time: 2.18436
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.68767

Cumulative Model Updates: 227,886
Cumulative Timesteps: 1,900,596,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------
