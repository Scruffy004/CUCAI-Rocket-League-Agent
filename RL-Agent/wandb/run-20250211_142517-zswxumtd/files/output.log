Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.58561
Policy Entropy: 3.16510
Value Function Loss: 0.00448

Mean KL Divergence: 0.00084
SB3 Clip Fraction: 0.00584
Policy Update Magnitude: 0.20137
Value Function Update Magnitude: 0.19446

Collected Steps per Second: 7,019.66851
Overall Steps per Second: 3,557.22813

Timestep Collection Time: 7.12341
Timestep Consumption Time: 6.93360
PPO Batch Consumption Time: 2.88519
Total Iteration Time: 14.05701

Cumulative Model Updates: 122,454
Cumulative Timesteps: 1,021,269,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.17475
Policy Entropy: 3.16211
Value Function Loss: 0.00442

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.21808
Value Function Update Magnitude: 0.19470

Collected Steps per Second: 19,286.82490
Overall Steps per Second: 12,447.73445

Timestep Collection Time: 2.59244
Timestep Consumption Time: 1.42435
PPO Batch Consumption Time: 0.31410
Total Iteration Time: 4.01680

Cumulative Model Updates: 122,456
Cumulative Timesteps: 1,021,319,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1021319436...
Checkpoint 1021319436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.90458
Policy Entropy: 3.16175
Value Function Loss: 0.00457

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.42219
Value Function Update Magnitude: 0.37993

Collected Steps per Second: 20,019.75081
Overall Steps per Second: 11,257.41860

Timestep Collection Time: 2.49873
Timestep Consumption Time: 1.94492
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.44365

Cumulative Model Updates: 122,460
Cumulative Timesteps: 1,021,369,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.41009
Policy Entropy: 3.15108
Value Function Loss: 0.00466

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.58476
Value Function Update Magnitude: 0.53704

Collected Steps per Second: 21,450.61223
Overall Steps per Second: 10,215.99760

Timestep Collection Time: 2.33168
Timestep Consumption Time: 2.56417
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.89585

Cumulative Model Updates: 122,466
Cumulative Timesteps: 1,021,419,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1021419476...
Checkpoint 1021419476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.64677
Policy Entropy: 3.15402
Value Function Loss: 0.00477

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.51218

Collected Steps per Second: 19,684.14675
Overall Steps per Second: 9,808.68206

Timestep Collection Time: 2.54052
Timestep Consumption Time: 2.55782
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 5.09834

Cumulative Model Updates: 122,472
Cumulative Timesteps: 1,021,469,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.28242
Policy Entropy: 3.14960
Value Function Loss: 0.00429

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.50877

Collected Steps per Second: 21,541.45097
Overall Steps per Second: 10,475.62855

Timestep Collection Time: 2.32213
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.77508

Cumulative Model Updates: 122,478
Cumulative Timesteps: 1,021,519,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1021519506...
Checkpoint 1021519506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.57215
Policy Entropy: 3.15306
Value Function Loss: 0.00432

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.53618
Value Function Update Magnitude: 0.51607

Collected Steps per Second: 21,769.10611
Overall Steps per Second: 10,220.80686

Timestep Collection Time: 2.29766
Timestep Consumption Time: 2.59608
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.89374

Cumulative Model Updates: 122,484
Cumulative Timesteps: 1,021,569,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.14987
Policy Entropy: 3.15208
Value Function Loss: 0.00425

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.49835

Collected Steps per Second: 19,193.26134
Overall Steps per Second: 9,832.72416

Timestep Collection Time: 2.60581
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 5.08648

Cumulative Model Updates: 122,490
Cumulative Timesteps: 1,021,619,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1021619538...
Checkpoint 1021619538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.05759
Policy Entropy: 3.14472
Value Function Loss: 0.00421

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.47705

Collected Steps per Second: 19,024.35661
Overall Steps per Second: 9,478.63222

Timestep Collection Time: 2.62979
Timestep Consumption Time: 2.64840
PPO Batch Consumption Time: 0.30745
Total Iteration Time: 5.27819

Cumulative Model Updates: 122,496
Cumulative Timesteps: 1,021,669,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.58732
Policy Entropy: 3.13776
Value Function Loss: 0.00410

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.52546
Value Function Update Magnitude: 0.48222

Collected Steps per Second: 21,695.79796
Overall Steps per Second: 10,083.32557

Timestep Collection Time: 2.30478
Timestep Consumption Time: 2.65430
PPO Batch Consumption Time: 0.31193
Total Iteration Time: 4.95908

Cumulative Model Updates: 122,502
Cumulative Timesteps: 1,021,719,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1021719572...
Checkpoint 1021719572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.83047
Policy Entropy: 3.13034
Value Function Loss: 0.00400

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.53062
Value Function Update Magnitude: 0.49091

Collected Steps per Second: 21,032.47543
Overall Steps per Second: 9,897.22266

Timestep Collection Time: 2.37775
Timestep Consumption Time: 2.67518
PPO Batch Consumption Time: 0.31904
Total Iteration Time: 5.05293

Cumulative Model Updates: 122,508
Cumulative Timesteps: 1,021,769,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.75588
Policy Entropy: 3.13460
Value Function Loss: 0.00374

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.52527
Value Function Update Magnitude: 0.49518

Collected Steps per Second: 19,038.70856
Overall Steps per Second: 9,672.18672

Timestep Collection Time: 2.62633
Timestep Consumption Time: 2.54334
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 5.16967

Cumulative Model Updates: 122,514
Cumulative Timesteps: 1,021,819,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1021819584...
Checkpoint 1021819584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.26017
Policy Entropy: 3.12653
Value Function Loss: 0.00386

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.52629
Value Function Update Magnitude: 0.48350

Collected Steps per Second: 21,269.58342
Overall Steps per Second: 10,209.07587

Timestep Collection Time: 2.35209
Timestep Consumption Time: 2.54825
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.90035

Cumulative Model Updates: 122,520
Cumulative Timesteps: 1,021,869,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.42045
Policy Entropy: 3.13026
Value Function Loss: 0.00410

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.54327
Value Function Update Magnitude: 0.48834

Collected Steps per Second: 20,286.39352
Overall Steps per Second: 10,079.22828

Timestep Collection Time: 2.46559
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.96248

Cumulative Model Updates: 122,526
Cumulative Timesteps: 1,021,919,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1021919630...
Checkpoint 1021919630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.00057
Policy Entropy: 3.12545
Value Function Loss: 0.00417

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.51148

Collected Steps per Second: 20,247.10158
Overall Steps per Second: 9,511.37692

Timestep Collection Time: 2.47077
Timestep Consumption Time: 2.78882
PPO Batch Consumption Time: 0.33114
Total Iteration Time: 5.25960

Cumulative Model Updates: 122,532
Cumulative Timesteps: 1,021,969,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.11852
Policy Entropy: 3.13072
Value Function Loss: 0.00417

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.53037
Value Function Update Magnitude: 0.50706

Collected Steps per Second: 19,412.06706
Overall Steps per Second: 9,697.62397

Timestep Collection Time: 2.57623
Timestep Consumption Time: 2.58070
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 5.15693

Cumulative Model Updates: 122,538
Cumulative Timesteps: 1,022,019,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1022019666...
Checkpoint 1022019666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.44770
Policy Entropy: 3.14356
Value Function Loss: 0.00401

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.52652
Value Function Update Magnitude: 0.50102

Collected Steps per Second: 19,221.96997
Overall Steps per Second: 9,624.05353

Timestep Collection Time: 2.60140
Timestep Consumption Time: 2.59433
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 5.19573

Cumulative Model Updates: 122,544
Cumulative Timesteps: 1,022,069,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.94953
Policy Entropy: 3.16172
Value Function Loss: 0.00386

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.52160
Value Function Update Magnitude: 0.50707

Collected Steps per Second: 21,129.91904
Overall Steps per Second: 10,138.17357

Timestep Collection Time: 2.36631
Timestep Consumption Time: 2.56554
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.93185

Cumulative Model Updates: 122,550
Cumulative Timesteps: 1,022,119,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1022119670...
Checkpoint 1022119670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.76384
Policy Entropy: 3.16101
Value Function Loss: 0.00401

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.51230

Collected Steps per Second: 20,049.28917
Overall Steps per Second: 9,762.23472

Timestep Collection Time: 2.49385
Timestep Consumption Time: 2.62792
PPO Batch Consumption Time: 0.31124
Total Iteration Time: 5.12178

Cumulative Model Updates: 122,556
Cumulative Timesteps: 1,022,169,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.97887
Policy Entropy: 3.15132
Value Function Loss: 0.00403

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.54006

Collected Steps per Second: 21,541.66195
Overall Steps per Second: 10,236.19303

Timestep Collection Time: 2.32220
Timestep Consumption Time: 2.56478
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.88697

Cumulative Model Updates: 122,562
Cumulative Timesteps: 1,022,219,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1022219694...
Checkpoint 1022219694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.81428
Policy Entropy: 3.14264
Value Function Loss: 0.00401

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.54453
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 20,431.01260
Overall Steps per Second: 10,082.86404

Timestep Collection Time: 2.44834
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.96109

Cumulative Model Updates: 122,568
Cumulative Timesteps: 1,022,269,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.97118
Policy Entropy: 3.14213
Value Function Loss: 0.00443

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.54452

Collected Steps per Second: 19,826.44961
Overall Steps per Second: 9,552.23771

Timestep Collection Time: 2.52350
Timestep Consumption Time: 2.71423
PPO Batch Consumption Time: 0.30751
Total Iteration Time: 5.23773

Cumulative Model Updates: 122,574
Cumulative Timesteps: 1,022,319,748

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1022319748...
Checkpoint 1022319748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.15015
Policy Entropy: 3.15009
Value Function Loss: 0.00474

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.56816

Collected Steps per Second: 20,197.54499
Overall Steps per Second: 9,887.07169

Timestep Collection Time: 2.47604
Timestep Consumption Time: 2.58208
PPO Batch Consumption Time: 0.30061
Total Iteration Time: 5.05812

Cumulative Model Updates: 122,580
Cumulative Timesteps: 1,022,369,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.75359
Policy Entropy: 3.15529
Value Function Loss: 0.00452

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.55490

Collected Steps per Second: 20,831.09234
Overall Steps per Second: 9,740.98016

Timestep Collection Time: 2.40035
Timestep Consumption Time: 2.73280
PPO Batch Consumption Time: 0.32422
Total Iteration Time: 5.13316

Cumulative Model Updates: 122,586
Cumulative Timesteps: 1,022,419,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022419760...
Checkpoint 1022419760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.51610
Policy Entropy: 3.16238
Value Function Loss: 0.00411

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.53918

Collected Steps per Second: 20,318.51153
Overall Steps per Second: 10,111.03258

Timestep Collection Time: 2.46209
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.94766

Cumulative Model Updates: 122,592
Cumulative Timesteps: 1,022,469,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.95350
Policy Entropy: 3.15744
Value Function Loss: 0.00386

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 20,176.88611
Overall Steps per Second: 9,931.78724

Timestep Collection Time: 2.47818
Timestep Consumption Time: 2.55636
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 5.03454

Cumulative Model Updates: 122,598
Cumulative Timesteps: 1,022,519,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022519788...
Checkpoint 1022519788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.19868
Policy Entropy: 3.15629
Value Function Loss: 0.00407

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.54971

Collected Steps per Second: 21,358.60103
Overall Steps per Second: 10,386.14274

Timestep Collection Time: 2.34219
Timestep Consumption Time: 2.47442
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.81661

Cumulative Model Updates: 122,604
Cumulative Timesteps: 1,022,569,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.15252
Policy Entropy: 3.15291
Value Function Loss: 0.00418

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.54534
Value Function Update Magnitude: 0.54409

Collected Steps per Second: 18,366.94309
Overall Steps per Second: 9,384.87279

Timestep Collection Time: 2.72326
Timestep Consumption Time: 2.60638
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 5.32964

Cumulative Model Updates: 122,610
Cumulative Timesteps: 1,022,619,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1022619832...
Checkpoint 1022619832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.57827
Policy Entropy: 3.15467
Value Function Loss: 0.00431

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.53611

Collected Steps per Second: 18,684.95816
Overall Steps per Second: 9,495.30125

Timestep Collection Time: 2.67606
Timestep Consumption Time: 2.58992
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 5.26597

Cumulative Model Updates: 122,616
Cumulative Timesteps: 1,022,669,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.23505
Policy Entropy: 3.14990
Value Function Loss: 0.00410

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 19,117.09127
Overall Steps per Second: 9,602.71069

Timestep Collection Time: 2.61630
Timestep Consumption Time: 2.59223
PPO Batch Consumption Time: 0.31024
Total Iteration Time: 5.20853

Cumulative Model Updates: 122,622
Cumulative Timesteps: 1,022,719,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022719850...
Checkpoint 1022719850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.93979
Policy Entropy: 3.14332
Value Function Loss: 0.00404

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.52755
Value Function Update Magnitude: 0.51081

Collected Steps per Second: 19,172.74295
Overall Steps per Second: 9,497.57750

Timestep Collection Time: 2.60860
Timestep Consumption Time: 2.65738
PPO Batch Consumption Time: 0.31823
Total Iteration Time: 5.26597

Cumulative Model Updates: 122,628
Cumulative Timesteps: 1,022,769,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.19225
Policy Entropy: 3.15622
Value Function Loss: 0.00416

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.52574
Value Function Update Magnitude: 0.50292

Collected Steps per Second: 16,494.12999
Overall Steps per Second: 9,107.08353

Timestep Collection Time: 3.03211
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 5.49155

Cumulative Model Updates: 122,634
Cumulative Timesteps: 1,022,819,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1022819876...
Checkpoint 1022819876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.03716
Policy Entropy: 3.15800
Value Function Loss: 0.00433

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.52692

Collected Steps per Second: 20,910.71819
Overall Steps per Second: 10,178.81881

Timestep Collection Time: 2.39121
Timestep Consumption Time: 2.52114
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.91236

Cumulative Model Updates: 122,640
Cumulative Timesteps: 1,022,869,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.07789
Policy Entropy: 3.16749
Value Function Loss: 0.00432

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.56036

Collected Steps per Second: 21,162.98209
Overall Steps per Second: 9,934.44502

Timestep Collection Time: 2.36271
Timestep Consumption Time: 2.67048
PPO Batch Consumption Time: 0.30664
Total Iteration Time: 5.03320

Cumulative Model Updates: 122,646
Cumulative Timesteps: 1,022,919,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022919880...
Checkpoint 1022919880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.97805
Policy Entropy: 3.17080
Value Function Loss: 0.00411

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.53561
Value Function Update Magnitude: 0.54453

Collected Steps per Second: 19,935.25248
Overall Steps per Second: 9,736.03176

Timestep Collection Time: 2.50882
Timestep Consumption Time: 2.62818
PPO Batch Consumption Time: 0.31290
Total Iteration Time: 5.13700

Cumulative Model Updates: 122,652
Cumulative Timesteps: 1,022,969,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.86598
Policy Entropy: 3.18497
Value Function Loss: 0.00421

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.53434

Collected Steps per Second: 20,576.73198
Overall Steps per Second: 10,222.13050

Timestep Collection Time: 2.43022
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.89194

Cumulative Model Updates: 122,658
Cumulative Timesteps: 1,023,019,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1023019900...
Checkpoint 1023019900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.06774
Policy Entropy: 3.18376
Value Function Loss: 0.00411

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.55550

Collected Steps per Second: 21,380.81442
Overall Steps per Second: 10,300.50243

Timestep Collection Time: 2.33976
Timestep Consumption Time: 2.51690
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.85666

Cumulative Model Updates: 122,664
Cumulative Timesteps: 1,023,069,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.93452
Policy Entropy: 3.17859
Value Function Loss: 0.00410

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.56668

Collected Steps per Second: 22,437.03545
Overall Steps per Second: 10,546.99807

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.74467

Cumulative Model Updates: 122,670
Cumulative Timesteps: 1,023,119,968

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1023119968...
Checkpoint 1023119968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.56164
Policy Entropy: 3.17645
Value Function Loss: 0.00380

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.54039

Collected Steps per Second: 22,412.05044
Overall Steps per Second: 10,492.65734

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.53541
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.76733

Cumulative Model Updates: 122,676
Cumulative Timesteps: 1,023,169,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.16257
Policy Entropy: 3.18993
Value Function Loss: 0.00360

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.50436

Collected Steps per Second: 22,550.62494
Overall Steps per Second: 10,573.62609

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.72969

Cumulative Model Updates: 122,682
Cumulative Timesteps: 1,023,220,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023220000...
Checkpoint 1023220000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.11351
Policy Entropy: 3.17945
Value Function Loss: 0.00397

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.50151

Collected Steps per Second: 22,334.30958
Overall Steps per Second: 10,548.95174

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.50170
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.74095

Cumulative Model Updates: 122,688
Cumulative Timesteps: 1,023,270,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.65833
Policy Entropy: 3.17837
Value Function Loss: 0.00432

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.53617
Value Function Update Magnitude: 0.52347

Collected Steps per Second: 22,409.61240
Overall Steps per Second: 10,785.01143

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.40488
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.63606

Cumulative Model Updates: 122,694
Cumulative Timesteps: 1,023,320,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023320012...
Checkpoint 1023320012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.33655
Policy Entropy: 3.16184
Value Function Loss: 0.00465

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.55092

Collected Steps per Second: 21,595.49764
Overall Steps per Second: 10,637.89659

Timestep Collection Time: 2.31669
Timestep Consumption Time: 2.38631
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.70300

Cumulative Model Updates: 122,700
Cumulative Timesteps: 1,023,370,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.54292
Policy Entropy: 3.16328
Value Function Loss: 0.00438

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.54196

Collected Steps per Second: 19,726.79182
Overall Steps per Second: 9,868.73848

Timestep Collection Time: 2.53462
Timestep Consumption Time: 2.53188
PPO Batch Consumption Time: 0.30534
Total Iteration Time: 5.06650

Cumulative Model Updates: 122,706
Cumulative Timesteps: 1,023,420,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1023420042...
Checkpoint 1023420042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.73178
Policy Entropy: 3.17564
Value Function Loss: 0.00400

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.52485

Collected Steps per Second: 20,915.91187
Overall Steps per Second: 10,425.88005

Timestep Collection Time: 2.39139
Timestep Consumption Time: 2.40610
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.79748

Cumulative Model Updates: 122,712
Cumulative Timesteps: 1,023,470,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.30438
Policy Entropy: 3.18194
Value Function Loss: 0.00400

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.52830
Value Function Update Magnitude: 0.52934

Collected Steps per Second: 20,753.00662
Overall Steps per Second: 10,163.50956

Timestep Collection Time: 2.41083
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.92271

Cumulative Model Updates: 122,718
Cumulative Timesteps: 1,023,520,092

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1023520092...
Checkpoint 1023520092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.44376
Policy Entropy: 3.17320
Value Function Loss: 0.00422

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.55000
Value Function Update Magnitude: 0.57318

Collected Steps per Second: 20,697.24025
Overall Steps per Second: 10,023.80323

Timestep Collection Time: 2.41636
Timestep Consumption Time: 2.57296
PPO Batch Consumption Time: 0.30641
Total Iteration Time: 4.98932

Cumulative Model Updates: 122,724
Cumulative Timesteps: 1,023,570,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.93321
Policy Entropy: 3.16507
Value Function Loss: 0.00417

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 20,720.32741
Overall Steps per Second: 10,317.82256

Timestep Collection Time: 2.41357
Timestep Consumption Time: 2.43338
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.84695

Cumulative Model Updates: 122,730
Cumulative Timesteps: 1,023,620,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023620114...
Checkpoint 1023620114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.53481
Policy Entropy: 3.18099
Value Function Loss: 0.00390

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.59099

Collected Steps per Second: 21,378.77904
Overall Steps per Second: 10,452.30749

Timestep Collection Time: 2.33895
Timestep Consumption Time: 2.44506
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.78402

Cumulative Model Updates: 122,736
Cumulative Timesteps: 1,023,670,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.79144
Policy Entropy: 3.19543
Value Function Loss: 0.00359

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.54424

Collected Steps per Second: 21,802.42508
Overall Steps per Second: 10,464.13357

Timestep Collection Time: 2.29341
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.77842

Cumulative Model Updates: 122,742
Cumulative Timesteps: 1,023,720,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1023720120...
Checkpoint 1023720120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.44558
Policy Entropy: 3.19549
Value Function Loss: 0.00366

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.53435
Value Function Update Magnitude: 0.53208

Collected Steps per Second: 21,522.66971
Overall Steps per Second: 10,583.11392

Timestep Collection Time: 2.32360
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.72545

Cumulative Model Updates: 122,748
Cumulative Timesteps: 1,023,770,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.33863
Policy Entropy: 3.18188
Value Function Loss: 0.00361

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.52998
Value Function Update Magnitude: 0.53137

Collected Steps per Second: 21,712.27934
Overall Steps per Second: 10,527.56521

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.44689
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.75001

Cumulative Model Updates: 122,754
Cumulative Timesteps: 1,023,820,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1023820136...
Checkpoint 1023820136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.33339
Policy Entropy: 3.17086
Value Function Loss: 0.00381

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.53484
Value Function Update Magnitude: 0.51789

Collected Steps per Second: 21,026.64811
Overall Steps per Second: 10,403.82886

Timestep Collection Time: 2.37803
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.80612

Cumulative Model Updates: 122,760
Cumulative Timesteps: 1,023,870,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.28879
Policy Entropy: 3.18029
Value Function Loss: 0.00369

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.50546

Collected Steps per Second: 21,811.59968
Overall Steps per Second: 10,599.71676

Timestep Collection Time: 2.29282
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.71805

Cumulative Model Updates: 122,766
Cumulative Timesteps: 1,023,920,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023920148...
Checkpoint 1023920148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.01579
Policy Entropy: 3.18972
Value Function Loss: 0.00381

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.52791
Value Function Update Magnitude: 0.50917

Collected Steps per Second: 20,930.82125
Overall Steps per Second: 10,252.04215

Timestep Collection Time: 2.38882
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.87708

Cumulative Model Updates: 122,772
Cumulative Timesteps: 1,023,970,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.51511
Policy Entropy: 3.20012
Value Function Loss: 0.00380

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.49509

Collected Steps per Second: 21,696.05556
Overall Steps per Second: 10,484.07086

Timestep Collection Time: 2.30494
Timestep Consumption Time: 2.46497
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.76990

Cumulative Model Updates: 122,778
Cumulative Timesteps: 1,024,020,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1024020156...
Checkpoint 1024020156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,783.79774
Policy Entropy: 3.19129
Value Function Loss: 0.00394

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.48126

Collected Steps per Second: 21,791.78169
Overall Steps per Second: 10,672.99014

Timestep Collection Time: 2.29509
Timestep Consumption Time: 2.39095
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.68603

Cumulative Model Updates: 122,784
Cumulative Timesteps: 1,024,070,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.61115
Policy Entropy: 3.19711
Value Function Loss: 0.00374

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.46819

Collected Steps per Second: 22,016.57261
Overall Steps per Second: 10,602.16319

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.44569
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.71734

Cumulative Model Updates: 122,790
Cumulative Timesteps: 1,024,120,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1024120184...
Checkpoint 1024120184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.12625
Policy Entropy: 3.20164
Value Function Loss: 0.00364

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.51424
Value Function Update Magnitude: 0.46414

Collected Steps per Second: 21,533.31437
Overall Steps per Second: 10,444.61127

Timestep Collection Time: 2.32319
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.78965

Cumulative Model Updates: 122,796
Cumulative Timesteps: 1,024,170,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.22013
Policy Entropy: 3.21159
Value Function Loss: 0.00370

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.46941

Collected Steps per Second: 21,882.09945
Overall Steps per Second: 10,430.97758

Timestep Collection Time: 2.28552
Timestep Consumption Time: 2.50904
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.79456

Cumulative Model Updates: 122,802
Cumulative Timesteps: 1,024,220,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1024220222...
Checkpoint 1024220222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.33719
Policy Entropy: 3.20730
Value Function Loss: 0.00381

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.48116

Collected Steps per Second: 20,870.33321
Overall Steps per Second: 10,264.61825

Timestep Collection Time: 2.39584
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.87130

Cumulative Model Updates: 122,808
Cumulative Timesteps: 1,024,270,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.86975
Policy Entropy: 3.19515
Value Function Loss: 0.00363

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.52692
Value Function Update Magnitude: 0.48930

Collected Steps per Second: 22,417.76692
Overall Steps per Second: 10,748.41100

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.42148
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.65185

Cumulative Model Updates: 122,814
Cumulative Timesteps: 1,024,320,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1024320224...
Checkpoint 1024320224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.11592
Policy Entropy: 3.18957
Value Function Loss: 0.00353

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.47684

Collected Steps per Second: 18,337.36127
Overall Steps per Second: 9,391.52900

Timestep Collection Time: 2.72853
Timestep Consumption Time: 2.59904
PPO Batch Consumption Time: 0.31221
Total Iteration Time: 5.32757

Cumulative Model Updates: 122,820
Cumulative Timesteps: 1,024,370,258

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.87922
Policy Entropy: 3.18391
Value Function Loss: 0.00381

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.46513

Collected Steps per Second: 16,209.03352
Overall Steps per Second: 8,850.60486

Timestep Collection Time: 3.08519
Timestep Consumption Time: 2.56504
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 5.65024

Cumulative Model Updates: 122,826
Cumulative Timesteps: 1,024,420,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1024420266...
Checkpoint 1024420266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.17883
Policy Entropy: 3.17509
Value Function Loss: 0.00394

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.52492
Value Function Update Magnitude: 0.46879

Collected Steps per Second: 21,108.96172
Overall Steps per Second: 10,392.28593

Timestep Collection Time: 2.36904
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.81203

Cumulative Model Updates: 122,832
Cumulative Timesteps: 1,024,470,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.79343
Policy Entropy: 3.17828
Value Function Loss: 0.00394

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.51917
Value Function Update Magnitude: 0.49024

Collected Steps per Second: 21,840.24112
Overall Steps per Second: 10,350.53950

Timestep Collection Time: 2.29082
Timestep Consumption Time: 2.54294
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.83376

Cumulative Model Updates: 122,838
Cumulative Timesteps: 1,024,520,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1024520306...
Checkpoint 1024520306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.31195
Policy Entropy: 3.17477
Value Function Loss: 0.00359

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.51278
Value Function Update Magnitude: 0.47977

Collected Steps per Second: 21,376.89352
Overall Steps per Second: 10,465.84192

Timestep Collection Time: 2.33963
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.77878

Cumulative Model Updates: 122,844
Cumulative Timesteps: 1,024,570,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.02683
Policy Entropy: 3.18167
Value Function Loss: 0.00368

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.51596
Value Function Update Magnitude: 0.49217

Collected Steps per Second: 22,282.70775
Overall Steps per Second: 10,509.72635

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.76035

Cumulative Model Updates: 122,850
Cumulative Timesteps: 1,024,620,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024620350...
Checkpoint 1024620350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.26307
Policy Entropy: 3.18420
Value Function Loss: 0.00381

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.52798
Value Function Update Magnitude: 0.51473

Collected Steps per Second: 20,981.32928
Overall Steps per Second: 10,118.83973

Timestep Collection Time: 2.38421
Timestep Consumption Time: 2.55943
PPO Batch Consumption Time: 0.30906
Total Iteration Time: 4.94365

Cumulative Model Updates: 122,856
Cumulative Timesteps: 1,024,670,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.74674
Policy Entropy: 3.18014
Value Function Loss: 0.00384

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.51238

Collected Steps per Second: 20,533.76376
Overall Steps per Second: 10,016.99197

Timestep Collection Time: 2.43657
Timestep Consumption Time: 2.55814
PPO Batch Consumption Time: 0.30853
Total Iteration Time: 4.99471

Cumulative Model Updates: 122,862
Cumulative Timesteps: 1,024,720,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1024720406...
Checkpoint 1024720406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.07275
Policy Entropy: 3.18681
Value Function Loss: 0.00382

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.50995

Collected Steps per Second: 20,364.90114
Overall Steps per Second: 10,198.10219

Timestep Collection Time: 2.45579
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.90405

Cumulative Model Updates: 122,868
Cumulative Timesteps: 1,024,770,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.68369
Policy Entropy: 3.19690
Value Function Loss: 0.00356

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.52467
Value Function Update Magnitude: 0.49496

Collected Steps per Second: 21,107.49167
Overall Steps per Second: 10,326.36449

Timestep Collection Time: 2.36940
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.84314

Cumulative Model Updates: 122,874
Cumulative Timesteps: 1,024,820,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1024820430...
Checkpoint 1024820430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.56912
Policy Entropy: 3.20550
Value Function Loss: 0.00379

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.51591
Value Function Update Magnitude: 0.49150

Collected Steps per Second: 20,621.06629
Overall Steps per Second: 10,131.64373

Timestep Collection Time: 2.42616
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.93799

Cumulative Model Updates: 122,880
Cumulative Timesteps: 1,024,870,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,833.28488
Policy Entropy: 3.20343
Value Function Loss: 0.00385

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.52716
Value Function Update Magnitude: 0.49959

Collected Steps per Second: 20,707.58848
Overall Steps per Second: 10,210.26262

Timestep Collection Time: 2.41554
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.89899

Cumulative Model Updates: 122,886
Cumulative Timesteps: 1,024,920,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1024920480...
Checkpoint 1024920480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.93850
Policy Entropy: 3.19918
Value Function Loss: 0.00380

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.53217
Value Function Update Magnitude: 0.51324

Collected Steps per Second: 20,595.58899
Overall Steps per Second: 10,187.24251

Timestep Collection Time: 2.42887
Timestep Consumption Time: 2.48159
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.91046

Cumulative Model Updates: 122,892
Cumulative Timesteps: 1,024,970,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.31969
Policy Entropy: 3.19638
Value Function Loss: 0.00372

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.50750

Collected Steps per Second: 20,711.86906
Overall Steps per Second: 10,118.16145

Timestep Collection Time: 2.41523
Timestep Consumption Time: 2.52875
PPO Batch Consumption Time: 0.30604
Total Iteration Time: 4.94398

Cumulative Model Updates: 122,898
Cumulative Timesteps: 1,025,020,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1025020528...
Checkpoint 1025020528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.15250
Policy Entropy: 3.18389
Value Function Loss: 0.00354

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.52336
Value Function Update Magnitude: 0.50495

Collected Steps per Second: 20,328.01289
Overall Steps per Second: 10,108.99623

Timestep Collection Time: 2.46104
Timestep Consumption Time: 2.48782
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.94886

Cumulative Model Updates: 122,904
Cumulative Timesteps: 1,025,070,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,267.43774
Policy Entropy: 3.19030
Value Function Loss: 0.00365

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.51323
Value Function Update Magnitude: 0.50798

Collected Steps per Second: 20,276.91211
Overall Steps per Second: 10,243.02945

Timestep Collection Time: 2.46645
Timestep Consumption Time: 2.41609
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.88254

Cumulative Model Updates: 122,910
Cumulative Timesteps: 1,025,120,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025120568...
Checkpoint 1025120568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.83805
Policy Entropy: 3.18387
Value Function Loss: 0.00374

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.51968

Collected Steps per Second: 20,766.35870
Overall Steps per Second: 10,076.88379

Timestep Collection Time: 2.40813
Timestep Consumption Time: 2.55452
PPO Batch Consumption Time: 0.30849
Total Iteration Time: 4.96265

Cumulative Model Updates: 122,916
Cumulative Timesteps: 1,025,170,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.00015
Policy Entropy: 3.19059
Value Function Loss: 0.00399

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.53621

Collected Steps per Second: 20,720.01042
Overall Steps per Second: 10,400.81063

Timestep Collection Time: 2.41313
Timestep Consumption Time: 2.39419
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.80732

Cumulative Model Updates: 122,922
Cumulative Timesteps: 1,025,220,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025220576...
Checkpoint 1025220576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.38504
Policy Entropy: 3.17816
Value Function Loss: 0.00411

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.53949

Collected Steps per Second: 21,632.92697
Overall Steps per Second: 10,280.88089

Timestep Collection Time: 2.31185
Timestep Consumption Time: 2.55272
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.86456

Cumulative Model Updates: 122,928
Cumulative Timesteps: 1,025,270,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.51744
Policy Entropy: 3.18192
Value Function Loss: 0.00406

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.52373

Collected Steps per Second: 21,294.47772
Overall Steps per Second: 10,056.26481

Timestep Collection Time: 2.34850
Timestep Consumption Time: 2.62452
PPO Batch Consumption Time: 0.30689
Total Iteration Time: 4.97302

Cumulative Model Updates: 122,934
Cumulative Timesteps: 1,025,320,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1025320598...
Checkpoint 1025320598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.89100
Policy Entropy: 3.18336
Value Function Loss: 0.00398

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.54132
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 21,355.64001
Overall Steps per Second: 10,144.34438

Timestep Collection Time: 2.34243
Timestep Consumption Time: 2.58879
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.93122

Cumulative Model Updates: 122,940
Cumulative Timesteps: 1,025,370,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.63672
Policy Entropy: 3.19671
Value Function Loss: 0.00387

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.52056

Collected Steps per Second: 21,877.05193
Overall Steps per Second: 10,528.98696

Timestep Collection Time: 2.28596
Timestep Consumption Time: 2.46379
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74974

Cumulative Model Updates: 122,946
Cumulative Timesteps: 1,025,420,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1025420632...
Checkpoint 1025420632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.99536
Policy Entropy: 3.20655
Value Function Loss: 0.00421

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.54045
Value Function Update Magnitude: 0.51762

Collected Steps per Second: 21,317.06519
Overall Steps per Second: 10,012.13826

Timestep Collection Time: 2.34582
Timestep Consumption Time: 2.64872
PPO Batch Consumption Time: 0.31024
Total Iteration Time: 4.99454

Cumulative Model Updates: 122,952
Cumulative Timesteps: 1,025,470,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.11794
Policy Entropy: 3.20788
Value Function Loss: 0.00397

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.50963

Collected Steps per Second: 20,876.23863
Overall Steps per Second: 10,011.60148

Timestep Collection Time: 2.39622
Timestep Consumption Time: 2.60039
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.99660

Cumulative Model Updates: 122,958
Cumulative Timesteps: 1,025,520,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1025520662...
Checkpoint 1025520662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.96574
Policy Entropy: 3.20326
Value Function Loss: 0.00390

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.51949
Value Function Update Magnitude: 0.50837

Collected Steps per Second: 21,740.57236
Overall Steps per Second: 10,451.99847

Timestep Collection Time: 2.30068
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.78550

Cumulative Model Updates: 122,964
Cumulative Timesteps: 1,025,570,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.80094
Policy Entropy: 3.19648
Value Function Loss: 0.00365

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.51937
Value Function Update Magnitude: 0.48672

Collected Steps per Second: 21,477.33058
Overall Steps per Second: 10,135.33255

Timestep Collection Time: 2.32822
Timestep Consumption Time: 2.60541
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.93363

Cumulative Model Updates: 122,970
Cumulative Timesteps: 1,025,620,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1025620684...
Checkpoint 1025620684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.23265
Policy Entropy: 3.20836
Value Function Loss: 0.00379

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.52836
Value Function Update Magnitude: 0.49860

Collected Steps per Second: 20,955.59789
Overall Steps per Second: 10,111.15395

Timestep Collection Time: 2.38647
Timestep Consumption Time: 2.55955
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.94602

Cumulative Model Updates: 122,976
Cumulative Timesteps: 1,025,670,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,872.60302
Policy Entropy: 3.21463
Value Function Loss: 0.00361

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.52228
Value Function Update Magnitude: 0.52690

Collected Steps per Second: 21,943.96812
Overall Steps per Second: 10,324.20898

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.56528
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.84454

Cumulative Model Updates: 122,982
Cumulative Timesteps: 1,025,720,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1025720710...
Checkpoint 1025720710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.18880
Policy Entropy: 3.21426
Value Function Loss: 0.00380

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.52514
Value Function Update Magnitude: 0.53329

Collected Steps per Second: 21,431.94819
Overall Steps per Second: 10,234.72943

Timestep Collection Time: 2.33297
Timestep Consumption Time: 2.55236
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.88533

Cumulative Model Updates: 122,988
Cumulative Timesteps: 1,025,770,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.74636
Policy Entropy: 3.19565
Value Function Loss: 0.00419

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.51524

Collected Steps per Second: 21,183.56274
Overall Steps per Second: 10,253.84142

Timestep Collection Time: 2.36089
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 4.87739

Cumulative Model Updates: 122,994
Cumulative Timesteps: 1,025,820,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025820722...
Checkpoint 1025820722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.95034
Policy Entropy: 3.18041
Value Function Loss: 0.00443

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.51027

Collected Steps per Second: 21,406.03876
Overall Steps per Second: 10,100.79747

Timestep Collection Time: 2.33794
Timestep Consumption Time: 2.61672
PPO Batch Consumption Time: 0.30621
Total Iteration Time: 4.95466

Cumulative Model Updates: 123,000
Cumulative Timesteps: 1,025,870,768

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.62593
Policy Entropy: 3.17851
Value Function Loss: 0.00393

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.54554
Value Function Update Magnitude: 0.51053

Collected Steps per Second: 20,435.85403
Overall Steps per Second: 9,420.57104

Timestep Collection Time: 2.44766
Timestep Consumption Time: 2.86200
PPO Batch Consumption Time: 0.33162
Total Iteration Time: 5.30966

Cumulative Model Updates: 123,006
Cumulative Timesteps: 1,025,920,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1025920788...
Checkpoint 1025920788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.84438
Policy Entropy: 3.18602
Value Function Loss: 0.00368

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.52842
Value Function Update Magnitude: 0.50381

Collected Steps per Second: 19,922.38174
Overall Steps per Second: 10,148.02675

Timestep Collection Time: 2.51054
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.92864

Cumulative Model Updates: 123,012
Cumulative Timesteps: 1,025,970,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.42185
Policy Entropy: 3.19098
Value Function Loss: 0.00363

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.52613
Value Function Update Magnitude: 0.49689

Collected Steps per Second: 22,144.51445
Overall Steps per Second: 10,559.37269

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.73608

Cumulative Model Updates: 123,018
Cumulative Timesteps: 1,026,020,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1026020814...
Checkpoint 1026020814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.43071
Policy Entropy: 3.18306
Value Function Loss: 0.00407

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.50436

Collected Steps per Second: 21,877.44170
Overall Steps per Second: 10,515.72809

Timestep Collection Time: 2.28555
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.75497

Cumulative Model Updates: 123,024
Cumulative Timesteps: 1,026,070,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.60501
Policy Entropy: 3.16819
Value Function Loss: 0.00410

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.51185

Collected Steps per Second: 22,020.65530
Overall Steps per Second: 10,465.70964

Timestep Collection Time: 2.27150
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.77942

Cumulative Model Updates: 123,030
Cumulative Timesteps: 1,026,120,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1026120836...
Checkpoint 1026120836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.33579
Policy Entropy: 3.18459
Value Function Loss: 0.00407

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.52105

Collected Steps per Second: 21,017.61733
Overall Steps per Second: 10,372.59983

Timestep Collection Time: 2.38038
Timestep Consumption Time: 2.44290
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.82328

Cumulative Model Updates: 123,036
Cumulative Timesteps: 1,026,170,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.83215
Policy Entropy: 3.19074
Value Function Loss: 0.00384

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.51028

Collected Steps per Second: 22,761.56406
Overall Steps per Second: 10,706.51202

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.47337
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.67006

Cumulative Model Updates: 123,042
Cumulative Timesteps: 1,026,220,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1026220866...
Checkpoint 1026220866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.05925
Policy Entropy: 3.19783
Value Function Loss: 0.00404

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.51270

Collected Steps per Second: 22,399.37091
Overall Steps per Second: 10,600.82679

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.48481
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.71737

Cumulative Model Updates: 123,048
Cumulative Timesteps: 1,026,270,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.99259
Policy Entropy: 3.19551
Value Function Loss: 0.00416

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 22,632.99498
Overall Steps per Second: 10,539.47164

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.53582
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.74578

Cumulative Model Updates: 123,054
Cumulative Timesteps: 1,026,320,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1026320892...
Checkpoint 1026320892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.42851
Policy Entropy: 3.19616
Value Function Loss: 0.00407

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.54886

Collected Steps per Second: 20,855.34165
Overall Steps per Second: 9,991.64094

Timestep Collection Time: 2.39871
Timestep Consumption Time: 2.60807
PPO Batch Consumption Time: 0.30136
Total Iteration Time: 5.00679

Cumulative Model Updates: 123,060
Cumulative Timesteps: 1,026,370,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,553.50308
Policy Entropy: 3.18764
Value Function Loss: 0.00403

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.52827

Collected Steps per Second: 20,602.68753
Overall Steps per Second: 10,192.54584

Timestep Collection Time: 2.42706
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.90594

Cumulative Model Updates: 123,066
Cumulative Timesteps: 1,026,420,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1026420922...
Checkpoint 1026420922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.61725
Policy Entropy: 3.18140
Value Function Loss: 0.00401

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.52089

Collected Steps per Second: 20,883.66383
Overall Steps per Second: 10,259.10182

Timestep Collection Time: 2.39422
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.87372

Cumulative Model Updates: 123,072
Cumulative Timesteps: 1,026,470,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.34515
Policy Entropy: 3.17278
Value Function Loss: 0.00424

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.53034

Collected Steps per Second: 22,220.74595
Overall Steps per Second: 10,506.97753

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.50889
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 4.75931

Cumulative Model Updates: 123,078
Cumulative Timesteps: 1,026,520,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1026520928...
Checkpoint 1026520928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.46412
Policy Entropy: 3.18284
Value Function Loss: 0.00445

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.54429

Collected Steps per Second: 20,183.91773
Overall Steps per Second: 10,332.35828

Timestep Collection Time: 2.47871
Timestep Consumption Time: 2.36336
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.84207

Cumulative Model Updates: 123,084
Cumulative Timesteps: 1,026,570,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.75635
Policy Entropy: 3.18289
Value Function Loss: 0.00455

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.53524

Collected Steps per Second: 19,355.69472
Overall Steps per Second: 9,732.31994

Timestep Collection Time: 2.58363
Timestep Consumption Time: 2.55471
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 5.13834

Cumulative Model Updates: 123,090
Cumulative Timesteps: 1,026,620,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1026620966...
Checkpoint 1026620966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.29526
Policy Entropy: 3.19398
Value Function Loss: 0.00411

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 19,488.06949
Overall Steps per Second: 9,853.83064

Timestep Collection Time: 2.56721
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 5.07721

Cumulative Model Updates: 123,096
Cumulative Timesteps: 1,026,670,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.34872
Policy Entropy: 3.20147
Value Function Loss: 0.00386

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.51732

Collected Steps per Second: 22,621.87402
Overall Steps per Second: 10,552.37508

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.52873
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.73960

Cumulative Model Updates: 123,102
Cumulative Timesteps: 1,026,721,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1026721010...
Checkpoint 1026721010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.83877
Policy Entropy: 3.19972
Value Function Loss: 0.00393

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.52027

Collected Steps per Second: 20,959.02980
Overall Steps per Second: 10,108.11116

Timestep Collection Time: 2.38675
Timestep Consumption Time: 2.56215
PPO Batch Consumption Time: 0.31573
Total Iteration Time: 4.94890

Cumulative Model Updates: 123,108
Cumulative Timesteps: 1,026,771,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.29527
Policy Entropy: 3.19978
Value Function Loss: 0.00412

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.54921
Value Function Update Magnitude: 0.52168

Collected Steps per Second: 20,569.51141
Overall Steps per Second: 9,965.52942

Timestep Collection Time: 2.43205
Timestep Consumption Time: 2.58786
PPO Batch Consumption Time: 0.30645
Total Iteration Time: 5.01990

Cumulative Model Updates: 123,114
Cumulative Timesteps: 1,026,821,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1026821060...
Checkpoint 1026821060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.48866
Policy Entropy: 3.20375
Value Function Loss: 0.00410

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.51244

Collected Steps per Second: 20,549.51738
Overall Steps per Second: 10,208.60075

Timestep Collection Time: 2.43402
Timestep Consumption Time: 2.46557
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.89959

Cumulative Model Updates: 123,120
Cumulative Timesteps: 1,026,871,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.82969
Policy Entropy: 3.20014
Value Function Loss: 0.00404

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.50506

Collected Steps per Second: 22,020.32229
Overall Steps per Second: 10,529.95605

Timestep Collection Time: 2.27063
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.74836

Cumulative Model Updates: 123,126
Cumulative Timesteps: 1,026,921,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1026921078...
Checkpoint 1026921078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.15599
Policy Entropy: 3.19262
Value Function Loss: 0.00385

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.53657
Value Function Update Magnitude: 0.49128

Collected Steps per Second: 18,199.55461
Overall Steps per Second: 9,541.08928

Timestep Collection Time: 2.74853
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 5.24280

Cumulative Model Updates: 123,132
Cumulative Timesteps: 1,026,971,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.94126
Policy Entropy: 3.18760
Value Function Loss: 0.00403

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.49480

Collected Steps per Second: 21,122.99846
Overall Steps per Second: 10,076.24118

Timestep Collection Time: 2.36813
Timestep Consumption Time: 2.59622
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.96435

Cumulative Model Updates: 123,138
Cumulative Timesteps: 1,027,021,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1027021122...
Checkpoint 1027021122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,447.72727
Policy Entropy: 3.20040
Value Function Loss: 0.00400

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.55018
Value Function Update Magnitude: 0.52004

Collected Steps per Second: 21,329.35195
Overall Steps per Second: 10,333.04722

Timestep Collection Time: 2.34531
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.84117

Cumulative Model Updates: 123,144
Cumulative Timesteps: 1,027,071,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.56205
Policy Entropy: 3.20783
Value Function Loss: 0.00433

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.53103

Collected Steps per Second: 19,996.29843
Overall Steps per Second: 9,970.23684

Timestep Collection Time: 2.50056
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 5.01513

Cumulative Model Updates: 123,150
Cumulative Timesteps: 1,027,121,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027121148...
Checkpoint 1027121148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.50717
Policy Entropy: 3.20670
Value Function Loss: 0.00408

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.52365

Collected Steps per Second: 22,319.84820
Overall Steps per Second: 10,548.74584

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.74274

Cumulative Model Updates: 123,156
Cumulative Timesteps: 1,027,171,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.52173
Policy Entropy: 3.20640
Value Function Loss: 0.00409

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.50807

Collected Steps per Second: 22,053.81934
Overall Steps per Second: 10,529.96229

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.75120

Cumulative Model Updates: 123,162
Cumulative Timesteps: 1,027,221,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1027221208...
Checkpoint 1027221208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.07615
Policy Entropy: 3.21761
Value Function Loss: 0.00419

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.50854

Collected Steps per Second: 21,813.65373
Overall Steps per Second: 10,348.15596

Timestep Collection Time: 2.29260
Timestep Consumption Time: 2.54014
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.83275

Cumulative Model Updates: 123,168
Cumulative Timesteps: 1,027,271,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.39253
Policy Entropy: 3.22011
Value Function Loss: 0.00439

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.53490

Collected Steps per Second: 21,915.72313
Overall Steps per Second: 10,218.73931

Timestep Collection Time: 2.28156
Timestep Consumption Time: 2.61161
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 4.89317

Cumulative Model Updates: 123,174
Cumulative Timesteps: 1,027,321,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027321220...
Checkpoint 1027321220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.01890
Policy Entropy: 3.21491
Value Function Loss: 0.00434

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.54498

Collected Steps per Second: 21,888.45762
Overall Steps per Second: 10,324.62600

Timestep Collection Time: 2.28486
Timestep Consumption Time: 2.55910
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.84395

Cumulative Model Updates: 123,180
Cumulative Timesteps: 1,027,371,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.24986
Policy Entropy: 3.21460
Value Function Loss: 0.00435

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.62035
Value Function Update Magnitude: 0.56160

Collected Steps per Second: 21,788.44307
Overall Steps per Second: 10,456.45240

Timestep Collection Time: 2.29626
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.78480

Cumulative Model Updates: 123,186
Cumulative Timesteps: 1,027,421,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1027421264...
Checkpoint 1027421264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.91319
Policy Entropy: 3.21648
Value Function Loss: 0.00413

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.55101

Collected Steps per Second: 22,035.24820
Overall Steps per Second: 10,446.97050

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.78742

Cumulative Model Updates: 123,192
Cumulative Timesteps: 1,027,471,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.55934
Policy Entropy: 3.20508
Value Function Loss: 0.00431

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.55310

Collected Steps per Second: 21,921.71807
Overall Steps per Second: 10,627.92404

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.70722

Cumulative Model Updates: 123,198
Cumulative Timesteps: 1,027,521,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1027521306...
Checkpoint 1027521306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.27787
Policy Entropy: 3.20905
Value Function Loss: 0.00447

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.58837

Collected Steps per Second: 21,385.08111
Overall Steps per Second: 10,542.97235

Timestep Collection Time: 2.33817
Timestep Consumption Time: 2.40451
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.74269

Cumulative Model Updates: 123,204
Cumulative Timesteps: 1,027,571,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.43153
Policy Entropy: 3.20294
Value Function Loss: 0.00412

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.56287
Value Function Update Magnitude: 0.59846

Collected Steps per Second: 21,403.77987
Overall Steps per Second: 10,515.00219

Timestep Collection Time: 2.33697
Timestep Consumption Time: 2.42004
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.75701

Cumulative Model Updates: 123,210
Cumulative Timesteps: 1,027,621,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1027621328...
Checkpoint 1027621328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.60127
Policy Entropy: 3.20900
Value Function Loss: 0.00445

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 0.56319

Collected Steps per Second: 22,146.26754
Overall Steps per Second: 10,445.80663

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.53021
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.78910

Cumulative Model Updates: 123,216
Cumulative Timesteps: 1,027,671,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.23487
Policy Entropy: 3.21250
Value Function Loss: 0.00439

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.54190

Collected Steps per Second: 22,061.26305
Overall Steps per Second: 10,399.55202

Timestep Collection Time: 2.26750
Timestep Consumption Time: 2.54270
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.81021

Cumulative Model Updates: 123,222
Cumulative Timesteps: 1,027,721,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1027721378...
Checkpoint 1027721378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.92450
Policy Entropy: 3.21590
Value Function Loss: 0.00454

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.54391

Collected Steps per Second: 21,399.86789
Overall Steps per Second: 10,540.29759

Timestep Collection Time: 2.33786
Timestep Consumption Time: 2.40868
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.74655

Cumulative Model Updates: 123,228
Cumulative Timesteps: 1,027,771,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.01154
Policy Entropy: 3.21044
Value Function Loss: 0.00424

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.57296

Collected Steps per Second: 22,187.28768
Overall Steps per Second: 10,469.42156

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.77677

Cumulative Model Updates: 123,234
Cumulative Timesteps: 1,027,821,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1027821418...
Checkpoint 1027821418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.68297
Policy Entropy: 3.19993
Value Function Loss: 0.00411

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.58532

Collected Steps per Second: 22,406.31260
Overall Steps per Second: 10,647.94263

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.69950

Cumulative Model Updates: 123,240
Cumulative Timesteps: 1,027,871,458

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.19612
Policy Entropy: 3.20073
Value Function Loss: 0.00387

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.56491

Collected Steps per Second: 22,318.54877
Overall Steps per Second: 10,437.80990

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.55060
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.79143

Cumulative Model Updates: 123,246
Cumulative Timesteps: 1,027,921,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1027921470...
Checkpoint 1027921470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.25623
Policy Entropy: 3.22394
Value Function Loss: 0.00366

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.52340
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 21,978.28755
Overall Steps per Second: 10,377.87775

Timestep Collection Time: 2.27579
Timestep Consumption Time: 2.54388
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.81968

Cumulative Model Updates: 123,252
Cumulative Timesteps: 1,027,971,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.47080
Policy Entropy: 3.23649
Value Function Loss: 0.00396

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.52987
Value Function Update Magnitude: 0.52957

Collected Steps per Second: 22,385.94825
Overall Steps per Second: 10,467.10448

Timestep Collection Time: 2.23444
Timestep Consumption Time: 2.54434
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.77878

Cumulative Model Updates: 123,258
Cumulative Timesteps: 1,028,021,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1028021508...
Checkpoint 1028021508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,992.67657
Policy Entropy: 3.23186
Value Function Loss: 0.00404

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.53025

Collected Steps per Second: 21,242.30590
Overall Steps per Second: 10,398.44053

Timestep Collection Time: 2.35502
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.81091

Cumulative Model Updates: 123,264
Cumulative Timesteps: 1,028,071,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.40049
Policy Entropy: 3.21441
Value Function Loss: 0.00398

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.52085

Collected Steps per Second: 22,128.76018
Overall Steps per Second: 10,424.83572

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.53724
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.79720

Cumulative Model Updates: 123,270
Cumulative Timesteps: 1,028,121,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1028121544...
Checkpoint 1028121544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.84978
Policy Entropy: 3.19751
Value Function Loss: 0.00379

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.50716

Collected Steps per Second: 21,720.08068
Overall Steps per Second: 10,271.81163

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.56690
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.87003

Cumulative Model Updates: 123,276
Cumulative Timesteps: 1,028,171,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.28757
Policy Entropy: 3.19071
Value Function Loss: 0.00381

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.50811

Collected Steps per Second: 20,406.25826
Overall Steps per Second: 9,936.57226

Timestep Collection Time: 2.45111
Timestep Consumption Time: 2.58262
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 5.03373

Cumulative Model Updates: 123,282
Cumulative Timesteps: 1,028,221,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1028221586...
Checkpoint 1028221586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.77780
Policy Entropy: 3.19876
Value Function Loss: 0.00382

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.52590

Collected Steps per Second: 19,725.34043
Overall Steps per Second: 9,791.32994

Timestep Collection Time: 2.53613
Timestep Consumption Time: 2.57309
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 5.10921

Cumulative Model Updates: 123,288
Cumulative Timesteps: 1,028,271,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.10824
Policy Entropy: 3.19146
Value Function Loss: 0.00389

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.53720

Collected Steps per Second: 19,972.40427
Overall Steps per Second: 9,632.20440

Timestep Collection Time: 2.50416
Timestep Consumption Time: 2.68822
PPO Batch Consumption Time: 0.31327
Total Iteration Time: 5.19237

Cumulative Model Updates: 123,294
Cumulative Timesteps: 1,028,321,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1028321626...
Checkpoint 1028321626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.82574
Policy Entropy: 3.19529
Value Function Loss: 0.00408

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.54986

Collected Steps per Second: 18,406.25109
Overall Steps per Second: 9,344.00685

Timestep Collection Time: 2.71734
Timestep Consumption Time: 2.63540
PPO Batch Consumption Time: 0.30986
Total Iteration Time: 5.35274

Cumulative Model Updates: 123,300
Cumulative Timesteps: 1,028,371,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.26511
Policy Entropy: 3.18935
Value Function Loss: 0.00408

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.56549

Collected Steps per Second: 21,044.85182
Overall Steps per Second: 10,091.56974

Timestep Collection Time: 2.37702
Timestep Consumption Time: 2.57999
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.95701

Cumulative Model Updates: 123,306
Cumulative Timesteps: 1,028,421,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028421666...
Checkpoint 1028421666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.90980
Policy Entropy: 3.20031
Value Function Loss: 0.00430

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.53415
Value Function Update Magnitude: 0.56118

Collected Steps per Second: 21,386.61363
Overall Steps per Second: 10,234.72430

Timestep Collection Time: 2.33829
Timestep Consumption Time: 2.54783
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.88611

Cumulative Model Updates: 123,312
Cumulative Timesteps: 1,028,471,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.50811
Policy Entropy: 3.20474
Value Function Loss: 0.00418

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.54008
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 21,116.67550
Overall Steps per Second: 10,196.56039

Timestep Collection Time: 2.36893
Timestep Consumption Time: 2.53703
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.90597

Cumulative Model Updates: 123,318
Cumulative Timesteps: 1,028,521,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028521698...
Checkpoint 1028521698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.28299
Policy Entropy: 3.20409
Value Function Loss: 0.00385

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07908
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.55643

Collected Steps per Second: 19,682.78223
Overall Steps per Second: 9,786.75678

Timestep Collection Time: 2.54049
Timestep Consumption Time: 2.56886
PPO Batch Consumption Time: 0.30794
Total Iteration Time: 5.10935

Cumulative Model Updates: 123,324
Cumulative Timesteps: 1,028,571,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.57139
Policy Entropy: 3.20150
Value Function Loss: 0.00395

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.53750
Value Function Update Magnitude: 0.55746

Collected Steps per Second: 21,044.93173
Overall Steps per Second: 10,158.87857

Timestep Collection Time: 2.37653
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.92318

Cumulative Model Updates: 123,330
Cumulative Timesteps: 1,028,621,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1028621716...
Checkpoint 1028621716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.89636
Policy Entropy: 3.19154
Value Function Loss: 0.00393

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.54375

Collected Steps per Second: 22,394.69529
Overall Steps per Second: 10,588.29586

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.72238

Cumulative Model Updates: 123,336
Cumulative Timesteps: 1,028,671,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.78118
Policy Entropy: 3.16712
Value Function Loss: 0.00431

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.54409

Collected Steps per Second: 21,351.66642
Overall Steps per Second: 9,838.87306

Timestep Collection Time: 2.34296
Timestep Consumption Time: 2.74157
PPO Batch Consumption Time: 0.31909
Total Iteration Time: 5.08453

Cumulative Model Updates: 123,342
Cumulative Timesteps: 1,028,721,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1028721744...
Checkpoint 1028721744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.99860
Policy Entropy: 3.15344
Value Function Loss: 0.00426

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.55598

Collected Steps per Second: 20,256.56617
Overall Steps per Second: 9,909.38542

Timestep Collection Time: 2.46972
Timestep Consumption Time: 2.57883
PPO Batch Consumption Time: 0.30241
Total Iteration Time: 5.04855

Cumulative Model Updates: 123,348
Cumulative Timesteps: 1,028,771,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.79063
Policy Entropy: 3.15673
Value Function Loss: 0.00457

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.57782

Collected Steps per Second: 21,993.70987
Overall Steps per Second: 10,507.41934

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.75873

Cumulative Model Updates: 123,354
Cumulative Timesteps: 1,028,821,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1028821774...
Checkpoint 1028821774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.14529
Policy Entropy: 3.18825
Value Function Loss: 0.00418

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.57708

Collected Steps per Second: 20,254.06345
Overall Steps per Second: 10,098.65022

Timestep Collection Time: 2.46943
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.95274

Cumulative Model Updates: 123,360
Cumulative Timesteps: 1,028,871,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.53155
Policy Entropy: 3.19886
Value Function Loss: 0.00413

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.53698
Value Function Update Magnitude: 0.55067

Collected Steps per Second: 22,490.94954
Overall Steps per Second: 10,580.91481

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.72814

Cumulative Model Updates: 123,366
Cumulative Timesteps: 1,028,921,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1028921818...
Checkpoint 1028921818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.84149
Policy Entropy: 3.20363
Value Function Loss: 0.00415

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.54557
Value Function Update Magnitude: 0.53978

Collected Steps per Second: 22,298.08533
Overall Steps per Second: 10,611.34407

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.47108
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.71477

Cumulative Model Updates: 123,372
Cumulative Timesteps: 1,028,971,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.51671
Policy Entropy: 3.19498
Value Function Loss: 0.00423

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.55592
Value Function Update Magnitude: 0.55383

Collected Steps per Second: 22,550.74752
Overall Steps per Second: 10,559.98825

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73656

Cumulative Model Updates: 123,378
Cumulative Timesteps: 1,029,021,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1029021866...
Checkpoint 1029021866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.22139
Policy Entropy: 3.20301
Value Function Loss: 0.00435

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.56232

Collected Steps per Second: 20,428.72720
Overall Steps per Second: 10,083.79943

Timestep Collection Time: 2.44861
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.96063

Cumulative Model Updates: 123,384
Cumulative Timesteps: 1,029,071,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.44101
Policy Entropy: 3.19672
Value Function Loss: 0.00479

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.57155

Collected Steps per Second: 22,084.26655
Overall Steps per Second: 10,510.32138

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.76008

Cumulative Model Updates: 123,390
Cumulative Timesteps: 1,029,121,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1029121918...
Checkpoint 1029121918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.63346
Policy Entropy: 3.20941
Value Function Loss: 0.00490

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.56740
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 19,832.69238
Overall Steps per Second: 9,810.77062

Timestep Collection Time: 2.52230
Timestep Consumption Time: 2.57659
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 5.09889

Cumulative Model Updates: 123,396
Cumulative Timesteps: 1,029,171,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.23559
Policy Entropy: 3.20957
Value Function Loss: 0.00442

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.62366

Collected Steps per Second: 22,413.08778
Overall Steps per Second: 10,424.11275

Timestep Collection Time: 2.23155
Timestep Consumption Time: 2.56655
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.79811

Cumulative Model Updates: 123,402
Cumulative Timesteps: 1,029,221,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1029221958...
Checkpoint 1029221958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.04468
Policy Entropy: 3.21637
Value Function Loss: 0.00393

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.59844

Collected Steps per Second: 19,413.93702
Overall Steps per Second: 9,922.62441

Timestep Collection Time: 2.57568
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 5.03939

Cumulative Model Updates: 123,408
Cumulative Timesteps: 1,029,271,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.44289
Policy Entropy: 3.23828
Value Function Loss: 0.00371

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.54321

Collected Steps per Second: 19,559.00401
Overall Steps per Second: 9,870.56081

Timestep Collection Time: 2.55770
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 5.06820

Cumulative Model Updates: 123,414
Cumulative Timesteps: 1,029,321,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1029321988...
Checkpoint 1029321988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.04651
Policy Entropy: 3.23713
Value Function Loss: 0.00382

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.54009

Collected Steps per Second: 20,260.22193
Overall Steps per Second: 10,012.46694

Timestep Collection Time: 2.46888
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 4.99577

Cumulative Model Updates: 123,420
Cumulative Timesteps: 1,029,372,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.64968
Policy Entropy: 3.24310
Value Function Loss: 0.00384

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.55206

Collected Steps per Second: 20,815.80209
Overall Steps per Second: 10,244.82929

Timestep Collection Time: 2.40202
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.88051

Cumulative Model Updates: 123,426
Cumulative Timesteps: 1,029,422,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1029422008...
Checkpoint 1029422008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.24927
Policy Entropy: 3.23543
Value Function Loss: 0.00400

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.53891
Value Function Update Magnitude: 0.54135

Collected Steps per Second: 18,997.09020
Overall Steps per Second: 9,787.38911

Timestep Collection Time: 2.63314
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 5.11086

Cumulative Model Updates: 123,432
Cumulative Timesteps: 1,029,472,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.13031
Policy Entropy: 3.23132
Value Function Loss: 0.00413

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.53160
Value Function Update Magnitude: 0.54976

Collected Steps per Second: 21,270.95034
Overall Steps per Second: 10,199.21873

Timestep Collection Time: 2.35175
Timestep Consumption Time: 2.55294
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.90469

Cumulative Model Updates: 123,438
Cumulative Timesteps: 1,029,522,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1029522054...
Checkpoint 1029522054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.07504
Policy Entropy: 3.21268
Value Function Loss: 0.00422

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.54329

Collected Steps per Second: 22,122.19833
Overall Steps per Second: 10,502.11999

Timestep Collection Time: 2.26135
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.76342

Cumulative Model Updates: 123,444
Cumulative Timesteps: 1,029,572,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.44618
Policy Entropy: 3.20961
Value Function Loss: 0.00419

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.54200

Collected Steps per Second: 22,390.02151
Overall Steps per Second: 10,593.57717

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.72022

Cumulative Model Updates: 123,450
Cumulative Timesteps: 1,029,622,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1029622084...
Checkpoint 1029622084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,717.24827
Policy Entropy: 3.21817
Value Function Loss: 0.00402

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.51966

Collected Steps per Second: 21,358.91940
Overall Steps per Second: 10,517.26764

Timestep Collection Time: 2.34169
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.75561

Cumulative Model Updates: 123,456
Cumulative Timesteps: 1,029,672,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,917.80945
Policy Entropy: 3.20954
Value Function Loss: 0.00407

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.52223

Collected Steps per Second: 21,879.69745
Overall Steps per Second: 10,459.04521

Timestep Collection Time: 2.28568
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.78151

Cumulative Model Updates: 123,462
Cumulative Timesteps: 1,029,722,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1029722110...
Checkpoint 1029722110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.56016
Policy Entropy: 3.20146
Value Function Loss: 0.00391

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.54172

Collected Steps per Second: 21,539.48939
Overall Steps per Second: 10,199.65284

Timestep Collection Time: 2.32150
Timestep Consumption Time: 2.58102
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 4.90252

Cumulative Model Updates: 123,468
Cumulative Timesteps: 1,029,772,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.38824
Policy Entropy: 3.19529
Value Function Loss: 0.00384

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.53790

Collected Steps per Second: 20,817.55340
Overall Steps per Second: 10,159.77415

Timestep Collection Time: 2.40297
Timestep Consumption Time: 2.52076
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.92373

Cumulative Model Updates: 123,474
Cumulative Timesteps: 1,029,822,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1029822138...
Checkpoint 1029822138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.56241
Policy Entropy: 3.18786
Value Function Loss: 0.00382

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.53984
Value Function Update Magnitude: 0.51385

Collected Steps per Second: 22,082.68584
Overall Steps per Second: 10,255.18263

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.61147
PPO Batch Consumption Time: 0.30536
Total Iteration Time: 4.87578

Cumulative Model Updates: 123,480
Cumulative Timesteps: 1,029,872,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.45415
Policy Entropy: 3.19476
Value Function Loss: 0.00393

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.53743
Value Function Update Magnitude: 0.49971

Collected Steps per Second: 21,975.25706
Overall Steps per Second: 10,368.08548

Timestep Collection Time: 2.27656
Timestep Consumption Time: 2.54863
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.82519

Cumulative Model Updates: 123,486
Cumulative Timesteps: 1,029,922,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1029922168...
Checkpoint 1029922168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.87957
Policy Entropy: 3.20155
Value Function Loss: 0.00388

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.49714

Collected Steps per Second: 20,381.29303
Overall Steps per Second: 9,918.11743

Timestep Collection Time: 2.45382
Timestep Consumption Time: 2.58867
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 5.04249

Cumulative Model Updates: 123,492
Cumulative Timesteps: 1,029,972,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.40286
Policy Entropy: 3.21007
Value Function Loss: 0.00365

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.48135

Collected Steps per Second: 20,910.41193
Overall Steps per Second: 10,199.51707

Timestep Collection Time: 2.39182
Timestep Consumption Time: 2.51174
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.90357

Cumulative Model Updates: 123,498
Cumulative Timesteps: 1,030,022,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1030022194...
Checkpoint 1030022194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.93826
Policy Entropy: 3.20875
Value Function Loss: 0.00397

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.48680

Collected Steps per Second: 20,771.85588
Overall Steps per Second: 10,001.53339

Timestep Collection Time: 2.40749
Timestep Consumption Time: 2.59254
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 5.00003

Cumulative Model Updates: 123,504
Cumulative Timesteps: 1,030,072,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.85988
Policy Entropy: 3.20086
Value Function Loss: 0.00381

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.50421

Collected Steps per Second: 20,144.71059
Overall Steps per Second: 9,807.82550

Timestep Collection Time: 2.48214
Timestep Consumption Time: 2.61603
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 5.09817

Cumulative Model Updates: 123,510
Cumulative Timesteps: 1,030,122,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1030122204...
Checkpoint 1030122204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.04776
Policy Entropy: 3.20165
Value Function Loss: 0.00385

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.54141
Value Function Update Magnitude: 0.49215

Collected Steps per Second: 20,556.20570
Overall Steps per Second: 9,643.24748

Timestep Collection Time: 2.43236
Timestep Consumption Time: 2.75262
PPO Batch Consumption Time: 0.31614
Total Iteration Time: 5.18498

Cumulative Model Updates: 123,516
Cumulative Timesteps: 1,030,172,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.18114
Policy Entropy: 3.19392
Value Function Loss: 0.00391

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.54126
Value Function Update Magnitude: 0.50015

Collected Steps per Second: 20,951.69557
Overall Steps per Second: 10,064.63448

Timestep Collection Time: 2.38644
Timestep Consumption Time: 2.58145
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.96789

Cumulative Model Updates: 123,522
Cumulative Timesteps: 1,030,222,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1030222204...
Checkpoint 1030222204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.11877
Policy Entropy: 3.20371
Value Function Loss: 0.00407

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.50512

Collected Steps per Second: 21,672.00300
Overall Steps per Second: 10,319.47037

Timestep Collection Time: 2.30823
Timestep Consumption Time: 2.53930
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.84754

Cumulative Model Updates: 123,528
Cumulative Timesteps: 1,030,272,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.75828
Policy Entropy: 3.19442
Value Function Loss: 0.00421

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.53412

Collected Steps per Second: 22,313.93369
Overall Steps per Second: 10,501.36018

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76395

Cumulative Model Updates: 123,534
Cumulative Timesteps: 1,030,322,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1030322256...
Checkpoint 1030322256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.83129
Policy Entropy: 3.20352
Value Function Loss: 0.00423

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.56417

Collected Steps per Second: 22,025.18885
Overall Steps per Second: 10,040.46809

Timestep Collection Time: 2.27022
Timestep Consumption Time: 2.70983
PPO Batch Consumption Time: 0.32064
Total Iteration Time: 4.98005

Cumulative Model Updates: 123,540
Cumulative Timesteps: 1,030,372,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.98534
Policy Entropy: 3.20503
Value Function Loss: 0.00414

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.56987

Collected Steps per Second: 20,610.76744
Overall Steps per Second: 9,724.42518

Timestep Collection Time: 2.42708
Timestep Consumption Time: 2.71708
PPO Batch Consumption Time: 0.32147
Total Iteration Time: 5.14416

Cumulative Model Updates: 123,546
Cumulative Timesteps: 1,030,422,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030422282...
Checkpoint 1030422282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.66627
Policy Entropy: 3.21471
Value Function Loss: 0.00392

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.56032

Collected Steps per Second: 20,984.28637
Overall Steps per Second: 9,817.07947

Timestep Collection Time: 2.38369
Timestep Consumption Time: 2.71151
PPO Batch Consumption Time: 0.32609
Total Iteration Time: 5.09520

Cumulative Model Updates: 123,552
Cumulative Timesteps: 1,030,472,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.62445
Policy Entropy: 3.21889
Value Function Loss: 0.00412

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.54296

Collected Steps per Second: 20,233.55208
Overall Steps per Second: 9,802.93936

Timestep Collection Time: 2.47164
Timestep Consumption Time: 2.62989
PPO Batch Consumption Time: 0.31134
Total Iteration Time: 5.10153

Cumulative Model Updates: 123,558
Cumulative Timesteps: 1,030,522,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1030522312...
Checkpoint 1030522312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.97092
Policy Entropy: 3.23723
Value Function Loss: 0.00433

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.56672
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 21,708.48202
Overall Steps per Second: 9,947.51338

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.72357
PPO Batch Consumption Time: 0.32464
Total Iteration Time: 5.02719

Cumulative Model Updates: 123,564
Cumulative Timesteps: 1,030,572,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.05123
Policy Entropy: 3.22834
Value Function Loss: 0.00432

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.56981
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 21,438.50940
Overall Steps per Second: 9,972.67865

Timestep Collection Time: 2.33225
Timestep Consumption Time: 2.68145
PPO Batch Consumption Time: 0.31819
Total Iteration Time: 5.01370

Cumulative Model Updates: 123,570
Cumulative Timesteps: 1,030,622,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1030622320...
Checkpoint 1030622320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.78085
Policy Entropy: 3.22114
Value Function Loss: 0.00412

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.54565

Collected Steps per Second: 21,298.01107
Overall Steps per Second: 10,347.11086

Timestep Collection Time: 2.34839
Timestep Consumption Time: 2.48542
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.83381

Cumulative Model Updates: 123,576
Cumulative Timesteps: 1,030,672,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.23557
Policy Entropy: 3.22421
Value Function Loss: 0.00386

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.51383

Collected Steps per Second: 21,284.78598
Overall Steps per Second: 9,897.07885

Timestep Collection Time: 2.34919
Timestep Consumption Time: 2.70301
PPO Batch Consumption Time: 0.31814
Total Iteration Time: 5.05220

Cumulative Model Updates: 123,582
Cumulative Timesteps: 1,030,722,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1030722338...
Checkpoint 1030722338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.21369
Policy Entropy: 3.22062
Value Function Loss: 0.00381

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.51042

Collected Steps per Second: 20,492.12393
Overall Steps per Second: 10,134.36491

Timestep Collection Time: 2.44123
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.93627

Cumulative Model Updates: 123,588
Cumulative Timesteps: 1,030,772,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.10591
Policy Entropy: 3.21073
Value Function Loss: 0.00380

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.52955

Collected Steps per Second: 22,281.40750
Overall Steps per Second: 10,562.76283

Timestep Collection Time: 2.24519
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.73607

Cumulative Model Updates: 123,594
Cumulative Timesteps: 1,030,822,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1030822390...
Checkpoint 1030822390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.26209
Policy Entropy: 3.20755
Value Function Loss: 0.00373

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.53640

Collected Steps per Second: 22,067.18470
Overall Steps per Second: 10,449.49286

Timestep Collection Time: 2.26599
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78530

Cumulative Model Updates: 123,600
Cumulative Timesteps: 1,030,872,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.72303
Policy Entropy: 3.20099
Value Function Loss: 0.00385

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.54126
Value Function Update Magnitude: 0.52658

Collected Steps per Second: 22,503.14525
Overall Steps per Second: 10,585.85322

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.72669

Cumulative Model Updates: 123,606
Cumulative Timesteps: 1,030,922,430

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1030922430...
Checkpoint 1030922430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.53575
Policy Entropy: 3.21362
Value Function Loss: 0.00405

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.54044

Collected Steps per Second: 21,704.78720
Overall Steps per Second: 10,267.57815

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.56637
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 4.87028

Cumulative Model Updates: 123,612
Cumulative Timesteps: 1,030,972,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.03252
Policy Entropy: 3.19922
Value Function Loss: 0.00409

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.56430

Collected Steps per Second: 22,129.06187
Overall Steps per Second: 10,444.45860

Timestep Collection Time: 2.26074
Timestep Consumption Time: 2.52917
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.78991

Cumulative Model Updates: 123,618
Cumulative Timesteps: 1,031,022,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1031022464...
Checkpoint 1031022464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.01670
Policy Entropy: 3.21328
Value Function Loss: 0.00404

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.56408
Value Function Update Magnitude: 0.57474

Collected Steps per Second: 21,977.93021
Overall Steps per Second: 10,468.86474

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.77626

Cumulative Model Updates: 123,624
Cumulative Timesteps: 1,031,072,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.63753
Policy Entropy: 3.19865
Value Function Loss: 0.00387

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.55989
Value Function Update Magnitude: 0.58426

Collected Steps per Second: 21,959.88239
Overall Steps per Second: 10,355.26735

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.55168
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.82865

Cumulative Model Updates: 123,630
Cumulative Timesteps: 1,031,122,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031122468...
Checkpoint 1031122468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.02872
Policy Entropy: 3.21237
Value Function Loss: 0.00386

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.57798

Collected Steps per Second: 22,055.10982
Overall Steps per Second: 10,474.27643

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.77608

Cumulative Model Updates: 123,636
Cumulative Timesteps: 1,031,172,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.71367
Policy Entropy: 3.21594
Value Function Loss: 0.00413

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.56594

Collected Steps per Second: 22,238.17309
Overall Steps per Second: 10,458.40538

Timestep Collection Time: 2.24983
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.78390

Cumulative Model Updates: 123,642
Cumulative Timesteps: 1,031,222,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1031222526...
Checkpoint 1031222526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.61183
Policy Entropy: 3.22870
Value Function Loss: 0.00408

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.56140

Collected Steps per Second: 21,947.45422
Overall Steps per Second: 10,305.26669

Timestep Collection Time: 2.27935
Timestep Consumption Time: 2.57506
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.85441

Cumulative Model Updates: 123,648
Cumulative Timesteps: 1,031,272,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.41562
Policy Entropy: 3.21569
Value Function Loss: 0.00419

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.55529

Collected Steps per Second: 22,115.41332
Overall Steps per Second: 10,410.91575

Timestep Collection Time: 2.26105
Timestep Consumption Time: 2.54199
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.80304

Cumulative Model Updates: 123,654
Cumulative Timesteps: 1,031,322,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1031322556...
Checkpoint 1031322556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.58833
Policy Entropy: 3.22309
Value Function Loss: 0.00417

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.55948

Collected Steps per Second: 22,318.35430
Overall Steps per Second: 10,542.56973

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.74495

Cumulative Model Updates: 123,660
Cumulative Timesteps: 1,031,372,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.98635
Policy Entropy: 3.21158
Value Function Loss: 0.00440

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.57817

Collected Steps per Second: 22,111.04592
Overall Steps per Second: 10,511.58342

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.75666

Cumulative Model Updates: 123,666
Cumulative Timesteps: 1,031,422,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1031422580...
Checkpoint 1031422580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.36551
Policy Entropy: 3.22102
Value Function Loss: 0.00421

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 21,661.85131
Overall Steps per Second: 10,297.52198

Timestep Collection Time: 2.30821
Timestep Consumption Time: 2.54733
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.85554

Cumulative Model Updates: 123,672
Cumulative Timesteps: 1,031,472,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.91606
Policy Entropy: 3.20797
Value Function Loss: 0.00445

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.61959

Collected Steps per Second: 22,739.02824
Overall Steps per Second: 10,660.82812

Timestep Collection Time: 2.19974
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.69194

Cumulative Model Updates: 123,678
Cumulative Timesteps: 1,031,522,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1031522600...
Checkpoint 1031522600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.40556
Policy Entropy: 3.20627
Value Function Loss: 0.00458

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.57553
Value Function Update Magnitude: 0.60756

Collected Steps per Second: 22,136.06472
Overall Steps per Second: 10,431.50135

Timestep Collection Time: 2.25876
Timestep Consumption Time: 2.53442
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.79317

Cumulative Model Updates: 123,684
Cumulative Timesteps: 1,031,572,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.16196
Policy Entropy: 3.20752
Value Function Loss: 0.00477

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.61525

Collected Steps per Second: 22,053.03451
Overall Steps per Second: 10,347.37265

Timestep Collection Time: 2.26799
Timestep Consumption Time: 2.56570
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.83369

Cumulative Model Updates: 123,690
Cumulative Timesteps: 1,031,622,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1031622616...
Checkpoint 1031622616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.65560
Policy Entropy: 3.21847
Value Function Loss: 0.00435

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,113.68222
Overall Steps per Second: 10,604.02613

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.45552
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.71783

Cumulative Model Updates: 123,696
Cumulative Timesteps: 1,031,672,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.59633
Policy Entropy: 3.23684
Value Function Loss: 0.00405

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.55604
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 22,379.43197
Overall Steps per Second: 10,481.73429

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.77097

Cumulative Model Updates: 123,702
Cumulative Timesteps: 1,031,722,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1031722652...
Checkpoint 1031722652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.91124
Policy Entropy: 3.23307
Value Function Loss: 0.00412

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 21,976.49413
Overall Steps per Second: 10,537.12451

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.74627

Cumulative Model Updates: 123,708
Cumulative Timesteps: 1,031,772,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.50325
Policy Entropy: 3.23505
Value Function Loss: 0.00399

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.58032

Collected Steps per Second: 20,431.80055
Overall Steps per Second: 10,139.05720

Timestep Collection Time: 2.44736
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.93182

Cumulative Model Updates: 123,714
Cumulative Timesteps: 1,031,822,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1031822668...
Checkpoint 1031822668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.28462
Policy Entropy: 3.23400
Value Function Loss: 0.00407

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.58371

Collected Steps per Second: 21,157.20826
Overall Steps per Second: 10,202.96383

Timestep Collection Time: 2.36402
Timestep Consumption Time: 2.53809
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.90211

Cumulative Model Updates: 123,720
Cumulative Timesteps: 1,031,872,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.86278
Policy Entropy: 3.24041
Value Function Loss: 0.00403

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.60471

Collected Steps per Second: 21,402.98890
Overall Steps per Second: 10,369.40653

Timestep Collection Time: 2.33734
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.82438

Cumulative Model Updates: 123,726
Cumulative Timesteps: 1,031,922,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1031922710...
Checkpoint 1031922710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.42557
Policy Entropy: 3.22541
Value Function Loss: 0.00416

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.64411

Collected Steps per Second: 22,266.79736
Overall Steps per Second: 10,635.60189

Timestep Collection Time: 2.24684
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.70401

Cumulative Model Updates: 123,732
Cumulative Timesteps: 1,031,972,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.65063
Policy Entropy: 3.22835
Value Function Loss: 0.00391

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,588.35387
Overall Steps per Second: 10,577.64802

Timestep Collection Time: 2.21450
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.72903

Cumulative Model Updates: 123,738
Cumulative Timesteps: 1,032,022,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1032022762...
Checkpoint 1032022762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.67596
Policy Entropy: 3.22265
Value Function Loss: 0.00394

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.53132
Value Function Update Magnitude: 0.56511

Collected Steps per Second: 22,218.02305
Overall Steps per Second: 10,662.81306

Timestep Collection Time: 2.25124
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.69088

Cumulative Model Updates: 123,744
Cumulative Timesteps: 1,032,072,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.44231
Policy Entropy: 3.24068
Value Function Loss: 0.00387

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.52764
Value Function Update Magnitude: 0.55619

Collected Steps per Second: 22,078.59317
Overall Steps per Second: 10,364.84310

Timestep Collection Time: 2.26554
Timestep Consumption Time: 2.56039
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.82593

Cumulative Model Updates: 123,750
Cumulative Timesteps: 1,032,122,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1032122800...
Checkpoint 1032122800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.54797
Policy Entropy: 3.23458
Value Function Loss: 0.00396

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.52956
Value Function Update Magnitude: 0.55720

Collected Steps per Second: 19,800.63764
Overall Steps per Second: 9,741.20613

Timestep Collection Time: 2.52659
Timestep Consumption Time: 2.60912
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 5.13571

Cumulative Model Updates: 123,756
Cumulative Timesteps: 1,032,172,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,467.03294
Policy Entropy: 3.24169
Value Function Loss: 0.00409

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.56345

Collected Steps per Second: 21,225.37182
Overall Steps per Second: 10,198.75570

Timestep Collection Time: 2.35765
Timestep Consumption Time: 2.54903
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 4.90668

Cumulative Model Updates: 123,762
Cumulative Timesteps: 1,032,222,870

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1032222870...
Checkpoint 1032222870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.95754
Policy Entropy: 3.21919
Value Function Loss: 0.00418

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 20,403.57676
Overall Steps per Second: 9,878.07571

Timestep Collection Time: 2.45084
Timestep Consumption Time: 2.61148
PPO Batch Consumption Time: 0.31381
Total Iteration Time: 5.06232

Cumulative Model Updates: 123,768
Cumulative Timesteps: 1,032,272,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.10352
Policy Entropy: 3.20550
Value Function Loss: 0.00422

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.54156

Collected Steps per Second: 22,264.18502
Overall Steps per Second: 10,470.41239

Timestep Collection Time: 2.24702
Timestep Consumption Time: 2.53102
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.77804

Cumulative Model Updates: 123,774
Cumulative Timesteps: 1,032,322,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1032322904...
Checkpoint 1032322904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.47159
Policy Entropy: 3.21439
Value Function Loss: 0.00389

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.53767

Collected Steps per Second: 21,865.77610
Overall Steps per Second: 10,498.56382

Timestep Collection Time: 2.28750
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.76427

Cumulative Model Updates: 123,780
Cumulative Timesteps: 1,032,372,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.37053
Policy Entropy: 3.22199
Value Function Loss: 0.00375

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.52231

Collected Steps per Second: 20,679.04207
Overall Steps per Second: 9,960.86099

Timestep Collection Time: 2.41926
Timestep Consumption Time: 2.60320
PPO Batch Consumption Time: 0.31316
Total Iteration Time: 5.02246

Cumulative Model Updates: 123,786
Cumulative Timesteps: 1,032,422,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1032422950...
Checkpoint 1032422950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.56740
Policy Entropy: 3.22419
Value Function Loss: 0.00372

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.51716
Value Function Update Magnitude: 0.51493

Collected Steps per Second: 21,065.93745
Overall Steps per Second: 10,001.18992

Timestep Collection Time: 2.37473
Timestep Consumption Time: 2.62727
PPO Batch Consumption Time: 0.30450
Total Iteration Time: 5.00200

Cumulative Model Updates: 123,792
Cumulative Timesteps: 1,032,472,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.56340
Policy Entropy: 3.21376
Value Function Loss: 0.00409

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.50400

Collected Steps per Second: 20,559.12145
Overall Steps per Second: 9,731.62553

Timestep Collection Time: 2.43269
Timestep Consumption Time: 2.70663
PPO Batch Consumption Time: 0.32702
Total Iteration Time: 5.13933

Cumulative Model Updates: 123,798
Cumulative Timesteps: 1,032,522,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1032522990...
Checkpoint 1032522990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.22385
Policy Entropy: 3.22196
Value Function Loss: 0.00408

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.50180

Collected Steps per Second: 19,692.81027
Overall Steps per Second: 9,917.43920

Timestep Collection Time: 2.54001
Timestep Consumption Time: 2.50363
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 5.04364

Cumulative Model Updates: 123,804
Cumulative Timesteps: 1,032,573,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.27068
Policy Entropy: 3.21625
Value Function Loss: 0.00431

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.52312

Collected Steps per Second: 21,998.35666
Overall Steps per Second: 10,505.43725

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.76001

Cumulative Model Updates: 123,810
Cumulative Timesteps: 1,032,623,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1032623016...
Checkpoint 1032623016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.10674
Policy Entropy: 3.21564
Value Function Loss: 0.00419

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.54998

Collected Steps per Second: 21,742.01693
Overall Steps per Second: 10,302.66319

Timestep Collection Time: 2.30006
Timestep Consumption Time: 2.55383
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.85389

Cumulative Model Updates: 123,816
Cumulative Timesteps: 1,032,673,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.10906
Policy Entropy: 3.21596
Value Function Loss: 0.00433

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.57367

Collected Steps per Second: 22,124.64067
Overall Steps per Second: 10,426.46963

Timestep Collection Time: 2.26019
Timestep Consumption Time: 2.53587
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.79606

Cumulative Model Updates: 123,822
Cumulative Timesteps: 1,032,723,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1032723030...
Checkpoint 1032723030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.68099
Policy Entropy: 3.21814
Value Function Loss: 0.00441

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.56334

Collected Steps per Second: 21,456.69911
Overall Steps per Second: 10,219.11384

Timestep Collection Time: 2.33065
Timestep Consumption Time: 2.56293
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.89358

Cumulative Model Updates: 123,828
Cumulative Timesteps: 1,032,773,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.49323
Policy Entropy: 3.23022
Value Function Loss: 0.00436

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.54864

Collected Steps per Second: 21,719.52868
Overall Steps per Second: 10,472.47246

Timestep Collection Time: 2.30336
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.77710

Cumulative Model Updates: 123,834
Cumulative Timesteps: 1,032,823,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1032823066...
Checkpoint 1032823066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.64448
Policy Entropy: 3.21948
Value Function Loss: 0.00429

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.54587
Value Function Update Magnitude: 0.55222

Collected Steps per Second: 22,100.78376
Overall Steps per Second: 10,574.22983

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.72867

Cumulative Model Updates: 123,840
Cumulative Timesteps: 1,032,873,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,067.80560
Policy Entropy: 3.23023
Value Function Loss: 0.00406

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.55389

Collected Steps per Second: 22,470.55636
Overall Steps per Second: 10,524.81168

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.75258

Cumulative Model Updates: 123,846
Cumulative Timesteps: 1,032,923,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1032923088...
Checkpoint 1032923088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536.44915
Policy Entropy: 3.22731
Value Function Loss: 0.00414

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 21,708.60530
Overall Steps per Second: 10,381.05317

Timestep Collection Time: 2.30323
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.81647

Cumulative Model Updates: 123,852
Cumulative Timesteps: 1,032,973,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.70742
Policy Entropy: 3.24551
Value Function Loss: 0.00408

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 21,787.88247
Overall Steps per Second: 10,286.13428

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.56739
PPO Batch Consumption Time: 0.30362
Total Iteration Time: 4.86344

Cumulative Model Updates: 123,858
Cumulative Timesteps: 1,033,023,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1033023114...
Checkpoint 1033023114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.90701
Policy Entropy: 3.25669
Value Function Loss: 0.00425

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.53039

Collected Steps per Second: 21,985.42351
Overall Steps per Second: 10,423.16096

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.52378
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.79893

Cumulative Model Updates: 123,864
Cumulative Timesteps: 1,033,073,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.12941
Policy Entropy: 3.25152
Value Function Loss: 0.00407

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.52115

Collected Steps per Second: 22,508.02759
Overall Steps per Second: 10,627.02756

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.70611

Cumulative Model Updates: 123,870
Cumulative Timesteps: 1,033,123,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033123146...
Checkpoint 1033123146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.65766
Policy Entropy: 3.23624
Value Function Loss: 0.00413

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.52571
Value Function Update Magnitude: 0.51054

Collected Steps per Second: 21,998.21648
Overall Steps per Second: 10,456.85589

Timestep Collection Time: 2.27382
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.78346

Cumulative Model Updates: 123,876
Cumulative Timesteps: 1,033,173,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.95325
Policy Entropy: 3.21812
Value Function Loss: 0.00418

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.54084
Value Function Update Magnitude: 0.51987

Collected Steps per Second: 22,376.92890
Overall Steps per Second: 10,662.80314

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.69126

Cumulative Model Updates: 123,882
Cumulative Timesteps: 1,033,223,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1033223188...
Checkpoint 1033223188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.94829
Policy Entropy: 3.22390
Value Function Loss: 0.00421

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.52567

Collected Steps per Second: 22,322.00651
Overall Steps per Second: 10,642.65422

Timestep Collection Time: 2.24012
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.69845

Cumulative Model Updates: 123,888
Cumulative Timesteps: 1,033,273,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.63992
Policy Entropy: 3.22181
Value Function Loss: 0.00410

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.53181

Collected Steps per Second: 22,354.38836
Overall Steps per Second: 10,519.59358

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75361

Cumulative Model Updates: 123,894
Cumulative Timesteps: 1,033,323,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1033323198...
Checkpoint 1033323198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.66174
Policy Entropy: 3.22527
Value Function Loss: 0.00374

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.53283
Value Function Update Magnitude: 0.52717

Collected Steps per Second: 21,972.52257
Overall Steps per Second: 10,487.71790

Timestep Collection Time: 2.27557
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.76748

Cumulative Model Updates: 123,900
Cumulative Timesteps: 1,033,373,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.30803
Policy Entropy: 3.23086
Value Function Loss: 0.00383

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.52036
Value Function Update Magnitude: 0.50821

Collected Steps per Second: 22,759.83166
Overall Steps per Second: 10,555.71999

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.54032
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.73753

Cumulative Model Updates: 123,906
Cumulative Timesteps: 1,033,423,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1033423206...
Checkpoint 1033423206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.35428
Policy Entropy: 3.22766
Value Function Loss: 0.00400

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.50497

Collected Steps per Second: 21,616.62839
Overall Steps per Second: 10,355.72351

Timestep Collection Time: 2.31405
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.83037

Cumulative Model Updates: 123,912
Cumulative Timesteps: 1,033,473,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.16614
Policy Entropy: 3.22593
Value Function Loss: 0.00395

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.52819
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 22,411.12853
Overall Steps per Second: 10,546.02141

Timestep Collection Time: 2.23112
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.74131

Cumulative Model Updates: 123,918
Cumulative Timesteps: 1,033,523,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1033523230...
Checkpoint 1033523230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.23239
Policy Entropy: 3.22465
Value Function Loss: 0.00412

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.51327

Collected Steps per Second: 21,884.12112
Overall Steps per Second: 10,471.92061

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.49011
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.77506

Cumulative Model Updates: 123,924
Cumulative Timesteps: 1,033,573,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.86630
Policy Entropy: 3.23566
Value Function Loss: 0.00384

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.52762
Value Function Update Magnitude: 0.50932

Collected Steps per Second: 22,196.57312
Overall Steps per Second: 10,404.72712

Timestep Collection Time: 2.25323
Timestep Consumption Time: 2.55362
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 4.80685

Cumulative Model Updates: 123,930
Cumulative Timesteps: 1,033,623,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1033623248...
Checkpoint 1033623248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.91498
Policy Entropy: 3.24375
Value Function Loss: 0.00367

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.51771
Value Function Update Magnitude: 0.49991

Collected Steps per Second: 22,424.90395
Overall Steps per Second: 10,646.35791

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69719

Cumulative Model Updates: 123,936
Cumulative Timesteps: 1,033,673,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.50116
Policy Entropy: 3.23609
Value Function Loss: 0.00392

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.52505
Value Function Update Magnitude: 0.49681

Collected Steps per Second: 22,158.63384
Overall Steps per Second: 10,284.92556

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.60503
PPO Batch Consumption Time: 0.31008
Total Iteration Time: 4.86148

Cumulative Model Updates: 123,942
Cumulative Timesteps: 1,033,723,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1033723256...
Checkpoint 1033723256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,014.25587
Policy Entropy: 3.22842
Value Function Loss: 0.00399

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.51501

Collected Steps per Second: 22,041.97362
Overall Steps per Second: 10,443.91919

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.78901

Cumulative Model Updates: 123,948
Cumulative Timesteps: 1,033,773,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.04246
Policy Entropy: 3.20568
Value Function Loss: 0.00422

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.54882

Collected Steps per Second: 22,383.57065
Overall Steps per Second: 10,570.48862

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.73299

Cumulative Model Updates: 123,954
Cumulative Timesteps: 1,033,823,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1033823302...
Checkpoint 1033823302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.51714
Policy Entropy: 3.21643
Value Function Loss: 0.00383

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.54287
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 22,246.69669
Overall Steps per Second: 10,446.45350

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.54021
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 4.78899

Cumulative Model Updates: 123,960
Cumulative Timesteps: 1,033,873,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.28752
Policy Entropy: 3.22934
Value Function Loss: 0.00426

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.59205

Collected Steps per Second: 20,164.67184
Overall Steps per Second: 10,139.67122

Timestep Collection Time: 2.47968
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.93132

Cumulative Model Updates: 123,966
Cumulative Timesteps: 1,033,923,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1033923332...
Checkpoint 1033923332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.41280
Policy Entropy: 3.23217
Value Function Loss: 0.00422

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 22,051.48264
Overall Steps per Second: 10,509.20349

Timestep Collection Time: 2.26842
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.75983

Cumulative Model Updates: 123,972
Cumulative Timesteps: 1,033,973,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.56996
Policy Entropy: 3.24917
Value Function Loss: 0.00393

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.58671

Collected Steps per Second: 22,239.50183
Overall Steps per Second: 10,460.66734

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.53257
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.78172

Cumulative Model Updates: 123,978
Cumulative Timesteps: 1,034,023,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1034023374...
Checkpoint 1034023374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.39205
Policy Entropy: 3.25514
Value Function Loss: 0.00385

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.57614

Collected Steps per Second: 21,870.72646
Overall Steps per Second: 10,601.30591

Timestep Collection Time: 2.28653
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.71715

Cumulative Model Updates: 123,984
Cumulative Timesteps: 1,034,073,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.24982
Policy Entropy: 3.25404
Value Function Loss: 0.00402

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.54372
Value Function Update Magnitude: 0.59300

Collected Steps per Second: 21,527.65897
Overall Steps per Second: 9,528.60222

Timestep Collection Time: 2.32352
Timestep Consumption Time: 2.92594
PPO Batch Consumption Time: 0.35487
Total Iteration Time: 5.24946

Cumulative Model Updates: 123,990
Cumulative Timesteps: 1,034,123,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1034123402...
Checkpoint 1034123402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.86536
Policy Entropy: 3.24216
Value Function Loss: 0.00404

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 18,951.25767
Overall Steps per Second: 9,479.80346

Timestep Collection Time: 2.63982
Timestep Consumption Time: 2.63750
PPO Batch Consumption Time: 0.30570
Total Iteration Time: 5.27732

Cumulative Model Updates: 123,996
Cumulative Timesteps: 1,034,173,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.60686
Policy Entropy: 3.24439
Value Function Loss: 0.00408

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.58543

Collected Steps per Second: 19,050.41891
Overall Steps per Second: 9,848.63487

Timestep Collection Time: 2.62598
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 5.07949

Cumulative Model Updates: 124,002
Cumulative Timesteps: 1,034,223,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1034223456...
Checkpoint 1034223456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.82420
Policy Entropy: 3.23906
Value Function Loss: 0.00393

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.54248
Value Function Update Magnitude: 0.54985

Collected Steps per Second: 19,668.19620
Overall Steps per Second: 9,978.41494

Timestep Collection Time: 2.54350
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 5.01342

Cumulative Model Updates: 124,008
Cumulative Timesteps: 1,034,273,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.62423
Policy Entropy: 3.23200
Value Function Loss: 0.00409

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.53216
Value Function Update Magnitude: 0.54894

Collected Steps per Second: 21,977.34785
Overall Steps per Second: 10,207.34803

Timestep Collection Time: 2.27562
Timestep Consumption Time: 2.62399
PPO Batch Consumption Time: 0.31060
Total Iteration Time: 4.89961

Cumulative Model Updates: 124,014
Cumulative Timesteps: 1,034,323,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1034323494...
Checkpoint 1034323494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.99316
Policy Entropy: 3.23225
Value Function Loss: 0.00415

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.53324
Value Function Update Magnitude: 0.56531

Collected Steps per Second: 20,715.67169
Overall Steps per Second: 10,094.46492

Timestep Collection Time: 2.41382
Timestep Consumption Time: 2.53978
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.95361

Cumulative Model Updates: 124,020
Cumulative Timesteps: 1,034,373,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.69464
Policy Entropy: 3.22952
Value Function Loss: 0.00431

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.57966

Collected Steps per Second: 21,537.89623
Overall Steps per Second: 10,235.77151

Timestep Collection Time: 2.32195
Timestep Consumption Time: 2.56385
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.88581

Cumulative Model Updates: 124,026
Cumulative Timesteps: 1,034,423,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1034423508...
Checkpoint 1034423508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.33534
Policy Entropy: 3.23214
Value Function Loss: 0.00418

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.57539

Collected Steps per Second: 20,520.21296
Overall Steps per Second: 10,034.31490

Timestep Collection Time: 2.43769
Timestep Consumption Time: 2.54740
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.98509

Cumulative Model Updates: 124,032
Cumulative Timesteps: 1,034,473,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.35588
Policy Entropy: 3.22766
Value Function Loss: 0.00399

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.54372
Value Function Update Magnitude: 0.54457

Collected Steps per Second: 21,696.00127
Overall Steps per Second: 10,441.25993

Timestep Collection Time: 2.30531
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.79023

Cumulative Model Updates: 124,038
Cumulative Timesteps: 1,034,523,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1034523546...
Checkpoint 1034523546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.71299
Policy Entropy: 3.23813
Value Function Loss: 0.00404

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.53584

Collected Steps per Second: 21,601.75595
Overall Steps per Second: 10,273.61458

Timestep Collection Time: 2.31555
Timestep Consumption Time: 2.55323
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.86878

Cumulative Model Updates: 124,044
Cumulative Timesteps: 1,034,573,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.72403
Policy Entropy: 3.25016
Value Function Loss: 0.00414

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.55196
Value Function Update Magnitude: 0.55706

Collected Steps per Second: 21,997.38837
Overall Steps per Second: 10,513.57047

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.48375
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.75766

Cumulative Model Updates: 124,050
Cumulative Timesteps: 1,034,623,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1034623586...
Checkpoint 1034623586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.89716
Policy Entropy: 3.26375
Value Function Loss: 0.00400

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.56122

Collected Steps per Second: 21,703.09830
Overall Steps per Second: 10,149.30337

Timestep Collection Time: 2.30621
Timestep Consumption Time: 2.62536
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.93157

Cumulative Model Updates: 124,056
Cumulative Timesteps: 1,034,673,638

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.80441
Policy Entropy: 3.25447
Value Function Loss: 0.00385

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.53145
Value Function Update Magnitude: 0.54615

Collected Steps per Second: 20,643.67552
Overall Steps per Second: 10,037.41673

Timestep Collection Time: 2.42263
Timestep Consumption Time: 2.55993
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.98256

Cumulative Model Updates: 124,062
Cumulative Timesteps: 1,034,723,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1034723650...
Checkpoint 1034723650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.32022
Policy Entropy: 3.23742
Value Function Loss: 0.00374

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.52688

Collected Steps per Second: 19,427.88103
Overall Steps per Second: 9,837.87282

Timestep Collection Time: 2.57393
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 5.08301

Cumulative Model Updates: 124,068
Cumulative Timesteps: 1,034,773,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.50938
Policy Entropy: 3.22499
Value Function Loss: 0.00413

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.52488

Collected Steps per Second: 19,481.98785
Overall Steps per Second: 9,413.05793

Timestep Collection Time: 2.56801
Timestep Consumption Time: 2.74694
PPO Batch Consumption Time: 0.32385
Total Iteration Time: 5.31496

Cumulative Model Updates: 124,074
Cumulative Timesteps: 1,034,823,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1034823686...
Checkpoint 1034823686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.40625
Policy Entropy: 3.22736
Value Function Loss: 0.00401

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.55404
Value Function Update Magnitude: 0.52966

Collected Steps per Second: 19,912.22347
Overall Steps per Second: 10,032.61211

Timestep Collection Time: 2.51192
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.98554

Cumulative Model Updates: 124,080
Cumulative Timesteps: 1,034,873,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.84391
Policy Entropy: 3.23778
Value Function Loss: 0.00370

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 21,275.68927
Overall Steps per Second: 9,899.29596

Timestep Collection Time: 2.35189
Timestep Consumption Time: 2.70282
PPO Batch Consumption Time: 0.31248
Total Iteration Time: 5.05470

Cumulative Model Updates: 124,086
Cumulative Timesteps: 1,034,923,742

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1034923742...
Checkpoint 1034923742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.85094
Policy Entropy: 3.23293
Value Function Loss: 0.00360

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.52719
Value Function Update Magnitude: 0.49104

Collected Steps per Second: 19,573.31840
Overall Steps per Second: 9,877.73202

Timestep Collection Time: 2.55583
Timestep Consumption Time: 2.50870
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 5.06452

Cumulative Model Updates: 124,092
Cumulative Timesteps: 1,034,973,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.50281
Policy Entropy: 3.22669
Value Function Loss: 0.00400

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.48295

Collected Steps per Second: 18,768.34174
Overall Steps per Second: 9,608.81378

Timestep Collection Time: 2.66523
Timestep Consumption Time: 2.54061
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 5.20585

Cumulative Model Updates: 124,098
Cumulative Timesteps: 1,035,023,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035023790...
Checkpoint 1035023790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.06772
Policy Entropy: 3.20589
Value Function Loss: 0.00427

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.49003

Collected Steps per Second: 20,536.10496
Overall Steps per Second: 10,004.28755

Timestep Collection Time: 2.43649
Timestep Consumption Time: 2.56497
PPO Batch Consumption Time: 0.30215
Total Iteration Time: 5.00146

Cumulative Model Updates: 124,104
Cumulative Timesteps: 1,035,073,826

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.22817
Policy Entropy: 3.21444
Value Function Loss: 0.00434

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.51799

Collected Steps per Second: 21,786.11567
Overall Steps per Second: 10,453.34416

Timestep Collection Time: 2.29605
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.78526

Cumulative Model Updates: 124,110
Cumulative Timesteps: 1,035,123,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035123848...
Checkpoint 1035123848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.73445
Policy Entropy: 3.21410
Value Function Loss: 0.00404

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.53653

Collected Steps per Second: 20,809.97534
Overall Steps per Second: 10,122.35664

Timestep Collection Time: 2.40317
Timestep Consumption Time: 2.53737
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.94055

Cumulative Model Updates: 124,116
Cumulative Timesteps: 1,035,173,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.04911
Policy Entropy: 3.21839
Value Function Loss: 0.00417

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.54628
Value Function Update Magnitude: 0.52857

Collected Steps per Second: 21,120.98848
Overall Steps per Second: 10,171.46625

Timestep Collection Time: 2.36788
Timestep Consumption Time: 2.54901
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.91689

Cumulative Model Updates: 124,122
Cumulative Timesteps: 1,035,223,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1035223870...
Checkpoint 1035223870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.56326
Policy Entropy: 3.22246
Value Function Loss: 0.00400

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.53286

Collected Steps per Second: 20,975.82944
Overall Steps per Second: 10,185.25582

Timestep Collection Time: 2.38436
Timestep Consumption Time: 2.52607
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.91043

Cumulative Model Updates: 124,128
Cumulative Timesteps: 1,035,273,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.19315
Policy Entropy: 3.23171
Value Function Loss: 0.00369

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.53546

Collected Steps per Second: 20,368.70533
Overall Steps per Second: 9,952.91963

Timestep Collection Time: 2.45573
Timestep Consumption Time: 2.56993
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.02566

Cumulative Model Updates: 124,134
Cumulative Timesteps: 1,035,323,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1035323904...
Checkpoint 1035323904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.54280
Policy Entropy: 3.22897
Value Function Loss: 0.00376

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.53891

Collected Steps per Second: 20,821.84809
Overall Steps per Second: 10,061.55789

Timestep Collection Time: 2.40200
Timestep Consumption Time: 2.56880
PPO Batch Consumption Time: 0.30205
Total Iteration Time: 4.97080

Cumulative Model Updates: 124,140
Cumulative Timesteps: 1,035,373,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.28246
Policy Entropy: 3.23008
Value Function Loss: 0.00407

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.55011
Value Function Update Magnitude: 0.53539

Collected Steps per Second: 20,574.15571
Overall Steps per Second: 10,022.83058

Timestep Collection Time: 2.43043
Timestep Consumption Time: 2.55858
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.98901

Cumulative Model Updates: 124,146
Cumulative Timesteps: 1,035,423,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1035423922...
Checkpoint 1035423922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.41155
Policy Entropy: 3.22000
Value Function Loss: 0.00422

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.52740

Collected Steps per Second: 19,383.34209
Overall Steps per Second: 9,749.23304

Timestep Collection Time: 2.57964
Timestep Consumption Time: 2.54918
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 5.12881

Cumulative Model Updates: 124,152
Cumulative Timesteps: 1,035,473,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.00944
Policy Entropy: 3.21492
Value Function Loss: 0.00450

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.53243

Collected Steps per Second: 22,455.03605
Overall Steps per Second: 10,386.89351

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.58771
PPO Batch Consumption Time: 0.30764
Total Iteration Time: 4.81491

Cumulative Model Updates: 124,158
Cumulative Timesteps: 1,035,523,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1035523936...
Checkpoint 1035523936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.13134
Policy Entropy: 3.21170
Value Function Loss: 0.00446

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.57628
Value Function Update Magnitude: 0.54873

Collected Steps per Second: 18,671.01911
Overall Steps per Second: 9,274.93433

Timestep Collection Time: 2.67902
Timestep Consumption Time: 2.71401
PPO Batch Consumption Time: 0.32287
Total Iteration Time: 5.39303

Cumulative Model Updates: 124,164
Cumulative Timesteps: 1,035,573,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.11664
Policy Entropy: 3.21668
Value Function Loss: 0.00445

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.58538
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 20,470.91454
Overall Steps per Second: 10,133.67872

Timestep Collection Time: 2.44288
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.93483

Cumulative Model Updates: 124,170
Cumulative Timesteps: 1,035,623,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035623964...
Checkpoint 1035623964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.39001
Policy Entropy: 3.21976
Value Function Loss: 0.00443

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.58209
Value Function Update Magnitude: 0.57831

Collected Steps per Second: 21,722.34726
Overall Steps per Second: 10,168.31844

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.61629
PPO Batch Consumption Time: 0.30922
Total Iteration Time: 4.91881

Cumulative Model Updates: 124,176
Cumulative Timesteps: 1,035,673,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.08001
Policy Entropy: 3.23242
Value Function Loss: 0.00448

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.58484

Collected Steps per Second: 20,061.12744
Overall Steps per Second: 10,107.59388

Timestep Collection Time: 2.49348
Timestep Consumption Time: 2.45547
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.94895

Cumulative Model Updates: 124,182
Cumulative Timesteps: 1,035,724,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035724002...
Checkpoint 1035724002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.92623
Policy Entropy: 3.24174
Value Function Loss: 0.00465

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.61111

Collected Steps per Second: 18,434.00969
Overall Steps per Second: 9,417.00761

Timestep Collection Time: 2.71401
Timestep Consumption Time: 2.59872
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 5.31273

Cumulative Model Updates: 124,188
Cumulative Timesteps: 1,035,774,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.99443
Policy Entropy: 3.25824
Value Function Loss: 0.00434

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 21,813.49198
Overall Steps per Second: 10,394.63790

Timestep Collection Time: 2.29262
Timestep Consumption Time: 2.51852
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.81113

Cumulative Model Updates: 124,194
Cumulative Timesteps: 1,035,824,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1035824042...
Checkpoint 1035824042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.07617
Policy Entropy: 3.25526
Value Function Loss: 0.00424

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 20,758.36192
Overall Steps per Second: 10,153.42406

Timestep Collection Time: 2.41011
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.92740

Cumulative Model Updates: 124,200
Cumulative Timesteps: 1,035,874,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.14935
Policy Entropy: 3.26489
Value Function Loss: 0.00399

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.59331

Collected Steps per Second: 22,494.57498
Overall Steps per Second: 10,677.02174

Timestep Collection Time: 2.22400
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.68558

Cumulative Model Updates: 124,206
Cumulative Timesteps: 1,035,924,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1035924100...
Checkpoint 1035924100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.56366
Policy Entropy: 3.25659
Value Function Loss: 0.00365

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.57409

Collected Steps per Second: 21,922.26081
Overall Steps per Second: 10,429.19185

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.79692

Cumulative Model Updates: 124,212
Cumulative Timesteps: 1,035,974,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.24509
Policy Entropy: 3.25019
Value Function Loss: 0.00400

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.57199

Collected Steps per Second: 20,419.23479
Overall Steps per Second: 10,164.98274

Timestep Collection Time: 2.44975
Timestep Consumption Time: 2.47126
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.92101

Cumulative Model Updates: 124,218
Cumulative Timesteps: 1,036,024,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1036024150...
Checkpoint 1036024150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.61379
Policy Entropy: 3.23913
Value Function Loss: 0.00375

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.59331

Collected Steps per Second: 22,196.04321
Overall Steps per Second: 10,292.18924

Timestep Collection Time: 2.25337
Timestep Consumption Time: 2.60623
PPO Batch Consumption Time: 0.30651
Total Iteration Time: 4.85961

Cumulative Model Updates: 124,224
Cumulative Timesteps: 1,036,074,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.98159
Policy Entropy: 3.23147
Value Function Loss: 0.00410

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 19,943.39044
Overall Steps per Second: 9,576.56732

Timestep Collection Time: 2.50760
Timestep Consumption Time: 2.71452
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 5.22212

Cumulative Model Updates: 124,230
Cumulative Timesteps: 1,036,124,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1036124176...
Checkpoint 1036124176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.46224
Policy Entropy: 3.22780
Value Function Loss: 0.00414

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.57883

Collected Steps per Second: 21,775.24531
Overall Steps per Second: 10,273.41356

Timestep Collection Time: 2.29738
Timestep Consumption Time: 2.57208
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.86946

Cumulative Model Updates: 124,236
Cumulative Timesteps: 1,036,174,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.90259
Policy Entropy: 3.21840
Value Function Loss: 0.00445

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.60515

Collected Steps per Second: 20,127.99979
Overall Steps per Second: 10,043.62690

Timestep Collection Time: 2.48569
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.98147

Cumulative Model Updates: 124,242
Cumulative Timesteps: 1,036,224,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1036224234...
Checkpoint 1036224234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.10594
Policy Entropy: 3.21941
Value Function Loss: 0.00427

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.61168

Collected Steps per Second: 22,059.78634
Overall Steps per Second: 10,511.97140

Timestep Collection Time: 2.26666
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.75667

Cumulative Model Updates: 124,248
Cumulative Timesteps: 1,036,274,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.80397
Policy Entropy: 3.21312
Value Function Loss: 0.00393

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 21,602.55717
Overall Steps per Second: 10,235.67298

Timestep Collection Time: 2.31556
Timestep Consumption Time: 2.57147
PPO Batch Consumption Time: 0.30520
Total Iteration Time: 4.88703

Cumulative Model Updates: 124,254
Cumulative Timesteps: 1,036,324,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1036324258...
Checkpoint 1036324258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.09813
Policy Entropy: 3.21012
Value Function Loss: 0.00382

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.56405
Value Function Update Magnitude: 0.55751

Collected Steps per Second: 16,715.15235
Overall Steps per Second: 8,596.36169

Timestep Collection Time: 2.99178
Timestep Consumption Time: 2.82557
PPO Batch Consumption Time: 0.33592
Total Iteration Time: 5.81734

Cumulative Model Updates: 124,260
Cumulative Timesteps: 1,036,374,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.99149
Policy Entropy: 3.20025
Value Function Loss: 0.00387

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.53332

Collected Steps per Second: 18,978.65838
Overall Steps per Second: 9,568.58022

Timestep Collection Time: 2.63496
Timestep Consumption Time: 2.59131
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 5.22627

Cumulative Model Updates: 124,266
Cumulative Timesteps: 1,036,424,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1036424274...
Checkpoint 1036424274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.44906
Policy Entropy: 3.19255
Value Function Loss: 0.00387

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.53559

Collected Steps per Second: 20,218.04877
Overall Steps per Second: 9,796.20143

Timestep Collection Time: 2.47324
Timestep Consumption Time: 2.63119
PPO Batch Consumption Time: 0.30768
Total Iteration Time: 5.10443

Cumulative Model Updates: 124,272
Cumulative Timesteps: 1,036,474,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.94885
Policy Entropy: 3.18782
Value Function Loss: 0.00415

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 18,294.65913
Overall Steps per Second: 9,345.69139

Timestep Collection Time: 2.73468
Timestep Consumption Time: 2.61859
PPO Batch Consumption Time: 0.30304
Total Iteration Time: 5.35327

Cumulative Model Updates: 124,278
Cumulative Timesteps: 1,036,524,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036524308...
Checkpoint 1036524308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.20121
Policy Entropy: 3.19419
Value Function Loss: 0.00407

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.55766

Collected Steps per Second: 19,154.47956
Overall Steps per Second: 9,549.78242

Timestep Collection Time: 2.61150
Timestep Consumption Time: 2.62652
PPO Batch Consumption Time: 0.30550
Total Iteration Time: 5.23803

Cumulative Model Updates: 124,284
Cumulative Timesteps: 1,036,574,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.79013
Policy Entropy: 3.20751
Value Function Loss: 0.00383

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.54241

Collected Steps per Second: 21,901.98483
Overall Steps per Second: 10,368.62268

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.53985
PPO Batch Consumption Time: 0.29927
Total Iteration Time: 4.82321

Cumulative Model Updates: 124,290
Cumulative Timesteps: 1,036,624,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1036624340...
Checkpoint 1036624340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.29344
Policy Entropy: 3.20429
Value Function Loss: 0.00379

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.51726

Collected Steps per Second: 22,427.75717
Overall Steps per Second: 10,601.21617

Timestep Collection Time: 2.22938
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71644

Cumulative Model Updates: 124,296
Cumulative Timesteps: 1,036,674,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.86905
Policy Entropy: 3.21162
Value Function Loss: 0.00377

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.51521

Collected Steps per Second: 22,470.89239
Overall Steps per Second: 10,520.61234

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.52818
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.75391

Cumulative Model Updates: 124,302
Cumulative Timesteps: 1,036,724,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1036724354...
Checkpoint 1036724354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.20393
Policy Entropy: 3.21291
Value Function Loss: 0.00397

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.52609

Collected Steps per Second: 22,142.98576
Overall Steps per Second: 10,584.23204

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.46596
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.72401

Cumulative Model Updates: 124,308
Cumulative Timesteps: 1,036,774,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,177.28310
Policy Entropy: 3.22028
Value Function Loss: 0.00377

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.54547

Collected Steps per Second: 22,778.29125
Overall Steps per Second: 10,461.25974

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.58560
PPO Batch Consumption Time: 0.30880
Total Iteration Time: 4.78164

Cumulative Model Updates: 124,314
Cumulative Timesteps: 1,036,824,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1036824376...
Checkpoint 1036824376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.72882
Policy Entropy: 3.20280
Value Function Loss: 0.00397

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.57559

Collected Steps per Second: 22,161.26855
Overall Steps per Second: 10,591.62755

Timestep Collection Time: 2.25745
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.72335

Cumulative Model Updates: 124,320
Cumulative Timesteps: 1,036,874,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.92309
Policy Entropy: 3.19778
Value Function Loss: 0.00388

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.58232

Collected Steps per Second: 22,870.29679
Overall Steps per Second: 10,630.24447

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.51782
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.70450

Cumulative Model Updates: 124,326
Cumulative Timesteps: 1,036,924,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1036924414...
Checkpoint 1036924414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.77109
Policy Entropy: 3.20404
Value Function Loss: 0.00357

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.55123

Collected Steps per Second: 22,136.68010
Overall Steps per Second: 10,542.26379

Timestep Collection Time: 2.25906
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.74357

Cumulative Model Updates: 124,332
Cumulative Timesteps: 1,036,974,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.27589
Policy Entropy: 3.21164
Value Function Loss: 0.00372

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.52351

Collected Steps per Second: 22,652.73083
Overall Steps per Second: 10,586.30941

Timestep Collection Time: 2.20724
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.72308

Cumulative Model Updates: 124,338
Cumulative Timesteps: 1,037,024,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037024422...
Checkpoint 1037024422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,417.66111
Policy Entropy: 3.22045
Value Function Loss: 0.00399

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.55848
Value Function Update Magnitude: 0.53552

Collected Steps per Second: 22,429.22341
Overall Steps per Second: 10,455.53921

Timestep Collection Time: 2.22941
Timestep Consumption Time: 2.55312
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.78254

Cumulative Model Updates: 124,344
Cumulative Timesteps: 1,037,074,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.08829
Policy Entropy: 3.21706
Value Function Loss: 0.00390

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.54942

Collected Steps per Second: 22,510.72722
Overall Steps per Second: 10,507.87892

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.53859
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.76100

Cumulative Model Updates: 124,350
Cumulative Timesteps: 1,037,124,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037124454...
Checkpoint 1037124454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.43640
Policy Entropy: 3.23082
Value Function Loss: 0.00420

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 0.54894

Collected Steps per Second: 21,693.49645
Overall Steps per Second: 10,469.22716

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.77686

Cumulative Model Updates: 124,356
Cumulative Timesteps: 1,037,174,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.04101
Policy Entropy: 3.23190
Value Function Loss: 0.00400

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.57005
Value Function Update Magnitude: 0.55486

Collected Steps per Second: 22,473.34457
Overall Steps per Second: 10,669.97859

Timestep Collection Time: 2.22610
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.68867

Cumulative Model Updates: 124,362
Cumulative Timesteps: 1,037,224,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037224492...
Checkpoint 1037224492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.79393
Policy Entropy: 3.21364
Value Function Loss: 0.00391

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.53770

Collected Steps per Second: 22,006.90030
Overall Steps per Second: 10,590.61413

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.72267

Cumulative Model Updates: 124,368
Cumulative Timesteps: 1,037,274,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.81240
Policy Entropy: 3.20737
Value Function Loss: 0.00410

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.54905

Collected Steps per Second: 22,489.92517
Overall Steps per Second: 10,504.45735

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.53768
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.76179

Cumulative Model Updates: 124,374
Cumulative Timesteps: 1,037,324,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1037324528...
Checkpoint 1037324528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.75329
Policy Entropy: 3.19596
Value Function Loss: 0.00416

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.57332
Value Function Update Magnitude: 0.56664

Collected Steps per Second: 22,106.58692
Overall Steps per Second: 10,520.43946

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.49128
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.75341

Cumulative Model Updates: 124,380
Cumulative Timesteps: 1,037,374,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.54191
Policy Entropy: 3.20217
Value Function Loss: 0.00435

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.57182
Value Function Update Magnitude: 0.55640

Collected Steps per Second: 22,720.97119
Overall Steps per Second: 10,557.11821

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.53695
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.73879

Cumulative Model Updates: 124,386
Cumulative Timesteps: 1,037,424,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037424564...
Checkpoint 1037424564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.82436
Policy Entropy: 3.20435
Value Function Loss: 0.00425

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.55742

Collected Steps per Second: 22,269.32207
Overall Steps per Second: 10,466.15623

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.53388
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.78074

Cumulative Model Updates: 124,392
Cumulative Timesteps: 1,037,474,600

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.47607
Policy Entropy: 3.20289
Value Function Loss: 0.00422

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.52876

Collected Steps per Second: 22,635.28096
Overall Steps per Second: 10,506.30772

Timestep Collection Time: 2.21018
Timestep Consumption Time: 2.55153
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.76171

Cumulative Model Updates: 124,398
Cumulative Timesteps: 1,037,524,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037524628...
Checkpoint 1037524628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.69680
Policy Entropy: 3.21330
Value Function Loss: 0.00404

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.55629
Value Function Update Magnitude: 0.50513

Collected Steps per Second: 22,207.89776
Overall Steps per Second: 10,642.07686

Timestep Collection Time: 2.25271
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.70096

Cumulative Model Updates: 124,404
Cumulative Timesteps: 1,037,574,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.28230
Policy Entropy: 3.21467
Value Function Loss: 0.00447

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.53094

Collected Steps per Second: 22,617.68808
Overall Steps per Second: 10,543.74246

Timestep Collection Time: 2.21137
Timestep Consumption Time: 2.53230
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.74367

Cumulative Model Updates: 124,410
Cumulative Timesteps: 1,037,624,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1037624672...
Checkpoint 1037624672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.16382
Policy Entropy: 3.22023
Value Function Loss: 0.00428

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.56613

Collected Steps per Second: 22,267.44082
Overall Steps per Second: 10,563.20446

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.73436

Cumulative Model Updates: 124,416
Cumulative Timesteps: 1,037,674,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.22840
Policy Entropy: 3.20494
Value Function Loss: 0.00431

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.58809

Collected Steps per Second: 22,110.50290
Overall Steps per Second: 10,519.67856

Timestep Collection Time: 2.26164
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.75357

Cumulative Model Updates: 124,422
Cumulative Timesteps: 1,037,724,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1037724688...
Checkpoint 1037724688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.16313
Policy Entropy: 3.20760
Value Function Loss: 0.00395

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,317.39811
Overall Steps per Second: 10,590.88432

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.72293

Cumulative Model Updates: 124,428
Cumulative Timesteps: 1,037,774,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.84083
Policy Entropy: 3.20664
Value Function Loss: 0.00396

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.55176

Collected Steps per Second: 22,572.27475
Overall Steps per Second: 10,548.32261

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.74312

Cumulative Model Updates: 124,434
Cumulative Timesteps: 1,037,824,740

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1037824740...
Checkpoint 1037824740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.50766
Policy Entropy: 3.21235
Value Function Loss: 0.00384

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.52942

Collected Steps per Second: 22,226.62885
Overall Steps per Second: 10,549.61463

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.73970

Cumulative Model Updates: 124,440
Cumulative Timesteps: 1,037,874,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.75742
Policy Entropy: 3.21116
Value Function Loss: 0.00387

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 22,792.26785
Overall Steps per Second: 10,533.75755

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.55435
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.74930

Cumulative Model Updates: 124,446
Cumulative Timesteps: 1,037,924,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037924770...
Checkpoint 1037924770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.49364
Policy Entropy: 3.21558
Value Function Loss: 0.00407

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.50420

Collected Steps per Second: 22,157.44582
Overall Steps per Second: 10,562.88854

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.47747
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.73450

Cumulative Model Updates: 124,452
Cumulative Timesteps: 1,037,974,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.33868
Policy Entropy: 3.21614
Value Function Loss: 0.00423

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55759
Value Function Update Magnitude: 0.52415

Collected Steps per Second: 22,645.06947
Overall Steps per Second: 10,531.24357

Timestep Collection Time: 2.20816
Timestep Consumption Time: 2.53999
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.74816

Cumulative Model Updates: 124,458
Cumulative Timesteps: 1,038,024,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1038024784...
Checkpoint 1038024784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.29389
Policy Entropy: 3.22898
Value Function Loss: 0.00415

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.54705

Collected Steps per Second: 22,210.20057
Overall Steps per Second: 10,606.59400

Timestep Collection Time: 2.25131
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.71424

Cumulative Model Updates: 124,464
Cumulative Timesteps: 1,038,074,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.75750
Policy Entropy: 3.23940
Value Function Loss: 0.00374

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.56992

Collected Steps per Second: 22,433.67256
Overall Steps per Second: 10,350.40752

Timestep Collection Time: 2.22888
Timestep Consumption Time: 2.60204
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 4.83092

Cumulative Model Updates: 124,470
Cumulative Timesteps: 1,038,124,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1038124788...
Checkpoint 1038124788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.66713
Policy Entropy: 3.23680
Value Function Loss: 0.00367

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.55567

Collected Steps per Second: 22,114.83426
Overall Steps per Second: 10,295.14823

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.59677
PPO Batch Consumption Time: 0.30731
Total Iteration Time: 4.85860

Cumulative Model Updates: 124,476
Cumulative Timesteps: 1,038,174,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.88254
Policy Entropy: 3.23091
Value Function Loss: 0.00384

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.54114
Value Function Update Magnitude: 0.53225

Collected Steps per Second: 22,405.22476
Overall Steps per Second: 10,468.32645

Timestep Collection Time: 2.23171
Timestep Consumption Time: 2.54479
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.77650

Cumulative Model Updates: 124,482
Cumulative Timesteps: 1,038,224,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1038224810...
Checkpoint 1038224810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.10227
Policy Entropy: 3.21717
Value Function Loss: 0.00400

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.52412

Collected Steps per Second: 22,661.18002
Overall Steps per Second: 10,622.37813

Timestep Collection Time: 2.20730
Timestep Consumption Time: 2.50163
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.70893

Cumulative Model Updates: 124,488
Cumulative Timesteps: 1,038,274,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.88798
Policy Entropy: 3.23163
Value Function Loss: 0.00423

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.52524

Collected Steps per Second: 22,160.15178
Overall Steps per Second: 10,477.45622

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.77349

Cumulative Model Updates: 124,494
Cumulative Timesteps: 1,038,324,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1038324844...
Checkpoint 1038324844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.36110
Policy Entropy: 3.22981
Value Function Loss: 0.00443

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.54600

Collected Steps per Second: 22,053.13360
Overall Steps per Second: 10,574.51712

Timestep Collection Time: 2.26807
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.73005

Cumulative Model Updates: 124,500
Cumulative Timesteps: 1,038,374,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.11013
Policy Entropy: 3.24226
Value Function Loss: 0.00438

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.57431

Collected Steps per Second: 22,483.55143
Overall Steps per Second: 10,484.59364

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.54607
PPO Batch Consumption Time: 0.30181
Total Iteration Time: 4.77081

Cumulative Model Updates: 124,506
Cumulative Timesteps: 1,038,424,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1038424882...
Checkpoint 1038424882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,646.07736
Policy Entropy: 3.23896
Value Function Loss: 0.00418

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.57752

Collected Steps per Second: 21,984.52475
Overall Steps per Second: 10,548.28779

Timestep Collection Time: 2.27460
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.74067

Cumulative Model Updates: 124,512
Cumulative Timesteps: 1,038,474,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.88237
Policy Entropy: 3.22257
Value Function Loss: 0.00405

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.55511

Collected Steps per Second: 22,539.52628
Overall Steps per Second: 10,553.33408

Timestep Collection Time: 2.21957
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.74049

Cumulative Model Updates: 124,518
Cumulative Timesteps: 1,038,524,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1038524916...
Checkpoint 1038524916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.83282
Policy Entropy: 3.21489
Value Function Loss: 0.00410

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 22,166.45325
Overall Steps per Second: 10,622.41864

Timestep Collection Time: 2.25629
Timestep Consumption Time: 2.45205
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.70834

Cumulative Model Updates: 124,524
Cumulative Timesteps: 1,038,574,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.74486
Policy Entropy: 3.21155
Value Function Loss: 0.00398

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.55224

Collected Steps per Second: 22,298.49756
Overall Steps per Second: 10,465.79396

Timestep Collection Time: 2.24275
Timestep Consumption Time: 2.53567
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.77842

Cumulative Model Updates: 124,530
Cumulative Timesteps: 1,038,624,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038624940...
Checkpoint 1038624940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.61613
Policy Entropy: 3.23075
Value Function Loss: 0.00385

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.55205
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 22,315.25076
Overall Steps per Second: 10,583.13201

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.72658

Cumulative Model Updates: 124,536
Cumulative Timesteps: 1,038,674,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.84555
Policy Entropy: 3.23706
Value Function Loss: 0.00384

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 22,459.34647
Overall Steps per Second: 10,524.19339

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.52623
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.75381

Cumulative Model Updates: 124,542
Cumulative Timesteps: 1,038,724,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1038724992...
Checkpoint 1038724992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.86538
Policy Entropy: 3.25082
Value Function Loss: 0.00388

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.50471

Collected Steps per Second: 22,479.55457
Overall Steps per Second: 10,585.66363

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.72375

Cumulative Model Updates: 124,548
Cumulative Timesteps: 1,038,774,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.52361
Policy Entropy: 3.25164
Value Function Loss: 0.00391

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.49787

Collected Steps per Second: 22,070.53765
Overall Steps per Second: 10,391.41912

Timestep Collection Time: 2.26637
Timestep Consumption Time: 2.54722
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.81359

Cumulative Model Updates: 124,554
Cumulative Timesteps: 1,038,825,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1038825016...
Checkpoint 1038825016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.74220
Policy Entropy: 3.24680
Value Function Loss: 0.00372

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.51872

Collected Steps per Second: 22,070.93480
Overall Steps per Second: 10,490.77114

Timestep Collection Time: 2.26569
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.76667

Cumulative Model Updates: 124,560
Cumulative Timesteps: 1,038,875,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.18514
Policy Entropy: 3.23074
Value Function Loss: 0.00378

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.55104

Collected Steps per Second: 22,301.81751
Overall Steps per Second: 10,634.86682

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.70453

Cumulative Model Updates: 124,566
Cumulative Timesteps: 1,038,925,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1038925054...
Checkpoint 1038925054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.17278
Policy Entropy: 3.23390
Value Function Loss: 0.00397

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.56264
Value Function Update Magnitude: 0.57384

Collected Steps per Second: 22,239.29760
Overall Steps per Second: 10,477.61323

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.52431
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.77303

Cumulative Model Updates: 124,572
Cumulative Timesteps: 1,038,975,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.90168
Policy Entropy: 3.23570
Value Function Loss: 0.00413

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.57593

Collected Steps per Second: 22,696.05604
Overall Steps per Second: 10,662.93634

Timestep Collection Time: 2.20373
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.69064

Cumulative Model Updates: 124,578
Cumulative Timesteps: 1,039,025,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1039025080...
Checkpoint 1039025080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.21599
Policy Entropy: 3.23909
Value Function Loss: 0.00460

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.58310

Collected Steps per Second: 21,897.36577
Overall Steps per Second: 10,439.88535

Timestep Collection Time: 2.28448
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.79162

Cumulative Model Updates: 124,584
Cumulative Timesteps: 1,039,075,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.08927
Policy Entropy: 3.21845
Value Function Loss: 0.00478

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.59493
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 22,005.39159
Overall Steps per Second: 10,461.01827

Timestep Collection Time: 2.27235
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.78003

Cumulative Model Updates: 124,590
Cumulative Timesteps: 1,039,125,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1039125108...
Checkpoint 1039125108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.80461
Policy Entropy: 3.23180
Value Function Loss: 0.00440

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.58989
Value Function Update Magnitude: 0.59449

Collected Steps per Second: 22,324.61341
Overall Steps per Second: 10,484.25425

Timestep Collection Time: 2.24067
Timestep Consumption Time: 2.53049
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.77115

Cumulative Model Updates: 124,596
Cumulative Timesteps: 1,039,175,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.21690
Policy Entropy: 3.24165
Value Function Loss: 0.00412

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.57357
Value Function Update Magnitude: 0.57563

Collected Steps per Second: 21,399.89817
Overall Steps per Second: 10,341.58555

Timestep Collection Time: 2.33739
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.83678

Cumulative Model Updates: 124,602
Cumulative Timesteps: 1,039,225,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1039225150...
Checkpoint 1039225150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.86094
Policy Entropy: 3.25831
Value Function Loss: 0.00407

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.56751
Value Function Update Magnitude: 0.55061

Collected Steps per Second: 22,585.73820
Overall Steps per Second: 10,724.36566

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.66265

Cumulative Model Updates: 124,608
Cumulative Timesteps: 1,039,275,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.55570
Policy Entropy: 3.25002
Value Function Loss: 0.00437

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.54885

Collected Steps per Second: 21,959.69124
Overall Steps per Second: 10,466.89308

Timestep Collection Time: 2.27745
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.77811

Cumulative Model Updates: 124,614
Cumulative Timesteps: 1,039,325,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1039325166...
Checkpoint 1039325166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.85214
Policy Entropy: 3.24690
Value Function Loss: 0.00431

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.55820

Collected Steps per Second: 21,060.00599
Overall Steps per Second: 9,913.53014

Timestep Collection Time: 2.37493
Timestep Consumption Time: 2.67030
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 5.04523

Cumulative Model Updates: 124,620
Cumulative Timesteps: 1,039,375,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.92868
Policy Entropy: 3.23702
Value Function Loss: 0.00422

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.55965

Collected Steps per Second: 20,590.25112
Overall Steps per Second: 10,078.86401

Timestep Collection Time: 2.42989
Timestep Consumption Time: 2.53416
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.96405

Cumulative Model Updates: 124,626
Cumulative Timesteps: 1,039,425,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1039425214...
Checkpoint 1039425214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.86259
Policy Entropy: 3.24180
Value Function Loss: 0.00426

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.57204
Value Function Update Magnitude: 0.57642

Collected Steps per Second: 20,981.15076
Overall Steps per Second: 10,297.83804

Timestep Collection Time: 2.38509
Timestep Consumption Time: 2.47437
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.85947

Cumulative Model Updates: 124,632
Cumulative Timesteps: 1,039,475,256

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.11334
Policy Entropy: 3.23570
Value Function Loss: 0.00478

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.60532

Collected Steps per Second: 21,528.25556
Overall Steps per Second: 10,465.94009

Timestep Collection Time: 2.32253
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.77740

Cumulative Model Updates: 124,638
Cumulative Timesteps: 1,039,525,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1039525256...
Checkpoint 1039525256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.74256
Policy Entropy: 3.25459
Value Function Loss: 0.00467

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.58820
Value Function Update Magnitude: 0.62461

Collected Steps per Second: 19,233.90335
Overall Steps per Second: 9,301.60245

Timestep Collection Time: 2.60041
Timestep Consumption Time: 2.77673
PPO Batch Consumption Time: 0.32821
Total Iteration Time: 5.37714

Cumulative Model Updates: 124,644
Cumulative Timesteps: 1,039,575,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.72644
Policy Entropy: 3.25535
Value Function Loss: 0.00435

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.57522
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 19,340.51108
Overall Steps per Second: 9,689.05764

Timestep Collection Time: 2.58535
Timestep Consumption Time: 2.57532
PPO Batch Consumption Time: 0.30677
Total Iteration Time: 5.16067

Cumulative Model Updates: 124,650
Cumulative Timesteps: 1,039,625,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1039625274...
Checkpoint 1039625274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.93029
Policy Entropy: 3.27001
Value Function Loss: 0.00404

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.55238
Value Function Update Magnitude: 0.56121

Collected Steps per Second: 21,323.21611
Overall Steps per Second: 10,010.61208

Timestep Collection Time: 2.34552
Timestep Consumption Time: 2.65058
PPO Batch Consumption Time: 0.30451
Total Iteration Time: 4.99610

Cumulative Model Updates: 124,656
Cumulative Timesteps: 1,039,675,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.10288
Policy Entropy: 3.26013
Value Function Loss: 0.00383

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.56378

Collected Steps per Second: 21,208.33966
Overall Steps per Second: 10,032.78328

Timestep Collection Time: 2.35954
Timestep Consumption Time: 2.62830
PPO Batch Consumption Time: 0.30431
Total Iteration Time: 4.98785

Cumulative Model Updates: 124,662
Cumulative Timesteps: 1,039,725,330

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1039725330...
Checkpoint 1039725330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.89656
Policy Entropy: 3.25279
Value Function Loss: 0.00379

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.56518

Collected Steps per Second: 21,190.90675
Overall Steps per Second: 10,201.39503

Timestep Collection Time: 2.35960
Timestep Consumption Time: 2.54189
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.90149

Cumulative Model Updates: 124,668
Cumulative Timesteps: 1,039,775,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.04570
Policy Entropy: 3.25026
Value Function Loss: 0.00397

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 18,355.82800
Overall Steps per Second: 9,500.98043

Timestep Collection Time: 2.72448
Timestep Consumption Time: 2.53919
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 5.26367

Cumulative Model Updates: 124,674
Cumulative Timesteps: 1,039,825,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1039825342...
Checkpoint 1039825342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.90557
Policy Entropy: 3.25312
Value Function Loss: 0.00402

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.55479

Collected Steps per Second: 21,440.19323
Overall Steps per Second: 10,407.08663

Timestep Collection Time: 2.33226
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.80480

Cumulative Model Updates: 124,680
Cumulative Timesteps: 1,039,875,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.00189
Policy Entropy: 3.26230
Value Function Loss: 0.00420

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.53851

Collected Steps per Second: 22,409.90453
Overall Steps per Second: 10,523.51610

Timestep Collection Time: 2.23151
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.75202

Cumulative Model Updates: 124,686
Cumulative Timesteps: 1,039,925,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1039925354...
Checkpoint 1039925354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.24046
Policy Entropy: 3.26272
Value Function Loss: 0.00389

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 21,752.00978
Overall Steps per Second: 10,461.43694

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.78252

Cumulative Model Updates: 124,692
Cumulative Timesteps: 1,039,975,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.94492
Policy Entropy: 3.24672
Value Function Loss: 0.00407

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.54481

Collected Steps per Second: 22,554.69249
Overall Steps per Second: 10,673.99485

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.46853
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.68634

Cumulative Model Updates: 124,698
Cumulative Timesteps: 1,040,025,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1040025408...
Checkpoint 1040025408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.01706
Policy Entropy: 3.23594
Value Function Loss: 0.00393

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.55732

Collected Steps per Second: 21,044.52168
Overall Steps per Second: 10,102.05845

Timestep Collection Time: 2.37734
Timestep Consumption Time: 2.57512
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.95246

Cumulative Model Updates: 124,704
Cumulative Timesteps: 1,040,075,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.75787
Policy Entropy: 3.23653
Value Function Loss: 0.00385

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.56103

Collected Steps per Second: 19,752.89688
Overall Steps per Second: 9,790.72022

Timestep Collection Time: 2.53249
Timestep Consumption Time: 2.57684
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 5.10933

Cumulative Model Updates: 124,710
Cumulative Timesteps: 1,040,125,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1040125462...
Checkpoint 1040125462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.42865
Policy Entropy: 3.24401
Value Function Loss: 0.00371

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.53908

Collected Steps per Second: 20,922.78315
Overall Steps per Second: 10,082.38713

Timestep Collection Time: 2.39098
Timestep Consumption Time: 2.57074
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.96172

Cumulative Model Updates: 124,716
Cumulative Timesteps: 1,040,175,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.30419
Policy Entropy: 3.25763
Value Function Loss: 0.00369

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.50342

Collected Steps per Second: 22,015.78123
Overall Steps per Second: 10,626.56086

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.70670

Cumulative Model Updates: 124,722
Cumulative Timesteps: 1,040,225,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1040225504...
Checkpoint 1040225504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,880.01843
Policy Entropy: 3.25015
Value Function Loss: 0.00406

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.51133

Collected Steps per Second: 22,010.52978
Overall Steps per Second: 10,572.17914

Timestep Collection Time: 2.27219
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.73053

Cumulative Model Updates: 124,728
Cumulative Timesteps: 1,040,275,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.07890
Policy Entropy: 3.24512
Value Function Loss: 0.00437

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56207
Value Function Update Magnitude: 0.53039

Collected Steps per Second: 22,860.69982
Overall Steps per Second: 10,781.66814

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.63806

Cumulative Model Updates: 124,734
Cumulative Timesteps: 1,040,325,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1040325522...
Checkpoint 1040325522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.42916
Policy Entropy: 3.22924
Value Function Loss: 0.00447

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.57521
Value Function Update Magnitude: 0.54164

Collected Steps per Second: 21,912.86228
Overall Steps per Second: 10,421.86392

Timestep Collection Time: 2.28176
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.79761

Cumulative Model Updates: 124,740
Cumulative Timesteps: 1,040,375,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.07296
Policy Entropy: 3.22358
Value Function Loss: 0.00405

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.52886

Collected Steps per Second: 22,758.70642
Overall Steps per Second: 10,444.10223

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.59053
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.78758

Cumulative Model Updates: 124,746
Cumulative Timesteps: 1,040,425,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1040425524...
Checkpoint 1040425524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.77634
Policy Entropy: 3.23469
Value Function Loss: 0.00397

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.50866

Collected Steps per Second: 21,002.52736
Overall Steps per Second: 10,003.29943

Timestep Collection Time: 2.38114
Timestep Consumption Time: 2.61821
PPO Batch Consumption Time: 0.31313
Total Iteration Time: 4.99935

Cumulative Model Updates: 124,752
Cumulative Timesteps: 1,040,475,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.46563
Policy Entropy: 3.24333
Value Function Loss: 0.00380

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.51024

Collected Steps per Second: 21,840.28738
Overall Steps per Second: 10,418.06885

Timestep Collection Time: 2.29063
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.80204

Cumulative Model Updates: 124,758
Cumulative Timesteps: 1,040,525,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040525562...
Checkpoint 1040525562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.23826
Policy Entropy: 3.24281
Value Function Loss: 0.00418

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.50979

Collected Steps per Second: 21,161.38043
Overall Steps per Second: 10,371.52708

Timestep Collection Time: 2.36346
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.82224

Cumulative Model Updates: 124,764
Cumulative Timesteps: 1,040,575,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.88970
Policy Entropy: 3.24539
Value Function Loss: 0.00434

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.52180

Collected Steps per Second: 22,160.10334
Overall Steps per Second: 10,266.28036

Timestep Collection Time: 2.25757
Timestep Consumption Time: 2.61547
PPO Batch Consumption Time: 0.31140
Total Iteration Time: 4.87304

Cumulative Model Updates: 124,770
Cumulative Timesteps: 1,040,625,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1040625604...
Checkpoint 1040625604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.27425
Policy Entropy: 3.23385
Value Function Loss: 0.00427

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.53159

Collected Steps per Second: 21,153.89893
Overall Steps per Second: 10,125.87412

Timestep Collection Time: 2.36495
Timestep Consumption Time: 2.57566
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.94061

Cumulative Model Updates: 124,776
Cumulative Timesteps: 1,040,675,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.94303
Policy Entropy: 3.24381
Value Function Loss: 0.00424

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.54160

Collected Steps per Second: 19,626.36068
Overall Steps per Second: 9,802.72914

Timestep Collection Time: 2.54851
Timestep Consumption Time: 2.55395
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 5.10246

Cumulative Model Updates: 124,782
Cumulative Timesteps: 1,040,725,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1040725650...
Checkpoint 1040725650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.47783
Policy Entropy: 3.24283
Value Function Loss: 0.00407

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.53444

Collected Steps per Second: 20,363.39621
Overall Steps per Second: 9,879.76953

Timestep Collection Time: 2.45539
Timestep Consumption Time: 2.60546
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 5.06085

Cumulative Model Updates: 124,788
Cumulative Timesteps: 1,040,775,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.42538
Policy Entropy: 3.26354
Value Function Loss: 0.00389

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.51745

Collected Steps per Second: 18,032.29056
Overall Steps per Second: 9,229.91408

Timestep Collection Time: 2.77380
Timestep Consumption Time: 2.64532
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 5.41912

Cumulative Model Updates: 124,794
Cumulative Timesteps: 1,040,825,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1040825668...
Checkpoint 1040825668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.80110
Policy Entropy: 3.27138
Value Function Loss: 0.00380

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.49100

Collected Steps per Second: 20,519.12635
Overall Steps per Second: 10,238.57405

Timestep Collection Time: 2.43714
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.88427

Cumulative Model Updates: 124,800
Cumulative Timesteps: 1,040,875,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.28335
Policy Entropy: 3.26096
Value Function Loss: 0.00424

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.47717

Collected Steps per Second: 22,193.86039
Overall Steps per Second: 10,480.82706

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.77310

Cumulative Model Updates: 124,806
Cumulative Timesteps: 1,040,925,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1040925702...
Checkpoint 1040925702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.29722
Policy Entropy: 3.25937
Value Function Loss: 0.00438

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.50279

Collected Steps per Second: 22,187.42352
Overall Steps per Second: 10,636.18984

Timestep Collection Time: 2.25398
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.70187

Cumulative Model Updates: 124,812
Cumulative Timesteps: 1,040,975,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.62719
Policy Entropy: 3.25463
Value Function Loss: 0.00417

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.51195

Collected Steps per Second: 21,862.19272
Overall Steps per Second: 10,532.97884

Timestep Collection Time: 2.28705
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.74700

Cumulative Model Updates: 124,818
Cumulative Timesteps: 1,041,025,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041025712...
Checkpoint 1041025712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.05926
Policy Entropy: 3.25114
Value Function Loss: 0.00404

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.56888
Value Function Update Magnitude: 0.50359

Collected Steps per Second: 22,361.53591
Overall Steps per Second: 10,509.34944

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.52280
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.75976

Cumulative Model Updates: 124,824
Cumulative Timesteps: 1,041,075,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.79002
Policy Entropy: 3.24530
Value Function Loss: 0.00396

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.51202

Collected Steps per Second: 22,342.24841
Overall Steps per Second: 10,534.81432

Timestep Collection Time: 2.23881
Timestep Consumption Time: 2.50926
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.74807

Cumulative Model Updates: 124,830
Cumulative Timesteps: 1,041,125,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1041125754...
Checkpoint 1041125754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.80095
Policy Entropy: 3.25833
Value Function Loss: 0.00422

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.52398

Collected Steps per Second: 22,265.04971
Overall Steps per Second: 10,594.09449

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.72131

Cumulative Model Updates: 124,836
Cumulative Timesteps: 1,041,175,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.84253
Policy Entropy: 3.25888
Value Function Loss: 0.00414

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.58297
Value Function Update Magnitude: 0.54151

Collected Steps per Second: 22,425.11039
Overall Steps per Second: 10,569.02202

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.73383

Cumulative Model Updates: 124,842
Cumulative Timesteps: 1,041,225,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1041225804...
Checkpoint 1041225804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.76403
Policy Entropy: 3.26369
Value Function Loss: 0.00442

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.54672

Collected Steps per Second: 22,290.80749
Overall Steps per Second: 10,631.19059

Timestep Collection Time: 2.24344
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.70389

Cumulative Model Updates: 124,848
Cumulative Timesteps: 1,041,275,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.86684
Policy Entropy: 3.26715
Value Function Loss: 0.00407

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.54538

Collected Steps per Second: 22,618.38716
Overall Steps per Second: 10,525.42868

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.54083
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.75230

Cumulative Model Updates: 124,854
Cumulative Timesteps: 1,041,325,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1041325832...
Checkpoint 1041325832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.24215
Policy Entropy: 3.26390
Value Function Loss: 0.00423

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.53189

Collected Steps per Second: 22,356.16276
Overall Steps per Second: 10,521.65439

Timestep Collection Time: 2.23759
Timestep Consumption Time: 2.51679
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.75439

Cumulative Model Updates: 124,860
Cumulative Timesteps: 1,041,375,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.76702
Policy Entropy: 3.23692
Value Function Loss: 0.00385

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.55945
Value Function Update Magnitude: 0.52672

Collected Steps per Second: 22,288.32872
Overall Steps per Second: 10,461.61182

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.53707
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.78129

Cumulative Model Updates: 124,866
Cumulative Timesteps: 1,041,425,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1041425876...
Checkpoint 1041425876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.64071
Policy Entropy: 3.23418
Value Function Loss: 0.00376

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.55811
Value Function Update Magnitude: 0.51842

Collected Steps per Second: 21,998.16037
Overall Steps per Second: 10,606.16794

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.71612

Cumulative Model Updates: 124,872
Cumulative Timesteps: 1,041,475,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.34004
Policy Entropy: 3.22302
Value Function Loss: 0.00396

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.51989

Collected Steps per Second: 22,177.87554
Overall Steps per Second: 10,499.06164

Timestep Collection Time: 2.25531
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.76404

Cumulative Model Updates: 124,878
Cumulative Timesteps: 1,041,525,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1041525914...
Checkpoint 1041525914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.89793
Policy Entropy: 3.23349
Value Function Loss: 0.00407

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.57048
Value Function Update Magnitude: 0.52618

Collected Steps per Second: 22,743.42909
Overall Steps per Second: 10,641.96118

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.70101

Cumulative Model Updates: 124,884
Cumulative Timesteps: 1,041,575,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.41661
Policy Entropy: 3.23146
Value Function Loss: 0.00404

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.52201

Collected Steps per Second: 22,078.49124
Overall Steps per Second: 10,502.24597

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.76089

Cumulative Model Updates: 124,890
Cumulative Timesteps: 1,041,625,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041625942...
Checkpoint 1041625942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.18311
Policy Entropy: 3.23251
Value Function Loss: 0.00387

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.52500

Collected Steps per Second: 22,296.36317
Overall Steps per Second: 10,634.75472

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.70401

Cumulative Model Updates: 124,896
Cumulative Timesteps: 1,041,675,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.53099
Policy Entropy: 3.24773
Value Function Loss: 0.00364

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.54511
Value Function Update Magnitude: 0.52539

Collected Steps per Second: 22,287.46552
Overall Steps per Second: 10,392.89672

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.56798
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.81175

Cumulative Model Updates: 124,902
Cumulative Timesteps: 1,041,725,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1041725976...
Checkpoint 1041725976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.56785
Policy Entropy: 3.23781
Value Function Loss: 0.00384

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.51954

Collected Steps per Second: 22,201.78237
Overall Steps per Second: 10,437.30706

Timestep Collection Time: 2.25333
Timestep Consumption Time: 2.53986
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.79319

Cumulative Model Updates: 124,908
Cumulative Timesteps: 1,041,776,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.46572
Policy Entropy: 3.25537
Value Function Loss: 0.00384

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.51866

Collected Steps per Second: 22,483.84398
Overall Steps per Second: 10,665.67588

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68962

Cumulative Model Updates: 124,914
Cumulative Timesteps: 1,041,826,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1041826022...
Checkpoint 1041826022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.19150
Policy Entropy: 3.25568
Value Function Loss: 0.00406

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.51519

Collected Steps per Second: 22,430.71346
Overall Steps per Second: 10,700.12680

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.44503
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.67527

Cumulative Model Updates: 124,920
Cumulative Timesteps: 1,041,876,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.05853
Policy Entropy: 3.26311
Value Function Loss: 0.00378

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.53339
Value Function Update Magnitude: 0.50015

Collected Steps per Second: 22,601.17397
Overall Steps per Second: 10,573.72377

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.73003

Cumulative Model Updates: 124,926
Cumulative Timesteps: 1,041,926,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1041926062...
Checkpoint 1041926062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.67423
Policy Entropy: 3.26743
Value Function Loss: 0.00377

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.52969
Value Function Update Magnitude: 0.47779

Collected Steps per Second: 22,633.37151
Overall Steps per Second: 10,633.37342

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.70406

Cumulative Model Updates: 124,932
Cumulative Timesteps: 1,041,976,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.95224
Policy Entropy: 3.25658
Value Function Loss: 0.00388

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.50003

Collected Steps per Second: 21,706.49720
Overall Steps per Second: 10,308.09017

Timestep Collection Time: 2.30493
Timestep Consumption Time: 2.54873
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.85366

Cumulative Model Updates: 124,938
Cumulative Timesteps: 1,042,026,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1042026114...
Checkpoint 1042026114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.20402
Policy Entropy: 3.24903
Value Function Loss: 0.00398

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.54913

Collected Steps per Second: 22,547.97937
Overall Steps per Second: 10,648.57454

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.47876
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69697

Cumulative Model Updates: 124,944
Cumulative Timesteps: 1,042,076,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.99244
Policy Entropy: 3.25189
Value Function Loss: 0.00358

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.54948

Collected Steps per Second: 22,230.92606
Overall Steps per Second: 10,450.69980

Timestep Collection Time: 2.24984
Timestep Consumption Time: 2.53606
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.78590

Cumulative Model Updates: 124,950
Cumulative Timesteps: 1,042,126,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1042126146...
Checkpoint 1042126146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.73272
Policy Entropy: 3.24971
Value Function Loss: 0.00378

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.52607

Collected Steps per Second: 22,539.60789
Overall Steps per Second: 10,679.61037

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.68350

Cumulative Model Updates: 124,956
Cumulative Timesteps: 1,042,176,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.76519
Policy Entropy: 3.25886
Value Function Loss: 0.00373

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.53563

Collected Steps per Second: 22,106.73097
Overall Steps per Second: 10,462.10686

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.78030

Cumulative Model Updates: 124,962
Cumulative Timesteps: 1,042,226,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1042226176...
Checkpoint 1042226176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.94056
Policy Entropy: 3.25614
Value Function Loss: 0.00403

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.52920

Collected Steps per Second: 22,026.10959
Overall Steps per Second: 10,548.06481

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.74040

Cumulative Model Updates: 124,968
Cumulative Timesteps: 1,042,276,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.95894
Policy Entropy: 3.25347
Value Function Loss: 0.00424

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 22,436.11639
Overall Steps per Second: 10,533.63252

Timestep Collection Time: 2.22944
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.74860

Cumulative Model Updates: 124,974
Cumulative Timesteps: 1,042,326,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1042326198...
Checkpoint 1042326198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.58754
Policy Entropy: 3.25777
Value Function Loss: 0.00419

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.51532

Collected Steps per Second: 22,512.87829
Overall Steps per Second: 10,650.11228

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.69666

Cumulative Model Updates: 124,980
Cumulative Timesteps: 1,042,376,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.53621
Policy Entropy: 3.25473
Value Function Loss: 0.00407

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.52749
Value Function Update Magnitude: 0.50154

Collected Steps per Second: 22,091.50522
Overall Steps per Second: 10,322.36508

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.58178
PPO Batch Consumption Time: 0.30557
Total Iteration Time: 4.84618

Cumulative Model Updates: 124,986
Cumulative Timesteps: 1,042,426,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1042426242...
Checkpoint 1042426242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.99694
Policy Entropy: 3.25790
Value Function Loss: 0.00367

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.51636

Collected Steps per Second: 22,311.08181
Overall Steps per Second: 10,595.94318

Timestep Collection Time: 2.24104
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71879

Cumulative Model Updates: 124,992
Cumulative Timesteps: 1,042,476,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.77461
Policy Entropy: 3.25523
Value Function Loss: 0.00368

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.51718

Collected Steps per Second: 22,775.68763
Overall Steps per Second: 10,623.70226

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70646

Cumulative Model Updates: 124,998
Cumulative Timesteps: 1,042,526,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1042526242...
Checkpoint 1042526242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.48703
Policy Entropy: 3.25643
Value Function Loss: 0.00383

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.53591

Collected Steps per Second: 22,365.74382
Overall Steps per Second: 10,691.21220

Timestep Collection Time: 2.23601
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.67767

Cumulative Model Updates: 125,004
Cumulative Timesteps: 1,042,576,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.27181
Policy Entropy: 3.24633
Value Function Loss: 0.00403

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.54111
Value Function Update Magnitude: 0.54631

Collected Steps per Second: 22,391.44622
Overall Steps per Second: 10,502.59663

Timestep Collection Time: 2.23317
Timestep Consumption Time: 2.52793
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.76111

Cumulative Model Updates: 125,010
Cumulative Timesteps: 1,042,626,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1042626256...
Checkpoint 1042626256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.80716
Policy Entropy: 3.25176
Value Function Loss: 0.00446

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.55740
Value Function Update Magnitude: 0.56847

Collected Steps per Second: 22,570.62708
Overall Steps per Second: 10,551.35136

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.52407
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.73987

Cumulative Model Updates: 125,016
Cumulative Timesteps: 1,042,676,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.63677
Policy Entropy: 3.24883
Value Function Loss: 0.00459

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 22,663.97880
Overall Steps per Second: 10,557.78822

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.53000
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.73641

Cumulative Model Updates: 125,022
Cumulative Timesteps: 1,042,726,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1042726274...
Checkpoint 1042726274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.77110
Policy Entropy: 3.23718
Value Function Loss: 0.00447

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.58437
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 22,605.74578
Overall Steps per Second: 10,527.69941

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.75185

Cumulative Model Updates: 125,028
Cumulative Timesteps: 1,042,776,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.59085
Policy Entropy: 3.24275
Value Function Loss: 0.00406

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.56345
Value Function Update Magnitude: 0.54828

Collected Steps per Second: 22,258.41341
Overall Steps per Second: 10,486.24135

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.52181
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.76815

Cumulative Model Updates: 125,034
Cumulative Timesteps: 1,042,826,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1042826300...
Checkpoint 1042826300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.22209
Policy Entropy: 3.24530
Value Function Loss: 0.00397

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.56577
Value Function Update Magnitude: 0.55929

Collected Steps per Second: 22,294.51895
Overall Steps per Second: 10,592.68111

Timestep Collection Time: 2.24387
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72269

Cumulative Model Updates: 125,040
Cumulative Timesteps: 1,042,876,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.86700
Policy Entropy: 3.25369
Value Function Loss: 0.00378

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.56203

Collected Steps per Second: 21,401.25518
Overall Steps per Second: 10,188.62749

Timestep Collection Time: 2.33762
Timestep Consumption Time: 2.57256
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.91018

Cumulative Model Updates: 125,046
Cumulative Timesteps: 1,042,926,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1042926354...
Checkpoint 1042926354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.00510
Policy Entropy: 3.24599
Value Function Loss: 0.00398

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.56824
Value Function Update Magnitude: 0.56225

Collected Steps per Second: 21,360.93289
Overall Steps per Second: 10,038.67835

Timestep Collection Time: 2.34156
Timestep Consumption Time: 2.64096
PPO Batch Consumption Time: 0.31011
Total Iteration Time: 4.98253

Cumulative Model Updates: 125,052
Cumulative Timesteps: 1,042,976,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.43457
Policy Entropy: 3.25072
Value Function Loss: 0.00383

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.57384

Collected Steps per Second: 18,997.32924
Overall Steps per Second: 9,648.29114

Timestep Collection Time: 2.63248
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 5.18330

Cumulative Model Updates: 125,058
Cumulative Timesteps: 1,043,026,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1043026382...
Checkpoint 1043026382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.65888
Policy Entropy: 3.24082
Value Function Loss: 0.00460

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.57219

Collected Steps per Second: 20,868.67530
Overall Steps per Second: 10,120.48150

Timestep Collection Time: 2.39594
Timestep Consumption Time: 2.54454
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.94048

Cumulative Model Updates: 125,064
Cumulative Timesteps: 1,043,076,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.97897
Policy Entropy: 3.23849
Value Function Loss: 0.00438

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.54008

Collected Steps per Second: 22,312.29892
Overall Steps per Second: 10,332.67118

Timestep Collection Time: 2.24128
Timestep Consumption Time: 2.59852
PPO Batch Consumption Time: 0.30459
Total Iteration Time: 4.83979

Cumulative Model Updates: 125,070
Cumulative Timesteps: 1,043,126,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1043126390...
Checkpoint 1043126390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.46695
Policy Entropy: 3.22689
Value Function Loss: 0.00458

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.57421
Value Function Update Magnitude: 0.51377

Collected Steps per Second: 21,685.14443
Overall Steps per Second: 10,486.24428

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.76987

Cumulative Model Updates: 125,076
Cumulative Timesteps: 1,043,176,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.46105
Policy Entropy: 3.24206
Value Function Loss: 0.00399

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.52431

Collected Steps per Second: 21,380.54497
Overall Steps per Second: 10,128.72358

Timestep Collection Time: 2.33895
Timestep Consumption Time: 2.59830
PPO Batch Consumption Time: 0.30642
Total Iteration Time: 4.93725

Cumulative Model Updates: 125,082
Cumulative Timesteps: 1,043,226,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1043226416...
Checkpoint 1043226416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,107.06392
Policy Entropy: 3.25145
Value Function Loss: 0.00385

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.52608

Collected Steps per Second: 17,592.46232
Overall Steps per Second: 9,371.59756

Timestep Collection Time: 2.84372
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 5.33826

Cumulative Model Updates: 125,088
Cumulative Timesteps: 1,043,276,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.54378
Policy Entropy: 3.24928
Value Function Loss: 0.00401

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.53078

Collected Steps per Second: 21,569.26051
Overall Steps per Second: 10,403.16518

Timestep Collection Time: 2.31895
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.80796

Cumulative Model Updates: 125,094
Cumulative Timesteps: 1,043,326,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1043326462...
Checkpoint 1043326462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.15936
Policy Entropy: 3.25349
Value Function Loss: 0.00410

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.57782
Value Function Update Magnitude: 0.54739

Collected Steps per Second: 21,585.75893
Overall Steps per Second: 10,255.41732

Timestep Collection Time: 2.31634
Timestep Consumption Time: 2.55913
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.87547

Cumulative Model Updates: 125,100
Cumulative Timesteps: 1,043,376,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.94971
Policy Entropy: 3.26461
Value Function Loss: 0.00394

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.56510
Value Function Update Magnitude: 0.55909

Collected Steps per Second: 22,631.30555
Overall Steps per Second: 10,567.22991

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.52309
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.73312

Cumulative Model Updates: 125,106
Cumulative Timesteps: 1,043,426,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1043426478...
Checkpoint 1043426478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.77559
Policy Entropy: 3.27417
Value Function Loss: 0.00387

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.53518

Collected Steps per Second: 22,526.98190
Overall Steps per Second: 10,560.44776

Timestep Collection Time: 2.21974
Timestep Consumption Time: 2.51529
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.73503

Cumulative Model Updates: 125,112
Cumulative Timesteps: 1,043,476,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.91809
Policy Entropy: 3.28928
Value Function Loss: 0.00390

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.54700
Value Function Update Magnitude: 0.53092

Collected Steps per Second: 22,810.79757
Overall Steps per Second: 10,720.95231

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.66376

Cumulative Model Updates: 125,118
Cumulative Timesteps: 1,043,526,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1043526482...
Checkpoint 1043526482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.56621
Policy Entropy: 3.28056
Value Function Loss: 0.00410

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.54772

Collected Steps per Second: 22,112.86912
Overall Steps per Second: 10,462.89468

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.51777
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.77898

Cumulative Model Updates: 125,124
Cumulative Timesteps: 1,043,576,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.60886
Policy Entropy: 3.28139
Value Function Loss: 0.00440

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.57805
Value Function Update Magnitude: 0.55791

Collected Steps per Second: 22,698.70788
Overall Steps per Second: 10,701.21413

Timestep Collection Time: 2.20312
Timestep Consumption Time: 2.46999
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.67311

Cumulative Model Updates: 125,130
Cumulative Timesteps: 1,043,626,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1043626492...
Checkpoint 1043626492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.57163
Policy Entropy: 3.27882
Value Function Loss: 0.00405

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.56451

Collected Steps per Second: 22,139.24065
Overall Steps per Second: 10,528.47217

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.75017

Cumulative Model Updates: 125,136
Cumulative Timesteps: 1,043,676,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.18567
Policy Entropy: 3.28276
Value Function Loss: 0.00392

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 22,499.97492
Overall Steps per Second: 10,556.75674

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.51498
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.73801

Cumulative Model Updates: 125,142
Cumulative Timesteps: 1,043,726,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1043726522...
Checkpoint 1043726522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.78882
Policy Entropy: 3.28064
Value Function Loss: 0.00380

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.52160

Collected Steps per Second: 22,125.88140
Overall Steps per Second: 10,505.33607

Timestep Collection Time: 2.26070
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.76139

Cumulative Model Updates: 125,148
Cumulative Timesteps: 1,043,776,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.90896
Policy Entropy: 3.27597
Value Function Loss: 0.00370

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.54432
Value Function Update Magnitude: 0.50591

Collected Steps per Second: 22,659.74023
Overall Steps per Second: 10,712.87585

Timestep Collection Time: 2.20779
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.66989

Cumulative Model Updates: 125,154
Cumulative Timesteps: 1,043,826,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1043826570...
Checkpoint 1043826570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.54709
Policy Entropy: 3.27639
Value Function Loss: 0.00360

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.54454
Value Function Update Magnitude: 0.48991

Collected Steps per Second: 22,279.42986
Overall Steps per Second: 10,525.04193

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.75057

Cumulative Model Updates: 125,160
Cumulative Timesteps: 1,043,876,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.53596
Policy Entropy: 3.27123
Value Function Loss: 0.00383

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.47882

Collected Steps per Second: 20,850.64563
Overall Steps per Second: 10,071.43342

Timestep Collection Time: 2.39810
Timestep Consumption Time: 2.56663
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.96474

Cumulative Model Updates: 125,166
Cumulative Timesteps: 1,043,926,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1043926572...
Checkpoint 1043926572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.15267
Policy Entropy: 3.27276
Value Function Loss: 0.00394

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.54950
Value Function Update Magnitude: 0.49678

Collected Steps per Second: 22,001.47453
Overall Steps per Second: 10,602.74654

Timestep Collection Time: 2.27394
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.71859

Cumulative Model Updates: 125,172
Cumulative Timesteps: 1,043,976,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.75565
Policy Entropy: 3.26451
Value Function Loss: 0.00418

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.51591

Collected Steps per Second: 22,680.33937
Overall Steps per Second: 10,555.67435

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.73944

Cumulative Model Updates: 125,178
Cumulative Timesteps: 1,044,026,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1044026630...
Checkpoint 1044026630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.38203
Policy Entropy: 3.26209
Value Function Loss: 0.00401

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.53280

Collected Steps per Second: 21,940.10562
Overall Steps per Second: 10,596.53625

Timestep Collection Time: 2.27893
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.71852

Cumulative Model Updates: 125,184
Cumulative Timesteps: 1,044,076,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.15256
Policy Entropy: 3.26417
Value Function Loss: 0.00407

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.53213

Collected Steps per Second: 22,510.49474
Overall Steps per Second: 10,498.12017

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.54310
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.76562

Cumulative Model Updates: 125,190
Cumulative Timesteps: 1,044,126,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1044126660...
Checkpoint 1044126660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.74128
Policy Entropy: 3.27314
Value Function Loss: 0.00389

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.51973

Collected Steps per Second: 22,212.27254
Overall Steps per Second: 10,538.25848

Timestep Collection Time: 2.25200
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.74670

Cumulative Model Updates: 125,196
Cumulative Timesteps: 1,044,176,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.42880
Policy Entropy: 3.26665
Value Function Loss: 0.00384

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.50105

Collected Steps per Second: 22,339.96875
Overall Steps per Second: 10,598.07345

Timestep Collection Time: 2.23814
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.71784

Cumulative Model Updates: 125,202
Cumulative Timesteps: 1,044,226,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1044226682...
Checkpoint 1044226682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.98540
Policy Entropy: 3.26939
Value Function Loss: 0.00384

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.51952

Collected Steps per Second: 22,102.00495
Overall Steps per Second: 10,557.91510

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.73768

Cumulative Model Updates: 125,208
Cumulative Timesteps: 1,044,276,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,334.56328
Policy Entropy: 3.25656
Value Function Loss: 0.00365

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.51781

Collected Steps per Second: 22,400.64065
Overall Steps per Second: 10,470.62033

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.54451
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.77775

Cumulative Model Updates: 125,214
Cumulative Timesteps: 1,044,326,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1044326728...
Checkpoint 1044326728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.21629
Policy Entropy: 3.25258
Value Function Loss: 0.00378

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.55420
Value Function Update Magnitude: 0.50295

Collected Steps per Second: 21,826.84360
Overall Steps per Second: 10,274.38129

Timestep Collection Time: 2.29094
Timestep Consumption Time: 2.57592
PPO Batch Consumption Time: 0.30625
Total Iteration Time: 4.86686

Cumulative Model Updates: 125,220
Cumulative Timesteps: 1,044,376,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.15216
Policy Entropy: 3.26075
Value Function Loss: 0.00406

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.49751

Collected Steps per Second: 22,603.51298
Overall Steps per Second: 10,522.52079

Timestep Collection Time: 2.21320
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.75418

Cumulative Model Updates: 125,226
Cumulative Timesteps: 1,044,426,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1044426758...
Checkpoint 1044426758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.55983
Policy Entropy: 3.25688
Value Function Loss: 0.00438

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.56622
Value Function Update Magnitude: 0.50392

Collected Steps per Second: 22,487.47851
Overall Steps per Second: 10,567.34581

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.73402

Cumulative Model Updates: 125,232
Cumulative Timesteps: 1,044,476,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.23213
Policy Entropy: 3.26259
Value Function Loss: 0.00414

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.56975
Value Function Update Magnitude: 0.51615

Collected Steps per Second: 22,432.77020
Overall Steps per Second: 10,474.25850

Timestep Collection Time: 2.22968
Timestep Consumption Time: 2.54564
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.77533

Cumulative Model Updates: 125,238
Cumulative Timesteps: 1,044,526,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1044526802...
Checkpoint 1044526802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.93053
Policy Entropy: 3.25784
Value Function Loss: 0.00399

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.52888

Collected Steps per Second: 22,137.36126
Overall Steps per Second: 10,671.80079

Timestep Collection Time: 2.25881
Timestep Consumption Time: 2.42681
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.68562

Cumulative Model Updates: 125,244
Cumulative Timesteps: 1,044,576,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.50133
Policy Entropy: 3.26214
Value Function Loss: 0.00395

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.56440
Value Function Update Magnitude: 0.52506

Collected Steps per Second: 22,340.90901
Overall Steps per Second: 10,477.00954

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.53522
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.77407

Cumulative Model Updates: 125,250
Cumulative Timesteps: 1,044,626,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1044626824...
Checkpoint 1044626824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.24494
Policy Entropy: 3.27015
Value Function Loss: 0.00382

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.51211

Collected Steps per Second: 22,587.61063
Overall Steps per Second: 10,550.16802

Timestep Collection Time: 2.21484
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.74192

Cumulative Model Updates: 125,256
Cumulative Timesteps: 1,044,676,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.17996
Policy Entropy: 3.26919
Value Function Loss: 0.00391

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.49492

Collected Steps per Second: 22,487.06710
Overall Steps per Second: 10,511.54718

Timestep Collection Time: 2.22377
Timestep Consumption Time: 2.53348
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.75724

Cumulative Model Updates: 125,262
Cumulative Timesteps: 1,044,726,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1044726858...
Checkpoint 1044726858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.92630
Policy Entropy: 3.27642
Value Function Loss: 0.00411

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.48738

Collected Steps per Second: 22,417.36019
Overall Steps per Second: 10,590.12843

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.72289

Cumulative Model Updates: 125,268
Cumulative Timesteps: 1,044,776,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.84639
Policy Entropy: 3.26255
Value Function Loss: 0.00411

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.55767
Value Function Update Magnitude: 0.51581

Collected Steps per Second: 22,581.61290
Overall Steps per Second: 10,492.26566

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.55255
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.76789

Cumulative Model Updates: 125,274
Cumulative Timesteps: 1,044,826,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1044826900...
Checkpoint 1044826900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,042.56940
Policy Entropy: 3.25366
Value Function Loss: 0.00432

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.57054
Value Function Update Magnitude: 0.54474

Collected Steps per Second: 22,496.79836
Overall Steps per Second: 10,609.16674

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.71554

Cumulative Model Updates: 125,280
Cumulative Timesteps: 1,044,876,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.29915
Policy Entropy: 3.24081
Value Function Loss: 0.00456

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.56596

Collected Steps per Second: 22,211.70910
Overall Steps per Second: 10,435.71957

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.54027
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.79143

Cumulative Model Updates: 125,286
Cumulative Timesteps: 1,044,926,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1044926930...
Checkpoint 1044926930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,792.36020
Policy Entropy: 3.23687
Value Function Loss: 0.00457

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.58632

Collected Steps per Second: 22,511.03065
Overall Steps per Second: 10,617.06476

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.48847
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.70978

Cumulative Model Updates: 125,292
Cumulative Timesteps: 1,044,976,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.10906
Policy Entropy: 3.24395
Value Function Loss: 0.00418

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.57788
Value Function Update Magnitude: 0.58312

Collected Steps per Second: 22,184.36981
Overall Steps per Second: 10,386.96953

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.56142
PPO Batch Consumption Time: 0.30376
Total Iteration Time: 4.81661

Cumulative Model Updates: 125,298
Cumulative Timesteps: 1,045,026,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1045026964...
Checkpoint 1045026964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.94813
Policy Entropy: 3.24943
Value Function Loss: 0.00406

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.56043

Collected Steps per Second: 22,313.66834
Overall Steps per Second: 10,504.52416

Timestep Collection Time: 2.24185
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.76214

Cumulative Model Updates: 125,304
Cumulative Timesteps: 1,045,076,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.81005
Policy Entropy: 3.22287
Value Function Loss: 0.00429

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.55068

Collected Steps per Second: 18,582.78595
Overall Steps per Second: 9,124.55534

Timestep Collection Time: 2.69142
Timestep Consumption Time: 2.78984
PPO Batch Consumption Time: 0.33479
Total Iteration Time: 5.48125

Cumulative Model Updates: 125,310
Cumulative Timesteps: 1,045,127,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1045127002...
Checkpoint 1045127002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.61453
Policy Entropy: 3.23236
Value Function Loss: 0.00420

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.58002
Value Function Update Magnitude: 0.55602

Collected Steps per Second: 19,612.33892
Overall Steps per Second: 9,813.86133

Timestep Collection Time: 2.55054
Timestep Consumption Time: 2.54654
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 5.09708

Cumulative Model Updates: 125,316
Cumulative Timesteps: 1,045,177,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.02246
Policy Entropy: 3.22903
Value Function Loss: 0.00394

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.57794
Value Function Update Magnitude: 0.55372

Collected Steps per Second: 20,748.66302
Overall Steps per Second: 9,935.75955

Timestep Collection Time: 2.41124
Timestep Consumption Time: 2.62411
PPO Batch Consumption Time: 0.30983
Total Iteration Time: 5.03535

Cumulative Model Updates: 125,322
Cumulative Timesteps: 1,045,227,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1045227054...
Checkpoint 1045227054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.81574
Policy Entropy: 3.23567
Value Function Loss: 0.00358

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.54283

Collected Steps per Second: 21,980.48513
Overall Steps per Second: 10,391.46108

Timestep Collection Time: 2.27529
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.81280

Cumulative Model Updates: 125,328
Cumulative Timesteps: 1,045,277,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.36238
Policy Entropy: 3.21482
Value Function Loss: 0.00349

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 21,878.45090
Overall Steps per Second: 10,472.59347

Timestep Collection Time: 2.28627
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.77628

Cumulative Model Updates: 125,334
Cumulative Timesteps: 1,045,327,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1045327086...
Checkpoint 1045327086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.91321
Policy Entropy: 3.21112
Value Function Loss: 0.00400

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.56477
Value Function Update Magnitude: 0.52464

Collected Steps per Second: 21,665.41886
Overall Steps per Second: 10,334.43895

Timestep Collection Time: 2.30912
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.84090

Cumulative Model Updates: 125,340
Cumulative Timesteps: 1,045,377,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.88762
Policy Entropy: 3.22398
Value Function Loss: 0.00428

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.53419

Collected Steps per Second: 22,084.15907
Overall Steps per Second: 10,359.37394

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.56381
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.82906

Cumulative Model Updates: 125,346
Cumulative Timesteps: 1,045,427,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1045427140...
Checkpoint 1045427140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.49053
Policy Entropy: 3.22669
Value Function Loss: 0.00420

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.52981

Collected Steps per Second: 21,157.65359
Overall Steps per Second: 10,202.82788

Timestep Collection Time: 2.36349
Timestep Consumption Time: 2.53770
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.90119

Cumulative Model Updates: 125,352
Cumulative Timesteps: 1,045,477,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,838.22996
Policy Entropy: 3.21998
Value Function Loss: 0.00378

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.54189

Collected Steps per Second: 21,724.81172
Overall Steps per Second: 10,476.00744

Timestep Collection Time: 2.30179
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.77338

Cumulative Model Updates: 125,358
Cumulative Timesteps: 1,045,527,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1045527152...
Checkpoint 1045527152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.25650
Policy Entropy: 3.21637
Value Function Loss: 0.00392

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.56738
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 21,594.68639
Overall Steps per Second: 10,332.91601

Timestep Collection Time: 2.31538
Timestep Consumption Time: 2.52352
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.83891

Cumulative Model Updates: 125,364
Cumulative Timesteps: 1,045,577,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,071.80697
Policy Entropy: 3.23495
Value Function Loss: 0.00434

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.56838

Collected Steps per Second: 22,314.54082
Overall Steps per Second: 9,878.53575

Timestep Collection Time: 2.24195
Timestep Consumption Time: 2.82237
PPO Batch Consumption Time: 0.33227
Total Iteration Time: 5.06431

Cumulative Model Updates: 125,370
Cumulative Timesteps: 1,045,627,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1045627180...
Checkpoint 1045627180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.02190
Policy Entropy: 3.24045
Value Function Loss: 0.00440

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.54967

Collected Steps per Second: 18,708.89479
Overall Steps per Second: 9,614.63066

Timestep Collection Time: 2.67402
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 5.20332

Cumulative Model Updates: 125,376
Cumulative Timesteps: 1,045,677,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.83501
Policy Entropy: 3.23565
Value Function Loss: 0.00417

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.53645

Collected Steps per Second: 21,557.07181
Overall Steps per Second: 10,329.61431

Timestep Collection Time: 2.32054
Timestep Consumption Time: 2.52224
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.84278

Cumulative Model Updates: 125,382
Cumulative Timesteps: 1,045,727,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1045727232...
Checkpoint 1045727232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.21850
Policy Entropy: 3.22288
Value Function Loss: 0.00400

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.55735

Collected Steps per Second: 21,477.44505
Overall Steps per Second: 10,123.03912

Timestep Collection Time: 2.32914
Timestep Consumption Time: 2.61246
PPO Batch Consumption Time: 0.31411
Total Iteration Time: 4.94160

Cumulative Model Updates: 125,388
Cumulative Timesteps: 1,045,777,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,000.19451
Policy Entropy: 3.22196
Value Function Loss: 0.00408

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.57908

Collected Steps per Second: 18,873.55559
Overall Steps per Second: 9,412.75448

Timestep Collection Time: 2.65006
Timestep Consumption Time: 2.66358
PPO Batch Consumption Time: 0.30840
Total Iteration Time: 5.31364

Cumulative Model Updates: 125,394
Cumulative Timesteps: 1,045,827,272

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1045827272...
Checkpoint 1045827272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.21922
Policy Entropy: 3.22167
Value Function Loss: 0.00433

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.57467

Collected Steps per Second: 20,196.90611
Overall Steps per Second: 10,156.06317

Timestep Collection Time: 2.47642
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.92474

Cumulative Model Updates: 125,400
Cumulative Timesteps: 1,045,877,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,636.40111
Policy Entropy: 3.21769
Value Function Loss: 0.00443

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.55576

Collected Steps per Second: 19,477.94586
Overall Steps per Second: 9,830.11516

Timestep Collection Time: 2.56701
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 5.08641

Cumulative Model Updates: 125,406
Cumulative Timesteps: 1,045,927,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1045927288...
Checkpoint 1045927288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.20353
Policy Entropy: 3.20787
Value Function Loss: 0.00426

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 21,269.47478
Overall Steps per Second: 10,391.04817

Timestep Collection Time: 2.35116
Timestep Consumption Time: 2.46144
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.81260

Cumulative Model Updates: 125,412
Cumulative Timesteps: 1,045,977,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.40358
Policy Entropy: 3.20334
Value Function Loss: 0.00380

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.55947

Collected Steps per Second: 18,997.14538
Overall Steps per Second: 9,892.12563

Timestep Collection Time: 2.63240
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 5.05533

Cumulative Model Updates: 125,418
Cumulative Timesteps: 1,046,027,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1046027304...
Checkpoint 1046027304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.53563
Policy Entropy: 3.20149
Value Function Loss: 0.00373

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.57867
Value Function Update Magnitude: 0.55115

Collected Steps per Second: 20,201.85297
Overall Steps per Second: 9,743.38960

Timestep Collection Time: 2.47641
Timestep Consumption Time: 2.65815
PPO Batch Consumption Time: 0.31966
Total Iteration Time: 5.13456

Cumulative Model Updates: 125,424
Cumulative Timesteps: 1,046,077,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.97394
Policy Entropy: 3.21630
Value Function Loss: 0.00361

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.54256

Collected Steps per Second: 20,073.12076
Overall Steps per Second: 9,940.63912

Timestep Collection Time: 2.49229
Timestep Consumption Time: 2.54039
PPO Batch Consumption Time: 0.30760
Total Iteration Time: 5.03267

Cumulative Model Updates: 125,430
Cumulative Timesteps: 1,046,127,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1046127360...
Checkpoint 1046127360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.79866
Policy Entropy: 3.21842
Value Function Loss: 0.00380

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.53616

Collected Steps per Second: 19,011.66763
Overall Steps per Second: 9,618.79216

Timestep Collection Time: 2.63175
Timestep Consumption Time: 2.56994
PPO Batch Consumption Time: 0.31339
Total Iteration Time: 5.20169

Cumulative Model Updates: 125,436
Cumulative Timesteps: 1,046,177,394

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.55929
Policy Entropy: 3.22397
Value Function Loss: 0.00358

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.51924

Collected Steps per Second: 18,279.11893
Overall Steps per Second: 9,685.56867

Timestep Collection Time: 2.73536
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 5.16232

Cumulative Model Updates: 125,442
Cumulative Timesteps: 1,046,227,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1046227394...
Checkpoint 1046227394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.86085
Policy Entropy: 3.21624
Value Function Loss: 0.00379

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.49456

Collected Steps per Second: 19,690.28013
Overall Steps per Second: 9,657.28049

Timestep Collection Time: 2.53953
Timestep Consumption Time: 2.63833
PPO Batch Consumption Time: 0.32439
Total Iteration Time: 5.17786

Cumulative Model Updates: 125,448
Cumulative Timesteps: 1,046,277,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.20722
Policy Entropy: 3.20992
Value Function Loss: 0.00381

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.48917

Collected Steps per Second: 18,158.01691
Overall Steps per Second: 9,211.86102

Timestep Collection Time: 2.75570
Timestep Consumption Time: 2.67621
PPO Batch Consumption Time: 0.30618
Total Iteration Time: 5.43191

Cumulative Model Updates: 125,454
Cumulative Timesteps: 1,046,327,436

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1046327436...
Checkpoint 1046327436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.91439
Policy Entropy: 3.19434
Value Function Loss: 0.00419

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.50308

Collected Steps per Second: 21,589.62296
Overall Steps per Second: 10,319.48205

Timestep Collection Time: 2.31685
Timestep Consumption Time: 2.53029
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.84714

Cumulative Model Updates: 125,460
Cumulative Timesteps: 1,046,377,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.97130
Policy Entropy: 3.20076
Value Function Loss: 0.00416

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.58411
Value Function Update Magnitude: 0.52751

Collected Steps per Second: 21,756.67297
Overall Steps per Second: 10,303.33375

Timestep Collection Time: 2.29851
Timestep Consumption Time: 2.55506
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.85357

Cumulative Model Updates: 125,466
Cumulative Timesteps: 1,046,427,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1046427464...
Checkpoint 1046427464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.56385
Policy Entropy: 3.20686
Value Function Loss: 0.00440

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.53657

Collected Steps per Second: 21,823.36277
Overall Steps per Second: 10,423.87342

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.79918

Cumulative Model Updates: 125,472
Cumulative Timesteps: 1,046,477,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.15630
Policy Entropy: 3.21936
Value Function Loss: 0.00438

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.58015
Value Function Update Magnitude: 0.56102

Collected Steps per Second: 21,943.63706
Overall Steps per Second: 10,499.57148

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.76458

Cumulative Model Updates: 125,478
Cumulative Timesteps: 1,046,527,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1046527516...
Checkpoint 1046527516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.20411
Policy Entropy: 3.23033
Value Function Loss: 0.00426

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.58622

Collected Steps per Second: 21,922.48213
Overall Steps per Second: 10,372.33906

Timestep Collection Time: 2.28186
Timestep Consumption Time: 2.54097
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.82283

Cumulative Model Updates: 125,484
Cumulative Timesteps: 1,046,577,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.58402
Policy Entropy: 3.23833
Value Function Loss: 0.00411

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.57979

Collected Steps per Second: 22,016.60632
Overall Steps per Second: 10,446.99314

Timestep Collection Time: 2.27138
Timestep Consumption Time: 2.51546
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.78683

Cumulative Model Updates: 125,490
Cumulative Timesteps: 1,046,627,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1046627548...
Checkpoint 1046627548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.05555
Policy Entropy: 3.23481
Value Function Loss: 0.00411

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.56819
Value Function Update Magnitude: 0.56021

Collected Steps per Second: 21,812.96488
Overall Steps per Second: 10,407.60302

Timestep Collection Time: 2.29267
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.80514

Cumulative Model Updates: 125,496
Cumulative Timesteps: 1,046,677,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.08968
Policy Entropy: 3.22891
Value Function Loss: 0.00432

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.57586
Value Function Update Magnitude: 0.53994

Collected Steps per Second: 22,160.74779
Overall Steps per Second: 10,540.17635

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.74546

Cumulative Model Updates: 125,502
Cumulative Timesteps: 1,046,727,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1046727576...
Checkpoint 1046727576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.04180
Policy Entropy: 3.22396
Value Function Loss: 0.00426

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.58444
Value Function Update Magnitude: 0.51892

Collected Steps per Second: 22,027.37170
Overall Steps per Second: 10,407.63270

Timestep Collection Time: 2.27063
Timestep Consumption Time: 2.53507
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.80570

Cumulative Model Updates: 125,508
Cumulative Timesteps: 1,046,777,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.42272
Policy Entropy: 3.21308
Value Function Loss: 0.00438

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.53904

Collected Steps per Second: 21,684.38757
Overall Steps per Second: 10,416.37323

Timestep Collection Time: 2.30719
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.80302

Cumulative Model Updates: 125,514
Cumulative Timesteps: 1,046,827,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1046827622...
Checkpoint 1046827622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.80516
Policy Entropy: 3.20452
Value Function Loss: 0.00413

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 22,045.97139
Overall Steps per Second: 10,325.42084

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.57567
PPO Batch Consumption Time: 0.30443
Total Iteration Time: 4.84474

Cumulative Model Updates: 125,520
Cumulative Timesteps: 1,046,877,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.27054
Policy Entropy: 3.20175
Value Function Loss: 0.00402

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.58706
Value Function Update Magnitude: 0.56616

Collected Steps per Second: 21,516.36792
Overall Steps per Second: 10,312.26072

Timestep Collection Time: 2.32456
Timestep Consumption Time: 2.52559
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.85015

Cumulative Model Updates: 125,526
Cumulative Timesteps: 1,046,927,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1046927662...
Checkpoint 1046927662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.42203
Policy Entropy: 3.19470
Value Function Loss: 0.00427

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.59945
Value Function Update Magnitude: 0.54216

Collected Steps per Second: 21,787.44210
Overall Steps per Second: 10,365.37910

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.53037
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.82664

Cumulative Model Updates: 125,532
Cumulative Timesteps: 1,046,977,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.04218
Policy Entropy: 3.20788
Value Function Loss: 0.00456

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.59900
Value Function Update Magnitude: 0.54142

Collected Steps per Second: 21,687.00313
Overall Steps per Second: 10,411.00602

Timestep Collection Time: 2.30673
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.80511

Cumulative Model Updates: 125,538
Cumulative Timesteps: 1,047,027,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1047027718...
Checkpoint 1047027718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.97319
Policy Entropy: 3.21245
Value Function Loss: 0.00469

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.58979
Value Function Update Magnitude: 0.55648

Collected Steps per Second: 21,620.88324
Overall Steps per Second: 10,347.29923

Timestep Collection Time: 2.31332
Timestep Consumption Time: 2.52041
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.83373

Cumulative Model Updates: 125,544
Cumulative Timesteps: 1,047,077,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.98720
Policy Entropy: 3.21933
Value Function Loss: 0.00465

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.59383
Value Function Update Magnitude: 0.55125

Collected Steps per Second: 22,036.17753
Overall Steps per Second: 10,434.98191

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.52298
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.79234

Cumulative Model Updates: 125,550
Cumulative Timesteps: 1,047,127,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1047127742...
Checkpoint 1047127742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.66158
Policy Entropy: 3.22762
Value Function Loss: 0.00445

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.52346

Collected Steps per Second: 21,619.04322
Overall Steps per Second: 10,485.50302

Timestep Collection Time: 2.31361
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.77021

Cumulative Model Updates: 125,556
Cumulative Timesteps: 1,047,177,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.83145
Policy Entropy: 3.22456
Value Function Loss: 0.00444

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.49244

Collected Steps per Second: 21,697.44563
Overall Steps per Second: 10,398.15186

Timestep Collection Time: 2.30571
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.81124

Cumulative Model Updates: 125,562
Cumulative Timesteps: 1,047,227,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1047227788...
Checkpoint 1047227788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.88081
Policy Entropy: 3.23168
Value Function Loss: 0.00435

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.50773

Collected Steps per Second: 21,175.72852
Overall Steps per Second: 10,300.59031

Timestep Collection Time: 2.36129
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.85428

Cumulative Model Updates: 125,568
Cumulative Timesteps: 1,047,277,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.94339
Policy Entropy: 3.21672
Value Function Loss: 0.00421

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.53970

Collected Steps per Second: 20,044.20932
Overall Steps per Second: 9,821.49532

Timestep Collection Time: 2.49508
Timestep Consumption Time: 2.59701
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 5.09210

Cumulative Model Updates: 125,574
Cumulative Timesteps: 1,047,327,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1047327802...
Checkpoint 1047327802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.93920
Policy Entropy: 3.21218
Value Function Loss: 0.00403

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.58588
Value Function Update Magnitude: 0.55038

Collected Steps per Second: 18,598.37367
Overall Steps per Second: 9,774.16053

Timestep Collection Time: 2.68927
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 5.11717

Cumulative Model Updates: 125,580
Cumulative Timesteps: 1,047,377,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.96950
Policy Entropy: 3.20911
Value Function Loss: 0.00404

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.59220
Value Function Update Magnitude: 0.55659

Collected Steps per Second: 21,058.75804
Overall Steps per Second: 10,169.45459

Timestep Collection Time: 2.37554
Timestep Consumption Time: 2.54370
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.91924

Cumulative Model Updates: 125,586
Cumulative Timesteps: 1,047,427,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1047427844...
Checkpoint 1047427844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.99537
Policy Entropy: 3.22728
Value Function Loss: 0.00411

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.58621
Value Function Update Magnitude: 0.57005

Collected Steps per Second: 20,992.69952
Overall Steps per Second: 10,116.43855

Timestep Collection Time: 2.38273
Timestep Consumption Time: 2.56169
PPO Batch Consumption Time: 0.30099
Total Iteration Time: 4.94443

Cumulative Model Updates: 125,592
Cumulative Timesteps: 1,047,477,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,361.05364
Policy Entropy: 3.22192
Value Function Loss: 0.00440

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.59429
Value Function Update Magnitude: 0.60800

Collected Steps per Second: 20,952.22926
Overall Steps per Second: 10,026.26668

Timestep Collection Time: 2.38705
Timestep Consumption Time: 2.60125
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.98830

Cumulative Model Updates: 125,598
Cumulative Timesteps: 1,047,527,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1047527878...
Checkpoint 1047527878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.70023
Policy Entropy: 3.21221
Value Function Loss: 0.00435

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.60136
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 21,388.14575
Overall Steps per Second: 10,116.63422

Timestep Collection Time: 2.33812
Timestep Consumption Time: 2.60503
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.94315

Cumulative Model Updates: 125,604
Cumulative Timesteps: 1,047,577,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.24477
Policy Entropy: 3.20593
Value Function Loss: 0.00425

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.59672
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 20,365.20836
Overall Steps per Second: 9,559.32991

Timestep Collection Time: 2.45644
Timestep Consumption Time: 2.77677
PPO Batch Consumption Time: 0.32450
Total Iteration Time: 5.23321

Cumulative Model Updates: 125,610
Cumulative Timesteps: 1,047,627,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1047627912...
Checkpoint 1047627912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.70343
Policy Entropy: 3.21368
Value Function Loss: 0.00417

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.59253
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 19,478.69431
Overall Steps per Second: 9,709.22884

Timestep Collection Time: 2.56763
Timestep Consumption Time: 2.58356
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 5.15118

Cumulative Model Updates: 125,616
Cumulative Timesteps: 1,047,677,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.80568
Policy Entropy: 3.21268
Value Function Loss: 0.00428

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.60567
Value Function Update Magnitude: 0.60934

Collected Steps per Second: 20,654.39876
Overall Steps per Second: 9,857.41868

Timestep Collection Time: 2.42128
Timestep Consumption Time: 2.65206
PPO Batch Consumption Time: 0.31394
Total Iteration Time: 5.07334

Cumulative Model Updates: 125,622
Cumulative Timesteps: 1,047,727,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1047727936...
Checkpoint 1047727936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.90100
Policy Entropy: 3.21579
Value Function Loss: 0.00454

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 19,789.56779
Overall Steps per Second: 9,892.37489

Timestep Collection Time: 2.52749
Timestep Consumption Time: 2.52872
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 5.05622

Cumulative Model Updates: 125,628
Cumulative Timesteps: 1,047,777,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.22959
Policy Entropy: 3.20305
Value Function Loss: 0.00434

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.60021
Value Function Update Magnitude: 0.62603

Collected Steps per Second: 21,914.47338
Overall Steps per Second: 10,137.79425

Timestep Collection Time: 2.28324
Timestep Consumption Time: 2.65235
PPO Batch Consumption Time: 0.31736
Total Iteration Time: 4.93559

Cumulative Model Updates: 125,634
Cumulative Timesteps: 1,047,827,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1047827990...
Checkpoint 1047827990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.55182
Policy Entropy: 3.21341
Value Function Loss: 0.00419

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.59419
Value Function Update Magnitude: 0.60226

Collected Steps per Second: 20,889.39244
Overall Steps per Second: 10,145.50255

Timestep Collection Time: 2.39509
Timestep Consumption Time: 2.53636
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.93145

Cumulative Model Updates: 125,640
Cumulative Timesteps: 1,047,878,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.57476
Policy Entropy: 3.20515
Value Function Loss: 0.00439

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.57953

Collected Steps per Second: 20,929.06649
Overall Steps per Second: 9,898.49091

Timestep Collection Time: 2.39046
Timestep Consumption Time: 2.66385
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 5.05431

Cumulative Model Updates: 125,646
Cumulative Timesteps: 1,047,928,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1047928052...
Checkpoint 1047928052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.41256
Policy Entropy: 3.22073
Value Function Loss: 0.00419

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.55814

Collected Steps per Second: 18,718.45522
Overall Steps per Second: 9,180.29487

Timestep Collection Time: 2.67255
Timestep Consumption Time: 2.77673
PPO Batch Consumption Time: 0.32677
Total Iteration Time: 5.44928

Cumulative Model Updates: 125,652
Cumulative Timesteps: 1,047,978,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.71321
Policy Entropy: 3.21993
Value Function Loss: 0.00424

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.54520

Collected Steps per Second: 19,277.63119
Overall Steps per Second: 9,537.53774

Timestep Collection Time: 2.59420
Timestep Consumption Time: 2.64929
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 5.24349

Cumulative Model Updates: 125,658
Cumulative Timesteps: 1,048,028,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048028088...
Checkpoint 1048028088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.28565
Policy Entropy: 3.21913
Value Function Loss: 0.00420

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.59682
Value Function Update Magnitude: 0.53439

Collected Steps per Second: 18,501.78037
Overall Steps per Second: 9,374.13457

Timestep Collection Time: 2.70385
Timestep Consumption Time: 2.63275
PPO Batch Consumption Time: 0.30623
Total Iteration Time: 5.33660

Cumulative Model Updates: 125,664
Cumulative Timesteps: 1,048,078,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.95563
Policy Entropy: 3.22572
Value Function Loss: 0.00415

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.59160
Value Function Update Magnitude: 0.56235

Collected Steps per Second: 19,068.03893
Overall Steps per Second: 9,623.37930

Timestep Collection Time: 2.62387
Timestep Consumption Time: 2.57514
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 5.19901

Cumulative Model Updates: 125,670
Cumulative Timesteps: 1,048,128,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1048128146...
Checkpoint 1048128146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.84832
Policy Entropy: 3.22975
Value Function Loss: 0.00405

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.58566
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 18,566.98190
Overall Steps per Second: 9,205.65822

Timestep Collection Time: 2.69306
Timestep Consumption Time: 2.73860
PPO Batch Consumption Time: 0.31826
Total Iteration Time: 5.43166

Cumulative Model Updates: 125,676
Cumulative Timesteps: 1,048,178,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.68325
Policy Entropy: 3.23100
Value Function Loss: 0.00374

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.54973

Collected Steps per Second: 14,779.55446
Overall Steps per Second: 7,246.79586

Timestep Collection Time: 3.38481
Timestep Consumption Time: 3.51838
PPO Batch Consumption Time: 0.43934
Total Iteration Time: 6.90319

Cumulative Model Updates: 125,682
Cumulative Timesteps: 1,048,228,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1048228174...
Checkpoint 1048228174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.58908
Policy Entropy: 3.22948
Value Function Loss: 0.00399

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.58522
Value Function Update Magnitude: 0.52269

Collected Steps per Second: 7,700.95878
Overall Steps per Second: 4,730.80652

Timestep Collection Time: 6.49452
Timestep Consumption Time: 4.07747
PPO Batch Consumption Time: 0.43909
Total Iteration Time: 10.57198

Cumulative Model Updates: 125,688
Cumulative Timesteps: 1,048,278,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,875.44855
Policy Entropy: 3.21656
Value Function Loss: 0.00401

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.58618
Value Function Update Magnitude: 0.52539

Collected Steps per Second: 9,603.54062
Overall Steps per Second: 4,741.83845

Timestep Collection Time: 5.20704
Timestep Consumption Time: 5.33866
PPO Batch Consumption Time: 0.74330
Total Iteration Time: 10.54570

Cumulative Model Updates: 125,694
Cumulative Timesteps: 1,048,328,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1048328194...
Checkpoint 1048328194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.69986
Policy Entropy: 3.21989
Value Function Loss: 0.00391

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.58220
Value Function Update Magnitude: 0.52671

Collected Steps per Second: 12,308.32759
Overall Steps per Second: 5,073.26976

Timestep Collection Time: 4.06262
Timestep Consumption Time: 5.79375
PPO Batch Consumption Time: 0.81028
Total Iteration Time: 9.85637

Cumulative Model Updates: 125,700
Cumulative Timesteps: 1,048,378,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.40840
Policy Entropy: 3.20910
Value Function Loss: 0.00389

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.59137
Value Function Update Magnitude: 0.54365

Collected Steps per Second: 13,315.71858
Overall Steps per Second: 6,065.30994

Timestep Collection Time: 3.75526
Timestep Consumption Time: 4.48900
PPO Batch Consumption Time: 0.60424
Total Iteration Time: 8.24426

Cumulative Model Updates: 125,706
Cumulative Timesteps: 1,048,428,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1048428202...
Checkpoint 1048428202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.96281
Policy Entropy: 3.21593
Value Function Loss: 0.00386

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.58866
Value Function Update Magnitude: 0.57527

Collected Steps per Second: 13,711.15174
Overall Steps per Second: 5,308.22340

Timestep Collection Time: 3.64696
Timestep Consumption Time: 5.77314
PPO Batch Consumption Time: 0.81471
Total Iteration Time: 9.42010

Cumulative Model Updates: 125,712
Cumulative Timesteps: 1,048,478,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.26390
Policy Entropy: 3.22432
Value Function Loss: 0.00383

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.57248

Collected Steps per Second: 9,825.26507
Overall Steps per Second: 4,730.60965

Timestep Collection Time: 5.09096
Timestep Consumption Time: 5.48273
PPO Batch Consumption Time: 0.73343
Total Iteration Time: 10.57369

Cumulative Model Updates: 125,718
Cumulative Timesteps: 1,048,528,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1048528226...
Checkpoint 1048528226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.27080
Policy Entropy: 3.22258
Value Function Loss: 0.00422

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.58179
Value Function Update Magnitude: 0.56219

Collected Steps per Second: 14,891.15734
Overall Steps per Second: 6,328.61298

Timestep Collection Time: 3.35971
Timestep Consumption Time: 4.54565
PPO Batch Consumption Time: 0.61519
Total Iteration Time: 7.90537

Cumulative Model Updates: 125,724
Cumulative Timesteps: 1,048,578,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.86286
Policy Entropy: 3.22445
Value Function Loss: 0.00400

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.57906
Value Function Update Magnitude: 0.54372

Collected Steps per Second: 12,442.57210
Overall Steps per Second: 5,259.94194

Timestep Collection Time: 4.02119
Timestep Consumption Time: 5.49108
PPO Batch Consumption Time: 0.77666
Total Iteration Time: 9.51227

Cumulative Model Updates: 125,730
Cumulative Timesteps: 1,048,628,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1048628290...
Checkpoint 1048628290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.31954
Policy Entropy: 3.22207
Value Function Loss: 0.00384

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.57070
Value Function Update Magnitude: 0.53013

Collected Steps per Second: 8,000.89011
Overall Steps per Second: 154.13217

Timestep Collection Time: 6.25180
Timestep Consumption Time: 318.27486
PPO Batch Consumption Time: 52.85715
Total Iteration Time: 324.52666

Cumulative Model Updates: 125,736
Cumulative Timesteps: 1,048,678,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1048678310...
Checkpoint 1048678310 saved!
