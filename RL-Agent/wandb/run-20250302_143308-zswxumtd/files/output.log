Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.71806
Policy Entropy: 4.45200
Value Function Loss: 0.00146

Mean KL Divergence: 0.00002
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.09890
Value Function Update Magnitude: 0.15717

Collected Steps per Second: 18,854.12994
Overall Steps per Second: 12,351.01950

Timestep Collection Time: 2.65226
Timestep Consumption Time: 1.39648
PPO Batch Consumption Time: 0.34758
Total Iteration Time: 4.04873

Cumulative Model Updates: 312,138
Cumulative Timesteps: 2,603,074,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.40995
Policy Entropy: 4.44682
Value Function Loss: 0.00214

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00398
Policy Update Magnitude: 0.21891
Value Function Update Magnitude: 0.32206

Collected Steps per Second: 21,484.73368
Overall Steps per Second: 11,658.29136

Timestep Collection Time: 2.32789
Timestep Consumption Time: 1.96211
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.28999

Cumulative Model Updates: 312,142
Cumulative Timesteps: 2,603,124,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2603124342...
Checkpoint 2603124342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.67730
Policy Entropy: 4.45286
Value Function Loss: 0.00180

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00358
Policy Update Magnitude: 0.21849
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 19,916.43033
Overall Steps per Second: 10,994.32677

Timestep Collection Time: 2.51079
Timestep Consumption Time: 2.03755
PPO Batch Consumption Time: 0.30934
Total Iteration Time: 4.54835

Cumulative Model Updates: 312,146
Cumulative Timesteps: 2,603,174,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.88237
Policy Entropy: 4.45114
Value Function Loss: 0.00276

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.30151
Value Function Update Magnitude: 0.49480

Collected Steps per Second: 19,132.51179
Overall Steps per Second: 9,690.87128

Timestep Collection Time: 2.61388
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 5.16053

Cumulative Model Updates: 312,152
Cumulative Timesteps: 2,603,224,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2603224358...
Checkpoint 2603224358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.96614
Policy Entropy: 4.45211
Value Function Loss: 0.00254

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00518
Policy Update Magnitude: 0.33970
Value Function Update Magnitude: 0.53660

Collected Steps per Second: 22,209.80696
Overall Steps per Second: 10,789.06637

Timestep Collection Time: 2.25189
Timestep Consumption Time: 2.38373
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.63562

Cumulative Model Updates: 312,158
Cumulative Timesteps: 2,603,274,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.58231
Policy Entropy: 4.44791
Value Function Loss: 0.00277

Mean KL Divergence: 0.00089
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.34323
Value Function Update Magnitude: 0.50889

Collected Steps per Second: 20,263.38677
Overall Steps per Second: 10,299.60764

Timestep Collection Time: 2.46948
Timestep Consumption Time: 2.38896
PPO Batch Consumption Time: 0.27536
Total Iteration Time: 4.85844

Cumulative Model Updates: 312,164
Cumulative Timesteps: 2,603,324,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2603324412...
Checkpoint 2603324412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.15153
Policy Entropy: 4.44856
Value Function Loss: 0.00238

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00488
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.44323

Collected Steps per Second: 21,838.63266
Overall Steps per Second: 10,553.44579

Timestep Collection Time: 2.29062
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.74006

Cumulative Model Updates: 312,170
Cumulative Timesteps: 2,603,374,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.25584
Policy Entropy: 4.45414
Value Function Loss: 0.00240

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00549
Policy Update Magnitude: 0.28359
Value Function Update Magnitude: 0.39763

Collected Steps per Second: 21,771.59263
Overall Steps per Second: 9,922.38020

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.74408
PPO Batch Consumption Time: 0.32170
Total Iteration Time: 5.04194

Cumulative Model Updates: 312,176
Cumulative Timesteps: 2,603,424,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2603424464...
Checkpoint 2603424464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.38539
Policy Entropy: 4.45713
Value Function Loss: 0.00214

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00573
Policy Update Magnitude: 0.27717
Value Function Update Magnitude: 0.38044

Collected Steps per Second: 19,990.27628
Overall Steps per Second: 9,619.90618

Timestep Collection Time: 2.50172
Timestep Consumption Time: 2.69688
PPO Batch Consumption Time: 0.31541
Total Iteration Time: 5.19860

Cumulative Model Updates: 312,182
Cumulative Timesteps: 2,603,474,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.36547
Policy Entropy: 4.46135
Value Function Loss: 0.00202

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00325
Policy Update Magnitude: 0.27433
Value Function Update Magnitude: 0.34063

Collected Steps per Second: 19,712.24629
Overall Steps per Second: 9,689.81772

Timestep Collection Time: 2.53720
Timestep Consumption Time: 2.62430
PPO Batch Consumption Time: 0.31291
Total Iteration Time: 5.16150

Cumulative Model Updates: 312,188
Cumulative Timesteps: 2,603,524,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2603524488...
Checkpoint 2603524488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.70271
Policy Entropy: 4.46166
Value Function Loss: 0.00224

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00373
Policy Update Magnitude: 0.28754
Value Function Update Magnitude: 0.39226

Collected Steps per Second: 19,566.26381
Overall Steps per Second: 9,444.13449

Timestep Collection Time: 2.55613
Timestep Consumption Time: 2.73964
PPO Batch Consumption Time: 0.31815
Total Iteration Time: 5.29577

Cumulative Model Updates: 312,194
Cumulative Timesteps: 2,603,574,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.91922
Policy Entropy: 4.45916
Value Function Loss: 0.00236

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00292
Policy Update Magnitude: 0.29550
Value Function Update Magnitude: 0.40482

Collected Steps per Second: 19,800.99321
Overall Steps per Second: 9,590.06002

Timestep Collection Time: 2.52593
Timestep Consumption Time: 2.68947
PPO Batch Consumption Time: 0.31432
Total Iteration Time: 5.21540

Cumulative Model Updates: 312,200
Cumulative Timesteps: 2,603,624,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2603624518...
Checkpoint 2603624518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.39566
Policy Entropy: 4.45514
Value Function Loss: 0.00249

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00377
Policy Update Magnitude: 0.28810
Value Function Update Magnitude: 0.41492

Collected Steps per Second: 20,425.50355
Overall Steps per Second: 9,842.91541

Timestep Collection Time: 2.44870
Timestep Consumption Time: 2.63272
PPO Batch Consumption Time: 0.31329
Total Iteration Time: 5.08142

Cumulative Model Updates: 312,206
Cumulative Timesteps: 2,603,674,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.27308
Policy Entropy: 4.45429
Value Function Loss: 0.00201

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00431
Policy Update Magnitude: 0.26607
Value Function Update Magnitude: 0.40109

Collected Steps per Second: 20,021.33330
Overall Steps per Second: 9,548.66705

Timestep Collection Time: 2.49853
Timestep Consumption Time: 2.74031
PPO Batch Consumption Time: 0.32003
Total Iteration Time: 5.23885

Cumulative Model Updates: 312,212
Cumulative Timesteps: 2,603,724,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2603724558...
Checkpoint 2603724558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.14472
Policy Entropy: 4.45460
Value Function Loss: 0.00155

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.25210
Value Function Update Magnitude: 0.38091

Collected Steps per Second: 19,641.69001
Overall Steps per Second: 9,777.78096

Timestep Collection Time: 2.54561
Timestep Consumption Time: 2.56803
PPO Batch Consumption Time: 0.30609
Total Iteration Time: 5.11363

Cumulative Model Updates: 312,218
Cumulative Timesteps: 2,603,774,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.27136
Policy Entropy: 4.46412
Value Function Loss: 0.00145

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00428
Policy Update Magnitude: 0.23754
Value Function Update Magnitude: 0.31586

Collected Steps per Second: 21,440.71324
Overall Steps per Second: 9,954.24902

Timestep Collection Time: 2.33332
Timestep Consumption Time: 2.69248
PPO Batch Consumption Time: 0.31404
Total Iteration Time: 5.02579

Cumulative Model Updates: 312,224
Cumulative Timesteps: 2,603,824,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2603824586...
Checkpoint 2603824586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.09984
Policy Entropy: 4.46443
Value Function Loss: 0.00184

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.24094
Value Function Update Magnitude: 0.29797

Collected Steps per Second: 22,620.77705
Overall Steps per Second: 10,665.29101

Timestep Collection Time: 2.21213
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.69186

Cumulative Model Updates: 312,230
Cumulative Timesteps: 2,603,874,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.28880
Policy Entropy: 4.46092
Value Function Loss: 0.00221

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00308
Policy Update Magnitude: 0.24773
Value Function Update Magnitude: 0.37190

Collected Steps per Second: 23,010.95280
Overall Steps per Second: 10,793.89695

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.63225

Cumulative Model Updates: 312,236
Cumulative Timesteps: 2,603,924,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2603924626...
Checkpoint 2603924626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.25244
Policy Entropy: 4.45552
Value Function Loss: 0.00217

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.25111
Value Function Update Magnitude: 0.38302

Collected Steps per Second: 21,747.06558
Overall Steps per Second: 10,415.69495

Timestep Collection Time: 2.29962
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.80141

Cumulative Model Updates: 312,242
Cumulative Timesteps: 2,603,974,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.67953
Policy Entropy: 4.45595
Value Function Loss: 0.00169

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00388
Policy Update Magnitude: 0.27045
Value Function Update Magnitude: 0.38881

Collected Steps per Second: 22,490.64711
Overall Steps per Second: 10,709.86549

Timestep Collection Time: 2.22332
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.66897

Cumulative Model Updates: 312,248
Cumulative Timesteps: 2,604,024,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2604024640...
Checkpoint 2604024640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.64097
Policy Entropy: 4.45641
Value Function Loss: 0.00197

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.32068
Value Function Update Magnitude: 0.43453

Collected Steps per Second: 21,941.25951
Overall Steps per Second: 10,589.63776

Timestep Collection Time: 2.28063
Timestep Consumption Time: 2.44474
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.72537

Cumulative Model Updates: 312,254
Cumulative Timesteps: 2,604,074,680

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.87311
Policy Entropy: 4.45592
Value Function Loss: 0.00212

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00426
Policy Update Magnitude: 0.31287
Value Function Update Magnitude: 0.42826

Collected Steps per Second: 22,661.19841
Overall Steps per Second: 10,640.92721

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69903

Cumulative Model Updates: 312,260
Cumulative Timesteps: 2,604,124,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2604124682...
Checkpoint 2604124682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.00722
Policy Entropy: 4.45203
Value Function Loss: 0.00271

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00562
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.42957

Collected Steps per Second: 22,865.84774
Overall Steps per Second: 10,980.85391

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.36766
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.55520

Cumulative Model Updates: 312,266
Cumulative Timesteps: 2,604,174,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.53827
Policy Entropy: 4.45034
Value Function Loss: 0.00220

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.40545

Collected Steps per Second: 22,549.74828
Overall Steps per Second: 10,522.82514

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.75557

Cumulative Model Updates: 312,272
Cumulative Timesteps: 2,604,224,744

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2604224744...
Checkpoint 2604224744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.59300
Policy Entropy: 4.44890
Value Function Loss: 0.00234

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00528
Policy Update Magnitude: 0.29979
Value Function Update Magnitude: 0.39481

Collected Steps per Second: 21,740.70824
Overall Steps per Second: 10,603.82514

Timestep Collection Time: 2.30094
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.71754

Cumulative Model Updates: 312,278
Cumulative Timesteps: 2,604,274,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.98914
Policy Entropy: 4.45480
Value Function Loss: 0.00169

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00505
Policy Update Magnitude: 0.27167
Value Function Update Magnitude: 0.34671

Collected Steps per Second: 23,541.61200
Overall Steps per Second: 10,885.57922

Timestep Collection Time: 2.12551
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.59672

Cumulative Model Updates: 312,284
Cumulative Timesteps: 2,604,324,806

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2604324806...
Checkpoint 2604324806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.96303
Policy Entropy: 4.45696
Value Function Loss: 0.00228

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00345
Policy Update Magnitude: 0.26735
Value Function Update Magnitude: 0.32330

Collected Steps per Second: 21,325.30661
Overall Steps per Second: 10,289.59267

Timestep Collection Time: 2.34510
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.86025

Cumulative Model Updates: 312,290
Cumulative Timesteps: 2,604,374,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.53805
Policy Entropy: 4.45332
Value Function Loss: 0.00231

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00400
Policy Update Magnitude: 0.26089
Value Function Update Magnitude: 0.38784

Collected Steps per Second: 22,880.68774
Overall Steps per Second: 10,876.25601

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.59717

Cumulative Model Updates: 312,296
Cumulative Timesteps: 2,604,424,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2604424816...
Checkpoint 2604424816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.93515
Policy Entropy: 4.44933
Value Function Loss: 0.00251

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.29007
Value Function Update Magnitude: 0.47208

Collected Steps per Second: 20,946.97240
Overall Steps per Second: 9,839.53335

Timestep Collection Time: 2.38698
Timestep Consumption Time: 2.69456
PPO Batch Consumption Time: 0.31275
Total Iteration Time: 5.08154

Cumulative Model Updates: 312,302
Cumulative Timesteps: 2,604,474,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.90654
Policy Entropy: 4.45635
Value Function Loss: 0.00209

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.28826
Value Function Update Magnitude: 0.39090

Collected Steps per Second: 20,073.54600
Overall Steps per Second: 9,800.54084

Timestep Collection Time: 2.49104
Timestep Consumption Time: 2.61113
PPO Batch Consumption Time: 0.31399
Total Iteration Time: 5.10217

Cumulative Model Updates: 312,308
Cumulative Timesteps: 2,604,524,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2604524820...
Checkpoint 2604524820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.62847
Policy Entropy: 4.45414
Value Function Loss: 0.00208

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00441
Policy Update Magnitude: 0.25714
Value Function Update Magnitude: 0.42711

Collected Steps per Second: 22,939.53418
Overall Steps per Second: 10,835.35122

Timestep Collection Time: 2.18095
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.61729

Cumulative Model Updates: 312,314
Cumulative Timesteps: 2,604,574,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.84013
Policy Entropy: 4.45511
Value Function Loss: 0.00167

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00536
Policy Update Magnitude: 0.23489
Value Function Update Magnitude: 0.39882

Collected Steps per Second: 22,337.54135
Overall Steps per Second: 10,466.95257

Timestep Collection Time: 2.23910
Timestep Consumption Time: 2.53937
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.77847

Cumulative Model Updates: 312,320
Cumulative Timesteps: 2,604,624,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2604624866...
Checkpoint 2604624866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.01543
Policy Entropy: 4.45159
Value Function Loss: 0.00203

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00441
Policy Update Magnitude: 0.24815
Value Function Update Magnitude: 0.35636

Collected Steps per Second: 22,141.83504
Overall Steps per Second: 10,621.13626

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.71004

Cumulative Model Updates: 312,326
Cumulative Timesteps: 2,604,674,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.43227
Policy Entropy: 4.45760
Value Function Loss: 0.00206

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00372
Policy Update Magnitude: 0.24582
Value Function Update Magnitude: 0.35661

Collected Steps per Second: 19,149.70457
Overall Steps per Second: 9,505.11634

Timestep Collection Time: 2.61195
Timestep Consumption Time: 2.65027
PPO Batch Consumption Time: 0.30857
Total Iteration Time: 5.26222

Cumulative Model Updates: 312,332
Cumulative Timesteps: 2,604,724,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2604724910...
Checkpoint 2604724910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.79495
Policy Entropy: 4.45627
Value Function Loss: 0.00185

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.25483
Value Function Update Magnitude: 0.36316

Collected Steps per Second: 19,153.01364
Overall Steps per Second: 9,579.18590

Timestep Collection Time: 2.61087
Timestep Consumption Time: 2.60941
PPO Batch Consumption Time: 0.30375
Total Iteration Time: 5.22028

Cumulative Model Updates: 312,338
Cumulative Timesteps: 2,604,774,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.81733
Policy Entropy: 4.45437
Value Function Loss: 0.00183

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00479
Policy Update Magnitude: 0.24822
Value Function Update Magnitude: 0.33363

Collected Steps per Second: 22,788.15091
Overall Steps per Second: 9,965.00788

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.82355
PPO Batch Consumption Time: 0.33096
Total Iteration Time: 5.01776

Cumulative Model Updates: 312,344
Cumulative Timesteps: 2,604,824,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2604824918...
Checkpoint 2604824918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.30404
Policy Entropy: 4.45344
Value Function Loss: 0.00169

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.24774
Value Function Update Magnitude: 0.31033

Collected Steps per Second: 18,038.37717
Overall Steps per Second: 8,906.61020

Timestep Collection Time: 2.77220
Timestep Consumption Time: 2.84228
PPO Batch Consumption Time: 0.34000
Total Iteration Time: 5.61448

Cumulative Model Updates: 312,350
Cumulative Timesteps: 2,604,874,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.76699
Policy Entropy: 4.45163
Value Function Loss: 0.00278

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00571
Policy Update Magnitude: 0.27620
Value Function Update Magnitude: 0.35191

Collected Steps per Second: 19,406.64680
Overall Steps per Second: 9,731.66546

Timestep Collection Time: 2.57778
Timestep Consumption Time: 2.56276
PPO Batch Consumption Time: 0.30601
Total Iteration Time: 5.14054

Cumulative Model Updates: 312,356
Cumulative Timesteps: 2,604,924,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2604924950...
Checkpoint 2604924950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.02477
Policy Entropy: 4.45397
Value Function Loss: 0.00271

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00618
Policy Update Magnitude: 0.28591
Value Function Update Magnitude: 0.42052

Collected Steps per Second: 21,042.12106
Overall Steps per Second: 9,625.96130

Timestep Collection Time: 2.37657
Timestep Consumption Time: 2.81855
PPO Batch Consumption Time: 0.33404
Total Iteration Time: 5.19512

Cumulative Model Updates: 312,362
Cumulative Timesteps: 2,604,974,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.04699
Policy Entropy: 4.45264
Value Function Loss: 0.00289

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00526
Policy Update Magnitude: 0.27377
Value Function Update Magnitude: 0.47788

Collected Steps per Second: 20,471.97632
Overall Steps per Second: 10,051.84293

Timestep Collection Time: 2.44275
Timestep Consumption Time: 2.53225
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.97501

Cumulative Model Updates: 312,368
Cumulative Timesteps: 2,605,024,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2605024966...
Checkpoint 2605024966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17471
Policy Entropy: 4.45661
Value Function Loss: 0.00246

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.26280
Value Function Update Magnitude: 0.46129

Collected Steps per Second: 21,132.00468
Overall Steps per Second: 9,932.81173

Timestep Collection Time: 2.36684
Timestep Consumption Time: 2.66860
PPO Batch Consumption Time: 0.31026
Total Iteration Time: 5.03543

Cumulative Model Updates: 312,374
Cumulative Timesteps: 2,605,074,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.24738
Policy Entropy: 4.45782
Value Function Loss: 0.00251

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00503
Policy Update Magnitude: 0.28588
Value Function Update Magnitude: 0.43177

Collected Steps per Second: 22,503.83325
Overall Steps per Second: 10,075.98111

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.74210
PPO Batch Consumption Time: 0.32370
Total Iteration Time: 4.96527

Cumulative Model Updates: 312,380
Cumulative Timesteps: 2,605,125,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2605125012...
Checkpoint 2605125012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.18238
Policy Entropy: 4.45329
Value Function Loss: 0.00226

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00489
Policy Update Magnitude: 0.28676
Value Function Update Magnitude: 0.49386

Collected Steps per Second: 20,140.57357
Overall Steps per Second: 10,179.72341

Timestep Collection Time: 2.48513
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.91683

Cumulative Model Updates: 312,386
Cumulative Timesteps: 2,605,175,064

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.61871
Policy Entropy: 4.45445
Value Function Loss: 0.00201

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00408
Policy Update Magnitude: 0.28263
Value Function Update Magnitude: 0.50465

Collected Steps per Second: 20,482.15632
Overall Steps per Second: 9,520.79279

Timestep Collection Time: 2.44174
Timestep Consumption Time: 2.81119
PPO Batch Consumption Time: 0.33096
Total Iteration Time: 5.25292

Cumulative Model Updates: 312,392
Cumulative Timesteps: 2,605,225,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2605225076...
Checkpoint 2605225076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.28392
Policy Entropy: 4.45267
Value Function Loss: 0.00212

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00461
Policy Update Magnitude: 0.26284
Value Function Update Magnitude: 0.49584

Collected Steps per Second: 18,673.40145
Overall Steps per Second: 9,644.88972

Timestep Collection Time: 2.67836
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 5.18554

Cumulative Model Updates: 312,398
Cumulative Timesteps: 2,605,275,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.07218
Policy Entropy: 4.45519
Value Function Loss: 0.00212

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00311
Policy Update Magnitude: 0.28942
Value Function Update Magnitude: 0.40986

Collected Steps per Second: 21,297.48151
Overall Steps per Second: 9,946.13738

Timestep Collection Time: 2.34854
Timestep Consumption Time: 2.68035
PPO Batch Consumption Time: 0.30820
Total Iteration Time: 5.02889

Cumulative Model Updates: 312,404
Cumulative Timesteps: 2,605,325,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2605325108...
Checkpoint 2605325108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.57510
Policy Entropy: 4.45448
Value Function Loss: 0.00198

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00355
Policy Update Magnitude: 0.28292
Value Function Update Magnitude: 0.41072

Collected Steps per Second: 20,170.85019
Overall Steps per Second: 9,722.87342

Timestep Collection Time: 2.47992
Timestep Consumption Time: 2.66486
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 5.14478

Cumulative Model Updates: 312,410
Cumulative Timesteps: 2,605,375,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.34235
Policy Entropy: 4.45331
Value Function Loss: 0.00186

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00326
Policy Update Magnitude: 0.25405
Value Function Update Magnitude: 0.40200

Collected Steps per Second: 22,004.64034
Overall Steps per Second: 10,568.25999

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.73115

Cumulative Model Updates: 312,416
Cumulative Timesteps: 2,605,425,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2605425130...
Checkpoint 2605425130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.92665
Policy Entropy: 4.44937
Value Function Loss: 0.00181

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.25720
Value Function Update Magnitude: 0.38538

Collected Steps per Second: 22,087.51242
Overall Steps per Second: 10,576.31997

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.46412
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.72811

Cumulative Model Updates: 312,422
Cumulative Timesteps: 2,605,475,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.66558
Policy Entropy: 4.45015
Value Function Loss: 0.00177

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.26853
Value Function Update Magnitude: 0.40168

Collected Steps per Second: 22,213.60709
Overall Steps per Second: 10,639.09374

Timestep Collection Time: 2.25159
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.70115

Cumulative Model Updates: 312,428
Cumulative Timesteps: 2,605,525,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2605525152...
Checkpoint 2605525152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.95949
Policy Entropy: 4.45168
Value Function Loss: 0.00169

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00418
Policy Update Magnitude: 0.26800
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 22,840.92552
Overall Steps per Second: 10,662.14346

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.69024

Cumulative Model Updates: 312,434
Cumulative Timesteps: 2,605,575,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.46333
Policy Entropy: 4.45568
Value Function Loss: 0.00151

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00294
Policy Update Magnitude: 0.24732
Value Function Update Magnitude: 0.37063

Collected Steps per Second: 22,438.53418
Overall Steps per Second: 10,742.67495

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.27515
Total Iteration Time: 4.65750

Cumulative Model Updates: 312,440
Cumulative Timesteps: 2,605,625,194

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2605625194...
Checkpoint 2605625194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.00508
Policy Entropy: 4.45282
Value Function Loss: 0.00152

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00304
Policy Update Magnitude: 0.23767
Value Function Update Magnitude: 0.36257

Collected Steps per Second: 22,780.11604
Overall Steps per Second: 10,758.20016

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.64910

Cumulative Model Updates: 312,446
Cumulative Timesteps: 2,605,675,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.10806
Policy Entropy: 4.45632
Value Function Loss: 0.00145

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00477
Policy Update Magnitude: 0.24289
Value Function Update Magnitude: 0.39597

Collected Steps per Second: 23,373.38762
Overall Steps per Second: 10,770.85857

Timestep Collection Time: 2.14021
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.64438

Cumulative Model Updates: 312,452
Cumulative Timesteps: 2,605,725,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2605725234...
Checkpoint 2605725234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.41182
Policy Entropy: 4.45899
Value Function Loss: 0.00134

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00298
Policy Update Magnitude: 0.24272
Value Function Update Magnitude: 0.34278

Collected Steps per Second: 22,875.49625
Overall Steps per Second: 10,645.49186

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.51198
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.69851

Cumulative Model Updates: 312,458
Cumulative Timesteps: 2,605,775,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.37029
Policy Entropy: 4.46455
Value Function Loss: 0.00126

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00274
Policy Update Magnitude: 0.21801
Value Function Update Magnitude: 0.31560

Collected Steps per Second: 22,907.83621
Overall Steps per Second: 10,851.89949

Timestep Collection Time: 2.18371
Timestep Consumption Time: 2.42599
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.60970

Cumulative Model Updates: 312,464
Cumulative Timesteps: 2,605,825,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2605825276...
Checkpoint 2605825276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.45354
Policy Entropy: 4.45789
Value Function Loss: 0.00136

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.21509
Value Function Update Magnitude: 0.32040

Collected Steps per Second: 22,687.12353
Overall Steps per Second: 10,640.67779

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.70158

Cumulative Model Updates: 312,470
Cumulative Timesteps: 2,605,875,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.33729
Policy Entropy: 4.45278
Value Function Loss: 0.00187

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00268
Policy Update Magnitude: 0.24387
Value Function Update Magnitude: 0.34597

Collected Steps per Second: 22,694.35936
Overall Steps per Second: 10,857.29611

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.40258
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.60630

Cumulative Model Updates: 312,476
Cumulative Timesteps: 2,605,925,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2605925316...
Checkpoint 2605925316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.53714
Policy Entropy: 4.44498
Value Function Loss: 0.00200

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00509
Policy Update Magnitude: 0.24973
Value Function Update Magnitude: 0.37576

Collected Steps per Second: 23,261.38663
Overall Steps per Second: 10,773.73539

Timestep Collection Time: 2.15086
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.64389

Cumulative Model Updates: 312,482
Cumulative Timesteps: 2,605,975,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.40522
Policy Entropy: 4.44851
Value Function Loss: 0.00220

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00352
Policy Update Magnitude: 0.27272
Value Function Update Magnitude: 0.38138

Collected Steps per Second: 22,491.46600
Overall Steps per Second: 10,785.09247

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.63844

Cumulative Model Updates: 312,488
Cumulative Timesteps: 2,606,025,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2606025374...
Checkpoint 2606025374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.75521
Policy Entropy: 4.45130
Value Function Loss: 0.00212

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.26818
Value Function Update Magnitude: 0.39685

Collected Steps per Second: 22,607.95479
Overall Steps per Second: 10,697.82491

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.67665

Cumulative Model Updates: 312,494
Cumulative Timesteps: 2,606,075,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.11377
Policy Entropy: 4.45637
Value Function Loss: 0.00228

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00323
Policy Update Magnitude: 0.25744
Value Function Update Magnitude: 0.37155

Collected Steps per Second: 23,821.53977
Overall Steps per Second: 10,944.41412

Timestep Collection Time: 2.09919
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.56909

Cumulative Model Updates: 312,500
Cumulative Timesteps: 2,606,125,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2606125410...
Checkpoint 2606125410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.07881
Policy Entropy: 4.45608
Value Function Loss: 0.00248

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00334
Policy Update Magnitude: 0.24931
Value Function Update Magnitude: 0.39696

Collected Steps per Second: 22,923.68064
Overall Steps per Second: 10,648.72623

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69821

Cumulative Model Updates: 312,506
Cumulative Timesteps: 2,606,175,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.22674
Policy Entropy: 4.46111
Value Function Loss: 0.00270

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.26926
Value Function Update Magnitude: 0.39933

Collected Steps per Second: 22,611.40676
Overall Steps per Second: 10,913.88724

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.37024
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.58169

Cumulative Model Updates: 312,512
Cumulative Timesteps: 2,606,225,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2606225444...
Checkpoint 2606225444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.12874
Policy Entropy: 4.45928
Value Function Loss: 0.00223

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.26766
Value Function Update Magnitude: 0.43700

Collected Steps per Second: 22,786.44424
Overall Steps per Second: 10,629.26404

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.70512

Cumulative Model Updates: 312,518
Cumulative Timesteps: 2,606,275,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.50866
Policy Entropy: 4.45793
Value Function Loss: 0.00197

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00360
Policy Update Magnitude: 0.26535
Value Function Update Magnitude: 0.42981

Collected Steps per Second: 22,101.86023
Overall Steps per Second: 10,594.27323

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.72368

Cumulative Model Updates: 312,524
Cumulative Timesteps: 2,606,325,500

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2606325500...
Checkpoint 2606325500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.98526
Policy Entropy: 4.45583
Value Function Loss: 0.00170

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.26473
Value Function Update Magnitude: 0.39259

Collected Steps per Second: 20,352.26610
Overall Steps per Second: 9,676.81223

Timestep Collection Time: 2.45732
Timestep Consumption Time: 2.71091
PPO Batch Consumption Time: 0.30271
Total Iteration Time: 5.16823

Cumulative Model Updates: 312,530
Cumulative Timesteps: 2,606,375,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.94320
Policy Entropy: 4.45405
Value Function Loss: 0.00198

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.26483
Value Function Update Magnitude: 0.41099

Collected Steps per Second: 20,655.42541
Overall Steps per Second: 10,168.51105

Timestep Collection Time: 2.42096
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.91773

Cumulative Model Updates: 312,536
Cumulative Timesteps: 2,606,425,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2606425518...
Checkpoint 2606425518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.37727
Policy Entropy: 4.46075
Value Function Loss: 0.00163

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00418
Policy Update Magnitude: 0.24603
Value Function Update Magnitude: 0.44002

Collected Steps per Second: 18,942.78202
Overall Steps per Second: 9,735.80674

Timestep Collection Time: 2.64016
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 5.13691

Cumulative Model Updates: 312,542
Cumulative Timesteps: 2,606,475,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.65407
Policy Entropy: 4.45828
Value Function Loss: 0.00176

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00508
Policy Update Magnitude: 0.23265
Value Function Update Magnitude: 0.42072

Collected Steps per Second: 21,783.43247
Overall Steps per Second: 10,410.44397

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.80767

Cumulative Model Updates: 312,548
Cumulative Timesteps: 2,606,525,580

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2606525580...
Checkpoint 2606525580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.96205
Policy Entropy: 4.46192
Value Function Loss: 0.00145

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00294
Policy Update Magnitude: 0.22493
Value Function Update Magnitude: 0.35090

Collected Steps per Second: 21,142.75580
Overall Steps per Second: 10,297.67701

Timestep Collection Time: 2.36488
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.85546

Cumulative Model Updates: 312,554
Cumulative Timesteps: 2,606,575,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.17944
Policy Entropy: 4.45625
Value Function Loss: 0.00156

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.22377
Value Function Update Magnitude: 0.36538

Collected Steps per Second: 19,720.38267
Overall Steps per Second: 9,827.42916

Timestep Collection Time: 2.53626
Timestep Consumption Time: 2.55317
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 5.08943

Cumulative Model Updates: 312,560
Cumulative Timesteps: 2,606,625,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2606625596...
Checkpoint 2606625596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.28136
Policy Entropy: 4.45727
Value Function Loss: 0.00166

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00432
Policy Update Magnitude: 0.22941
Value Function Update Magnitude: 0.35158

Collected Steps per Second: 22,089.62774
Overall Steps per Second: 10,708.00010

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.40715
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.67183

Cumulative Model Updates: 312,566
Cumulative Timesteps: 2,606,675,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.37577
Policy Entropy: 4.45270
Value Function Loss: 0.00177

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00436
Policy Update Magnitude: 0.27181
Value Function Update Magnitude: 0.38586

Collected Steps per Second: 20,877.32789
Overall Steps per Second: 10,500.62241

Timestep Collection Time: 2.39523
Timestep Consumption Time: 2.36696
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.76219

Cumulative Model Updates: 312,572
Cumulative Timesteps: 2,606,725,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2606725628...
Checkpoint 2606725628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.09095
Policy Entropy: 4.45336
Value Function Loss: 0.00177

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00461
Policy Update Magnitude: 0.27878
Value Function Update Magnitude: 0.39054

Collected Steps per Second: 22,521.13833
Overall Steps per Second: 10,688.22603

Timestep Collection Time: 2.22102
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.67992

Cumulative Model Updates: 312,578
Cumulative Timesteps: 2,606,775,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.59152
Policy Entropy: 4.45402
Value Function Loss: 0.00187

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.27755
Value Function Update Magnitude: 0.37688

Collected Steps per Second: 21,261.24125
Overall Steps per Second: 10,243.93797

Timestep Collection Time: 2.35207
Timestep Consumption Time: 2.52964
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.88172

Cumulative Model Updates: 312,584
Cumulative Timesteps: 2,606,825,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2606825656...
Checkpoint 2606825656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.66010
Policy Entropy: 4.45600
Value Function Loss: 0.00174

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00342
Policy Update Magnitude: 0.23905
Value Function Update Magnitude: 0.39795

Collected Steps per Second: 21,599.32632
Overall Steps per Second: 10,404.72846

Timestep Collection Time: 2.31516
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.80608

Cumulative Model Updates: 312,590
Cumulative Timesteps: 2,606,875,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.15532
Policy Entropy: 4.45922
Value Function Loss: 0.00161

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00297
Policy Update Magnitude: 0.22686
Value Function Update Magnitude: 0.35562

Collected Steps per Second: 21,702.43686
Overall Steps per Second: 10,385.66324

Timestep Collection Time: 2.30398
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.81452

Cumulative Model Updates: 312,596
Cumulative Timesteps: 2,606,925,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2606925664...
Checkpoint 2606925664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.28755
Policy Entropy: 4.45357
Value Function Loss: 0.00210

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00299
Policy Update Magnitude: 0.23778
Value Function Update Magnitude: 0.33930

Collected Steps per Second: 21,769.20757
Overall Steps per Second: 10,699.14906

Timestep Collection Time: 2.29728
Timestep Consumption Time: 2.37692
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.67420

Cumulative Model Updates: 312,602
Cumulative Timesteps: 2,606,975,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.76652
Policy Entropy: 4.45840
Value Function Loss: 0.00197

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00360
Policy Update Magnitude: 0.25114
Value Function Update Magnitude: 0.33617

Collected Steps per Second: 21,713.59446
Overall Steps per Second: 10,434.83857

Timestep Collection Time: 2.30289
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.79202

Cumulative Model Updates: 312,608
Cumulative Timesteps: 2,607,025,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2607025678...
Checkpoint 2607025678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.68931
Policy Entropy: 4.45755
Value Function Loss: 0.00210

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00327
Policy Update Magnitude: 0.24352
Value Function Update Magnitude: 0.35737

Collected Steps per Second: 22,128.47224
Overall Steps per Second: 10,719.54403

Timestep Collection Time: 2.25953
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.66438

Cumulative Model Updates: 312,614
Cumulative Timesteps: 2,607,075,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.71042
Policy Entropy: 4.46288
Value Function Loss: 0.00155

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00367
Policy Update Magnitude: 0.23606
Value Function Update Magnitude: 0.41569

Collected Steps per Second: 23,506.17753
Overall Steps per Second: 10,927.16284

Timestep Collection Time: 2.12719
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.57594

Cumulative Model Updates: 312,620
Cumulative Timesteps: 2,607,125,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2607125680...
Checkpoint 2607125680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.17679
Policy Entropy: 4.45678
Value Function Loss: 0.00157

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00296
Policy Update Magnitude: 0.22906
Value Function Update Magnitude: 0.38614

Collected Steps per Second: 22,665.24950
Overall Steps per Second: 10,606.54928

Timestep Collection Time: 2.20628
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71463

Cumulative Model Updates: 312,626
Cumulative Timesteps: 2,607,175,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.56464
Policy Entropy: 4.45664
Value Function Loss: 0.00162

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00444
Policy Update Magnitude: 0.25375
Value Function Update Magnitude: 0.38637

Collected Steps per Second: 22,526.64615
Overall Steps per Second: 10,913.18799

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.36211
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.58180

Cumulative Model Updates: 312,632
Cumulative Timesteps: 2,607,225,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2607225688...
Checkpoint 2607225688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.91245
Policy Entropy: 4.45459
Value Function Loss: 0.00137

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00498
Policy Update Magnitude: 0.23075
Value Function Update Magnitude: 0.37577

Collected Steps per Second: 22,298.00536
Overall Steps per Second: 10,495.82159

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.76494

Cumulative Model Updates: 312,638
Cumulative Timesteps: 2,607,275,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.43035
Policy Entropy: 4.45430
Value Function Loss: 0.00149

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.22449
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 21,361.12216
Overall Steps per Second: 10,386.03371

Timestep Collection Time: 2.34070
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.81416

Cumulative Model Updates: 312,644
Cumulative Timesteps: 2,607,325,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2607325700...
Checkpoint 2607325700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.87634
Policy Entropy: 4.45598
Value Function Loss: 0.00161

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00505
Policy Update Magnitude: 0.21252
Value Function Update Magnitude: 0.30954

Collected Steps per Second: 23,500.40729
Overall Steps per Second: 10,885.97583

Timestep Collection Time: 2.12762
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.59307

Cumulative Model Updates: 312,650
Cumulative Timesteps: 2,607,375,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.64015
Policy Entropy: 4.45484
Value Function Loss: 0.00266

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.24587
Value Function Update Magnitude: 0.40977

Collected Steps per Second: 22,114.64093
Overall Steps per Second: 10,286.90053

Timestep Collection Time: 2.26239
Timestep Consumption Time: 2.60127
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.86366

Cumulative Model Updates: 312,656
Cumulative Timesteps: 2,607,425,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2607425732...
Checkpoint 2607425732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.12494
Policy Entropy: 4.45725
Value Function Loss: 0.00236

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00540
Policy Update Magnitude: 0.28268
Value Function Update Magnitude: 0.43640

Collected Steps per Second: 21,538.37450
Overall Steps per Second: 10,300.89290

Timestep Collection Time: 2.32265
Timestep Consumption Time: 2.53383
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.85647

Cumulative Model Updates: 312,662
Cumulative Timesteps: 2,607,475,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.37495
Policy Entropy: 4.45561
Value Function Loss: 0.00286

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00689
Policy Update Magnitude: 0.33413
Value Function Update Magnitude: 0.39135

Collected Steps per Second: 20,016.07081
Overall Steps per Second: 10,105.48711

Timestep Collection Time: 2.49869
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.94919

Cumulative Model Updates: 312,668
Cumulative Timesteps: 2,607,525,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2607525772...
Checkpoint 2607525772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.26321
Policy Entropy: 4.46369
Value Function Loss: 0.00236

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00481
Policy Update Magnitude: 0.31418
Value Function Update Magnitude: 0.37182

Collected Steps per Second: 21,587.31458
Overall Steps per Second: 10,448.59369

Timestep Collection Time: 2.31701
Timestep Consumption Time: 2.47005
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.78706

Cumulative Model Updates: 312,674
Cumulative Timesteps: 2,607,575,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.94798
Policy Entropy: 4.46015
Value Function Loss: 0.00247

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00486
Policy Update Magnitude: 0.28925
Value Function Update Magnitude: 0.35507

Collected Steps per Second: 22,735.01876
Overall Steps per Second: 10,888.39185

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.39356
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.59352

Cumulative Model Updates: 312,680
Cumulative Timesteps: 2,607,625,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2607625806...
Checkpoint 2607625806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.05038
Policy Entropy: 4.45961
Value Function Loss: 0.00199

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00521
Policy Update Magnitude: 0.30363
Value Function Update Magnitude: 0.31810

Collected Steps per Second: 22,650.11304
Overall Steps per Second: 10,822.81412

Timestep Collection Time: 2.20802
Timestep Consumption Time: 2.41296
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.62098

Cumulative Model Updates: 312,686
Cumulative Timesteps: 2,607,675,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.23001
Policy Entropy: 4.45803
Value Function Loss: 0.00209

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00569
Policy Update Magnitude: 0.33209
Value Function Update Magnitude: 0.34997

Collected Steps per Second: 22,855.54406
Overall Steps per Second: 10,875.40487

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.41113
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.59992

Cumulative Model Updates: 312,692
Cumulative Timesteps: 2,607,725,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2607725844...
Checkpoint 2607725844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.73258
Policy Entropy: 4.46196
Value Function Loss: 0.00189

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00574
Policy Update Magnitude: 0.32848
Value Function Update Magnitude: 0.36181

Collected Steps per Second: 23,296.82395
Overall Steps per Second: 10,704.17616

Timestep Collection Time: 2.14622
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.67107

Cumulative Model Updates: 312,698
Cumulative Timesteps: 2,607,775,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.13943
Policy Entropy: 4.46455
Value Function Loss: 0.00180

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00468
Policy Update Magnitude: 0.29422
Value Function Update Magnitude: 0.37490

Collected Steps per Second: 23,115.63392
Overall Steps per Second: 10,872.42385

Timestep Collection Time: 2.16330
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.59934

Cumulative Model Updates: 312,704
Cumulative Timesteps: 2,607,825,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2607825850...
Checkpoint 2607825850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.15457
Policy Entropy: 4.46264
Value Function Loss: 0.00187

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.28014
Value Function Update Magnitude: 0.42466

Collected Steps per Second: 22,729.66026
Overall Steps per Second: 10,821.97677

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.62245

Cumulative Model Updates: 312,710
Cumulative Timesteps: 2,607,875,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.69530
Policy Entropy: 4.46026
Value Function Loss: 0.00203

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.28521
Value Function Update Magnitude: 0.42590

Collected Steps per Second: 23,117.32182
Overall Steps per Second: 10,785.66867

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.47419
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.63819

Cumulative Model Updates: 312,716
Cumulative Timesteps: 2,607,925,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2607925900...
Checkpoint 2607925900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.93215
Policy Entropy: 4.45532
Value Function Loss: 0.00191

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.39960

Collected Steps per Second: 22,716.28244
Overall Steps per Second: 10,371.97463

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.62067
PPO Batch Consumption Time: 0.31456
Total Iteration Time: 4.82261

Cumulative Model Updates: 312,722
Cumulative Timesteps: 2,607,975,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.72432
Policy Entropy: 4.45766
Value Function Loss: 0.00176

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00501
Policy Update Magnitude: 0.29300
Value Function Update Magnitude: 0.38948

Collected Steps per Second: 19,456.86688
Overall Steps per Second: 9,816.37197

Timestep Collection Time: 2.56999
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 5.09394

Cumulative Model Updates: 312,728
Cumulative Timesteps: 2,608,025,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2608025924...
Checkpoint 2608025924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.83156
Policy Entropy: 4.45952
Value Function Loss: 0.00137

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00292
Policy Update Magnitude: 0.24783
Value Function Update Magnitude: 0.38424

Collected Steps per Second: 21,675.03916
Overall Steps per Second: 10,161.37206

Timestep Collection Time: 2.30782
Timestep Consumption Time: 2.61494
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.92276

Cumulative Model Updates: 312,734
Cumulative Timesteps: 2,608,075,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.15590
Policy Entropy: 4.46023
Value Function Loss: 0.00142

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00244
Policy Update Magnitude: 0.23908
Value Function Update Magnitude: 0.45133

Collected Steps per Second: 19,870.48234
Overall Steps per Second: 9,944.61194

Timestep Collection Time: 2.51720
Timestep Consumption Time: 2.51246
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 5.02966

Cumulative Model Updates: 312,740
Cumulative Timesteps: 2,608,125,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2608125964...
Checkpoint 2608125964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.70545
Policy Entropy: 4.45596
Value Function Loss: 0.00156

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00283
Policy Update Magnitude: 0.23853
Value Function Update Magnitude: 0.42387

Collected Steps per Second: 21,312.25210
Overall Steps per Second: 10,360.44194

Timestep Collection Time: 2.34729
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.82856

Cumulative Model Updates: 312,746
Cumulative Timesteps: 2,608,175,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.21095
Policy Entropy: 4.45340
Value Function Loss: 0.00201

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.25852
Value Function Update Magnitude: 0.43104

Collected Steps per Second: 19,232.34781
Overall Steps per Second: 9,835.04157

Timestep Collection Time: 2.60093
Timestep Consumption Time: 2.48517
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 5.08610

Cumulative Model Updates: 312,752
Cumulative Timesteps: 2,608,226,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2608226012...
Checkpoint 2608226012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.17599
Policy Entropy: 4.45992
Value Function Loss: 0.00178

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.24627
Value Function Update Magnitude: 0.43145

Collected Steps per Second: 21,707.64053
Overall Steps per Second: 10,562.73264

Timestep Collection Time: 2.30426
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.73552

Cumulative Model Updates: 312,758
Cumulative Timesteps: 2,608,276,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.88337
Policy Entropy: 4.46295
Value Function Loss: 0.00151

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.21530
Value Function Update Magnitude: 0.39571

Collected Steps per Second: 22,408.93949
Overall Steps per Second: 10,502.57505

Timestep Collection Time: 2.23179
Timestep Consumption Time: 2.53009
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.76188

Cumulative Model Updates: 312,764
Cumulative Timesteps: 2,608,326,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2608326044...
Checkpoint 2608326044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.55062
Policy Entropy: 4.46370
Value Function Loss: 0.00158

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.21515
Value Function Update Magnitude: 0.38593

Collected Steps per Second: 21,680.46444
Overall Steps per Second: 10,332.37593

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.84051

Cumulative Model Updates: 312,770
Cumulative Timesteps: 2,608,376,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.35531
Policy Entropy: 4.46164
Value Function Loss: 0.00216

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00324
Policy Update Magnitude: 0.26249
Value Function Update Magnitude: 0.39432

Collected Steps per Second: 22,867.07790
Overall Steps per Second: 10,504.85768

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.57531
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.76370

Cumulative Model Updates: 312,776
Cumulative Timesteps: 2,608,426,100

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2608426100...
Checkpoint 2608426100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.59651
Policy Entropy: 4.46323
Value Function Loss: 0.00196

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00333
Policy Update Magnitude: 0.27879
Value Function Update Magnitude: 0.37627

Collected Steps per Second: 20,369.65744
Overall Steps per Second: 9,823.52455

Timestep Collection Time: 2.45571
Timestep Consumption Time: 2.63635
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 5.09206

Cumulative Model Updates: 312,782
Cumulative Timesteps: 2,608,476,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.83822
Policy Entropy: 4.46547
Value Function Loss: 0.00168

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.24860
Value Function Update Magnitude: 0.33663

Collected Steps per Second: 22,478.45231
Overall Steps per Second: 10,622.12474

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.70810

Cumulative Model Updates: 312,788
Cumulative Timesteps: 2,608,526,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2608526132...
Checkpoint 2608526132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.86286
Policy Entropy: 4.46443
Value Function Loss: 0.00189

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00336
Policy Update Magnitude: 0.24893
Value Function Update Magnitude: 0.41340

Collected Steps per Second: 21,763.07734
Overall Steps per Second: 10,390.66775

Timestep Collection Time: 2.29784
Timestep Consumption Time: 2.51494
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.81278

Cumulative Model Updates: 312,794
Cumulative Timesteps: 2,608,576,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.65837
Policy Entropy: 4.45669
Value Function Loss: 0.00203

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00346
Policy Update Magnitude: 0.25034
Value Function Update Magnitude: 0.41469

Collected Steps per Second: 22,329.43570
Overall Steps per Second: 10,596.01639

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.72026

Cumulative Model Updates: 312,800
Cumulative Timesteps: 2,608,626,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2608626156...
Checkpoint 2608626156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.01916
Policy Entropy: 4.45346
Value Function Loss: 0.00233

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.27543
Value Function Update Magnitude: 0.42291

Collected Steps per Second: 22,560.40064
Overall Steps per Second: 10,576.35196

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.72791

Cumulative Model Updates: 312,806
Cumulative Timesteps: 2,608,676,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.57307
Policy Entropy: 4.45267
Value Function Loss: 0.00224

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.25272
Value Function Update Magnitude: 0.41848

Collected Steps per Second: 22,283.07193
Overall Steps per Second: 10,507.97277

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.75867

Cumulative Model Updates: 312,812
Cumulative Timesteps: 2,608,726,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2608726164...
Checkpoint 2608726164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.69019
Policy Entropy: 4.45558
Value Function Loss: 0.00221

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00255
Policy Update Magnitude: 0.25433
Value Function Update Magnitude: 0.39235

Collected Steps per Second: 21,634.85823
Overall Steps per Second: 10,530.03522

Timestep Collection Time: 2.31136
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74889

Cumulative Model Updates: 312,818
Cumulative Timesteps: 2,608,776,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.80287
Policy Entropy: 4.45820
Value Function Loss: 0.00219

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00383
Policy Update Magnitude: 0.26259
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 22,397.07667
Overall Steps per Second: 10,483.87699

Timestep Collection Time: 2.23252
Timestep Consumption Time: 2.53690
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.76942

Cumulative Model Updates: 312,824
Cumulative Timesteps: 2,608,826,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2608826172...
Checkpoint 2608826172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.80376
Policy Entropy: 4.46473
Value Function Loss: 0.00168

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.22710
Value Function Update Magnitude: 0.32067

Collected Steps per Second: 22,008.86648
Overall Steps per Second: 10,307.53053

Timestep Collection Time: 2.27208
Timestep Consumption Time: 2.57932
PPO Batch Consumption Time: 0.30764
Total Iteration Time: 4.85140

Cumulative Model Updates: 312,830
Cumulative Timesteps: 2,608,876,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.44125
Policy Entropy: 4.46603
Value Function Loss: 0.00166

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00221
Policy Update Magnitude: 0.18667
Value Function Update Magnitude: 0.33126

Collected Steps per Second: 22,244.42355
Overall Steps per Second: 10,623.52675

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.70729

Cumulative Model Updates: 312,836
Cumulative Timesteps: 2,608,926,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2608926186...
Checkpoint 2608926186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.47084
Policy Entropy: 4.46520
Value Function Loss: 0.00154

Mean KL Divergence: 0.00017
SB3 Clip Fraction: 0.00189
Policy Update Magnitude: 0.19369
Value Function Update Magnitude: 0.37555

Collected Steps per Second: 22,129.85965
Overall Steps per Second: 10,453.05668

Timestep Collection Time: 2.26066
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.78597

Cumulative Model Updates: 312,842
Cumulative Timesteps: 2,608,976,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.08518
Policy Entropy: 4.45778
Value Function Loss: 0.00175

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00407
Policy Update Magnitude: 0.24857
Value Function Update Magnitude: 0.45814

Collected Steps per Second: 21,973.73230
Overall Steps per Second: 10,440.80856

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.51446
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.79082

Cumulative Model Updates: 312,848
Cumulative Timesteps: 2,609,026,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2609026234...
Checkpoint 2609026234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.05560
Policy Entropy: 4.45662
Value Function Loss: 0.00140

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00272
Policy Update Magnitude: 0.22941
Value Function Update Magnitude: 0.40856

Collected Steps per Second: 22,993.31815
Overall Steps per Second: 10,634.10473

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.52832
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.70373

Cumulative Model Updates: 312,854
Cumulative Timesteps: 2,609,076,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.10713
Policy Entropy: 4.45744
Value Function Loss: 0.00139

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00321
Policy Update Magnitude: 0.19867
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 22,180.69877
Overall Steps per Second: 10,449.26185

Timestep Collection Time: 2.25484
Timestep Consumption Time: 2.53152
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.78637

Cumulative Model Updates: 312,860
Cumulative Timesteps: 2,609,126,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2609126268...
Checkpoint 2609126268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.97955
Policy Entropy: 4.45862
Value Function Loss: 0.00164

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00284
Policy Update Magnitude: 0.22661
Value Function Update Magnitude: 0.33483

Collected Steps per Second: 21,924.81090
Overall Steps per Second: 10,674.05544

Timestep Collection Time: 2.28061
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68444

Cumulative Model Updates: 312,866
Cumulative Timesteps: 2,609,176,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.59812
Policy Entropy: 4.45783
Value Function Loss: 0.00152

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00316
Policy Update Magnitude: 0.23169
Value Function Update Magnitude: 0.30948

Collected Steps per Second: 22,424.09569
Overall Steps per Second: 10,466.56683

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.54758
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.77750

Cumulative Model Updates: 312,872
Cumulative Timesteps: 2,609,226,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2609226274...
Checkpoint 2609226274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.66740
Policy Entropy: 4.46070
Value Function Loss: 0.00178

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00294
Policy Update Magnitude: 0.23556
Value Function Update Magnitude: 0.30670

Collected Steps per Second: 22,000.29409
Overall Steps per Second: 10,499.25862

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.76243

Cumulative Model Updates: 312,878
Cumulative Timesteps: 2,609,276,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.84087
Policy Entropy: 4.46231
Value Function Loss: 0.00154

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00302
Policy Update Magnitude: 0.26531
Value Function Update Magnitude: 0.31467

Collected Steps per Second: 23,007.92401
Overall Steps per Second: 10,565.91467

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.55965
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.73333

Cumulative Model Updates: 312,884
Cumulative Timesteps: 2,609,326,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2609326288...
Checkpoint 2609326288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.49002
Policy Entropy: 4.45796
Value Function Loss: 0.00177

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.28456
Value Function Update Magnitude: 0.33470

Collected Steps per Second: 21,713.38257
Overall Steps per Second: 10,194.64806

Timestep Collection Time: 2.30319
Timestep Consumption Time: 2.60233
PPO Batch Consumption Time: 0.30433
Total Iteration Time: 4.90552

Cumulative Model Updates: 312,890
Cumulative Timesteps: 2,609,376,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.03301
Policy Entropy: 4.45540
Value Function Loss: 0.00168

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00351
Policy Update Magnitude: 0.27262
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 22,263.19154
Overall Steps per Second: 10,564.43233

Timestep Collection Time: 2.24667
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.73457

Cumulative Model Updates: 312,896
Cumulative Timesteps: 2,609,426,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2609426316...
Checkpoint 2609426316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.37534
Policy Entropy: 4.45337
Value Function Loss: 0.00153

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00320
Policy Update Magnitude: 0.25093
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 22,086.52435
Overall Steps per Second: 10,471.77264

Timestep Collection Time: 2.26464
Timestep Consumption Time: 2.51182
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.77646

Cumulative Model Updates: 312,902
Cumulative Timesteps: 2,609,476,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.68985
Policy Entropy: 4.45846
Value Function Loss: 0.00153

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.24224
Value Function Update Magnitude: 0.37255

Collected Steps per Second: 22,036.36975
Overall Steps per Second: 10,340.08861

Timestep Collection Time: 2.26979
Timestep Consumption Time: 2.56750
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.83729

Cumulative Model Updates: 312,908
Cumulative Timesteps: 2,609,526,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2609526352...
Checkpoint 2609526352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.89180
Policy Entropy: 4.45908
Value Function Loss: 0.00149

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00405
Policy Update Magnitude: 0.21315
Value Function Update Magnitude: 0.33261

Collected Steps per Second: 22,965.10749
Overall Steps per Second: 10,628.46529

Timestep Collection Time: 2.17739
Timestep Consumption Time: 2.52733
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.70472

Cumulative Model Updates: 312,914
Cumulative Timesteps: 2,609,576,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.17979
Policy Entropy: 4.46197
Value Function Loss: 0.00156

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.20281
Value Function Update Magnitude: 0.32603

Collected Steps per Second: 21,686.61805
Overall Steps per Second: 10,273.44935

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.56196
PPO Batch Consumption Time: 0.30155
Total Iteration Time: 4.86808

Cumulative Model Updates: 312,920
Cumulative Timesteps: 2,609,626,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2609626368...
Checkpoint 2609626368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61198
Policy Entropy: 4.45817
Value Function Loss: 0.00153

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.20810
Value Function Update Magnitude: 0.30924

Collected Steps per Second: 21,856.32277
Overall Steps per Second: 10,604.86665

Timestep Collection Time: 2.28858
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71670

Cumulative Model Updates: 312,926
Cumulative Timesteps: 2,609,676,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.30847
Policy Entropy: 4.46030
Value Function Loss: 0.00199

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.24628
Value Function Update Magnitude: 0.29637

Collected Steps per Second: 22,321.41861
Overall Steps per Second: 10,508.18730

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.51930
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.76029

Cumulative Model Updates: 312,932
Cumulative Timesteps: 2,609,726,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2609726410...
Checkpoint 2609726410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.51577
Policy Entropy: 4.45738
Value Function Loss: 0.00211

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00446
Policy Update Magnitude: 0.28246
Value Function Update Magnitude: 0.30666

Collected Steps per Second: 22,039.72923
Overall Steps per Second: 10,551.86312

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.74096

Cumulative Model Updates: 312,938
Cumulative Timesteps: 2,609,776,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.53819
Policy Entropy: 4.46141
Value Function Loss: 0.00240

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00376
Policy Update Magnitude: 0.27362
Value Function Update Magnitude: 0.37334

Collected Steps per Second: 22,722.73637
Overall Steps per Second: 10,550.63864

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.53973
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.74113

Cumulative Model Updates: 312,944
Cumulative Timesteps: 2,609,826,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2609826458...
Checkpoint 2609826458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.38588
Policy Entropy: 4.46086
Value Function Loss: 0.00197

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00388
Policy Update Magnitude: 0.27463
Value Function Update Magnitude: 0.42674

Collected Steps per Second: 22,325.88300
Overall Steps per Second: 10,572.46361

Timestep Collection Time: 2.24045
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73116

Cumulative Model Updates: 312,950
Cumulative Timesteps: 2,609,876,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.44891
Policy Entropy: 4.45886
Value Function Loss: 0.00199

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00374
Policy Update Magnitude: 0.26430
Value Function Update Magnitude: 0.48911

Collected Steps per Second: 21,973.94129
Overall Steps per Second: 10,468.79050

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.77858

Cumulative Model Updates: 312,956
Cumulative Timesteps: 2,609,926,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2609926504...
Checkpoint 2609926504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.81942
Policy Entropy: 4.45835
Value Function Loss: 0.00154

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00292
Policy Update Magnitude: 0.26593
Value Function Update Magnitude: 0.44030

Collected Steps per Second: 21,932.16197
Overall Steps per Second: 10,320.92883

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.56487
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.84472

Cumulative Model Updates: 312,962
Cumulative Timesteps: 2,609,976,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44689
Policy Entropy: 4.45903
Value Function Loss: 0.00168

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00391
Policy Update Magnitude: 0.24083
Value Function Update Magnitude: 0.33420

Collected Steps per Second: 22,212.61733
Overall Steps per Second: 10,440.01306

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.53982
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.79214

Cumulative Model Updates: 312,968
Cumulative Timesteps: 2,610,026,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2610026536...
Checkpoint 2610026536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.63979
Policy Entropy: 4.46159
Value Function Loss: 0.00197

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00472
Policy Update Magnitude: 0.25933
Value Function Update Magnitude: 0.34848

Collected Steps per Second: 22,242.19521
Overall Steps per Second: 10,520.77743

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 4.75497

Cumulative Model Updates: 312,974
Cumulative Timesteps: 2,610,076,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.27297
Policy Entropy: 4.45894
Value Function Loss: 0.00238

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00586
Policy Update Magnitude: 0.26781
Value Function Update Magnitude: 0.39891

Collected Steps per Second: 21,834.73111
Overall Steps per Second: 10,374.55602

Timestep Collection Time: 2.29103
Timestep Consumption Time: 2.53077
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.82180

Cumulative Model Updates: 312,980
Cumulative Timesteps: 2,610,126,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2610126586...
Checkpoint 2610126586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.93851
Policy Entropy: 4.45874
Value Function Loss: 0.00236

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00492
Policy Update Magnitude: 0.25840
Value Function Update Magnitude: 0.40418

Collected Steps per Second: 21,835.00509
Overall Steps per Second: 10,300.87517

Timestep Collection Time: 2.28990
Timestep Consumption Time: 2.56406
PPO Batch Consumption Time: 0.30894
Total Iteration Time: 4.85396

Cumulative Model Updates: 312,986
Cumulative Timesteps: 2,610,176,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.77518
Policy Entropy: 4.45957
Value Function Loss: 0.00183

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00370
Policy Update Magnitude: 0.25794
Value Function Update Magnitude: 0.37767

Collected Steps per Second: 22,213.91522
Overall Steps per Second: 10,522.99686

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.75264

Cumulative Model Updates: 312,992
Cumulative Timesteps: 2,610,226,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2610226598...
Checkpoint 2610226598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.76998
Policy Entropy: 4.46143
Value Function Loss: 0.00201

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.25655
Value Function Update Magnitude: 0.36914

Collected Steps per Second: 22,237.25706
Overall Steps per Second: 10,520.77898

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.50542
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.75516

Cumulative Model Updates: 312,998
Cumulative Timesteps: 2,610,276,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02704
Policy Entropy: 4.45551
Value Function Loss: 0.00244

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00630
Policy Update Magnitude: 0.24434
Value Function Update Magnitude: 0.38654

Collected Steps per Second: 22,268.38971
Overall Steps per Second: 10,573.30797

Timestep Collection Time: 2.24578
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.72983

Cumulative Model Updates: 313,004
Cumulative Timesteps: 2,610,326,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2610326636...
Checkpoint 2610326636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.38890
Policy Entropy: 4.45533
Value Function Loss: 0.00232

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00738
Policy Update Magnitude: 0.24463
Value Function Update Magnitude: 0.40672

Collected Steps per Second: 21,745.82897
Overall Steps per Second: 10,349.53159

Timestep Collection Time: 2.29966
Timestep Consumption Time: 2.53225
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.83191

Cumulative Model Updates: 313,010
Cumulative Timesteps: 2,610,376,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.37976
Policy Entropy: 4.45452
Value Function Loss: 0.00221

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.25838
Value Function Update Magnitude: 0.40798

Collected Steps per Second: 22,505.93504
Overall Steps per Second: 10,687.23975

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.67848

Cumulative Model Updates: 313,016
Cumulative Timesteps: 2,610,426,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2610426644...
Checkpoint 2610426644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.40633
Policy Entropy: 4.46015
Value Function Loss: 0.00215

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.26002
Value Function Update Magnitude: 0.36859

Collected Steps per Second: 21,921.86698
Overall Steps per Second: 10,356.44519

Timestep Collection Time: 2.28128
Timestep Consumption Time: 2.54759
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.82888

Cumulative Model Updates: 313,022
Cumulative Timesteps: 2,610,476,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.54170
Policy Entropy: 4.46053
Value Function Loss: 0.00226

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00416
Policy Update Magnitude: 0.27123
Value Function Update Magnitude: 0.40285

Collected Steps per Second: 22,259.88572
Overall Steps per Second: 10,416.15778

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.55506
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 4.80215

Cumulative Model Updates: 313,028
Cumulative Timesteps: 2,610,526,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2610526674...
Checkpoint 2610526674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.09000
Policy Entropy: 4.46111
Value Function Loss: 0.00215

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00351
Policy Update Magnitude: 0.24460
Value Function Update Magnitude: 0.50336

Collected Steps per Second: 22,044.75965
Overall Steps per Second: 10,575.48664

Timestep Collection Time: 2.26911
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.73000

Cumulative Model Updates: 313,034
Cumulative Timesteps: 2,610,576,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.15381
Policy Entropy: 4.45831
Value Function Loss: 0.00186

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00406
Policy Update Magnitude: 0.23383
Value Function Update Magnitude: 0.44359

Collected Steps per Second: 21,973.81766
Overall Steps per Second: 10,440.58923

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.78919

Cumulative Model Updates: 313,040
Cumulative Timesteps: 2,610,626,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2610626698...
Checkpoint 2610626698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.69609
Policy Entropy: 4.45356
Value Function Loss: 0.00193

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00452
Policy Update Magnitude: 0.25056
Value Function Update Magnitude: 0.35995

Collected Steps per Second: 22,115.49261
Overall Steps per Second: 10,650.36836

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.69618

Cumulative Model Updates: 313,046
Cumulative Timesteps: 2,610,676,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.39596
Policy Entropy: 4.45609
Value Function Loss: 0.00221

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.23340
Value Function Update Magnitude: 0.37658

Collected Steps per Second: 22,168.40812
Overall Steps per Second: 10,464.13758

Timestep Collection Time: 2.25691
Timestep Consumption Time: 2.52438
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.78128

Cumulative Model Updates: 313,052
Cumulative Timesteps: 2,610,726,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2610726746...
Checkpoint 2610726746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.09994
Policy Entropy: 4.45773
Value Function Loss: 0.00206

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.23433
Value Function Update Magnitude: 0.36961

Collected Steps per Second: 22,142.65465
Overall Steps per Second: 10,592.43363

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.72224

Cumulative Model Updates: 313,058
Cumulative Timesteps: 2,610,776,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.51546
Policy Entropy: 4.46055
Value Function Loss: 0.00187

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00392
Policy Update Magnitude: 0.22934
Value Function Update Magnitude: 0.34010

Collected Steps per Second: 21,985.11486
Overall Steps per Second: 10,412.19498

Timestep Collection Time: 2.27499
Timestep Consumption Time: 2.52860
PPO Batch Consumption Time: 0.30519
Total Iteration Time: 4.80360

Cumulative Model Updates: 313,064
Cumulative Timesteps: 2,610,826,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2610826782...
Checkpoint 2610826782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.36928
Policy Entropy: 4.46160
Value Function Loss: 0.00164

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00322
Policy Update Magnitude: 0.20982
Value Function Update Magnitude: 0.33420

Collected Steps per Second: 22,157.18336
Overall Steps per Second: 10,368.63362

Timestep Collection Time: 2.25715
Timestep Consumption Time: 2.56625
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.82339

Cumulative Model Updates: 313,070
Cumulative Timesteps: 2,610,876,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.76258
Policy Entropy: 4.45930
Value Function Loss: 0.00170

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00241
Policy Update Magnitude: 0.21795
Value Function Update Magnitude: 0.40431

Collected Steps per Second: 21,950.15571
Overall Steps per Second: 10,564.86088

Timestep Collection Time: 2.27807
Timestep Consumption Time: 2.45498
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.73305

Cumulative Model Updates: 313,076
Cumulative Timesteps: 2,610,926,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2610926798...
Checkpoint 2610926798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.82402
Policy Entropy: 4.46166
Value Function Loss: 0.00164

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00249
Policy Update Magnitude: 0.21412
Value Function Update Magnitude: 0.45376

Collected Steps per Second: 22,030.50120
Overall Steps per Second: 10,464.81853

Timestep Collection Time: 2.27058
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.78002

Cumulative Model Updates: 313,082
Cumulative Timesteps: 2,610,976,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.62314
Policy Entropy: 4.45949
Value Function Loss: 0.00197

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00427
Policy Update Magnitude: 0.23412
Value Function Update Magnitude: 0.37293

Collected Steps per Second: 22,118.73804
Overall Steps per Second: 10,494.04433

Timestep Collection Time: 2.26098
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.76556

Cumulative Model Updates: 313,088
Cumulative Timesteps: 2,611,026,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2611026830...
Checkpoint 2611026830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.24862
Policy Entropy: 4.45889
Value Function Loss: 0.00231

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.23319
Value Function Update Magnitude: 0.35188

Collected Steps per Second: 21,822.67464
Overall Steps per Second: 10,646.37346

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.40572
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.69737

Cumulative Model Updates: 313,094
Cumulative Timesteps: 2,611,076,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.91496
Policy Entropy: 4.46018
Value Function Loss: 0.00223

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.24603
Value Function Update Magnitude: 0.45474

Collected Steps per Second: 22,159.00669
Overall Steps per Second: 10,432.45922

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.79465

Cumulative Model Updates: 313,100
Cumulative Timesteps: 2,611,126,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2611126860...
Checkpoint 2611126860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.98726
Policy Entropy: 4.45852
Value Function Loss: 0.00207

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00315
Policy Update Magnitude: 0.24205
Value Function Update Magnitude: 0.37852

Collected Steps per Second: 22,033.23624
Overall Steps per Second: 10,681.01511

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.41210
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.68158

Cumulative Model Updates: 313,106
Cumulative Timesteps: 2,611,176,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.85639
Policy Entropy: 4.45920
Value Function Loss: 0.00191

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00309
Policy Update Magnitude: 0.23575
Value Function Update Magnitude: 0.37006

Collected Steps per Second: 22,444.68327
Overall Steps per Second: 10,384.69191

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.58749
PPO Batch Consumption Time: 0.30530
Total Iteration Time: 4.81555

Cumulative Model Updates: 313,112
Cumulative Timesteps: 2,611,226,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2611226872...
Checkpoint 2611226872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.85269
Policy Entropy: 4.45427
Value Function Loss: 0.00214

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00439
Policy Update Magnitude: 0.25338
Value Function Update Magnitude: 0.40861

Collected Steps per Second: 21,995.75065
Overall Steps per Second: 10,378.38270

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.54668
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.82175

Cumulative Model Updates: 313,118
Cumulative Timesteps: 2,611,276,914

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.80749
Policy Entropy: 4.45399
Value Function Loss: 0.00202

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.27603
Value Function Update Magnitude: 0.40814

Collected Steps per Second: 22,106.09156
Overall Steps per Second: 10,637.63410

Timestep Collection Time: 2.26282
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.70236

Cumulative Model Updates: 313,124
Cumulative Timesteps: 2,611,326,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2611326936...
Checkpoint 2611326936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.66435
Policy Entropy: 4.45219
Value Function Loss: 0.00209

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00640
Policy Update Magnitude: 0.26513
Value Function Update Magnitude: 0.45642

Collected Steps per Second: 22,270.13359
Overall Steps per Second: 10,334.07712

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.59465
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.84107

Cumulative Model Updates: 313,130
Cumulative Timesteps: 2,611,376,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.32981
Policy Entropy: 4.45120
Value Function Loss: 0.00182

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.26280
Value Function Update Magnitude: 0.43521

Collected Steps per Second: 21,722.91126
Overall Steps per Second: 10,431.74192

Timestep Collection Time: 2.30310
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.79594

Cumulative Model Updates: 313,136
Cumulative Timesteps: 2,611,426,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2611426994...
Checkpoint 2611426994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.30691
Policy Entropy: 4.45267
Value Function Loss: 0.00191

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00498
Policy Update Magnitude: 0.25183
Value Function Update Magnitude: 0.37365

Collected Steps per Second: 21,892.55206
Overall Steps per Second: 10,153.63521

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.64057
PPO Batch Consumption Time: 0.30802
Total Iteration Time: 4.92454

Cumulative Model Updates: 313,142
Cumulative Timesteps: 2,611,476,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.93609
Policy Entropy: 4.45297
Value Function Loss: 0.00229

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00406
Policy Update Magnitude: 0.28162
Value Function Update Magnitude: 0.37872

Collected Steps per Second: 21,416.75358
Overall Steps per Second: 10,252.53000

Timestep Collection Time: 2.33509
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.87782

Cumulative Model Updates: 313,148
Cumulative Timesteps: 2,611,527,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2611527006...
Checkpoint 2611527006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.02703
Policy Entropy: 4.45114
Value Function Loss: 0.00261

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.30516
Value Function Update Magnitude: 0.46553

Collected Steps per Second: 21,251.51263
Overall Steps per Second: 10,396.04092

Timestep Collection Time: 2.35277
Timestep Consumption Time: 2.45675
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.80952

Cumulative Model Updates: 313,154
Cumulative Timesteps: 2,611,577,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.87203
Policy Entropy: 4.45286
Value Function Loss: 0.00270

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00430
Policy Update Magnitude: 0.29743
Value Function Update Magnitude: 0.46628

Collected Steps per Second: 22,044.00146
Overall Steps per Second: 10,464.88821

Timestep Collection Time: 2.26937
Timestep Consumption Time: 2.51100
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.78037

Cumulative Model Updates: 313,160
Cumulative Timesteps: 2,611,627,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2611627032...
Checkpoint 2611627032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.79492
Policy Entropy: 4.45083
Value Function Loss: 0.00266

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00546
Policy Update Magnitude: 0.29595
Value Function Update Magnitude: 0.43658

Collected Steps per Second: 21,770.98248
Overall Steps per Second: 10,547.58446

Timestep Collection Time: 2.29792
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74308

Cumulative Model Updates: 313,166
Cumulative Timesteps: 2,611,677,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.74598
Policy Entropy: 4.45844
Value Function Loss: 0.00276

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00523
Policy Update Magnitude: 0.30888
Value Function Update Magnitude: 0.46538

Collected Steps per Second: 22,290.42619
Overall Steps per Second: 10,566.01793

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.73386

Cumulative Model Updates: 313,172
Cumulative Timesteps: 2,611,727,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2611727078...
Checkpoint 2611727078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.45773
Policy Entropy: 4.45505
Value Function Loss: 0.00279

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00514
Policy Update Magnitude: 0.30712
Value Function Update Magnitude: 0.49829

Collected Steps per Second: 22,090.27029
Overall Steps per Second: 10,452.55439

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.78486

Cumulative Model Updates: 313,178
Cumulative Timesteps: 2,611,777,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.35817
Policy Entropy: 4.45672
Value Function Loss: 0.00265

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.30115
Value Function Update Magnitude: 0.49495

Collected Steps per Second: 22,426.75682
Overall Steps per Second: 10,753.19365

Timestep Collection Time: 2.22966
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.65015

Cumulative Model Updates: 313,184
Cumulative Timesteps: 2,611,827,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2611827096...
Checkpoint 2611827096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.59882
Policy Entropy: 4.45057
Value Function Loss: 0.00284

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.00801
Policy Update Magnitude: 0.32058
Value Function Update Magnitude: 0.48831

Collected Steps per Second: 22,458.62226
Overall Steps per Second: 10,555.98611

Timestep Collection Time: 2.22658
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.73722

Cumulative Model Updates: 313,190
Cumulative Timesteps: 2,611,877,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.09049
Policy Entropy: 4.45721
Value Function Loss: 0.00224

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00890
Policy Update Magnitude: 0.28410
Value Function Update Magnitude: 0.45978

Collected Steps per Second: 21,841.07530
Overall Steps per Second: 10,525.90460

Timestep Collection Time: 2.28981
Timestep Consumption Time: 2.46151
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.75133

Cumulative Model Updates: 313,196
Cumulative Timesteps: 2,611,927,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2611927114...
Checkpoint 2611927114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.80173
Policy Entropy: 4.46050
Value Function Loss: 0.00176

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00614
Policy Update Magnitude: 0.23580
Value Function Update Magnitude: 0.39975

Collected Steps per Second: 22,043.72321
Overall Steps per Second: 10,508.60806

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.75819

Cumulative Model Updates: 313,202
Cumulative Timesteps: 2,611,977,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.81190
Policy Entropy: 4.46082
Value Function Loss: 0.00210

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00583
Policy Update Magnitude: 0.25128
Value Function Update Magnitude: 0.37446

Collected Steps per Second: 21,740.65280
Overall Steps per Second: 10,407.24013

Timestep Collection Time: 2.30048
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.80569

Cumulative Model Updates: 313,208
Cumulative Timesteps: 2,612,027,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2612027130...
Checkpoint 2612027130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.26694
Policy Entropy: 4.45978
Value Function Loss: 0.00209

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00465
Policy Update Magnitude: 0.25606
Value Function Update Magnitude: 0.38232

Collected Steps per Second: 22,515.12934
Overall Steps per Second: 10,798.18200

Timestep Collection Time: 2.22082
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.63059

Cumulative Model Updates: 313,214
Cumulative Timesteps: 2,612,077,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.18516
Policy Entropy: 4.45535
Value Function Loss: 0.00226

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00414
Policy Update Magnitude: 0.26032
Value Function Update Magnitude: 0.38282

Collected Steps per Second: 21,788.23340
Overall Steps per Second: 10,331.09823

Timestep Collection Time: 2.29500
Timestep Consumption Time: 2.54514
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.84014

Cumulative Model Updates: 313,220
Cumulative Timesteps: 2,612,127,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2612127136...
Checkpoint 2612127136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.35761
Policy Entropy: 4.46015
Value Function Loss: 0.00168

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00284
Policy Update Magnitude: 0.25182
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 22,146.32505
Overall Steps per Second: 10,667.29476

Timestep Collection Time: 2.25852
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.68891

Cumulative Model Updates: 313,226
Cumulative Timesteps: 2,612,177,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.60619
Policy Entropy: 4.45911
Value Function Loss: 0.00157

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00360
Policy Update Magnitude: 0.23331
Value Function Update Magnitude: 0.33913

Collected Steps per Second: 22,041.75920
Overall Steps per Second: 10,477.31709

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.50439
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.77336

Cumulative Model Updates: 313,232
Cumulative Timesteps: 2,612,227,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2612227166...
Checkpoint 2612227166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.99755
Policy Entropy: 4.45910
Value Function Loss: 0.00159

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.20409
Value Function Update Magnitude: 0.33479

Collected Steps per Second: 22,119.13406
Overall Steps per Second: 10,419.93279

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.53842
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.79926

Cumulative Model Updates: 313,238
Cumulative Timesteps: 2,612,277,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.13847
Policy Entropy: 4.45621
Value Function Loss: 0.00166

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00449
Policy Update Magnitude: 0.20594
Value Function Update Magnitude: 0.33462

Collected Steps per Second: 22,214.78344
Overall Steps per Second: 10,707.74495

Timestep Collection Time: 2.25156
Timestep Consumption Time: 2.41963
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.67120

Cumulative Model Updates: 313,244
Cumulative Timesteps: 2,612,327,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2612327192...
Checkpoint 2612327192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.62690
Policy Entropy: 4.45491
Value Function Loss: 0.00230

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00303
Policy Update Magnitude: 0.22409
Value Function Update Magnitude: 0.34749

Collected Steps per Second: 22,158.39157
Overall Steps per Second: 10,392.49038

Timestep Collection Time: 2.25775
Timestep Consumption Time: 2.55612
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.81386

Cumulative Model Updates: 313,250
Cumulative Timesteps: 2,612,377,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.28008
Policy Entropy: 4.45824
Value Function Loss: 0.00241

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.24844
Value Function Update Magnitude: 0.38592

Collected Steps per Second: 21,313.06372
Overall Steps per Second: 10,262.69924

Timestep Collection Time: 2.34645
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.30419
Total Iteration Time: 4.87299

Cumulative Model Updates: 313,256
Cumulative Timesteps: 2,612,427,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2612427230...
Checkpoint 2612427230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.55893
Policy Entropy: 4.45774
Value Function Loss: 0.00227

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00330
Policy Update Magnitude: 0.25570
Value Function Update Magnitude: 0.38885

Collected Steps per Second: 22,226.80292
Overall Steps per Second: 10,404.76535

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.55595
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.80549

Cumulative Model Updates: 313,262
Cumulative Timesteps: 2,612,477,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.47198
Policy Entropy: 4.46016
Value Function Loss: 0.00188

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00318
Policy Update Magnitude: 0.25631
Value Function Update Magnitude: 0.34526

Collected Steps per Second: 21,212.30373
Overall Steps per Second: 10,259.86551

Timestep Collection Time: 2.35759
Timestep Consumption Time: 2.51674
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.87433

Cumulative Model Updates: 313,268
Cumulative Timesteps: 2,612,527,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2612527240...
Checkpoint 2612527240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.71357
Policy Entropy: 4.46151
Value Function Loss: 0.00152

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00276
Policy Update Magnitude: 0.24305
Value Function Update Magnitude: 0.33906

Collected Steps per Second: 21,961.61928
Overall Steps per Second: 10,668.25545

Timestep Collection Time: 2.27770
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.68886

Cumulative Model Updates: 313,274
Cumulative Timesteps: 2,612,577,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.04763
Policy Entropy: 4.46341
Value Function Loss: 0.00151

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.24686
Value Function Update Magnitude: 0.32612

Collected Steps per Second: 22,107.39195
Overall Steps per Second: 10,445.53763

Timestep Collection Time: 2.26295
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.78941

Cumulative Model Updates: 313,280
Cumulative Timesteps: 2,612,627,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2612627290...
Checkpoint 2612627290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.41090
Policy Entropy: 4.46445
Value Function Loss: 0.00142

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00273
Policy Update Magnitude: 0.23974
Value Function Update Magnitude: 0.39282

Collected Steps per Second: 22,337.29041
Overall Steps per Second: 10,705.25397

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.67285

Cumulative Model Updates: 313,286
Cumulative Timesteps: 2,612,677,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.89323
Policy Entropy: 4.46327
Value Function Loss: 0.00122

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00282
Policy Update Magnitude: 0.20604
Value Function Update Magnitude: 0.35153

Collected Steps per Second: 22,338.68643
Overall Steps per Second: 10,390.71805

Timestep Collection Time: 2.23863
Timestep Consumption Time: 2.57413
PPO Batch Consumption Time: 0.30171
Total Iteration Time: 4.81276

Cumulative Model Updates: 313,292
Cumulative Timesteps: 2,612,727,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2612727322...
Checkpoint 2612727322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.66636
Policy Entropy: 4.45966
Value Function Loss: 0.00217

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00226
Policy Update Magnitude: 0.25537
Value Function Update Magnitude: 0.35730

Collected Steps per Second: 21,800.11860
Overall Steps per Second: 10,293.57003

Timestep Collection Time: 2.29485
Timestep Consumption Time: 2.56527
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.86012

Cumulative Model Updates: 313,298
Cumulative Timesteps: 2,612,777,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.41530
Policy Entropy: 4.45974
Value Function Loss: 0.00197

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.23729
Value Function Update Magnitude: 0.38524

Collected Steps per Second: 21,791.57972
Overall Steps per Second: 10,422.88562

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.80001

Cumulative Model Updates: 313,304
Cumulative Timesteps: 2,612,827,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2612827380...
Checkpoint 2612827380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16810
Policy Entropy: 4.46135
Value Function Loss: 0.00190

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00370
Policy Update Magnitude: 0.21513
Value Function Update Magnitude: 0.39626

Collected Steps per Second: 21,686.50476
Overall Steps per Second: 10,272.34195

Timestep Collection Time: 2.30595
Timestep Consumption Time: 2.56227
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.86822

Cumulative Model Updates: 313,310
Cumulative Timesteps: 2,612,877,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.21712
Policy Entropy: 4.46283
Value Function Loss: 0.00125

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00297
Policy Update Magnitude: 0.18295
Value Function Update Magnitude: 0.37267

Collected Steps per Second: 21,961.60154
Overall Steps per Second: 10,452.55452

Timestep Collection Time: 2.27725
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.30573
Total Iteration Time: 4.78467

Cumulative Model Updates: 313,316
Cumulative Timesteps: 2,612,927,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2612927400...
Checkpoint 2612927400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.30754
Policy Entropy: 4.46326
Value Function Loss: 0.00137

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.18738
Value Function Update Magnitude: 0.32479

Collected Steps per Second: 22,272.52766
Overall Steps per Second: 10,514.93340

Timestep Collection Time: 2.24707
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.75971

Cumulative Model Updates: 313,322
Cumulative Timesteps: 2,612,977,448

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.18700
Policy Entropy: 4.45863
Value Function Loss: 0.00159

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00251
Policy Update Magnitude: 0.20439
Value Function Update Magnitude: 0.36788

Collected Steps per Second: 22,435.92030
Overall Steps per Second: 10,582.60212

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.49697
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.72625

Cumulative Model Updates: 313,328
Cumulative Timesteps: 2,613,027,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2613027464...
Checkpoint 2613027464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.18287
Policy Entropy: 4.45839
Value Function Loss: 0.00146

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00325
Policy Update Magnitude: 0.21034
Value Function Update Magnitude: 0.33010

Collected Steps per Second: 21,935.88000
Overall Steps per Second: 10,579.31477

Timestep Collection Time: 2.28046
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.72847

Cumulative Model Updates: 313,334
Cumulative Timesteps: 2,613,077,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.09344
Policy Entropy: 4.46090
Value Function Loss: 0.00153

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00238
Policy Update Magnitude: 0.20269
Value Function Update Magnitude: 0.37519

Collected Steps per Second: 22,035.55511
Overall Steps per Second: 10,420.37964

Timestep Collection Time: 2.26942
Timestep Consumption Time: 2.52963
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.79906

Cumulative Model Updates: 313,340
Cumulative Timesteps: 2,613,127,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2613127496...
Checkpoint 2613127496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.99836
Policy Entropy: 4.46071
Value Function Loss: 0.00126

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00192
Policy Update Magnitude: 0.20802
Value Function Update Magnitude: 0.32359

Collected Steps per Second: 22,018.85473
Overall Steps per Second: 10,671.59854

Timestep Collection Time: 2.27096
Timestep Consumption Time: 2.41475
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68571

Cumulative Model Updates: 313,346
Cumulative Timesteps: 2,613,177,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.11172
Policy Entropy: 4.45736
Value Function Loss: 0.00179

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00274
Policy Update Magnitude: 0.26018
Value Function Update Magnitude: 0.32794

Collected Steps per Second: 22,152.04916
Overall Steps per Second: 10,405.89569

Timestep Collection Time: 2.25731
Timestep Consumption Time: 2.54804
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.80535

Cumulative Model Updates: 313,352
Cumulative Timesteps: 2,613,227,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2613227504...
Checkpoint 2613227504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.10053
Policy Entropy: 4.44945
Value Function Loss: 0.00207

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00249
Policy Update Magnitude: 0.25739
Value Function Update Magnitude: 0.35713

Collected Steps per Second: 22,085.46802
Overall Steps per Second: 10,444.25626

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.52339
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.78732

Cumulative Model Updates: 313,358
Cumulative Timesteps: 2,613,277,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.91675
Policy Entropy: 4.44897
Value Function Loss: 0.00250

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00332
Policy Update Magnitude: 0.27735
Value Function Update Magnitude: 0.39162

Collected Steps per Second: 22,330.67131
Overall Steps per Second: 10,722.48526

Timestep Collection Time: 2.24042
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.66590

Cumulative Model Updates: 313,364
Cumulative Timesteps: 2,613,327,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2613327534...
Checkpoint 2613327534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.85420
Policy Entropy: 4.45136
Value Function Loss: 0.00233

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00365
Policy Update Magnitude: 0.26981
Value Function Update Magnitude: 0.41948

Collected Steps per Second: 22,127.27704
Overall Steps per Second: 10,369.70562

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.56393
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.82521

Cumulative Model Updates: 313,370
Cumulative Timesteps: 2,613,377,570

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.22598
Policy Entropy: 4.45276
Value Function Loss: 0.00270

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00480
Policy Update Magnitude: 0.26638
Value Function Update Magnitude: 0.40466

Collected Steps per Second: 21,896.89383
Overall Steps per Second: 10,606.79466

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.71603

Cumulative Model Updates: 313,376
Cumulative Timesteps: 2,613,427,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2613427592...
Checkpoint 2613427592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.38530
Policy Entropy: 4.45097
Value Function Loss: 0.00274

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00634
Policy Update Magnitude: 0.26829
Value Function Update Magnitude: 0.38154

Collected Steps per Second: 21,428.42421
Overall Steps per Second: 10,317.67027

Timestep Collection Time: 2.33372
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.84683

Cumulative Model Updates: 313,382
Cumulative Timesteps: 2,613,477,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.58930
Policy Entropy: 4.45537
Value Function Loss: 0.00268

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00597
Policy Update Magnitude: 0.30278
Value Function Update Magnitude: 0.45533

Collected Steps per Second: 22,195.39124
Overall Steps per Second: 10,503.76403

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.50838
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.76191

Cumulative Model Updates: 313,388
Cumulative Timesteps: 2,613,527,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2613527618...
Checkpoint 2613527618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.13241
Policy Entropy: 4.45798
Value Function Loss: 0.00217

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.48989

Collected Steps per Second: 22,130.03660
Overall Steps per Second: 10,665.21705

Timestep Collection Time: 2.25964
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68870

Cumulative Model Updates: 313,394
Cumulative Timesteps: 2,613,577,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.60909
Policy Entropy: 4.46087
Value Function Loss: 0.00195

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00381
Policy Update Magnitude: 0.28061
Value Function Update Magnitude: 0.49303

Collected Steps per Second: 22,492.07475
Overall Steps per Second: 10,400.97921

Timestep Collection Time: 2.22372
Timestep Consumption Time: 2.58506
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.80878

Cumulative Model Updates: 313,400
Cumulative Timesteps: 2,613,627,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2613627640...
Checkpoint 2613627640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.44860
Policy Entropy: 4.45985
Value Function Loss: 0.00179

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.28756
Value Function Update Magnitude: 0.41934

Collected Steps per Second: 21,603.29488
Overall Steps per Second: 10,209.79281

Timestep Collection Time: 2.31474
Timestep Consumption Time: 2.58311
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 4.89785

Cumulative Model Updates: 313,406
Cumulative Timesteps: 2,613,677,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.43714
Policy Entropy: 4.45610
Value Function Loss: 0.00191

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00383
Policy Update Magnitude: 0.26389
Value Function Update Magnitude: 0.38907

Collected Steps per Second: 23,175.87296
Overall Steps per Second: 10,671.91551

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.52889
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 4.68726

Cumulative Model Updates: 313,412
Cumulative Timesteps: 2,613,727,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2613727668...
Checkpoint 2613727668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.29840
Policy Entropy: 4.45433
Value Function Loss: 0.00195

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00441
Policy Update Magnitude: 0.26405
Value Function Update Magnitude: 0.37685

Collected Steps per Second: 21,907.70751
Overall Steps per Second: 10,462.57455

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.78104

Cumulative Model Updates: 313,418
Cumulative Timesteps: 2,613,777,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.58884
Policy Entropy: 4.45462
Value Function Loss: 0.00181

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00372
Policy Update Magnitude: 0.25443
Value Function Update Magnitude: 0.33804

Collected Steps per Second: 22,224.53938
Overall Steps per Second: 10,551.41055

Timestep Collection Time: 2.25085
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.74098

Cumulative Model Updates: 313,424
Cumulative Timesteps: 2,613,827,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2613827714...
Checkpoint 2613827714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.67093
Policy Entropy: 4.45664
Value Function Loss: 0.00202

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00275
Policy Update Magnitude: 0.25059
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 22,128.39022
Overall Steps per Second: 10,551.27846

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.74161

Cumulative Model Updates: 313,430
Cumulative Timesteps: 2,613,877,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.92800
Policy Entropy: 4.45271
Value Function Loss: 0.00230

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.25981
Value Function Update Magnitude: 0.32043

Collected Steps per Second: 22,304.82675
Overall Steps per Second: 10,430.17236

Timestep Collection Time: 2.24265
Timestep Consumption Time: 2.55324
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.79589

Cumulative Model Updates: 313,436
Cumulative Timesteps: 2,613,927,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2613927766...
Checkpoint 2613927766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.26547
Policy Entropy: 4.44964
Value Function Loss: 0.00213

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00308
Policy Update Magnitude: 0.26124
Value Function Update Magnitude: 0.34153

Collected Steps per Second: 23,012.70325
Overall Steps per Second: 10,712.67343

Timestep Collection Time: 2.17454
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.67129

Cumulative Model Updates: 313,442
Cumulative Timesteps: 2,613,977,808

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.29690
Policy Entropy: 4.44894
Value Function Loss: 0.00193

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00408
Policy Update Magnitude: 0.23896
Value Function Update Magnitude: 0.33521

Collected Steps per Second: 22,439.85781
Overall Steps per Second: 10,424.35604

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.57013
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 4.79991

Cumulative Model Updates: 313,448
Cumulative Timesteps: 2,614,027,844

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2614027844...
Checkpoint 2614027844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.46861
Policy Entropy: 4.45637
Value Function Loss: 0.00166

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00389
Policy Update Magnitude: 0.22858
Value Function Update Magnitude: 0.29670

Collected Steps per Second: 21,719.10522
Overall Steps per Second: 10,534.89666

Timestep Collection Time: 2.30286
Timestep Consumption Time: 2.44479
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.74765

Cumulative Model Updates: 313,454
Cumulative Timesteps: 2,614,077,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.71368
Policy Entropy: 4.46305
Value Function Loss: 0.00174

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.22286
Value Function Update Magnitude: 0.28334

Collected Steps per Second: 21,908.17161
Overall Steps per Second: 10,477.63061

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.77283

Cumulative Model Updates: 313,460
Cumulative Timesteps: 2,614,127,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2614127868...
Checkpoint 2614127868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.93705
Policy Entropy: 4.46498
Value Function Loss: 0.00163

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00245
Policy Update Magnitude: 0.27547
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 21,582.22904
Overall Steps per Second: 10,273.94137

Timestep Collection Time: 2.31746
Timestep Consumption Time: 2.55078
PPO Batch Consumption Time: 0.30185
Total Iteration Time: 4.86824

Cumulative Model Updates: 313,466
Cumulative Timesteps: 2,614,177,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.26523
Policy Entropy: 4.45795
Value Function Loss: 0.00240

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00329
Policy Update Magnitude: 0.28000
Value Function Update Magnitude: 0.35419

Collected Steps per Second: 23,072.68116
Overall Steps per Second: 10,537.26707

Timestep Collection Time: 2.16811
Timestep Consumption Time: 2.57924
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.74734

Cumulative Model Updates: 313,472
Cumulative Timesteps: 2,614,227,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2614227908...
Checkpoint 2614227908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.68077
Policy Entropy: 4.45420
Value Function Loss: 0.00271

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00476
Policy Update Magnitude: 0.28257
Value Function Update Magnitude: 0.43751

Collected Steps per Second: 22,057.96715
Overall Steps per Second: 10,440.17208

Timestep Collection Time: 2.26757
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.79092

Cumulative Model Updates: 313,478
Cumulative Timesteps: 2,614,277,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.95561
Policy Entropy: 4.45207
Value Function Loss: 0.00260

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00545
Policy Update Magnitude: 0.28522
Value Function Update Magnitude: 0.46778

Collected Steps per Second: 22,207.24439
Overall Steps per Second: 10,543.01634

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.74551

Cumulative Model Updates: 313,484
Cumulative Timesteps: 2,614,327,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2614327958...
Checkpoint 2614327958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.14811
Policy Entropy: 4.45643
Value Function Loss: 0.00208

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00607
Policy Update Magnitude: 0.28739
Value Function Update Magnitude: 0.40619

Collected Steps per Second: 22,314.17377
Overall Steps per Second: 10,401.13774

Timestep Collection Time: 2.24082
Timestep Consumption Time: 2.56654
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.80736

Cumulative Model Updates: 313,490
Cumulative Timesteps: 2,614,377,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.38240
Policy Entropy: 4.45604
Value Function Loss: 0.00219

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.26436
Value Function Update Magnitude: 0.38263

Collected Steps per Second: 22,201.85109
Overall Steps per Second: 10,427.10209

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.54354
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.79596

Cumulative Model Updates: 313,496
Cumulative Timesteps: 2,614,427,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2614427968...
Checkpoint 2614427968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.78745
Policy Entropy: 4.45624
Value Function Loss: 0.00230

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00662
Policy Update Magnitude: 0.25242
Value Function Update Magnitude: 0.35090

Collected Steps per Second: 22,927.75411
Overall Steps per Second: 10,531.10830

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.56810
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 4.74974

Cumulative Model Updates: 313,502
Cumulative Timesteps: 2,614,477,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.57997
Policy Entropy: 4.45606
Value Function Loss: 0.00216

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00589
Policy Update Magnitude: 0.27294
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 22,276.04747
Overall Steps per Second: 10,431.62664

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.55008
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.79599

Cumulative Model Updates: 313,508
Cumulative Timesteps: 2,614,528,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2614528018...
Checkpoint 2614528018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.91074
Policy Entropy: 4.45603
Value Function Loss: 0.00213

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.26675
Value Function Update Magnitude: 0.33400

Collected Steps per Second: 22,061.50552
Overall Steps per Second: 10,682.75523

Timestep Collection Time: 2.26703
Timestep Consumption Time: 2.41473
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.68175

Cumulative Model Updates: 313,514
Cumulative Timesteps: 2,614,578,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.55126
Policy Entropy: 4.45366
Value Function Loss: 0.00242

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00287
Policy Update Magnitude: 0.26604
Value Function Update Magnitude: 0.40465

Collected Steps per Second: 22,513.07449
Overall Steps per Second: 10,430.79618

Timestep Collection Time: 2.22173
Timestep Consumption Time: 2.57349
PPO Batch Consumption Time: 0.30408
Total Iteration Time: 4.79522

Cumulative Model Updates: 313,520
Cumulative Timesteps: 2,614,628,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2614628050...
Checkpoint 2614628050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.84071
Policy Entropy: 4.45135
Value Function Loss: 0.00299

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00345
Policy Update Magnitude: 0.29899
Value Function Update Magnitude: 0.44489

Collected Steps per Second: 21,852.65741
Overall Steps per Second: 10,374.38581

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.82091

Cumulative Model Updates: 313,526
Cumulative Timesteps: 2,614,678,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.89074
Policy Entropy: 4.45184
Value Function Loss: 0.00291

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.42886

Collected Steps per Second: 22,271.55632
Overall Steps per Second: 10,476.25749

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.52970
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.77651

Cumulative Model Updates: 313,532
Cumulative Timesteps: 2,614,728,104

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2614728104...
Checkpoint 2614728104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.41691
Policy Entropy: 4.45461
Value Function Loss: 0.00288

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00612
Policy Update Magnitude: 0.30420
Value Function Update Magnitude: 0.40115

Collected Steps per Second: 22,057.91192
Overall Steps per Second: 10,485.97319

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.77114

Cumulative Model Updates: 313,538
Cumulative Timesteps: 2,614,778,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.58240
Policy Entropy: 4.45556
Value Function Loss: 0.00277

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00587
Policy Update Magnitude: 0.27838
Value Function Update Magnitude: 0.41099

Collected Steps per Second: 21,961.59202
Overall Steps per Second: 10,395.46031

Timestep Collection Time: 2.27807
Timestep Consumption Time: 2.53461
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.81268

Cumulative Model Updates: 313,544
Cumulative Timesteps: 2,614,828,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2614828164...
Checkpoint 2614828164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.10071
Policy Entropy: 4.45217
Value Function Loss: 0.00296

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.29536
Value Function Update Magnitude: 0.44637

Collected Steps per Second: 22,223.19396
Overall Steps per Second: 10,402.59507

Timestep Collection Time: 2.25026
Timestep Consumption Time: 2.55700
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.80726

Cumulative Model Updates: 313,550
Cumulative Timesteps: 2,614,878,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.19703
Policy Entropy: 4.45223
Value Function Loss: 0.00245

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00435
Policy Update Magnitude: 0.33650
Value Function Update Magnitude: 0.43334

Collected Steps per Second: 22,352.27829
Overall Steps per Second: 10,551.92127

Timestep Collection Time: 2.23745
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.73961

Cumulative Model Updates: 313,556
Cumulative Timesteps: 2,614,928,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2614928184...
Checkpoint 2614928184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.84250
Policy Entropy: 4.45212
Value Function Loss: 0.00229

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.38562

Collected Steps per Second: 22,201.73297
Overall Steps per Second: 10,716.43732

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.66629

Cumulative Model Updates: 313,562
Cumulative Timesteps: 2,614,978,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.17014
Policy Entropy: 4.45564
Value Function Loss: 0.00220

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00383
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.33302

Collected Steps per Second: 22,289.34443
Overall Steps per Second: 10,518.42915

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.51054
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.75394

Cumulative Model Updates: 313,568
Cumulative Timesteps: 2,615,028,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2615028194...
Checkpoint 2615028194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.01757
Policy Entropy: 4.45415
Value Function Loss: 0.00272

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.30650
Value Function Update Magnitude: 0.32860

Collected Steps per Second: 22,003.20799
Overall Steps per Second: 10,637.03227

Timestep Collection Time: 2.27276
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70131

Cumulative Model Updates: 313,574
Cumulative Timesteps: 2,615,078,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.22723
Policy Entropy: 4.45778
Value Function Loss: 0.00220

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00310
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.36789

Collected Steps per Second: 22,223.81657
Overall Steps per Second: 10,457.13828

Timestep Collection Time: 2.25101
Timestep Consumption Time: 2.53290
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.78391

Cumulative Model Updates: 313,580
Cumulative Timesteps: 2,615,128,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2615128228...
Checkpoint 2615128228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.82974
Policy Entropy: 4.45862
Value Function Loss: 0.00218

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00280
Policy Update Magnitude: 0.30706
Value Function Update Magnitude: 0.37884

Collected Steps per Second: 21,800.24610
Overall Steps per Second: 10,384.83421

Timestep Collection Time: 2.29401
Timestep Consumption Time: 2.52167
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.81568

Cumulative Model Updates: 313,586
Cumulative Timesteps: 2,615,178,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.39325
Policy Entropy: 4.45712
Value Function Loss: 0.00202

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00196
Policy Update Magnitude: 0.27579
Value Function Update Magnitude: 0.41078

Collected Steps per Second: 22,138.69577
Overall Steps per Second: 10,620.56292

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.70804

Cumulative Model Updates: 313,592
Cumulative Timesteps: 2,615,228,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2615228240...
Checkpoint 2615228240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.92753
Policy Entropy: 4.45358
Value Function Loss: 0.00233

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00231
Policy Update Magnitude: 0.30086
Value Function Update Magnitude: 0.40200

Collected Steps per Second: 22,038.48107
Overall Steps per Second: 10,377.72577

Timestep Collection Time: 2.26967
Timestep Consumption Time: 2.55027
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.81994

Cumulative Model Updates: 313,598
Cumulative Timesteps: 2,615,278,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.75595
Policy Entropy: 4.45403
Value Function Loss: 0.00256

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00315
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.37735

Collected Steps per Second: 21,955.50576
Overall Steps per Second: 10,441.69170

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.51116
PPO Batch Consumption Time: 0.30561
Total Iteration Time: 4.78850

Cumulative Model Updates: 313,604
Cumulative Timesteps: 2,615,328,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2615328260...
Checkpoint 2615328260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.92693
Policy Entropy: 4.45159
Value Function Loss: 0.00256

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.31380
Value Function Update Magnitude: 0.36326

Collected Steps per Second: 21,965.99040
Overall Steps per Second: 10,348.69062

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.55610
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.83308

Cumulative Model Updates: 313,610
Cumulative Timesteps: 2,615,378,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.28081
Policy Entropy: 4.45357
Value Function Loss: 0.00249

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00531
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.36394

Collected Steps per Second: 21,930.12840
Overall Steps per Second: 10,347.72048

Timestep Collection Time: 2.28079
Timestep Consumption Time: 2.55293
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.83372

Cumulative Model Updates: 313,616
Cumulative Timesteps: 2,615,428,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2615428294...
Checkpoint 2615428294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.95561
Policy Entropy: 4.45326
Value Function Loss: 0.00237

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.28923
Value Function Update Magnitude: 0.42823

Collected Steps per Second: 22,130.07235
Overall Steps per Second: 10,609.25316

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.45360
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.71306

Cumulative Model Updates: 313,622
Cumulative Timesteps: 2,615,478,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.44404
Policy Entropy: 4.45466
Value Function Loss: 0.00206

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.25575
Value Function Update Magnitude: 0.40096

Collected Steps per Second: 21,287.97752
Overall Steps per Second: 10,293.44252

Timestep Collection Time: 2.35053
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.86115

Cumulative Model Updates: 313,628
Cumulative Timesteps: 2,615,528,334

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2615528334...
Checkpoint 2615528334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.12154
Policy Entropy: 4.45427
Value Function Loss: 0.00189

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.25828
Value Function Update Magnitude: 0.38018

Collected Steps per Second: 21,980.70701
Overall Steps per Second: 10,653.93426

Timestep Collection Time: 2.27554
Timestep Consumption Time: 2.41925
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.69479

Cumulative Model Updates: 313,634
Cumulative Timesteps: 2,615,578,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.44788
Policy Entropy: 4.45249
Value Function Loss: 0.00188

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00407
Policy Update Magnitude: 0.24825
Value Function Update Magnitude: 0.34389

Collected Steps per Second: 22,614.36757
Overall Steps per Second: 10,579.38661

Timestep Collection Time: 2.21169
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72768

Cumulative Model Updates: 313,640
Cumulative Timesteps: 2,615,628,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2615628368...
Checkpoint 2615628368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.71630
Policy Entropy: 4.45148
Value Function Loss: 0.00190

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00427
Policy Update Magnitude: 0.23495
Value Function Update Magnitude: 0.35290

Collected Steps per Second: 21,609.86867
Overall Steps per Second: 10,271.76597

Timestep Collection Time: 2.31431
Timestep Consumption Time: 2.55457
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.86888

Cumulative Model Updates: 313,646
Cumulative Timesteps: 2,615,678,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.14386
Policy Entropy: 4.45320
Value Function Loss: 0.00207

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00445
Policy Update Magnitude: 0.24994
Value Function Update Magnitude: 0.34442

Collected Steps per Second: 22,228.94884
Overall Steps per Second: 10,673.66980

Timestep Collection Time: 2.25076
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.68742

Cumulative Model Updates: 313,652
Cumulative Timesteps: 2,615,728,412

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2615728412...
Checkpoint 2615728412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.73437
Policy Entropy: 4.45469
Value Function Loss: 0.00235

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00512
Policy Update Magnitude: 0.26761
Value Function Update Magnitude: 0.41985

Collected Steps per Second: 22,012.14511
Overall Steps per Second: 10,403.84736

Timestep Collection Time: 2.27193
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.80688

Cumulative Model Updates: 313,658
Cumulative Timesteps: 2,615,778,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.15330
Policy Entropy: 4.45737
Value Function Loss: 0.00207

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00379
Policy Update Magnitude: 0.28417
Value Function Update Magnitude: 0.39126

Collected Steps per Second: 21,607.37765
Overall Steps per Second: 10,342.97211

Timestep Collection Time: 2.31578
Timestep Consumption Time: 2.52209
PPO Batch Consumption Time: 0.30446
Total Iteration Time: 4.83787

Cumulative Model Updates: 313,664
Cumulative Timesteps: 2,615,828,460

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2615828460...
Checkpoint 2615828460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.94114
Policy Entropy: 4.45455
Value Function Loss: 0.00215

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00371
Policy Update Magnitude: 0.28334
Value Function Update Magnitude: 0.37849

Collected Steps per Second: 21,944.14431
Overall Steps per Second: 10,273.01013

Timestep Collection Time: 2.27924
Timestep Consumption Time: 2.58944
PPO Batch Consumption Time: 0.30426
Total Iteration Time: 4.86868

Cumulative Model Updates: 313,670
Cumulative Timesteps: 2,615,878,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.47969
Policy Entropy: 4.45340
Value Function Loss: 0.00212

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00403
Policy Update Magnitude: 0.26313
Value Function Update Magnitude: 0.33784

Collected Steps per Second: 22,052.04249
Overall Steps per Second: 10,443.77854

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.52149
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.79003

Cumulative Model Updates: 313,676
Cumulative Timesteps: 2,615,928,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2615928502...
Checkpoint 2615928502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.30078
Policy Entropy: 4.45403
Value Function Loss: 0.00233

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00692
Policy Update Magnitude: 0.24430
Value Function Update Magnitude: 0.32890

Collected Steps per Second: 21,690.24899
Overall Steps per Second: 10,567.18450

Timestep Collection Time: 2.30629
Timestep Consumption Time: 2.42761
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.73390

Cumulative Model Updates: 313,682
Cumulative Timesteps: 2,615,978,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.46909
Policy Entropy: 4.45680
Value Function Loss: 0.00200

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00525
Policy Update Magnitude: 0.23567
Value Function Update Magnitude: 0.33339

Collected Steps per Second: 21,622.88464
Overall Steps per Second: 10,153.13078

Timestep Collection Time: 2.31449
Timestep Consumption Time: 2.61463
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.92912

Cumulative Model Updates: 313,688
Cumulative Timesteps: 2,616,028,572

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2616028572...
Checkpoint 2616028572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.89610
Policy Entropy: 4.45861
Value Function Loss: 0.00215

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00330
Policy Update Magnitude: 0.23420
Value Function Update Magnitude: 0.30753

Collected Steps per Second: 21,558.61270
Overall Steps per Second: 10,504.94732

Timestep Collection Time: 2.32019
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.76157

Cumulative Model Updates: 313,694
Cumulative Timesteps: 2,616,078,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.56153
Policy Entropy: 4.45527
Value Function Loss: 0.00196

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00378
Policy Update Magnitude: 0.28973
Value Function Update Magnitude: 0.29168

Collected Steps per Second: 21,669.29927
Overall Steps per Second: 10,088.99089

Timestep Collection Time: 2.30861
Timestep Consumption Time: 2.64986
PPO Batch Consumption Time: 0.31020
Total Iteration Time: 4.95847

Cumulative Model Updates: 313,700
Cumulative Timesteps: 2,616,128,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2616128618...
Checkpoint 2616128618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.63342
Policy Entropy: 4.45155
Value Function Loss: 0.00221

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.30576

Collected Steps per Second: 22,027.15343
Overall Steps per Second: 10,387.56828

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.54433
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.81499

Cumulative Model Updates: 313,706
Cumulative Timesteps: 2,616,178,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.55760
Policy Entropy: 4.44710
Value Function Loss: 0.00211

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.28086
Value Function Update Magnitude: 0.30137

Collected Steps per Second: 22,077.72878
Overall Steps per Second: 10,612.65962

Timestep Collection Time: 2.26482
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.71154

Cumulative Model Updates: 313,712
Cumulative Timesteps: 2,616,228,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2616228636...
Checkpoint 2616228636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.81427
Policy Entropy: 4.44686
Value Function Loss: 0.00221

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00426
Policy Update Magnitude: 0.27298
Value Function Update Magnitude: 0.29161

Collected Steps per Second: 22,156.83641
Overall Steps per Second: 10,240.14231

Timestep Collection Time: 2.25808
Timestep Consumption Time: 2.62779
PPO Batch Consumption Time: 0.30920
Total Iteration Time: 4.88587

Cumulative Model Updates: 313,718
Cumulative Timesteps: 2,616,278,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.30835
Policy Entropy: 4.45466
Value Function Loss: 0.00172

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00491
Policy Update Magnitude: 0.24055
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 22,065.47452
Overall Steps per Second: 10,388.69069

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.54786
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.81466

Cumulative Model Updates: 313,724
Cumulative Timesteps: 2,616,328,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2616328686...
Checkpoint 2616328686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.40129
Policy Entropy: 4.45260
Value Function Loss: 0.00184

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00438
Policy Update Magnitude: 0.24375
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 22,948.29642
Overall Steps per Second: 10,661.89175

Timestep Collection Time: 2.17986
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.69185

Cumulative Model Updates: 313,730
Cumulative Timesteps: 2,616,378,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.33968
Policy Entropy: 4.45600
Value Function Loss: 0.00191

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00465
Policy Update Magnitude: 0.25336
Value Function Update Magnitude: 0.34349

Collected Steps per Second: 22,368.49162
Overall Steps per Second: 10,499.66906

Timestep Collection Time: 2.23556
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.76263

Cumulative Model Updates: 313,736
Cumulative Timesteps: 2,616,428,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2616428716...
Checkpoint 2616428716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.18954
Policy Entropy: 4.44985
Value Function Loss: 0.00224

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00445
Policy Update Magnitude: 0.28664
Value Function Update Magnitude: 0.32948

Collected Steps per Second: 22,306.36305
Overall Steps per Second: 10,725.14610

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.66325

Cumulative Model Updates: 313,742
Cumulative Timesteps: 2,616,478,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.44869
Policy Entropy: 4.45131
Value Function Loss: 0.00204

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00530
Policy Update Magnitude: 0.28496
Value Function Update Magnitude: 0.37077

Collected Steps per Second: 22,061.25711
Overall Steps per Second: 10,450.86585

Timestep Collection Time: 2.26669
Timestep Consumption Time: 2.51818
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.78487

Cumulative Model Updates: 313,748
Cumulative Timesteps: 2,616,528,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2616528736...
Checkpoint 2616528736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.15288
Policy Entropy: 4.44729
Value Function Loss: 0.00225

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00471
Policy Update Magnitude: 0.27635
Value Function Update Magnitude: 0.33059

Collected Steps per Second: 21,834.65034
Overall Steps per Second: 10,287.20716

Timestep Collection Time: 2.29012
Timestep Consumption Time: 2.57067
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.86079

Cumulative Model Updates: 313,754
Cumulative Timesteps: 2,616,578,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.34899
Policy Entropy: 4.45105
Value Function Loss: 0.00199

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00419
Policy Update Magnitude: 0.26402
Value Function Update Magnitude: 0.33277

Collected Steps per Second: 22,276.85613
Overall Steps per Second: 10,473.10769

Timestep Collection Time: 2.24484
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.77490

Cumulative Model Updates: 313,760
Cumulative Timesteps: 2,616,628,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2616628748...
Checkpoint 2616628748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.32126
Policy Entropy: 4.45429
Value Function Loss: 0.00188

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.24253
Value Function Update Magnitude: 0.33862

Collected Steps per Second: 21,406.92377
Overall Steps per Second: 10,209.66017

Timestep Collection Time: 2.33635
Timestep Consumption Time: 2.56235
PPO Batch Consumption Time: 0.30030
Total Iteration Time: 4.89869

Cumulative Model Updates: 313,766
Cumulative Timesteps: 2,616,678,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.39256
Policy Entropy: 4.45953
Value Function Loss: 0.00154

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00291
Policy Update Magnitude: 0.24301
Value Function Update Magnitude: 0.39117

Collected Steps per Second: 21,894.52365
Overall Steps per Second: 10,506.31636

Timestep Collection Time: 2.28468
Timestep Consumption Time: 2.47645
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 4.76114

Cumulative Model Updates: 313,772
Cumulative Timesteps: 2,616,728,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2616728784...
Checkpoint 2616728784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.59512
Policy Entropy: 4.46020
Value Function Loss: 0.00137

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00256
Policy Update Magnitude: 0.22307
Value Function Update Magnitude: 0.33578

Collected Steps per Second: 21,659.59330
Overall Steps per Second: 10,271.75004

Timestep Collection Time: 2.31057
Timestep Consumption Time: 2.56163
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.87220

Cumulative Model Updates: 313,778
Cumulative Timesteps: 2,616,778,830

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.40826
Policy Entropy: 4.45783
Value Function Loss: 0.00161

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00303
Policy Update Magnitude: 0.22288
Value Function Update Magnitude: 0.30387

Collected Steps per Second: 21,861.32411
Overall Steps per Second: 10,332.69890

Timestep Collection Time: 2.28824
Timestep Consumption Time: 2.55309
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.84133

Cumulative Model Updates: 313,784
Cumulative Timesteps: 2,616,828,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2616828854...
Checkpoint 2616828854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.09882
Policy Entropy: 4.45433
Value Function Loss: 0.00196

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00404
Policy Update Magnitude: 0.22564
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 22,826.57009
Overall Steps per Second: 10,649.13141

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.50579
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.69710

Cumulative Model Updates: 313,790
Cumulative Timesteps: 2,616,878,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.70019
Policy Entropy: 4.45226
Value Function Loss: 0.00206

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00444
Policy Update Magnitude: 0.23719
Value Function Update Magnitude: 0.37089

Collected Steps per Second: 21,764.44574
Overall Steps per Second: 10,364.83704

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.52749
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.82555

Cumulative Model Updates: 313,796
Cumulative Timesteps: 2,616,928,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2616928890...
Checkpoint 2616928890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.25137
Policy Entropy: 4.45455
Value Function Loss: 0.00204

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00272
Policy Update Magnitude: 0.25161
Value Function Update Magnitude: 0.37547

Collected Steps per Second: 22,016.06379
Overall Steps per Second: 10,623.48994

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70787

Cumulative Model Updates: 313,802
Cumulative Timesteps: 2,616,978,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.30871
Policy Entropy: 4.45936
Value Function Loss: 0.00142

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00293
Policy Update Magnitude: 0.23414
Value Function Update Magnitude: 0.37891

Collected Steps per Second: 21,725.90163
Overall Steps per Second: 10,416.78899

Timestep Collection Time: 2.30278
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.80282

Cumulative Model Updates: 313,808
Cumulative Timesteps: 2,617,028,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2617028934...
Checkpoint 2617028934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.78987
Policy Entropy: 4.45874
Value Function Loss: 0.00163

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00262
Policy Update Magnitude: 0.23427
Value Function Update Magnitude: 0.37230

Collected Steps per Second: 21,770.92753
Overall Steps per Second: 10,310.29606

Timestep Collection Time: 2.29793
Timestep Consumption Time: 2.55431
PPO Batch Consumption Time: 0.30478
Total Iteration Time: 4.85224

Cumulative Model Updates: 313,814
Cumulative Timesteps: 2,617,078,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.50663
Policy Entropy: 4.46535
Value Function Loss: 0.00155

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00359
Policy Update Magnitude: 0.24361
Value Function Update Magnitude: 0.34142

Collected Steps per Second: 22,528.88058
Overall Steps per Second: 10,498.52439

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.54432
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.76467

Cumulative Model Updates: 313,820
Cumulative Timesteps: 2,617,128,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2617128984...
Checkpoint 2617128984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.76196
Policy Entropy: 4.45684
Value Function Loss: 0.00198

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.26268
Value Function Update Magnitude: 0.34065

Collected Steps per Second: 22,424.71452
Overall Steps per Second: 10,559.56310

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.73637

Cumulative Model Updates: 313,826
Cumulative Timesteps: 2,617,178,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.50981
Policy Entropy: 4.45761
Value Function Loss: 0.00227

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00286
Policy Update Magnitude: 0.30381
Value Function Update Magnitude: 0.33252

Collected Steps per Second: 21,961.35665
Overall Steps per Second: 10,410.40294

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.80462

Cumulative Model Updates: 313,832
Cumulative Timesteps: 2,617,229,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2617229016...
Checkpoint 2617229016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.57861
Policy Entropy: 4.45149
Value Function Loss: 0.00213

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.29627
Value Function Update Magnitude: 0.36087

Collected Steps per Second: 22,663.57918
Overall Steps per Second: 10,576.11622

Timestep Collection Time: 2.20662
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.72858

Cumulative Model Updates: 313,838
Cumulative Timesteps: 2,617,279,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.02329
Policy Entropy: 4.45141
Value Function Loss: 0.00222

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00404
Policy Update Magnitude: 0.27897
Value Function Update Magnitude: 0.39747

Collected Steps per Second: 21,969.38213
Overall Steps per Second: 10,527.84587

Timestep Collection Time: 2.27772
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.75311

Cumulative Model Updates: 313,844
Cumulative Timesteps: 2,617,329,066

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2617329066...
Checkpoint 2617329066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.86874
Policy Entropy: 4.45231
Value Function Loss: 0.00202

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00428
Policy Update Magnitude: 0.26476
Value Function Update Magnitude: 0.37650

Collected Steps per Second: 21,696.49259
Overall Steps per Second: 10,600.78204

Timestep Collection Time: 2.30572
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.71909

Cumulative Model Updates: 313,850
Cumulative Timesteps: 2,617,379,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.13966
Policy Entropy: 4.45065
Value Function Loss: 0.00238

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00561
Policy Update Magnitude: 0.27811
Value Function Update Magnitude: 0.36323

Collected Steps per Second: 22,279.88223
Overall Steps per Second: 10,494.57748

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.52029
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.76456

Cumulative Model Updates: 313,856
Cumulative Timesteps: 2,617,429,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2617429094...
Checkpoint 2617429094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.23027
Policy Entropy: 4.45440
Value Function Loss: 0.00216

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00464
Policy Update Magnitude: 0.28534
Value Function Update Magnitude: 0.34500

Collected Steps per Second: 22,169.84302
Overall Steps per Second: 10,448.67416

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.53059
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.78644

Cumulative Model Updates: 313,862
Cumulative Timesteps: 2,617,479,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.34862
Policy Entropy: 4.45182
Value Function Loss: 0.00244

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.27847
Value Function Update Magnitude: 0.37769

Collected Steps per Second: 23,092.83650
Overall Steps per Second: 10,698.66875

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.50971
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.67610

Cumulative Model Updates: 313,868
Cumulative Timesteps: 2,617,529,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2617529134...
Checkpoint 2617529134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.77379
Policy Entropy: 4.45781
Value Function Loss: 0.00203

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.26750
Value Function Update Magnitude: 0.34536

Collected Steps per Second: 22,286.51737
Overall Steps per Second: 10,475.25973

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.53065
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.77506

Cumulative Model Updates: 313,874
Cumulative Timesteps: 2,617,579,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.98665
Policy Entropy: 4.45328
Value Function Loss: 0.00266

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00318
Policy Update Magnitude: 0.29740
Value Function Update Magnitude: 0.36285

Collected Steps per Second: 22,284.83732
Overall Steps per Second: 10,680.96443

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.68347

Cumulative Model Updates: 313,880
Cumulative Timesteps: 2,617,629,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2617629178...
Checkpoint 2617629178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.14851
Policy Entropy: 4.45380
Value Function Loss: 0.00253

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00314
Policy Update Magnitude: 0.29180
Value Function Update Magnitude: 0.39169

Collected Steps per Second: 22,491.46398
Overall Steps per Second: 10,590.33194

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.49952
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.72374

Cumulative Model Updates: 313,886
Cumulative Timesteps: 2,617,679,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.25790
Policy Entropy: 4.45289
Value Function Loss: 0.00246

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00404
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.36508

Collected Steps per Second: 22,013.08205
Overall Steps per Second: 10,480.53428

Timestep Collection Time: 2.27183
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.77170

Cumulative Model Updates: 313,892
Cumulative Timesteps: 2,617,729,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2617729214...
Checkpoint 2617729214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.33603
Policy Entropy: 4.46261
Value Function Loss: 0.00160

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00344
Policy Update Magnitude: 0.29456
Value Function Update Magnitude: 0.34216

Collected Steps per Second: 23,094.70422
Overall Steps per Second: 10,723.74193

Timestep Collection Time: 2.16534
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.66330

Cumulative Model Updates: 313,898
Cumulative Timesteps: 2,617,779,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.16789
Policy Entropy: 4.46382
Value Function Loss: 0.00171

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.26411
Value Function Update Magnitude: 0.35555

Collected Steps per Second: 22,267.68752
Overall Steps per Second: 10,376.59510

Timestep Collection Time: 2.24630
Timestep Consumption Time: 2.57416
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.82046

Cumulative Model Updates: 313,904
Cumulative Timesteps: 2,617,829,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2617829242...
Checkpoint 2617829242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.69755
Policy Entropy: 4.46078
Value Function Loss: 0.00193

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00290
Policy Update Magnitude: 0.30251
Value Function Update Magnitude: 0.42505

Collected Steps per Second: 21,853.02580
Overall Steps per Second: 10,371.22956

Timestep Collection Time: 2.28902
Timestep Consumption Time: 2.53413
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.82315

Cumulative Model Updates: 313,910
Cumulative Timesteps: 2,617,879,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.87424
Policy Entropy: 4.45409
Value Function Loss: 0.00211

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.30533
Value Function Update Magnitude: 0.37150

Collected Steps per Second: 22,781.90513
Overall Steps per Second: 10,573.68553

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.53552
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.73156

Cumulative Model Updates: 313,916
Cumulative Timesteps: 2,617,929,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2617929294...
Checkpoint 2617929294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.11925
Policy Entropy: 4.45916
Value Function Loss: 0.00170

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.33603

Collected Steps per Second: 22,064.73505
Overall Steps per Second: 10,381.35010

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.55078
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.81729

Cumulative Model Updates: 313,922
Cumulative Timesteps: 2,617,979,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.17611
Policy Entropy: 4.46081
Value Function Loss: 0.00157

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00285
Policy Update Magnitude: 0.27047
Value Function Update Magnitude: 0.34816

Collected Steps per Second: 21,904.67284
Overall Steps per Second: 10,452.87646

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.50125
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 4.78433

Cumulative Model Updates: 313,928
Cumulative Timesteps: 2,618,029,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2618029314...
Checkpoint 2618029314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.33678
Policy Entropy: 4.46156
Value Function Loss: 0.00163

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00400
Policy Update Magnitude: 0.33829
Value Function Update Magnitude: 0.33933

Collected Steps per Second: 22,209.52926
Overall Steps per Second: 10,417.80884

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.79986

Cumulative Model Updates: 313,934
Cumulative Timesteps: 2,618,079,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.74993
Policy Entropy: 4.45836
Value Function Loss: 0.00167

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00461
Policy Update Magnitude: 0.29246
Value Function Update Magnitude: 0.34360

Collected Steps per Second: 22,181.17521
Overall Steps per Second: 10,556.99270

Timestep Collection Time: 2.25498
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.73790

Cumulative Model Updates: 313,940
Cumulative Timesteps: 2,618,129,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2618129336...
Checkpoint 2618129336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.30349
Policy Entropy: 4.45648
Value Function Loss: 0.00199

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00377
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.34071

Collected Steps per Second: 22,981.28123
Overall Steps per Second: 10,647.04089

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.52177
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69858

Cumulative Model Updates: 313,946
Cumulative Timesteps: 2,618,179,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.42200
Policy Entropy: 4.45642
Value Function Loss: 0.00208

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00410
Policy Update Magnitude: 0.29596
Value Function Update Magnitude: 0.31003

Collected Steps per Second: 22,257.92713
Overall Steps per Second: 10,497.34730

Timestep Collection Time: 2.24675
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.76387

Cumulative Model Updates: 313,952
Cumulative Timesteps: 2,618,229,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2618229370...
Checkpoint 2618229370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.58834
Policy Entropy: 4.45612
Value Function Loss: 0.00216

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.28958
Value Function Update Magnitude: 0.35916

Collected Steps per Second: 21,705.18860
Overall Steps per Second: 10,459.28712

Timestep Collection Time: 2.30452
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.78235

Cumulative Model Updates: 313,958
Cumulative Timesteps: 2,618,279,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.24317
Policy Entropy: 4.45699
Value Function Loss: 0.00236

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00314
Policy Update Magnitude: 0.28942
Value Function Update Magnitude: 0.34732

Collected Steps per Second: 22,009.37630
Overall Steps per Second: 10,305.47031

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.58024
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.85218

Cumulative Model Updates: 313,964
Cumulative Timesteps: 2,618,329,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2618329394...
Checkpoint 2618329394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.59368
Policy Entropy: 4.45621
Value Function Loss: 0.00225

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00370
Policy Update Magnitude: 0.27589
Value Function Update Magnitude: 0.37793

Collected Steps per Second: 22,051.62591
Overall Steps per Second: 10,685.84069

Timestep Collection Time: 2.26750
Timestep Consumption Time: 2.41178
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.67928

Cumulative Model Updates: 313,970
Cumulative Timesteps: 2,618,379,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.30210
Policy Entropy: 4.45630
Value Function Loss: 0.00206

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.27203
Value Function Update Magnitude: 0.36258

Collected Steps per Second: 22,397.16457
Overall Steps per Second: 10,327.47710

Timestep Collection Time: 2.23368
Timestep Consumption Time: 2.61049
PPO Batch Consumption Time: 0.30561
Total Iteration Time: 4.84416

Cumulative Model Updates: 313,976
Cumulative Timesteps: 2,618,429,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2618429424...
Checkpoint 2618429424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.57506
Policy Entropy: 4.45666
Value Function Loss: 0.00161

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00300
Policy Update Magnitude: 0.25058
Value Function Update Magnitude: 0.31513

Collected Steps per Second: 21,814.56780
Overall Steps per Second: 10,266.93160

Timestep Collection Time: 2.29269
Timestep Consumption Time: 2.57868
PPO Batch Consumption Time: 0.30524
Total Iteration Time: 4.87137

Cumulative Model Updates: 313,982
Cumulative Timesteps: 2,618,479,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.18630
Policy Entropy: 4.45522
Value Function Loss: 0.00187

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.24671
Value Function Update Magnitude: 0.33802

Collected Steps per Second: 22,205.98682
Overall Steps per Second: 10,584.09056

Timestep Collection Time: 2.25201
Timestep Consumption Time: 2.47282
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.72483

Cumulative Model Updates: 313,988
Cumulative Timesteps: 2,618,529,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2618529446...
Checkpoint 2618529446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.11202
Policy Entropy: 4.45573
Value Function Loss: 0.00184

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00442
Policy Update Magnitude: 0.25341
Value Function Update Magnitude: 0.32315

Collected Steps per Second: 22,163.54836
Overall Steps per Second: 10,521.23796

Timestep Collection Time: 2.25677
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.75400

Cumulative Model Updates: 313,994
Cumulative Timesteps: 2,618,579,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.29558
Policy Entropy: 4.45493
Value Function Loss: 0.00200

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00460
Policy Update Magnitude: 0.24647
Value Function Update Magnitude: 0.36318

Collected Steps per Second: 22,416.01691
Overall Steps per Second: 10,376.65692

Timestep Collection Time: 2.23126
Timestep Consumption Time: 2.58879
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.82005

Cumulative Model Updates: 314,000
Cumulative Timesteps: 2,618,629,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2618629480...
Checkpoint 2618629480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.22814
Policy Entropy: 4.44890
Value Function Loss: 0.00242

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00531
Policy Update Magnitude: 0.28542
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 22,591.32996
Overall Steps per Second: 10,590.63652

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.72342

Cumulative Model Updates: 314,006
Cumulative Timesteps: 2,618,679,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.15589
Policy Entropy: 4.44926
Value Function Loss: 0.00255

Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00650
Policy Update Magnitude: 0.32166
Value Function Update Magnitude: 0.38447

Collected Steps per Second: 22,777.91650
Overall Steps per Second: 10,564.22462

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.53825
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.73371

Cumulative Model Updates: 314,012
Cumulative Timesteps: 2,618,729,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2618729512...
Checkpoint 2618729512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.52545
Policy Entropy: 4.44943
Value Function Loss: 0.00286

Mean KL Divergence: 0.00078
SB3 Clip Fraction: 0.00616
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.41555

Collected Steps per Second: 22,146.16799
Overall Steps per Second: 10,652.36140

Timestep Collection Time: 2.25836
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.69511

Cumulative Model Updates: 314,018
Cumulative Timesteps: 2,618,779,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.23205
Policy Entropy: 4.45435
Value Function Loss: 0.00246

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00461
Policy Update Magnitude: 0.28157
Value Function Update Magnitude: 0.40754

Collected Steps per Second: 22,170.34983
Overall Steps per Second: 10,462.43279

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.77958

Cumulative Model Updates: 314,024
Cumulative Timesteps: 2,618,829,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2618829532...
Checkpoint 2618829532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.02630
Policy Entropy: 4.45313
Value Function Loss: 0.00245

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.27729
Value Function Update Magnitude: 0.42353

Collected Steps per Second: 21,947.48304
Overall Steps per Second: 10,505.31824

Timestep Collection Time: 2.27899
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.76121

Cumulative Model Updates: 314,030
Cumulative Timesteps: 2,618,879,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.65087
Policy Entropy: 4.45166
Value Function Loss: 0.00229

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00549
Policy Update Magnitude: 0.25545
Value Function Update Magnitude: 0.42578

Collected Steps per Second: 23,501.78582
Overall Steps per Second: 10,651.49743

Timestep Collection Time: 2.12869
Timestep Consumption Time: 2.56812
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.69680

Cumulative Model Updates: 314,036
Cumulative Timesteps: 2,618,929,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2618929578...
Checkpoint 2618929578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.45626
Policy Entropy: 4.45366
Value Function Loss: 0.00205

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.25571
Value Function Update Magnitude: 0.38494

Collected Steps per Second: 21,848.70280
Overall Steps per Second: 10,350.71594

Timestep Collection Time: 2.28993
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.83368

Cumulative Model Updates: 314,042
Cumulative Timesteps: 2,618,979,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.25279
Policy Entropy: 4.45723
Value Function Loss: 0.00184

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00303
Policy Update Magnitude: 0.25723
Value Function Update Magnitude: 0.34623

Collected Steps per Second: 22,405.52723
Overall Steps per Second: 10,688.57264

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.68051

Cumulative Model Updates: 314,048
Cumulative Timesteps: 2,619,029,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2619029638...
Checkpoint 2619029638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.20798
Policy Entropy: 4.46228
Value Function Loss: 0.00135

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00371
Policy Update Magnitude: 0.23622
Value Function Update Magnitude: 0.30915

Collected Steps per Second: 22,169.62899
Overall Steps per Second: 10,454.97707

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.52859
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.78528

Cumulative Model Updates: 314,054
Cumulative Timesteps: 2,619,079,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.52284
Policy Entropy: 4.46176
Value Function Loss: 0.00111

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.20941
Value Function Update Magnitude: 0.28659

Collected Steps per Second: 22,224.52009
Overall Steps per Second: 10,409.99854

Timestep Collection Time: 2.25040
Timestep Consumption Time: 2.55402
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.80442

Cumulative Model Updates: 314,060
Cumulative Timesteps: 2,619,129,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2619129682...
Checkpoint 2619129682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.31932
Policy Entropy: 4.45910
Value Function Loss: 0.00144

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00344
Policy Update Magnitude: 0.18915
Value Function Update Magnitude: 0.26129

Collected Steps per Second: 22,160.82590
Overall Steps per Second: 10,531.64281

Timestep Collection Time: 2.25623
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.74760

Cumulative Model Updates: 314,066
Cumulative Timesteps: 2,619,179,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.06932
Policy Entropy: 4.45372
Value Function Loss: 0.00208

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00506
Policy Update Magnitude: 0.22616
Value Function Update Magnitude: 0.28937

Collected Steps per Second: 22,231.95251
Overall Steps per Second: 10,384.31498

Timestep Collection Time: 2.24911
Timestep Consumption Time: 2.56604
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.81515

Cumulative Model Updates: 314,072
Cumulative Timesteps: 2,619,229,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2619229684...
Checkpoint 2619229684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32503
Policy Entropy: 4.45536
Value Function Loss: 0.00229

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.26793
Value Function Update Magnitude: 0.32968

Collected Steps per Second: 21,965.86501
Overall Steps per Second: 10,372.20324

Timestep Collection Time: 2.27753
Timestep Consumption Time: 2.54574
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.82328

Cumulative Model Updates: 314,078
Cumulative Timesteps: 2,619,279,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.45828
Policy Entropy: 4.45720
Value Function Loss: 0.00189

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.34664

Collected Steps per Second: 22,708.27405
Overall Steps per Second: 10,616.59749

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.71111

Cumulative Model Updates: 314,084
Cumulative Timesteps: 2,619,329,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2619329728...
Checkpoint 2619329728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.35285
Policy Entropy: 4.46016
Value Function Loss: 0.00165

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00333
Policy Update Magnitude: 0.26761
Value Function Update Magnitude: 0.33793

Collected Steps per Second: 22,148.20302
Overall Steps per Second: 10,358.67964

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.57058
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.82919

Cumulative Model Updates: 314,090
Cumulative Timesteps: 2,619,379,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.41537
Policy Entropy: 4.45954
Value Function Loss: 0.00176

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.25810
Value Function Update Magnitude: 0.32785

Collected Steps per Second: 21,872.56002
Overall Steps per Second: 10,412.31623

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.51664
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.80316

Cumulative Model Updates: 314,096
Cumulative Timesteps: 2,619,429,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2619429764...
Checkpoint 2619429764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.66311
Policy Entropy: 4.45776
Value Function Loss: 0.00187

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.24563
Value Function Update Magnitude: 0.37788

Collected Steps per Second: 22,329.32609
Overall Steps per Second: 10,508.59393

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.51991
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.76010

Cumulative Model Updates: 314,102
Cumulative Timesteps: 2,619,479,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.20468
Policy Entropy: 4.45654
Value Function Loss: 0.00173

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.23128
Value Function Update Magnitude: 0.37759

Collected Steps per Second: 22,270.71248
Overall Steps per Second: 10,614.91991

Timestep Collection Time: 2.24618
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.71261

Cumulative Model Updates: 314,108
Cumulative Timesteps: 2,619,529,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2619529810...
Checkpoint 2619529810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.95034
Policy Entropy: 4.45593
Value Function Loss: 0.00170

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.23744
Value Function Update Magnitude: 0.34708

Collected Steps per Second: 21,846.69529
Overall Steps per Second: 10,628.35094

Timestep Collection Time: 2.28932
Timestep Consumption Time: 2.41640
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70572

Cumulative Model Updates: 314,114
Cumulative Timesteps: 2,619,579,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.36634
Policy Entropy: 4.45469
Value Function Loss: 0.00193

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.26248
Value Function Update Magnitude: 0.36092

Collected Steps per Second: 22,252.11488
Overall Steps per Second: 10,472.53439

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.77745

Cumulative Model Updates: 314,120
Cumulative Timesteps: 2,619,629,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2619629856...
Checkpoint 2619629856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.26138
Policy Entropy: 4.45751
Value Function Loss: 0.00198

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00272
Policy Update Magnitude: 0.26863
Value Function Update Magnitude: 0.33758

Collected Steps per Second: 21,962.47167
Overall Steps per Second: 10,461.69776

Timestep Collection Time: 2.27761
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.78144

Cumulative Model Updates: 314,126
Cumulative Timesteps: 2,619,679,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.13155
Policy Entropy: 4.45474
Value Function Loss: 0.00186

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.25673
Value Function Update Magnitude: 0.33550

Collected Steps per Second: 23,390.65980
Overall Steps per Second: 10,635.04084

Timestep Collection Time: 2.13820
Timestep Consumption Time: 2.56455
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70276

Cumulative Model Updates: 314,132
Cumulative Timesteps: 2,619,729,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2619729892...
Checkpoint 2619729892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.56688
Policy Entropy: 4.45591
Value Function Loss: 0.00200

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00572
Policy Update Magnitude: 0.26052
Value Function Update Magnitude: 0.31532

Collected Steps per Second: 21,578.90549
Overall Steps per Second: 10,239.75835

Timestep Collection Time: 2.31745
Timestep Consumption Time: 2.56626
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.88371

Cumulative Model Updates: 314,138
Cumulative Timesteps: 2,619,779,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.62762
Policy Entropy: 4.45135
Value Function Loss: 0.00217

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00554
Policy Update Magnitude: 0.26984
Value Function Update Magnitude: 0.33073

Collected Steps per Second: 22,205.90725
Overall Steps per Second: 10,548.76547

Timestep Collection Time: 2.25246
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.74160

Cumulative Model Updates: 314,144
Cumulative Timesteps: 2,619,829,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2619829918...
Checkpoint 2619829918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.05894
Policy Entropy: 4.45385
Value Function Loss: 0.00222

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.25778
Value Function Update Magnitude: 0.42349

Collected Steps per Second: 22,341.82247
Overall Steps per Second: 10,479.18878

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.53341
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.77136

Cumulative Model Updates: 314,150
Cumulative Timesteps: 2,619,879,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.03277
Policy Entropy: 4.45480
Value Function Loss: 0.00207

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.28299
Value Function Update Magnitude: 0.42390

Collected Steps per Second: 22,225.31907
Overall Steps per Second: 10,405.54928

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.55616
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.80647

Cumulative Model Updates: 314,156
Cumulative Timesteps: 2,619,929,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2619929932...
Checkpoint 2619929932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.77047
Policy Entropy: 4.45807
Value Function Loss: 0.00219

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.37024

Collected Steps per Second: 21,876.31630
Overall Steps per Second: 10,606.26815

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.71457

Cumulative Model Updates: 314,162
Cumulative Timesteps: 2,619,979,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.69401
Policy Entropy: 4.45855
Value Function Loss: 0.00251

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00462
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.35722

Collected Steps per Second: 22,684.41222
Overall Steps per Second: 10,535.48286

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.54242
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.74720

Cumulative Model Updates: 314,168
Cumulative Timesteps: 2,620,029,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2620029950...
Checkpoint 2620029950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.96083
Policy Entropy: 4.45944
Value Function Loss: 0.00224

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00344
Policy Update Magnitude: 0.28953
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 21,856.30660
Overall Steps per Second: 10,376.70820

Timestep Collection Time: 2.28868
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.82060

Cumulative Model Updates: 314,174
Cumulative Timesteps: 2,620,079,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.75560
Policy Entropy: 4.46072
Value Function Loss: 0.00233

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00446
Policy Update Magnitude: 0.26386
Value Function Update Magnitude: 0.33782

Collected Steps per Second: 22,878.17882
Overall Steps per Second: 10,499.25318

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.57758
PPO Batch Consumption Time: 0.30092
Total Iteration Time: 4.76377

Cumulative Model Updates: 314,180
Cumulative Timesteps: 2,620,129,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2620129988...
Checkpoint 2620129988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.45543
Policy Entropy: 4.45868
Value Function Loss: 0.00195

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00326
Policy Update Magnitude: 0.26863
Value Function Update Magnitude: 0.32519

Collected Steps per Second: 21,929.91207
Overall Steps per Second: 10,458.27378

Timestep Collection Time: 2.28045
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78186

Cumulative Model Updates: 314,186
Cumulative Timesteps: 2,620,179,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.28339
Policy Entropy: 4.45830
Value Function Loss: 0.00199

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00434
Policy Update Magnitude: 0.27155
Value Function Update Magnitude: 0.33385

Collected Steps per Second: 22,189.41377
Overall Steps per Second: 10,542.25090

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.74358

Cumulative Model Updates: 314,192
Cumulative Timesteps: 2,620,230,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2620230006...
Checkpoint 2620230006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.44915
Policy Entropy: 4.45771
Value Function Loss: 0.00207

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.26578
Value Function Update Magnitude: 0.36635

Collected Steps per Second: 21,936.25291
Overall Steps per Second: 10,462.38319

Timestep Collection Time: 2.27951
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.77941

Cumulative Model Updates: 314,198
Cumulative Timesteps: 2,620,280,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.47873
Policy Entropy: 4.45850
Value Function Loss: 0.00187

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00330
Policy Update Magnitude: 0.24519
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 22,312.20236
Overall Steps per Second: 10,506.50391

Timestep Collection Time: 2.24128
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.75972

Cumulative Model Updates: 314,204
Cumulative Timesteps: 2,620,330,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2620330018...
Checkpoint 2620330018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.98262
Policy Entropy: 4.45733
Value Function Loss: 0.00202

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00388
Policy Update Magnitude: 0.25427
Value Function Update Magnitude: 0.36114

Collected Steps per Second: 22,251.89359
Overall Steps per Second: 10,464.31037

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.53256
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.78082

Cumulative Model Updates: 314,210
Cumulative Timesteps: 2,620,380,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.02993
Policy Entropy: 4.45482
Value Function Loss: 0.00192

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.25034
Value Function Update Magnitude: 0.38305

Collected Steps per Second: 22,728.72437
Overall Steps per Second: 10,559.83281

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.53669
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.73795

Cumulative Model Updates: 314,216
Cumulative Timesteps: 2,620,430,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2620430078...
Checkpoint 2620430078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.34238
Policy Entropy: 4.46032
Value Function Loss: 0.00193

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00352
Policy Update Magnitude: 0.25114
Value Function Update Magnitude: 0.34111

Collected Steps per Second: 22,274.42193
Overall Steps per Second: 10,467.44711

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.53259
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.77786

Cumulative Model Updates: 314,222
Cumulative Timesteps: 2,620,480,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.65555
Policy Entropy: 4.45995
Value Function Loss: 0.00245

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00495
Policy Update Magnitude: 0.25568
Value Function Update Magnitude: 0.32431

Collected Steps per Second: 23,002.10160
Overall Steps per Second: 10,706.84822

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.67290

Cumulative Model Updates: 314,228
Cumulative Timesteps: 2,620,530,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2620530122...
Checkpoint 2620530122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.38979
Policy Entropy: 4.45885
Value Function Loss: 0.00221

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00486
Policy Update Magnitude: 0.25214
Value Function Update Magnitude: 0.35615

Collected Steps per Second: 21,469.40164
Overall Steps per Second: 10,097.36203

Timestep Collection Time: 2.32918
Timestep Consumption Time: 2.62321
PPO Batch Consumption Time: 0.31668
Total Iteration Time: 4.95238

Cumulative Model Updates: 314,234
Cumulative Timesteps: 2,620,580,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.53613
Policy Entropy: 4.45452
Value Function Loss: 0.00199

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.25948
Value Function Update Magnitude: 0.36133

Collected Steps per Second: 22,262.94409
Overall Steps per Second: 10,585.66537

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.47818
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.72469

Cumulative Model Updates: 314,240
Cumulative Timesteps: 2,620,630,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2620630142...
Checkpoint 2620630142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.73734
Policy Entropy: 4.45393
Value Function Loss: 0.00214

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.25102
Value Function Update Magnitude: 0.39051

Collected Steps per Second: 22,096.29438
Overall Steps per Second: 10,358.47655

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.56527
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.82909

Cumulative Model Updates: 314,246
Cumulative Timesteps: 2,620,680,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.91518
Policy Entropy: 4.45954
Value Function Loss: 0.00189

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.26031
Value Function Update Magnitude: 0.36364

Collected Steps per Second: 22,012.04162
Overall Steps per Second: 10,366.85470

Timestep Collection Time: 2.27212
Timestep Consumption Time: 2.55229
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.82441

Cumulative Model Updates: 314,252
Cumulative Timesteps: 2,620,730,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2620730178...
Checkpoint 2620730178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.68018
Policy Entropy: 4.46049
Value Function Loss: 0.00195

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.26779
Value Function Update Magnitude: 0.34701

Collected Steps per Second: 22,629.83590
Overall Steps per Second: 10,548.83861

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.53180
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.74251

Cumulative Model Updates: 314,258
Cumulative Timesteps: 2,620,780,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.15045
Policy Entropy: 4.45724
Value Function Loss: 0.00188

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00538
Policy Update Magnitude: 0.25886
Value Function Update Magnitude: 0.31827

Collected Steps per Second: 22,602.06691
Overall Steps per Second: 10,594.82130

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.72174

Cumulative Model Updates: 314,264
Cumulative Timesteps: 2,620,830,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2620830232...
Checkpoint 2620830232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.55028
Policy Entropy: 4.45573
Value Function Loss: 0.00178

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00486
Policy Update Magnitude: 0.27115
Value Function Update Magnitude: 0.31798

Collected Steps per Second: 22,034.84113
Overall Steps per Second: 10,574.98639

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.72908

Cumulative Model Updates: 314,270
Cumulative Timesteps: 2,620,880,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.09826
Policy Entropy: 4.45763
Value Function Loss: 0.00170

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.00595
Policy Update Magnitude: 0.24575
Value Function Update Magnitude: 0.32678

Collected Steps per Second: 22,176.20873
Overall Steps per Second: 10,451.18903

Timestep Collection Time: 2.25557
Timestep Consumption Time: 2.53049
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.78606

Cumulative Model Updates: 314,276
Cumulative Timesteps: 2,620,930,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2620930262...
Checkpoint 2620930262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.15146
Policy Entropy: 4.46111
Value Function Loss: 0.00250

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.00620
Policy Update Magnitude: 0.24280
Value Function Update Magnitude: 0.32443

Collected Steps per Second: 22,057.02585
Overall Steps per Second: 10,500.91163

Timestep Collection Time: 2.26721
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.76225

Cumulative Model Updates: 314,282
Cumulative Timesteps: 2,620,980,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.35891
Policy Entropy: 4.46068
Value Function Loss: 0.00269

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.00666
Policy Update Magnitude: 0.24896
Value Function Update Magnitude: 0.32799

Collected Steps per Second: 22,010.90044
Overall Steps per Second: 10,585.88382

Timestep Collection Time: 2.27224
Timestep Consumption Time: 2.45236
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.72459

Cumulative Model Updates: 314,288
Cumulative Timesteps: 2,621,030,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2621030284...
Checkpoint 2621030284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.11862
Policy Entropy: 4.46070
Value Function Loss: 0.00295

Mean KL Divergence: 0.00069
SB3 Clip Fraction: 0.00536
Policy Update Magnitude: 0.26879
Value Function Update Magnitude: 0.35382

Collected Steps per Second: 22,075.23256
Overall Steps per Second: 10,325.44202

Timestep Collection Time: 2.26516
Timestep Consumption Time: 2.57763
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.84280

Cumulative Model Updates: 314,294
Cumulative Timesteps: 2,621,080,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.98904
Policy Entropy: 4.45842
Value Function Loss: 0.00232

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00553
Policy Update Magnitude: 0.26659
Value Function Update Magnitude: 0.35321

Collected Steps per Second: 22,019.94971
Overall Steps per Second: 10,421.04363

Timestep Collection Time: 2.27094
Timestep Consumption Time: 2.52762
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.79856

Cumulative Model Updates: 314,300
Cumulative Timesteps: 2,621,130,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2621130294...
Checkpoint 2621130294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.11629
Policy Entropy: 4.45724
Value Function Loss: 0.00268

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00669
Policy Update Magnitude: 0.27382
Value Function Update Magnitude: 0.37462

Collected Steps per Second: 22,848.17077
Overall Steps per Second: 10,587.35451

Timestep Collection Time: 2.18888
Timestep Consumption Time: 2.53486
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.72375

Cumulative Model Updates: 314,306
Cumulative Timesteps: 2,621,180,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.53665
Policy Entropy: 4.46315
Value Function Loss: 0.00228

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00440
Policy Update Magnitude: 0.26519
Value Function Update Magnitude: 0.42474

Collected Steps per Second: 22,147.54894
Overall Steps per Second: 10,226.30865

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.63292
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 4.89150

Cumulative Model Updates: 314,312
Cumulative Timesteps: 2,621,230,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2621230328...
Checkpoint 2621230328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.50253
Policy Entropy: 4.46293
Value Function Loss: 0.00199

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00410
Policy Update Magnitude: 0.25776
Value Function Update Magnitude: 0.39954

Collected Steps per Second: 22,342.19734
Overall Steps per Second: 10,570.54566

Timestep Collection Time: 2.23819
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.73069

Cumulative Model Updates: 314,318
Cumulative Timesteps: 2,621,280,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.73493
Policy Entropy: 4.46252
Value Function Loss: 0.00172

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00374
Policy Update Magnitude: 0.24181
Value Function Update Magnitude: 0.35021

Collected Steps per Second: 22,244.27711
Overall Steps per Second: 10,387.58392

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.81421

Cumulative Model Updates: 314,324
Cumulative Timesteps: 2,621,330,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2621330342...
Checkpoint 2621330342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.68950
Policy Entropy: 4.46350
Value Function Loss: 0.00225

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.22478
Value Function Update Magnitude: 0.37450

Collected Steps per Second: 22,088.26491
Overall Steps per Second: 10,590.72446

Timestep Collection Time: 2.26437
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.72262

Cumulative Model Updates: 314,330
Cumulative Timesteps: 2,621,380,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.95038
Policy Entropy: 4.46130
Value Function Loss: 0.00277

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.26813
Value Function Update Magnitude: 0.44926

Collected Steps per Second: 22,903.44628
Overall Steps per Second: 10,532.23470

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.56569
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 4.74999

Cumulative Model Updates: 314,336
Cumulative Timesteps: 2,621,430,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2621430386...
Checkpoint 2621430386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.94440
Policy Entropy: 4.45848
Value Function Loss: 0.00265

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00464
Policy Update Magnitude: 0.28331
Value Function Update Magnitude: 0.39682

Collected Steps per Second: 22,092.65828
Overall Steps per Second: 10,484.19746

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.77194

Cumulative Model Updates: 314,342
Cumulative Timesteps: 2,621,480,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.48035
Policy Entropy: 4.45668
Value Function Loss: 0.00239

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00495
Policy Update Magnitude: 0.27306
Value Function Update Magnitude: 0.36104

Collected Steps per Second: 21,862.49432
Overall Steps per Second: 10,578.10241

Timestep Collection Time: 2.28821
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.72920

Cumulative Model Updates: 314,348
Cumulative Timesteps: 2,621,530,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2621530442...
Checkpoint 2621530442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.00409
Policy Entropy: 4.45339
Value Function Loss: 0.00182

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00449
Policy Update Magnitude: 0.26106
Value Function Update Magnitude: 0.36052

Collected Steps per Second: 22,339.45100
Overall Steps per Second: 10,614.82063

Timestep Collection Time: 2.23828
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.71058

Cumulative Model Updates: 314,354
Cumulative Timesteps: 2,621,580,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.12086
Policy Entropy: 4.46063
Value Function Loss: 0.00157

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00422
Policy Update Magnitude: 0.23221
Value Function Update Magnitude: 0.34241

Collected Steps per Second: 21,681.55930
Overall Steps per Second: 10,386.40307

Timestep Collection Time: 2.30611
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.81399

Cumulative Model Updates: 314,360
Cumulative Timesteps: 2,621,630,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2621630444...
Checkpoint 2621630444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.61950
Policy Entropy: 4.46030
Value Function Loss: 0.00119

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00304
Policy Update Magnitude: 0.21938
Value Function Update Magnitude: 0.31550

Collected Steps per Second: 22,987.97640
Overall Steps per Second: 10,719.02553

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.66610

Cumulative Model Updates: 314,366
Cumulative Timesteps: 2,621,680,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.86486
Policy Entropy: 4.46204
Value Function Loss: 0.00152

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00245
Policy Update Magnitude: 0.21638
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 21,892.00426
Overall Steps per Second: 10,432.90682

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.79521

Cumulative Model Updates: 314,372
Cumulative Timesteps: 2,621,730,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2621730488...
Checkpoint 2621730488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.36468
Policy Entropy: 4.45808
Value Function Loss: 0.00140

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00298
Policy Update Magnitude: 0.20357
Value Function Update Magnitude: 0.36409

Collected Steps per Second: 22,130.63757
Overall Steps per Second: 10,626.08901

Timestep Collection Time: 2.26003
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.70691

Cumulative Model Updates: 314,378
Cumulative Timesteps: 2,621,780,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.16066
Policy Entropy: 4.46243
Value Function Loss: 0.00130

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00281
Policy Update Magnitude: 0.18911
Value Function Update Magnitude: 0.37875

Collected Steps per Second: 22,156.68859
Overall Steps per Second: 10,480.72929

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.51521
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.77295

Cumulative Model Updates: 314,384
Cumulative Timesteps: 2,621,830,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2621830528...
Checkpoint 2621830528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.53995
Policy Entropy: 4.46740
Value Function Loss: 0.00142

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.18184
Value Function Update Magnitude: 0.33056

Collected Steps per Second: 22,134.38637
Overall Steps per Second: 10,393.99644

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.55195
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.81124

Cumulative Model Updates: 314,390
Cumulative Timesteps: 2,621,880,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.22585
Policy Entropy: 4.46391
Value Function Loss: 0.00172

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00287
Policy Update Magnitude: 0.20081
Value Function Update Magnitude: 0.30603

Collected Steps per Second: 22,915.91760
Overall Steps per Second: 10,546.13586

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.55918
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74107

Cumulative Model Updates: 314,396
Cumulative Timesteps: 2,621,930,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2621930536...
Checkpoint 2621930536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.56516
Policy Entropy: 4.45842
Value Function Loss: 0.00181

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.22351
Value Function Update Magnitude: 0.33532

Collected Steps per Second: 22,100.64355
Overall Steps per Second: 10,359.68532

Timestep Collection Time: 2.26346
Timestep Consumption Time: 2.56525
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.82872

Cumulative Model Updates: 314,402
Cumulative Timesteps: 2,621,980,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.47644
Policy Entropy: 4.45412
Value Function Loss: 0.00173

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00432
Policy Update Magnitude: 0.22923
Value Function Update Magnitude: 0.41332

Collected Steps per Second: 22,110.19804
Overall Steps per Second: 10,497.80601

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.30243
Total Iteration Time: 4.76557

Cumulative Model Updates: 314,408
Cumulative Timesteps: 2,622,030,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2622030588...
Checkpoint 2622030588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.82679
Policy Entropy: 4.45597
Value Function Loss: 0.00158

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00391
Policy Update Magnitude: 0.23453
Value Function Update Magnitude: 0.39043

Collected Steps per Second: 22,348.38435
Overall Steps per Second: 10,504.21602

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.52391
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.76228

Cumulative Model Updates: 314,414
Cumulative Timesteps: 2,622,080,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.36788
Policy Entropy: 4.45324
Value Function Loss: 0.00224

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00424
Policy Update Magnitude: 0.27365
Value Function Update Magnitude: 0.36161

Collected Steps per Second: 21,999.41929
Overall Steps per Second: 10,562.31964

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.73438

Cumulative Model Updates: 314,420
Cumulative Timesteps: 2,622,130,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2622130618...
Checkpoint 2622130618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.57883
Policy Entropy: 4.45558
Value Function Loss: 0.00236

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.35600

Collected Steps per Second: 22,002.11314
Overall Steps per Second: 10,632.67294

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70550

Cumulative Model Updates: 314,426
Cumulative Timesteps: 2,622,180,650

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.03858
Policy Entropy: 4.45241
Value Function Loss: 0.00259

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00487
Policy Update Magnitude: 0.31961
Value Function Update Magnitude: 0.35099

Collected Steps per Second: 22,270.81516
Overall Steps per Second: 10,474.47157

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.52842
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.77351

Cumulative Model Updates: 314,432
Cumulative Timesteps: 2,622,230,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2622230650...
Checkpoint 2622230650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.45592
Policy Entropy: 4.46205
Value Function Loss: 0.00180

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00513
Policy Update Magnitude: 0.29064
Value Function Update Magnitude: 0.36163

Collected Steps per Second: 22,170.66572
Overall Steps per Second: 10,539.93956

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.74519

Cumulative Model Updates: 314,438
Cumulative Timesteps: 2,622,280,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.92995
Policy Entropy: 4.45656
Value Function Loss: 0.00194

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.26129
Value Function Update Magnitude: 0.35111

Collected Steps per Second: 22,091.26068
Overall Steps per Second: 10,405.66257

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.54336
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.80815

Cumulative Model Updates: 314,444
Cumulative Timesteps: 2,622,330,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2622330696...
Checkpoint 2622330696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.55625
Policy Entropy: 4.46210
Value Function Loss: 0.00153

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.26603
Value Function Update Magnitude: 0.34869

Collected Steps per Second: 22,360.40218
Overall Steps per Second: 10,563.46670

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.73443

Cumulative Model Updates: 314,450
Cumulative Timesteps: 2,622,380,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.24319
Policy Entropy: 4.45823
Value Function Loss: 0.00216

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.28403
Value Function Update Magnitude: 0.33902

Collected Steps per Second: 22,390.49456
Overall Steps per Second: 10,678.52315

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68492

Cumulative Model Updates: 314,456
Cumulative Timesteps: 2,622,430,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2622430736...
Checkpoint 2622430736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.31876
Policy Entropy: 4.46153
Value Function Loss: 0.00188

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00446
Policy Update Magnitude: 0.29367
Value Function Update Magnitude: 0.33850

Collected Steps per Second: 22,382.06271
Overall Steps per Second: 10,530.26029

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.51529
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.75012

Cumulative Model Updates: 314,462
Cumulative Timesteps: 2,622,480,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.31423
Policy Entropy: 4.46004
Value Function Loss: 0.00251

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00585
Policy Update Magnitude: 0.27353
Value Function Update Magnitude: 0.39371

Collected Steps per Second: 22,138.78213
Overall Steps per Second: 10,408.87608

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.54654
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.80628

Cumulative Model Updates: 314,468
Cumulative Timesteps: 2,622,530,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2622530784...
Checkpoint 2622530784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.56332
Policy Entropy: 4.46204
Value Function Loss: 0.00195

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00366
Policy Update Magnitude: 0.24782
Value Function Update Magnitude: 0.42540

Collected Steps per Second: 22,828.87193
Overall Steps per Second: 10,475.11237

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.58342
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 4.77398

Cumulative Model Updates: 314,474
Cumulative Timesteps: 2,622,580,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.31850
Policy Entropy: 4.46251
Value Function Loss: 0.00193

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.23109
Value Function Update Magnitude: 0.46708

Collected Steps per Second: 22,243.64236
Overall Steps per Second: 10,343.36560

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.58618
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.83402

Cumulative Model Updates: 314,480
Cumulative Timesteps: 2,622,630,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2622630792...
Checkpoint 2622630792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.10092
Policy Entropy: 4.46113
Value Function Loss: 0.00175

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00283
Policy Update Magnitude: 0.24968
Value Function Update Magnitude: 0.47856

Collected Steps per Second: 22,206.62419
Overall Steps per Second: 10,627.96127

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.70514

Cumulative Model Updates: 314,486
Cumulative Timesteps: 2,622,680,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.93920
Policy Entropy: 4.45503
Value Function Loss: 0.00184

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.25369
Value Function Update Magnitude: 0.44587

Collected Steps per Second: 22,299.45846
Overall Steps per Second: 10,472.53318

Timestep Collection Time: 2.24310
Timestep Consumption Time: 2.53320
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.77630

Cumulative Model Updates: 314,492
Cumulative Timesteps: 2,622,730,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2622730818...
Checkpoint 2622730818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.35643
Policy Entropy: 4.45311
Value Function Loss: 0.00174

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.25602
Value Function Update Magnitude: 0.40336

Collected Steps per Second: 21,752.57800
Overall Steps per Second: 10,293.89770

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.55908
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.85802

Cumulative Model Updates: 314,498
Cumulative Timesteps: 2,622,780,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.79551
Policy Entropy: 4.45220
Value Function Loss: 0.00220

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00436
Policy Update Magnitude: 0.26790
Value Function Update Magnitude: 0.37988

Collected Steps per Second: 22,690.05861
Overall Steps per Second: 10,500.07516

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.55980
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.76473

Cumulative Model Updates: 314,504
Cumulative Timesteps: 2,622,830,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2622830856...
Checkpoint 2622830856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.14640
Policy Entropy: 4.45711
Value Function Loss: 0.00194

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00416
Policy Update Magnitude: 0.27838
Value Function Update Magnitude: 0.38540

Collected Steps per Second: 22,225.93553
Overall Steps per Second: 10,461.51554

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.53041
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.78057

Cumulative Model Updates: 314,510
Cumulative Timesteps: 2,622,880,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.47581
Policy Entropy: 4.45557
Value Function Loss: 0.00214

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.27081
Value Function Update Magnitude: 0.38314

Collected Steps per Second: 21,641.48800
Overall Steps per Second: 10,494.86424

Timestep Collection Time: 2.31112
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.76576

Cumulative Model Updates: 314,516
Cumulative Timesteps: 2,622,930,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2622930884...
Checkpoint 2622930884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.84377
Policy Entropy: 4.46065
Value Function Loss: 0.00206

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.27862
Value Function Update Magnitude: 0.35400

Collected Steps per Second: 22,130.48790
Overall Steps per Second: 10,479.84025

Timestep Collection Time: 2.26168
Timestep Consumption Time: 2.51435
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.77603

Cumulative Model Updates: 314,522
Cumulative Timesteps: 2,622,980,936

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.79123
Policy Entropy: 4.46017
Value Function Loss: 0.00220

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00443
Policy Update Magnitude: 0.28749
Value Function Update Magnitude: 0.33742

Collected Steps per Second: 22,129.04425
Overall Steps per Second: 10,487.31752

Timestep Collection Time: 2.26074
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.77033

Cumulative Model Updates: 314,528
Cumulative Timesteps: 2,623,030,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2623030964...
Checkpoint 2623030964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.48747
Policy Entropy: 4.46184
Value Function Loss: 0.00213

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.27324
Value Function Update Magnitude: 0.37396

Collected Steps per Second: 23,118.96775
Overall Steps per Second: 10,710.37921

Timestep Collection Time: 2.16350
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.67005

Cumulative Model Updates: 314,534
Cumulative Timesteps: 2,623,080,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.77427
Policy Entropy: 4.46186
Value Function Loss: 0.00160

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.29515
Value Function Update Magnitude: 0.37209

Collected Steps per Second: 21,980.74854
Overall Steps per Second: 10,423.47313

Timestep Collection Time: 2.27554
Timestep Consumption Time: 2.52306
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.79859

Cumulative Model Updates: 314,540
Cumulative Timesteps: 2,623,131,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2623131000...
Checkpoint 2623131000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.42330
Policy Entropy: 4.46041
Value Function Loss: 0.00150

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.25512
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 22,122.55241
Overall Steps per Second: 10,582.15228

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.46598
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.72720

Cumulative Model Updates: 314,546
Cumulative Timesteps: 2,623,181,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.02677
Policy Entropy: 4.45491
Value Function Loss: 0.00169

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.24630
Value Function Update Magnitude: 0.37231

Collected Steps per Second: 22,465.41642
Overall Steps per Second: 10,383.62901

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.59066
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 4.81720

Cumulative Model Updates: 314,552
Cumulative Timesteps: 2,623,231,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2623231044...
Checkpoint 2623231044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.35342
Policy Entropy: 4.45410
Value Function Loss: 0.00154

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00375
Policy Update Magnitude: 0.24231
Value Function Update Magnitude: 0.40102

Collected Steps per Second: 22,037.21928
Overall Steps per Second: 10,439.66218

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.52145
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.79115

Cumulative Model Updates: 314,558
Cumulative Timesteps: 2,623,281,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.95112
Policy Entropy: 4.45618
Value Function Loss: 0.00165

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.23138
Value Function Update Magnitude: 0.35182

Collected Steps per Second: 22,020.45005
Overall Steps per Second: 10,549.47700

Timestep Collection Time: 2.27089
Timestep Consumption Time: 2.46925
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.74014

Cumulative Model Updates: 314,564
Cumulative Timesteps: 2,623,331,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2623331068...
Checkpoint 2623331068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.23112
Policy Entropy: 4.45995
Value Function Loss: 0.00182

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00250
Policy Update Magnitude: 0.23991
Value Function Update Magnitude: 0.34141

Collected Steps per Second: 22,510.41327
Overall Steps per Second: 10,612.18051

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.71383

Cumulative Model Updates: 314,570
Cumulative Timesteps: 2,623,381,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.11645
Policy Entropy: 4.46167
Value Function Loss: 0.00184

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00278
Policy Update Magnitude: 0.25470
Value Function Update Magnitude: 0.33189

Collected Steps per Second: 22,406.32675
Overall Steps per Second: 10,614.72919

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.71081

Cumulative Model Updates: 314,576
Cumulative Timesteps: 2,623,431,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2623431096...
Checkpoint 2623431096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.56466
Policy Entropy: 4.46095
Value Function Loss: 0.00193

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.23577
Value Function Update Magnitude: 0.36082

Collected Steps per Second: 22,254.56697
Overall Steps per Second: 10,481.35909

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.77133

Cumulative Model Updates: 314,582
Cumulative Timesteps: 2,623,481,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.34272
Policy Entropy: 4.46073
Value Function Loss: 0.00170

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00254
Policy Update Magnitude: 0.23993
Value Function Update Magnitude: 0.35122

Collected Steps per Second: 22,029.32069
Overall Steps per Second: 10,406.64672

Timestep Collection Time: 2.27052
Timestep Consumption Time: 2.53583
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.80635

Cumulative Model Updates: 314,588
Cumulative Timesteps: 2,623,531,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2623531124...
Checkpoint 2623531124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.33728
Policy Entropy: 4.46063
Value Function Loss: 0.00177

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00275
Policy Update Magnitude: 0.23773
Value Function Update Magnitude: 0.33423

Collected Steps per Second: 22,161.34424
Overall Steps per Second: 10,627.63990

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.44951
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.70660

Cumulative Model Updates: 314,594
Cumulative Timesteps: 2,623,581,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.20814
Policy Entropy: 4.45548
Value Function Loss: 0.00229

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00496
Policy Update Magnitude: 0.24228
Value Function Update Magnitude: 0.35778

Collected Steps per Second: 22,424.65331
Overall Steps per Second: 10,463.69645

Timestep Collection Time: 2.23022
Timestep Consumption Time: 2.54935
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.77957

Cumulative Model Updates: 314,600
Cumulative Timesteps: 2,623,631,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2623631156...
Checkpoint 2623631156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.94188
Policy Entropy: 4.45842
Value Function Loss: 0.00209

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.25908
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 21,843.30513
Overall Steps per Second: 10,351.44361

Timestep Collection Time: 2.29040
Timestep Consumption Time: 2.54274
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.83314

Cumulative Model Updates: 314,606
Cumulative Timesteps: 2,623,681,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.20563
Policy Entropy: 4.45781
Value Function Loss: 0.00172

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00592
Policy Update Magnitude: 0.22627
Value Function Update Magnitude: 0.35512

Collected Steps per Second: 23,086.88051
Overall Steps per Second: 10,687.56725

Timestep Collection Time: 2.16669
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.68039

Cumulative Model Updates: 314,612
Cumulative Timesteps: 2,623,731,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2623731208...
Checkpoint 2623731208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.31941
Policy Entropy: 4.46362
Value Function Loss: 0.00130

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00345
Policy Update Magnitude: 0.19495
Value Function Update Magnitude: 0.39375

Collected Steps per Second: 22,184.79452
Overall Steps per Second: 10,439.86420

Timestep Collection Time: 2.25389
Timestep Consumption Time: 2.53564
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.78953

Cumulative Model Updates: 314,618
Cumulative Timesteps: 2,623,781,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.12492
Policy Entropy: 4.46076
Value Function Loss: 0.00135

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00562
Policy Update Magnitude: 0.18880
Value Function Update Magnitude: 0.40806

Collected Steps per Second: 22,169.03754
Overall Steps per Second: 10,684.87931

Timestep Collection Time: 2.25558
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67988

Cumulative Model Updates: 314,624
Cumulative Timesteps: 2,623,831,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2623831214...
Checkpoint 2623831214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.59049
Policy Entropy: 4.45773
Value Function Loss: 0.00142

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.21152
Value Function Update Magnitude: 0.39232

Collected Steps per Second: 21,596.49777
Overall Steps per Second: 10,134.98564

Timestep Collection Time: 2.31519
Timestep Consumption Time: 2.61822
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.93341

Cumulative Model Updates: 314,630
Cumulative Timesteps: 2,623,881,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.45734
Policy Entropy: 4.45804
Value Function Loss: 0.00155

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00358
Policy Update Magnitude: 0.20843
Value Function Update Magnitude: 0.38125

Collected Steps per Second: 21,845.68426
Overall Steps per Second: 10,634.72049

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.41338
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.70271

Cumulative Model Updates: 314,636
Cumulative Timesteps: 2,623,931,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2623931226...
Checkpoint 2623931226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.32348
Policy Entropy: 4.45985
Value Function Loss: 0.00160

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.21136
Value Function Update Magnitude: 0.42438

Collected Steps per Second: 23,818.87442
Overall Steps per Second: 10,938.00311

Timestep Collection Time: 2.09918
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.57122

Cumulative Model Updates: 314,642
Cumulative Timesteps: 2,623,981,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.78781
Policy Entropy: 4.46203
Value Function Loss: 0.00197

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00387
Policy Update Magnitude: 0.24157
Value Function Update Magnitude: 0.45563

Collected Steps per Second: 23,019.70829
Overall Steps per Second: 10,703.54796

Timestep Collection Time: 2.17327
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67396

Cumulative Model Updates: 314,648
Cumulative Timesteps: 2,624,031,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2624031254...
Checkpoint 2624031254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.75771
Policy Entropy: 4.46337
Value Function Loss: 0.00184

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.27282
Value Function Update Magnitude: 0.41810

Collected Steps per Second: 22,849.30202
Overall Steps per Second: 11,046.01206

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.33874
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.52743

Cumulative Model Updates: 314,654
Cumulative Timesteps: 2,624,081,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.88718
Policy Entropy: 4.45985
Value Function Loss: 0.00210

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00408
Policy Update Magnitude: 0.28980
Value Function Update Magnitude: 0.43536

Collected Steps per Second: 23,262.69397
Overall Steps per Second: 10,793.12744

Timestep Collection Time: 2.15048
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.63499

Cumulative Model Updates: 314,660
Cumulative Timesteps: 2,624,131,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2624131290...
Checkpoint 2624131290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.54358
Policy Entropy: 4.45831
Value Function Loss: 0.00191

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.00535
Policy Update Magnitude: 0.28314
Value Function Update Magnitude: 0.47134

Collected Steps per Second: 22,727.42865
Overall Steps per Second: 10,912.08657

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.38314
PPO Batch Consumption Time: 0.27352
Total Iteration Time: 4.58409

Cumulative Model Updates: 314,666
Cumulative Timesteps: 2,624,181,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.77404
Policy Entropy: 4.45435
Value Function Loss: 0.00180

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00543
Policy Update Magnitude: 0.26979
Value Function Update Magnitude: 0.41642

Collected Steps per Second: 23,929.92969
Overall Steps per Second: 10,932.23633

Timestep Collection Time: 2.08994
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.57473

Cumulative Model Updates: 314,672
Cumulative Timesteps: 2,624,231,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2624231324...
Checkpoint 2624231324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.29155
Policy Entropy: 4.45605
Value Function Loss: 0.00215

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.24170
Value Function Update Magnitude: 0.39604

Collected Steps per Second: 23,160.06736
Overall Steps per Second: 10,926.07032

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.41790
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.57731

Cumulative Model Updates: 314,678
Cumulative Timesteps: 2,624,281,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.93173
Policy Entropy: 4.45944
Value Function Loss: 0.00201

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00555
Policy Update Magnitude: 0.22179
Value Function Update Magnitude: 0.41107

Collected Steps per Second: 22,567.19614
Overall Steps per Second: 10,968.75136

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.34308
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.55895

Cumulative Model Updates: 314,684
Cumulative Timesteps: 2,624,331,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2624331342...
Checkpoint 2624331342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.66442
Policy Entropy: 4.45972
Value Function Loss: 0.00193

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00389
Policy Update Magnitude: 0.21445
Value Function Update Magnitude: 0.43625

Collected Steps per Second: 22,854.97281
Overall Steps per Second: 10,686.24518

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.68116

Cumulative Model Updates: 314,690
Cumulative Timesteps: 2,624,381,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17524
Policy Entropy: 4.46361
Value Function Loss: 0.00144

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00231
Policy Update Magnitude: 0.20944
Value Function Update Magnitude: 0.38150

Collected Steps per Second: 23,156.10714
Overall Steps per Second: 10,864.73151

Timestep Collection Time: 2.16038
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.60444

Cumulative Model Updates: 314,696
Cumulative Timesteps: 2,624,431,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2624431392...
Checkpoint 2624431392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.86630
Policy Entropy: 4.46423
Value Function Loss: 0.00147

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00255
Policy Update Magnitude: 0.21060
Value Function Update Magnitude: 0.36723

Collected Steps per Second: 23,780.85332
Overall Steps per Second: 11,078.78268

Timestep Collection Time: 2.10346
Timestep Consumption Time: 2.41166
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.51512

Cumulative Model Updates: 314,702
Cumulative Timesteps: 2,624,481,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.34084
Policy Entropy: 4.46524
Value Function Loss: 0.00144

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00215
Policy Update Magnitude: 0.22162
Value Function Update Magnitude: 0.35754

Collected Steps per Second: 22,637.43185
Overall Steps per Second: 10,633.40743

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.70479

Cumulative Model Updates: 314,708
Cumulative Timesteps: 2,624,531,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2624531442...
Checkpoint 2624531442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.32633
Policy Entropy: 4.45714
Value Function Loss: 0.00211

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00212
Policy Update Magnitude: 0.21864
Value Function Update Magnitude: 0.38198

Collected Steps per Second: 22,911.46007
Overall Steps per Second: 11,043.21567

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.34657
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.53002

Cumulative Model Updates: 314,714
Cumulative Timesteps: 2,624,581,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.99224
Policy Entropy: 4.45497
Value Function Loss: 0.00198

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00280
Policy Update Magnitude: 0.26000
Value Function Update Magnitude: 0.40536

Collected Steps per Second: 23,271.25046
Overall Steps per Second: 10,922.39716

Timestep Collection Time: 2.14969
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.58013

Cumulative Model Updates: 314,720
Cumulative Timesteps: 2,624,631,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2624631494...
Checkpoint 2624631494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.66761
Policy Entropy: 4.45394
Value Function Loss: 0.00214

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00426
Policy Update Magnitude: 0.30625
Value Function Update Magnitude: 0.38962

Collected Steps per Second: 22,884.22725
Overall Steps per Second: 10,808.10678

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.62653

Cumulative Model Updates: 314,726
Cumulative Timesteps: 2,624,681,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.36274
Policy Entropy: 4.45995
Value Function Loss: 0.00139

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.30538
Value Function Update Magnitude: 0.37076

Collected Steps per Second: 23,866.59789
Overall Steps per Second: 10,996.55215

Timestep Collection Time: 2.09540
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.54779

Cumulative Model Updates: 314,732
Cumulative Timesteps: 2,624,731,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2624731508...
Checkpoint 2624731508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.67512
Policy Entropy: 4.46594
Value Function Loss: 0.00155

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00476
Policy Update Magnitude: 0.26187
Value Function Update Magnitude: 0.33421

Collected Steps per Second: 22,880.82236
Overall Steps per Second: 10,770.72771

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.64333

Cumulative Model Updates: 314,738
Cumulative Timesteps: 2,624,781,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.34586
Policy Entropy: 4.46731
Value Function Loss: 0.00151

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.23041
Value Function Update Magnitude: 0.35158

Collected Steps per Second: 23,201.20306
Overall Steps per Second: 10,944.02783

Timestep Collection Time: 2.15644
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.57163

Cumulative Model Updates: 314,744
Cumulative Timesteps: 2,624,831,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2624831552...
Checkpoint 2624831552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.48359
Policy Entropy: 4.46416
Value Function Loss: 0.00170

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.22485
Value Function Update Magnitude: 0.33415

Collected Steps per Second: 23,917.38639
Overall Steps per Second: 10,655.88227

Timestep Collection Time: 2.09162
Timestep Consumption Time: 2.60307
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.69468

Cumulative Model Updates: 314,750
Cumulative Timesteps: 2,624,881,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.52258
Policy Entropy: 4.46296
Value Function Loss: 0.00133

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00367
Policy Update Magnitude: 0.22768
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 11,769.54469
Overall Steps per Second: 7,155.42123

Timestep Collection Time: 4.24995
Timestep Consumption Time: 2.74055
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 6.99050

Cumulative Model Updates: 314,756
Cumulative Timesteps: 2,624,931,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2624931598...
Checkpoint 2624931598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.06819
Policy Entropy: 4.46221
Value Function Loss: 0.00128

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.22812
Value Function Update Magnitude: 0.27770

Collected Steps per Second: 20,826.96712
Overall Steps per Second: 10,383.67455

Timestep Collection Time: 2.40102
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.81583

Cumulative Model Updates: 314,762
Cumulative Timesteps: 2,624,981,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.32036
Policy Entropy: 4.46418
Value Function Loss: 0.00164

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00295
Policy Update Magnitude: 0.24267
Value Function Update Magnitude: 0.38351

Collected Steps per Second: 22,746.27889
Overall Steps per Second: 10,735.87982

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.65840

Cumulative Model Updates: 314,768
Cumulative Timesteps: 2,625,031,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2625031616...
Checkpoint 2625031616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.73811
Policy Entropy: 4.46391
Value Function Loss: 0.00172

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00253
Policy Update Magnitude: 0.24549
Value Function Update Magnitude: 0.40867

Collected Steps per Second: 22,739.29645
Overall Steps per Second: 10,642.52619

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.69982

Cumulative Model Updates: 314,774
Cumulative Timesteps: 2,625,081,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.05396
Policy Entropy: 4.46073
Value Function Loss: 0.00253

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.30440
Value Function Update Magnitude: 0.38888

Collected Steps per Second: 24,057.38871
Overall Steps per Second: 10,919.77214

Timestep Collection Time: 2.07895
Timestep Consumption Time: 2.50119
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.58013

Cumulative Model Updates: 314,780
Cumulative Timesteps: 2,625,131,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2625131648...
Checkpoint 2625131648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.11864
Policy Entropy: 4.45955
Value Function Loss: 0.00227

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.28618
Value Function Update Magnitude: 0.37052

Collected Steps per Second: 23,013.50976
Overall Steps per Second: 10,728.24207

Timestep Collection Time: 2.17298
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.66134

Cumulative Model Updates: 314,786
Cumulative Timesteps: 2,625,181,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.99701
Policy Entropy: 4.45929
Value Function Loss: 0.00208

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.26606
Value Function Update Magnitude: 0.34594

Collected Steps per Second: 23,255.67766
Overall Steps per Second: 10,988.45819

Timestep Collection Time: 2.15001
Timestep Consumption Time: 2.40022
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.55023

Cumulative Model Updates: 314,792
Cumulative Timesteps: 2,625,231,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2625231656...
Checkpoint 2625231656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.92989
Policy Entropy: 4.46500
Value Function Loss: 0.00143

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00441
Policy Update Magnitude: 0.24397
Value Function Update Magnitude: 0.32439

Collected Steps per Second: 23,011.59710
Overall Steps per Second: 10,903.49733

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.58623

Cumulative Model Updates: 314,798
Cumulative Timesteps: 2,625,281,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.58527
Policy Entropy: 4.46529
Value Function Loss: 0.00167

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00398
Policy Update Magnitude: 0.26636
Value Function Update Magnitude: 0.37202

Collected Steps per Second: 21,983.30271
Overall Steps per Second: 10,536.03450

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.74657

Cumulative Model Updates: 314,804
Cumulative Timesteps: 2,625,331,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2625331672...
Checkpoint 2625331672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.68193
Policy Entropy: 4.45958
Value Function Loss: 0.00246

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00439
Policy Update Magnitude: 0.27028
Value Function Update Magnitude: 0.37906

Collected Steps per Second: 22,814.09134
Overall Steps per Second: 10,714.94925

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.66712

Cumulative Model Updates: 314,810
Cumulative Timesteps: 2,625,381,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.27067
Policy Entropy: 4.45942
Value Function Loss: 0.00227

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00386
Policy Update Magnitude: 0.27253
Value Function Update Magnitude: 0.37801

Collected Steps per Second: 22,521.56219
Overall Steps per Second: 10,748.16096

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.65382

Cumulative Model Updates: 314,816
Cumulative Timesteps: 2,625,431,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2625431700...
Checkpoint 2625431700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.13332
Policy Entropy: 4.45684
Value Function Loss: 0.00254

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00316
Policy Update Magnitude: 0.26315
Value Function Update Magnitude: 0.37716

Collected Steps per Second: 22,604.32043
Overall Steps per Second: 10,722.50663

Timestep Collection Time: 2.21329
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.66589

Cumulative Model Updates: 314,822
Cumulative Timesteps: 2,625,481,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.61640
Policy Entropy: 4.45547
Value Function Loss: 0.00178

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00375
Policy Update Magnitude: 0.24332
Value Function Update Magnitude: 0.35737

Collected Steps per Second: 22,847.72460
Overall Steps per Second: 10,806.85991

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.62706

Cumulative Model Updates: 314,828
Cumulative Timesteps: 2,625,531,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2625531734...
Checkpoint 2625531734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.46777
Policy Entropy: 4.45477
Value Function Loss: 0.00175

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00590
Policy Update Magnitude: 0.25068
Value Function Update Magnitude: 0.34883

Collected Steps per Second: 22,666.67627
Overall Steps per Second: 10,684.93656

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.47440
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.68098

Cumulative Model Updates: 314,834
Cumulative Timesteps: 2,625,581,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.37782
Policy Entropy: 4.45478
Value Function Loss: 0.00188

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00503
Policy Update Magnitude: 0.26871
Value Function Update Magnitude: 0.33727

Collected Steps per Second: 23,719.46610
Overall Steps per Second: 10,906.82048

Timestep Collection Time: 2.10865
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.58575

Cumulative Model Updates: 314,840
Cumulative Timesteps: 2,625,631,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2625631766...
Checkpoint 2625631766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.00794
Policy Entropy: 4.46078
Value Function Loss: 0.00209

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00485
Policy Update Magnitude: 0.27903
Value Function Update Magnitude: 0.31747

Collected Steps per Second: 22,471.85459
Overall Steps per Second: 10,633.38156

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.70405

Cumulative Model Updates: 314,846
Cumulative Timesteps: 2,625,681,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.06325
Policy Entropy: 4.46071
Value Function Loss: 0.00224

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00447
Policy Update Magnitude: 0.28531
Value Function Update Magnitude: 0.30135

Collected Steps per Second: 22,811.74548
Overall Steps per Second: 10,948.76233

Timestep Collection Time: 2.19361
Timestep Consumption Time: 2.37677
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.57038

Cumulative Model Updates: 314,852
Cumulative Timesteps: 2,625,731,826

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2625731826...
Checkpoint 2625731826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.56058
Policy Entropy: 4.46129
Value Function Loss: 0.00187

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00198
Policy Update Magnitude: 0.25681
Value Function Update Magnitude: 0.28931

Collected Steps per Second: 22,548.03528
Overall Steps per Second: 10,629.29254

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.48729
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.70549

Cumulative Model Updates: 314,858
Cumulative Timesteps: 2,625,781,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.85559
Policy Entropy: 4.45227
Value Function Loss: 0.00188

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00361
Policy Update Magnitude: 0.24482
Value Function Update Magnitude: 0.28928

Collected Steps per Second: 22,491.90605
Overall Steps per Second: 10,707.26588

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.67141

Cumulative Model Updates: 314,864
Cumulative Timesteps: 2,625,831,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2625831860...
Checkpoint 2625831860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.58407
Policy Entropy: 4.45215
Value Function Loss: 0.00165

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00429
Policy Update Magnitude: 0.23909
Value Function Update Magnitude: 0.28228

Collected Steps per Second: 23,154.43220
Overall Steps per Second: 10,890.86676

Timestep Collection Time: 2.16045
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59321

Cumulative Model Updates: 314,870
Cumulative Timesteps: 2,625,881,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.97638
Policy Entropy: 4.45647
Value Function Loss: 0.00160

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.25289
Value Function Update Magnitude: 0.27675

Collected Steps per Second: 22,770.80839
Overall Steps per Second: 10,801.43326

Timestep Collection Time: 2.19606
Timestep Consumption Time: 2.43351
PPO Batch Consumption Time: 0.27554
Total Iteration Time: 4.62957

Cumulative Model Updates: 314,876
Cumulative Timesteps: 2,625,931,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2625931890...
Checkpoint 2625931890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.39664
Policy Entropy: 4.46362
Value Function Loss: 0.00178

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00354
Policy Update Magnitude: 0.24207
Value Function Update Magnitude: 0.35464

Collected Steps per Second: 22,766.13502
Overall Steps per Second: 10,863.94609

Timestep Collection Time: 2.19704
Timestep Consumption Time: 2.40700
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.60404

Cumulative Model Updates: 314,882
Cumulative Timesteps: 2,625,981,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.23829
Policy Entropy: 4.46513
Value Function Loss: 0.00177

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00215
Policy Update Magnitude: 0.24940
Value Function Update Magnitude: 0.40968

Collected Steps per Second: 23,507.70589
Overall Steps per Second: 10,822.95918

Timestep Collection Time: 2.12705
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.61999

Cumulative Model Updates: 314,888
Cumulative Timesteps: 2,626,031,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2626031910...
Checkpoint 2626031910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.71086
Policy Entropy: 4.46444
Value Function Loss: 0.00217

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00246
Policy Update Magnitude: 0.25520
Value Function Update Magnitude: 0.37220

Collected Steps per Second: 22,787.39464
Overall Steps per Second: 10,801.95384

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.43567
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.63083

Cumulative Model Updates: 314,894
Cumulative Timesteps: 2,626,081,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.22503
Policy Entropy: 4.46343
Value Function Loss: 0.00206

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00231
Policy Update Magnitude: 0.27096
Value Function Update Magnitude: 0.35456

Collected Steps per Second: 23,611.27432
Overall Steps per Second: 10,932.38159

Timestep Collection Time: 2.11890
Timestep Consumption Time: 2.45741
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.57631

Cumulative Model Updates: 314,900
Cumulative Timesteps: 2,626,131,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2626131962...
Checkpoint 2626131962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.43071
Policy Entropy: 4.45753
Value Function Loss: 0.00247

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.27116
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 22,903.87297
Overall Steps per Second: 10,861.78956

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.60495

Cumulative Model Updates: 314,906
Cumulative Timesteps: 2,626,181,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.87543
Policy Entropy: 4.45758
Value Function Loss: 0.00223

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.25973
Value Function Update Magnitude: 0.42592

Collected Steps per Second: 22,422.23433
Overall Steps per Second: 10,679.46500

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.45264
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.68319

Cumulative Model Updates: 314,912
Cumulative Timesteps: 2,626,231,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2626231994...
Checkpoint 2626231994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.38952
Policy Entropy: 4.45489
Value Function Loss: 0.00226

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.00524
Policy Update Magnitude: 0.28675
Value Function Update Magnitude: 0.42871

Collected Steps per Second: 22,636.87135
Overall Steps per Second: 10,816.83152

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.27568
Total Iteration Time: 4.62243

Cumulative Model Updates: 314,918
Cumulative Timesteps: 2,626,281,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.26435
Policy Entropy: 4.46199
Value Function Loss: 0.00184

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.25700
Value Function Update Magnitude: 0.43723

Collected Steps per Second: 22,512.67885
Overall Steps per Second: 10,624.34993

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70862

Cumulative Model Updates: 314,924
Cumulative Timesteps: 2,626,332,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2626332020...
Checkpoint 2626332020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.04587
Policy Entropy: 4.45812
Value Function Loss: 0.00217

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.22998
Value Function Update Magnitude: 0.43833

Collected Steps per Second: 22,087.35484
Overall Steps per Second: 10,753.97140

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.38628
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.65056

Cumulative Model Updates: 314,930
Cumulative Timesteps: 2,626,382,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.44314
Policy Entropy: 4.46716
Value Function Loss: 0.00184

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00342
Policy Update Magnitude: 0.22842
Value Function Update Magnitude: 0.41886

Collected Steps per Second: 22,810.44249
Overall Steps per Second: 10,683.81958

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.68016

Cumulative Model Updates: 314,936
Cumulative Timesteps: 2,626,432,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2626432034...
Checkpoint 2626432034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.45659
Policy Entropy: 4.46117
Value Function Loss: 0.00220

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00366
Policy Update Magnitude: 0.22680
Value Function Update Magnitude: 0.36787

Collected Steps per Second: 23,085.95031
Overall Steps per Second: 10,841.95115

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.61430

Cumulative Model Updates: 314,942
Cumulative Timesteps: 2,626,482,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.37045
Policy Entropy: 4.46095
Value Function Loss: 0.00261

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00342
Policy Update Magnitude: 0.23980
Value Function Update Magnitude: 0.37676

Collected Steps per Second: 23,929.06825
Overall Steps per Second: 11,093.20416

Timestep Collection Time: 2.09060
Timestep Consumption Time: 2.41901
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.50961

Cumulative Model Updates: 314,948
Cumulative Timesteps: 2,626,532,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2626532088...
Checkpoint 2626532088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.35409
Policy Entropy: 4.45777
Value Function Loss: 0.00291

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.26189
Value Function Update Magnitude: 0.42285

Collected Steps per Second: 22,490.69671
Overall Steps per Second: 10,779.69026

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.41579
PPO Batch Consumption Time: 0.27467
Total Iteration Time: 4.63947

Cumulative Model Updates: 314,954
Cumulative Timesteps: 2,626,582,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.11412
Policy Entropy: 4.46002
Value Function Loss: 0.00271

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00387
Policy Update Magnitude: 0.26539
Value Function Update Magnitude: 0.46189

Collected Steps per Second: 23,279.44667
Overall Steps per Second: 10,994.16459

Timestep Collection Time: 2.14868
Timestep Consumption Time: 2.40101
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.54969

Cumulative Model Updates: 314,960
Cumulative Timesteps: 2,626,632,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2626632120...
Checkpoint 2626632120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02290
Policy Entropy: 4.45546
Value Function Loss: 0.00237

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00424
Policy Update Magnitude: 0.25786
Value Function Update Magnitude: 0.37657

Collected Steps per Second: 22,352.42112
Overall Steps per Second: 10,587.03594

Timestep Collection Time: 2.23707
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.72314

Cumulative Model Updates: 314,966
Cumulative Timesteps: 2,626,682,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.56572
Policy Entropy: 4.45465
Value Function Loss: 0.00243

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00460
Policy Update Magnitude: 0.26293
Value Function Update Magnitude: 0.36002

Collected Steps per Second: 22,217.89534
Overall Steps per Second: 10,778.82055

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.38838
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.63891

Cumulative Model Updates: 314,972
Cumulative Timesteps: 2,626,732,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2626732126...
Checkpoint 2626732126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.87382
Policy Entropy: 4.45523
Value Function Loss: 0.00290

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00416
Policy Update Magnitude: 0.31726
Value Function Update Magnitude: 0.37967

Collected Steps per Second: 22,413.08645
Overall Steps per Second: 10,772.22906

Timestep Collection Time: 2.23173
Timestep Consumption Time: 2.41169
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.64342

Cumulative Model Updates: 314,978
Cumulative Timesteps: 2,626,782,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.52428
Policy Entropy: 4.45755
Value Function Loss: 0.00288

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00463
Policy Update Magnitude: 0.29835
Value Function Update Magnitude: 0.37037

Collected Steps per Second: 23,244.86905
Overall Steps per Second: 10,829.71699

Timestep Collection Time: 2.15222
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.61951

Cumulative Model Updates: 314,984
Cumulative Timesteps: 2,626,832,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2626832174...
Checkpoint 2626832174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.79483
Policy Entropy: 4.45819
Value Function Loss: 0.00318

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.28239
Value Function Update Magnitude: 0.41738

Collected Steps per Second: 21,762.91156
Overall Steps per Second: 10,641.80889

Timestep Collection Time: 2.29859
Timestep Consumption Time: 2.40212
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.70070

Cumulative Model Updates: 314,990
Cumulative Timesteps: 2,626,882,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.19559
Policy Entropy: 4.45780
Value Function Loss: 0.00270

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.00838
Policy Update Magnitude: 0.42320
Value Function Update Magnitude: 0.46007

Collected Steps per Second: 22,892.42688
Overall Steps per Second: 10,871.88860

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.60067

Cumulative Model Updates: 314,996
Cumulative Timesteps: 2,626,932,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2626932216...
Checkpoint 2626932216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.51608
Policy Entropy: 4.46084
Value Function Loss: 0.00241

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00789
Policy Update Magnitude: 0.31625
Value Function Update Magnitude: 0.43751

Collected Steps per Second: 22,583.97000
Overall Steps per Second: 10,704.89872

Timestep Collection Time: 2.21423
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.67132

Cumulative Model Updates: 315,002
Cumulative Timesteps: 2,626,982,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.26634
Policy Entropy: 4.46064
Value Function Loss: 0.00226

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.00633
Policy Update Magnitude: 0.25874
Value Function Update Magnitude: 0.41854

Collected Steps per Second: 22,927.25285
Overall Steps per Second: 10,885.84896

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.41298
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.59441

Cumulative Model Updates: 315,008
Cumulative Timesteps: 2,627,032,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2627032236...
Checkpoint 2627032236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.40464
Policy Entropy: 4.45890
Value Function Loss: 0.00219

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00378
Policy Update Magnitude: 0.23917
Value Function Update Magnitude: 0.40687

Collected Steps per Second: 23,068.06139
Overall Steps per Second: 10,668.90425

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.52003
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.68839

Cumulative Model Updates: 315,014
Cumulative Timesteps: 2,627,082,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.99972
Policy Entropy: 4.45468
Value Function Loss: 0.00208

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00547
Policy Update Magnitude: 0.26239
Value Function Update Magnitude: 0.35835

Collected Steps per Second: 22,851.43809
Overall Steps per Second: 10,903.08961

Timestep Collection Time: 2.18805
Timestep Consumption Time: 2.39781
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.58586

Cumulative Model Updates: 315,020
Cumulative Timesteps: 2,627,132,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2627132256...
Checkpoint 2627132256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.34652
Policy Entropy: 4.45314
Value Function Loss: 0.00210

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.27103
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 23,991.79831
Overall Steps per Second: 11,087.54243

Timestep Collection Time: 2.08455
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.51065

Cumulative Model Updates: 315,026
Cumulative Timesteps: 2,627,182,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.80945
Policy Entropy: 4.45807
Value Function Loss: 0.00176

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00349
Policy Update Magnitude: 0.26780
Value Function Update Magnitude: 0.32082

Collected Steps per Second: 23,290.85175
Overall Steps per Second: 10,911.68436

Timestep Collection Time: 2.14831
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.58554

Cumulative Model Updates: 315,032
Cumulative Timesteps: 2,627,232,304

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2627232304...
Checkpoint 2627232304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.13670
Policy Entropy: 4.45553
Value Function Loss: 0.00206

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.24210
Value Function Update Magnitude: 0.33761

Collected Steps per Second: 22,601.51425
Overall Steps per Second: 10,671.11616

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.68836

Cumulative Model Updates: 315,038
Cumulative Timesteps: 2,627,282,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.01666
Policy Entropy: 4.45532
Value Function Loss: 0.00160

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.22883
Value Function Update Magnitude: 0.33745

Collected Steps per Second: 22,948.04369
Overall Steps per Second: 10,877.53077

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.41876
PPO Batch Consumption Time: 0.27560
Total Iteration Time: 4.59847

Cumulative Model Updates: 315,044
Cumulative Timesteps: 2,627,332,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2627332354...
Checkpoint 2627332354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.96936
Policy Entropy: 4.45228
Value Function Loss: 0.00185

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00342
Policy Update Magnitude: 0.22789
Value Function Update Magnitude: 0.32083

Collected Steps per Second: 22,496.68888
Overall Steps per Second: 10,667.03823

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.68790

Cumulative Model Updates: 315,050
Cumulative Timesteps: 2,627,382,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.77494
Policy Entropy: 4.45739
Value Function Loss: 0.00129

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00315
Policy Update Magnitude: 0.22367
Value Function Update Magnitude: 0.29355

Collected Steps per Second: 22,265.84938
Overall Steps per Second: 10,882.56828

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.34929
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.59524

Cumulative Model Updates: 315,056
Cumulative Timesteps: 2,627,432,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2627432368...
Checkpoint 2627432368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.71920
Policy Entropy: 4.45959
Value Function Loss: 0.00142

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00306
Policy Update Magnitude: 0.20622
Value Function Update Magnitude: 0.27543

Collected Steps per Second: 22,943.97743
Overall Steps per Second: 10,661.02466

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.69186

Cumulative Model Updates: 315,062
Cumulative Timesteps: 2,627,482,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.32283
Policy Entropy: 4.45539
Value Function Loss: 0.00191

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00247
Policy Update Magnitude: 0.23834
Value Function Update Magnitude: 0.33225

Collected Steps per Second: 22,679.87266
Overall Steps per Second: 10,846.58482

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.40524
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.60993

Cumulative Model Updates: 315,068
Cumulative Timesteps: 2,627,532,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2627532390...
Checkpoint 2627532390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.29662
Policy Entropy: 4.45069
Value Function Loss: 0.00221

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00315
Policy Update Magnitude: 0.24030
Value Function Update Magnitude: 0.39930

Collected Steps per Second: 23,767.55963
Overall Steps per Second: 10,926.32191

Timestep Collection Time: 2.10497
Timestep Consumption Time: 2.47388
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.57885

Cumulative Model Updates: 315,074
Cumulative Timesteps: 2,627,582,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.91249
Policy Entropy: 4.44808
Value Function Loss: 0.00207

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.26047
Value Function Update Magnitude: 0.41221

Collected Steps per Second: 23,125.35266
Overall Steps per Second: 10,674.48751

Timestep Collection Time: 2.16265
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.68519

Cumulative Model Updates: 315,080
Cumulative Timesteps: 2,627,632,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2627632432...
Checkpoint 2627632432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.72909
Policy Entropy: 4.45162
Value Function Loss: 0.00167

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00438
Policy Update Magnitude: 0.25440
Value Function Update Magnitude: 0.34360

Collected Steps per Second: 23,027.57342
Overall Steps per Second: 11,069.59350

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.34632
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.51832

Cumulative Model Updates: 315,086
Cumulative Timesteps: 2,627,682,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.75606
Policy Entropy: 4.45244
Value Function Loss: 0.00166

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00408
Policy Update Magnitude: 0.25502
Value Function Update Magnitude: 0.31773

Collected Steps per Second: 22,888.84442
Overall Steps per Second: 10,746.75229

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.65313

Cumulative Model Updates: 315,092
Cumulative Timesteps: 2,627,732,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2627732454...
Checkpoint 2627732454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.26204
Policy Entropy: 4.45180
Value Function Loss: 0.00159

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.25107
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 22,371.94720
Overall Steps per Second: 10,912.70164

Timestep Collection Time: 2.23503
Timestep Consumption Time: 2.34697
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.58200

Cumulative Model Updates: 315,098
Cumulative Timesteps: 2,627,782,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.56953
Policy Entropy: 4.45086
Value Function Loss: 0.00180

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00563
Policy Update Magnitude: 0.25289
Value Function Update Magnitude: 0.29719

Collected Steps per Second: 22,667.45365
Overall Steps per Second: 10,785.63570

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.63598

Cumulative Model Updates: 315,104
Cumulative Timesteps: 2,627,832,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2627832458...
Checkpoint 2627832458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.94128
Policy Entropy: 4.45571
Value Function Loss: 0.00162

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00566
Policy Update Magnitude: 0.25499
Value Function Update Magnitude: 0.31293

Collected Steps per Second: 22,465.22706
Overall Steps per Second: 10,714.17137

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.44252
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.66952

Cumulative Model Updates: 315,110
Cumulative Timesteps: 2,627,882,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.82960
Policy Entropy: 4.45606
Value Function Loss: 0.00167

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.23368
Value Function Update Magnitude: 0.30043

Collected Steps per Second: 22,677.26111
Overall Steps per Second: 10,916.86502

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.37683
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.58318

Cumulative Model Updates: 315,116
Cumulative Timesteps: 2,627,932,522

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2627932522...
Checkpoint 2627932522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.04704
Policy Entropy: 4.45392
Value Function Loss: 0.00191

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.25658
Value Function Update Magnitude: 0.30537

Collected Steps per Second: 22,903.49534
Overall Steps per Second: 10,632.17555

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.51963
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70271

Cumulative Model Updates: 315,122
Cumulative Timesteps: 2,627,982,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.39264
Policy Entropy: 4.45233
Value Function Loss: 0.00182

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00296
Policy Update Magnitude: 0.27086
Value Function Update Magnitude: 0.32188

Collected Steps per Second: 23,069.15503
Overall Steps per Second: 10,930.92320

Timestep Collection Time: 2.16835
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.57619

Cumulative Model Updates: 315,128
Cumulative Timesteps: 2,628,032,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2628032544...
Checkpoint 2628032544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.96919
Policy Entropy: 4.45261
Value Function Loss: 0.00212

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00362
Policy Update Magnitude: 0.26901
Value Function Update Magnitude: 0.37714

Collected Steps per Second: 22,978.56990
Overall Steps per Second: 10,708.88411

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.67070

Cumulative Model Updates: 315,134
Cumulative Timesteps: 2,628,082,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.48014
Policy Entropy: 4.45495
Value Function Loss: 0.00173

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.23119
Value Function Update Magnitude: 0.46229

Collected Steps per Second: 22,428.11754
Overall Steps per Second: 10,786.77912

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.40625
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.63586

Cumulative Model Updates: 315,140
Cumulative Timesteps: 2,628,132,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2628132568...
Checkpoint 2628132568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.02171
Policy Entropy: 4.45121
Value Function Loss: 0.00218

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00326
Policy Update Magnitude: 0.27549
Value Function Update Magnitude: 0.41779

Collected Steps per Second: 22,877.45095
Overall Steps per Second: 11,046.82216

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.34072
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.52637

Cumulative Model Updates: 315,146
Cumulative Timesteps: 2,628,182,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.74499
Policy Entropy: 4.45415
Value Function Loss: 0.00221

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00359
Policy Update Magnitude: 0.27967
Value Function Update Magnitude: 0.44227

Collected Steps per Second: 22,495.56635
Overall Steps per Second: 10,563.80953

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.73314

Cumulative Model Updates: 315,152
Cumulative Timesteps: 2,628,232,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2628232570...
Checkpoint 2628232570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.13486
Policy Entropy: 4.45413
Value Function Loss: 0.00223

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00430
Policy Update Magnitude: 0.27812
Value Function Update Magnitude: 0.47783

Collected Steps per Second: 22,270.08898
Overall Steps per Second: 10,753.84270

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.40568
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.65210

Cumulative Model Updates: 315,158
Cumulative Timesteps: 2,628,282,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.30251
Policy Entropy: 4.45933
Value Function Loss: 0.00222

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.26633
Value Function Update Magnitude: 0.48030

Collected Steps per Second: 22,241.49585
Overall Steps per Second: 10,706.90577

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.67212

Cumulative Model Updates: 315,164
Cumulative Timesteps: 2,628,332,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2628332622...
Checkpoint 2628332622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.24242
Policy Entropy: 4.45788
Value Function Loss: 0.00219

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00444
Policy Update Magnitude: 0.25890
Value Function Update Magnitude: 0.50044

Collected Steps per Second: 22,427.55327
Overall Steps per Second: 10,725.46488

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.66311

Cumulative Model Updates: 315,170
Cumulative Timesteps: 2,628,382,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.49981
Policy Entropy: 4.46016
Value Function Loss: 0.00220

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.25308
Value Function Update Magnitude: 0.46184

Collected Steps per Second: 23,114.78471
Overall Steps per Second: 10,945.16522

Timestep Collection Time: 2.16381
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.56969

Cumulative Model Updates: 315,176
Cumulative Timesteps: 2,628,432,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2628432652...
Checkpoint 2628432652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.85071
Policy Entropy: 4.46379
Value Function Loss: 0.00152

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00305
Policy Update Magnitude: 0.22978
Value Function Update Magnitude: 0.40145

Collected Steps per Second: 23,199.00128
Overall Steps per Second: 10,792.78043

Timestep Collection Time: 2.15613
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.63458

Cumulative Model Updates: 315,182
Cumulative Timesteps: 2,628,482,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.53862
Policy Entropy: 4.46001
Value Function Loss: 0.00163

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00378
Policy Update Magnitude: 0.23383
Value Function Update Magnitude: 0.34097

Collected Steps per Second: 22,834.25279
Overall Steps per Second: 10,851.09043

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.61004

Cumulative Model Updates: 315,188
Cumulative Timesteps: 2,628,532,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2628532696...
Checkpoint 2628532696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.77619
Policy Entropy: 4.45880
Value Function Loss: 0.00194

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00516
Policy Update Magnitude: 0.27955
Value Function Update Magnitude: 0.33444

Collected Steps per Second: 22,782.38003
Overall Steps per Second: 10,516.20881

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.56081
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.75628

Cumulative Model Updates: 315,194
Cumulative Timesteps: 2,628,582,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.87423
Policy Entropy: 4.45472
Value Function Loss: 0.00247

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00507
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.36112

Collected Steps per Second: 22,700.54943
Overall Steps per Second: 10,852.98726

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.40549
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.60905

Cumulative Model Updates: 315,200
Cumulative Timesteps: 2,628,632,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2628632736...
Checkpoint 2628632736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.88068
Policy Entropy: 4.45637
Value Function Loss: 0.00257

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.29240
Value Function Update Magnitude: 0.39507

Collected Steps per Second: 22,793.77893
Overall Steps per Second: 10,874.27189

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.40491
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.59893

Cumulative Model Updates: 315,206
Cumulative Timesteps: 2,628,682,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.34447
Policy Entropy: 4.44975
Value Function Loss: 0.00258

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.25715
Value Function Update Magnitude: 0.36850

Collected Steps per Second: 22,386.39589
Overall Steps per Second: 10,737.72027

Timestep Collection Time: 2.23502
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.65965

Cumulative Model Updates: 315,212
Cumulative Timesteps: 2,628,732,780

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2628732780...
Checkpoint 2628732780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.84039
Policy Entropy: 4.45296
Value Function Loss: 0.00210

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00450
Policy Update Magnitude: 0.24792
Value Function Update Magnitude: 0.33313

Collected Steps per Second: 22,295.56129
Overall Steps per Second: 10,740.22863

Timestep Collection Time: 2.24385
Timestep Consumption Time: 2.41415
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.65800

Cumulative Model Updates: 315,218
Cumulative Timesteps: 2,628,782,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.95413
Policy Entropy: 4.45669
Value Function Loss: 0.00162

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.24536
Value Function Update Magnitude: 0.30016

Collected Steps per Second: 22,434.22109
Overall Steps per Second: 10,753.16164

Timestep Collection Time: 2.22936
Timestep Consumption Time: 2.42174
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.65110

Cumulative Model Updates: 315,224
Cumulative Timesteps: 2,628,832,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2628832822...
Checkpoint 2628832822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.94727
Policy Entropy: 4.45916
Value Function Loss: 0.00178

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00276
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.29882

Collected Steps per Second: 22,487.91996
Overall Steps per Second: 10,778.53305

Timestep Collection Time: 2.22377
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.27455
Total Iteration Time: 4.63959

Cumulative Model Updates: 315,230
Cumulative Timesteps: 2,628,882,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.95374
Policy Entropy: 4.46103
Value Function Loss: 0.00185

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00345
Policy Update Magnitude: 0.36249
Value Function Update Magnitude: 0.32309

Collected Steps per Second: 23,032.76882
Overall Steps per Second: 10,829.64051

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.61973

Cumulative Model Updates: 315,236
Cumulative Timesteps: 2,628,932,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2628932860...
Checkpoint 2628932860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.46469
Policy Entropy: 4.45879
Value Function Loss: 0.00222

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00375
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.34737

Collected Steps per Second: 23,277.19330
Overall Steps per Second: 10,788.49045

Timestep Collection Time: 2.14845
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.63550

Cumulative Model Updates: 315,242
Cumulative Timesteps: 2,628,982,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.66668
Policy Entropy: 4.46300
Value Function Loss: 0.00199

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00358
Policy Update Magnitude: 0.25471
Value Function Update Magnitude: 0.32697

Collected Steps per Second: 23,380.64311
Overall Steps per Second: 10,839.72018

Timestep Collection Time: 2.13861
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.61285

Cumulative Model Updates: 315,248
Cumulative Timesteps: 2,629,032,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2629032872...
Checkpoint 2629032872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.28351
Policy Entropy: 4.46077
Value Function Loss: 0.00176

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00311
Policy Update Magnitude: 0.21602
Value Function Update Magnitude: 0.29883

Collected Steps per Second: 23,725.75483
Overall Steps per Second: 11,050.28072

Timestep Collection Time: 2.10767
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.52531

Cumulative Model Updates: 315,254
Cumulative Timesteps: 2,629,082,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.35560
Policy Entropy: 4.46071
Value Function Loss: 0.00149

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00312
Policy Update Magnitude: 0.20027
Value Function Update Magnitude: 0.27649

Collected Steps per Second: 23,087.92453
Overall Steps per Second: 10,903.89611

Timestep Collection Time: 2.16685
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.58808

Cumulative Model Updates: 315,260
Cumulative Timesteps: 2,629,132,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2629132906...
Checkpoint 2629132906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.09153
Policy Entropy: 4.46006
Value Function Loss: 0.00137

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00334
Policy Update Magnitude: 0.19751
Value Function Update Magnitude: 0.27002

Collected Steps per Second: 22,646.80106
Overall Steps per Second: 10,904.22400

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.37804
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.58630

Cumulative Model Updates: 315,266
Cumulative Timesteps: 2,629,182,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.79501
Policy Entropy: 4.45576
Value Function Loss: 0.00136

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00237
Policy Update Magnitude: 0.22277
Value Function Update Magnitude: 0.28232

Collected Steps per Second: 22,440.56887
Overall Steps per Second: 10,644.44062

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.69954

Cumulative Model Updates: 315,272
Cumulative Timesteps: 2,629,232,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2629232940...
Checkpoint 2629232940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.42525
Policy Entropy: 4.45553
Value Function Loss: 0.00168

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00503
Policy Update Magnitude: 0.23735
Value Function Update Magnitude: 0.29674

Collected Steps per Second: 22,277.12010
Overall Steps per Second: 10,648.72289

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.69615

Cumulative Model Updates: 315,278
Cumulative Timesteps: 2,629,282,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.30694
Policy Entropy: 4.45265
Value Function Loss: 0.00168

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00453
Policy Update Magnitude: 0.23437
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 21,917.44223
Overall Steps per Second: 10,406.79155

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.80532

Cumulative Model Updates: 315,284
Cumulative Timesteps: 2,629,332,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2629332956...
Checkpoint 2629332956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.49028
Policy Entropy: 4.45901
Value Function Loss: 0.00176

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.26572
Value Function Update Magnitude: 0.34777

Collected Steps per Second: 21,162.04235
Overall Steps per Second: 10,233.84395

Timestep Collection Time: 2.36367
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.88770

Cumulative Model Updates: 315,290
Cumulative Timesteps: 2,629,382,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.13797
Policy Entropy: 4.45948
Value Function Loss: 0.00166

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00371
Policy Update Magnitude: 0.24933
Value Function Update Magnitude: 0.34797

Collected Steps per Second: 22,775.05256
Overall Steps per Second: 10,852.81062

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.60931

Cumulative Model Updates: 315,296
Cumulative Timesteps: 2,629,433,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2629433000...
Checkpoint 2629433000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.23753
Policy Entropy: 4.46062
Value Function Loss: 0.00139

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00284
Policy Update Magnitude: 0.23181
Value Function Update Magnitude: 0.30996

Collected Steps per Second: 23,024.90719
Overall Steps per Second: 10,681.30985

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68313

Cumulative Model Updates: 315,302
Cumulative Timesteps: 2,629,483,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.63340
Policy Entropy: 4.45982
Value Function Loss: 0.00143

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.24648
Value Function Update Magnitude: 0.31802

Collected Steps per Second: 22,909.70790
Overall Steps per Second: 10,892.61103

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.59119

Cumulative Model Updates: 315,308
Cumulative Timesteps: 2,629,533,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2629533032...
Checkpoint 2629533032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.66698
Policy Entropy: 4.45315
Value Function Loss: 0.00188

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00412
Policy Update Magnitude: 0.25755
Value Function Update Magnitude: 0.37477

Collected Steps per Second: 23,592.69561
Overall Steps per Second: 10,841.99790

Timestep Collection Time: 2.12023
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.61373

Cumulative Model Updates: 315,314
Cumulative Timesteps: 2,629,583,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.16073
Policy Entropy: 4.45193
Value Function Loss: 0.00214

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.25718
Value Function Update Magnitude: 0.44145

Collected Steps per Second: 23,265.02690
Overall Steps per Second: 10,754.59555

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.64918

Cumulative Model Updates: 315,320
Cumulative Timesteps: 2,629,633,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2629633054...
Checkpoint 2629633054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.13465
Policy Entropy: 4.45078
Value Function Loss: 0.00215

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00398
Policy Update Magnitude: 0.26790
Value Function Update Magnitude: 0.42530

Collected Steps per Second: 22,251.37289
Overall Steps per Second: 10,679.70112

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68346

Cumulative Model Updates: 315,326
Cumulative Timesteps: 2,629,683,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.78816
Policy Entropy: 4.45829
Value Function Loss: 0.00170

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00457
Policy Update Magnitude: 0.24299
Value Function Update Magnitude: 0.37557

Collected Steps per Second: 22,682.80476
Overall Steps per Second: 10,837.43629

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.40981
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.61456

Cumulative Model Updates: 315,332
Cumulative Timesteps: 2,629,733,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2629733082...
Checkpoint 2629733082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.78418
Policy Entropy: 4.45926
Value Function Loss: 0.00137

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00386
Policy Update Magnitude: 0.21830
Value Function Update Magnitude: 0.33493

Collected Steps per Second: 22,637.54556
Overall Steps per Second: 10,691.46313

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.67925

Cumulative Model Updates: 315,338
Cumulative Timesteps: 2,629,783,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.87506
Policy Entropy: 4.46039
Value Function Loss: 0.00135

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00447
Policy Update Magnitude: 0.21818
Value Function Update Magnitude: 0.32549

Collected Steps per Second: 22,792.80288
Overall Steps per Second: 10,883.46409

Timestep Collection Time: 2.19420
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.59523

Cumulative Model Updates: 315,344
Cumulative Timesteps: 2,629,833,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2629833122...
Checkpoint 2629833122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.64266
Policy Entropy: 4.46230
Value Function Loss: 0.00144

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00350
Policy Update Magnitude: 0.23597
Value Function Update Magnitude: 0.31181

Collected Steps per Second: 23,164.53998
Overall Steps per Second: 10,774.53327

Timestep Collection Time: 2.15908
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.64187

Cumulative Model Updates: 315,350
Cumulative Timesteps: 2,629,883,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.93213
Policy Entropy: 4.46210
Value Function Loss: 0.00182

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00592
Policy Update Magnitude: 0.23390
Value Function Update Magnitude: 0.36993

Collected Steps per Second: 22,536.21175
Overall Steps per Second: 10,856.62176

Timestep Collection Time: 2.21865
Timestep Consumption Time: 2.38683
PPO Batch Consumption Time: 0.27431
Total Iteration Time: 4.60548

Cumulative Model Updates: 315,356
Cumulative Timesteps: 2,629,933,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2629933136...
Checkpoint 2629933136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.43270
Policy Entropy: 4.46479
Value Function Loss: 0.00190

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00314
Policy Update Magnitude: 0.25334
Value Function Update Magnitude: 0.37595

Collected Steps per Second: 23,933.48243
Overall Steps per Second: 11,058.12674

Timestep Collection Time: 2.08954
Timestep Consumption Time: 2.43292
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.52247

Cumulative Model Updates: 315,362
Cumulative Timesteps: 2,629,983,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.30646
Policy Entropy: 4.46182
Value Function Loss: 0.00191

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.26380
Value Function Update Magnitude: 0.38081

Collected Steps per Second: 22,674.89512
Overall Steps per Second: 10,786.35299

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.63753

Cumulative Model Updates: 315,368
Cumulative Timesteps: 2,630,033,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2630033168...
Checkpoint 2630033168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.96116
Policy Entropy: 4.46302
Value Function Loss: 0.00161

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00487
Policy Update Magnitude: 0.25307
Value Function Update Magnitude: 0.36112

Collected Steps per Second: 22,898.47161
Overall Steps per Second: 10,901.68382

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.40347
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.58755

Cumulative Model Updates: 315,374
Cumulative Timesteps: 2,630,083,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.67975
Policy Entropy: 4.46386
Value Function Loss: 0.00160

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.23625
Value Function Update Magnitude: 0.37343

Collected Steps per Second: 22,575.40539
Overall Steps per Second: 10,766.05547

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.43127
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.64776

Cumulative Model Updates: 315,380
Cumulative Timesteps: 2,630,133,218

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2630133218...
Checkpoint 2630133218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.55511
Policy Entropy: 4.46761
Value Function Loss: 0.00139

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.24317
Value Function Update Magnitude: 0.47176

Collected Steps per Second: 22,123.33994
Overall Steps per Second: 10,693.42584

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.67745

Cumulative Model Updates: 315,386
Cumulative Timesteps: 2,630,183,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.70449
Policy Entropy: 4.46244
Value Function Loss: 0.00167

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00742
Policy Update Magnitude: 0.23919
Value Function Update Magnitude: 0.47156

Collected Steps per Second: 23,656.90187
Overall Steps per Second: 10,911.65312

Timestep Collection Time: 2.11355
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.58226

Cumulative Model Updates: 315,392
Cumulative Timesteps: 2,630,233,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2630233236...
Checkpoint 2630233236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.17786
Policy Entropy: 4.46243
Value Function Loss: 0.00158

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00639
Policy Update Magnitude: 0.27551
Value Function Update Magnitude: 0.37844

Collected Steps per Second: 23,168.57644
Overall Steps per Second: 10,658.90495

Timestep Collection Time: 2.15999
Timestep Consumption Time: 2.53505
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.69504

Cumulative Model Updates: 315,398
Cumulative Timesteps: 2,630,283,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.47913
Policy Entropy: 4.45771
Value Function Loss: 0.00190

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00470
Policy Update Magnitude: 0.28816
Value Function Update Magnitude: 0.34734

Collected Steps per Second: 23,002.11070
Overall Steps per Second: 10,726.71051

Timestep Collection Time: 2.17450
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.66294

Cumulative Model Updates: 315,404
Cumulative Timesteps: 2,630,333,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2630333298...
Checkpoint 2630333298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.18500
Policy Entropy: 4.46373
Value Function Loss: 0.00189

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.26890
Value Function Update Magnitude: 0.32865

Collected Steps per Second: 23,009.79660
Overall Steps per Second: 10,813.56884

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.62493

Cumulative Model Updates: 315,410
Cumulative Timesteps: 2,630,383,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.60009
Policy Entropy: 4.46271
Value Function Loss: 0.00177

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00392
Policy Update Magnitude: 0.27011
Value Function Update Magnitude: 0.36355

Collected Steps per Second: 22,804.25498
Overall Steps per Second: 10,928.63556

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.38342
PPO Batch Consumption Time: 0.27504
Total Iteration Time: 4.57678

Cumulative Model Updates: 315,416
Cumulative Timesteps: 2,630,433,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2630433328...
Checkpoint 2630433328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.58509
Policy Entropy: 4.46413
Value Function Loss: 0.00164

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.27988
Value Function Update Magnitude: 0.36606

Collected Steps per Second: 23,529.09732
Overall Steps per Second: 11,016.98915

Timestep Collection Time: 2.12511
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.53863

Cumulative Model Updates: 315,422
Cumulative Timesteps: 2,630,483,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.75836
Policy Entropy: 4.46030
Value Function Loss: 0.00197

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.28603
Value Function Update Magnitude: 0.39694

Collected Steps per Second: 22,820.21080
Overall Steps per Second: 10,709.62441

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66944

Cumulative Model Updates: 315,428
Cumulative Timesteps: 2,630,533,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2630533338...
Checkpoint 2630533338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.46184
Policy Entropy: 4.45471
Value Function Loss: 0.00263

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00657
Policy Update Magnitude: 0.28628
Value Function Update Magnitude: 0.40001

Collected Steps per Second: 22,292.01361
Overall Steps per Second: 10,893.16100

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.34736
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.59059

Cumulative Model Updates: 315,434
Cumulative Timesteps: 2,630,583,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.32077
Policy Entropy: 4.45415
Value Function Loss: 0.00269

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00568
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.37923

Collected Steps per Second: 22,665.64520
Overall Steps per Second: 10,794.35739

Timestep Collection Time: 2.20651
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.63316

Cumulative Model Updates: 315,440
Cumulative Timesteps: 2,630,633,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2630633356...
Checkpoint 2630633356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.29398
Policy Entropy: 4.45376
Value Function Loss: 0.00250

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00662
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.35748

Collected Steps per Second: 21,763.08400
Overall Steps per Second: 10,651.14326

Timestep Collection Time: 2.29765
Timestep Consumption Time: 2.39706
PPO Batch Consumption Time: 0.27595
Total Iteration Time: 4.69471

Cumulative Model Updates: 315,446
Cumulative Timesteps: 2,630,683,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.02683
Policy Entropy: 4.45977
Value Function Loss: 0.00170

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.26367
Value Function Update Magnitude: 0.39555

Collected Steps per Second: 21,867.57371
Overall Steps per Second: 10,529.22018

Timestep Collection Time: 2.28676
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.74926

Cumulative Model Updates: 315,452
Cumulative Timesteps: 2,630,733,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2630733366...
Checkpoint 2630733366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.18349
Policy Entropy: 4.45903
Value Function Loss: 0.00169

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.23906
Value Function Update Magnitude: 0.43908

Collected Steps per Second: 23,165.79491
Overall Steps per Second: 10,738.76081

Timestep Collection Time: 2.15835
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.65603

Cumulative Model Updates: 315,458
Cumulative Timesteps: 2,630,783,366

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.34620
Policy Entropy: 4.45957
Value Function Loss: 0.00176

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00325
Policy Update Magnitude: 0.26281
Value Function Update Magnitude: 0.36136

Collected Steps per Second: 23,153.92314
Overall Steps per Second: 10,958.01517

Timestep Collection Time: 2.16050
Timestep Consumption Time: 2.40456
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.56506

Cumulative Model Updates: 315,464
Cumulative Timesteps: 2,630,833,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2630833390...
Checkpoint 2630833390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.48501
Policy Entropy: 4.45627
Value Function Loss: 0.00190

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00294
Policy Update Magnitude: 0.26478
Value Function Update Magnitude: 0.33772

Collected Steps per Second: 23,277.08054
Overall Steps per Second: 10,934.94692

Timestep Collection Time: 2.14924
Timestep Consumption Time: 2.42582
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.57506

Cumulative Model Updates: 315,470
Cumulative Timesteps: 2,630,883,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.83347
Policy Entropy: 4.46155
Value Function Loss: 0.00173

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00316
Policy Update Magnitude: 0.24863
Value Function Update Magnitude: 0.34806

Collected Steps per Second: 23,087.99004
Overall Steps per Second: 10,942.98575

Timestep Collection Time: 2.16563
Timestep Consumption Time: 2.40351
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.56914

Cumulative Model Updates: 315,476
Cumulative Timesteps: 2,630,933,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2630933418...
Checkpoint 2630933418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.99877
Policy Entropy: 4.46542
Value Function Loss: 0.00145

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00337
Policy Update Magnitude: 0.23578
Value Function Update Magnitude: 0.33741

Collected Steps per Second: 22,488.64372
Overall Steps per Second: 10,770.85357

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.41968
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.64383

Cumulative Model Updates: 315,482
Cumulative Timesteps: 2,630,983,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.78172
Policy Entropy: 4.46106
Value Function Loss: 0.00180

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.24717
Value Function Update Magnitude: 0.32302

Collected Steps per Second: 22,576.91342
Overall Steps per Second: 10,750.62021

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.65108

Cumulative Model Updates: 315,488
Cumulative Timesteps: 2,631,033,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2631033438...
Checkpoint 2631033438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.71753
Policy Entropy: 4.46093
Value Function Loss: 0.00200

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00503
Policy Update Magnitude: 0.31124
Value Function Update Magnitude: 0.34181

Collected Steps per Second: 22,371.53776
Overall Steps per Second: 10,766.95851

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.64532

Cumulative Model Updates: 315,494
Cumulative Timesteps: 2,631,083,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.65549
Policy Entropy: 4.45294
Value Function Loss: 0.00238

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00927
Policy Update Magnitude: 0.33078
Value Function Update Magnitude: 0.31386

Collected Steps per Second: 22,580.49854
Overall Steps per Second: 10,778.26957

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.64156

Cumulative Model Updates: 315,500
Cumulative Timesteps: 2,631,133,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2631133482...
Checkpoint 2631133482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.77050
Policy Entropy: 4.45891
Value Function Loss: 0.00221

Mean KL Divergence: 0.00071
SB3 Clip Fraction: 0.00631
Policy Update Magnitude: 0.28261
Value Function Update Magnitude: 0.30741

Collected Steps per Second: 22,942.31180
Overall Steps per Second: 10,679.65831

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.68199

Cumulative Model Updates: 315,506
Cumulative Timesteps: 2,631,183,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.26885
Policy Entropy: 4.45889
Value Function Loss: 0.00179

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.00523
Policy Update Magnitude: 0.25697
Value Function Update Magnitude: 0.32298

Collected Steps per Second: 22,647.68075
Overall Steps per Second: 10,919.90354

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.37230
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.58118

Cumulative Model Updates: 315,512
Cumulative Timesteps: 2,631,233,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2631233510...
Checkpoint 2631233510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.70214
Policy Entropy: 4.46667
Value Function Loss: 0.00138

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.26636
Value Function Update Magnitude: 0.30704

Collected Steps per Second: 23,185.79220
Overall Steps per Second: 10,813.22557

Timestep Collection Time: 2.15684
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.62471

Cumulative Model Updates: 315,518
Cumulative Timesteps: 2,631,283,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.65575
Policy Entropy: 4.46320
Value Function Loss: 0.00185

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.25058
Value Function Update Magnitude: 0.31801

Collected Steps per Second: 22,467.47411
Overall Steps per Second: 10,738.58711

Timestep Collection Time: 2.22642
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.65815

Cumulative Model Updates: 315,524
Cumulative Timesteps: 2,631,333,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2631333540...
Checkpoint 2631333540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16000
Policy Entropy: 4.45433
Value Function Loss: 0.00217

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.35204

Collected Steps per Second: 23,160.70697
Overall Steps per Second: 10,748.65354

Timestep Collection Time: 2.15892
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.65193

Cumulative Model Updates: 315,530
Cumulative Timesteps: 2,631,383,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.53444
Policy Entropy: 4.45061
Value Function Loss: 0.00230

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.30886
Value Function Update Magnitude: 0.40226

Collected Steps per Second: 22,843.28155
Overall Steps per Second: 10,804.09340

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.43983
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.62936

Cumulative Model Updates: 315,536
Cumulative Timesteps: 2,631,433,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2631433558...
Checkpoint 2631433558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.88874
Policy Entropy: 4.45881
Value Function Loss: 0.00146

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00555
Policy Update Magnitude: 0.26802
Value Function Update Magnitude: 0.34756

Collected Steps per Second: 22,779.11070
Overall Steps per Second: 11,036.83599

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.33641
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.53246

Cumulative Model Updates: 315,542
Cumulative Timesteps: 2,631,483,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.33721
Policy Entropy: 4.46580
Value Function Loss: 0.00117

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00285
Policy Update Magnitude: 0.24121
Value Function Update Magnitude: 0.28926

Collected Steps per Second: 22,442.58243
Overall Steps per Second: 10,596.40141

Timestep Collection Time: 2.22844
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.71972

Cumulative Model Updates: 315,548
Cumulative Timesteps: 2,631,533,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2631533594...
Checkpoint 2631533594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.86804
Policy Entropy: 4.46746
Value Function Loss: 0.00139

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00184
Policy Update Magnitude: 0.20404
Value Function Update Magnitude: 0.29068

Collected Steps per Second: 22,317.67652
Overall Steps per Second: 10,934.13195

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.33377
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.57540

Cumulative Model Updates: 315,554
Cumulative Timesteps: 2,631,583,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.00579
Policy Entropy: 4.46140
Value Function Loss: 0.00151

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00296
Policy Update Magnitude: 0.20407
Value Function Update Magnitude: 0.41958

Collected Steps per Second: 22,786.36236
Overall Steps per Second: 10,569.95933

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.53630
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.73077

Cumulative Model Updates: 315,560
Cumulative Timesteps: 2,631,633,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2631633626...
Checkpoint 2631633626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.25576
Policy Entropy: 4.46152
Value Function Loss: 0.00172

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00215
Policy Update Magnitude: 0.21168
Value Function Update Magnitude: 0.41411

Collected Steps per Second: 22,926.92390
Overall Steps per Second: 10,663.54532

Timestep Collection Time: 2.18198
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69131

Cumulative Model Updates: 315,566
Cumulative Timesteps: 2,631,683,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.10650
Policy Entropy: 4.46045
Value Function Loss: 0.00143

Mean KL Divergence: 0.00020
SB3 Clip Fraction: 0.00179
Policy Update Magnitude: 0.23731
Value Function Update Magnitude: 0.37608

Collected Steps per Second: 22,403.31276
Overall Steps per Second: 10,889.32855

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.36050
PPO Batch Consumption Time: 0.27577
Total Iteration Time: 4.59294

Cumulative Model Updates: 315,572
Cumulative Timesteps: 2,631,733,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2631733666...
Checkpoint 2631733666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.41588
Policy Entropy: 4.46536
Value Function Loss: 0.00155

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00196
Policy Update Magnitude: 0.27104
Value Function Update Magnitude: 0.37315

Collected Steps per Second: 22,836.27316
Overall Steps per Second: 10,673.45598

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68658

Cumulative Model Updates: 315,578
Cumulative Timesteps: 2,631,783,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.90518
Policy Entropy: 4.46240
Value Function Loss: 0.00146

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.24775
Value Function Update Magnitude: 0.44480

Collected Steps per Second: 22,911.35424
Overall Steps per Second: 10,832.27621

Timestep Collection Time: 2.18328
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.61787

Cumulative Model Updates: 315,584
Cumulative Timesteps: 2,631,833,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2631833710...
Checkpoint 2631833710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.03067
Policy Entropy: 4.46094
Value Function Loss: 0.00168

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00232
Policy Update Magnitude: 0.23519
Value Function Update Magnitude: 0.44374

Collected Steps per Second: 23,114.47568
Overall Steps per Second: 10,764.15259

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.64560

Cumulative Model Updates: 315,590
Cumulative Timesteps: 2,631,883,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.66695
Policy Entropy: 4.45525
Value Function Loss: 0.00193

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.26245
Value Function Update Magnitude: 0.42181

Collected Steps per Second: 22,621.84567
Overall Steps per Second: 10,859.02252

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.39421
PPO Batch Consumption Time: 0.27489
Total Iteration Time: 4.60447

Cumulative Model Updates: 315,596
Cumulative Timesteps: 2,631,933,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2631933716...
Checkpoint 2631933716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.14174
Policy Entropy: 4.45628
Value Function Loss: 0.00245

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00504
Policy Update Magnitude: 0.28727
Value Function Update Magnitude: 0.39854

Collected Steps per Second: 22,168.50314
Overall Steps per Second: 10,748.21275

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.39735
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.65361

Cumulative Model Updates: 315,602
Cumulative Timesteps: 2,631,983,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.15329
Policy Entropy: 4.45690
Value Function Loss: 0.00246

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00416
Policy Update Magnitude: 0.30372
Value Function Update Magnitude: 0.38629

Collected Steps per Second: 22,521.90380
Overall Steps per Second: 10,808.14051

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.40656
PPO Batch Consumption Time: 0.27464
Total Iteration Time: 4.62707

Cumulative Model Updates: 315,608
Cumulative Timesteps: 2,632,033,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2632033744...
Checkpoint 2632033744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.95519
Policy Entropy: 4.45592
Value Function Loss: 0.00315

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00509
Policy Update Magnitude: 0.33394
Value Function Update Magnitude: 0.37961

Collected Steps per Second: 21,660.03052
Overall Steps per Second: 10,606.27073

Timestep Collection Time: 2.30960
Timestep Consumption Time: 2.40704
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.71664

Cumulative Model Updates: 315,614
Cumulative Timesteps: 2,632,083,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.76489
Policy Entropy: 4.45139
Value Function Loss: 0.00302

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00651
Policy Update Magnitude: 0.34526
Value Function Update Magnitude: 0.39012

Collected Steps per Second: 22,965.88258
Overall Steps per Second: 10,791.81157

Timestep Collection Time: 2.17740
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.63370

Cumulative Model Updates: 315,620
Cumulative Timesteps: 2,632,133,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2632133776...
Checkpoint 2632133776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23166
Policy Entropy: 4.45106
Value Function Loss: 0.00256

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00676
Policy Update Magnitude: 0.33664
Value Function Update Magnitude: 0.39258

Collected Steps per Second: 22,752.47273
Overall Steps per Second: 10,697.04960

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67849

Cumulative Model Updates: 315,626
Cumulative Timesteps: 2,632,183,822

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.45751
Policy Entropy: 4.45222
Value Function Loss: 0.00196

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00521
Policy Update Magnitude: 0.37532
Value Function Update Magnitude: 0.39379

Collected Steps per Second: 23,117.48128
Overall Steps per Second: 10,965.86812

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.39750
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.56106

Cumulative Model Updates: 315,632
Cumulative Timesteps: 2,632,233,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2632233838...
Checkpoint 2632233838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.23138
Policy Entropy: 4.45593
Value Function Loss: 0.00156

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00528
Policy Update Magnitude: 0.36441
Value Function Update Magnitude: 0.38049

Collected Steps per Second: 23,177.65405
Overall Steps per Second: 10,748.29187

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.65469

Cumulative Model Updates: 315,638
Cumulative Timesteps: 2,632,283,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.64966
Policy Entropy: 4.45498
Value Function Loss: 0.00161

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.00695
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.33691

Collected Steps per Second: 23,035.91429
Overall Steps per Second: 10,896.76403

Timestep Collection Time: 2.17139
Timestep Consumption Time: 2.41896
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.59035

Cumulative Model Updates: 315,644
Cumulative Timesteps: 2,632,333,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2632333888...
Checkpoint 2632333888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.03656
Policy Entropy: 4.45887
Value Function Loss: 0.00211

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00727
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.35091

Collected Steps per Second: 23,177.64707
Overall Steps per Second: 10,922.74913

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.42132
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.57943

Cumulative Model Updates: 315,650
Cumulative Timesteps: 2,632,383,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.10626
Policy Entropy: 4.45874
Value Function Loss: 0.00206

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00548
Policy Update Magnitude: 0.34734
Value Function Update Magnitude: 0.37007

Collected Steps per Second: 22,084.28154
Overall Steps per Second: 10,565.28119

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.46981
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.73513

Cumulative Model Updates: 315,656
Cumulative Timesteps: 2,632,433,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2632433936...
Checkpoint 2632433936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.56918
Policy Entropy: 4.45861
Value Function Loss: 0.00205

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00593
Policy Update Magnitude: 0.31065
Value Function Update Magnitude: 0.36340

Collected Steps per Second: 22,413.07175
Overall Steps per Second: 10,848.75109

Timestep Collection Time: 2.23263
Timestep Consumption Time: 2.37989
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.61251

Cumulative Model Updates: 315,662
Cumulative Timesteps: 2,632,483,976

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.46127
Policy Entropy: 4.45932
Value Function Loss: 0.00184

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00556
Policy Update Magnitude: 0.30047
Value Function Update Magnitude: 0.36721

Collected Steps per Second: 22,473.55798
Overall Steps per Second: 10,655.85174

Timestep Collection Time: 2.22555
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.69376

Cumulative Model Updates: 315,668
Cumulative Timesteps: 2,632,533,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2632533992...
Checkpoint 2632533992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.10129
Policy Entropy: 4.46214
Value Function Loss: 0.00167

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00350
Policy Update Magnitude: 0.27113
Value Function Update Magnitude: 0.36377

Collected Steps per Second: 22,316.50121
Overall Steps per Second: 10,751.43042

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.41015
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.65073

Cumulative Model Updates: 315,674
Cumulative Timesteps: 2,632,583,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.28961
Policy Entropy: 4.46019
Value Function Loss: 0.00172

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.26896
Value Function Update Magnitude: 0.31956

Collected Steps per Second: 23,160.90146
Overall Steps per Second: 10,894.64064

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27456
Total Iteration Time: 4.59180

Cumulative Model Updates: 315,680
Cumulative Timesteps: 2,632,634,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2632634020...
Checkpoint 2632634020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.28524
Policy Entropy: 4.45907
Value Function Loss: 0.00156

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.26860
Value Function Update Magnitude: 0.30990

Collected Steps per Second: 22,092.70729
Overall Steps per Second: 10,575.43633

Timestep Collection Time: 2.26364
Timestep Consumption Time: 2.46524
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.72888

Cumulative Model Updates: 315,686
Cumulative Timesteps: 2,632,684,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.01135
Policy Entropy: 4.45287
Value Function Loss: 0.00153

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00619
Policy Update Magnitude: 0.27512
Value Function Update Magnitude: 0.30194

Collected Steps per Second: 22,045.09041
Overall Steps per Second: 10,836.26866

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.34606
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.61413

Cumulative Model Updates: 315,692
Cumulative Timesteps: 2,632,734,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2632734030...
Checkpoint 2632734030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.42551
Policy Entropy: 4.45394
Value Function Loss: 0.00183

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00502
Policy Update Magnitude: 0.25768
Value Function Update Magnitude: 0.33451

Collected Steps per Second: 22,699.65388
Overall Steps per Second: 10,683.05207

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.47823
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.68143

Cumulative Model Updates: 315,698
Cumulative Timesteps: 2,632,784,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.31902
Policy Entropy: 4.45507
Value Function Loss: 0.00221

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00542
Policy Update Magnitude: 0.28650
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,606.22955
Overall Steps per Second: 10,558.71679

Timestep Collection Time: 2.21275
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.73751

Cumulative Model Updates: 315,704
Cumulative Timesteps: 2,632,834,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2632834064...
Checkpoint 2632834064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.07126
Policy Entropy: 4.45608
Value Function Loss: 0.00239

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00470
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.37496

Collected Steps per Second: 23,900.18770
Overall Steps per Second: 10,972.14835

Timestep Collection Time: 2.09329
Timestep Consumption Time: 2.46644
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.55973

Cumulative Model Updates: 315,710
Cumulative Timesteps: 2,632,884,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.36058
Policy Entropy: 4.45574
Value Function Loss: 0.00246

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00463
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.39757

Collected Steps per Second: 22,701.99810
Overall Steps per Second: 10,675.01587

Timestep Collection Time: 2.20280
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.68458

Cumulative Model Updates: 315,716
Cumulative Timesteps: 2,632,934,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2632934102...
Checkpoint 2632934102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.59747
Policy Entropy: 4.45943
Value Function Loss: 0.00238

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00400
Policy Update Magnitude: 0.32414
Value Function Update Magnitude: 0.39907

Collected Steps per Second: 23,173.46534
Overall Steps per Second: 10,897.92485

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.58858

Cumulative Model Updates: 315,722
Cumulative Timesteps: 2,632,984,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.52785
Policy Entropy: 4.46424
Value Function Loss: 0.00187

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.29722
Value Function Update Magnitude: 0.45189

Collected Steps per Second: 23,149.85518
Overall Steps per Second: 10,901.01530

Timestep Collection Time: 2.16019
Timestep Consumption Time: 2.42728
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.58746

Cumulative Model Updates: 315,728
Cumulative Timesteps: 2,633,034,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2633034116...
Checkpoint 2633034116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.82454
Policy Entropy: 4.46728
Value Function Loss: 0.00168

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00302
Policy Update Magnitude: 0.24727
Value Function Update Magnitude: 0.40289

Collected Steps per Second: 22,287.80956
Overall Steps per Second: 10,674.03557

Timestep Collection Time: 2.24383
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.68520

Cumulative Model Updates: 315,734
Cumulative Timesteps: 2,633,084,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.35549
Policy Entropy: 4.46127
Value Function Loss: 0.00145

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00230
Policy Update Magnitude: 0.24910
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 23,299.82014
Overall Steps per Second: 10,984.08809

Timestep Collection Time: 2.14706
Timestep Consumption Time: 2.40735
PPO Batch Consumption Time: 0.27466
Total Iteration Time: 4.55441

Cumulative Model Updates: 315,740
Cumulative Timesteps: 2,633,134,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2633134152...
Checkpoint 2633134152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.29345
Policy Entropy: 4.46117
Value Function Loss: 0.00127

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.23761
Value Function Update Magnitude: 0.32314

Collected Steps per Second: 22,421.25331
Overall Steps per Second: 10,557.58426

Timestep Collection Time: 2.23101
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.73802

Cumulative Model Updates: 315,746
Cumulative Timesteps: 2,633,184,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.26344
Policy Entropy: 4.45812
Value Function Loss: 0.00094

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00300
Policy Update Magnitude: 0.20646
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 22,340.26245
Overall Steps per Second: 10,874.83174

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.35976
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.59796

Cumulative Model Updates: 315,752
Cumulative Timesteps: 2,633,234,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2633234176...
Checkpoint 2633234176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.66495
Policy Entropy: 4.46139
Value Function Loss: 0.00097

Mean KL Divergence: 0.00022
SB3 Clip Fraction: 0.00215
Policy Update Magnitude: 0.20808
Value Function Update Magnitude: 0.28300

Collected Steps per Second: 22,649.54882
Overall Steps per Second: 10,731.13588

Timestep Collection Time: 2.20790
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.66008

Cumulative Model Updates: 315,758
Cumulative Timesteps: 2,633,284,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.52618
Policy Entropy: 4.46442
Value Function Loss: 0.00100

Mean KL Divergence: 0.00024
SB3 Clip Fraction: 0.00253
Policy Update Magnitude: 0.20552
Value Function Update Magnitude: 0.29929

Collected Steps per Second: 23,107.78014
Overall Steps per Second: 10,897.37769

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.27533
Total Iteration Time: 4.58826

Cumulative Model Updates: 315,764
Cumulative Timesteps: 2,633,334,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2633334184...
Checkpoint 2633334184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.97279
Policy Entropy: 4.46622
Value Function Loss: 0.00129

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00254
Policy Update Magnitude: 0.21953
Value Function Update Magnitude: 0.32621

Collected Steps per Second: 23,594.04578
Overall Steps per Second: 11,028.96630

Timestep Collection Time: 2.11952
Timestep Consumption Time: 2.41472
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.53424

Cumulative Model Updates: 315,770
Cumulative Timesteps: 2,633,384,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.76347
Policy Entropy: 4.46559
Value Function Loss: 0.00168

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00298
Policy Update Magnitude: 0.25491
Value Function Update Magnitude: 0.36840

Collected Steps per Second: 22,998.95484
Overall Steps per Second: 10,848.65962

Timestep Collection Time: 2.17497
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.61089

Cumulative Model Updates: 315,776
Cumulative Timesteps: 2,633,434,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2633434214...
Checkpoint 2633434214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.95076
Policy Entropy: 4.46141
Value Function Loss: 0.00182

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00438
Policy Update Magnitude: 0.30187
Value Function Update Magnitude: 0.39954

Collected Steps per Second: 22,628.09087
Overall Steps per Second: 10,735.22193

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65999

Cumulative Model Updates: 315,782
Cumulative Timesteps: 2,633,484,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.17125
Policy Entropy: 4.45882
Value Function Loss: 0.00201

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00410
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.38326

Collected Steps per Second: 24,039.74307
Overall Steps per Second: 10,916.90426

Timestep Collection Time: 2.08022
Timestep Consumption Time: 2.50056
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.58079

Cumulative Model Updates: 315,788
Cumulative Timesteps: 2,633,534,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2633534248...
Checkpoint 2633534248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.10308
Policy Entropy: 4.45933
Value Function Loss: 0.00189

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.28806
Value Function Update Magnitude: 0.36149

Collected Steps per Second: 22,065.32481
Overall Steps per Second: 10,636.66898

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.43589
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.70298

Cumulative Model Updates: 315,794
Cumulative Timesteps: 2,633,584,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.05101
Policy Entropy: 4.45896
Value Function Loss: 0.00203

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00342
Policy Update Magnitude: 0.28738
Value Function Update Magnitude: 0.37703

Collected Steps per Second: 22,638.16315
Overall Steps per Second: 11,013.08221

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.33168
PPO Batch Consumption Time: 0.27397
Total Iteration Time: 4.54060

Cumulative Model Updates: 315,800
Cumulative Timesteps: 2,633,634,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2633634278...
Checkpoint 2633634278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.31000
Policy Entropy: 4.45952
Value Function Loss: 0.00185

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.31938
Value Function Update Magnitude: 0.35026

Collected Steps per Second: 22,246.82922
Overall Steps per Second: 10,556.94458

Timestep Collection Time: 2.24796
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.73717

Cumulative Model Updates: 315,806
Cumulative Timesteps: 2,633,684,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.02652
Policy Entropy: 4.45984
Value Function Loss: 0.00181

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.36088

Collected Steps per Second: 22,700.98932
Overall Steps per Second: 10,835.63070

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.61644

Cumulative Model Updates: 315,812
Cumulative Timesteps: 2,633,734,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2633734310...
Checkpoint 2633734310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.30337
Policy Entropy: 4.46223
Value Function Loss: 0.00205

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00602
Policy Update Magnitude: 0.29769
Value Function Update Magnitude: 0.37220

Collected Steps per Second: 23,799.92792
Overall Steps per Second: 10,870.05242

Timestep Collection Time: 2.10110
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.60035

Cumulative Model Updates: 315,818
Cumulative Timesteps: 2,633,784,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.57941
Policy Entropy: 4.46001
Value Function Loss: 0.00234

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.32827
Value Function Update Magnitude: 0.41219

Collected Steps per Second: 23,214.32110
Overall Steps per Second: 10,759.77810

Timestep Collection Time: 2.15453
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.64842

Cumulative Model Updates: 315,824
Cumulative Timesteps: 2,633,834,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2633834332...
Checkpoint 2633834332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.88331
Policy Entropy: 4.45932
Value Function Loss: 0.00221

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00453
Policy Update Magnitude: 0.32190
Value Function Update Magnitude: 0.43224

Collected Steps per Second: 23,136.42282
Overall Steps per Second: 11,121.10235

Timestep Collection Time: 2.16135
Timestep Consumption Time: 2.33514
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.49650

Cumulative Model Updates: 315,830
Cumulative Timesteps: 2,633,884,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.78890
Policy Entropy: 4.45807
Value Function Loss: 0.00203

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.31687
Value Function Update Magnitude: 0.40393

Collected Steps per Second: 22,955.12115
Overall Steps per Second: 10,838.80936

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.61379

Cumulative Model Updates: 315,836
Cumulative Timesteps: 2,633,934,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2633934346...
Checkpoint 2633934346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.91924
Policy Entropy: 4.45744
Value Function Loss: 0.00200

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.32424
Value Function Update Magnitude: 0.37632

Collected Steps per Second: 22,635.75469
Overall Steps per Second: 10,681.54400

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68378

Cumulative Model Updates: 315,842
Cumulative Timesteps: 2,633,984,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.46748
Policy Entropy: 4.45506
Value Function Loss: 0.00209

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.30680
Value Function Update Magnitude: 0.39434

Collected Steps per Second: 23,276.14241
Overall Steps per Second: 11,004.97022

Timestep Collection Time: 2.14821
Timestep Consumption Time: 2.39538
PPO Batch Consumption Time: 0.27401
Total Iteration Time: 4.54358

Cumulative Model Updates: 315,848
Cumulative Timesteps: 2,634,034,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2634034378...
Checkpoint 2634034378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.27728
Policy Entropy: 4.45581
Value Function Loss: 0.00193

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00347
Policy Update Magnitude: 0.27197
Value Function Update Magnitude: 0.43843

Collected Steps per Second: 22,359.79105
Overall Steps per Second: 10,587.86987

Timestep Collection Time: 2.23625
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.72257

Cumulative Model Updates: 315,854
Cumulative Timesteps: 2,634,084,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.69791
Policy Entropy: 4.45521
Value Function Loss: 0.00166

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00357
Policy Update Magnitude: 0.27445
Value Function Update Magnitude: 0.37315

Collected Steps per Second: 22,574.74720
Overall Steps per Second: 10,786.96438

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.63615

Cumulative Model Updates: 315,860
Cumulative Timesteps: 2,634,134,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2634134390...
Checkpoint 2634134390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.45328
Policy Entropy: 4.45704
Value Function Loss: 0.00156

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.26217
Value Function Update Magnitude: 0.35369

Collected Steps per Second: 23,455.44823
Overall Steps per Second: 10,736.27449

Timestep Collection Time: 2.13196
Timestep Consumption Time: 2.52571
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.65767

Cumulative Model Updates: 315,866
Cumulative Timesteps: 2,634,184,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.44239
Policy Entropy: 4.45744
Value Function Loss: 0.00153

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.26864
Value Function Update Magnitude: 0.33559

Collected Steps per Second: 22,925.79307
Overall Steps per Second: 10,887.09919

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.59388

Cumulative Model Updates: 315,872
Cumulative Timesteps: 2,634,234,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2634234410...
Checkpoint 2634234410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.99398
Policy Entropy: 4.46002
Value Function Loss: 0.00152

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00238
Policy Update Magnitude: 0.25764
Value Function Update Magnitude: 0.31434

Collected Steps per Second: 22,765.86822
Overall Steps per Second: 10,910.58427

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.38758
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.58491

Cumulative Model Updates: 315,878
Cumulative Timesteps: 2,634,284,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.38233
Policy Entropy: 4.45913
Value Function Loss: 0.00155

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00251
Policy Update Magnitude: 0.26969
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 23,149.90126
Overall Steps per Second: 10,750.59133

Timestep Collection Time: 2.16018
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.65165

Cumulative Model Updates: 315,884
Cumulative Timesteps: 2,634,334,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2634334442...
Checkpoint 2634334442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.26723
Policy Entropy: 4.45906
Value Function Loss: 0.00194

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00478
Policy Update Magnitude: 0.29559
Value Function Update Magnitude: 0.37542

Collected Steps per Second: 22,824.10864
Overall Steps per Second: 10,792.52856

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.63524

Cumulative Model Updates: 315,890
Cumulative Timesteps: 2,634,384,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.54916
Policy Entropy: 4.45742
Value Function Loss: 0.00216

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00498
Policy Update Magnitude: 0.29295
Value Function Update Magnitude: 0.38118

Collected Steps per Second: 23,380.38884
Overall Steps per Second: 10,834.96065

Timestep Collection Time: 2.13872
Timestep Consumption Time: 2.47635
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.61506

Cumulative Model Updates: 315,896
Cumulative Timesteps: 2,634,434,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2634434472...
Checkpoint 2634434472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.53063
Policy Entropy: 4.46360
Value Function Loss: 0.00193

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.28608
Value Function Update Magnitude: 0.40032

Collected Steps per Second: 22,486.69387
Overall Steps per Second: 10,664.48709

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.69033

Cumulative Model Updates: 315,902
Cumulative Timesteps: 2,634,484,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.94167
Policy Entropy: 4.45997
Value Function Loss: 0.00219

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00255
Policy Update Magnitude: 0.27062
Value Function Update Magnitude: 0.41923

Collected Steps per Second: 22,483.28711
Overall Steps per Second: 10,742.98347

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65588

Cumulative Model Updates: 315,908
Cumulative Timesteps: 2,634,534,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2634534510...
Checkpoint 2634534510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.09012
Policy Entropy: 4.46108
Value Function Loss: 0.00206

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00321
Policy Update Magnitude: 0.28855
Value Function Update Magnitude: 0.42677

Collected Steps per Second: 22,607.13199
Overall Steps per Second: 10,601.26764

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.50543
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.71774

Cumulative Model Updates: 315,914
Cumulative Timesteps: 2,634,584,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.74192
Policy Entropy: 4.45808
Value Function Loss: 0.00207

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00393
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.38992

Collected Steps per Second: 22,899.25983
Overall Steps per Second: 10,876.96368

Timestep Collection Time: 2.18418
Timestep Consumption Time: 2.41417
PPO Batch Consumption Time: 0.27576
Total Iteration Time: 4.59834

Cumulative Model Updates: 315,920
Cumulative Timesteps: 2,634,634,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2634634540...
Checkpoint 2634634540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.21671
Policy Entropy: 4.46032
Value Function Loss: 0.00186

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.39947

Collected Steps per Second: 22,839.94491
Overall Steps per Second: 10,891.48651

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.40198
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.59148

Cumulative Model Updates: 315,926
Cumulative Timesteps: 2,634,684,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.82022
Policy Entropy: 4.46016
Value Function Loss: 0.00221

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.29775
Value Function Update Magnitude: 0.38181

Collected Steps per Second: 23,564.10200
Overall Steps per Second: 10,834.74505

Timestep Collection Time: 2.12238
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.61589

Cumulative Model Updates: 315,932
Cumulative Timesteps: 2,634,734,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2634734560...
Checkpoint 2634734560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.93699
Policy Entropy: 4.45873
Value Function Loss: 0.00226

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.33451
Value Function Update Magnitude: 0.40700

Collected Steps per Second: 22,913.32802
Overall Steps per Second: 10,910.56049

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.40183
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.58510

Cumulative Model Updates: 315,938
Cumulative Timesteps: 2,634,784,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.15443
Policy Entropy: 4.46281
Value Function Loss: 0.00221

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.31160
Value Function Update Magnitude: 0.38105

Collected Steps per Second: 23,643.84148
Overall Steps per Second: 11,048.09261

Timestep Collection Time: 2.11607
Timestep Consumption Time: 2.41250
PPO Batch Consumption Time: 0.27551
Total Iteration Time: 4.52856

Cumulative Model Updates: 315,944
Cumulative Timesteps: 2,634,834,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2634834618...
Checkpoint 2634834618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.09538
Policy Entropy: 4.46077
Value Function Loss: 0.00198

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00351
Policy Update Magnitude: 0.30922
Value Function Update Magnitude: 0.37232

Collected Steps per Second: 22,669.20916
Overall Steps per Second: 10,616.50281

Timestep Collection Time: 2.20581
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.71003

Cumulative Model Updates: 315,950
Cumulative Timesteps: 2,634,884,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.37369
Policy Entropy: 4.45942
Value Function Loss: 0.00161

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.29046
Value Function Update Magnitude: 0.36923

Collected Steps per Second: 22,605.71588
Overall Steps per Second: 10,911.21443

Timestep Collection Time: 2.21307
Timestep Consumption Time: 2.37194
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.58501

Cumulative Model Updates: 315,956
Cumulative Timesteps: 2,634,934,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2634934650...
Checkpoint 2634934650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.20126
Policy Entropy: 4.45943
Value Function Loss: 0.00168

Mean KL Divergence: 0.00077
SB3 Clip Fraction: 0.00446
Policy Update Magnitude: 0.30052
Value Function Update Magnitude: 0.35976

Collected Steps per Second: 22,273.31625
Overall Steps per Second: 10,612.73561

Timestep Collection Time: 2.24619
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.71415

Cumulative Model Updates: 315,962
Cumulative Timesteps: 2,634,984,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.62607
Policy Entropy: 4.45921
Value Function Loss: 0.00175

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.27634
Value Function Update Magnitude: 0.35623

Collected Steps per Second: 22,531.01326
Overall Steps per Second: 10,737.77415

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.65702

Cumulative Model Updates: 315,968
Cumulative Timesteps: 2,635,034,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2635034686...
Checkpoint 2635034686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.97154
Policy Entropy: 4.45834
Value Function Loss: 0.00192

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00376
Policy Update Magnitude: 0.27539
Value Function Update Magnitude: 0.35144

Collected Steps per Second: 23,713.76259
Overall Steps per Second: 10,852.33155

Timestep Collection Time: 2.10924
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.60896

Cumulative Model Updates: 315,974
Cumulative Timesteps: 2,635,084,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.73663
Policy Entropy: 4.45399
Value Function Loss: 0.00200

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00307
Policy Update Magnitude: 0.25879
Value Function Update Magnitude: 0.40335

Collected Steps per Second: 23,250.93537
Overall Steps per Second: 10,879.34680

Timestep Collection Time: 2.15131
Timestep Consumption Time: 2.44639
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.59770

Cumulative Model Updates: 315,980
Cumulative Timesteps: 2,635,134,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2635134724...
Checkpoint 2635134724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.56635
Policy Entropy: 4.45567
Value Function Loss: 0.00180

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00306
Policy Update Magnitude: 0.26966
Value Function Update Magnitude: 0.37533

Collected Steps per Second: 22,655.58412
Overall Steps per Second: 10,641.67922

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.70039

Cumulative Model Updates: 315,986
Cumulative Timesteps: 2,635,184,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.05562
Policy Entropy: 4.45688
Value Function Loss: 0.00187

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00343
Policy Update Magnitude: 0.27369
Value Function Update Magnitude: 0.42247

Collected Steps per Second: 23,998.89521
Overall Steps per Second: 10,972.46842

Timestep Collection Time: 2.08401
Timestep Consumption Time: 2.47412
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.55814

Cumulative Model Updates: 315,992
Cumulative Timesteps: 2,635,234,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2635234758...
Checkpoint 2635234758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.02074
Policy Entropy: 4.46033
Value Function Loss: 0.00137

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00319
Policy Update Magnitude: 0.26880
Value Function Update Magnitude: 0.44461

Collected Steps per Second: 22,584.90079
Overall Steps per Second: 10,617.36919

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.71002

Cumulative Model Updates: 315,998
Cumulative Timesteps: 2,635,284,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.17632
Policy Entropy: 4.46094
Value Function Loss: 0.00136

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00285
Policy Update Magnitude: 0.23024
Value Function Update Magnitude: 0.41602

Collected Steps per Second: 23,080.99104
Overall Steps per Second: 10,928.43197

Timestep Collection Time: 2.16646
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.57559

Cumulative Model Updates: 316,004
Cumulative Timesteps: 2,635,334,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2635334770...
Checkpoint 2635334770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.53377
Policy Entropy: 4.46315
Value Function Loss: 0.00114

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00264
Policy Update Magnitude: 0.21733
Value Function Update Magnitude: 0.35578

Collected Steps per Second: 22,303.01785
Overall Steps per Second: 10,572.46697

Timestep Collection Time: 2.24212
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.72983

Cumulative Model Updates: 316,010
Cumulative Timesteps: 2,635,384,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.54502
Policy Entropy: 4.46642
Value Function Loss: 0.00127

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00412
Policy Update Magnitude: 0.20510
Value Function Update Magnitude: 0.31154

Collected Steps per Second: 22,653.77401
Overall Steps per Second: 10,772.56303

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.64346

Cumulative Model Updates: 316,016
Cumulative Timesteps: 2,635,434,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2635434798...
Checkpoint 2635434798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.76945
Policy Entropy: 4.46827
Value Function Loss: 0.00130

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00234
Policy Update Magnitude: 0.20016
Value Function Update Magnitude: 0.31285

Collected Steps per Second: 23,000.92214
Overall Steps per Second: 10,914.48537

Timestep Collection Time: 2.17417
Timestep Consumption Time: 2.40763
PPO Batch Consumption Time: 0.27407
Total Iteration Time: 4.58180

Cumulative Model Updates: 316,022
Cumulative Timesteps: 2,635,484,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.94842
Policy Entropy: 4.46109
Value Function Loss: 0.00155

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00326
Policy Update Magnitude: 0.22902
Value Function Update Magnitude: 0.30217

Collected Steps per Second: 22,488.46005
Overall Steps per Second: 10,581.82455

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.72697

Cumulative Model Updates: 316,028
Cumulative Timesteps: 2,635,534,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2635534826...
Checkpoint 2635534826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.12324
Policy Entropy: 4.46500
Value Function Loss: 0.00199

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00412
Policy Update Magnitude: 0.26361
Value Function Update Magnitude: 0.32040

Collected Steps per Second: 22,801.33561
Overall Steps per Second: 10,911.78481

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.38935
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.58220

Cumulative Model Updates: 316,034
Cumulative Timesteps: 2,635,584,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.32417
Policy Entropy: 4.46514
Value Function Loss: 0.00222

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.26449
Value Function Update Magnitude: 0.40558

Collected Steps per Second: 22,757.35330
Overall Steps per Second: 10,816.27699

Timestep Collection Time: 2.19736
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.62322

Cumulative Model Updates: 316,040
Cumulative Timesteps: 2,635,634,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2635634832...
Checkpoint 2635634832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.79984
Policy Entropy: 4.46874
Value Function Loss: 0.00230

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00266
Policy Update Magnitude: 0.28452
Value Function Update Magnitude: 0.44205

Collected Steps per Second: 22,859.80263
Overall Steps per Second: 10,737.37580

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.47018
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.65812

Cumulative Model Updates: 316,046
Cumulative Timesteps: 2,635,684,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.24018
Policy Entropy: 4.46390
Value Function Loss: 0.00194

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00341
Policy Update Magnitude: 0.28199
Value Function Update Magnitude: 0.39892

Collected Steps per Second: 23,819.67998
Overall Steps per Second: 10,875.30078

Timestep Collection Time: 2.09936
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.59813

Cumulative Model Updates: 316,052
Cumulative Timesteps: 2,635,734,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2635734854...
Checkpoint 2635734854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.11883
Policy Entropy: 4.45557
Value Function Loss: 0.00236

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00571
Policy Update Magnitude: 0.29192
Value Function Update Magnitude: 0.39317

Collected Steps per Second: 22,713.74114
Overall Steps per Second: 10,629.45480

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.70485

Cumulative Model Updates: 316,058
Cumulative Timesteps: 2,635,784,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.23744
Policy Entropy: 4.45570
Value Function Loss: 0.00212

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00457
Policy Update Magnitude: 0.33831
Value Function Update Magnitude: 0.38564

Collected Steps per Second: 22,332.92213
Overall Steps per Second: 10,664.78397

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.45095
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.69114

Cumulative Model Updates: 316,064
Cumulative Timesteps: 2,635,834,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2635834894...
Checkpoint 2635834894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.73917
Policy Entropy: 4.45331
Value Function Loss: 0.00249

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00454
Policy Update Magnitude: 0.38036
Value Function Update Magnitude: 0.38842

Collected Steps per Second: 23,223.74426
Overall Steps per Second: 11,004.24951

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.39207
PPO Batch Consumption Time: 0.27440
Total Iteration Time: 4.54624

Cumulative Model Updates: 316,070
Cumulative Timesteps: 2,635,884,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.84036
Policy Entropy: 4.45584
Value Function Loss: 0.00206

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00634
Policy Update Magnitude: 0.36052
Value Function Update Magnitude: 0.39857

Collected Steps per Second: 22,982.98710
Overall Steps per Second: 10,827.19356

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61837

Cumulative Model Updates: 316,076
Cumulative Timesteps: 2,635,934,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2635934926...
Checkpoint 2635934926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.49973
Policy Entropy: 4.45779
Value Function Loss: 0.00193

Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00702
Policy Update Magnitude: 0.32011
Value Function Update Magnitude: 0.45575

Collected Steps per Second: 23,026.30761
Overall Steps per Second: 11,003.32911

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.37341
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.54553

Cumulative Model Updates: 316,082
Cumulative Timesteps: 2,635,984,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.34102
Policy Entropy: 4.46273
Value Function Loss: 0.00191

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00568
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.42523

Collected Steps per Second: 23,052.24541
Overall Steps per Second: 10,762.80764

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.64749

Cumulative Model Updates: 316,088
Cumulative Timesteps: 2,636,034,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2636034962...
Checkpoint 2636034962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.94826
Policy Entropy: 4.46135
Value Function Loss: 0.00177

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00521
Policy Update Magnitude: 0.30597
Value Function Update Magnitude: 0.43603

Collected Steps per Second: 22,850.80725
Overall Steps per Second: 10,940.54857

Timestep Collection Time: 2.18881
Timestep Consumption Time: 2.38281
PPO Batch Consumption Time: 0.27450
Total Iteration Time: 4.57162

Cumulative Model Updates: 316,094
Cumulative Timesteps: 2,636,084,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.95937
Policy Entropy: 4.45810
Value Function Loss: 0.00214

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.41083

Collected Steps per Second: 24,091.29436
Overall Steps per Second: 10,981.32696

Timestep Collection Time: 2.07635
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.55519

Cumulative Model Updates: 316,100
Cumulative Timesteps: 2,636,135,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2636135000...
Checkpoint 2636135000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.67206
Policy Entropy: 4.45366
Value Function Loss: 0.00216

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00528
Policy Update Magnitude: 0.35206
Value Function Update Magnitude: 0.38502

Collected Steps per Second: 22,640.46443
Overall Steps per Second: 10,665.22604

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.47980
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.68832

Cumulative Model Updates: 316,106
Cumulative Timesteps: 2,636,185,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.71245
Policy Entropy: 4.45074
Value Function Loss: 0.00232

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00598
Policy Update Magnitude: 0.36724
Value Function Update Magnitude: 0.37375

Collected Steps per Second: 22,425.60038
Overall Steps per Second: 10,813.46919

Timestep Collection Time: 2.23075
Timestep Consumption Time: 2.39551
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.62627

Cumulative Model Updates: 316,112
Cumulative Timesteps: 2,636,235,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2636235028...
Checkpoint 2636235028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.90642
Policy Entropy: 4.44880
Value Function Loss: 0.00242

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00568
Policy Update Magnitude: 0.35801
Value Function Update Magnitude: 0.33758

Collected Steps per Second: 22,608.36304
Overall Steps per Second: 10,607.02101

Timestep Collection Time: 2.21228
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.71537

Cumulative Model Updates: 316,118
Cumulative Timesteps: 2,636,285,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.99215
Policy Entropy: 4.45227
Value Function Loss: 0.00277

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.33526
Value Function Update Magnitude: 0.38696

Collected Steps per Second: 22,789.41781
Overall Steps per Second: 10,882.10318

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.40108
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.59544

Cumulative Model Updates: 316,124
Cumulative Timesteps: 2,636,335,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2636335052...
Checkpoint 2636335052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.90771
Policy Entropy: 4.44751
Value Function Loss: 0.00285

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00626
Policy Update Magnitude: 0.35237
Value Function Update Magnitude: 0.48854

Collected Steps per Second: 23,608.20458
Overall Steps per Second: 10,769.31983

Timestep Collection Time: 2.11960
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.64653

Cumulative Model Updates: 316,130
Cumulative Timesteps: 2,636,385,092

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.24961
Policy Entropy: 4.44482
Value Function Loss: 0.00321

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00613
Policy Update Magnitude: 0.35979
Value Function Update Magnitude: 0.48962

Collected Steps per Second: 23,465.60353
Overall Steps per Second: 10,820.58107

Timestep Collection Time: 2.13146
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.62230

Cumulative Model Updates: 316,136
Cumulative Timesteps: 2,636,435,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2636435108...
Checkpoint 2636435108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.94830
Policy Entropy: 4.44610
Value Function Loss: 0.00283

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.35978
Value Function Update Magnitude: 0.43278

Collected Steps per Second: 22,624.21642
Overall Steps per Second: 10,661.16555

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69179

Cumulative Model Updates: 316,142
Cumulative Timesteps: 2,636,485,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.66130
Policy Entropy: 4.45256
Value Function Loss: 0.00275

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00519
Policy Update Magnitude: 0.37632
Value Function Update Magnitude: 0.39690

Collected Steps per Second: 22,782.70604
Overall Steps per Second: 10,615.57318

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.71289

Cumulative Model Updates: 316,148
Cumulative Timesteps: 2,636,535,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2636535158...
Checkpoint 2636535158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.08689
Policy Entropy: 4.45203
Value Function Loss: 0.00225

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00611
Policy Update Magnitude: 0.30551
Value Function Update Magnitude: 0.35127

Collected Steps per Second: 22,817.24350
Overall Steps per Second: 10,674.42680

Timestep Collection Time: 2.19220
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.68597

Cumulative Model Updates: 316,154
Cumulative Timesteps: 2,636,585,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.17327
Policy Entropy: 4.45045
Value Function Loss: 0.00225

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00473
Policy Update Magnitude: 0.29031
Value Function Update Magnitude: 0.40767

Collected Steps per Second: 23,055.20930
Overall Steps per Second: 11,070.61197

Timestep Collection Time: 2.16966
Timestep Consumption Time: 2.34879
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.51845

Cumulative Model Updates: 316,160
Cumulative Timesteps: 2,636,635,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2636635200...
Checkpoint 2636635200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.90213
Policy Entropy: 4.45254
Value Function Loss: 0.00213

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00453
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.47319

Collected Steps per Second: 22,150.97278
Overall Steps per Second: 10,668.20874

Timestep Collection Time: 2.25733
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.68701

Cumulative Model Updates: 316,166
Cumulative Timesteps: 2,636,685,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.00229
Policy Entropy: 4.45636
Value Function Loss: 0.00180

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.27657
Value Function Update Magnitude: 0.40781

Collected Steps per Second: 22,543.67381
Overall Steps per Second: 10,690.08509

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.68153

Cumulative Model Updates: 316,172
Cumulative Timesteps: 2,636,735,248

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2636735248...
Checkpoint 2636735248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.09301
Policy Entropy: 4.45632
Value Function Loss: 0.00204

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00539
Policy Update Magnitude: 0.28011
Value Function Update Magnitude: 0.38188

Collected Steps per Second: 23,082.58641
Overall Steps per Second: 10,896.58595

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.58951

Cumulative Model Updates: 316,178
Cumulative Timesteps: 2,636,785,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.33506
Policy Entropy: 4.45492
Value Function Loss: 0.00186

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.29542
Value Function Update Magnitude: 0.36650

Collected Steps per Second: 22,597.99308
Overall Steps per Second: 10,625.31493

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.70781

Cumulative Model Updates: 316,184
Cumulative Timesteps: 2,636,835,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2636835280...
Checkpoint 2636835280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.95819
Policy Entropy: 4.45399
Value Function Loss: 0.00225

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00438
Policy Update Magnitude: 0.30687
Value Function Update Magnitude: 0.34809

Collected Steps per Second: 22,995.74509
Overall Steps per Second: 10,958.16933

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.38983
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.56536

Cumulative Model Updates: 316,190
Cumulative Timesteps: 2,636,885,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.88999
Policy Entropy: 4.45494
Value Function Loss: 0.00188

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00445
Policy Update Magnitude: 0.29231
Value Function Update Magnitude: 0.37353

Collected Steps per Second: 22,603.04182
Overall Steps per Second: 10,663.66645

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.47762
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.69051

Cumulative Model Updates: 316,196
Cumulative Timesteps: 2,636,935,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2636935326...
Checkpoint 2636935326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.13310
Policy Entropy: 4.45971
Value Function Loss: 0.00183

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.26966
Value Function Update Magnitude: 0.40565

Collected Steps per Second: 22,714.20334
Overall Steps per Second: 10,840.03510

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.61419

Cumulative Model Updates: 316,202
Cumulative Timesteps: 2,636,985,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.65966
Policy Entropy: 4.46445
Value Function Loss: 0.00137

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00295
Policy Update Magnitude: 0.25533
Value Function Update Magnitude: 0.35251

Collected Steps per Second: 23,774.42127
Overall Steps per Second: 10,952.69943

Timestep Collection Time: 2.10445
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.56801

Cumulative Model Updates: 316,208
Cumulative Timesteps: 2,637,035,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2637035376...
Checkpoint 2637035376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.13959
Policy Entropy: 4.46312
Value Function Loss: 0.00140

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00311
Policy Update Magnitude: 0.22725
Value Function Update Magnitude: 0.29523

Collected Steps per Second: 22,588.32271
Overall Steps per Second: 10,647.39233

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.69599

Cumulative Model Updates: 316,214
Cumulative Timesteps: 2,637,085,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.01133
Policy Entropy: 4.45883
Value Function Loss: 0.00202

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.25478
Value Function Update Magnitude: 0.28748

Collected Steps per Second: 22,255.22326
Overall Steps per Second: 10,903.46646

Timestep Collection Time: 2.24666
Timestep Consumption Time: 2.33903
PPO Batch Consumption Time: 0.27547
Total Iteration Time: 4.58570

Cumulative Model Updates: 316,220
Cumulative Timesteps: 2,637,135,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2637135376...
Checkpoint 2637135376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.70448
Policy Entropy: 4.45534
Value Function Loss: 0.00226

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00511
Policy Update Magnitude: 0.26950
Value Function Update Magnitude: 0.30542

Collected Steps per Second: 22,420.56689
Overall Steps per Second: 10,656.67260

Timestep Collection Time: 2.23099
Timestep Consumption Time: 2.46279
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.69377

Cumulative Model Updates: 316,226
Cumulative Timesteps: 2,637,185,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.42530
Policy Entropy: 4.45448
Value Function Loss: 0.00241

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00478
Policy Update Magnitude: 0.28535
Value Function Update Magnitude: 0.33665

Collected Steps per Second: 22,285.02091
Overall Steps per Second: 10,646.77974

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.69889

Cumulative Model Updates: 316,232
Cumulative Timesteps: 2,637,235,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2637235424...
Checkpoint 2637235424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.17577
Policy Entropy: 4.45825
Value Function Loss: 0.00168

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00318
Policy Update Magnitude: 0.27034
Value Function Update Magnitude: 0.32263

Collected Steps per Second: 23,904.58056
Overall Steps per Second: 10,928.70544

Timestep Collection Time: 2.09173
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.57529

Cumulative Model Updates: 316,238
Cumulative Timesteps: 2,637,285,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.69601
Policy Entropy: 4.46140
Value Function Loss: 0.00163

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00252
Policy Update Magnitude: 0.24587
Value Function Update Magnitude: 0.38896

Collected Steps per Second: 23,291.09420
Overall Steps per Second: 10,860.32200

Timestep Collection Time: 2.14726
Timestep Consumption Time: 2.45776
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.60502

Cumulative Model Updates: 316,244
Cumulative Timesteps: 2,637,335,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2637335438...
Checkpoint 2637335438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.24634
Policy Entropy: 4.46394
Value Function Loss: 0.00129

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00296
Policy Update Magnitude: 0.23791
Value Function Update Magnitude: 0.35886

Collected Steps per Second: 23,056.53627
Overall Steps per Second: 11,072.95190

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.34768
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.51695

Cumulative Model Updates: 316,250
Cumulative Timesteps: 2,637,385,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.49913
Policy Entropy: 4.45875
Value Function Loss: 0.00169

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00486
Policy Update Magnitude: 0.24498
Value Function Update Magnitude: 0.48042

Collected Steps per Second: 23,061.17576
Overall Steps per Second: 10,889.95110

Timestep Collection Time: 2.16823
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.59157

Cumulative Model Updates: 316,256
Cumulative Timesteps: 2,637,435,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2637435456...
Checkpoint 2637435456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.63636
Policy Entropy: 4.45714
Value Function Loss: 0.00175

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00430
Policy Update Magnitude: 0.24817
Value Function Update Magnitude: 0.40818

Collected Steps per Second: 22,557.05409
Overall Steps per Second: 10,725.26162

Timestep Collection Time: 2.21784
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.66450

Cumulative Model Updates: 316,262
Cumulative Timesteps: 2,637,485,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.91866
Policy Entropy: 4.45528
Value Function Loss: 0.00177

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00290
Policy Update Magnitude: 0.25754
Value Function Update Magnitude: 0.38400

Collected Steps per Second: 23,641.30012
Overall Steps per Second: 10,935.95729

Timestep Collection Time: 2.11520
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.57262

Cumulative Model Updates: 316,268
Cumulative Timesteps: 2,637,535,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2637535490...
Checkpoint 2637535490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.51858
Policy Entropy: 4.45962
Value Function Loss: 0.00152

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00274
Policy Update Magnitude: 0.25381
Value Function Update Magnitude: 0.36257

Collected Steps per Second: 22,287.10746
Overall Steps per Second: 10,612.33801

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.71300

Cumulative Model Updates: 316,274
Cumulative Timesteps: 2,637,585,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.58370
Policy Entropy: 4.45820
Value Function Loss: 0.00188

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00305
Policy Update Magnitude: 0.24576
Value Function Update Magnitude: 0.34523

Collected Steps per Second: 22,169.74462
Overall Steps per Second: 10,597.08616

Timestep Collection Time: 2.25578
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.71922

Cumulative Model Updates: 316,280
Cumulative Timesteps: 2,637,635,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2637635516...
Checkpoint 2637635516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.33044
Policy Entropy: 4.46035
Value Function Loss: 0.00209

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00458
Policy Update Magnitude: 0.26479
Value Function Update Magnitude: 0.30543

Collected Steps per Second: 23,549.25707
Overall Steps per Second: 10,933.15718

Timestep Collection Time: 2.12431
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.57562

Cumulative Model Updates: 316,286
Cumulative Timesteps: 2,637,685,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61914
Policy Entropy: 4.45609
Value Function Loss: 0.00201

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00425
Policy Update Magnitude: 0.27526
Value Function Update Magnitude: 0.31701

Collected Steps per Second: 23,084.46166
Overall Steps per Second: 10,849.59934

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.44299
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.60939

Cumulative Model Updates: 316,292
Cumulative Timesteps: 2,637,735,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2637735552...
Checkpoint 2637735552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.28358
Policy Entropy: 4.45273
Value Function Loss: 0.00210

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.28716
Value Function Update Magnitude: 0.32556

Collected Steps per Second: 22,624.23996
Overall Steps per Second: 10,812.24377

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.62624

Cumulative Model Updates: 316,298
Cumulative Timesteps: 2,637,785,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.59800
Policy Entropy: 4.45226
Value Function Loss: 0.00199

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.27979
Value Function Update Magnitude: 0.33302

Collected Steps per Second: 23,379.22101
Overall Steps per Second: 10,828.89661

Timestep Collection Time: 2.13951
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.61912

Cumulative Model Updates: 316,304
Cumulative Timesteps: 2,637,835,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2637835592...
Checkpoint 2637835592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.27493
Policy Entropy: 4.45577
Value Function Loss: 0.00221

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.27145
Value Function Update Magnitude: 0.32973

Collected Steps per Second: 22,670.83976
Overall Steps per Second: 10,704.92372

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.46626
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.67262

Cumulative Model Updates: 316,310
Cumulative Timesteps: 2,637,885,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.95901
Policy Entropy: 4.45655
Value Function Loss: 0.00245

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.29241
Value Function Update Magnitude: 0.34005

Collected Steps per Second: 23,524.54978
Overall Steps per Second: 10,848.17722

Timestep Collection Time: 2.12646
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.61128

Cumulative Model Updates: 316,316
Cumulative Timesteps: 2,637,935,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2637935636...
Checkpoint 2637935636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.38529
Policy Entropy: 4.46082
Value Function Loss: 0.00247

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.29885
Value Function Update Magnitude: 0.37540

Collected Steps per Second: 21,982.74519
Overall Steps per Second: 10,595.40994

Timestep Collection Time: 2.27588
Timestep Consumption Time: 2.44598
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.72186

Cumulative Model Updates: 316,322
Cumulative Timesteps: 2,637,985,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.58979
Policy Entropy: 4.45749
Value Function Loss: 0.00283

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00488
Policy Update Magnitude: 0.29232
Value Function Update Magnitude: 0.41608

Collected Steps per Second: 22,555.70545
Overall Steps per Second: 10,945.40492

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.35243
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.57014

Cumulative Model Updates: 316,328
Cumulative Timesteps: 2,638,035,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2638035688...
Checkpoint 2638035688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.00808
Policy Entropy: 4.45698
Value Function Loss: 0.00264

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00466
Policy Update Magnitude: 0.28577
Value Function Update Magnitude: 0.42022

Collected Steps per Second: 22,647.11878
Overall Steps per Second: 10,659.57665

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69287

Cumulative Model Updates: 316,334
Cumulative Timesteps: 2,638,085,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.08873
Policy Entropy: 4.45344
Value Function Loss: 0.00244

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00511
Policy Update Magnitude: 0.27416
Value Function Update Magnitude: 0.39204

Collected Steps per Second: 22,813.58834
Overall Steps per Second: 10,846.65952

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.61230

Cumulative Model Updates: 316,340
Cumulative Timesteps: 2,638,135,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2638135740...
Checkpoint 2638135740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.73338
Policy Entropy: 4.45635
Value Function Loss: 0.00183

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00379
Policy Update Magnitude: 0.26152
Value Function Update Magnitude: 0.35036

Collected Steps per Second: 23,401.40772
Overall Steps per Second: 10,737.73570

Timestep Collection Time: 2.13662
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.65648

Cumulative Model Updates: 316,346
Cumulative Timesteps: 2,638,185,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.67213
Policy Entropy: 4.46070
Value Function Loss: 0.00160

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00350
Policy Update Magnitude: 0.30620
Value Function Update Magnitude: 0.30320

Collected Steps per Second: 23,177.88442
Overall Steps per Second: 10,879.90716

Timestep Collection Time: 2.15809
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59747

Cumulative Model Updates: 316,352
Cumulative Timesteps: 2,638,235,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2638235760...
Checkpoint 2638235760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.15057
Policy Entropy: 4.46162
Value Function Loss: 0.00177

Mean KL Divergence: 0.00062
SB3 Clip Fraction: 0.00465
Policy Update Magnitude: 0.27307
Value Function Update Magnitude: 0.28589

Collected Steps per Second: 22,900.52606
Overall Steps per Second: 11,046.86151

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.34375
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.52798

Cumulative Model Updates: 316,358
Cumulative Timesteps: 2,638,285,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.83752
Policy Entropy: 4.45996
Value Function Loss: 0.00197

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00569
Policy Update Magnitude: 0.25536
Value Function Update Magnitude: 0.28972

Collected Steps per Second: 22,943.54396
Overall Steps per Second: 10,852.94149

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.42905
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.60944

Cumulative Model Updates: 316,364
Cumulative Timesteps: 2,638,335,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2638335806...
Checkpoint 2638335806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.00645
Policy Entropy: 4.45716
Value Function Loss: 0.00193

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00421
Policy Update Magnitude: 0.27390
Value Function Update Magnitude: 0.33921

Collected Steps per Second: 22,502.00670
Overall Steps per Second: 10,727.29453

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.66343

Cumulative Model Updates: 316,370
Cumulative Timesteps: 2,638,385,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.07192
Policy Entropy: 4.44966
Value Function Loss: 0.00234

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00548
Policy Update Magnitude: 0.27693
Value Function Update Magnitude: 0.35525

Collected Steps per Second: 23,159.22047
Overall Steps per Second: 10,886.18438

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.59481

Cumulative Model Updates: 316,376
Cumulative Timesteps: 2,638,435,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2638435852...
Checkpoint 2638435852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.45141
Policy Entropy: 4.45222
Value Function Loss: 0.00215

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00381
Policy Update Magnitude: 0.28014
Value Function Update Magnitude: 0.40004

Collected Steps per Second: 21,035.61382
Overall Steps per Second: 10,226.07235

Timestep Collection Time: 2.37721
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.89005

Cumulative Model Updates: 316,382
Cumulative Timesteps: 2,638,485,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.09260
Policy Entropy: 4.45157
Value Function Loss: 0.00247

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.27807
Value Function Update Magnitude: 0.43833

Collected Steps per Second: 21,989.42413
Overall Steps per Second: 10,693.30385

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.40210
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67601

Cumulative Model Updates: 316,388
Cumulative Timesteps: 2,638,535,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2638535860...
Checkpoint 2638535860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.31717
Policy Entropy: 4.46262
Value Function Loss: 0.00180

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00474
Policy Update Magnitude: 0.27259
Value Function Update Magnitude: 0.47999

Collected Steps per Second: 22,333.75851
Overall Steps per Second: 10,628.34313

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.70459

Cumulative Model Updates: 316,394
Cumulative Timesteps: 2,638,585,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.80447
Policy Entropy: 4.46343
Value Function Loss: 0.00166

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00424
Policy Update Magnitude: 0.21716
Value Function Update Magnitude: 0.46799

Collected Steps per Second: 23,105.99821
Overall Steps per Second: 10,695.11191

Timestep Collection Time: 2.16429
Timestep Consumption Time: 2.51149
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.67578

Cumulative Model Updates: 316,400
Cumulative Timesteps: 2,638,635,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2638635870...
Checkpoint 2638635870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.32104
Policy Entropy: 4.46492
Value Function Loss: 0.00175

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00339
Policy Update Magnitude: 0.21498
Value Function Update Magnitude: 0.41370

Collected Steps per Second: 23,733.12767
Overall Steps per Second: 11,035.48258

Timestep Collection Time: 2.10684
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.53102

Cumulative Model Updates: 316,406
Cumulative Timesteps: 2,638,685,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.85057
Policy Entropy: 4.45895
Value Function Loss: 0.00199

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.24000
Value Function Update Magnitude: 0.41821

Collected Steps per Second: 23,164.97341
Overall Steps per Second: 10,876.24466

Timestep Collection Time: 2.15973
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.59993

Cumulative Model Updates: 316,412
Cumulative Timesteps: 2,638,735,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2638735902...
Checkpoint 2638735902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.01465
Policy Entropy: 4.45776
Value Function Loss: 0.00217

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00351
Policy Update Magnitude: 0.27247
Value Function Update Magnitude: 0.39345

Collected Steps per Second: 22,614.85083
Overall Steps per Second: 10,835.12852

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.40513
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.61739

Cumulative Model Updates: 316,418
Cumulative Timesteps: 2,638,785,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.99406
Policy Entropy: 4.45732
Value Function Loss: 0.00214

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00510
Policy Update Magnitude: 0.28130
Value Function Update Magnitude: 0.35994

Collected Steps per Second: 23,379.39009
Overall Steps per Second: 10,831.97777

Timestep Collection Time: 2.13906
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.61689

Cumulative Model Updates: 316,424
Cumulative Timesteps: 2,638,835,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2638835942...
Checkpoint 2638835942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.30912
Policy Entropy: 4.45770
Value Function Loss: 0.00178

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00669
Policy Update Magnitude: 0.28696
Value Function Update Magnitude: 0.35494

Collected Steps per Second: 22,674.46286
Overall Steps per Second: 10,732.88833

Timestep Collection Time: 2.20689
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.66231

Cumulative Model Updates: 316,430
Cumulative Timesteps: 2,638,885,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.24380
Policy Entropy: 4.45520
Value Function Loss: 0.00187

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00483
Policy Update Magnitude: 0.26048
Value Function Update Magnitude: 0.30783

Collected Steps per Second: 23,188.88947
Overall Steps per Second: 10,811.49839

Timestep Collection Time: 2.15741
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.62730

Cumulative Model Updates: 316,436
Cumulative Timesteps: 2,638,936,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2638936010...
Checkpoint 2638936010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.12744
Policy Entropy: 4.45636
Value Function Loss: 0.00172

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00412
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.30198

Collected Steps per Second: 22,307.74147
Overall Steps per Second: 10,631.52901

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.70788

Cumulative Model Updates: 316,442
Cumulative Timesteps: 2,638,986,062

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.41141
Policy Entropy: 4.45735
Value Function Loss: 0.00186

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00412
Policy Update Magnitude: 0.29110
Value Function Update Magnitude: 0.38252

Collected Steps per Second: 22,502.49435
Overall Steps per Second: 10,925.02784

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.35599
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.57921

Cumulative Model Updates: 316,448
Cumulative Timesteps: 2,639,036,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2639036090...
Checkpoint 2639036090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.79572
Policy Entropy: 4.45681
Value Function Loss: 0.00186

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00386
Policy Update Magnitude: 0.29073
Value Function Update Magnitude: 0.38169

Collected Steps per Second: 22,541.17063
Overall Steps per Second: 10,667.48547

Timestep Collection Time: 2.21878
Timestep Consumption Time: 2.46967
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.68845

Cumulative Model Updates: 316,454
Cumulative Timesteps: 2,639,086,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.78228
Policy Entropy: 4.45183
Value Function Loss: 0.00207

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00423
Policy Update Magnitude: 0.29640
Value Function Update Magnitude: 0.35020

Collected Steps per Second: 23,189.96571
Overall Steps per Second: 10,846.07356

Timestep Collection Time: 2.15619
Timestep Consumption Time: 2.45396
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.61015

Cumulative Model Updates: 316,460
Cumulative Timesteps: 2,639,136,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2639136106...
Checkpoint 2639136106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.48196
Policy Entropy: 4.45470
Value Function Loss: 0.00232

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00530
Policy Update Magnitude: 0.30177
Value Function Update Magnitude: 0.34610

Collected Steps per Second: 23,334.79131
Overall Steps per Second: 10,832.81166

Timestep Collection Time: 2.14315
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.61653

Cumulative Model Updates: 316,466
Cumulative Timesteps: 2,639,186,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.68265
Policy Entropy: 4.46047
Value Function Loss: 0.00200

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.28173
Value Function Update Magnitude: 0.41636

Collected Steps per Second: 21,981.76514
Overall Steps per Second: 10,476.82716

Timestep Collection Time: 2.27580
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.77492

Cumulative Model Updates: 316,472
Cumulative Timesteps: 2,639,236,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2639236142...
Checkpoint 2639236142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.23648
Policy Entropy: 4.46207
Value Function Loss: 0.00178

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00380
Policy Update Magnitude: 0.24851
Value Function Update Magnitude: 0.37945

Collected Steps per Second: 22,617.97650
Overall Steps per Second: 10,972.49991

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.34622
PPO Batch Consumption Time: 0.27527
Total Iteration Time: 4.55685

Cumulative Model Updates: 316,478
Cumulative Timesteps: 2,639,286,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.26168
Policy Entropy: 4.45999
Value Function Loss: 0.00154

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.24555
Value Function Update Magnitude: 0.32844

Collected Steps per Second: 23,226.66390
Overall Steps per Second: 10,869.27921

Timestep Collection Time: 2.15373
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.60233

Cumulative Model Updates: 316,484
Cumulative Timesteps: 2,639,336,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2639336166...
Checkpoint 2639336166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.65611
Policy Entropy: 4.45716
Value Function Loss: 0.00140

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00360
Policy Update Magnitude: 0.23044
Value Function Update Magnitude: 0.31675

Collected Steps per Second: 22,314.85723
Overall Steps per Second: 10,675.57394

Timestep Collection Time: 2.24120
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.68471

Cumulative Model Updates: 316,490
Cumulative Timesteps: 2,639,386,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.37835
Policy Entropy: 4.45672
Value Function Loss: 0.00146

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00370
Policy Update Magnitude: 0.23540
Value Function Update Magnitude: 0.29897

Collected Steps per Second: 22,460.60796
Overall Steps per Second: 10,949.66536

Timestep Collection Time: 2.22728
Timestep Consumption Time: 2.34145
PPO Batch Consumption Time: 0.27476
Total Iteration Time: 4.56872

Cumulative Model Updates: 316,496
Cumulative Timesteps: 2,639,436,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2639436204...
Checkpoint 2639436204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.25277
Policy Entropy: 4.45081
Value Function Loss: 0.00165

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00325
Policy Update Magnitude: 0.27885
Value Function Update Magnitude: 0.29121

Collected Steps per Second: 22,687.73186
Overall Steps per Second: 10,662.62089

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.48614
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.69059

Cumulative Model Updates: 316,502
Cumulative Timesteps: 2,639,486,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.88961
Policy Entropy: 4.45075
Value Function Loss: 0.00179

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00494
Policy Update Magnitude: 0.27004
Value Function Update Magnitude: 0.34053

Collected Steps per Second: 23,049.48536
Overall Steps per Second: 10,811.34236

Timestep Collection Time: 2.16933
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.62496

Cumulative Model Updates: 316,508
Cumulative Timesteps: 2,639,536,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2639536220...
Checkpoint 2639536220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.46951
Policy Entropy: 4.44858
Value Function Loss: 0.00173

Mean KL Divergence: 0.00061
SB3 Clip Fraction: 0.00566
Policy Update Magnitude: 0.26681
Value Function Update Magnitude: 0.33143

Collected Steps per Second: 23,053.63249
Overall Steps per Second: 10,695.94985

Timestep Collection Time: 2.16981
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.67672

Cumulative Model Updates: 316,514
Cumulative Timesteps: 2,639,586,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.05349
Policy Entropy: 4.44836
Value Function Loss: 0.00205

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00372
Policy Update Magnitude: 0.26627
Value Function Update Magnitude: 0.32355

Collected Steps per Second: 23,284.09897
Overall Steps per Second: 10,885.19497

Timestep Collection Time: 2.14790
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59450

Cumulative Model Updates: 316,520
Cumulative Timesteps: 2,639,636,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2639636254...
Checkpoint 2639636254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.63024
Policy Entropy: 4.44846
Value Function Loss: 0.00228

Mean KL Divergence: 0.00066
SB3 Clip Fraction: 0.00552
Policy Update Magnitude: 0.27909
Value Function Update Magnitude: 0.37671

Collected Steps per Second: 22,984.75964
Overall Steps per Second: 11,063.56651

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.34473
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.52078

Cumulative Model Updates: 316,526
Cumulative Timesteps: 2,639,686,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.06198
Policy Entropy: 4.45378
Value Function Loss: 0.00206

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.27579
Value Function Update Magnitude: 0.33365

Collected Steps per Second: 23,049.37264
Overall Steps per Second: 10,896.64989

Timestep Collection Time: 2.16995
Timestep Consumption Time: 2.42008
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.59003

Cumulative Model Updates: 316,532
Cumulative Timesteps: 2,639,736,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2639736286...
Checkpoint 2639736286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.07506
Policy Entropy: 4.45837
Value Function Loss: 0.00168

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.27537
Value Function Update Magnitude: 0.29704

Collected Steps per Second: 22,515.82111
Overall Steps per Second: 10,802.64410

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.62961

Cumulative Model Updates: 316,538
Cumulative Timesteps: 2,639,786,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.19419
Policy Entropy: 4.46159
Value Function Loss: 0.00181

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00411
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.28573

Collected Steps per Second: 22,601.88334
Overall Steps per Second: 10,792.81864

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.63475

Cumulative Model Updates: 316,544
Cumulative Timesteps: 2,639,836,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2639836320...
Checkpoint 2639836320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.39791
Policy Entropy: 4.46252
Value Function Loss: 0.00196

Mean KL Divergence: 0.00068
SB3 Clip Fraction: 0.00598
Policy Update Magnitude: 0.30263
Value Function Update Magnitude: 0.32239

Collected Steps per Second: 22,600.69650
Overall Steps per Second: 10,647.60819

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.69589

Cumulative Model Updates: 316,550
Cumulative Timesteps: 2,639,886,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.45141
Policy Entropy: 4.46228
Value Function Loss: 0.00225

Mean KL Divergence: 0.00057
SB3 Clip Fraction: 0.00447
Policy Update Magnitude: 0.28825
Value Function Update Magnitude: 0.36298

Collected Steps per Second: 23,568.99375
Overall Steps per Second: 10,902.20889

Timestep Collection Time: 2.12253
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.58861

Cumulative Model Updates: 316,556
Cumulative Timesteps: 2,639,936,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2639936346...
Checkpoint 2639936346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.14990
Policy Entropy: 4.46458
Value Function Loss: 0.00188

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.27115
Value Function Update Magnitude: 0.34988

Collected Steps per Second: 23,000.29422
Overall Steps per Second: 10,725.76719

Timestep Collection Time: 2.17493
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.66391

Cumulative Model Updates: 316,562
Cumulative Timesteps: 2,639,986,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.24918
Policy Entropy: 4.46375
Value Function Loss: 0.00192

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00430
Policy Update Magnitude: 0.25889
Value Function Update Magnitude: 0.37972

Collected Steps per Second: 22,707.28626
Overall Steps per Second: 10,855.32053

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.60843

Cumulative Model Updates: 316,568
Cumulative Timesteps: 2,640,036,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2640036396...
Checkpoint 2640036396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.58032
Policy Entropy: 4.46246
Value Function Loss: 0.00176

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00529
Policy Update Magnitude: 0.26150
Value Function Update Magnitude: 0.34644

Collected Steps per Second: 22,925.14849
Overall Steps per Second: 10,681.31419

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68313

Cumulative Model Updates: 316,574
Cumulative Timesteps: 2,640,086,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.82391
Policy Entropy: 4.46098
Value Function Loss: 0.00197

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00489
Policy Update Magnitude: 0.28192
Value Function Update Magnitude: 0.33969

Collected Steps per Second: 22,613.39887
Overall Steps per Second: 10,811.21393

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.41442
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.62612

Cumulative Model Updates: 316,580
Cumulative Timesteps: 2,640,136,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2640136432...
Checkpoint 2640136432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.19602
Policy Entropy: 4.46017
Value Function Loss: 0.00174

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00391
Policy Update Magnitude: 0.31065
Value Function Update Magnitude: 0.34487

Collected Steps per Second: 22,755.05285
Overall Steps per Second: 10,892.41330

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.39390
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.59200

Cumulative Model Updates: 316,586
Cumulative Timesteps: 2,640,186,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.47171
Policy Entropy: 4.45949
Value Function Loss: 0.00163

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00421
Policy Update Magnitude: 0.31018
Value Function Update Magnitude: 0.33736

Collected Steps per Second: 22,590.29136
Overall Steps per Second: 10,725.29646

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.44854
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.66188

Cumulative Model Updates: 316,592
Cumulative Timesteps: 2,640,236,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2640236450...
Checkpoint 2640236450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.58972
Policy Entropy: 4.45828
Value Function Loss: 0.00178

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00419
Policy Update Magnitude: 0.27873
Value Function Update Magnitude: 0.35894

Collected Steps per Second: 21,574.91907
Overall Steps per Second: 10,647.20841

Timestep Collection Time: 2.31899
Timestep Consumption Time: 2.38008
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.69907

Cumulative Model Updates: 316,598
Cumulative Timesteps: 2,640,286,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.33703
Policy Entropy: 4.46118
Value Function Loss: 0.00195

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.27492
Value Function Update Magnitude: 0.44931

Collected Steps per Second: 22,453.75182
Overall Steps per Second: 10,645.90197

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.47073
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.69833

Cumulative Model Updates: 316,604
Cumulative Timesteps: 2,640,336,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2640336500...
Checkpoint 2640336500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.83958
Policy Entropy: 4.46206
Value Function Loss: 0.00208

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00280
Policy Update Magnitude: 0.28169
Value Function Update Magnitude: 0.47337

Collected Steps per Second: 22,480.83962
Overall Steps per Second: 10,634.04081

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.70357

Cumulative Model Updates: 316,610
Cumulative Timesteps: 2,640,386,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.72219
Policy Entropy: 4.46377
Value Function Loss: 0.00198

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00373
Policy Update Magnitude: 0.25366
Value Function Update Magnitude: 0.48976

Collected Steps per Second: 22,994.52531
Overall Steps per Second: 10,925.86203

Timestep Collection Time: 2.17452
Timestep Consumption Time: 2.40196
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.57648

Cumulative Model Updates: 316,616
Cumulative Timesteps: 2,640,436,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2640436520...
Checkpoint 2640436520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.60370
Policy Entropy: 4.46445
Value Function Loss: 0.00181

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00352
Policy Update Magnitude: 0.22831
Value Function Update Magnitude: 0.47626

Collected Steps per Second: 22,844.48808
Overall Steps per Second: 10,854.58709

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.60911

Cumulative Model Updates: 316,622
Cumulative Timesteps: 2,640,486,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.25462
Policy Entropy: 4.46866
Value Function Loss: 0.00150

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00305
Policy Update Magnitude: 0.23706
Value Function Update Magnitude: 0.40074

Collected Steps per Second: 22,968.81589
Overall Steps per Second: 10,904.24194

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.40928
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.58684

Cumulative Model Updates: 316,628
Cumulative Timesteps: 2,640,536,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2640536566...
Checkpoint 2640536566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.60651
Policy Entropy: 4.46938
Value Function Loss: 0.00161

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00310
Policy Update Magnitude: 0.22152
Value Function Update Magnitude: 0.34395

Collected Steps per Second: 23,668.52478
Overall Steps per Second: 11,028.39326

Timestep Collection Time: 2.11268
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.53411

Cumulative Model Updates: 316,634
Cumulative Timesteps: 2,640,586,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.19326
Policy Entropy: 4.46786
Value Function Loss: 0.00148

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00273
Policy Update Magnitude: 0.20651
Value Function Update Magnitude: 0.36151

Collected Steps per Second: 22,745.07985
Overall Steps per Second: 10,664.90313

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.68996

Cumulative Model Updates: 316,640
Cumulative Timesteps: 2,640,636,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2640636588...
Checkpoint 2640636588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.21883
Policy Entropy: 4.46031
Value Function Loss: 0.00183

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00319
Policy Update Magnitude: 0.23439
Value Function Update Magnitude: 0.39714

Collected Steps per Second: 22,330.35101
Overall Steps per Second: 10,943.66613

Timestep Collection Time: 2.24054
Timestep Consumption Time: 2.33124
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.57178

Cumulative Model Updates: 316,646
Cumulative Timesteps: 2,640,686,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.23177
Policy Entropy: 4.45530
Value Function Loss: 0.00201

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00396
Policy Update Magnitude: 0.25335
Value Function Update Magnitude: 0.36167

Collected Steps per Second: 22,316.01776
Overall Steps per Second: 10,566.03834

Timestep Collection Time: 2.24171
Timestep Consumption Time: 2.49290
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.73460

Cumulative Model Updates: 316,652
Cumulative Timesteps: 2,640,736,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2640736646...
Checkpoint 2640736646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.44585
Policy Entropy: 4.45650
Value Function Loss: 0.00181

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00476
Policy Update Magnitude: 0.24497
Value Function Update Magnitude: 0.33138

Collected Steps per Second: 22,521.29637
Overall Steps per Second: 10,678.92959

Timestep Collection Time: 2.22074
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68343

Cumulative Model Updates: 316,658
Cumulative Timesteps: 2,640,786,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.81594
Policy Entropy: 4.46182
Value Function Loss: 0.00140

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00495
Policy Update Magnitude: 0.21619
Value Function Update Magnitude: 0.30684

Collected Steps per Second: 22,732.39413
Overall Steps per Second: 10,821.82505

Timestep Collection Time: 2.19977
Timestep Consumption Time: 2.42108
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.62085

Cumulative Model Updates: 316,664
Cumulative Timesteps: 2,640,836,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2640836666...
Checkpoint 2640836666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.74421
Policy Entropy: 4.46262
Value Function Loss: 0.00129

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.21704
Value Function Update Magnitude: 0.27827

Collected Steps per Second: 23,186.80596
Overall Steps per Second: 10,679.27246

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.52597
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68272

Cumulative Model Updates: 316,670
Cumulative Timesteps: 2,640,886,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.50871
Policy Entropy: 4.46002
Value Function Loss: 0.00141

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00399
Policy Update Magnitude: 0.24340
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 22,629.37401
Overall Steps per Second: 10,826.61580

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.62010

Cumulative Model Updates: 316,676
Cumulative Timesteps: 2,640,936,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2640936694...
Checkpoint 2640936694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.97709
Policy Entropy: 4.45687
Value Function Loss: 0.00152

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00428
Policy Update Magnitude: 0.23248
Value Function Update Magnitude: 0.39071

Collected Steps per Second: 22,895.52039
Overall Steps per Second: 10,641.53620

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70101

Cumulative Model Updates: 316,682
Cumulative Timesteps: 2,640,986,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.89636
Policy Entropy: 4.45710
Value Function Loss: 0.00164

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00377
Policy Update Magnitude: 0.24487
Value Function Update Magnitude: 0.38255

Collected Steps per Second: 22,722.66091
Overall Steps per Second: 10,883.60365

Timestep Collection Time: 2.20185
Timestep Consumption Time: 2.39515
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.59701

Cumulative Model Updates: 316,688
Cumulative Timesteps: 2,641,036,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2641036752...
Checkpoint 2641036752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.98428
Policy Entropy: 4.45988
Value Function Loss: 0.00161

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00394
Policy Update Magnitude: 0.25962
Value Function Update Magnitude: 0.40903

Collected Steps per Second: 23,643.27399
Overall Steps per Second: 11,062.64035

Timestep Collection Time: 2.11604
Timestep Consumption Time: 2.40639
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.52243

Cumulative Model Updates: 316,694
Cumulative Timesteps: 2,641,086,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.67133
Policy Entropy: 4.46344
Value Function Loss: 0.00164

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00346
Policy Update Magnitude: 0.24245
Value Function Update Magnitude: 0.38168

Collected Steps per Second: 22,341.65407
Overall Steps per Second: 10,532.02920

Timestep Collection Time: 2.23860
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.74875

Cumulative Model Updates: 316,700
Cumulative Timesteps: 2,641,136,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2641136796...
Checkpoint 2641136796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.46813
Policy Entropy: 4.45647
Value Function Loss: 0.00205

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00453
Policy Update Magnitude: 0.28014
Value Function Update Magnitude: 0.38955

Collected Steps per Second: 22,494.74171
Overall Steps per Second: 10,795.14219

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.40916
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.63208

Cumulative Model Updates: 316,706
Cumulative Timesteps: 2,641,186,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.02023
Policy Entropy: 4.45620
Value Function Loss: 0.00221

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00528
Policy Update Magnitude: 0.27356
Value Function Update Magnitude: 0.38043

Collected Steps per Second: 22,616.51169
Overall Steps per Second: 10,806.83920

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.27470
Total Iteration Time: 4.62744

Cumulative Model Updates: 316,712
Cumulative Timesteps: 2,641,236,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2641236808...
Checkpoint 2641236808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.38837
Policy Entropy: 4.45331
Value Function Loss: 0.00254

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.41203

Collected Steps per Second: 22,978.64711
Overall Steps per Second: 10,681.49967

Timestep Collection Time: 2.17628
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.68174

Cumulative Model Updates: 316,718
Cumulative Timesteps: 2,641,286,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.36828
Policy Entropy: 4.46001
Value Function Loss: 0.00196

Mean KL Divergence: 0.00032
SB3 Clip Fraction: 0.00263
Policy Update Magnitude: 0.32340
Value Function Update Magnitude: 0.42008

Collected Steps per Second: 23,026.16784
Overall Steps per Second: 10,855.46960

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.60782

Cumulative Model Updates: 316,724
Cumulative Timesteps: 2,641,336,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2641336836...
Checkpoint 2641336836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.21338
Policy Entropy: 4.46072
Value Function Loss: 0.00180

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00397
Policy Update Magnitude: 0.30359
Value Function Update Magnitude: 0.40037

Collected Steps per Second: 22,833.77366
Overall Steps per Second: 10,667.37279

Timestep Collection Time: 2.19053
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.68888

Cumulative Model Updates: 316,730
Cumulative Timesteps: 2,641,386,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.06364
Policy Entropy: 4.46248
Value Function Loss: 0.00152

Mean KL Divergence: 0.00072
SB3 Clip Fraction: 0.00600
Policy Update Magnitude: 0.42142
Value Function Update Magnitude: 0.37230

Collected Steps per Second: 22,790.79746
Overall Steps per Second: 10,873.63558

Timestep Collection Time: 2.19396
Timestep Consumption Time: 2.40451
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.59846

Cumulative Model Updates: 316,736
Cumulative Timesteps: 2,641,436,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2641436856...
Checkpoint 2641436856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.52752
Policy Entropy: 4.45855
Value Function Loss: 0.00217

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.00798
Policy Update Magnitude: 0.40818
Value Function Update Magnitude: 0.38240

Collected Steps per Second: 23,030.66439
Overall Steps per Second: 10,736.95059

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.66017

Cumulative Model Updates: 316,742
Cumulative Timesteps: 2,641,486,892

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.85112
Policy Entropy: 4.45557
Value Function Loss: 0.00208

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.00775
Policy Update Magnitude: 0.43079
Value Function Update Magnitude: 0.36660

Collected Steps per Second: 22,727.18495
Overall Steps per Second: 10,891.27207

Timestep Collection Time: 2.20089
Timestep Consumption Time: 2.39178
PPO Batch Consumption Time: 0.27429
Total Iteration Time: 4.59267

Cumulative Model Updates: 316,748
Cumulative Timesteps: 2,641,536,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2641536912...
Checkpoint 2641536912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.11236
Policy Entropy: 4.45595
Value Function Loss: 0.00226

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00794
Policy Update Magnitude: 0.35648
Value Function Update Magnitude: 0.34732

Collected Steps per Second: 22,409.61139
Overall Steps per Second: 10,948.33228

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.33572
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.56691

Cumulative Model Updates: 316,754
Cumulative Timesteps: 2,641,586,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.29137
Policy Entropy: 4.45974
Value Function Loss: 0.00189

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00574
Policy Update Magnitude: 0.29414
Value Function Update Magnitude: 0.36176

Collected Steps per Second: 22,043.12137
Overall Steps per Second: 10,555.41522

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.73994

Cumulative Model Updates: 316,760
Cumulative Timesteps: 2,641,636,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2641636944...
Checkpoint 2641636944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.25524
Policy Entropy: 4.46151
Value Function Loss: 0.00215

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00414
Policy Update Magnitude: 0.27235
Value Function Update Magnitude: 0.35201

Collected Steps per Second: 22,111.70446
Overall Steps per Second: 10,696.45602

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.41465
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67725

Cumulative Model Updates: 316,766
Cumulative Timesteps: 2,641,686,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.34474
Policy Entropy: 4.45892
Value Function Loss: 0.00219

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.27014
Value Function Update Magnitude: 0.38833

Collected Steps per Second: 22,731.64994
Overall Steps per Second: 10,770.40346

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.64309

Cumulative Model Updates: 316,772
Cumulative Timesteps: 2,641,736,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2641736982...
Checkpoint 2641736982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.75171
Policy Entropy: 4.45956
Value Function Loss: 0.00232

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00455
Policy Update Magnitude: 0.27197
Value Function Update Magnitude: 0.38008

Collected Steps per Second: 23,009.30154
Overall Steps per Second: 10,678.56281

Timestep Collection Time: 2.17330
Timestep Consumption Time: 2.50954
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.68284

Cumulative Model Updates: 316,778
Cumulative Timesteps: 2,641,786,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.84137
Policy Entropy: 4.45892
Value Function Loss: 0.00235

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00329
Policy Update Magnitude: 0.28686
Value Function Update Magnitude: 0.41512

Collected Steps per Second: 22,895.55359
Overall Steps per Second: 10,941.42559

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.38624
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.57034

Cumulative Model Updates: 316,784
Cumulative Timesteps: 2,641,836,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2641836994...
Checkpoint 2641836994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.02346
Policy Entropy: 4.46052
Value Function Loss: 0.00214

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00294
Policy Update Magnitude: 0.28195
Value Function Update Magnitude: 0.42051

Collected Steps per Second: 23,052.16192
Overall Steps per Second: 10,740.43264

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.65605

Cumulative Model Updates: 316,790
Cumulative Timesteps: 2,641,887,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.31417
Policy Entropy: 4.45907
Value Function Loss: 0.00228

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00434
Policy Update Magnitude: 0.32108
Value Function Update Magnitude: 0.40841

Collected Steps per Second: 22,913.76042
Overall Steps per Second: 10,868.95120

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.60265

Cumulative Model Updates: 316,796
Cumulative Timesteps: 2,641,937,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2641937028...
Checkpoint 2641937028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.84226
Policy Entropy: 4.46068
Value Function Loss: 0.00211

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00341
Policy Update Magnitude: 0.32076
Value Function Update Magnitude: 0.42567

Collected Steps per Second: 23,123.66026
Overall Steps per Second: 10,787.93961

Timestep Collection Time: 2.16263
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.63555

Cumulative Model Updates: 316,802
Cumulative Timesteps: 2,641,987,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.08421
Policy Entropy: 4.45945
Value Function Loss: 0.00199

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.34137
Value Function Update Magnitude: 0.50704

Collected Steps per Second: 22,388.33028
Overall Steps per Second: 10,831.51850

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.38361
PPO Batch Consumption Time: 0.27394
Total Iteration Time: 4.61764

Cumulative Model Updates: 316,808
Cumulative Timesteps: 2,642,037,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2642037052...
Checkpoint 2642037052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.93604
Policy Entropy: 4.45401
Value Function Loss: 0.00225

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00312
Policy Update Magnitude: 0.33759
Value Function Update Magnitude: 0.47563

Collected Steps per Second: 22,463.10962
Overall Steps per Second: 10,970.82787

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.33167
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.55754

Cumulative Model Updates: 316,814
Cumulative Timesteps: 2,642,087,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.42510
Policy Entropy: 4.45554
Value Function Loss: 0.00227

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00492
Policy Update Magnitude: 0.30653
Value Function Update Magnitude: 0.40521

Collected Steps per Second: 22,660.98526
Overall Steps per Second: 10,622.70953

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.70953

Cumulative Model Updates: 316,820
Cumulative Timesteps: 2,642,137,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2642137080...
Checkpoint 2642137080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.40355
Policy Entropy: 4.45642
Value Function Loss: 0.00211

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00440
Policy Update Magnitude: 0.28332
Value Function Update Magnitude: 0.37429

Collected Steps per Second: 23,022.46167
Overall Steps per Second: 11,009.76371

Timestep Collection Time: 2.17266
Timestep Consumption Time: 2.37058
PPO Batch Consumption Time: 0.27506
Total Iteration Time: 4.54324

Cumulative Model Updates: 316,826
Cumulative Timesteps: 2,642,187,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.03243
Policy Entropy: 4.46415
Value Function Loss: 0.00186

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00336
Policy Update Magnitude: 0.26821
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 22,957.50970
Overall Steps per Second: 10,856.47275

Timestep Collection Time: 2.17907
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.60794

Cumulative Model Updates: 316,832
Cumulative Timesteps: 2,642,237,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2642237126...
Checkpoint 2642237126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.44387
Policy Entropy: 4.46473
Value Function Loss: 0.00193

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00253
Policy Update Magnitude: 0.25100
Value Function Update Magnitude: 0.44327

Collected Steps per Second: 23,195.22505
Overall Steps per Second: 10,824.83784

Timestep Collection Time: 2.15570
Timestep Consumption Time: 2.46349
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.61919

Cumulative Model Updates: 316,838
Cumulative Timesteps: 2,642,287,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.49703
Policy Entropy: 4.46084
Value Function Loss: 0.00204

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00236
Policy Update Magnitude: 0.23409
Value Function Update Magnitude: 0.43986

Collected Steps per Second: 21,558.47177
Overall Steps per Second: 10,676.09390

Timestep Collection Time: 2.31946
Timestep Consumption Time: 2.36428
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.68374

Cumulative Model Updates: 316,844
Cumulative Timesteps: 2,642,337,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2642337132...
Checkpoint 2642337132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.82189
Policy Entropy: 4.45034
Value Function Loss: 0.00231

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00335
Policy Update Magnitude: 0.28865
Value Function Update Magnitude: 0.41909

Collected Steps per Second: 22,884.92241
Overall Steps per Second: 10,702.96011

Timestep Collection Time: 2.18537
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.67273

Cumulative Model Updates: 316,850
Cumulative Timesteps: 2,642,387,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.21985
Policy Entropy: 4.44633
Value Function Loss: 0.00227

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00417
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.42283

Collected Steps per Second: 22,818.60147
Overall Steps per Second: 10,927.87205

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.38474
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.57637

Cumulative Model Updates: 316,856
Cumulative Timesteps: 2,642,437,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2642437154...
Checkpoint 2642437154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.74175
Policy Entropy: 4.45011
Value Function Loss: 0.00238

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00469
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.41271

Collected Steps per Second: 22,477.90375
Overall Steps per Second: 10,615.59567

Timestep Collection Time: 2.22521
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.71175

Cumulative Model Updates: 316,862
Cumulative Timesteps: 2,642,487,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23505
Policy Entropy: 4.45901
Value Function Loss: 0.00191

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00299
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.38371

Collected Steps per Second: 22,492.44078
Overall Steps per Second: 10,696.58459

Timestep Collection Time: 2.22315
Timestep Consumption Time: 2.45162
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.67476

Cumulative Model Updates: 316,868
Cumulative Timesteps: 2,642,537,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2642537176...
Checkpoint 2642537176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.16232
Policy Entropy: 4.45622
Value Function Loss: 0.00206

Mean KL Divergence: 0.00064
SB3 Clip Fraction: 0.00485
Policy Update Magnitude: 0.28903
Value Function Update Magnitude: 0.34441

Collected Steps per Second: 22,596.01829
Overall Steps per Second: 10,894.58193

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.37808
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.59219

Cumulative Model Updates: 316,874
Cumulative Timesteps: 2,642,587,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.69136
Policy Entropy: 4.45944
Value Function Loss: 0.00195

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.28119
Value Function Update Magnitude: 0.31581

Collected Steps per Second: 22,888.85588
Overall Steps per Second: 10,801.27628

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.44540
PPO Batch Consumption Time: 0.27543
Total Iteration Time: 4.63056

Cumulative Model Updates: 316,880
Cumulative Timesteps: 2,642,637,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2642637222...
Checkpoint 2642637222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.69569
Policy Entropy: 4.46027
Value Function Loss: 0.00234

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.27667
Value Function Update Magnitude: 0.32445

Collected Steps per Second: 22,579.46758
Overall Steps per Second: 10,790.04313

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.63464

Cumulative Model Updates: 316,886
Cumulative Timesteps: 2,642,687,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.98707
Policy Entropy: 4.46715
Value Function Loss: 0.00218

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00314
Policy Update Magnitude: 0.26789
Value Function Update Magnitude: 0.33112

Collected Steps per Second: 23,042.24201
Overall Steps per Second: 10,899.77769

Timestep Collection Time: 2.17097
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27491
Total Iteration Time: 4.58945

Cumulative Model Updates: 316,892
Cumulative Timesteps: 2,642,737,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2642737254...
Checkpoint 2642737254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.11508
Policy Entropy: 4.46537
Value Function Loss: 0.00235

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00292
Policy Update Magnitude: 0.27327
Value Function Update Magnitude: 0.36663

Collected Steps per Second: 22,958.39578
Overall Steps per Second: 10,936.83558

Timestep Collection Time: 2.17838
Timestep Consumption Time: 2.39443
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.57280

Cumulative Model Updates: 316,898
Cumulative Timesteps: 2,642,787,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.64597
Policy Entropy: 4.46534
Value Function Loss: 0.00191

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00227
Policy Update Magnitude: 0.28212
Value Function Update Magnitude: 0.37687

Collected Steps per Second: 22,539.89331
Overall Steps per Second: 10,941.09590

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.35248
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.57157

Cumulative Model Updates: 316,904
Cumulative Timesteps: 2,642,837,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2642837284...
Checkpoint 2642837284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.59374
Policy Entropy: 4.45817
Value Function Loss: 0.00189

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00306
Policy Update Magnitude: 0.29801
Value Function Update Magnitude: 0.34451

Collected Steps per Second: 22,811.30632
Overall Steps per Second: 10,741.12380

Timestep Collection Time: 2.19304
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.65743

Cumulative Model Updates: 316,910
Cumulative Timesteps: 2,642,887,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.04904
Policy Entropy: 4.45371
Value Function Loss: 0.00214

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00333
Policy Update Magnitude: 0.30940
Value Function Update Magnitude: 0.32764

Collected Steps per Second: 22,379.38198
Overall Steps per Second: 10,678.97395

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.68397

Cumulative Model Updates: 316,916
Cumulative Timesteps: 2,642,937,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2642937330...
Checkpoint 2642937330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.33091
Policy Entropy: 4.45372
Value Function Loss: 0.00218

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00699
Policy Update Magnitude: 0.32678
Value Function Update Magnitude: 0.38804

Collected Steps per Second: 22,362.23348
Overall Steps per Second: 10,626.52942

Timestep Collection Time: 2.23636
Timestep Consumption Time: 2.46979
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.70615

Cumulative Model Updates: 316,922
Cumulative Timesteps: 2,642,987,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.10593
Policy Entropy: 4.45408
Value Function Loss: 0.00265

Mean KL Divergence: 0.00082
SB3 Clip Fraction: 0.00585
Policy Update Magnitude: 0.31268
Value Function Update Magnitude: 0.38764

Collected Steps per Second: 22,170.09998
Overall Steps per Second: 10,668.41980

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.43241
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.68860

Cumulative Model Updates: 316,928
Cumulative Timesteps: 2,643,037,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2643037360...
Checkpoint 2643037360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.34367
Policy Entropy: 4.45839
Value Function Loss: 0.00245

Mean KL Divergence: 0.00053
SB3 Clip Fraction: 0.00526
Policy Update Magnitude: 0.30293
Value Function Update Magnitude: 0.36044

Collected Steps per Second: 22,499.36858
Overall Steps per Second: 10,789.33405

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.63606

Cumulative Model Updates: 316,934
Cumulative Timesteps: 2,643,087,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.88320
Policy Entropy: 4.45353
Value Function Loss: 0.00259

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00482
Policy Update Magnitude: 0.32151
Value Function Update Magnitude: 0.38595

Collected Steps per Second: 23,018.68771
Overall Steps per Second: 10,780.06513

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.64153

Cumulative Model Updates: 316,940
Cumulative Timesteps: 2,643,137,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2643137416...
Checkpoint 2643137416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.43207
Policy Entropy: 4.45260
Value Function Loss: 0.00235

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.31602
Value Function Update Magnitude: 0.41778

Collected Steps per Second: 22,919.11745
Overall Steps per Second: 10,789.46018

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.63656

Cumulative Model Updates: 316,946
Cumulative Timesteps: 2,643,187,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.95772
Policy Entropy: 4.45281
Value Function Loss: 0.00209

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.31801
Value Function Update Magnitude: 0.41409

Collected Steps per Second: 23,816.19094
Overall Steps per Second: 10,916.45617

Timestep Collection Time: 2.09950
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.58042

Cumulative Model Updates: 316,952
Cumulative Timesteps: 2,643,237,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2643237444...
Checkpoint 2643237444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.48080
Policy Entropy: 4.45697
Value Function Loss: 0.00230

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00295
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 23,068.22738
Overall Steps per Second: 10,895.90330

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.58998

Cumulative Model Updates: 316,958
Cumulative Timesteps: 2,643,287,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.95067
Policy Entropy: 4.45724
Value Function Loss: 0.00199

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00320
Policy Update Magnitude: 0.30071
Value Function Update Magnitude: 0.33365

Collected Steps per Second: 22,723.93541
Overall Steps per Second: 10,959.00715

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.36213
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.56246

Cumulative Model Updates: 316,964
Cumulative Timesteps: 2,643,337,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2643337456...
Checkpoint 2643337456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.64514
Policy Entropy: 4.45480
Value Function Loss: 0.00288

Mean KL Divergence: 0.00056
SB3 Clip Fraction: 0.00444
Policy Update Magnitude: 0.32858
Value Function Update Magnitude: 0.36893

Collected Steps per Second: 22,545.11232
Overall Steps per Second: 10,637.47856

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.70036

Cumulative Model Updates: 316,970
Cumulative Timesteps: 2,643,387,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.88311
Policy Entropy: 4.45079
Value Function Loss: 0.00290

Mean KL Divergence: 0.00075
SB3 Clip Fraction: 0.00533
Policy Update Magnitude: 0.33904
Value Function Update Magnitude: 0.42226

Collected Steps per Second: 22,488.35319
Overall Steps per Second: 10,704.20604

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.67256

Cumulative Model Updates: 316,976
Cumulative Timesteps: 2,643,437,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2643437472...
Checkpoint 2643437472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.59145
Policy Entropy: 4.45300
Value Function Loss: 0.00310

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00477
Policy Update Magnitude: 0.37515
Value Function Update Magnitude: 0.43073

Collected Steps per Second: 23,039.53405
Overall Steps per Second: 10,873.82228

Timestep Collection Time: 2.17044
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59875

Cumulative Model Updates: 316,982
Cumulative Timesteps: 2,643,487,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.60197
Policy Entropy: 4.45578
Value Function Loss: 0.00231

Mean KL Divergence: 0.00074
SB3 Clip Fraction: 0.00415
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.38070

Collected Steps per Second: 22,691.96870
Overall Steps per Second: 10,788.76597

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.63723

Cumulative Model Updates: 316,988
Cumulative Timesteps: 2,643,537,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2643537508...
Checkpoint 2643537508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.13116
Policy Entropy: 4.45890
Value Function Loss: 0.00209

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00444
Policy Update Magnitude: 0.28575
Value Function Update Magnitude: 0.40391

Collected Steps per Second: 22,617.97267
Overall Steps per Second: 10,734.71101

Timestep Collection Time: 2.21107
Timestep Consumption Time: 2.44765
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.65872

Cumulative Model Updates: 316,994
Cumulative Timesteps: 2,643,587,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.84365
Policy Entropy: 4.45796
Value Function Loss: 0.00163

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00374
Policy Update Magnitude: 0.24709
Value Function Update Magnitude: 0.37697

Collected Steps per Second: 23,040.83053
Overall Steps per Second: 10,885.81959

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.59589

Cumulative Model Updates: 317,000
Cumulative Timesteps: 2,643,637,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2643637548...
Checkpoint 2643637548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.75331
Policy Entropy: 4.46014
Value Function Loss: 0.00178

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00308
Policy Update Magnitude: 0.22596
Value Function Update Magnitude: 0.35995

Collected Steps per Second: 22,762.28471
Overall Steps per Second: 10,662.36727

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.69127

Cumulative Model Updates: 317,006
Cumulative Timesteps: 2,643,687,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.24756
Policy Entropy: 4.45775
Value Function Loss: 0.00221

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00341
Policy Update Magnitude: 0.24539
Value Function Update Magnitude: 0.41235

Collected Steps per Second: 23,837.99430
Overall Steps per Second: 10,913.32030

Timestep Collection Time: 2.09791
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.58247

Cumulative Model Updates: 317,012
Cumulative Timesteps: 2,643,737,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2643737578...
Checkpoint 2643737578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.59613
Policy Entropy: 4.45779
Value Function Loss: 0.00215

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00386
Policy Update Magnitude: 0.26820
Value Function Update Magnitude: 0.43318

Collected Steps per Second: 23,286.04753
Overall Steps per Second: 10,806.51115

Timestep Collection Time: 2.14747
Timestep Consumption Time: 2.47993
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.62740

Cumulative Model Updates: 317,018
Cumulative Timesteps: 2,643,787,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.00282
Policy Entropy: 4.45924
Value Function Loss: 0.00183

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00317
Policy Update Magnitude: 0.26088
Value Function Update Magnitude: 0.35259

Collected Steps per Second: 22,553.90933
Overall Steps per Second: 10,803.51015

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.62868

Cumulative Model Updates: 317,024
Cumulative Timesteps: 2,643,837,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2643837590...
Checkpoint 2643837590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.78791
Policy Entropy: 4.46285
Value Function Loss: 0.00139

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00227
Policy Update Magnitude: 0.23071
Value Function Update Magnitude: 0.30515

Collected Steps per Second: 22,613.21859
Overall Steps per Second: 10,651.13497

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69509

Cumulative Model Updates: 317,030
Cumulative Timesteps: 2,643,887,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.79722
Policy Entropy: 4.46379
Value Function Loss: 0.00125

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00205
Policy Update Magnitude: 0.22625
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 22,607.80512
Overall Steps per Second: 10,832.29990

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.40468
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.61675

Cumulative Model Updates: 317,036
Cumulative Timesteps: 2,643,937,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2643937608...
Checkpoint 2643937608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.11361
Policy Entropy: 4.45956
Value Function Loss: 0.00158

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00287
Policy Update Magnitude: 0.21829
Value Function Update Magnitude: 0.29812

Collected Steps per Second: 22,612.45110
Overall Steps per Second: 10,695.44470

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.46441
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.67620

Cumulative Model Updates: 317,042
Cumulative Timesteps: 2,643,987,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.57697
Policy Entropy: 4.45824
Value Function Loss: 0.00162

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.23557
Value Function Update Magnitude: 0.33157

Collected Steps per Second: 22,953.61931
Overall Steps per Second: 10,820.55493

Timestep Collection Time: 2.17909
Timestep Consumption Time: 2.44341
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.62250

Cumulative Model Updates: 317,048
Cumulative Timesteps: 2,644,037,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2644037640...
Checkpoint 2644037640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.03927
Policy Entropy: 4.45628
Value Function Loss: 0.00209

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00339
Policy Update Magnitude: 0.24903
Value Function Update Magnitude: 0.39861

Collected Steps per Second: 22,827.94838
Overall Steps per Second: 11,049.70105

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.33490
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.52537

Cumulative Model Updates: 317,054
Cumulative Timesteps: 2,644,087,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.75708
Policy Entropy: 4.45798
Value Function Loss: 0.00206

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00340
Policy Update Magnitude: 0.26096
Value Function Update Magnitude: 0.37766

Collected Steps per Second: 22,588.07874
Overall Steps per Second: 10,648.65457

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69806

Cumulative Model Updates: 317,060
Cumulative Timesteps: 2,644,137,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2644137672...
Checkpoint 2644137672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.40806
Policy Entropy: 4.46135
Value Function Loss: 0.00256

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00301
Policy Update Magnitude: 0.28689
Value Function Update Magnitude: 0.37637

Collected Steps per Second: 23,063.86405
Overall Steps per Second: 10,956.83404

Timestep Collection Time: 2.16867
Timestep Consumption Time: 2.39633
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.56500

Cumulative Model Updates: 317,066
Cumulative Timesteps: 2,644,187,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.82733
Policy Entropy: 4.46152
Value Function Loss: 0.00218

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00281
Policy Update Magnitude: 0.28232
Value Function Update Magnitude: 0.41203

Collected Steps per Second: 22,537.20911
Overall Steps per Second: 10,931.21208

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.35569
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.57442

Cumulative Model Updates: 317,072
Cumulative Timesteps: 2,644,237,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2644237694...
Checkpoint 2644237694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.21776
Policy Entropy: 4.45604
Value Function Loss: 0.00210

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00402
Policy Update Magnitude: 0.26739
Value Function Update Magnitude: 0.40683

Collected Steps per Second: 21,756.07757
Overall Steps per Second: 10,602.75887

Timestep Collection Time: 2.29986
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27540
Total Iteration Time: 4.71915

Cumulative Model Updates: 317,078
Cumulative Timesteps: 2,644,287,730

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.34412
Policy Entropy: 4.45553
Value Function Loss: 0.00164

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00391
Policy Update Magnitude: 0.25066
Value Function Update Magnitude: 0.37237

Collected Steps per Second: 21,952.55573
Overall Steps per Second: 10,679.97203

Timestep Collection Time: 2.27873
Timestep Consumption Time: 2.40518
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.68391

Cumulative Model Updates: 317,084
Cumulative Timesteps: 2,644,337,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2644337754...
Checkpoint 2644337754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.58375
Policy Entropy: 4.45838
Value Function Loss: 0.00191

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00529
Policy Update Magnitude: 0.23903
Value Function Update Magnitude: 0.37707

Collected Steps per Second: 22,751.85853
Overall Steps per Second: 10,717.79113

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.66645

Cumulative Model Updates: 317,090
Cumulative Timesteps: 2,644,387,768

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.87541
Policy Entropy: 4.46228
Value Function Loss: 0.00178

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00433
Policy Update Magnitude: 0.27874
Value Function Update Magnitude: 0.42084

Collected Steps per Second: 17,837.45250
Overall Steps per Second: 9,096.40273

Timestep Collection Time: 2.80567
Timestep Consumption Time: 2.69607
PPO Batch Consumption Time: 0.30800
Total Iteration Time: 5.50174

Cumulative Model Updates: 317,096
Cumulative Timesteps: 2,644,437,814

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2644437814...
Checkpoint 2644437814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.81126
Policy Entropy: 4.45619
Value Function Loss: 0.00239

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.32159
Value Function Update Magnitude: 0.45915

Collected Steps per Second: 19,451.33045
Overall Steps per Second: 9,759.20555

Timestep Collection Time: 2.57124
Timestep Consumption Time: 2.55356
PPO Batch Consumption Time: 0.30274
Total Iteration Time: 5.12480

Cumulative Model Updates: 317,102
Cumulative Timesteps: 2,644,487,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.26933
Policy Entropy: 4.45500
Value Function Loss: 0.00228

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00561
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.41132

Collected Steps per Second: 20,053.48210
Overall Steps per Second: 9,772.52924

Timestep Collection Time: 2.49523
Timestep Consumption Time: 2.62504
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 5.12027

Cumulative Model Updates: 317,108
Cumulative Timesteps: 2,644,537,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2644537866...
Checkpoint 2644537866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.42185
Policy Entropy: 4.45599
Value Function Loss: 0.00232

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00630
Policy Update Magnitude: 0.29926
Value Function Update Magnitude: 0.36548

Collected Steps per Second: 21,262.29673
Overall Steps per Second: 10,227.83550

Timestep Collection Time: 2.35309
Timestep Consumption Time: 2.53866
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.89175

Cumulative Model Updates: 317,114
Cumulative Timesteps: 2,644,587,898

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.50780
Policy Entropy: 4.46008
Value Function Loss: 0.00180

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00376
Policy Update Magnitude: 0.28620
Value Function Update Magnitude: 0.34081

Collected Steps per Second: 22,549.40196
Overall Steps per Second: 10,529.18848

Timestep Collection Time: 2.21744
Timestep Consumption Time: 2.53145
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.74889

Cumulative Model Updates: 317,120
Cumulative Timesteps: 2,644,637,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2644637900...
Checkpoint 2644637900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.30899
Policy Entropy: 4.46572
Value Function Loss: 0.00174

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.27070
Value Function Update Magnitude: 0.35010

Collected Steps per Second: 21,628.79027
Overall Steps per Second: 10,463.09575

Timestep Collection Time: 2.31247
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.78023

Cumulative Model Updates: 317,126
Cumulative Timesteps: 2,644,687,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.75345
Policy Entropy: 4.46116
Value Function Loss: 0.00183

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00372
Policy Update Magnitude: 0.26813
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 21,946.19180
Overall Steps per Second: 10,458.17757

Timestep Collection Time: 2.27830
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.78095

Cumulative Model Updates: 317,132
Cumulative Timesteps: 2,644,737,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2644737916...
Checkpoint 2644737916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.84117
Policy Entropy: 4.46281
Value Function Loss: 0.00178

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00308
Policy Update Magnitude: 0.29171
Value Function Update Magnitude: 0.43397

Collected Steps per Second: 21,951.50967
Overall Steps per Second: 10,577.98695

Timestep Collection Time: 2.27802
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.72736

Cumulative Model Updates: 317,138
Cumulative Timesteps: 2,644,787,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.65653
Policy Entropy: 4.45872
Value Function Loss: 0.00160

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.26781
Value Function Update Magnitude: 0.38528

Collected Steps per Second: 19,311.10173
Overall Steps per Second: 9,456.81471

Timestep Collection Time: 2.59022
Timestep Consumption Time: 2.69909
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 5.28931

Cumulative Model Updates: 317,144
Cumulative Timesteps: 2,644,837,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2644837942...
Checkpoint 2644837942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.65507
Policy Entropy: 4.46267
Value Function Loss: 0.00181

Mean KL Divergence: 0.00025
SB3 Clip Fraction: 0.00262
Policy Update Magnitude: 0.24299
Value Function Update Magnitude: 0.33979

Collected Steps per Second: 19,918.08578
Overall Steps per Second: 9,989.21616

Timestep Collection Time: 2.51129
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 5.00740

Cumulative Model Updates: 317,150
Cumulative Timesteps: 2,644,887,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.08843
Policy Entropy: 4.45597
Value Function Loss: 0.00214

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00365
Policy Update Magnitude: 0.25314
Value Function Update Magnitude: 0.31515

Collected Steps per Second: 21,543.91977
Overall Steps per Second: 10,332.68631

Timestep Collection Time: 2.32242
Timestep Consumption Time: 2.51988
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.84230

Cumulative Model Updates: 317,156
Cumulative Timesteps: 2,644,937,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2644937996...
Checkpoint 2644937996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.01283
Policy Entropy: 4.45805
Value Function Loss: 0.00232

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00311
Policy Update Magnitude: 0.25203
Value Function Update Magnitude: 0.37688

Collected Steps per Second: 21,634.55195
Overall Steps per Second: 10,520.68714

Timestep Collection Time: 2.31177
Timestep Consumption Time: 2.44211
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.75387

Cumulative Model Updates: 317,162
Cumulative Timesteps: 2,644,988,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.37100
Policy Entropy: 4.45912
Value Function Loss: 0.00201

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00360
Policy Update Magnitude: 0.23261
Value Function Update Magnitude: 0.34080

Collected Steps per Second: 21,652.71136
Overall Steps per Second: 10,260.67624

Timestep Collection Time: 2.30983
Timestep Consumption Time: 2.56451
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.87434

Cumulative Model Updates: 317,168
Cumulative Timesteps: 2,645,038,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2645038024...
Checkpoint 2645038024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.75956
Policy Entropy: 4.46142
Value Function Loss: 0.00180

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00292
Policy Update Magnitude: 0.23063
Value Function Update Magnitude: 0.34000

Collected Steps per Second: 21,927.75877
Overall Steps per Second: 10,697.55002

Timestep Collection Time: 2.28131
Timestep Consumption Time: 2.39490
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.67621

Cumulative Model Updates: 317,174
Cumulative Timesteps: 2,645,088,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.70487
Policy Entropy: 4.45879
Value Function Loss: 0.00185

Mean KL Divergence: 0.00037
SB3 Clip Fraction: 0.00368
Policy Update Magnitude: 0.24925
Value Function Update Magnitude: 0.34647

Collected Steps per Second: 19,411.42450
Overall Steps per Second: 9,771.30040

Timestep Collection Time: 2.57735
Timestep Consumption Time: 2.54275
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 5.12010

Cumulative Model Updates: 317,180
Cumulative Timesteps: 2,645,138,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2645138078...
Checkpoint 2645138078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.99021
Policy Entropy: 4.45877
Value Function Loss: 0.00198

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00436
Policy Update Magnitude: 0.29854
Value Function Update Magnitude: 0.33737

Collected Steps per Second: 20,944.34632
Overall Steps per Second: 10,156.45386

Timestep Collection Time: 2.38823
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.92495

Cumulative Model Updates: 317,186
Cumulative Timesteps: 2,645,188,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.57860
Policy Entropy: 4.46054
Value Function Loss: 0.00201

Mean KL Divergence: 0.00063
SB3 Clip Fraction: 0.00490
Policy Update Magnitude: 0.28063
Value Function Update Magnitude: 0.37222

Collected Steps per Second: 21,250.04397
Overall Steps per Second: 10,526.24203

Timestep Collection Time: 2.35397
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.75212

Cumulative Model Updates: 317,192
Cumulative Timesteps: 2,645,238,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2645238120...
Checkpoint 2645238120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.42506
Policy Entropy: 4.46530
Value Function Loss: 0.00185

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00286
Policy Update Magnitude: 0.26247
Value Function Update Magnitude: 0.38489

Collected Steps per Second: 21,973.06430
Overall Steps per Second: 10,548.24554

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.46510
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.74107

Cumulative Model Updates: 317,198
Cumulative Timesteps: 2,645,288,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.91868
Policy Entropy: 4.45652
Value Function Loss: 0.00285

Mean KL Divergence: 0.00044
SB3 Clip Fraction: 0.00434
Policy Update Magnitude: 0.28093
Value Function Update Magnitude: 0.42201

Collected Steps per Second: 19,070.43267
Overall Steps per Second: 9,724.53299

Timestep Collection Time: 2.62333
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 5.14451

Cumulative Model Updates: 317,204
Cumulative Timesteps: 2,645,338,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2645338158...
Checkpoint 2645338158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.69077
Policy Entropy: 4.45422
Value Function Loss: 0.00302

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00489
Policy Update Magnitude: 0.33187
Value Function Update Magnitude: 0.42728

Collected Steps per Second: 18,106.14541
Overall Steps per Second: 8,908.42620

Timestep Collection Time: 2.76216
Timestep Consumption Time: 2.85185
PPO Batch Consumption Time: 0.32610
Total Iteration Time: 5.61401

Cumulative Model Updates: 317,210
Cumulative Timesteps: 2,645,388,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.15795
Policy Entropy: 4.45112
Value Function Loss: 0.00302

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00448
Policy Update Magnitude: 0.32379
Value Function Update Magnitude: 0.43663

Collected Steps per Second: 20,175.11434
Overall Steps per Second: 9,937.55005

Timestep Collection Time: 2.47830
Timestep Consumption Time: 2.55312
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 5.03142

Cumulative Model Updates: 317,216
Cumulative Timesteps: 2,645,438,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2645438170...
Checkpoint 2645438170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.48804
Policy Entropy: 4.45122
Value Function Loss: 0.00224

Mean KL Divergence: 0.00052
SB3 Clip Fraction: 0.00528
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.38346

Collected Steps per Second: 21,378.42696
Overall Steps per Second: 10,419.29249

Timestep Collection Time: 2.34021
Timestep Consumption Time: 2.46146
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.80167

Cumulative Model Updates: 317,222
Cumulative Timesteps: 2,645,488,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.93052
Policy Entropy: 4.45428
Value Function Loss: 0.00214

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00457
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.35698

Collected Steps per Second: 19,648.27236
Overall Steps per Second: 9,677.49057

Timestep Collection Time: 2.54577
Timestep Consumption Time: 2.62292
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 5.16870

Cumulative Model Updates: 317,228
Cumulative Timesteps: 2,645,538,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2645538220...
Checkpoint 2645538220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.32340
Policy Entropy: 4.45815
Value Function Loss: 0.00163

Mean KL Divergence: 0.00085
SB3 Clip Fraction: 0.00581
Policy Update Magnitude: 0.27998
Value Function Update Magnitude: 0.38018

Collected Steps per Second: 19,879.82670
Overall Steps per Second: 9,947.08795

Timestep Collection Time: 2.51582
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 5.02800

Cumulative Model Updates: 317,234
Cumulative Timesteps: 2,645,588,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.92642
Policy Entropy: 4.46058
Value Function Loss: 0.00149

Mean KL Divergence: 0.00065
SB3 Clip Fraction: 0.00389
Policy Update Magnitude: 0.24872
Value Function Update Magnitude: 0.36320

Collected Steps per Second: 22,797.94107
Overall Steps per Second: 10,776.31483

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.64110

Cumulative Model Updates: 317,240
Cumulative Timesteps: 2,645,638,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2645638248...
Checkpoint 2645638248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.44669
Policy Entropy: 4.46285
Value Function Loss: 0.00142

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00452
Policy Update Magnitude: 0.23330
Value Function Update Magnitude: 0.35249

Collected Steps per Second: 21,207.32854
Overall Steps per Second: 10,326.28790

Timestep Collection Time: 2.35834
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.84337

Cumulative Model Updates: 317,246
Cumulative Timesteps: 2,645,688,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.36948
Policy Entropy: 4.45984
Value Function Loss: 0.00186

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.23645
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 22,467.99003
Overall Steps per Second: 10,629.26015

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70757

Cumulative Model Updates: 317,252
Cumulative Timesteps: 2,645,738,300

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2645738300...
Checkpoint 2645738300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.88355
Policy Entropy: 4.46333
Value Function Loss: 0.00186

Mean KL Divergence: 0.00043
SB3 Clip Fraction: 0.00334
Policy Update Magnitude: 0.25592
Value Function Update Magnitude: 0.29784

Collected Steps per Second: 22,275.16826
Overall Steps per Second: 10,671.07508

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.44130
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68631

Cumulative Model Updates: 317,258
Cumulative Timesteps: 2,645,788,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.33008
Policy Entropy: 4.46477
Value Function Loss: 0.00173

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.24051
Value Function Update Magnitude: 0.30143

Collected Steps per Second: 18,519.13560
Overall Steps per Second: 9,801.20780

Timestep Collection Time: 2.70088
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 5.10325

Cumulative Model Updates: 317,264
Cumulative Timesteps: 2,645,838,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2645838326...
Checkpoint 2645838326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.95911
Policy Entropy: 4.46802
Value Function Loss: 0.00140

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00228
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.29929

Collected Steps per Second: 22,196.17110
Overall Steps per Second: 10,675.03308

Timestep Collection Time: 2.25309
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.68476

Cumulative Model Updates: 317,270
Cumulative Timesteps: 2,645,888,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.60953
Policy Entropy: 4.46546
Value Function Loss: 0.00158

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.23823
Value Function Update Magnitude: 0.39024

Collected Steps per Second: 18,847.19640
Overall Steps per Second: 9,521.38356

Timestep Collection Time: 2.65440
Timestep Consumption Time: 2.59988
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 5.25428

Cumulative Model Updates: 317,276
Cumulative Timesteps: 2,645,938,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2645938364...
Checkpoint 2645938364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.28864
Policy Entropy: 4.46445
Value Function Loss: 0.00170

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00238
Policy Update Magnitude: 0.23882
Value Function Update Magnitude: 0.36384

Collected Steps per Second: 20,004.47406
Overall Steps per Second: 10,066.78247

Timestep Collection Time: 2.49974
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.96743

Cumulative Model Updates: 317,282
Cumulative Timesteps: 2,645,988,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.37838
Policy Entropy: 4.46102
Value Function Loss: 0.00186

Mean KL Divergence: 0.00047
SB3 Clip Fraction: 0.00328
Policy Update Magnitude: 0.23976
Value Function Update Magnitude: 0.36497

Collected Steps per Second: 20,804.85124
Overall Steps per Second: 10,162.64167

Timestep Collection Time: 2.40473
Timestep Consumption Time: 2.51821
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.92293

Cumulative Model Updates: 317,288
Cumulative Timesteps: 2,646,038,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2646038400...
Checkpoint 2646038400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.92628
Policy Entropy: 4.45544
Value Function Loss: 0.00179

Mean KL Divergence: 0.00050
SB3 Clip Fraction: 0.00354
Policy Update Magnitude: 0.25806
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 20,221.45942
Overall Steps per Second: 9,952.12103

Timestep Collection Time: 2.47381
Timestep Consumption Time: 2.55266
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 5.02647

Cumulative Model Updates: 317,294
Cumulative Timesteps: 2,646,088,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.81409
Policy Entropy: 4.45569
Value Function Loss: 0.00168

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00383
Policy Update Magnitude: 0.25573
Value Function Update Magnitude: 0.35343

Collected Steps per Second: 23,068.62225
Overall Steps per Second: 10,706.48200

Timestep Collection Time: 2.16753
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.67025

Cumulative Model Updates: 317,300
Cumulative Timesteps: 2,646,138,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2646138426...
Checkpoint 2646138426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.32927
Policy Entropy: 4.45703
Value Function Loss: 0.00137

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00350
Policy Update Magnitude: 0.22846
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 22,361.51716
Overall Steps per Second: 10,465.67547

Timestep Collection Time: 2.23634
Timestep Consumption Time: 2.54194
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.77829

Cumulative Model Updates: 317,306
Cumulative Timesteps: 2,646,188,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.68796
Policy Entropy: 4.46003
Value Function Loss: 0.00167

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00358
Policy Update Magnitude: 0.21052
Value Function Update Magnitude: 0.35474

Collected Steps per Second: 21,887.29008
Overall Steps per Second: 10,509.33822

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.76034

Cumulative Model Updates: 317,312
Cumulative Timesteps: 2,646,238,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2646238462...
Checkpoint 2646238462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.52733
Policy Entropy: 4.45813
Value Function Loss: 0.00180

Mean KL Divergence: 0.00038
SB3 Clip Fraction: 0.00353
Policy Update Magnitude: 0.22030
Value Function Update Magnitude: 0.32915

Collected Steps per Second: 22,280.40344
Overall Steps per Second: 10,608.69628

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.71330

Cumulative Model Updates: 317,318
Cumulative Timesteps: 2,646,288,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.30824
Policy Entropy: 4.45734
Value Function Loss: 0.00176

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00432
Policy Update Magnitude: 0.23899
Value Function Update Magnitude: 0.31283

Collected Steps per Second: 22,698.86748
Overall Steps per Second: 10,738.34228

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.45473
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65863

Cumulative Model Updates: 317,324
Cumulative Timesteps: 2,646,338,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2646338490...
Checkpoint 2646338490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.81460
Policy Entropy: 4.46142
Value Function Loss: 0.00178

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00354
Policy Update Magnitude: 0.24109
Value Function Update Magnitude: 0.34348

Collected Steps per Second: 20,968.84234
Overall Steps per Second: 10,228.94357

Timestep Collection Time: 2.38563
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.89044

Cumulative Model Updates: 317,330
Cumulative Timesteps: 2,646,388,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.52673
Policy Entropy: 4.45986
Value Function Loss: 0.00202

Mean KL Divergence: 0.00045
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.25341
Value Function Update Magnitude: 0.41231

Collected Steps per Second: 21,405.24894
Overall Steps per Second: 10,250.18965

Timestep Collection Time: 2.33625
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.87874

Cumulative Model Updates: 317,336
Cumulative Timesteps: 2,646,438,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2646438522...
Checkpoint 2646438522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.10605
Policy Entropy: 4.45913
Value Function Loss: 0.00254

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00283
Policy Update Magnitude: 0.28641
Value Function Update Magnitude: 0.46374

Collected Steps per Second: 20,578.07594
Overall Steps per Second: 10,135.41036

Timestep Collection Time: 2.42987
Timestep Consumption Time: 2.50353
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.93340

Cumulative Model Updates: 317,342
Cumulative Timesteps: 2,646,488,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.41698
Policy Entropy: 4.45473
Value Function Loss: 0.00236

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00467
Policy Update Magnitude: 0.29011
Value Function Update Magnitude: 0.50253

Collected Steps per Second: 23,220.16636
Overall Steps per Second: 10,830.33202

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61851

Cumulative Model Updates: 317,348
Cumulative Timesteps: 2,646,538,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2646538544...
Checkpoint 2646538544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.45119
Policy Entropy: 4.45811
Value Function Loss: 0.00198

Mean KL Divergence: 0.00040
SB3 Clip Fraction: 0.00332
Policy Update Magnitude: 0.29020
Value Function Update Magnitude: 0.54380

Collected Steps per Second: 22,054.19488
Overall Steps per Second: 10,323.10949

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.57698
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.84466

Cumulative Model Updates: 317,354
Cumulative Timesteps: 2,646,588,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.63316
Policy Entropy: 4.46218
Value Function Loss: 0.00169

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00409
Policy Update Magnitude: 0.25708
Value Function Update Magnitude: 0.52833

Collected Steps per Second: 21,373.91882
Overall Steps per Second: 10,327.67037

Timestep Collection Time: 2.33967
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.84214

Cumulative Model Updates: 317,360
Cumulative Timesteps: 2,646,638,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2646638564...
Checkpoint 2646638564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.94382
Policy Entropy: 4.46551
Value Function Loss: 0.00171

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00269
Policy Update Magnitude: 0.25520
Value Function Update Magnitude: 0.45650

Collected Steps per Second: 21,191.06912
Overall Steps per Second: 10,252.17492

Timestep Collection Time: 2.35967
Timestep Consumption Time: 2.51773
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.87740

Cumulative Model Updates: 317,366
Cumulative Timesteps: 2,646,688,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.45601
Policy Entropy: 4.46353
Value Function Loss: 0.00166

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00369
Policy Update Magnitude: 0.32393
Value Function Update Magnitude: 0.40700

Collected Steps per Second: 22,021.29168
Overall Steps per Second: 10,474.62725

Timestep Collection Time: 2.27162
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.77573

Cumulative Model Updates: 317,372
Cumulative Timesteps: 2,646,738,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2646738592...
Checkpoint 2646738592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.40240
Policy Entropy: 4.46263
Value Function Loss: 0.00165

Mean KL Divergence: 0.00070
SB3 Clip Fraction: 0.00499
Policy Update Magnitude: 0.27075
Value Function Update Magnitude: 0.37543

Collected Steps per Second: 22,141.45143
Overall Steps per Second: 10,250.89448

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.62099
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.88055

Cumulative Model Updates: 317,378
Cumulative Timesteps: 2,646,788,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.93333
Policy Entropy: 4.46310
Value Function Loss: 0.00154

Mean KL Divergence: 0.00059
SB3 Clip Fraction: 0.00349
Policy Update Magnitude: 0.25667
Value Function Update Magnitude: 0.34909

Collected Steps per Second: 21,986.80668
Overall Steps per Second: 10,467.42817

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.77691

Cumulative Model Updates: 317,384
Cumulative Timesteps: 2,646,838,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2646838624...
Checkpoint 2646838624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.03453
Policy Entropy: 4.46302
Value Function Loss: 0.00223

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00385
Policy Update Magnitude: 0.28255
Value Function Update Magnitude: 0.38418

Collected Steps per Second: 21,988.54256
Overall Steps per Second: 10,650.90330

Timestep Collection Time: 2.27518
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.69707

Cumulative Model Updates: 317,390
Cumulative Timesteps: 2,646,888,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.21909
Policy Entropy: 4.45972
Value Function Loss: 0.00253

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00428
Policy Update Magnitude: 0.35358
Value Function Update Magnitude: 0.38622

Collected Steps per Second: 21,544.89740
Overall Steps per Second: 10,504.86892

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.76217

Cumulative Model Updates: 317,396
Cumulative Timesteps: 2,646,938,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2646938678...
Checkpoint 2646938678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.37558
Policy Entropy: 4.46091
Value Function Loss: 0.00245

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00498
Policy Update Magnitude: 0.31772
Value Function Update Magnitude: 0.40353

Collected Steps per Second: 21,384.04927
Overall Steps per Second: 10,400.27416

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.47046
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.80968

Cumulative Model Updates: 317,402
Cumulative Timesteps: 2,646,988,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.55371
Policy Entropy: 4.46117
Value Function Loss: 0.00219

Mean KL Divergence: 0.00054
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.32587
Value Function Update Magnitude: 0.40407

Collected Steps per Second: 21,331.50553
Overall Steps per Second: 10,185.44264

Timestep Collection Time: 2.34423
Timestep Consumption Time: 2.56532
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.90956

Cumulative Model Updates: 317,408
Cumulative Timesteps: 2,647,038,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2647038706...
Checkpoint 2647038706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.28342
Policy Entropy: 4.46347
Value Function Loss: 0.00198

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00420
Policy Update Magnitude: 0.28846
Value Function Update Magnitude: 0.46431

Collected Steps per Second: 20,590.82261
Overall Steps per Second: 9,875.93829

Timestep Collection Time: 2.42836
Timestep Consumption Time: 2.63465
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 5.06301

Cumulative Model Updates: 317,414
Cumulative Timesteps: 2,647,088,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.57165
Policy Entropy: 4.46316
Value Function Loss: 0.00174

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00382
Policy Update Magnitude: 0.24374
Value Function Update Magnitude: 0.42906

Collected Steps per Second: 21,163.53569
Overall Steps per Second: 10,412.82935

Timestep Collection Time: 2.36284
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.80235

Cumulative Model Updates: 317,420
Cumulative Timesteps: 2,647,138,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2647138714...
Checkpoint 2647138714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.79238
Policy Entropy: 4.46375
Value Function Loss: 0.00198

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00395
Policy Update Magnitude: 0.21422
Value Function Update Magnitude: 0.42327

Collected Steps per Second: 21,981.20370
Overall Steps per Second: 10,549.36604

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.46495
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.73962

Cumulative Model Updates: 317,426
Cumulative Timesteps: 2,647,188,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23966
Policy Entropy: 4.46794
Value Function Loss: 0.00185

Mean KL Divergence: 0.00036
SB3 Clip Fraction: 0.00262
Policy Update Magnitude: 0.21370
Value Function Update Magnitude: 0.43882

Collected Steps per Second: 22,528.26844
Overall Steps per Second: 10,556.67530

Timestep Collection Time: 2.22014
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.73786

Cumulative Model Updates: 317,432
Cumulative Timesteps: 2,647,238,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2647238730...
Checkpoint 2647238730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.44452
Policy Entropy: 4.46877
Value Function Loss: 0.00169

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00348
Policy Update Magnitude: 0.21136
Value Function Update Magnitude: 0.36554

Collected Steps per Second: 23,232.32788
Overall Steps per Second: 10,752.12521

Timestep Collection Time: 2.15338
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.65285

Cumulative Model Updates: 317,438
Cumulative Timesteps: 2,647,288,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.25648
Policy Entropy: 4.46802
Value Function Loss: 0.00161

Mean KL Divergence: 0.00042
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.19136
Value Function Update Magnitude: 0.35142

Collected Steps per Second: 22,834.21056
Overall Steps per Second: 10,761.66053

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.64761

Cumulative Model Updates: 317,444
Cumulative Timesteps: 2,647,338,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2647338774...
Checkpoint 2647338774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.28020
Policy Entropy: 4.46264
Value Function Loss: 0.00139

Mean KL Divergence: 0.00028
SB3 Clip Fraction: 0.00229
Policy Update Magnitude: 0.19445
Value Function Update Magnitude: 0.36716

Collected Steps per Second: 22,255.61860
Overall Steps per Second: 10,657.38431

Timestep Collection Time: 2.24788
Timestep Consumption Time: 2.44633
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.69421

Cumulative Model Updates: 317,450
Cumulative Timesteps: 2,647,388,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.18577
Policy Entropy: 4.46056
Value Function Loss: 0.00135

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00441
Policy Update Magnitude: 0.19824
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 22,945.18975
Overall Steps per Second: 10,821.21332

Timestep Collection Time: 2.17928
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62092

Cumulative Model Updates: 317,456
Cumulative Timesteps: 2,647,438,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2647438806...
Checkpoint 2647438806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.39778
Policy Entropy: 4.46100
Value Function Loss: 0.00120

Mean KL Divergence: 0.00048
SB3 Clip Fraction: 0.00414
Policy Update Magnitude: 0.21073
Value Function Update Magnitude: 0.31022

Collected Steps per Second: 20,951.14532
Overall Steps per Second: 10,276.43748

Timestep Collection Time: 2.38813
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.86881

Cumulative Model Updates: 317,462
Cumulative Timesteps: 2,647,488,840

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.59938
Policy Entropy: 4.46180
Value Function Loss: 0.00151

Mean KL Divergence: 0.00030
SB3 Clip Fraction: 0.00277
Policy Update Magnitude: 0.21033
Value Function Update Magnitude: 0.28176

Collected Steps per Second: 20,442.51469
Overall Steps per Second: 10,377.83613

Timestep Collection Time: 2.44715
Timestep Consumption Time: 2.37331
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.82047

Cumulative Model Updates: 317,468
Cumulative Timesteps: 2,647,538,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2647538866...
Checkpoint 2647538866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.00711
Policy Entropy: 4.45862
Value Function Loss: 0.00191

Mean KL Divergence: 0.00046
SB3 Clip Fraction: 0.00452
Policy Update Magnitude: 0.21282
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 21,106.72337
Overall Steps per Second: 10,331.51871

Timestep Collection Time: 2.37024
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.84227

Cumulative Model Updates: 317,474
Cumulative Timesteps: 2,647,588,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.80013
Policy Entropy: 4.46049
Value Function Loss: 0.00204

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00436
Policy Update Magnitude: 0.22177
Value Function Update Magnitude: 0.37576

Collected Steps per Second: 21,048.93583
Overall Steps per Second: 10,191.80716

Timestep Collection Time: 2.37542
Timestep Consumption Time: 2.53048
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.90590

Cumulative Model Updates: 317,480
Cumulative Timesteps: 2,647,638,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2647638894...
Checkpoint 2647638894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.28026
Policy Entropy: 4.46363
Value Function Loss: 0.00160

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00343
Policy Update Magnitude: 0.22646
Value Function Update Magnitude: 0.36882

Collected Steps per Second: 21,734.42087
Overall Steps per Second: 10,473.29460

Timestep Collection Time: 2.30059
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.77424

Cumulative Model Updates: 317,486
Cumulative Timesteps: 2,647,688,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.93741
Policy Entropy: 4.46773
Value Function Loss: 0.00149

Mean KL Divergence: 0.00019
SB3 Clip Fraction: 0.00192
Policy Update Magnitude: 0.23216
Value Function Update Magnitude: 0.39803

Collected Steps per Second: 21,680.54438
Overall Steps per Second: 10,435.85808

Timestep Collection Time: 2.30649
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.79175

Cumulative Model Updates: 317,492
Cumulative Timesteps: 2,647,738,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2647738902...
Checkpoint 2647738902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.57500
Policy Entropy: 4.46781
Value Function Loss: 0.00156

Mean KL Divergence: 0.00027
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.23272
Value Function Update Magnitude: 0.36322

Collected Steps per Second: 22,378.20663
Overall Steps per Second: 10,708.73189

Timestep Collection Time: 2.23584
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.67226

Cumulative Model Updates: 317,498
Cumulative Timesteps: 2,647,788,936

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.97038
Policy Entropy: 4.46623
Value Function Loss: 0.00188

Mean KL Divergence: 0.00041
SB3 Clip Fraction: 0.00424
Policy Update Magnitude: 0.27676
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 22,461.09591
Overall Steps per Second: 10,471.13621

Timestep Collection Time: 2.22616
Timestep Consumption Time: 2.54906
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77522

Cumulative Model Updates: 317,504
Cumulative Timesteps: 2,647,838,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2647838938...
Checkpoint 2647838938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.88214
Policy Entropy: 4.46348
Value Function Loss: 0.00192

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00452
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.35222

Collected Steps per Second: 22,465.69694
Overall Steps per Second: 10,624.31804

Timestep Collection Time: 2.22615
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.70731

Cumulative Model Updates: 317,510
Cumulative Timesteps: 2,647,888,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.20074
Policy Entropy: 4.46754
Value Function Loss: 0.00160

Mean KL Divergence: 0.00049
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.25054
Value Function Update Magnitude: 0.41774

Collected Steps per Second: 22,747.88087
Overall Steps per Second: 10,804.93807

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.62807

Cumulative Model Updates: 317,516
Cumulative Timesteps: 2,647,938,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2647938956...
Checkpoint 2647938956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.53273
Policy Entropy: 4.46682
Value Function Loss: 0.00133

Mean KL Divergence: 0.00055
SB3 Clip Fraction: 0.00432
Policy Update Magnitude: 0.21502
Value Function Update Magnitude: 0.44229

Collected Steps per Second: 21,296.37863
Overall Steps per Second: 10,325.91417

Timestep Collection Time: 2.34923
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.84509

Cumulative Model Updates: 317,522
Cumulative Timesteps: 2,647,988,986

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.47017
Policy Entropy: 4.46866
Value Function Loss: 0.00112

Mean KL Divergence: 0.00060
SB3 Clip Fraction: 0.00517
Policy Update Magnitude: 0.19816
Value Function Update Magnitude: 0.37142

Collected Steps per Second: 21,851.40338
Overall Steps per Second: 10,790.82081

Timestep Collection Time: 2.28901
Timestep Consumption Time: 2.34623
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.63524

Cumulative Model Updates: 317,528
Cumulative Timesteps: 2,648,039,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2648039004...
Checkpoint 2648039004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.49351
Policy Entropy: 4.46642
Value Function Loss: 0.00130

Mean KL Divergence: 0.00051
SB3 Clip Fraction: 0.00406
Policy Update Magnitude: 0.19066
Value Function Update Magnitude: 0.33156

Collected Steps per Second: 20,216.32175
Overall Steps per Second: 10,172.10894

Timestep Collection Time: 2.47483
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.91855

Cumulative Model Updates: 317,534
Cumulative Timesteps: 2,648,089,036

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.14552
Policy Entropy: 4.46574
Value Function Loss: 0.00147

Mean KL Divergence: 0.00031
SB3 Clip Fraction: 0.00185
Policy Update Magnitude: 0.22595
Value Function Update Magnitude: 0.33484

Collected Steps per Second: 20,584.39602
Overall Steps per Second: 10,071.38725

Timestep Collection Time: 2.43000
Timestep Consumption Time: 2.53655
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.96655

Cumulative Model Updates: 317,540
Cumulative Timesteps: 2,648,139,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2648139056...
Checkpoint 2648139056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.33077
Policy Entropy: 4.46999
Value Function Loss: 0.00136

Mean KL Divergence: 0.00018
SB3 Clip Fraction: 0.00161
Policy Update Magnitude: 0.20683
Value Function Update Magnitude: 0.32300

Collected Steps per Second: 21,538.84570
Overall Steps per Second: 10,314.84448

Timestep Collection Time: 2.32194
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.84855

Cumulative Model Updates: 317,546
Cumulative Timesteps: 2,648,189,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.16450
Policy Entropy: 4.46762
Value Function Loss: 0.00144

Mean KL Divergence: 0.00029
SB3 Clip Fraction: 0.00258
Policy Update Magnitude: 0.18261
Value Function Update Magnitude: 0.35941

Collected Steps per Second: 20,193.27666
Overall Steps per Second: 9,914.83011

Timestep Collection Time: 2.47686
Timestep Consumption Time: 2.56770
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 5.04456

Cumulative Model Updates: 317,552
Cumulative Timesteps: 2,648,239,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2648239084...
Checkpoint 2648239084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.34904
Policy Entropy: 4.46824
Value Function Loss: 0.00147

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00186
Policy Update Magnitude: 0.19357
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 19,611.98126
Overall Steps per Second: 9,669.00132

Timestep Collection Time: 2.55018
Timestep Consumption Time: 2.62244
PPO Batch Consumption Time: 0.31707
Total Iteration Time: 5.17261

Cumulative Model Updates: 317,558
Cumulative Timesteps: 2,648,289,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.44263
Policy Entropy: 4.46471
Value Function Loss: 0.00179

Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00270
Policy Update Magnitude: 0.24627
Value Function Update Magnitude: 0.35394

Collected Steps per Second: 19,101.89975
Overall Steps per Second: 9,503.29897

Timestep Collection Time: 2.61765
Timestep Consumption Time: 2.64390
PPO Batch Consumption Time: 0.31241
Total Iteration Time: 5.26154

Cumulative Model Updates: 317,564
Cumulative Timesteps: 2,648,339,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2648339100...
Checkpoint 2648339100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.53405
Policy Entropy: 4.46356
Value Function Loss: 0.00186

Mean KL Divergence: 0.00039
SB3 Clip Fraction: 0.00332
Policy Update Magnitude: 0.26800
Value Function Update Magnitude: 0.38731

Collected Steps per Second: 21,452.34154
Overall Steps per Second: 9,883.34021

Timestep Collection Time: 2.33075
Timestep Consumption Time: 2.72827
PPO Batch Consumption Time: 0.32961
Total Iteration Time: 5.05902

Cumulative Model Updates: 317,570
Cumulative Timesteps: 2,648,389,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2648389100...
Checkpoint 2648389100 saved!
